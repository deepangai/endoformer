<EasyDict 0x7f410a7d7d80
  'Unet': <EasyDict 0x7f3fae0aef20
    'bilinear': False,
    'n_channels': 3,
    'n_classes': 1
  >,
  'cfp_net': <EasyDict 0x7f3fae0af060
    'block_1': 2,
    'block_2': 6,
    'classes': 1
  >,
  'cvc_unetr': <EasyDict 0x7f3fae0aee30
    'dims': [64, 128, 320, 512],
    'kernel_size': 3,
    'mlp_ratio': 4,
    'model_dir': '/workspace/Encvis/Code/src/DuAT/pvt_v2_b2.pth',
    'out_dim': 32
  >,
  'dataset': <EasyDict 0x7f3fb4e67060
    'CVC_ClinicDB': <EasyDict 0x7f3fae0afb00
      'batch_size': 8,
      'data_root': '/dataset/cv/seg/CVC-ClinicDB/',
      'image_size': 352,
      'num_workers': 4,
      'train_ratio': 0.8
    >
  >,
  'duat': <EasyDict 0x7f3fae0aede0
    'dim': 32,
    'dims': [64, 128, 320, 512],
    'model_dir': '/workspace/Encvis/Code/src/DuAT/pvt_v2_b2.pth'
  >,
  'finetune': <EasyDict 0x7f3fae0aecf0
    'checkpoint': 'CVC'
  >,
  'swin_unetr': <EasyDict 0x7f3fae0aee80
    'img_size': [352, 352],
    'in_channels': 3,
    'out_channels': 1,
    'spatial_dims': 2,
    'use_checkpoint': True
  >,
  'trainer': <EasyDict 0x7f3fae22ac50
    'lr': 0.001,
    'min_lr': 1e-07,
    'num_epochs': 300,
    'optimizer': 'adamw',
    'pred_ratio_var': 0,
    'resume': True,
    'train_ratio': 0.8,
    'warmup': 2,
    'weight_decay': 0.05,
    'weight_decay_end': 0.04
  >,
  'trans_unet': <EasyDict 0x7f3fae0aeed0
    'block_num': 8,
    'class_num': 1,
    'head_num': 4,
    'img_dim': 352,
    'in_channels': 3,
    'mlp_dim': 512,
    'out_channels': 128,
    'patch_dim': 16
  >,
  'u_netr': <EasyDict 0x7f3fae0aef70
    'img_size': 352,
    'in_channels': 3,
    'out_channels': 1,
    'spatial_dims': 2
  >,
  'unet': <EasyDict 0x7f3fae0aed40
    'channels': [4, 8, 16, 32, 64],
    'in_channels': 3,
    'out_channels': 1,
    'spatial_dims': 2,
    'strides': [2, 2, 2, 2]
  >
>
Load Model...
Load Dataloader...
[Errno 2] No such file or directory: '/workspace/Unitest/model_store/CVC/checkpoint/epoch.pth.tar'
Failed to load training state！
Start Training！
Epoch [1/300] Training [1/62] Loss: 1.16058 
Epoch [1/300] Training [2/62] Loss: 1.08144 
Epoch [1/300] Training [3/62] Loss: 1.11151 
Epoch [1/300] Training [4/62] Loss: 1.12155 
Epoch [1/300] Training [5/62] Loss: 1.15926 
Epoch [1/300] Training [6/62] Loss: 1.13153 
Epoch [1/300] Training [7/62] Loss: 1.12220 
Epoch [1/300] Training [8/62] Loss: 1.07497 
Epoch [1/300] Training [9/62] Loss: 1.15260 
Epoch [1/300] Training [10/62] Loss: 1.08188 
Epoch [1/300] Training [11/62] Loss: 1.05183 
Epoch [1/300] Training [12/62] Loss: 1.18112 
Epoch [1/300] Training [13/62] Loss: 1.16915 
Epoch [1/300] Training [14/62] Loss: 1.09714 
Epoch [1/300] Training [15/62] Loss: 1.15372 
Epoch [1/300] Training [16/62] Loss: 1.09157 
Epoch [1/300] Training [17/62] Loss: 1.12600 
Epoch [1/300] Training [18/62] Loss: 1.16670 
Epoch [1/300] Training [19/62] Loss: 1.13282 
Epoch [1/300] Training [20/62] Loss: 1.06510 
Epoch [1/300] Training [21/62] Loss: 1.05750 
Epoch [1/300] Training [22/62] Loss: 1.11117 
Epoch [1/300] Training [23/62] Loss: 1.13210 
Epoch [1/300] Training [24/62] Loss: 1.08209 
Epoch [1/300] Training [25/62] Loss: 1.14870 
Epoch [1/300] Training [26/62] Loss: 1.10834 
Epoch [1/300] Training [27/62] Loss: 1.11543 
Epoch [1/300] Training [28/62] Loss: 1.07856 
Epoch [1/300] Training [29/62] Loss: 1.17615 
Epoch [1/300] Training [30/62] Loss: 1.06972 
Epoch [1/300] Training [31/62] Loss: 1.09130 
Epoch [1/300] Training [32/62] Loss: 1.11483 
Epoch [1/300] Training [33/62] Loss: 1.11313 
Epoch [1/300] Training [34/62] Loss: 1.11485 
Epoch [1/300] Training [35/62] Loss: 1.08040 
Epoch [1/300] Training [36/62] Loss: 1.15781 
Epoch [1/300] Training [37/62] Loss: 1.07543 
Epoch [1/300] Training [38/62] Loss: 1.13774 
Epoch [1/300] Training [39/62] Loss: 1.03336 
Epoch [1/300] Training [40/62] Loss: 1.10782 
Epoch [1/300] Training [41/62] Loss: 1.03482 
Epoch [1/300] Training [42/62] Loss: 1.10572 
Epoch [1/300] Training [43/62] Loss: 1.11976 
Epoch [1/300] Training [44/62] Loss: 1.08338 
Epoch [1/300] Training [45/62] Loss: 1.14641 
Epoch [1/300] Training [46/62] Loss: 1.13664 
Epoch [1/300] Training [47/62] Loss: 1.18933 
Epoch [1/300] Training [48/62] Loss: 1.11282 
Epoch [1/300] Training [49/62] Loss: 1.07268 
Epoch [1/300] Training [50/62] Loss: 1.12437 
Epoch [1/300] Training [51/62] Loss: 1.16861 
Epoch [1/300] Training [52/62] Loss: 1.05434 
Epoch [1/300] Training [53/62] Loss: 1.16167 
Epoch [1/300] Training [54/62] Loss: 1.14767 
Epoch [1/300] Training [55/62] Loss: 1.11159 
Epoch [1/300] Training [56/62] Loss: 1.08723 
Epoch [1/300] Training [57/62] Loss: 0.98110 
Epoch [1/300] Training [58/62] Loss: 1.12789 
Epoch [1/300] Training [59/62] Loss: 1.15301 
Epoch [1/300] Training [60/62] Loss: 1.16350 
Epoch [1/300] Training [61/62] Loss: 1.11683 
Epoch [1/300] Training [62/62] Loss: 1.12187 
Epoch [1/300] Training metric {'Train/mean dice_metric': 0.16560454666614532, 'Train/mean miou_metric': 0.09540969878435135, 'Train/mean f1': 0.1750262826681137, 'Train/mean precision': 0.0969010591506958, 'Train/mean recall': 0.9033014178276062, 'Train/mean hd95_metric': 205.67059326171875}
Epoch [1/300] Validation [1/16] Loss: 1.06178  focal_loss 0.25157  dice_loss 0.81021 
Epoch [1/300] Validation [2/16] Loss: 1.11885  focal_loss 0.25964  dice_loss 0.85921 
Epoch [1/300] Validation [3/16] Loss: 1.13482  focal_loss 0.26696  dice_loss 0.86786 
Epoch [1/300] Validation [4/16] Loss: 1.11164  focal_loss 0.26363  dice_loss 0.84801 
Epoch [1/300] Validation [5/16] Loss: 1.13911  focal_loss 0.26368  dice_loss 0.87544 
Epoch [1/300] Validation [6/16] Loss: 1.12157  focal_loss 0.26074  dice_loss 0.86083 
Epoch [1/300] Validation [7/16] Loss: 1.10764  focal_loss 0.26292  dice_loss 0.84472 
Epoch [1/300] Validation [8/16] Loss: 1.16089  focal_loss 0.26315  dice_loss 0.89774 
Epoch [1/300] Validation [9/16] Loss: 1.10153  focal_loss 0.25437  dice_loss 0.84716 
Epoch [1/300] Validation [10/16] Loss: 1.10464  focal_loss 0.27119  dice_loss 0.83345 
Epoch [1/300] Validation [11/16] Loss: 1.12694  focal_loss 0.26521  dice_loss 0.86174 
Epoch [1/300] Validation [12/16] Loss: 1.16152  focal_loss 0.26026  dice_loss 0.90126 
Epoch [1/300] Validation [13/16] Loss: 1.12213  focal_loss 0.25749  dice_loss 0.86465 
Epoch [1/300] Validation [14/16] Loss: 1.13375  focal_loss 0.26200  dice_loss 0.87175 
Epoch [1/300] Validation [15/16] Loss: 1.08662  focal_loss 0.25812  dice_loss 0.82850 
Epoch [1/300] Validation [16/16] Loss: 1.04585  focal_loss 0.23667  dice_loss 0.80918 
Epoch [1/300] Validation metric {'Val/mean dice_metric': 0.16392533481121063, 'Val/mean miou_metric': 0.09419295936822891, 'Val/mean f1': 0.172822043299675, 'Val/mean precision': 0.09552473574876785, 'Val/mean recall': 0.9057102203369141, 'Val/mean hd95_metric': 206.87205505371094}
Cheakpoint...
Epoch [1/300] best acc:tensor([0.1639], device='cuda:0'), Now : mean acc: tensor([0.1639], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.16392533481121063, 'Val/mean miou_metric': 0.09419295936822891, 'Val/mean f1': 0.172822043299675, 'Val/mean precision': 0.09552473574876785, 'Val/mean recall': 0.9057102203369141, 'Val/mean hd95_metric': 206.87205505371094}
Epoch [2/300] Training [1/62] Loss: 1.09813 
Epoch [2/300] Training [2/62] Loss: 1.14176 
Epoch [2/300] Training [3/62] Loss: 1.08406 
Epoch [2/300] Training [4/62] Loss: 1.09981 
Epoch [2/300] Training [5/62] Loss: 1.09382 
Epoch [2/300] Training [6/62] Loss: 1.09258 
Epoch [2/300] Training [7/62] Loss: 1.11373 
Epoch [2/300] Training [8/62] Loss: 1.12399 
Epoch [2/300] Training [9/62] Loss: 1.06963 
Epoch [2/300] Training [10/62] Loss: 1.10440 
Epoch [2/300] Training [11/62] Loss: 1.15879 
Epoch [2/300] Training [12/62] Loss: 1.14115 
Epoch [2/300] Training [13/62] Loss: 1.11626 
Epoch [2/300] Training [14/62] Loss: 1.13020 
Epoch [2/300] Training [15/62] Loss: 1.12435 
Epoch [2/300] Training [16/62] Loss: 1.09959 
Epoch [2/300] Training [17/62] Loss: 1.12288 
Epoch [2/300] Training [18/62] Loss: 1.13700 
Epoch [2/300] Training [19/62] Loss: 1.14534 
Epoch [2/300] Training [20/62] Loss: 1.06080 
Epoch [2/300] Training [21/62] Loss: 1.10649 
Epoch [2/300] Training [22/62] Loss: 1.12835 
Epoch [2/300] Training [23/62] Loss: 1.03983 
Epoch [2/300] Training [24/62] Loss: 1.13408 
Epoch [2/300] Training [25/62] Loss: 1.16087 
Epoch [2/300] Training [26/62] Loss: 1.11501 
Epoch [2/300] Training [27/62] Loss: 1.17709 
Epoch [2/300] Training [28/62] Loss: 1.13911 
Epoch [2/300] Training [29/62] Loss: 1.12525 
Epoch [2/300] Training [30/62] Loss: 1.15311 
Epoch [2/300] Training [31/62] Loss: 1.13445 
Epoch [2/300] Training [32/62] Loss: 1.11577 
Epoch [2/300] Training [33/62] Loss: 1.11863 
Epoch [2/300] Training [34/62] Loss: 1.15836 
Epoch [2/300] Training [35/62] Loss: 1.10252 
Epoch [2/300] Training [36/62] Loss: 1.11136 
Epoch [2/300] Training [37/62] Loss: 1.14134 
Epoch [2/300] Training [38/62] Loss: 1.07038 
Epoch [2/300] Training [39/62] Loss: 1.11797 
Epoch [2/300] Training [40/62] Loss: 1.05506 
Epoch [2/300] Training [41/62] Loss: 1.14974 
Epoch [2/300] Training [42/62] Loss: 1.11684 
Epoch [2/300] Training [43/62] Loss: 1.09668 
Epoch [2/300] Training [44/62] Loss: 1.11275 
Epoch [2/300] Training [45/62] Loss: 1.09156 
Epoch [2/300] Training [46/62] Loss: 1.11725 
Epoch [2/300] Training [47/62] Loss: 1.11484 
Epoch [2/300] Training [48/62] Loss: 1.06394 
Epoch [2/300] Training [49/62] Loss: 1.21349 
Epoch [2/300] Training [50/62] Loss: 1.08245 
Epoch [2/300] Training [51/62] Loss: 1.12091 
Epoch [2/300] Training [52/62] Loss: 1.09956 
Epoch [2/300] Training [53/62] Loss: 1.06595 
Epoch [2/300] Training [54/62] Loss: 1.12966 
Epoch [2/300] Training [55/62] Loss: 1.16577 
Epoch [2/300] Training [56/62] Loss: 1.08818 
Epoch [2/300] Training [57/62] Loss: 1.10461 
Epoch [2/300] Training [58/62] Loss: 1.11549 
Epoch [2/300] Training [59/62] Loss: 1.05164 
Epoch [2/300] Training [60/62] Loss: 1.12896 
Epoch [2/300] Training [61/62] Loss: 1.07657 
Epoch [2/300] Training [62/62] Loss: 1.13102 
Epoch [2/300] Training metric {'Train/mean dice_metric': 0.16526342928409576, 'Train/mean miou_metric': 0.09520018100738525, 'Train/mean f1': 0.17453014850616455, 'Train/mean precision': 0.09661992639303207, 'Train/mean recall': 0.9013016819953918, 'Train/mean hd95_metric': 205.28878784179688}
Epoch [2/300] Validation [1/16] Loss: 1.06487  focal_loss 0.25497  dice_loss 0.80990 
Epoch [2/300] Validation [2/16] Loss: 1.12702  focal_loss 0.26831  dice_loss 0.85870 
Epoch [2/300] Validation [3/16] Loss: 1.14050  focal_loss 0.27281  dice_loss 0.86769 
Epoch [2/300] Validation [4/16] Loss: 1.11622  focal_loss 0.26842  dice_loss 0.84780 
Epoch [2/300] Validation [5/16] Loss: 1.14433  focal_loss 0.26913  dice_loss 0.87520 
Epoch [2/300] Validation [6/16] Loss: 1.12628  focal_loss 0.26655  dice_loss 0.85974 
Epoch [2/300] Validation [7/16] Loss: 1.10915  focal_loss 0.26519  dice_loss 0.84396 
Epoch [2/300] Validation [8/16] Loss: 1.16419  focal_loss 0.26691  dice_loss 0.89728 
Epoch [2/300] Validation [9/16] Loss: 1.10571  focal_loss 0.25934  dice_loss 0.84637 
Epoch [2/300] Validation [10/16] Loss: 1.10799  focal_loss 0.27543  dice_loss 0.83256 
Epoch [2/300] Validation [11/16] Loss: 1.13222  focal_loss 0.27094  dice_loss 0.86128 
Epoch [2/300] Validation [12/16] Loss: 1.16642  focal_loss 0.26534  dice_loss 0.90108 
Epoch [2/300] Validation [13/16] Loss: 1.12645  focal_loss 0.26203  dice_loss 0.86441 
Epoch [2/300] Validation [14/16] Loss: 1.14201  focal_loss 0.27088  dice_loss 0.87112 
Epoch [2/300] Validation [15/16] Loss: 1.09581  focal_loss 0.26738  dice_loss 0.82843 
Epoch [2/300] Validation [16/16] Loss: 1.04680  focal_loss 0.23880  dice_loss 0.80801 
Epoch [2/300] Validation metric {'Val/mean dice_metric': 0.16344119608402252, 'Val/mean miou_metric': 0.09388695657253265, 'Val/mean f1': 0.17228975892066956, 'Val/mean precision': 0.09524700045585632, 'Val/mean recall': 0.9014430046081543, 'Val/mean hd95_metric': 206.24349975585938}
Cheakpoint...
Epoch [2/300] best acc:tensor([0.1639], device='cuda:0'), Now : mean acc: tensor([0.1634], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.16344119608402252, 'Val/mean miou_metric': 0.09388695657253265, 'Val/mean f1': 0.17228975892066956, 'Val/mean precision': 0.09524700045585632, 'Val/mean recall': 0.9014430046081543, 'Val/mean hd95_metric': 206.24349975585938}
Epoch [3/300] Training [1/62] Loss: 1.10364 
Epoch [3/300] Training [2/62] Loss: 1.06826 
Epoch [3/300] Training [3/62] Loss: 1.04958 
Epoch [3/300] Training [4/62] Loss: 0.96971 
Epoch [3/300] Training [5/62] Loss: 0.98975 
Epoch [3/300] Training [6/62] Loss: 1.00008 
Epoch [3/300] Training [7/62] Loss: 1.00934 
Epoch [3/300] Training [8/62] Loss: 0.89880 
Epoch [3/300] Training [9/62] Loss: 0.95030 
Epoch [3/300] Training [10/62] Loss: 0.92876 
Epoch [3/300] Training [11/62] Loss: 1.01170 
Epoch [3/300] Training [12/62] Loss: 1.01207 
Epoch [3/300] Training [13/62] Loss: 0.90746 
Epoch [3/300] Training [14/62] Loss: 0.91945 
Epoch [3/300] Training [15/62] Loss: 0.95133 
Epoch [3/300] Training [16/62] Loss: 0.92051 
Epoch [3/300] Training [17/62] Loss: 0.95226 
Epoch [3/300] Training [18/62] Loss: 0.91335 
Epoch [3/300] Training [19/62] Loss: 0.90851 
Epoch [3/300] Training [20/62] Loss: 0.96279 
Epoch [3/300] Training [21/62] Loss: 0.94770 
Epoch [3/300] Training [22/62] Loss: 0.95971 
Epoch [3/300] Training [23/62] Loss: 0.87915 
Epoch [3/300] Training [24/62] Loss: 0.92773 
Epoch [3/300] Training [25/62] Loss: 0.92476 
Epoch [3/300] Training [26/62] Loss: 0.97150 
Epoch [3/300] Training [27/62] Loss: 0.91862 
Epoch [3/300] Training [28/62] Loss: 0.96690 
Epoch [3/300] Training [29/62] Loss: 0.88969 
Epoch [3/300] Training [30/62] Loss: 0.83914 
Epoch [3/300] Training [31/62] Loss: 0.94026 
Epoch [3/300] Training [32/62] Loss: 0.87860 
Epoch [3/300] Training [33/62] Loss: 0.88888 
Epoch [3/300] Training [34/62] Loss: 0.91004 
Epoch [3/300] Training [35/62] Loss: 0.87221 
Epoch [3/300] Training [36/62] Loss: 0.87863 
Epoch [3/300] Training [37/62] Loss: 0.94609 
Epoch [3/300] Training [38/62] Loss: 0.86933 
Epoch [3/300] Training [39/62] Loss: 0.94750 
Epoch [3/300] Training [40/62] Loss: 0.82539 
Epoch [3/300] Training [41/62] Loss: 0.91614 
Epoch [3/300] Training [42/62] Loss: 0.87263 
Epoch [3/300] Training [43/62] Loss: 0.94786 
Epoch [3/300] Training [44/62] Loss: 0.81199 
Epoch [3/300] Training [45/62] Loss: 0.84497 
Epoch [3/300] Training [46/62] Loss: 0.85094 
Epoch [3/300] Training [47/62] Loss: 0.89323 
Epoch [3/300] Training [48/62] Loss: 0.92846 
Epoch [3/300] Training [49/62] Loss: 0.89622 
Epoch [3/300] Training [50/62] Loss: 0.77610 
Epoch [3/300] Training [51/62] Loss: 0.81322 
Epoch [3/300] Training [52/62] Loss: 0.84632 
Epoch [3/300] Training [53/62] Loss: 0.96065 
Epoch [3/300] Training [54/62] Loss: 0.83381 
Epoch [3/300] Training [55/62] Loss: 0.85410 
Epoch [3/300] Training [56/62] Loss: 0.92259 
Epoch [3/300] Training [57/62] Loss: 0.88201 
Epoch [3/300] Training [58/62] Loss: 0.93100 
Epoch [3/300] Training [59/62] Loss: 0.92685 
Epoch [3/300] Training [60/62] Loss: 0.91780 
Epoch [3/300] Training [61/62] Loss: 0.97232 
Epoch [3/300] Training [62/62] Loss: 1.02640 
Epoch [3/300] Training metric {'Train/mean dice_metric': 0.17623481154441833, 'Train/mean miou_metric': 0.11406473070383072, 'Train/mean f1': 0.2513069808483124, 'Train/mean precision': 0.19958534836769104, 'Train/mean recall': 0.3392122685909271, 'Train/mean hd95_metric': 149.46888732910156}
Epoch [3/300] Validation [1/16] Loss: 0.85397  focal_loss 0.08337  dice_loss 0.77060 
Epoch [3/300] Validation [2/16] Loss: 0.91273  focal_loss 0.08048  dice_loss 0.83225 
Epoch [3/300] Validation [3/16] Loss: 0.92426  focal_loss 0.07827  dice_loss 0.84599 
Epoch [3/300] Validation [4/16] Loss: 0.89427  focal_loss 0.07767  dice_loss 0.81660 
Epoch [3/300] Validation [5/16] Loss: 0.91400  focal_loss 0.07456  dice_loss 0.83944 
Epoch [3/300] Validation [6/16] Loss: 0.90077  focal_loss 0.07092  dice_loss 0.82985 
Epoch [3/300] Validation [7/16] Loss: 0.87163  focal_loss 0.07337  dice_loss 0.79827 
Epoch [3/300] Validation [8/16] Loss: 0.93614  focal_loss 0.06887  dice_loss 0.86727 
Epoch [3/300] Validation [9/16] Loss: 0.88658  focal_loss 0.07796  dice_loss 0.80862 
Epoch [3/300] Validation [10/16] Loss: 0.89030  focal_loss 0.08393  dice_loss 0.80637 
Epoch [3/300] Validation [11/16] Loss: 0.89289  focal_loss 0.07160  dice_loss 0.82129 
Epoch [3/300] Validation [12/16] Loss: 0.94770  focal_loss 0.07011  dice_loss 0.87759 
Epoch [3/300] Validation [13/16] Loss: 0.89260  focal_loss 0.06942  dice_loss 0.82318 
Epoch [3/300] Validation [14/16] Loss: 0.92129  focal_loss 0.07510  dice_loss 0.84619 
Epoch [3/300] Validation [15/16] Loss: 0.88446  focal_loss 0.08761  dice_loss 0.79685 
Epoch [3/300] Validation [16/16] Loss: 0.83415  focal_loss 0.06805  dice_loss 0.76610 
Epoch [3/300] Validation metric {'Val/mean dice_metric': 0.1529833823442459, 'Val/mean miou_metric': 0.09824185073375702, 'Val/mean f1': 0.23487477004528046, 'Val/mean precision': 0.20035286247730255, 'Val/mean recall': 0.2837699055671692, 'Val/mean hd95_metric': 145.64654541015625}
Cheakpoint...
Epoch [3/300] best acc:tensor([0.1639], device='cuda:0'), Now : mean acc: tensor([0.1530], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.1529833823442459, 'Val/mean miou_metric': 0.09824185073375702, 'Val/mean f1': 0.23487477004528046, 'Val/mean precision': 0.20035286247730255, 'Val/mean recall': 0.2837699055671692, 'Val/mean hd95_metric': 145.64654541015625}
Epoch [4/300] Training [1/62] Loss: 0.85871 
Epoch [4/300] Training [2/62] Loss: 0.90557 
Epoch [4/300] Training [3/62] Loss: 0.89157 
Epoch [4/300] Training [4/62] Loss: 0.86061 
Epoch [4/300] Training [5/62] Loss: 0.90661 
Epoch [4/300] Training [6/62] Loss: 0.86131 
Epoch [4/300] Training [7/62] Loss: 0.91674 
Epoch [4/300] Training [8/62] Loss: 0.89095 
Epoch [4/300] Training [9/62] Loss: 0.95739 
Epoch [4/300] Training [10/62] Loss: 0.86305 
Epoch [4/300] Training [11/62] Loss: 0.79382 
Epoch [4/300] Training [12/62] Loss: 0.90613 
Epoch [4/300] Training [13/62] Loss: 0.92024 
Epoch [4/300] Training [14/62] Loss: 0.87947 
Epoch [4/300] Training [15/62] Loss: 0.95879 
Epoch [4/300] Training [16/62] Loss: 0.89156 
Epoch [4/300] Training [17/62] Loss: 0.86420 
Epoch [4/300] Training [18/62] Loss: 0.90869 
Epoch [4/300] Training [19/62] Loss: 0.89696 
Epoch [4/300] Training [20/62] Loss: 0.86074 
Epoch [4/300] Training [21/62] Loss: 0.90151 
Epoch [4/300] Training [22/62] Loss: 0.89858 
Epoch [4/300] Training [23/62] Loss: 0.85826 
Epoch [4/300] Training [24/62] Loss: 0.85649 
Epoch [4/300] Training [25/62] Loss: 0.90608 
Epoch [4/300] Training [26/62] Loss: 0.85493 
Epoch [4/300] Training [27/62] Loss: 0.91021 
Epoch [4/300] Training [28/62] Loss: 0.94210 
Epoch [4/300] Training [29/62] Loss: 0.85144 
Epoch [4/300] Training [30/62] Loss: 0.85200 
Epoch [4/300] Training [31/62] Loss: 0.92709 
Epoch [4/300] Training [32/62] Loss: 0.88468 
Epoch [4/300] Training [33/62] Loss: 0.87190 
Epoch [4/300] Training [34/62] Loss: 0.91539 
Epoch [4/300] Training [35/62] Loss: 0.87929 
Epoch [4/300] Training [36/62] Loss: 0.78692 
Epoch [4/300] Training [37/62] Loss: 0.85072 
Epoch [4/300] Training [38/62] Loss: 0.78517 
Epoch [4/300] Training [39/62] Loss: 0.89248 
Epoch [4/300] Training [40/62] Loss: 0.82061 
Epoch [4/300] Training [41/62] Loss: 0.94779 
Epoch [4/300] Training [42/62] Loss: 0.87771 
Epoch [4/300] Training [43/62] Loss: 0.88633 
Epoch [4/300] Training [44/62] Loss: 0.89384 
Epoch [4/300] Training [45/62] Loss: 0.90003 
Epoch [4/300] Training [46/62] Loss: 0.88567 
Epoch [4/300] Training [47/62] Loss: 0.95594 
Epoch [4/300] Training [48/62] Loss: 0.94656 
Epoch [4/300] Training [49/62] Loss: 0.87458 
Epoch [4/300] Training [50/62] Loss: 0.86054 
Epoch [4/300] Training [51/62] Loss: 0.85681 
Epoch [4/300] Training [52/62] Loss: 0.84020 
Epoch [4/300] Training [53/62] Loss: 0.89213 
Epoch [4/300] Training [54/62] Loss: 0.85126 
Epoch [4/300] Training [55/62] Loss: 0.86283 
Epoch [4/300] Training [56/62] Loss: 0.86900 
Epoch [4/300] Training [57/62] Loss: 0.85534 
Epoch [4/300] Training [58/62] Loss: 0.86089 
Epoch [4/300] Training [59/62] Loss: 0.79604 
Epoch [4/300] Training [60/62] Loss: 0.81040 
Epoch [4/300] Training [61/62] Loss: 0.79141 
Epoch [4/300] Training [62/62] Loss: 0.72420 
Epoch [4/300] Training metric {'Train/mean dice_metric': 0.0825130045413971, 'Train/mean miou_metric': 0.05557939037680626, 'Train/mean f1': 0.17721252143383026, 'Train/mean precision': 0.22457356750965118, 'Train/mean recall': 0.14634859561920166, 'Train/mean hd95_metric': 138.1168212890625}
Epoch [4/300] Validation [1/16] Loss: 0.97614  focal_loss 0.25056  dice_loss 0.72558 
Epoch [4/300] Validation [2/16] Loss: 0.90997  focal_loss 0.11916  dice_loss 0.79081 
Epoch [4/300] Validation [3/16] Loss: 0.99089  focal_loss 0.17307  dice_loss 0.81782 
Epoch [4/300] Validation [4/16] Loss: 0.91320  focal_loss 0.13960  dice_loss 0.77360 
Epoch [4/300] Validation [5/16] Loss: 0.89479  focal_loss 0.10304  dice_loss 0.79176 
Epoch [4/300] Validation [6/16] Loss: 0.86152  focal_loss 0.09112  dice_loss 0.77040 
Epoch [4/300] Validation [7/16] Loss: 0.87825  focal_loss 0.13053  dice_loss 0.74772 
Epoch [4/300] Validation [8/16] Loss: 0.97175  focal_loss 0.14667  dice_loss 0.82508 
Epoch [4/300] Validation [9/16] Loss: 0.89978  focal_loss 0.13190  dice_loss 0.76788 
Epoch [4/300] Validation [10/16] Loss: 0.99051  focal_loss 0.21975  dice_loss 0.77076 
Epoch [4/300] Validation [11/16] Loss: 0.88905  focal_loss 0.11355  dice_loss 0.77550 
Epoch [4/300] Validation [12/16] Loss: 0.93159  focal_loss 0.08819  dice_loss 0.84341 
Epoch [4/300] Validation [13/16] Loss: 0.84850  focal_loss 0.08527  dice_loss 0.76324 
Epoch [4/300] Validation [14/16] Loss: 0.91041  focal_loss 0.10452  dice_loss 0.80589 
Epoch [4/300] Validation [15/16] Loss: 0.87879  focal_loss 0.11759  dice_loss 0.76120 
Epoch [4/300] Validation [16/16] Loss: 0.72658  focal_loss 0.05251  dice_loss 0.67407 
Epoch [4/300] Validation metric {'Val/mean dice_metric': 0.12337036430835724, 'Val/mean miou_metric': 0.08249200135469437, 'Val/mean f1': 0.22486168146133423, 'Val/mean precision': 0.21428053081035614, 'Val/mean recall': 0.23654212057590485, 'Val/mean hd95_metric': 139.50869750976562}
Cheakpoint...
Epoch [4/300] best acc:tensor([0.1639], device='cuda:0'), Now : mean acc: tensor([0.1234], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.12337036430835724, 'Val/mean miou_metric': 0.08249200135469437, 'Val/mean f1': 0.22486168146133423, 'Val/mean precision': 0.21428053081035614, 'Val/mean recall': 0.23654212057590485, 'Val/mean hd95_metric': 139.50869750976562}
Epoch [5/300] Training [1/62] Loss: 0.85809 
Epoch [5/300] Training [2/62] Loss: 0.89078 
Epoch [5/300] Training [3/62] Loss: 0.92496 
Epoch [5/300] Training [4/62] Loss: 0.85893 
Epoch [5/300] Training [5/62] Loss: 0.81191 
Epoch [5/300] Training [6/62] Loss: 0.83676 
Epoch [5/300] Training [7/62] Loss: 0.82187 
Epoch [5/300] Training [8/62] Loss: 0.87005 
Epoch [5/300] Training [9/62] Loss: 0.81933 
Epoch [5/300] Training [10/62] Loss: 0.91877 
Epoch [5/300] Training [11/62] Loss: 0.94131 
Epoch [5/300] Training [12/62] Loss: 0.89352 
Epoch [5/300] Training [13/62] Loss: 0.87868 
Epoch [5/300] Training [14/62] Loss: 0.85189 
Epoch [5/300] Training [15/62] Loss: 0.85978 
Epoch [5/300] Training [16/62] Loss: 0.91211 
Epoch [5/300] Training [17/62] Loss: 0.87027 
Epoch [5/300] Training [18/62] Loss: 0.90135 
Epoch [5/300] Training [19/62] Loss: 0.90708 
Epoch [5/300] Training [20/62] Loss: 0.78616 
Epoch [5/300] Training [21/62] Loss: 0.88776 
Epoch [5/300] Training [22/62] Loss: 0.82313 
Epoch [5/300] Training [23/62] Loss: 0.90768 
Epoch [5/300] Training [24/62] Loss: 0.86617 
Epoch [5/300] Training [25/62] Loss: 0.91971 
Epoch [5/300] Training [26/62] Loss: 0.89222 
Epoch [5/300] Training [27/62] Loss: 0.92712 
Epoch [5/300] Training [28/62] Loss: 0.90758 
Epoch [5/300] Training [29/62] Loss: 0.90811 
Epoch [5/300] Training [30/62] Loss: 0.88223 
Epoch [5/300] Training [31/62] Loss: 0.83088 
Epoch [5/300] Training [32/62] Loss: 0.85228 
Epoch [5/300] Training [33/62] Loss: 0.89226 
Epoch [5/300] Training [34/62] Loss: 0.86574 
Epoch [5/300] Training [35/62] Loss: 0.83697 
Epoch [5/300] Training [36/62] Loss: 0.84481 
Epoch [5/300] Training [37/62] Loss: 0.78322 
Epoch [5/300] Training [38/62] Loss: 0.92199 
Epoch [5/300] Training [39/62] Loss: 0.80971 
Epoch [5/300] Training [40/62] Loss: 0.80024 
Epoch [5/300] Training [41/62] Loss: 0.91608 
Epoch [5/300] Training [42/62] Loss: 0.76452 
Epoch [5/300] Training [43/62] Loss: 0.88273 
Epoch [5/300] Training [44/62] Loss: 0.80564 
Epoch [5/300] Training [45/62] Loss: 0.82946 
Epoch [5/300] Training [46/62] Loss: 0.89530 
Epoch [5/300] Training [47/62] Loss: 0.85819 
Epoch [5/300] Training [48/62] Loss: 0.84828 
Epoch [5/300] Training [49/62] Loss: 0.84694 
Epoch [5/300] Training [50/62] Loss: 0.85743 
Epoch [5/300] Training [51/62] Loss: 0.78354 
Epoch [5/300] Training [52/62] Loss: 0.85954 
Epoch [5/300] Training [53/62] Loss: 0.81521 
Epoch [5/300] Training [54/62] Loss: 0.86337 
Epoch [5/300] Training [55/62] Loss: 0.81176 
Epoch [5/300] Training [56/62] Loss: 0.90345 
Epoch [5/300] Training [57/62] Loss: 0.81134 
Epoch [5/300] Training [58/62] Loss: 0.76850 
Epoch [5/300] Training [59/62] Loss: 0.82673 
Epoch [5/300] Training [60/62] Loss: 0.82952 
Epoch [5/300] Training [61/62] Loss: 0.83864 
Epoch [5/300] Training [62/62] Loss: 0.46788 
Epoch [5/300] Training metric {'Train/mean dice_metric': 0.18266107141971588, 'Train/mean miou_metric': 0.12312730401754379, 'Train/mean f1': 0.2831970453262329, 'Train/mean precision': 0.2719862759113312, 'Train/mean recall': 0.2953716814517975, 'Train/mean hd95_metric': 127.77981567382812}
Epoch [5/300] Validation [1/16] Loss: 0.90168  focal_loss 0.19756  dice_loss 0.70412 
Epoch [5/300] Validation [2/16] Loss: 0.97900  focal_loss 0.20039  dice_loss 0.77861 
Epoch [5/300] Validation [3/16] Loss: 0.97003  focal_loss 0.17562  dice_loss 0.79442 
Epoch [5/300] Validation [4/16] Loss: 0.91836  focal_loss 0.16957  dice_loss 0.74879 
Epoch [5/300] Validation [5/16] Loss: 0.95924  focal_loss 0.18255  dice_loss 0.77669 
Epoch [5/300] Validation [6/16] Loss: 0.89506  focal_loss 0.13962  dice_loss 0.75544 
Epoch [5/300] Validation [7/16] Loss: 0.86912  focal_loss 0.15656  dice_loss 0.71256 
Epoch [5/300] Validation [8/16] Loss: 0.93797  focal_loss 0.13931  dice_loss 0.79866 
Epoch [5/300] Validation [9/16] Loss: 0.92241  focal_loss 0.17461  dice_loss 0.74781 
Epoch [5/300] Validation [10/16] Loss: 0.93056  focal_loss 0.18605  dice_loss 0.74450 
Epoch [5/300] Validation [11/16] Loss: 0.88015  focal_loss 0.13807  dice_loss 0.74208 
Epoch [5/300] Validation [12/16] Loss: 0.98020  focal_loss 0.15048  dice_loss 0.82972 
Epoch [5/300] Validation [13/16] Loss: 0.87843  focal_loss 0.14073  dice_loss 0.73770 
Epoch [5/300] Validation [14/16] Loss: 0.96138  focal_loss 0.16220  dice_loss 0.79918 
Epoch [5/300] Validation [15/16] Loss: 0.94388  focal_loss 0.19862  dice_loss 0.74527 
Epoch [5/300] Validation [16/16] Loss: 0.72359  focal_loss 0.08108  dice_loss 0.64250 
Epoch [5/300] Validation metric {'Val/mean dice_metric': 0.20760320127010345, 'Val/mean miou_metric': 0.13853420317173004, 'Val/mean f1': 0.29304051399230957, 'Val/mean precision': 0.23657651245594025, 'Val/mean recall': 0.38490667939186096, 'Val/mean hd95_metric': 136.03839111328125}
Cheakpoint...
Epoch [5/300] best acc:tensor([0.2076], device='cuda:0'), Now : mean acc: tensor([0.2076], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.20760320127010345, 'Val/mean miou_metric': 0.13853420317173004, 'Val/mean f1': 0.29304051399230957, 'Val/mean precision': 0.23657651245594025, 'Val/mean recall': 0.38490667939186096, 'Val/mean hd95_metric': 136.03839111328125}
Epoch [6/300] Training [1/62] Loss: 0.83284 
Epoch [6/300] Training [2/62] Loss: 0.81604 
Epoch [6/300] Training [3/62] Loss: 0.88404 
Epoch [6/300] Training [4/62] Loss: 0.87543 
Epoch [6/300] Training [5/62] Loss: 0.75816 
Epoch [6/300] Training [6/62] Loss: 0.81832 
Epoch [6/300] Training [7/62] Loss: 0.81188 
Epoch [6/300] Training [8/62] Loss: 0.82030 
Epoch [6/300] Training [9/62] Loss: 0.86078 
Epoch [6/300] Training [10/62] Loss: 0.87398 
Epoch [6/300] Training [11/62] Loss: 0.86820 
Epoch [6/300] Training [12/62] Loss: 0.87999 
Epoch [6/300] Training [13/62] Loss: 0.81472 
Epoch [6/300] Training [14/62] Loss: 0.80065 
Epoch [6/300] Training [15/62] Loss: 0.86443 
Epoch [6/300] Training [16/62] Loss: 0.82936 
Epoch [6/300] Training [17/62] Loss: 0.79998 
Epoch [6/300] Training [18/62] Loss: 0.82088 
Epoch [6/300] Training [19/62] Loss: 0.99426 
Epoch [6/300] Training [20/62] Loss: 0.79796 
Epoch [6/300] Training [21/62] Loss: 0.82097 
Epoch [6/300] Training [22/62] Loss: 0.86679 
Epoch [6/300] Training [23/62] Loss: 0.79330 
Epoch [6/300] Training [24/62] Loss: 0.72629 
Epoch [6/300] Training [25/62] Loss: 0.87106 
Epoch [6/300] Training [26/62] Loss: 0.90863 
Epoch [6/300] Training [27/62] Loss: 0.76036 
Epoch [6/300] Training [28/62] Loss: 0.78231 
Epoch [6/300] Training [29/62] Loss: 0.80908 
Epoch [6/300] Training [30/62] Loss: 0.92452 
Epoch [6/300] Training [31/62] Loss: 0.83656 
Epoch [6/300] Training [32/62] Loss: 0.90487 
Epoch [6/300] Training [33/62] Loss: 0.78419 
Epoch [6/300] Training [34/62] Loss: 0.82095 
Epoch [6/300] Training [35/62] Loss: 0.74718 
Epoch [6/300] Training [36/62] Loss: 0.79911 
Epoch [6/300] Training [37/62] Loss: 0.87587 
Epoch [6/300] Training [38/62] Loss: 0.81201 
Epoch [6/300] Training [39/62] Loss: 0.76180 
Epoch [6/300] Training [40/62] Loss: 0.82929 
Epoch [6/300] Training [41/62] Loss: 0.74766 
Epoch [6/300] Training [42/62] Loss: 0.88720 
Epoch [6/300] Training [43/62] Loss: 0.64134 
Epoch [6/300] Training [44/62] Loss: 0.71882 
Epoch [6/300] Training [45/62] Loss: 0.91915 
Epoch [6/300] Training [46/62] Loss: 0.76813 
Epoch [6/300] Training [47/62] Loss: 0.80967 
Epoch [6/300] Training [48/62] Loss: 0.74444 
Epoch [6/300] Training [49/62] Loss: 0.85379 
Epoch [6/300] Training [50/62] Loss: 0.79051 
Epoch [6/300] Training [51/62] Loss: 0.81080 
Epoch [6/300] Training [52/62] Loss: 0.88774 
Epoch [6/300] Training [53/62] Loss: 0.80373 
Epoch [6/300] Training [54/62] Loss: 0.78118 
Epoch [6/300] Training [55/62] Loss: 0.86004 
Epoch [6/300] Training [56/62] Loss: 0.83265 
Epoch [6/300] Training [57/62] Loss: 0.73706 
Epoch [6/300] Training [58/62] Loss: 0.85179 
Epoch [6/300] Training [59/62] Loss: 0.84072 
Epoch [6/300] Training [60/62] Loss: 0.86769 
Epoch [6/300] Training [61/62] Loss: 0.82015 
Epoch [6/300] Training [62/62] Loss: 0.99397 
Epoch [6/300] Training metric {'Train/mean dice_metric': 0.34608209133148193, 'Train/mean miou_metric': 0.23538850247859955, 'Train/mean f1': 0.39636483788490295, 'Train/mean precision': 0.3220103979110718, 'Train/mean recall': 0.5153665542602539, 'Train/mean hd95_metric': 123.17764282226562}
Epoch [6/300] Validation [1/16] Loss: 0.87813  focal_loss 0.17071  dice_loss 0.70742 
Epoch [6/300] Validation [2/16] Loss: 1.01223  focal_loss 0.17132  dice_loss 0.84091 
Epoch [6/300] Validation [3/16] Loss: 0.91063  focal_loss 0.13500  dice_loss 0.77563 
Epoch [6/300] Validation [4/16] Loss: 0.90405  focal_loss 0.15198  dice_loss 0.75207 
Epoch [6/300] Validation [5/16] Loss: 0.84504  focal_loss 0.09221  dice_loss 0.75283 
Epoch [6/300] Validation [6/16] Loss: 0.92212  focal_loss 0.14021  dice_loss 0.78191 
Epoch [6/300] Validation [7/16] Loss: 0.79110  focal_loss 0.11679  dice_loss 0.67430 
Epoch [6/300] Validation [8/16] Loss: 0.93135  focal_loss 0.11986  dice_loss 0.81149 
Epoch [6/300] Validation [9/16] Loss: 0.83025  focal_loss 0.12054  dice_loss 0.70972 
Epoch [6/300] Validation [10/16] Loss: 0.86279  focal_loss 0.12842  dice_loss 0.73437 
Epoch [6/300] Validation [11/16] Loss: 0.83019  focal_loss 0.11854  dice_loss 0.71165 
Epoch [6/300] Validation [12/16] Loss: 0.95062  focal_loss 0.11551  dice_loss 0.83511 
Epoch [6/300] Validation [13/16] Loss: 0.87091  focal_loss 0.13521  dice_loss 0.73571 
Epoch [6/300] Validation [14/16] Loss: 1.05367  focal_loss 0.17118  dice_loss 0.88249 
Epoch [6/300] Validation [15/16] Loss: 0.84863  focal_loss 0.13361  dice_loss 0.71502 
Epoch [6/300] Validation [16/16] Loss: 0.89905  focal_loss 0.16190  dice_loss 0.73715 
Epoch [6/300] Validation metric {'Val/mean dice_metric': 0.3288266062736511, 'Val/mean miou_metric': 0.22176288068294525, 'Val/mean f1': 0.37240636348724365, 'Val/mean precision': 0.29397818446159363, 'Val/mean recall': 0.5079069137573242, 'Val/mean hd95_metric': 124.74677276611328}
Cheakpoint...
Epoch [6/300] best acc:tensor([0.3288], device='cuda:0'), Now : mean acc: tensor([0.3288], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3288266062736511, 'Val/mean miou_metric': 0.22176288068294525, 'Val/mean f1': 0.37240636348724365, 'Val/mean precision': 0.29397818446159363, 'Val/mean recall': 0.5079069137573242, 'Val/mean hd95_metric': 124.74677276611328}
Epoch [7/300] Training [1/62] Loss: 0.71364 
Epoch [7/300] Training [2/62] Loss: 0.82079 
Epoch [7/300] Training [3/62] Loss: 0.90707 
Epoch [7/300] Training [4/62] Loss: 0.69392 
Epoch [7/300] Training [5/62] Loss: 0.73918 
Epoch [7/300] Training [6/62] Loss: 0.84985 
Epoch [7/300] Training [7/62] Loss: 0.78843 
Epoch [7/300] Training [8/62] Loss: 0.78684 
Epoch [7/300] Training [9/62] Loss: 0.82998 
Epoch [7/300] Training [10/62] Loss: 0.85897 
Epoch [7/300] Training [11/62] Loss: 0.66692 
Epoch [7/300] Training [12/62] Loss: 0.89507 
Epoch [7/300] Training [13/62] Loss: 0.86707 
Epoch [7/300] Training [14/62] Loss: 0.85770 
Epoch [7/300] Training [15/62] Loss: 0.80587 
Epoch [7/300] Training [16/62] Loss: 0.85454 
Epoch [7/300] Training [17/62] Loss: 0.86645 
Epoch [7/300] Training [18/62] Loss: 0.93994 
Epoch [7/300] Training [19/62] Loss: 0.88100 
Epoch [7/300] Training [20/62] Loss: 0.87056 
Epoch [7/300] Training [21/62] Loss: 0.80069 
Epoch [7/300] Training [22/62] Loss: 0.84311 
Epoch [7/300] Training [23/62] Loss: 0.76052 
Epoch [7/300] Training [24/62] Loss: 0.80901 
Epoch [7/300] Training [25/62] Loss: 0.91416 
Epoch [7/300] Training [26/62] Loss: 0.80735 
Epoch [7/300] Training [27/62] Loss: 0.84685 
Epoch [7/300] Training [28/62] Loss: 0.93261 
Epoch [7/300] Training [29/62] Loss: 0.79762 
Epoch [7/300] Training [30/62] Loss: 0.77491 
Epoch [7/300] Training [31/62] Loss: 0.80513 
Epoch [7/300] Training [32/62] Loss: 0.70169 
Epoch [7/300] Training [33/62] Loss: 0.82064 
Epoch [7/300] Training [34/62] Loss: 0.82415 
Epoch [7/300] Training [35/62] Loss: 0.87888 
Epoch [7/300] Training [36/62] Loss: 0.86325 
Epoch [7/300] Training [37/62] Loss: 0.80408 
Epoch [7/300] Training [38/62] Loss: 0.84387 
Epoch [7/300] Training [39/62] Loss: 0.76875 
Epoch [7/300] Training [40/62] Loss: 0.75945 
Epoch [7/300] Training [41/62] Loss: 0.73202 
Epoch [7/300] Training [42/62] Loss: 0.81807 
Epoch [7/300] Training [43/62] Loss: 0.83837 
Epoch [7/300] Training [44/62] Loss: 0.80329 
Epoch [7/300] Training [45/62] Loss: 0.94746 
Epoch [7/300] Training [46/62] Loss: 0.82969 
Epoch [7/300] Training [47/62] Loss: 0.81181 
Epoch [7/300] Training [48/62] Loss: 0.78107 
Epoch [7/300] Training [49/62] Loss: 0.78926 
Epoch [7/300] Training [50/62] Loss: 0.82833 
Epoch [7/300] Training [51/62] Loss: 0.83349 
Epoch [7/300] Training [52/62] Loss: 0.69397 
Epoch [7/300] Training [53/62] Loss: 0.71426 
Epoch [7/300] Training [54/62] Loss: 0.79256 
Epoch [7/300] Training [55/62] Loss: 0.81499 
Epoch [7/300] Training [56/62] Loss: 0.84859 
Epoch [7/300] Training [57/62] Loss: 0.71256 
Epoch [7/300] Training [58/62] Loss: 0.75837 
Epoch [7/300] Training [59/62] Loss: 0.68353 
Epoch [7/300] Training [60/62] Loss: 0.76017 
Epoch [7/300] Training [61/62] Loss: 0.94996 
Epoch [7/300] Training [62/62] Loss: 1.01071 
Epoch [7/300] Training metric {'Train/mean dice_metric': 0.3579955995082855, 'Train/mean miou_metric': 0.24679510295391083, 'Train/mean f1': 0.41494220495224, 'Train/mean precision': 0.3357560932636261, 'Train/mean recall': 0.5430073142051697, 'Train/mean hd95_metric': 119.83008575439453}
Epoch [7/300] Validation [1/16] Loss: 0.84753  focal_loss 0.16914  dice_loss 0.67839 
Epoch [7/300] Validation [2/16] Loss: 0.96515  focal_loss 0.20617  dice_loss 0.75899 
Epoch [7/300] Validation [3/16] Loss: 0.94621  focal_loss 0.17966  dice_loss 0.76655 
Epoch [7/300] Validation [4/16] Loss: 0.91645  focal_loss 0.18426  dice_loss 0.73219 
Epoch [7/300] Validation [5/16] Loss: 0.90265  focal_loss 0.17770  dice_loss 0.72494 
Epoch [7/300] Validation [6/16] Loss: 0.88488  focal_loss 0.15614  dice_loss 0.72874 
Epoch [7/300] Validation [7/16] Loss: 0.82757  focal_loss 0.16675  dice_loss 0.66082 
Epoch [7/300] Validation [8/16] Loss: 0.92448  focal_loss 0.13840  dice_loss 0.78608 
Epoch [7/300] Validation [9/16] Loss: 0.88665  focal_loss 0.17662  dice_loss 0.71002 
Epoch [7/300] Validation [10/16] Loss: 0.87420  focal_loss 0.15986  dice_loss 0.71434 
Epoch [7/300] Validation [11/16] Loss: 0.85523  focal_loss 0.15244  dice_loss 0.70278 
Epoch [7/300] Validation [12/16] Loss: 0.96361  focal_loss 0.16250  dice_loss 0.80111 
Epoch [7/300] Validation [13/16] Loss: 0.86385  focal_loss 0.15172  dice_loss 0.71213 
Epoch [7/300] Validation [14/16] Loss: 0.98427  focal_loss 0.17817  dice_loss 0.80611 
Epoch [7/300] Validation [15/16] Loss: 0.89169  focal_loss 0.19230  dice_loss 0.69939 
Epoch [7/300] Validation [16/16] Loss: 0.74435  focal_loss 0.12918  dice_loss 0.61517 
Epoch [7/300] Validation metric {'Val/mean dice_metric': 0.3519410192966461, 'Val/mean miou_metric': 0.24054940044879913, 'Val/mean f1': 0.3929508626461029, 'Val/mean precision': 0.2963995337486267, 'Val/mean recall': 0.5827946662902832, 'Val/mean hd95_metric': 124.1235122680664}
Cheakpoint...
Epoch [7/300] best acc:tensor([0.3519], device='cuda:0'), Now : mean acc: tensor([0.3519], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3519410192966461, 'Val/mean miou_metric': 0.24054940044879913, 'Val/mean f1': 0.3929508626461029, 'Val/mean precision': 0.2963995337486267, 'Val/mean recall': 0.5827946662902832, 'Val/mean hd95_metric': 124.1235122680664}
Epoch [8/300] Training [1/62] Loss: 0.85941 
Epoch [8/300] Training [2/62] Loss: 0.73358 
Epoch [8/300] Training [3/62] Loss: 0.80163 
Epoch [8/300] Training [4/62] Loss: 0.73128 
Epoch [8/300] Training [5/62] Loss: 0.87358 
Epoch [8/300] Training [6/62] Loss: 0.75302 
Epoch [8/300] Training [7/62] Loss: 0.82203 
Epoch [8/300] Training [8/62] Loss: 0.83258 
Epoch [8/300] Training [9/62] Loss: 0.85298 
Epoch [8/300] Training [10/62] Loss: 0.94079 
Epoch [8/300] Training [11/62] Loss: 0.86927 
Epoch [8/300] Training [12/62] Loss: 0.84547 
Epoch [8/300] Training [13/62] Loss: 0.77272 
Epoch [8/300] Training [14/62] Loss: 0.80696 
Epoch [8/300] Training [15/62] Loss: 0.82197 
Epoch [8/300] Training [16/62] Loss: 0.87919 
Epoch [8/300] Training [17/62] Loss: 0.78360 
Epoch [8/300] Training [18/62] Loss: 0.78635 
Epoch [8/300] Training [19/62] Loss: 0.76940 
Epoch [8/300] Training [20/62] Loss: 0.85549 
Epoch [8/300] Training [21/62] Loss: 0.81189 
Epoch [8/300] Training [22/62] Loss: 0.82671 
Epoch [8/300] Training [23/62] Loss: 0.85936 
Epoch [8/300] Training [24/62] Loss: 0.79829 
Epoch [8/300] Training [25/62] Loss: 0.74372 
Epoch [8/300] Training [26/62] Loss: 0.89246 
Epoch [8/300] Training [27/62] Loss: 0.79225 
Epoch [8/300] Training [28/62] Loss: 0.75453 
Epoch [8/300] Training [29/62] Loss: 0.72898 
Epoch [8/300] Training [30/62] Loss: 0.86419 
Epoch [8/300] Training [31/62] Loss: 0.83862 
Epoch [8/300] Training [32/62] Loss: 0.82044 
Epoch [8/300] Training [33/62] Loss: 0.85163 
Epoch [8/300] Training [34/62] Loss: 0.88864 
Epoch [8/300] Training [35/62] Loss: 0.80818 
Epoch [8/300] Training [36/62] Loss: 0.80144 
Epoch [8/300] Training [37/62] Loss: 0.80533 
Epoch [8/300] Training [38/62] Loss: 0.81111 
Epoch [8/300] Training [39/62] Loss: 0.82847 
Epoch [8/300] Training [40/62] Loss: 0.82954 
Epoch [8/300] Training [41/62] Loss: 0.75832 
Epoch [8/300] Training [42/62] Loss: 0.79395 
Epoch [8/300] Training [43/62] Loss: 0.86139 
Epoch [8/300] Training [44/62] Loss: 0.82336 
Epoch [8/300] Training [45/62] Loss: 0.86033 
Epoch [8/300] Training [46/62] Loss: 0.78378 
Epoch [8/300] Training [47/62] Loss: 0.82254 
Epoch [8/300] Training [48/62] Loss: 0.81264 
Epoch [8/300] Training [49/62] Loss: 0.70584 
Epoch [8/300] Training [50/62] Loss: 0.78166 
Epoch [8/300] Training [51/62] Loss: 0.79846 
Epoch [8/300] Training [52/62] Loss: 0.86418 
Epoch [8/300] Training [53/62] Loss: 0.82243 
Epoch [8/300] Training [54/62] Loss: 0.80877 
Epoch [8/300] Training [55/62] Loss: 0.74691 
Epoch [8/300] Training [56/62] Loss: 0.81604 
Epoch [8/300] Training [57/62] Loss: 0.76489 
Epoch [8/300] Training [58/62] Loss: 0.86994 
Epoch [8/300] Training [59/62] Loss: 0.71357 
Epoch [8/300] Training [60/62] Loss: 0.77827 
Epoch [8/300] Training [61/62] Loss: 0.77915 
Epoch [8/300] Training [62/62] Loss: 0.89763 
Epoch [8/300] Training metric {'Train/mean dice_metric': 0.3593474328517914, 'Train/mean miou_metric': 0.24776391685009003, 'Train/mean f1': 0.4127846360206604, 'Train/mean precision': 0.33338621258735657, 'Train/mean recall': 0.5418241024017334, 'Train/mean hd95_metric': 120.55148315429688}
Epoch [8/300] Validation [1/16] Loss: 0.87347  focal_loss 0.18187  dice_loss 0.69161 
Epoch [8/300] Validation [2/16] Loss: 0.91302  focal_loss 0.11527  dice_loss 0.79775 
Epoch [8/300] Validation [3/16] Loss: 0.92168  focal_loss 0.13359  dice_loss 0.78809 
Epoch [8/300] Validation [4/16] Loss: 0.84517  focal_loss 0.12247  dice_loss 0.72270 
Epoch [8/300] Validation [5/16] Loss: 0.81727  focal_loss 0.08246  dice_loss 0.73481 
Epoch [8/300] Validation [6/16] Loss: 0.83486  focal_loss 0.10254  dice_loss 0.73232 
Epoch [8/300] Validation [7/16] Loss: 0.76210  focal_loss 0.09114  dice_loss 0.67095 
Epoch [8/300] Validation [8/16] Loss: 0.90370  focal_loss 0.10330  dice_loss 0.80041 
Epoch [8/300] Validation [9/16] Loss: 0.78522  focal_loss 0.09219  dice_loss 0.69303 
Epoch [8/300] Validation [10/16] Loss: 0.79994  focal_loss 0.11611  dice_loss 0.68384 
Epoch [8/300] Validation [11/16] Loss: 0.78060  focal_loss 0.07321  dice_loss 0.70739 
Epoch [8/300] Validation [12/16] Loss: 0.88943  focal_loss 0.06552  dice_loss 0.82391 
Epoch [8/300] Validation [13/16] Loss: 0.86024  focal_loss 0.11050  dice_loss 0.74974 
Epoch [8/300] Validation [14/16] Loss: 0.96274  focal_loss 0.13372  dice_loss 0.82903 
Epoch [8/300] Validation [15/16] Loss: 0.85832  focal_loss 0.11570  dice_loss 0.74261 
Epoch [8/300] Validation [16/16] Loss: 0.82866  focal_loss 0.12399  dice_loss 0.70466 
Epoch [8/300] Validation metric {'Val/mean dice_metric': 0.33985355496406555, 'Val/mean miou_metric': 0.2327156513929367, 'Val/mean f1': 0.40079590678215027, 'Val/mean precision': 0.33503058552742004, 'Val/mean recall': 0.4986863434314728, 'Val/mean hd95_metric': 122.42296600341797}
Cheakpoint...
Epoch [8/300] best acc:tensor([0.3519], device='cuda:0'), Now : mean acc: tensor([0.3399], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.33985355496406555, 'Val/mean miou_metric': 0.2327156513929367, 'Val/mean f1': 0.40079590678215027, 'Val/mean precision': 0.33503058552742004, 'Val/mean recall': 0.4986863434314728, 'Val/mean hd95_metric': 122.42296600341797}
Epoch [9/300] Training [1/62] Loss: 0.78930 
Epoch [9/300] Training [2/62] Loss: 0.81199 
Epoch [9/300] Training [3/62] Loss: 0.74862 
Epoch [9/300] Training [4/62] Loss: 0.86924 
Epoch [9/300] Training [5/62] Loss: 0.85230 
Epoch [9/300] Training [6/62] Loss: 0.79898 
Epoch [9/300] Training [7/62] Loss: 0.82157 
Epoch [9/300] Training [8/62] Loss: 0.90095 
Epoch [9/300] Training [9/62] Loss: 0.83979 
Epoch [9/300] Training [10/62] Loss: 0.75216 
Epoch [9/300] Training [11/62] Loss: 0.63172 
Epoch [9/300] Training [12/62] Loss: 0.85219 
Epoch [9/300] Training [13/62] Loss: 0.84278 
Epoch [9/300] Training [14/62] Loss: 0.82001 
Epoch [9/300] Training [15/62] Loss: 0.85470 
Epoch [9/300] Training [16/62] Loss: 0.80840 
Epoch [9/300] Training [17/62] Loss: 0.72451 
Epoch [9/300] Training [18/62] Loss: 0.77197 
Epoch [9/300] Training [19/62] Loss: 0.80359 
Epoch [9/300] Training [20/62] Loss: 0.78688 
Epoch [9/300] Training [21/62] Loss: 0.86061 
Epoch [9/300] Training [22/62] Loss: 0.71360 
Epoch [9/300] Training [23/62] Loss: 0.79308 
Epoch [9/300] Training [24/62] Loss: 0.81543 
Epoch [9/300] Training [25/62] Loss: 0.80248 
Epoch [9/300] Training [26/62] Loss: 0.86107 
Epoch [9/300] Training [27/62] Loss: 0.92813 
Epoch [9/300] Training [28/62] Loss: 0.87164 
Epoch [9/300] Training [29/62] Loss: 0.76511 
Epoch [9/300] Training [30/62] Loss: 0.79799 
Epoch [9/300] Training [31/62] Loss: 0.77252 
Epoch [9/300] Training [32/62] Loss: 0.74844 
Epoch [9/300] Training [33/62] Loss: 0.85139 
Epoch [9/300] Training [34/62] Loss: 0.75413 
Epoch [9/300] Training [35/62] Loss: 0.85304 
Epoch [9/300] Training [36/62] Loss: 0.75290 
Epoch [9/300] Training [37/62] Loss: 0.77108 
Epoch [9/300] Training [38/62] Loss: 0.69233 
Epoch [9/300] Training [39/62] Loss: 0.71377 
Epoch [9/300] Training [40/62] Loss: 0.80154 
Epoch [9/300] Training [41/62] Loss: 0.67749 
Epoch [9/300] Training [42/62] Loss: 0.89375 
Epoch [9/300] Training [43/62] Loss: 0.79875 
Epoch [9/300] Training [44/62] Loss: 0.77968 
Epoch [9/300] Training [45/62] Loss: 0.70506 
Epoch [9/300] Training [46/62] Loss: 0.85720 
Epoch [9/300] Training [47/62] Loss: 0.94926 
Epoch [9/300] Training [48/62] Loss: 0.72389 
Epoch [9/300] Training [49/62] Loss: 0.89759 
Epoch [9/300] Training [50/62] Loss: 0.91046 
Epoch [9/300] Training [51/62] Loss: 0.85612 
Epoch [9/300] Training [52/62] Loss: 0.76606 
Epoch [9/300] Training [53/62] Loss: 0.73773 
Epoch [9/300] Training [54/62] Loss: 0.80814 
Epoch [9/300] Training [55/62] Loss: 0.84193 
Epoch [9/300] Training [56/62] Loss: 0.83714 
Epoch [9/300] Training [57/62] Loss: 0.89237 
Epoch [9/300] Training [58/62] Loss: 0.88415 
Epoch [9/300] Training [59/62] Loss: 0.83301 
Epoch [9/300] Training [60/62] Loss: 0.72033 
Epoch [9/300] Training [61/62] Loss: 0.85895 
Epoch [9/300] Training [62/62] Loss: 0.98729 
Epoch [9/300] Training metric {'Train/mean dice_metric': 0.3755187392234802, 'Train/mean miou_metric': 0.2596406936645508, 'Train/mean f1': 0.4288879632949829, 'Train/mean precision': 0.350044310092926, 'Train/mean recall': 0.5535746216773987, 'Train/mean hd95_metric': 117.90015411376953}
Epoch [9/300] Validation [1/16] Loss: 0.79843  focal_loss 0.10313  dice_loss 0.69530 
Epoch [9/300] Validation [2/16] Loss: 0.87438  focal_loss 0.09188  dice_loss 0.78251 
Epoch [9/300] Validation [3/16] Loss: 0.89875  focal_loss 0.10831  dice_loss 0.79044 
Epoch [9/300] Validation [4/16] Loss: 0.84962  focal_loss 0.09949  dice_loss 0.75014 
Epoch [9/300] Validation [5/16] Loss: 0.82914  focal_loss 0.08294  dice_loss 0.74621 
Epoch [9/300] Validation [6/16] Loss: 0.84698  focal_loss 0.09001  dice_loss 0.75696 
Epoch [9/300] Validation [7/16] Loss: 0.78720  focal_loss 0.08734  dice_loss 0.69986 
Epoch [9/300] Validation [8/16] Loss: 0.90136  focal_loss 0.08515  dice_loss 0.81621 
Epoch [9/300] Validation [9/16] Loss: 0.82077  focal_loss 0.08518  dice_loss 0.73560 
Epoch [9/300] Validation [10/16] Loss: 0.82318  focal_loss 0.09263  dice_loss 0.73054 
Epoch [9/300] Validation [11/16] Loss: 0.80724  focal_loss 0.07140  dice_loss 0.73584 
Epoch [9/300] Validation [12/16] Loss: 0.89442  focal_loss 0.07512  dice_loss 0.81930 
Epoch [9/300] Validation [13/16] Loss: 0.83424  focal_loss 0.08795  dice_loss 0.74629 
Epoch [9/300] Validation [14/16] Loss: 0.91313  focal_loss 0.10347  dice_loss 0.80966 
Epoch [9/300] Validation [15/16] Loss: 0.83321  focal_loss 0.10262  dice_loss 0.73058 
Epoch [9/300] Validation [16/16] Loss: 0.72958  focal_loss 0.06801  dice_loss 0.66157 
Epoch [9/300] Validation metric {'Val/mean dice_metric': 0.3699663281440735, 'Val/mean miou_metric': 0.2536437213420868, 'Val/mean f1': 0.4150317907333374, 'Val/mean precision': 0.32543274760246277, 'Val/mean recall': 0.5727126598358154, 'Val/mean hd95_metric': 120.70484924316406}
Cheakpoint...
Epoch [9/300] best acc:tensor([0.3700], device='cuda:0'), Now : mean acc: tensor([0.3700], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3699663281440735, 'Val/mean miou_metric': 0.2536437213420868, 'Val/mean f1': 0.4150317907333374, 'Val/mean precision': 0.32543274760246277, 'Val/mean recall': 0.5727126598358154, 'Val/mean hd95_metric': 120.70484924316406}
Epoch [10/300] Training [1/62] Loss: 0.76897 
Epoch [10/300] Training [2/62] Loss: 0.76226 
Epoch [10/300] Training [3/62] Loss: 0.77039 
Epoch [10/300] Training [4/62] Loss: 0.87028 
Epoch [10/300] Training [5/62] Loss: 0.84096 
Epoch [10/300] Training [6/62] Loss: 0.77124 
Epoch [10/300] Training [7/62] Loss: 0.80759 
Epoch [10/300] Training [8/62] Loss: 0.81103 
Epoch [10/300] Training [9/62] Loss: 0.73015 
Epoch [10/300] Training [10/62] Loss: 0.90349 
Epoch [10/300] Training [11/62] Loss: 0.75807 
Epoch [10/300] Training [12/62] Loss: 0.72432 
Epoch [10/300] Training [13/62] Loss: 0.81096 
Epoch [10/300] Training [14/62] Loss: 0.84648 
Epoch [10/300] Training [15/62] Loss: 0.71170 
Epoch [10/300] Training [16/62] Loss: 0.80288 
Epoch [10/300] Training [17/62] Loss: 0.77825 
Epoch [10/300] Training [18/62] Loss: 0.66501 
Epoch [10/300] Training [19/62] Loss: 0.70332 
Epoch [10/300] Training [20/62] Loss: 0.80247 
Epoch [10/300] Training [21/62] Loss: 0.76405 
Epoch [10/300] Training [22/62] Loss: 0.84159 
Epoch [10/300] Training [23/62] Loss: 0.71921 
Epoch [10/300] Training [24/62] Loss: 0.71835 
Epoch [10/300] Training [25/62] Loss: 0.77385 
Epoch [10/300] Training [26/62] Loss: 0.73988 
Epoch [10/300] Training [27/62] Loss: 0.92693 
Epoch [10/300] Training [28/62] Loss: 0.80918 
Epoch [10/300] Training [29/62] Loss: 0.78257 
Epoch [10/300] Training [30/62] Loss: 0.82631 
Epoch [10/300] Training [31/62] Loss: 0.91195 
Epoch [10/300] Training [32/62] Loss: 0.87495 
Epoch [10/300] Training [33/62] Loss: 0.82981 
Epoch [10/300] Training [34/62] Loss: 0.72659 
Epoch [10/300] Training [35/62] Loss: 0.75702 
Epoch [10/300] Training [36/62] Loss: 0.89383 
Epoch [10/300] Training [37/62] Loss: 0.81308 
Epoch [10/300] Training [38/62] Loss: 0.82260 
Epoch [10/300] Training [39/62] Loss: 0.84975 
Epoch [10/300] Training [40/62] Loss: 0.81997 
Epoch [10/300] Training [41/62] Loss: 0.79763 
Epoch [10/300] Training [42/62] Loss: 0.77273 
Epoch [10/300] Training [43/62] Loss: 0.68559 
Epoch [10/300] Training [44/62] Loss: 0.74889 
Epoch [10/300] Training [45/62] Loss: 0.70255 
Epoch [10/300] Training [46/62] Loss: 0.91469 
Epoch [10/300] Training [47/62] Loss: 0.74729 
Epoch [10/300] Training [48/62] Loss: 0.82060 
Epoch [10/300] Training [49/62] Loss: 0.73949 
Epoch [10/300] Training [50/62] Loss: 0.68982 
Epoch [10/300] Training [51/62] Loss: 0.89611 
Epoch [10/300] Training [52/62] Loss: 0.79987 
Epoch [10/300] Training [53/62] Loss: 0.78668 
Epoch [10/300] Training [54/62] Loss: 0.85453 
Epoch [10/300] Training [55/62] Loss: 0.79914 
Epoch [10/300] Training [56/62] Loss: 0.72436 
Epoch [10/300] Training [57/62] Loss: 0.77179 
Epoch [10/300] Training [58/62] Loss: 0.74698 
Epoch [10/300] Training [59/62] Loss: 0.86735 
Epoch [10/300] Training [60/62] Loss: 0.80564 
Epoch [10/300] Training [61/62] Loss: 0.96657 
Epoch [10/300] Training [62/62] Loss: 0.62900 
Epoch [10/300] Training metric {'Train/mean dice_metric': 0.3839969336986542, 'Train/mean miou_metric': 0.26839932799339294, 'Train/mean f1': 0.4512281119823456, 'Train/mean precision': 0.3689468801021576, 'Train/mean recall': 0.5807434320449829, 'Train/mean hd95_metric': 116.4732666015625}
Epoch [10/300] Validation [1/16] Loss: 0.90560  focal_loss 0.19681  dice_loss 0.70879 
Epoch [10/300] Validation [2/16] Loss: 1.00386  focal_loss 0.16188  dice_loss 0.84198 
Epoch [10/300] Validation [3/16] Loss: 0.96912  focal_loss 0.17308  dice_loss 0.79603 
Epoch [10/300] Validation [4/16] Loss: 0.97587  focal_loss 0.18199  dice_loss 0.79388 
Epoch [10/300] Validation [5/16] Loss: 0.91214  focal_loss 0.11642  dice_loss 0.79571 
Epoch [10/300] Validation [6/16] Loss: 0.98815  focal_loss 0.17970  dice_loss 0.80845 
Epoch [10/300] Validation [7/16] Loss: 0.84678  focal_loss 0.13111  dice_loss 0.71567 
Epoch [10/300] Validation [8/16] Loss: 1.06486  focal_loss 0.20922  dice_loss 0.85564 
Epoch [10/300] Validation [9/16] Loss: 0.90703  focal_loss 0.15038  dice_loss 0.75665 
Epoch [10/300] Validation [10/16] Loss: 0.92596  focal_loss 0.15652  dice_loss 0.76944 
Epoch [10/300] Validation [11/16] Loss: 0.93189  focal_loss 0.16945  dice_loss 0.76243 
Epoch [10/300] Validation [12/16] Loss: 1.03645  focal_loss 0.18170  dice_loss 0.85475 
Epoch [10/300] Validation [13/16] Loss: 0.95301  focal_loss 0.17231  dice_loss 0.78070 
Epoch [10/300] Validation [14/16] Loss: 1.06978  focal_loss 0.21665  dice_loss 0.85313 
Epoch [10/300] Validation [15/16] Loss: 0.87744  focal_loss 0.13917  dice_loss 0.73826 
Epoch [10/300] Validation [16/16] Loss: 0.99324  focal_loss 0.23227  dice_loss 0.76097 
Epoch [10/300] Validation metric {'Val/mean dice_metric': 0.34675613045692444, 'Val/mean miou_metric': 0.23876190185546875, 'Val/mean f1': 0.38878509402275085, 'Val/mean precision': 0.2987837791442871, 'Val/mean recall': 0.5563814043998718, 'Val/mean hd95_metric': 123.51387786865234}
Cheakpoint...
Epoch [10/300] best acc:tensor([0.3700], device='cuda:0'), Now : mean acc: tensor([0.3468], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.34675613045692444, 'Val/mean miou_metric': 0.23876190185546875, 'Val/mean f1': 0.38878509402275085, 'Val/mean precision': 0.2987837791442871, 'Val/mean recall': 0.5563814043998718, 'Val/mean hd95_metric': 123.51387786865234}
Epoch [11/300] Training [1/62] Loss: 0.84623 
Epoch [11/300] Training [2/62] Loss: 0.85077 
Epoch [11/300] Training [3/62] Loss: 0.75958 
Epoch [11/300] Training [4/62] Loss: 0.76929 
Epoch [11/300] Training [5/62] Loss: 0.81979 
Epoch [11/300] Training [6/62] Loss: 0.80037 
Epoch [11/300] Training [7/62] Loss: 0.80607 
Epoch [11/300] Training [8/62] Loss: 0.81475 
Epoch [11/300] Training [9/62] Loss: 0.83448 
Epoch [11/300] Training [10/62] Loss: 0.86795 
Epoch [11/300] Training [11/62] Loss: 0.79130 
Epoch [11/300] Training [12/62] Loss: 0.72743 
Epoch [11/300] Training [13/62] Loss: 0.77953 
Epoch [11/300] Training [14/62] Loss: 0.82162 
Epoch [11/300] Training [15/62] Loss: 0.75905 
Epoch [11/300] Training [16/62] Loss: 0.74879 
Epoch [11/300] Training [17/62] Loss: 0.68192 
Epoch [11/300] Training [18/62] Loss: 0.72371 
Epoch [11/300] Training [19/62] Loss: 0.70410 
Epoch [11/300] Training [20/62] Loss: 0.81001 
Epoch [11/300] Training [21/62] Loss: 0.67237 
Epoch [11/300] Training [22/62] Loss: 0.77692 
Epoch [11/300] Training [23/62] Loss: 0.82488 
Epoch [11/300] Training [24/62] Loss: 0.74518 
Epoch [11/300] Training [25/62] Loss: 0.77995 
Epoch [11/300] Training [26/62] Loss: 0.76818 
Epoch [11/300] Training [27/62] Loss: 0.76100 
Epoch [11/300] Training [28/62] Loss: 0.81034 
Epoch [11/300] Training [29/62] Loss: 0.80432 
Epoch [11/300] Training [30/62] Loss: 0.71314 
Epoch [11/300] Training [31/62] Loss: 0.75902 
Epoch [11/300] Training [32/62] Loss: 0.71801 
Epoch [11/300] Training [33/62] Loss: 0.70162 
Epoch [11/300] Training [34/62] Loss: 0.93665 
Epoch [11/300] Training [35/62] Loss: 0.88351 
Epoch [11/300] Training [36/62] Loss: 0.93736 
Epoch [11/300] Training [37/62] Loss: 0.81332 
Epoch [11/300] Training [38/62] Loss: 0.82401 
Epoch [11/300] Training [39/62] Loss: 0.78932 
Epoch [11/300] Training [40/62] Loss: 0.79250 
Epoch [11/300] Training [41/62] Loss: 0.77804 
Epoch [11/300] Training [42/62] Loss: 0.88288 
Epoch [11/300] Training [43/62] Loss: 0.79962 
Epoch [11/300] Training [44/62] Loss: 0.82963 
Epoch [11/300] Training [45/62] Loss: 0.84438 
Epoch [11/300] Training [46/62] Loss: 0.81417 
Epoch [11/300] Training [47/62] Loss: 0.80647 
Epoch [11/300] Training [48/62] Loss: 0.85663 
Epoch [11/300] Training [49/62] Loss: 0.81102 
Epoch [11/300] Training [50/62] Loss: 0.74049 
Epoch [11/300] Training [51/62] Loss: 0.75184 
Epoch [11/300] Training [52/62] Loss: 0.84174 
Epoch [11/300] Training [53/62] Loss: 0.68254 
Epoch [11/300] Training [54/62] Loss: 0.80322 
Epoch [11/300] Training [55/62] Loss: 0.78589 
Epoch [11/300] Training [56/62] Loss: 0.81981 
Epoch [11/300] Training [57/62] Loss: 0.89549 
Epoch [11/300] Training [58/62] Loss: 0.95954 
Epoch [11/300] Training [59/62] Loss: 0.75294 
Epoch [11/300] Training [60/62] Loss: 0.78195 
Epoch [11/300] Training [61/62] Loss: 0.87015 
Epoch [11/300] Training [62/62] Loss: 0.80428 
Epoch [11/300] Training metric {'Train/mean dice_metric': 0.38559895753860474, 'Train/mean miou_metric': 0.273292601108551, 'Train/mean f1': 0.44546860456466675, 'Train/mean precision': 0.3630167841911316, 'Train/mean recall': 0.576382040977478, 'Train/mean hd95_metric': 112.2401123046875}
Epoch [11/300] Validation [1/16] Loss: 0.88504  focal_loss 0.18482  dice_loss 0.70023 
Epoch [11/300] Validation [2/16] Loss: 0.97564  focal_loss 0.17916  dice_loss 0.79648 
Epoch [11/300] Validation [3/16] Loss: 0.97882  focal_loss 0.19277  dice_loss 0.78605 
Epoch [11/300] Validation [4/16] Loss: 0.90870  focal_loss 0.16075  dice_loss 0.74795 
Epoch [11/300] Validation [5/16] Loss: 0.92311  focal_loss 0.15725  dice_loss 0.76586 
Epoch [11/300] Validation [6/16] Loss: 0.94758  focal_loss 0.17805  dice_loss 0.76953 
Epoch [11/300] Validation [7/16] Loss: 0.83127  focal_loss 0.14399  dice_loss 0.68728 
Epoch [11/300] Validation [8/16] Loss: 0.97952  focal_loss 0.15862  dice_loss 0.82090 
Epoch [11/300] Validation [9/16] Loss: 0.86986  focal_loss 0.15458  dice_loss 0.71528 
Epoch [11/300] Validation [10/16] Loss: 0.86972  focal_loss 0.14565  dice_loss 0.72407 
Epoch [11/300] Validation [11/16] Loss: 0.92367  focal_loss 0.16992  dice_loss 0.75375 
Epoch [11/300] Validation [12/16] Loss: 0.98556  focal_loss 0.16511  dice_loss 0.82045 
Epoch [11/300] Validation [13/16] Loss: 0.89824  focal_loss 0.16004  dice_loss 0.73820 
Epoch [11/300] Validation [14/16] Loss: 1.03368  focal_loss 0.19830  dice_loss 0.83538 
Epoch [11/300] Validation [15/16] Loss: 0.86901  focal_loss 0.16544  dice_loss 0.70356 
Epoch [11/300] Validation [16/16] Loss: 0.85887  focal_loss 0.16587  dice_loss 0.69300 
Epoch [11/300] Validation metric {'Val/mean dice_metric': 0.3658141791820526, 'Val/mean miou_metric': 0.25506702065467834, 'Val/mean f1': 0.3987073302268982, 'Val/mean precision': 0.29503756761550903, 'Val/mean recall': 0.6146991848945618, 'Val/mean hd95_metric': 120.62964630126953}
Cheakpoint...
Epoch [11/300] best acc:tensor([0.3700], device='cuda:0'), Now : mean acc: tensor([0.3658], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3658141791820526, 'Val/mean miou_metric': 0.25506702065467834, 'Val/mean f1': 0.3987073302268982, 'Val/mean precision': 0.29503756761550903, 'Val/mean recall': 0.6146991848945618, 'Val/mean hd95_metric': 120.62964630126953}
Epoch [12/300] Training [1/62] Loss: 0.71807 
Epoch [12/300] Training [2/62] Loss: 0.82903 
Epoch [12/300] Training [3/62] Loss: 0.82428 
Epoch [12/300] Training [4/62] Loss: 0.80952 
Epoch [12/300] Training [5/62] Loss: 0.71036 
Epoch [12/300] Training [6/62] Loss: 0.80447 
Epoch [12/300] Training [7/62] Loss: 0.78903 
Epoch [12/300] Training [8/62] Loss: 0.76450 
Epoch [12/300] Training [9/62] Loss: 0.78468 
Epoch [12/300] Training [10/62] Loss: 0.73180 
Epoch [12/300] Training [11/62] Loss: 0.90017 
Epoch [12/300] Training [12/62] Loss: 0.84644 
Epoch [12/300] Training [13/62] Loss: 0.73681 
Epoch [12/300] Training [14/62] Loss: 0.83321 
Epoch [12/300] Training [15/62] Loss: 0.77776 
Epoch [12/300] Training [16/62] Loss: 0.79096 
Epoch [12/300] Training [17/62] Loss: 0.79898 
Epoch [12/300] Training [18/62] Loss: 0.73285 
Epoch [12/300] Training [19/62] Loss: 0.74197 
Epoch [12/300] Training [20/62] Loss: 0.72481 
Epoch [12/300] Training [21/62] Loss: 0.72174 
Epoch [12/300] Training [22/62] Loss: 0.81931 
Epoch [12/300] Training [23/62] Loss: 0.79207 
Epoch [12/300] Training [24/62] Loss: 0.76863 
Epoch [12/300] Training [25/62] Loss: 0.77680 
Epoch [12/300] Training [26/62] Loss: 0.81372 
Epoch [12/300] Training [27/62] Loss: 0.79621 
Epoch [12/300] Training [28/62] Loss: 0.78164 
Epoch [12/300] Training [29/62] Loss: 0.88829 
Epoch [12/300] Training [30/62] Loss: 0.73719 
Epoch [12/300] Training [31/62] Loss: 0.85526 
Epoch [12/300] Training [32/62] Loss: 0.84328 
Epoch [12/300] Training [33/62] Loss: 0.77678 
Epoch [12/300] Training [34/62] Loss: 0.87488 
Epoch [12/300] Training [35/62] Loss: 0.86408 
Epoch [12/300] Training [36/62] Loss: 0.85715 
Epoch [12/300] Training [37/62] Loss: 0.79822 
Epoch [12/300] Training [38/62] Loss: 0.78797 
Epoch [12/300] Training [39/62] Loss: 0.78324 
Epoch [12/300] Training [40/62] Loss: 0.80951 
Epoch [12/300] Training [41/62] Loss: 0.81042 
Epoch [12/300] Training [42/62] Loss: 0.77483 
Epoch [12/300] Training [43/62] Loss: 0.80523 
Epoch [12/300] Training [44/62] Loss: 0.71560 
Epoch [12/300] Training [45/62] Loss: 0.79208 
Epoch [12/300] Training [46/62] Loss: 0.86324 
Epoch [12/300] Training [47/62] Loss: 0.76580 
Epoch [12/300] Training [48/62] Loss: 0.79604 
Epoch [12/300] Training [49/62] Loss: 0.75769 
Epoch [12/300] Training [50/62] Loss: 0.86835 
Epoch [12/300] Training [51/62] Loss: 0.66957 
Epoch [12/300] Training [52/62] Loss: 0.82456 
Epoch [12/300] Training [53/62] Loss: 0.71141 
Epoch [12/300] Training [54/62] Loss: 0.73699 
Epoch [12/300] Training [55/62] Loss: 0.75066 
Epoch [12/300] Training [56/62] Loss: 0.64668 
Epoch [12/300] Training [57/62] Loss: 0.74627 
Epoch [12/300] Training [58/62] Loss: 0.76069 
Epoch [12/300] Training [59/62] Loss: 0.85298 
Epoch [12/300] Training [60/62] Loss: 0.70828 
Epoch [12/300] Training [61/62] Loss: 0.86619 
Epoch [12/300] Training [62/62] Loss: 0.76111 
Epoch [12/300] Training metric {'Train/mean dice_metric': 0.39840567111968994, 'Train/mean miou_metric': 0.28042301535606384, 'Train/mean f1': 0.45500755310058594, 'Train/mean precision': 0.3742147982120514, 'Train/mean recall': 0.5802922248840332, 'Train/mean hd95_metric': 112.7073745727539}
Epoch [12/300] Validation [1/16] Loss: 0.93293  focal_loss 0.25231  dice_loss 0.68062 
Epoch [12/300] Validation [2/16] Loss: 1.04896  focal_loss 0.28084  dice_loss 0.76812 
Epoch [12/300] Validation [3/16] Loss: 1.06625  focal_loss 0.28822  dice_loss 0.77803 
Epoch [12/300] Validation [4/16] Loss: 1.01619  focal_loss 0.27615  dice_loss 0.74003 
Epoch [12/300] Validation [5/16] Loss: 1.00177  focal_loss 0.25453  dice_loss 0.74724 
Epoch [12/300] Validation [6/16] Loss: 1.01199  focal_loss 0.25576  dice_loss 0.75623 
Epoch [12/300] Validation [7/16] Loss: 0.89419  focal_loss 0.22618  dice_loss 0.66801 
Epoch [12/300] Validation [8/16] Loss: 1.07106  focal_loss 0.27016  dice_loss 0.80090 
Epoch [12/300] Validation [9/16] Loss: 1.00193  focal_loss 0.28234  dice_loss 0.71959 
Epoch [12/300] Validation [10/16] Loss: 0.94016  focal_loss 0.23062  dice_loss 0.70954 
Epoch [12/300] Validation [11/16] Loss: 0.98927  focal_loss 0.26359  dice_loss 0.72568 
Epoch [12/300] Validation [12/16] Loss: 1.10728  focal_loss 0.28182  dice_loss 0.82545 
Epoch [12/300] Validation [13/16] Loss: 0.97232  focal_loss 0.25433  dice_loss 0.71798 
Epoch [12/300] Validation [14/16] Loss: 1.07554  focal_loss 0.27529  dice_loss 0.80025 
Epoch [12/300] Validation [15/16] Loss: 0.97598  focal_loss 0.26708  dice_loss 0.70890 
Epoch [12/300] Validation [16/16] Loss: 0.89358  focal_loss 0.22935  dice_loss 0.66423 
Epoch [12/300] Validation metric {'Val/mean dice_metric': 0.37556192278862, 'Val/mean miou_metric': 0.2603098750114441, 'Val/mean f1': 0.3965037763118744, 'Val/mean precision': 0.28734642267227173, 'Val/mean recall': 0.6393991708755493, 'Val/mean hd95_metric': 122.05021667480469}
Cheakpoint...
Epoch [12/300] best acc:tensor([0.3756], device='cuda:0'), Now : mean acc: tensor([0.3756], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.37556192278862, 'Val/mean miou_metric': 0.2603098750114441, 'Val/mean f1': 0.3965037763118744, 'Val/mean precision': 0.28734642267227173, 'Val/mean recall': 0.6393991708755493, 'Val/mean hd95_metric': 122.05021667480469}
Epoch [13/300] Training [1/62] Loss: 0.66989 
Epoch [13/300] Training [2/62] Loss: 0.81712 
Epoch [13/300] Training [3/62] Loss: 0.62190 
Epoch [13/300] Training [4/62] Loss: 0.77614 
Epoch [13/300] Training [5/62] Loss: 0.75619 
Epoch [13/300] Training [6/62] Loss: 0.75315 
Epoch [13/300] Training [7/62] Loss: 0.82577 
Epoch [13/300] Training [8/62] Loss: 0.77951 
Epoch [13/300] Training [9/62] Loss: 0.69534 
Epoch [13/300] Training [10/62] Loss: 0.82794 
Epoch [13/300] Training [11/62] Loss: 0.75838 
Epoch [13/300] Training [12/62] Loss: 0.76524 
Epoch [13/300] Training [13/62] Loss: 0.73790 
Epoch [13/300] Training [14/62] Loss: 0.79486 
Epoch [13/300] Training [15/62] Loss: 0.78659 
Epoch [13/300] Training [16/62] Loss: 0.87032 
Epoch [13/300] Training [17/62] Loss: 0.81853 
Epoch [13/300] Training [18/62] Loss: 0.71697 
Epoch [13/300] Training [19/62] Loss: 0.74778 
Epoch [13/300] Training [20/62] Loss: 0.74043 
Epoch [13/300] Training [21/62] Loss: 0.83577 
Epoch [13/300] Training [22/62] Loss: 0.85336 
Epoch [13/300] Training [23/62] Loss: 0.90175 
Epoch [13/300] Training [24/62] Loss: 0.77792 
Epoch [13/300] Training [25/62] Loss: 0.76163 
Epoch [13/300] Training [26/62] Loss: 0.76614 
Epoch [13/300] Training [27/62] Loss: 0.81576 
Epoch [13/300] Training [28/62] Loss: 0.79250 
Epoch [13/300] Training [29/62] Loss: 0.63839 
Epoch [13/300] Training [30/62] Loss: 0.77605 
Epoch [13/300] Training [31/62] Loss: 0.82063 
Epoch [13/300] Training [32/62] Loss: 0.95241 
Epoch [13/300] Training [33/62] Loss: 0.80491 
Epoch [13/300] Training [34/62] Loss: 0.75384 
Epoch [13/300] Training [35/62] Loss: 0.75008 
Epoch [13/300] Training [36/62] Loss: 0.81777 
Epoch [13/300] Training [37/62] Loss: 0.78737 
Epoch [13/300] Training [38/62] Loss: 0.77895 
Epoch [13/300] Training [39/62] Loss: 0.86148 
Epoch [13/300] Training [40/62] Loss: 0.86176 
Epoch [13/300] Training [41/62] Loss: 0.91942 
Epoch [13/300] Training [42/62] Loss: 0.76344 
Epoch [13/300] Training [43/62] Loss: 0.77416 
Epoch [13/300] Training [44/62] Loss: 0.87630 
Epoch [13/300] Training [45/62] Loss: 0.80541 
Epoch [13/300] Training [46/62] Loss: 0.70390 
Epoch [13/300] Training [47/62] Loss: 0.68075 
Epoch [13/300] Training [48/62] Loss: 0.81607 
Epoch [13/300] Training [49/62] Loss: 0.90212 
Epoch [13/300] Training [50/62] Loss: 0.76860 
Epoch [13/300] Training [51/62] Loss: 0.77051 
Epoch [13/300] Training [52/62] Loss: 0.90841 
Epoch [13/300] Training [53/62] Loss: 0.64254 
Epoch [13/300] Training [54/62] Loss: 0.78779 
Epoch [13/300] Training [55/62] Loss: 0.74623 
Epoch [13/300] Training [56/62] Loss: 0.68202 
Epoch [13/300] Training [57/62] Loss: 0.83736 
Epoch [13/300] Training [58/62] Loss: 0.71225 
Epoch [13/300] Training [59/62] Loss: 0.68883 
Epoch [13/300] Training [60/62] Loss: 0.88966 
Epoch [13/300] Training [61/62] Loss: 0.65102 
Epoch [13/300] Training [62/62] Loss: 0.80002 
Epoch [13/300] Training metric {'Train/mean dice_metric': 0.39049383997917175, 'Train/mean miou_metric': 0.27782881259918213, 'Train/mean f1': 0.46161147952079773, 'Train/mean precision': 0.3982679843902588, 'Train/mean recall': 0.5489149689674377, 'Train/mean hd95_metric': 111.12996673583984}
Epoch [13/300] Validation [1/16] Loss: 0.96320  focal_loss 0.27118  dice_loss 0.69202 
Epoch [13/300] Validation [2/16] Loss: 1.12188  focal_loss 0.34813  dice_loss 0.77375 
Epoch [13/300] Validation [3/16] Loss: 1.11152  focal_loss 0.32787  dice_loss 0.78365 
Epoch [13/300] Validation [4/16] Loss: 1.06056  focal_loss 0.31426  dice_loss 0.74630 
Epoch [13/300] Validation [5/16] Loss: 1.08454  focal_loss 0.33072  dice_loss 0.75382 
Epoch [13/300] Validation [6/16] Loss: 1.04604  focal_loss 0.28308  dice_loss 0.76296 
Epoch [13/300] Validation [7/16] Loss: 0.94242  focal_loss 0.26921  dice_loss 0.67321 
Epoch [13/300] Validation [8/16] Loss: 1.12337  focal_loss 0.31048  dice_loss 0.81289 
Epoch [13/300] Validation [9/16] Loss: 1.04251  focal_loss 0.32115  dice_loss 0.72135 
Epoch [13/300] Validation [10/16] Loss: 0.96799  focal_loss 0.25199  dice_loss 0.71600 
Epoch [13/300] Validation [11/16] Loss: 1.01852  focal_loss 0.28362  dice_loss 0.73490 
Epoch [13/300] Validation [12/16] Loss: 1.15356  focal_loss 0.32200  dice_loss 0.83156 
Epoch [13/300] Validation [13/16] Loss: 1.01470  focal_loss 0.28501  dice_loss 0.72969 
Epoch [13/300] Validation [14/16] Loss: 1.13403  focal_loss 0.32914  dice_loss 0.80489 
Epoch [13/300] Validation [15/16] Loss: 1.05689  focal_loss 0.33440  dice_loss 0.72250 
Epoch [13/300] Validation [16/16] Loss: 0.88838  focal_loss 0.22891  dice_loss 0.65947 
Epoch [13/300] Validation metric {'Val/mean dice_metric': 0.36728084087371826, 'Val/mean miou_metric': 0.25692859292030334, 'Val/mean f1': 0.3934655487537384, 'Val/mean precision': 0.2894049286842346, 'Val/mean recall': 0.6143747568130493, 'Val/mean hd95_metric': 120.86937713623047}
Cheakpoint...
Epoch [13/300] best acc:tensor([0.3756], device='cuda:0'), Now : mean acc: tensor([0.3673], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.36728084087371826, 'Val/mean miou_metric': 0.25692859292030334, 'Val/mean f1': 0.3934655487537384, 'Val/mean precision': 0.2894049286842346, 'Val/mean recall': 0.6143747568130493, 'Val/mean hd95_metric': 120.86937713623047}
Epoch [14/300] Training [1/62] Loss: 0.91304 
Epoch [14/300] Training [2/62] Loss: 0.63288 
Epoch [14/300] Training [3/62] Loss: 0.92768 
Epoch [14/300] Training [4/62] Loss: 0.64534 
Epoch [14/300] Training [5/62] Loss: 0.90102 
Epoch [14/300] Training [6/62] Loss: 0.88054 
Epoch [14/300] Training [7/62] Loss: 0.78431 
Epoch [14/300] Training [8/62] Loss: 0.81483 
Epoch [14/300] Training [9/62] Loss: 0.80692 
Epoch [14/300] Training [10/62] Loss: 0.82552 
Epoch [14/300] Training [11/62] Loss: 0.79281 
Epoch [14/300] Training [12/62] Loss: 0.81590 
Epoch [14/300] Training [13/62] Loss: 0.78813 
Epoch [14/300] Training [14/62] Loss: 0.72263 
Epoch [14/300] Training [15/62] Loss: 0.80272 
Epoch [14/300] Training [16/62] Loss: 0.84101 
Epoch [14/300] Training [17/62] Loss: 0.74418 
Epoch [14/300] Training [18/62] Loss: 0.84239 
Epoch [14/300] Training [19/62] Loss: 0.78928 
Epoch [14/300] Training [20/62] Loss: 0.70443 
Epoch [14/300] Training [21/62] Loss: 0.81227 
Epoch [14/300] Training [22/62] Loss: 0.81910 
Epoch [14/300] Training [23/62] Loss: 0.75606 
Epoch [14/300] Training [24/62] Loss: 0.77019 
Epoch [14/300] Training [25/62] Loss: 0.75571 
Epoch [14/300] Training [26/62] Loss: 0.81482 
Epoch [14/300] Training [27/62] Loss: 0.81677 
Epoch [14/300] Training [28/62] Loss: 0.76762 
Epoch [14/300] Training [29/62] Loss: 0.64346 
Epoch [14/300] Training [30/62] Loss: 0.64023 
Epoch [14/300] Training [31/62] Loss: 0.67700 
Epoch [14/300] Training [32/62] Loss: 0.86065 
Epoch [14/300] Training [33/62] Loss: 0.83484 
Epoch [14/300] Training [34/62] Loss: 0.84603 
Epoch [14/300] Training [35/62] Loss: 0.72426 
Epoch [14/300] Training [36/62] Loss: 0.78203 
Epoch [14/300] Training [37/62] Loss: 0.75660 
Epoch [14/300] Training [38/62] Loss: 0.78879 
Epoch [14/300] Training [39/62] Loss: 0.87632 
Epoch [14/300] Training [40/62] Loss: 0.74650 
Epoch [14/300] Training [41/62] Loss: 0.72557 
Epoch [14/300] Training [42/62] Loss: 0.66615 
Epoch [14/300] Training [43/62] Loss: 0.76127 
Epoch [14/300] Training [44/62] Loss: 0.77571 
Epoch [14/300] Training [45/62] Loss: 0.76187 
Epoch [14/300] Training [46/62] Loss: 0.85146 
Epoch [14/300] Training [47/62] Loss: 0.68910 
Epoch [14/300] Training [48/62] Loss: 0.76132 
Epoch [14/300] Training [49/62] Loss: 0.79542 
Epoch [14/300] Training [50/62] Loss: 0.81069 
Epoch [14/300] Training [51/62] Loss: 0.71612 
Epoch [14/300] Training [52/62] Loss: 0.80612 
Epoch [14/300] Training [53/62] Loss: 0.85361 
Epoch [14/300] Training [54/62] Loss: 0.71856 
Epoch [14/300] Training [55/62] Loss: 0.76862 
Epoch [14/300] Training [56/62] Loss: 0.90008 
Epoch [14/300] Training [57/62] Loss: 0.77072 
Epoch [14/300] Training [58/62] Loss: 0.83766 
Epoch [14/300] Training [59/62] Loss: 0.73009 
Epoch [14/300] Training [60/62] Loss: 0.71291 
Epoch [14/300] Training [61/62] Loss: 0.89018 
Epoch [14/300] Training [62/62] Loss: 0.67834 
Epoch [14/300] Training metric {'Train/mean dice_metric': 0.40013864636421204, 'Train/mean miou_metric': 0.28702062368392944, 'Train/mean f1': 0.46454495191574097, 'Train/mean precision': 0.39754927158355713, 'Train/mean recall': 0.5586977005004883, 'Train/mean hd95_metric': 109.06287384033203}
Epoch [14/300] Validation [1/16] Loss: 1.05791  focal_loss 0.38043  dice_loss 0.67747 
Epoch [14/300] Validation [2/16] Loss: 1.29485  focal_loss 0.52897  dice_loss 0.76588 
Epoch [14/300] Validation [3/16] Loss: 1.25691  focal_loss 0.48244  dice_loss 0.77447 
Epoch [14/300] Validation [4/16] Loss: 1.17633  focal_loss 0.44374  dice_loss 0.73259 
Epoch [14/300] Validation [5/16] Loss: 1.25149  focal_loss 0.48806  dice_loss 0.76343 
Epoch [14/300] Validation [6/16] Loss: 1.22343  focal_loss 0.46435  dice_loss 0.75909 
Epoch [14/300] Validation [7/16] Loss: 1.11154  focal_loss 0.42811  dice_loss 0.68344 
Epoch [14/300] Validation [8/16] Loss: 1.25048  focal_loss 0.43549  dice_loss 0.81499 
Epoch [14/300] Validation [9/16] Loss: 1.20938  focal_loss 0.48866  dice_loss 0.72072 
Epoch [14/300] Validation [10/16] Loss: 1.15735  focal_loss 0.43553  dice_loss 0.72181 
Epoch [14/300] Validation [11/16] Loss: 1.19410  focal_loss 0.45734  dice_loss 0.73676 
Epoch [14/300] Validation [12/16] Loss: 1.30530  focal_loss 0.47378  dice_loss 0.83152 
Epoch [14/300] Validation [13/16] Loss: 1.17141  focal_loss 0.43384  dice_loss 0.73757 
Epoch [14/300] Validation [14/16] Loss: 1.31576  focal_loss 0.50898  dice_loss 0.80678 
Epoch [14/300] Validation [15/16] Loss: 1.22815  focal_loss 0.51405  dice_loss 0.71410 
Epoch [14/300] Validation [16/16] Loss: 0.99599  focal_loss 0.34940  dice_loss 0.64659 
Epoch [14/300] Validation metric {'Val/mean dice_metric': 0.3723571002483368, 'Val/mean miou_metric': 0.2621997892856598, 'Val/mean f1': 0.38589733839035034, 'Val/mean precision': 0.2781156897544861, 'Val/mean recall': 0.6300801634788513, 'Val/mean hd95_metric': 121.40557861328125}
Cheakpoint...
Epoch [14/300] best acc:tensor([0.3756], device='cuda:0'), Now : mean acc: tensor([0.3724], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3723571002483368, 'Val/mean miou_metric': 0.2621997892856598, 'Val/mean f1': 0.38589733839035034, 'Val/mean precision': 0.2781156897544861, 'Val/mean recall': 0.6300801634788513, 'Val/mean hd95_metric': 121.40557861328125}
Epoch [15/300] Training [1/62] Loss: 0.86964 
Epoch [15/300] Training [2/62] Loss: 0.88520 
Epoch [15/300] Training [3/62] Loss: 0.84931 
Epoch [15/300] Training [4/62] Loss: 0.76610 
Epoch [15/300] Training [5/62] Loss: 0.77259 
Epoch [15/300] Training [6/62] Loss: 0.75096 
Epoch [15/300] Training [7/62] Loss: 0.74995 
Epoch [15/300] Training [8/62] Loss: 0.64935 
Epoch [15/300] Training [9/62] Loss: 0.66993 
Epoch [15/300] Training [10/62] Loss: 0.60951 
Epoch [15/300] Training [11/62] Loss: 0.76286 
Epoch [15/300] Training [12/62] Loss: 0.80862 
Epoch [15/300] Training [13/62] Loss: 0.72049 
Epoch [15/300] Training [14/62] Loss: 0.82418 
Epoch [15/300] Training [15/62] Loss: 0.70851 
Epoch [15/300] Training [16/62] Loss: 0.73846 
Epoch [15/300] Training [17/62] Loss: 0.77542 
Epoch [15/300] Training [18/62] Loss: 0.81468 
Epoch [15/300] Training [19/62] Loss: 0.73872 
Epoch [15/300] Training [20/62] Loss: 0.81128 
Epoch [15/300] Training [21/62] Loss: 0.66332 
Epoch [15/300] Training [22/62] Loss: 0.80622 
Epoch [15/300] Training [23/62] Loss: 0.75524 
Epoch [15/300] Training [24/62] Loss: 0.71730 
Epoch [15/300] Training [25/62] Loss: 0.69179 
Epoch [15/300] Training [26/62] Loss: 0.77050 
Epoch [15/300] Training [27/62] Loss: 0.72129 
Epoch [15/300] Training [28/62] Loss: 0.73493 
Epoch [15/300] Training [29/62] Loss: 0.91233 
Epoch [15/300] Training [30/62] Loss: 0.92357 
Epoch [15/300] Training [31/62] Loss: 0.92739 
Epoch [15/300] Training [32/62] Loss: 0.72871 
Epoch [15/300] Training [33/62] Loss: 0.74774 
Epoch [15/300] Training [34/62] Loss: 0.92000 
Epoch [15/300] Training [35/62] Loss: 0.77266 
Epoch [15/300] Training [36/62] Loss: 0.62179 
Epoch [15/300] Training [37/62] Loss: 0.84411 
Epoch [15/300] Training [38/62] Loss: 0.67532 
Epoch [15/300] Training [39/62] Loss: 0.80568 
Epoch [15/300] Training [40/62] Loss: 0.79152 
Epoch [15/300] Training [41/62] Loss: 0.66611 
Epoch [15/300] Training [42/62] Loss: 0.74630 
Epoch [15/300] Training [43/62] Loss: 0.89159 
Epoch [15/300] Training [44/62] Loss: 0.79897 
Epoch [15/300] Training [45/62] Loss: 0.81092 
Epoch [15/300] Training [46/62] Loss: 0.77913 
Epoch [15/300] Training [47/62] Loss: 0.75660 
Epoch [15/300] Training [48/62] Loss: 0.76443 
Epoch [15/300] Training [49/62] Loss: 0.80178 
Epoch [15/300] Training [50/62] Loss: 0.73208 
Epoch [15/300] Training [51/62] Loss: 0.82754 
Epoch [15/300] Training [52/62] Loss: 0.75847 
Epoch [15/300] Training [53/62] Loss: 0.77176 
Epoch [15/300] Training [54/62] Loss: 0.71706 
Epoch [15/300] Training [55/62] Loss: 0.78667 
Epoch [15/300] Training [56/62] Loss: 0.75247 
Epoch [15/300] Training [57/62] Loss: 0.74147 
Epoch [15/300] Training [58/62] Loss: 0.76328 
Epoch [15/300] Training [59/62] Loss: 0.82720 
Epoch [15/300] Training [60/62] Loss: 0.82069 
Epoch [15/300] Training [61/62] Loss: 0.77769 
Epoch [15/300] Training [62/62] Loss: 0.69624 
Epoch [15/300] Training metric {'Train/mean dice_metric': 0.4155249297618866, 'Train/mean miou_metric': 0.2958191931247711, 'Train/mean f1': 0.47394633293151855, 'Train/mean precision': 0.40880873799324036, 'Train/mean recall': 0.5637756586074829, 'Train/mean hd95_metric': 109.67234802246094}
Epoch [15/300] Validation [1/16] Loss: 0.85590  focal_loss 0.16865  dice_loss 0.68724 
Epoch [15/300] Validation [2/16] Loss: 0.96885  focal_loss 0.17311  dice_loss 0.79574 
Epoch [15/300] Validation [3/16] Loss: 0.96916  focal_loss 0.19884  dice_loss 0.77032 
Epoch [15/300] Validation [4/16] Loss: 0.91705  focal_loss 0.18456  dice_loss 0.73248 
Epoch [15/300] Validation [5/16] Loss: 0.88709  focal_loss 0.14369  dice_loss 0.74340 
Epoch [15/300] Validation [6/16] Loss: 0.89887  focal_loss 0.17044  dice_loss 0.72843 
Epoch [15/300] Validation [7/16] Loss: 0.85036  focal_loss 0.15184  dice_loss 0.69852 
Epoch [15/300] Validation [8/16] Loss: 1.01621  focal_loss 0.17774  dice_loss 0.83847 
Epoch [15/300] Validation [9/16] Loss: 0.87184  focal_loss 0.15440  dice_loss 0.71743 
Epoch [15/300] Validation [10/16] Loss: 0.87024  focal_loss 0.15182  dice_loss 0.71843 
Epoch [15/300] Validation [11/16] Loss: 0.88621  focal_loss 0.15868  dice_loss 0.72753 
Epoch [15/300] Validation [12/16] Loss: 0.98180  focal_loss 0.16767  dice_loss 0.81413 
Epoch [15/300] Validation [13/16] Loss: 0.91703  focal_loss 0.16795  dice_loss 0.74908 
Epoch [15/300] Validation [14/16] Loss: 0.96202  focal_loss 0.16531  dice_loss 0.79671 
Epoch [15/300] Validation [15/16] Loss: 0.86848  focal_loss 0.15713  dice_loss 0.71135 
Epoch [15/300] Validation [16/16] Loss: 0.84872  focal_loss 0.17798  dice_loss 0.67074 
Epoch [15/300] Validation metric {'Val/mean dice_metric': 0.3935835659503937, 'Val/mean miou_metric': 0.2762382924556732, 'Val/mean f1': 0.42152634263038635, 'Val/mean precision': 0.3234400749206543, 'Val/mean recall': 0.6049976944923401, 'Val/mean hd95_metric': 119.1297378540039}
Cheakpoint...
Epoch [15/300] best acc:tensor([0.3936], device='cuda:0'), Now : mean acc: tensor([0.3936], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3935835659503937, 'Val/mean miou_metric': 0.2762382924556732, 'Val/mean f1': 0.42152634263038635, 'Val/mean precision': 0.3234400749206543, 'Val/mean recall': 0.6049976944923401, 'Val/mean hd95_metric': 119.1297378540039}
Epoch [16/300] Training [1/62] Loss: 0.73994 
Epoch [16/300] Training [2/62] Loss: 0.84238 
Epoch [16/300] Training [3/62] Loss: 0.81465 
Epoch [16/300] Training [4/62] Loss: 0.80849 
Epoch [16/300] Training [5/62] Loss: 0.84108 
Epoch [16/300] Training [6/62] Loss: 0.71300 
Epoch [16/300] Training [7/62] Loss: 0.76360 
Epoch [16/300] Training [8/62] Loss: 0.72137 
Epoch [16/300] Training [9/62] Loss: 0.74068 
Epoch [16/300] Training [10/62] Loss: 0.79821 
Epoch [16/300] Training [11/62] Loss: 0.72275 
Epoch [16/300] Training [12/62] Loss: 0.66306 
Epoch [16/300] Training [13/62] Loss: 0.87478 
Epoch [16/300] Training [14/62] Loss: 0.69956 
Epoch [16/300] Training [15/62] Loss: 0.78072 
Epoch [16/300] Training [16/62] Loss: 0.75363 
Epoch [16/300] Training [17/62] Loss: 0.72420 
Epoch [16/300] Training [18/62] Loss: 0.59387 
Epoch [16/300] Training [19/62] Loss: 0.83024 
Epoch [16/300] Training [20/62] Loss: 0.90710 
Epoch [16/300] Training [21/62] Loss: 0.80278 
Epoch [16/300] Training [22/62] Loss: 0.77109 
Epoch [16/300] Training [23/62] Loss: 0.86353 
Epoch [16/300] Training [24/62] Loss: 0.63576 
Epoch [16/300] Training [25/62] Loss: 0.61590 
Epoch [16/300] Training [26/62] Loss: 0.76955 
Epoch [16/300] Training [27/62] Loss: 0.76471 
Epoch [16/300] Training [28/62] Loss: 0.89023 
Epoch [16/300] Training [29/62] Loss: 0.84723 
Epoch [16/300] Training [30/62] Loss: 0.67966 
Epoch [16/300] Training [31/62] Loss: 0.87906 
Epoch [16/300] Training [32/62] Loss: 0.69581 
Epoch [16/300] Training [33/62] Loss: 0.67490 
Epoch [16/300] Training [34/62] Loss: 0.75740 
Epoch [16/300] Training [35/62] Loss: 0.74038 
Epoch [16/300] Training [36/62] Loss: 0.89917 
Epoch [16/300] Training [37/62] Loss: 0.67817 
Epoch [16/300] Training [38/62] Loss: 0.78575 
Epoch [16/300] Training [39/62] Loss: 0.72597 
Epoch [16/300] Training [40/62] Loss: 0.75784 
Epoch [16/300] Training [41/62] Loss: 0.66714 
Epoch [16/300] Training [42/62] Loss: 0.71738 
Epoch [16/300] Training [43/62] Loss: 0.70618 
Epoch [16/300] Training [44/62] Loss: 0.76348 
Epoch [16/300] Training [45/62] Loss: 0.66712 
Epoch [16/300] Training [46/62] Loss: 0.72359 
Epoch [16/300] Training [47/62] Loss: 0.67940 
Epoch [16/300] Training [48/62] Loss: 0.75624 
Epoch [16/300] Training [49/62] Loss: 0.72306 
Epoch [16/300] Training [50/62] Loss: 0.67772 
Epoch [16/300] Training [51/62] Loss: 0.76179 
Epoch [16/300] Training [52/62] Loss: 0.85065 
Epoch [16/300] Training [53/62] Loss: 0.72029 
Epoch [16/300] Training [54/62] Loss: 0.86475 
Epoch [16/300] Training [55/62] Loss: 0.80138 
Epoch [16/300] Training [56/62] Loss: 0.78607 
Epoch [16/300] Training [57/62] Loss: 0.92106 
Epoch [16/300] Training [58/62] Loss: 0.72570 
Epoch [16/300] Training [59/62] Loss: 0.85604 
Epoch [16/300] Training [60/62] Loss: 0.79085 
Epoch [16/300] Training [61/62] Loss: 0.64839 
Epoch [16/300] Training [62/62] Loss: 0.96791 
Epoch [16/300] Training metric {'Train/mean dice_metric': 0.422442227602005, 'Train/mean miou_metric': 0.30814310908317566, 'Train/mean f1': 0.49131152033805847, 'Train/mean precision': 0.4314919710159302, 'Train/mean recall': 0.570386528968811, 'Train/mean hd95_metric': 106.58222198486328}
Epoch [16/300] Validation [1/16] Loss: 0.85920  focal_loss 0.18485  dice_loss 0.67435 
Epoch [16/300] Validation [2/16] Loss: 0.82578  focal_loss 0.09008  dice_loss 0.73569 
Epoch [16/300] Validation [3/16] Loss: 0.95846  focal_loss 0.19584  dice_loss 0.76263 
Epoch [16/300] Validation [4/16] Loss: 0.86557  focal_loss 0.17159  dice_loss 0.69398 
Epoch [16/300] Validation [5/16] Loss: 0.72388  focal_loss 0.07601  dice_loss 0.64786 
Epoch [16/300] Validation [6/16] Loss: 0.74280  focal_loss 0.08966  dice_loss 0.65314 
Epoch [16/300] Validation [7/16] Loss: 0.67264  focal_loss 0.07682  dice_loss 0.59582 
Epoch [16/300] Validation [8/16] Loss: 0.93864  focal_loss 0.11680  dice_loss 0.82184 
Epoch [16/300] Validation [9/16] Loss: 0.79582  focal_loss 0.09995  dice_loss 0.69587 
Epoch [16/300] Validation [10/16] Loss: 0.74599  focal_loss 0.10133  dice_loss 0.64467 
Epoch [16/300] Validation [11/16] Loss: 0.71233  focal_loss 0.07799  dice_loss 0.63434 
Epoch [16/300] Validation [12/16] Loss: 0.78544  focal_loss 0.05506  dice_loss 0.73038 
Epoch [16/300] Validation [13/16] Loss: 0.85860  focal_loss 0.14415  dice_loss 0.71445 
Epoch [16/300] Validation [14/16] Loss: 0.97454  focal_loss 0.16738  dice_loss 0.80716 
Epoch [16/300] Validation [15/16] Loss: 0.79228  focal_loss 0.12215  dice_loss 0.67013 
Epoch [16/300] Validation [16/16] Loss: 0.61825  focal_loss 0.07353  dice_loss 0.54472 
Epoch [16/300] Validation metric {'Val/mean dice_metric': 0.41029641032218933, 'Val/mean miou_metric': 0.2978347837924957, 'Val/mean f1': 0.47849953174591064, 'Val/mean precision': 0.41728752851486206, 'Val/mean recall': 0.5607569813728333, 'Val/mean hd95_metric': 107.8863525390625}
Cheakpoint...
Epoch [16/300] best acc:tensor([0.4103], device='cuda:0'), Now : mean acc: tensor([0.4103], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.41029641032218933, 'Val/mean miou_metric': 0.2978347837924957, 'Val/mean f1': 0.47849953174591064, 'Val/mean precision': 0.41728752851486206, 'Val/mean recall': 0.5607569813728333, 'Val/mean hd95_metric': 107.8863525390625}
Epoch [17/300] Training [1/62] Loss: 0.64395 
Epoch [17/300] Training [2/62] Loss: 0.65944 
Epoch [17/300] Training [3/62] Loss: 0.57014 
Epoch [17/300] Training [4/62] Loss: 0.76958 
Epoch [17/300] Training [5/62] Loss: 0.83622 
Epoch [17/300] Training [6/62] Loss: 0.71005 
Epoch [17/300] Training [7/62] Loss: 0.71486 
Epoch [17/300] Training [8/62] Loss: 0.73563 
Epoch [17/300] Training [9/62] Loss: 0.80848 
Epoch [17/300] Training [10/62] Loss: 0.89263 
Epoch [17/300] Training [11/62] Loss: 0.80859 
Epoch [17/300] Training [12/62] Loss: 0.75539 
Epoch [17/300] Training [13/62] Loss: 0.66109 
Epoch [17/300] Training [14/62] Loss: 0.81035 
Epoch [17/300] Training [15/62] Loss: 0.73931 
Epoch [17/300] Training [16/62] Loss: 0.71301 
Epoch [17/300] Training [17/62] Loss: 0.84853 
Epoch [17/300] Training [18/62] Loss: 0.76685 
Epoch [17/300] Training [19/62] Loss: 0.86307 
Epoch [17/300] Training [20/62] Loss: 0.78893 
Epoch [17/300] Training [21/62] Loss: 0.85738 
Epoch [17/300] Training [22/62] Loss: 0.80667 
Epoch [17/300] Training [23/62] Loss: 0.76290 
Epoch [17/300] Training [24/62] Loss: 0.84091 
Epoch [17/300] Training [25/62] Loss: 0.72738 
Epoch [17/300] Training [26/62] Loss: 0.70249 
Epoch [17/300] Training [27/62] Loss: 0.84071 
Epoch [17/300] Training [28/62] Loss: 0.72451 
Epoch [17/300] Training [29/62] Loss: 0.73746 
Epoch [17/300] Training [30/62] Loss: 0.76898 
Epoch [17/300] Training [31/62] Loss: 0.73325 
Epoch [17/300] Training [32/62] Loss: 0.77676 
Epoch [17/300] Training [33/62] Loss: 0.75171 
Epoch [17/300] Training [34/62] Loss: 0.64543 
Epoch [17/300] Training [35/62] Loss: 0.78632 
Epoch [17/300] Training [36/62] Loss: 0.61424 
Epoch [17/300] Training [37/62] Loss: 0.62292 
Epoch [17/300] Training [38/62] Loss: 0.77506 
Epoch [17/300] Training [39/62] Loss: 0.80694 
Epoch [17/300] Training [40/62] Loss: 0.78069 
Epoch [17/300] Training [41/62] Loss: 0.69208 
Epoch [17/300] Training [42/62] Loss: 0.72344 
Epoch [17/300] Training [43/62] Loss: 0.72385 
Epoch [17/300] Training [44/62] Loss: 0.65080 
Epoch [17/300] Training [45/62] Loss: 0.80807 
Epoch [17/300] Training [46/62] Loss: 0.67749 
Epoch [17/300] Training [47/62] Loss: 0.87587 
Epoch [17/300] Training [48/62] Loss: 0.63212 
Epoch [17/300] Training [49/62] Loss: 0.76608 
Epoch [17/300] Training [50/62] Loss: 0.82827 
Epoch [17/300] Training [51/62] Loss: 0.69834 
Epoch [17/300] Training [52/62] Loss: 0.95901 
Epoch [17/300] Training [53/62] Loss: 0.84784 
Epoch [17/300] Training [54/62] Loss: 0.85948 
Epoch [17/300] Training [55/62] Loss: 0.69496 
Epoch [17/300] Training [56/62] Loss: 0.73255 
Epoch [17/300] Training [57/62] Loss: 0.75806 
Epoch [17/300] Training [58/62] Loss: 0.79305 
Epoch [17/300] Training [59/62] Loss: 0.84037 
Epoch [17/300] Training [60/62] Loss: 0.80409 
Epoch [17/300] Training [61/62] Loss: 0.75935 
Epoch [17/300] Training [62/62] Loss: 0.57215 
Epoch [17/300] Training metric {'Train/mean dice_metric': 0.42141884565353394, 'Train/mean miou_metric': 0.3059723377227783, 'Train/mean f1': 0.493197500705719, 'Train/mean precision': 0.4400329291820526, 'Train/mean recall': 0.5609740614891052, 'Train/mean hd95_metric': 104.21670532226562}
Epoch [17/300] Validation [1/16] Loss: 0.80413  focal_loss 0.18191  dice_loss 0.62222 
Epoch [17/300] Validation [2/16] Loss: 0.83970  focal_loss 0.10285  dice_loss 0.73685 
Epoch [17/300] Validation [3/16] Loss: 0.87474  focal_loss 0.15137  dice_loss 0.72336 
Epoch [17/300] Validation [4/16] Loss: 0.79774  focal_loss 0.14640  dice_loss 0.65134 
Epoch [17/300] Validation [5/16] Loss: 0.72622  focal_loss 0.07329  dice_loss 0.65293 
Epoch [17/300] Validation [6/16] Loss: 0.68263  focal_loss 0.06777  dice_loss 0.61485 
Epoch [17/300] Validation [7/16] Loss: 0.62185  focal_loss 0.06590  dice_loss 0.55595 
Epoch [17/300] Validation [8/16] Loss: 0.81164  focal_loss 0.08801  dice_loss 0.72363 
Epoch [17/300] Validation [9/16] Loss: 0.77134  focal_loss 0.09642  dice_loss 0.67492 
Epoch [17/300] Validation [10/16] Loss: 0.78446  focal_loss 0.11750  dice_loss 0.66696 
Epoch [17/300] Validation [11/16] Loss: 0.70652  focal_loss 0.06863  dice_loss 0.63788 
Epoch [17/300] Validation [12/16] Loss: 0.81100  focal_loss 0.04734  dice_loss 0.76366 
Epoch [17/300] Validation [13/16] Loss: 0.68889  focal_loss 0.07032  dice_loss 0.61857 
Epoch [17/300] Validation [14/16] Loss: 0.95384  focal_loss 0.14626  dice_loss 0.80757 
Epoch [17/300] Validation [15/16] Loss: 0.74306  focal_loss 0.10224  dice_loss 0.64082 
Epoch [17/300] Validation [16/16] Loss: 0.64900  focal_loss 0.06899  dice_loss 0.58001 
Epoch [17/300] Validation metric {'Val/mean dice_metric': 0.4137667417526245, 'Val/mean miou_metric': 0.30062955617904663, 'Val/mean f1': 0.488333523273468, 'Val/mean precision': 0.4357030987739563, 'Val/mean recall': 0.555425763130188, 'Val/mean hd95_metric': 105.449462890625}
Cheakpoint...
Epoch [17/300] best acc:tensor([0.4138], device='cuda:0'), Now : mean acc: tensor([0.4138], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.4137667417526245, 'Val/mean miou_metric': 0.30062955617904663, 'Val/mean f1': 0.488333523273468, 'Val/mean precision': 0.4357030987739563, 'Val/mean recall': 0.555425763130188, 'Val/mean hd95_metric': 105.449462890625}
Epoch [18/300] Training [1/62] Loss: 0.66806 
Epoch [18/300] Training [2/62] Loss: 0.70515 
Epoch [18/300] Training [3/62] Loss: 0.82472 
Epoch [18/300] Training [4/62] Loss: 0.74198 
Epoch [18/300] Training [5/62] Loss: 0.73752 
Epoch [18/300] Training [6/62] Loss: 0.67265 
Epoch [18/300] Training [7/62] Loss: 0.87589 
Epoch [18/300] Training [8/62] Loss: 0.89383 
Epoch [18/300] Training [9/62] Loss: 0.78322 
Epoch [18/300] Training [10/62] Loss: 0.75442 
Epoch [18/300] Training [11/62] Loss: 0.69671 
Epoch [18/300] Training [12/62] Loss: 0.63064 
Epoch [18/300] Training [13/62] Loss: 0.79919 
Epoch [18/300] Training [14/62] Loss: 0.75645 
Epoch [18/300] Training [15/62] Loss: 0.79756 
Epoch [18/300] Training [16/62] Loss: 0.76128 
Epoch [18/300] Training [17/62] Loss: 0.87609 
Epoch [18/300] Training [18/62] Loss: 0.82261 
Epoch [18/300] Training [19/62] Loss: 0.83138 
Epoch [18/300] Training [20/62] Loss: 0.66602 
Epoch [18/300] Training [21/62] Loss: 0.65869 
Epoch [18/300] Training [22/62] Loss: 0.78656 
Epoch [18/300] Training [23/62] Loss: 0.80486 
Epoch [18/300] Training [24/62] Loss: 0.84435 
Epoch [18/300] Training [25/62] Loss: 0.84845 
Epoch [18/300] Training [26/62] Loss: 0.74034 
Epoch [18/300] Training [27/62] Loss: 0.76740 
Epoch [18/300] Training [28/62] Loss: 0.75490 
Epoch [18/300] Training [29/62] Loss: 0.75341 
Epoch [18/300] Training [30/62] Loss: 0.75264 
Epoch [18/300] Training [31/62] Loss: 0.67398 
Epoch [18/300] Training [32/62] Loss: 0.76574 
Epoch [18/300] Training [33/62] Loss: 0.76375 
Epoch [18/300] Training [34/62] Loss: 0.59118 
Epoch [18/300] Training [35/62] Loss: 0.75965 
Epoch [18/300] Training [36/62] Loss: 0.61912 
Epoch [18/300] Training [37/62] Loss: 0.76685 
Epoch [18/300] Training [38/62] Loss: 0.72456 
Epoch [18/300] Training [39/62] Loss: 0.71365 
Epoch [18/300] Training [40/62] Loss: 0.64646 
Epoch [18/300] Training [41/62] Loss: 0.79266 
Epoch [18/300] Training [42/62] Loss: 0.68352 
Epoch [18/300] Training [43/62] Loss: 0.72869 
Epoch [18/300] Training [44/62] Loss: 0.75845 
Epoch [18/300] Training [45/62] Loss: 0.77475 
Epoch [18/300] Training [46/62] Loss: 0.55739 
Epoch [18/300] Training [47/62] Loss: 1.03976 
Epoch [18/300] Training [48/62] Loss: 0.83360 
Epoch [18/300] Training [49/62] Loss: 0.76927 
Epoch [18/300] Training [50/62] Loss: 0.90391 
Epoch [18/300] Training [51/62] Loss: 0.61633 
Epoch [18/300] Training [52/62] Loss: 0.62290 
Epoch [18/300] Training [53/62] Loss: 0.79528 
Epoch [18/300] Training [54/62] Loss: 0.71843 
Epoch [18/300] Training [55/62] Loss: 0.58579 
Epoch [18/300] Training [56/62] Loss: 0.74773 
Epoch [18/300] Training [57/62] Loss: 0.69995 
Epoch [18/300] Training [58/62] Loss: 0.83781 
Epoch [18/300] Training [59/62] Loss: 0.82275 
Epoch [18/300] Training [60/62] Loss: 0.88994 
Epoch [18/300] Training [61/62] Loss: 0.76393 
Epoch [18/300] Training [62/62] Loss: 0.66577 
Epoch [18/300] Training metric {'Train/mean dice_metric': 0.4250636100769043, 'Train/mean miou_metric': 0.3103317320346832, 'Train/mean f1': 0.4907074272632599, 'Train/mean precision': 0.43167349696159363, 'Train/mean recall': 0.5684456825256348, 'Train/mean hd95_metric': 104.76795196533203}
Epoch [18/300] Validation [1/16] Loss: 0.81607  focal_loss 0.16510  dice_loss 0.65097 
Epoch [18/300] Validation [2/16] Loss: 0.90403  focal_loss 0.13571  dice_loss 0.76832 
Epoch [18/300] Validation [3/16] Loss: 0.89501  focal_loss 0.16517  dice_loss 0.72984 
Epoch [18/300] Validation [4/16] Loss: 0.92335  focal_loss 0.21165  dice_loss 0.71170 
Epoch [18/300] Validation [5/16] Loss: 0.73999  focal_loss 0.07282  dice_loss 0.66717 
Epoch [18/300] Validation [6/16] Loss: 0.80255  focal_loss 0.10414  dice_loss 0.69841 
Epoch [18/300] Validation [7/16] Loss: 0.77586  focal_loss 0.15059  dice_loss 0.62527 
Epoch [18/300] Validation [8/16] Loss: 0.85714  focal_loss 0.11129  dice_loss 0.74585 
Epoch [18/300] Validation [9/16] Loss: 0.79290  focal_loss 0.14373  dice_loss 0.64918 
Epoch [18/300] Validation [10/16] Loss: 0.75307  focal_loss 0.10880  dice_loss 0.64426 
Epoch [18/300] Validation [11/16] Loss: 0.76991  focal_loss 0.10181  dice_loss 0.66811 
Epoch [18/300] Validation [12/16] Loss: 0.87550  focal_loss 0.09710  dice_loss 0.77840 
Epoch [18/300] Validation [13/16] Loss: 0.79063  focal_loss 0.12246  dice_loss 0.66816 
Epoch [18/300] Validation [14/16] Loss: 0.92214  focal_loss 0.14053  dice_loss 0.78161 
Epoch [18/300] Validation [15/16] Loss: 0.74529  focal_loss 0.11032  dice_loss 0.63497 
Epoch [18/300] Validation [16/16] Loss: 0.67172  focal_loss 0.12166  dice_loss 0.55006 
Epoch [18/300] Validation metric {'Val/mean dice_metric': 0.4170808494091034, 'Val/mean miou_metric': 0.30149173736572266, 'Val/mean f1': 0.46801018714904785, 'Val/mean precision': 0.38665899634361267, 'Val/mean recall': 0.5927144289016724, 'Val/mean hd95_metric': 108.82988739013672}
Cheakpoint...
Epoch [18/300] best acc:tensor([0.4171], device='cuda:0'), Now : mean acc: tensor([0.4171], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.4170808494091034, 'Val/mean miou_metric': 0.30149173736572266, 'Val/mean f1': 0.46801018714904785, 'Val/mean precision': 0.38665899634361267, 'Val/mean recall': 0.5927144289016724, 'Val/mean hd95_metric': 108.82988739013672}
Epoch [19/300] Training [1/62] Loss: 0.73976 
Epoch [19/300] Training [2/62] Loss: 0.72185 
Epoch [19/300] Training [3/62] Loss: 0.58169 
Epoch [19/300] Training [4/62] Loss: 0.78684 
Epoch [19/300] Training [5/62] Loss: 0.78728 
Epoch [19/300] Training [6/62] Loss: 0.68440 
Epoch [19/300] Training [7/62] Loss: 0.67565 
Epoch [19/300] Training [8/62] Loss: 0.76199 
Epoch [19/300] Training [9/62] Loss: 0.87559 
Epoch [19/300] Training [10/62] Loss: 0.77832 
Epoch [19/300] Training [11/62] Loss: 0.63236 
Epoch [19/300] Training [12/62] Loss: 0.80010 
Epoch [19/300] Training [13/62] Loss: 0.82619 
Epoch [19/300] Training [14/62] Loss: 0.70473 
Epoch [19/300] Training [15/62] Loss: 0.75402 
Epoch [19/300] Training [16/62] Loss: 0.84556 
Epoch [19/300] Training [17/62] Loss: 0.67684 
Epoch [19/300] Training [18/62] Loss: 0.67310 
Epoch [19/300] Training [19/62] Loss: 0.82888 
Epoch [19/300] Training [20/62] Loss: 0.94214 
Epoch [19/300] Training [21/62] Loss: 0.66010 
Epoch [19/300] Training [22/62] Loss: 0.71645 
Epoch [19/300] Training [23/62] Loss: 0.83264 
Epoch [19/300] Training [24/62] Loss: 0.73146 
Epoch [19/300] Training [25/62] Loss: 0.74768 
Epoch [19/300] Training [26/62] Loss: 0.70278 
Epoch [19/300] Training [27/62] Loss: 0.80533 
Epoch [19/300] Training [28/62] Loss: 0.68653 
Epoch [19/300] Training [29/62] Loss: 0.65396 
Epoch [19/300] Training [30/62] Loss: 0.79504 
Epoch [19/300] Training [31/62] Loss: 0.68754 
Epoch [19/300] Training [32/62] Loss: 0.86777 
Epoch [19/300] Training [33/62] Loss: 0.80046 
Epoch [19/300] Training [34/62] Loss: 0.61522 
Epoch [19/300] Training [35/62] Loss: 0.80139 
Epoch [19/300] Training [36/62] Loss: 0.75838 
Epoch [19/300] Training [37/62] Loss: 0.72940 
Epoch [19/300] Training [38/62] Loss: 0.71029 
Epoch [19/300] Training [39/62] Loss: 0.71581 
Epoch [19/300] Training [40/62] Loss: 0.65304 
Epoch [19/300] Training [41/62] Loss: 0.77374 
Epoch [19/300] Training [42/62] Loss: 0.64312 
Epoch [19/300] Training [43/62] Loss: 0.75496 
Epoch [19/300] Training [44/62] Loss: 0.83407 
Epoch [19/300] Training [45/62] Loss: 0.57287 
Epoch [19/300] Training [46/62] Loss: 0.65859 
Epoch [19/300] Training [47/62] Loss: 0.74013 
Epoch [19/300] Training [48/62] Loss: 0.78123 
Epoch [19/300] Training [49/62] Loss: 0.73901 
Epoch [19/300] Training [50/62] Loss: 0.71222 
Epoch [19/300] Training [51/62] Loss: 0.83491 
Epoch [19/300] Training [52/62] Loss: 0.88875 
Epoch [19/300] Training [53/62] Loss: 0.83012 
Epoch [19/300] Training [54/62] Loss: 0.77107 
Epoch [19/300] Training [55/62] Loss: 0.59908 
Epoch [19/300] Training [56/62] Loss: 0.70914 
Epoch [19/300] Training [57/62] Loss: 0.86195 
Epoch [19/300] Training [58/62] Loss: 0.73789 
Epoch [19/300] Training [59/62] Loss: 0.88167 
Epoch [19/300] Training [60/62] Loss: 0.68943 
Epoch [19/300] Training [61/62] Loss: 0.65661 
Epoch [19/300] Training [62/62] Loss: 0.57892 
Epoch [19/300] Training metric {'Train/mean dice_metric': 0.4275306165218353, 'Train/mean miou_metric': 0.3114394545555115, 'Train/mean f1': 0.4975179135799408, 'Train/mean precision': 0.4408186078071594, 'Train/mean recall': 0.5709558725357056, 'Train/mean hd95_metric': 105.52352905273438}
Epoch [19/300] Validation [1/16] Loss: 1.40345  focal_loss 0.69227  dice_loss 0.71118 
Epoch [19/300] Validation [2/16] Loss: 1.23823  focal_loss 0.40436  dice_loss 0.83387 
Epoch [19/300] Validation [3/16] Loss: 1.37404  focal_loss 0.58087  dice_loss 0.79317 
Epoch [19/300] Validation [4/16] Loss: 1.41776  focal_loss 0.62214  dice_loss 0.79562 
Epoch [19/300] Validation [5/16] Loss: 1.17260  focal_loss 0.38761  dice_loss 0.78500 
Epoch [19/300] Validation [6/16] Loss: 1.44428  focal_loss 0.61753  dice_loss 0.82675 
Epoch [19/300] Validation [7/16] Loss: 1.21673  focal_loss 0.48700  dice_loss 0.72973 
Epoch [19/300] Validation [8/16] Loss: 1.66440  focal_loss 0.78464  dice_loss 0.87976 
Epoch [19/300] Validation [9/16] Loss: 1.23377  focal_loss 0.49118  dice_loss 0.74259 
Epoch [19/300] Validation [10/16] Loss: 1.27743  focal_loss 0.51937  dice_loss 0.75806 
Epoch [19/300] Validation [11/16] Loss: 1.38659  focal_loss 0.58726  dice_loss 0.79932 
Epoch [19/300] Validation [12/16] Loss: 1.47697  focal_loss 0.61717  dice_loss 0.85980 
Epoch [19/300] Validation [13/16] Loss: 1.30586  focal_loss 0.53067  dice_loss 0.77519 
Epoch [19/300] Validation [14/16] Loss: 1.52284  focal_loss 0.66359  dice_loss 0.85926 
Epoch [19/300] Validation [15/16] Loss: 1.16391  focal_loss 0.41187  dice_loss 0.75204 
Epoch [19/300] Validation [16/16] Loss: 1.44920  focal_loss 0.70987  dice_loss 0.73933 
Epoch [19/300] Validation metric {'Val/mean dice_metric': 0.38640719652175903, 'Val/mean miou_metric': 0.27600592374801636, 'Val/mean f1': 0.40239661931991577, 'Val/mean precision': 0.306566447019577, 'Val/mean recall': 0.5853824615478516, 'Val/mean hd95_metric': 118.85206604003906}
Cheakpoint...
Epoch [19/300] best acc:tensor([0.4171], device='cuda:0'), Now : mean acc: tensor([0.3864], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.38640719652175903, 'Val/mean miou_metric': 0.27600592374801636, 'Val/mean f1': 0.40239661931991577, 'Val/mean precision': 0.306566447019577, 'Val/mean recall': 0.5853824615478516, 'Val/mean hd95_metric': 118.85206604003906}
Epoch [20/300] Training [1/62] Loss: 0.78764 
Epoch [20/300] Training [2/62] Loss: 0.60109 
Epoch [20/300] Training [3/62] Loss: 0.63230 
Epoch [20/300] Training [4/62] Loss: 0.72621 
Epoch [20/300] Training [5/62] Loss: 0.74508 
Epoch [20/300] Training [6/62] Loss: 0.79006 
Epoch [20/300] Training [7/62] Loss: 0.74235 
Epoch [20/300] Training [8/62] Loss: 0.79461 
Epoch [20/300] Training [9/62] Loss: 0.66838 
Epoch [20/300] Training [10/62] Loss: 0.68327 
Epoch [20/300] Training [11/62] Loss: 0.70967 
Epoch [20/300] Training [12/62] Loss: 0.72465 
Epoch [20/300] Training [13/62] Loss: 0.81220 
Epoch [20/300] Training [14/62] Loss: 0.77117 
Epoch [20/300] Training [15/62] Loss: 0.69904 
Epoch [20/300] Training [16/62] Loss: 0.64429 
Epoch [20/300] Training [17/62] Loss: 0.90059 
Epoch [20/300] Training [18/62] Loss: 1.02424 
Epoch [20/300] Training [19/62] Loss: 0.73880 
Epoch [20/300] Training [20/62] Loss: 0.83704 
Epoch [20/300] Training [21/62] Loss: 0.65860 
Epoch [20/300] Training [22/62] Loss: 0.88832 
Epoch [20/300] Training [23/62] Loss: 0.66383 
Epoch [20/300] Training [24/62] Loss: 0.76252 
Epoch [20/300] Training [25/62] Loss: 0.90049 
Epoch [20/300] Training [26/62] Loss: 0.83746 
Epoch [20/300] Training [27/62] Loss: 0.74925 
Epoch [20/300] Training [28/62] Loss: 0.71940 
Epoch [20/300] Training [29/62] Loss: 0.78313 
Epoch [20/300] Training [30/62] Loss: 0.83469 
Epoch [20/300] Training [31/62] Loss: 0.74804 
Epoch [20/300] Training [32/62] Loss: 0.77102 
Epoch [20/300] Training [33/62] Loss: 0.71165 
Epoch [20/300] Training [34/62] Loss: 0.60046 
Epoch [20/300] Training [35/62] Loss: 0.85826 
Epoch [20/300] Training [36/62] Loss: 0.73101 
Epoch [20/300] Training [37/62] Loss: 0.81789 
Epoch [20/300] Training [38/62] Loss: 0.77846 
Epoch [20/300] Training [39/62] Loss: 0.78083 
Epoch [20/300] Training [40/62] Loss: 0.60312 
Epoch [20/300] Training [41/62] Loss: 0.72185 
Epoch [20/300] Training [42/62] Loss: 0.66559 
Epoch [20/300] Training [43/62] Loss: 0.75690 
Epoch [20/300] Training [44/62] Loss: 0.79046 
Epoch [20/300] Training [45/62] Loss: 0.61015 
Epoch [20/300] Training [46/62] Loss: 0.67231 
Epoch [20/300] Training [47/62] Loss: 0.75967 
Epoch [20/300] Training [48/62] Loss: 0.71394 
Epoch [20/300] Training [49/62] Loss: 0.76869 
Epoch [20/300] Training [50/62] Loss: 0.76122 
Epoch [20/300] Training [51/62] Loss: 0.86879 
Epoch [20/300] Training [52/62] Loss: 0.66842 
Epoch [20/300] Training [53/62] Loss: 0.74577 
Epoch [20/300] Training [54/62] Loss: 0.66118 
Epoch [20/300] Training [55/62] Loss: 0.77613 
Epoch [20/300] Training [56/62] Loss: 0.69010 
Epoch [20/300] Training [57/62] Loss: 0.70913 
Epoch [20/300] Training [58/62] Loss: 0.76056 
Epoch [20/300] Training [59/62] Loss: 0.62693 
Epoch [20/300] Training [60/62] Loss: 0.80733 
Epoch [20/300] Training [61/62] Loss: 0.69820 
Epoch [20/300] Training [62/62] Loss: 0.64161 
Epoch [20/300] Training metric {'Train/mean dice_metric': 0.4310337007045746, 'Train/mean miou_metric': 0.31456708908081055, 'Train/mean f1': 0.49452677369117737, 'Train/mean precision': 0.4537345767021179, 'Train/mean recall': 0.5433782935142517, 'Train/mean hd95_metric': 102.0538558959961}
Epoch [20/300] Validation [1/16] Loss: 0.77946  focal_loss 0.13492  dice_loss 0.64453 
Epoch [20/300] Validation [2/16] Loss: 0.86039  focal_loss 0.12529  dice_loss 0.73510 
Epoch [20/300] Validation [3/16] Loss: 0.88110  focal_loss 0.14690  dice_loss 0.73420 
Epoch [20/300] Validation [4/16] Loss: 0.86613  focal_loss 0.15490  dice_loss 0.71123 
Epoch [20/300] Validation [5/16] Loss: 0.78818  focal_loss 0.10855  dice_loss 0.67963 
Epoch [20/300] Validation [6/16] Loss: 0.78017  focal_loss 0.09764  dice_loss 0.68253 
Epoch [20/300] Validation [7/16] Loss: 0.76338  focal_loss 0.11256  dice_loss 0.65082 
Epoch [20/300] Validation [8/16] Loss: 0.91337  focal_loss 0.12883  dice_loss 0.78454 
Epoch [20/300] Validation [9/16] Loss: 0.81200  focal_loss 0.13855  dice_loss 0.67345 
Epoch [20/300] Validation [10/16] Loss: 0.80945  focal_loss 0.11463  dice_loss 0.69482 
Epoch [20/300] Validation [11/16] Loss: 0.80433  focal_loss 0.11417  dice_loss 0.69016 
Epoch [20/300] Validation [12/16] Loss: 0.87613  focal_loss 0.09625  dice_loss 0.77988 
Epoch [20/300] Validation [13/16] Loss: 0.82714  focal_loss 0.12421  dice_loss 0.70293 
Epoch [20/300] Validation [14/16] Loss: 0.92874  focal_loss 0.14154  dice_loss 0.78720 
Epoch [20/300] Validation [15/16] Loss: 0.78657  focal_loss 0.12277  dice_loss 0.66379 
Epoch [20/300] Validation [16/16] Loss: 0.71455  focal_loss 0.10778  dice_loss 0.60677 
Epoch [20/300] Validation metric {'Val/mean dice_metric': 0.41896292567253113, 'Val/mean miou_metric': 0.3021581768989563, 'Val/mean f1': 0.4644710421562195, 'Val/mean precision': 0.38841548562049866, 'Val/mean recall': 0.5775636434555054, 'Val/mean hd95_metric': 108.9565200805664}
Cheakpoint...
Epoch [20/300] best acc:tensor([0.4190], device='cuda:0'), Now : mean acc: tensor([0.4190], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.41896292567253113, 'Val/mean miou_metric': 0.3021581768989563, 'Val/mean f1': 0.4644710421562195, 'Val/mean precision': 0.38841548562049866, 'Val/mean recall': 0.5775636434555054, 'Val/mean hd95_metric': 108.9565200805664}
Epoch [21/300] Training [1/62] Loss: 0.66706 
Epoch [21/300] Training [2/62] Loss: 0.70471 
Epoch [21/300] Training [3/62] Loss: 0.66499 
Epoch [21/300] Training [4/62] Loss: 0.68259 
Epoch [21/300] Training [5/62] Loss: 0.72798 
Epoch [21/300] Training [6/62] Loss: 0.81072 
Epoch [21/300] Training [7/62] Loss: 0.75285 
Epoch [21/300] Training [8/62] Loss: 0.73458 
Epoch [21/300] Training [9/62] Loss: 0.73978 
Epoch [21/300] Training [10/62] Loss: 0.62888 
Epoch [21/300] Training [11/62] Loss: 0.68714 
Epoch [21/300] Training [12/62] Loss: 0.80844 
Epoch [21/300] Training [13/62] Loss: 0.68202 
Epoch [21/300] Training [14/62] Loss: 0.73220 
Epoch [21/300] Training [15/62] Loss: 0.60030 
Epoch [21/300] Training [16/62] Loss: 0.84221 
Epoch [21/300] Training [17/62] Loss: 0.96981 
Epoch [21/300] Training [18/62] Loss: 0.70545 
Epoch [21/300] Training [19/62] Loss: 0.66915 
Epoch [21/300] Training [20/62] Loss: 0.74905 
Epoch [21/300] Training [21/62] Loss: 0.79195 
Epoch [21/300] Training [22/62] Loss: 0.66190 
Epoch [21/300] Training [23/62] Loss: 0.71622 
Epoch [21/300] Training [24/62] Loss: 0.67324 
Epoch [21/300] Training [25/62] Loss: 0.74825 
Epoch [21/300] Training [26/62] Loss: 0.64635 
Epoch [21/300] Training [27/62] Loss: 0.79115 
Epoch [21/300] Training [28/62] Loss: 0.72929 
Epoch [21/300] Training [29/62] Loss: 0.80187 
Epoch [21/300] Training [30/62] Loss: 0.65059 
Epoch [21/300] Training [31/62] Loss: 0.75992 
Epoch [21/300] Training [32/62] Loss: 0.69170 
Epoch [21/300] Training [33/62] Loss: 0.82015 
Epoch [21/300] Training [34/62] Loss: 0.70247 
Epoch [21/300] Training [35/62] Loss: 0.81376 
Epoch [21/300] Training [36/62] Loss: 0.83522 
Epoch [21/300] Training [37/62] Loss: 0.74204 
Epoch [21/300] Training [38/62] Loss: 0.67516 
Epoch [21/300] Training [39/62] Loss: 0.63189 
Epoch [21/300] Training [40/62] Loss: 0.70245 
Epoch [21/300] Training [41/62] Loss: 0.75392 
Epoch [21/300] Training [42/62] Loss: 0.75341 
Epoch [21/300] Training [43/62] Loss: 1.04196 
Epoch [21/300] Training [44/62] Loss: 0.69052 
Epoch [21/300] Training [45/62] Loss: 0.83998 
Epoch [21/300] Training [46/62] Loss: 0.78106 
Epoch [21/300] Training [47/62] Loss: 0.57760 
Epoch [21/300] Training [48/62] Loss: 0.73885 
Epoch [21/300] Training [49/62] Loss: 0.80219 
Epoch [21/300] Training [50/62] Loss: 0.79160 
Epoch [21/300] Training [51/62] Loss: 0.59589 
Epoch [21/300] Training [52/62] Loss: 0.61316 
Epoch [21/300] Training [53/62] Loss: 0.75143 
Epoch [21/300] Training [54/62] Loss: 0.74098 
Epoch [21/300] Training [55/62] Loss: 0.54535 
Epoch [21/300] Training [56/62] Loss: 0.70843 
Epoch [21/300] Training [57/62] Loss: 0.77847 
Epoch [21/300] Training [58/62] Loss: 0.68676 
Epoch [21/300] Training [59/62] Loss: 0.71724 
Epoch [21/300] Training [60/62] Loss: 0.51101 
Epoch [21/300] Training [61/62] Loss: 0.73959 
Epoch [21/300] Training [62/62] Loss: 0.45823 
Epoch [21/300] Training metric {'Train/mean dice_metric': 0.44938474893569946, 'Train/mean miou_metric': 0.3317711651325226, 'Train/mean f1': 0.5222167372703552, 'Train/mean precision': 0.4867689609527588, 'Train/mean recall': 0.5632327198982239, 'Train/mean hd95_metric': 99.57904815673828}
Epoch [21/300] Validation [1/16] Loss: 0.88577  focal_loss 0.19540  dice_loss 0.69037 
Epoch [21/300] Validation [2/16] Loss: 0.90537  focal_loss 0.15600  dice_loss 0.74936 
Epoch [21/300] Validation [3/16] Loss: 0.90327  focal_loss 0.18254  dice_loss 0.72073 
Epoch [21/300] Validation [4/16] Loss: 0.81433  focal_loss 0.14934  dice_loss 0.66498 
Epoch [21/300] Validation [5/16] Loss: 0.81724  focal_loss 0.13060  dice_loss 0.68664 
Epoch [21/300] Validation [6/16] Loss: 0.81642  focal_loss 0.14041  dice_loss 0.67600 
Epoch [21/300] Validation [7/16] Loss: 0.75085  focal_loss 0.12631  dice_loss 0.62454 
Epoch [21/300] Validation [8/16] Loss: 0.88275  focal_loss 0.14023  dice_loss 0.74252 
Epoch [21/300] Validation [9/16] Loss: 0.79676  focal_loss 0.13058  dice_loss 0.66618 
Epoch [21/300] Validation [10/16] Loss: 0.76009  focal_loss 0.10682  dice_loss 0.65327 
Epoch [21/300] Validation [11/16] Loss: 0.80064  focal_loss 0.13601  dice_loss 0.66463 
Epoch [21/300] Validation [12/16] Loss: 0.86182  focal_loss 0.10272  dice_loss 0.75911 
Epoch [21/300] Validation [13/16] Loss: 0.76364  focal_loss 0.11259  dice_loss 0.65105 
Epoch [21/300] Validation [14/16] Loss: 0.95784  focal_loss 0.18321  dice_loss 0.77463 
Epoch [21/300] Validation [15/16] Loss: 0.76418  focal_loss 0.12371  dice_loss 0.64047 
Epoch [21/300] Validation [16/16] Loss: 0.66293  focal_loss 0.12329  dice_loss 0.53965 
Epoch [21/300] Validation metric {'Val/mean dice_metric': 0.43802598118782043, 'Val/mean miou_metric': 0.3200564980506897, 'Val/mean f1': 0.48700520396232605, 'Val/mean precision': 0.40708696842193604, 'Val/mean recall': 0.6059671640396118, 'Val/mean hd95_metric': 106.68346405029297}
Cheakpoint...
Epoch [21/300] best acc:tensor([0.4380], device='cuda:0'), Now : mean acc: tensor([0.4380], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.43802598118782043, 'Val/mean miou_metric': 0.3200564980506897, 'Val/mean f1': 0.48700520396232605, 'Val/mean precision': 0.40708696842193604, 'Val/mean recall': 0.6059671640396118, 'Val/mean hd95_metric': 106.68346405029297}
Epoch [22/300] Training [1/62] Loss: 0.69905 
Epoch [22/300] Training [2/62] Loss: 0.84842 
Epoch [22/300] Training [3/62] Loss: 0.73337 
Epoch [22/300] Training [4/62] Loss: 0.82954 
Epoch [22/300] Training [5/62] Loss: 0.76107 
Epoch [22/300] Training [6/62] Loss: 0.65727 
Epoch [22/300] Training [7/62] Loss: 0.78887 
Epoch [22/300] Training [8/62] Loss: 0.68308 
Epoch [22/300] Training [9/62] Loss: 0.75736 
Epoch [22/300] Training [10/62] Loss: 0.62718 
Epoch [22/300] Training [11/62] Loss: 0.62394 
Epoch [22/300] Training [12/62] Loss: 0.53645 
Epoch [22/300] Training [13/62] Loss: 0.69056 
Epoch [22/300] Training [14/62] Loss: 0.61624 
Epoch [22/300] Training [15/62] Loss: 0.63072 
Epoch [22/300] Training [16/62] Loss: 0.87892 
Epoch [22/300] Training [17/62] Loss: 0.72753 
Epoch [22/300] Training [18/62] Loss: 0.71628 
Epoch [22/300] Training [19/62] Loss: 0.60759 
Epoch [22/300] Training [20/62] Loss: 0.81060 
Epoch [22/300] Training [21/62] Loss: 0.72243 
Epoch [22/300] Training [22/62] Loss: 0.64351 
Epoch [22/300] Training [23/62] Loss: 0.75208 
Epoch [22/300] Training [24/62] Loss: 0.68554 
Epoch [22/300] Training [25/62] Loss: 0.73209 
Epoch [22/300] Training [26/62] Loss: 0.66528 
Epoch [22/300] Training [27/62] Loss: 0.70410 
Epoch [22/300] Training [28/62] Loss: 0.62078 
Epoch [22/300] Training [29/62] Loss: 0.77575 
Epoch [22/300] Training [30/62] Loss: 0.65838 
Epoch [22/300] Training [31/62] Loss: 0.56500 
Epoch [22/300] Training [32/62] Loss: 0.62227 
Epoch [22/300] Training [33/62] Loss: 0.85207 
Epoch [22/300] Training [34/62] Loss: 0.78512 
Epoch [22/300] Training [35/62] Loss: 0.58352 
Epoch [22/300] Training [36/62] Loss: 0.67067 
Epoch [22/300] Training [37/62] Loss: 0.64532 
Epoch [22/300] Training [38/62] Loss: 0.75120 
Epoch [22/300] Training [39/62] Loss: 0.68947 
Epoch [22/300] Training [40/62] Loss: 0.70093 
Epoch [22/300] Training [41/62] Loss: 0.73405 
Epoch [22/300] Training [42/62] Loss: 0.72764 
Epoch [22/300] Training [43/62] Loss: 0.76498 
Epoch [22/300] Training [44/62] Loss: 0.88109 
Epoch [22/300] Training [45/62] Loss: 0.79490 
Epoch [22/300] Training [46/62] Loss: 0.88732 
Epoch [22/300] Training [47/62] Loss: 0.69112 
Epoch [22/300] Training [48/62] Loss: 0.74220 
Epoch [22/300] Training [49/62] Loss: 0.59944 
Epoch [22/300] Training [50/62] Loss: 0.70063 
Epoch [22/300] Training [51/62] Loss: 0.69187 
Epoch [22/300] Training [52/62] Loss: 0.76032 
Epoch [22/300] Training [53/62] Loss: 0.57199 
Epoch [22/300] Training [54/62] Loss: 0.61173 
Epoch [22/300] Training [55/62] Loss: 0.73038 
Epoch [22/300] Training [56/62] Loss: 0.64578 
Epoch [22/300] Training [57/62] Loss: 0.71513 
Epoch [22/300] Training [58/62] Loss: 0.72074 
Epoch [22/300] Training [59/62] Loss: 0.56434 
Epoch [22/300] Training [60/62] Loss: 0.65835 
Epoch [22/300] Training [61/62] Loss: 0.73501 
Epoch [22/300] Training [62/62] Loss: 0.75247 
Epoch [22/300] Training metric {'Train/mean dice_metric': 0.4670807123184204, 'Train/mean miou_metric': 0.34819331765174866, 'Train/mean f1': 0.5388511419296265, 'Train/mean precision': 0.4870058298110962, 'Train/mean recall': 0.6030502915382385, 'Train/mean hd95_metric': 99.52603912353516}
Epoch [22/300] Validation [1/16] Loss: 1.09410  focal_loss 0.40808  dice_loss 0.68602 
Epoch [22/300] Validation [2/16] Loss: 0.72553  focal_loss 0.11809  dice_loss 0.60744 
Epoch [22/300] Validation [3/16] Loss: 0.72729  focal_loss 0.12951  dice_loss 0.59778 
Epoch [22/300] Validation [4/16] Loss: 0.78505  focal_loss 0.19134  dice_loss 0.59371 
Epoch [22/300] Validation [5/16] Loss: 0.70441  focal_loss 0.08066  dice_loss 0.62376 
Epoch [22/300] Validation [6/16] Loss: 0.52341  focal_loss 0.06667  dice_loss 0.45674 
Epoch [22/300] Validation [7/16] Loss: 0.78344  focal_loss 0.17318  dice_loss 0.61026 
Epoch [22/300] Validation [8/16] Loss: 0.93716  focal_loss 0.17601  dice_loss 0.76116 
Epoch [22/300] Validation [9/16] Loss: 0.90301  focal_loss 0.22455  dice_loss 0.67847 
Epoch [22/300] Validation [10/16] Loss: 0.95845  focal_loss 0.23692  dice_loss 0.72153 
Epoch [22/300] Validation [11/16] Loss: 0.54144  focal_loss 0.07767  dice_loss 0.46377 
Epoch [22/300] Validation [12/16] Loss: 0.72914  focal_loss 0.06849  dice_loss 0.66065 
Epoch [22/300] Validation [13/16] Loss: 0.62742  focal_loss 0.10979  dice_loss 0.51763 
Epoch [22/300] Validation [14/16] Loss: 0.97845  focal_loss 0.18741  dice_loss 0.79104 
Epoch [22/300] Validation [15/16] Loss: 0.73884  focal_loss 0.13627  dice_loss 0.60257 
Epoch [22/300] Validation [16/16] Loss: 0.63225  focal_loss 0.09618  dice_loss 0.53607 
Epoch [22/300] Validation metric {'Val/mean dice_metric': 0.4509974420070648, 'Val/mean miou_metric': 0.3382004499435425, 'Val/mean f1': 0.5279974937438965, 'Val/mean precision': 0.4974486827850342, 'Val/mean recall': 0.5625438094139099, 'Val/mean hd95_metric': 98.10791778564453}
Cheakpoint...
Epoch [22/300] best acc:tensor([0.4510], device='cuda:0'), Now : mean acc: tensor([0.4510], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.4509974420070648, 'Val/mean miou_metric': 0.3382004499435425, 'Val/mean f1': 0.5279974937438965, 'Val/mean precision': 0.4974486827850342, 'Val/mean recall': 0.5625438094139099, 'Val/mean hd95_metric': 98.10791778564453}
Epoch [23/300] Training [1/62] Loss: 0.70233 
Epoch [23/300] Training [2/62] Loss: 0.71484 
Epoch [23/300] Training [3/62] Loss: 0.76827 
Epoch [23/300] Training [4/62] Loss: 0.73064 
Epoch [23/300] Training [5/62] Loss: 0.68804 
Epoch [23/300] Training [6/62] Loss: 0.72299 
Epoch [23/300] Training [7/62] Loss: 0.74796 
Epoch [23/300] Training [8/62] Loss: 0.71092 
Epoch [23/300] Training [9/62] Loss: 0.61882 
Epoch [23/300] Training [10/62] Loss: 0.61547 
Epoch [23/300] Training [11/62] Loss: 0.72796 
Epoch [23/300] Training [12/62] Loss: 0.68322 
Epoch [23/300] Training [13/62] Loss: 0.84016 
Epoch [23/300] Training [14/62] Loss: 0.61832 
Epoch [23/300] Training [15/62] Loss: 0.71406 
Epoch [23/300] Training [16/62] Loss: 0.82352 
Epoch [23/300] Training [17/62] Loss: 0.59650 
Epoch [23/300] Training [18/62] Loss: 0.59078 
Epoch [23/300] Training [19/62] Loss: 0.56813 
Epoch [23/300] Training [20/62] Loss: 0.74746 
Epoch [23/300] Training [21/62] Loss: 0.69654 
Epoch [23/300] Training [22/62] Loss: 0.73102 
Epoch [23/300] Training [23/62] Loss: 0.85916 
Epoch [23/300] Training [24/62] Loss: 0.79707 
Epoch [23/300] Training [25/62] Loss: 0.69908 
Epoch [23/300] Training [26/62] Loss: 0.70297 
Epoch [23/300] Training [27/62] Loss: 0.85090 
Epoch [23/300] Training [28/62] Loss: 0.63117 
Epoch [23/300] Training [29/62] Loss: 0.71838 
Epoch [23/300] Training [30/62] Loss: 0.73382 
Epoch [23/300] Training [31/62] Loss: 0.66674 
Epoch [23/300] Training [32/62] Loss: 0.52805 
Epoch [23/300] Training [33/62] Loss: 0.84275 
Epoch [23/300] Training [34/62] Loss: 0.80603 
Epoch [23/300] Training [35/62] Loss: 0.62567 
Epoch [23/300] Training [36/62] Loss: 0.73198 
Epoch [23/300] Training [37/62] Loss: 0.68335 
Epoch [23/300] Training [38/62] Loss: 0.78447 
Epoch [23/300] Training [39/62] Loss: 0.81788 
Epoch [23/300] Training [40/62] Loss: 0.56559 
Epoch [23/300] Training [41/62] Loss: 0.90548 
Epoch [23/300] Training [42/62] Loss: 0.76630 
Epoch [23/300] Training [43/62] Loss: 0.67619 
Epoch [23/300] Training [44/62] Loss: 0.68229 
Epoch [23/300] Training [45/62] Loss: 0.72028 
Epoch [23/300] Training [46/62] Loss: 0.59188 
Epoch [23/300] Training [47/62] Loss: 0.71837 
Epoch [23/300] Training [48/62] Loss: 0.70990 
Epoch [23/300] Training [49/62] Loss: 0.59832 
Epoch [23/300] Training [50/62] Loss: 0.80739 
Epoch [23/300] Training [51/62] Loss: 0.80354 
Epoch [23/300] Training [52/62] Loss: 0.63863 
Epoch [23/300] Training [53/62] Loss: 0.73548 
Epoch [23/300] Training [54/62] Loss: 0.80686 
Epoch [23/300] Training [55/62] Loss: 0.60155 
Epoch [23/300] Training [56/62] Loss: 0.67814 
Epoch [23/300] Training [57/62] Loss: 0.60403 
Epoch [23/300] Training [58/62] Loss: 0.65317 
Epoch [23/300] Training [59/62] Loss: 0.75525 
Epoch [23/300] Training [60/62] Loss: 0.49219 
Epoch [23/300] Training [61/62] Loss: 0.48840 
Epoch [23/300] Training [62/62] Loss: 0.67566 
Epoch [23/300] Training metric {'Train/mean dice_metric': 0.467610239982605, 'Train/mean miou_metric': 0.34830668568611145, 'Train/mean f1': 0.5380783081054688, 'Train/mean precision': 0.518300473690033, 'Train/mean recall': 0.559425413608551, 'Train/mean hd95_metric': 98.6727523803711}
Epoch [23/300] Validation [1/16] Loss: 0.86967  focal_loss 0.18936  dice_loss 0.68032 
Epoch [23/300] Validation [2/16] Loss: 1.00680  focal_loss 0.17204  dice_loss 0.83476 
Epoch [23/300] Validation [3/16] Loss: 1.02626  focal_loss 0.23820  dice_loss 0.78807 
Epoch [23/300] Validation [4/16] Loss: 0.89570  focal_loss 0.18522  dice_loss 0.71047 
Epoch [23/300] Validation [5/16] Loss: 0.87828  focal_loss 0.16555  dice_loss 0.71273 
Epoch [23/300] Validation [6/16] Loss: 0.87589  focal_loss 0.13460  dice_loss 0.74129 
Epoch [23/300] Validation [7/16] Loss: 0.81088  focal_loss 0.13541  dice_loss 0.67547 
Epoch [23/300] Validation [8/16] Loss: 1.12464  focal_loss 0.27879  dice_loss 0.84585 
Epoch [23/300] Validation [9/16] Loss: 0.78946  focal_loss 0.10894  dice_loss 0.68053 
Epoch [23/300] Validation [10/16] Loss: 0.88232  focal_loss 0.14637  dice_loss 0.73595 
Epoch [23/300] Validation [11/16] Loss: 0.87497  focal_loss 0.15584  dice_loss 0.71914 
Epoch [23/300] Validation [12/16] Loss: 0.99470  focal_loss 0.16109  dice_loss 0.83361 
Epoch [23/300] Validation [13/16] Loss: 0.87860  focal_loss 0.14372  dice_loss 0.73488 
Epoch [23/300] Validation [14/16] Loss: 1.12621  focal_loss 0.25082  dice_loss 0.87539 
Epoch [23/300] Validation [15/16] Loss: 0.86238  focal_loss 0.13871  dice_loss 0.72367 
Epoch [23/300] Validation [16/16] Loss: 0.82403  focal_loss 0.12972  dice_loss 0.69431 
Epoch [23/300] Validation metric {'Val/mean dice_metric': 0.43091723322868347, 'Val/mean miou_metric': 0.31655505299568176, 'Val/mean f1': 0.4862585961818695, 'Val/mean precision': 0.444275826215744, 'Val/mean recall': 0.5370038151741028, 'Val/mean hd95_metric': 105.62610626220703}
Cheakpoint...
Epoch [23/300] best acc:tensor([0.4510], device='cuda:0'), Now : mean acc: tensor([0.4309], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.43091723322868347, 'Val/mean miou_metric': 0.31655505299568176, 'Val/mean f1': 0.4862585961818695, 'Val/mean precision': 0.444275826215744, 'Val/mean recall': 0.5370038151741028, 'Val/mean hd95_metric': 105.62610626220703}
Epoch [24/300] Training [1/62] Loss: 0.64393 
Epoch [24/300] Training [2/62] Loss: 0.75786 
Epoch [24/300] Training [3/62] Loss: 0.73341 
Epoch [24/300] Training [4/62] Loss: 0.70371 
Epoch [24/300] Training [5/62] Loss: 0.68245 
Epoch [24/300] Training [6/62] Loss: 0.63931 
Epoch [24/300] Training [7/62] Loss: 0.60828 
Epoch [24/300] Training [8/62] Loss: 0.71627 
Epoch [24/300] Training [9/62] Loss: 0.83927 
Epoch [24/300] Training [10/62] Loss: 0.74384 
Epoch [24/300] Training [11/62] Loss: 0.80301 
Epoch [24/300] Training [12/62] Loss: 0.60259 
Epoch [24/300] Training [13/62] Loss: 0.76562 
Epoch [24/300] Training [14/62] Loss: 0.64868 
Epoch [24/300] Training [15/62] Loss: 0.65595 
Epoch [24/300] Training [16/62] Loss: 0.76338 
Epoch [24/300] Training [17/62] Loss: 0.82465 
Epoch [24/300] Training [18/62] Loss: 0.65725 
Epoch [24/300] Training [19/62] Loss: 0.84409 
Epoch [24/300] Training [20/62] Loss: 0.75796 
Epoch [24/300] Training [21/62] Loss: 0.56564 
Epoch [24/300] Training [22/62] Loss: 0.79564 
Epoch [24/300] Training [23/62] Loss: 0.68511 
Epoch [24/300] Training [24/62] Loss: 0.64778 
Epoch [24/300] Training [25/62] Loss: 0.61041 
Epoch [24/300] Training [26/62] Loss: 0.79232 
Epoch [24/300] Training [27/62] Loss: 0.62313 
Epoch [24/300] Training [28/62] Loss: 0.61269 
Epoch [24/300] Training [29/62] Loss: 0.73553 
Epoch [24/300] Training [30/62] Loss: 0.82005 
Epoch [24/300] Training [31/62] Loss: 0.67751 
Epoch [24/300] Training [32/62] Loss: 0.83896 
Epoch [24/300] Training [33/62] Loss: 0.68188 
Epoch [24/300] Training [34/62] Loss: 0.86896 
Epoch [24/300] Training [35/62] Loss: 0.54047 
Epoch [24/300] Training [36/62] Loss: 0.71207 
Epoch [24/300] Training [37/62] Loss: 0.73898 
Epoch [24/300] Training [38/62] Loss: 0.77686 
Epoch [24/300] Training [39/62] Loss: 0.56628 
Epoch [24/300] Training [40/62] Loss: 0.86065 
Epoch [24/300] Training [41/62] Loss: 0.65830 
Epoch [24/300] Training [42/62] Loss: 0.63646 
Epoch [24/300] Training [43/62] Loss: 0.78597 
Epoch [24/300] Training [44/62] Loss: 0.73074 
Epoch [24/300] Training [45/62] Loss: 0.57010 
Epoch [24/300] Training [46/62] Loss: 0.53285 
Epoch [24/300] Training [47/62] Loss: 0.77310 
Epoch [24/300] Training [48/62] Loss: 0.55296 
Epoch [24/300] Training [49/62] Loss: 0.72359 
Epoch [24/300] Training [50/62] Loss: 0.62114 
Epoch [24/300] Training [51/62] Loss: 0.78456 
Epoch [24/300] Training [52/62] Loss: 0.70953 
Epoch [24/300] Training [53/62] Loss: 0.81484 
Epoch [24/300] Training [54/62] Loss: 0.53755 
Epoch [24/300] Training [55/62] Loss: 0.77115 
Epoch [24/300] Training [56/62] Loss: 0.64211 
Epoch [24/300] Training [57/62] Loss: 0.70446 
Epoch [24/300] Training [58/62] Loss: 0.66859 
Epoch [24/300] Training [59/62] Loss: 0.61028 
Epoch [24/300] Training [60/62] Loss: 0.74092 
Epoch [24/300] Training [61/62] Loss: 0.61261 
Epoch [24/300] Training [62/62] Loss: 1.29054 
Epoch [24/300] Training metric {'Train/mean dice_metric': 0.47945019602775574, 'Train/mean miou_metric': 0.3611481785774231, 'Train/mean f1': 0.5433069467544556, 'Train/mean precision': 0.5124679207801819, 'Train/mean recall': 0.5780953168869019, 'Train/mean hd95_metric': 96.7925796508789}
Epoch [24/300] Validation [1/16] Loss: 1.01086  focal_loss 0.35843  dice_loss 0.65243 
Epoch [24/300] Validation [2/16] Loss: 1.10414  focal_loss 0.33706  dice_loss 0.76708 
Epoch [24/300] Validation [3/16] Loss: 1.15520  focal_loss 0.38741  dice_loss 0.76779 
Epoch [24/300] Validation [4/16] Loss: 1.14363  focal_loss 0.40016  dice_loss 0.74347 
Epoch [24/300] Validation [5/16] Loss: 0.96720  focal_loss 0.22956  dice_loss 0.73764 
Epoch [24/300] Validation [6/16] Loss: 1.02954  focal_loss 0.28947  dice_loss 0.74007 
Epoch [24/300] Validation [7/16] Loss: 1.09348  focal_loss 0.40425  dice_loss 0.68923 
Epoch [24/300] Validation [8/16] Loss: 1.16999  focal_loss 0.35770  dice_loss 0.81230 
Epoch [24/300] Validation [9/16] Loss: 1.14157  focal_loss 0.42587  dice_loss 0.71571 
Epoch [24/300] Validation [10/16] Loss: 0.95510  focal_loss 0.25726  dice_loss 0.69784 
Epoch [24/300] Validation [11/16] Loss: 1.11534  focal_loss 0.40855  dice_loss 0.70679 
Epoch [24/300] Validation [12/16] Loss: 1.11114  focal_loss 0.32497  dice_loss 0.78617 
Epoch [24/300] Validation [13/16] Loss: 1.10378  focal_loss 0.38091  dice_loss 0.72286 
Epoch [24/300] Validation [14/16] Loss: 1.15796  focal_loss 0.33987  dice_loss 0.81809 
Epoch [24/300] Validation [15/16] Loss: 0.93707  focal_loss 0.27824  dice_loss 0.65882 
Epoch [24/300] Validation [16/16] Loss: 1.02840  focal_loss 0.32891  dice_loss 0.69949 
Epoch [24/300] Validation metric {'Val/mean dice_metric': 0.44086286425590515, 'Val/mean miou_metric': 0.32511091232299805, 'Val/mean f1': 0.4596109092235565, 'Val/mean precision': 0.37220466136932373, 'Val/mean recall': 0.6006680727005005, 'Val/mean hd95_metric': 109.5762939453125}
Cheakpoint...
Epoch [24/300] best acc:tensor([0.4510], device='cuda:0'), Now : mean acc: tensor([0.4409], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.44086286425590515, 'Val/mean miou_metric': 0.32511091232299805, 'Val/mean f1': 0.4596109092235565, 'Val/mean precision': 0.37220466136932373, 'Val/mean recall': 0.6006680727005005, 'Val/mean hd95_metric': 109.5762939453125}
Epoch [25/300] Training [1/62] Loss: 0.76759 
Epoch [25/300] Training [2/62] Loss: 0.71197 
Epoch [25/300] Training [3/62] Loss: 0.63704 
Epoch [25/300] Training [4/62] Loss: 0.56655 
Epoch [25/300] Training [5/62] Loss: 0.78777 
Epoch [25/300] Training [6/62] Loss: 0.69019 
Epoch [25/300] Training [7/62] Loss: 0.51970 
Epoch [25/300] Training [8/62] Loss: 0.76664 
Epoch [25/300] Training [9/62] Loss: 0.56244 
Epoch [25/300] Training [10/62] Loss: 0.61561 
Epoch [25/300] Training [11/62] Loss: 0.61145 
Epoch [25/300] Training [12/62] Loss: 0.59909 
Epoch [25/300] Training [13/62] Loss: 0.73912 
Epoch [25/300] Training [14/62] Loss: 0.52812 
Epoch [25/300] Training [15/62] Loss: 0.83099 
Epoch [25/300] Training [16/62] Loss: 0.62132 
Epoch [25/300] Training [17/62] Loss: 0.70672 
Epoch [25/300] Training [18/62] Loss: 0.71189 
Epoch [25/300] Training [19/62] Loss: 0.66984 
Epoch [25/300] Training [20/62] Loss: 0.73138 
Epoch [25/300] Training [21/62] Loss: 0.56671 
Epoch [25/300] Training [22/62] Loss: 0.63545 
Epoch [25/300] Training [23/62] Loss: 0.69135 
Epoch [25/300] Training [24/62] Loss: 0.67514 
Epoch [25/300] Training [25/62] Loss: 0.57046 
Epoch [25/300] Training [26/62] Loss: 0.88608 
Epoch [25/300] Training [27/62] Loss: 0.66591 
Epoch [25/300] Training [28/62] Loss: 0.61750 
Epoch [25/300] Training [29/62] Loss: 0.65922 
Epoch [25/300] Training [30/62] Loss: 0.62837 
Epoch [25/300] Training [31/62] Loss: 0.57894 
Epoch [25/300] Training [32/62] Loss: 0.69526 
Epoch [25/300] Training [33/62] Loss: 0.75622 
Epoch [25/300] Training [34/62] Loss: 0.55691 
Epoch [25/300] Training [35/62] Loss: 0.75116 
Epoch [25/300] Training [36/62] Loss: 0.77453 
Epoch [25/300] Training [37/62] Loss: 0.84342 
Epoch [25/300] Training [38/62] Loss: 0.64556 
Epoch [25/300] Training [39/62] Loss: 0.59516 
Epoch [25/300] Training [40/62] Loss: 0.59590 
Epoch [25/300] Training [41/62] Loss: 0.76477 
Epoch [25/300] Training [42/62] Loss: 0.94547 
Epoch [25/300] Training [43/62] Loss: 0.63399 
Epoch [25/300] Training [44/62] Loss: 0.68173 
Epoch [25/300] Training [45/62] Loss: 0.59297 
Epoch [25/300] Training [46/62] Loss: 0.65095 
Epoch [25/300] Training [47/62] Loss: 0.71638 
Epoch [25/300] Training [48/62] Loss: 0.73327 
Epoch [25/300] Training [49/62] Loss: 0.69387 
Epoch [25/300] Training [50/62] Loss: 0.49794 
Epoch [25/300] Training [51/62] Loss: 0.59652 
Epoch [25/300] Training [52/62] Loss: 0.78665 
Epoch [25/300] Training [53/62] Loss: 0.68520 
Epoch [25/300] Training [54/62] Loss: 0.66563 
Epoch [25/300] Training [55/62] Loss: 0.77144 
Epoch [25/300] Training [56/62] Loss: 0.63219 
Epoch [25/300] Training [57/62] Loss: 0.67653 
Epoch [25/300] Training [58/62] Loss: 0.64981 
Epoch [25/300] Training [59/62] Loss: 0.64834 
Epoch [25/300] Training [60/62] Loss: 0.73730 
Epoch [25/300] Training [61/62] Loss: 0.69045 
Epoch [25/300] Training [62/62] Loss: 0.91768 
Epoch [25/300] Training metric {'Train/mean dice_metric': 0.5005546808242798, 'Train/mean miou_metric': 0.3808356523513794, 'Train/mean f1': 0.5671674609184265, 'Train/mean precision': 0.552554726600647, 'Train/mean recall': 0.5825740098953247, 'Train/mean hd95_metric': 92.44376373291016}
Epoch [25/300] Validation [1/16] Loss: 0.94400  focal_loss 0.29249  dice_loss 0.65151 
Epoch [25/300] Validation [2/16] Loss: 0.73402  focal_loss 0.11384  dice_loss 0.62018 
Epoch [25/300] Validation [3/16] Loss: 0.78037  focal_loss 0.14736  dice_loss 0.63302 
Epoch [25/300] Validation [4/16] Loss: 0.67183  focal_loss 0.13438  dice_loss 0.53746 
Epoch [25/300] Validation [5/16] Loss: 0.62845  focal_loss 0.05712  dice_loss 0.57133 
Epoch [25/300] Validation [6/16] Loss: 0.61519  focal_loss 0.08230  dice_loss 0.53289 
Epoch [25/300] Validation [7/16] Loss: 0.62304  focal_loss 0.11993  dice_loss 0.50312 
Epoch [25/300] Validation [8/16] Loss: 0.84261  focal_loss 0.13745  dice_loss 0.70516 
Epoch [25/300] Validation [9/16] Loss: 0.82843  focal_loss 0.16544  dice_loss 0.66299 
Epoch [25/300] Validation [10/16] Loss: 0.73170  focal_loss 0.12774  dice_loss 0.60396 
Epoch [25/300] Validation [11/16] Loss: 0.55991  focal_loss 0.07987  dice_loss 0.48004 
Epoch [25/300] Validation [12/16] Loss: 0.72046  focal_loss 0.06205  dice_loss 0.65841 
Epoch [25/300] Validation [13/16] Loss: 0.54861  focal_loss 0.08922  dice_loss 0.45939 
Epoch [25/300] Validation [14/16] Loss: 0.91096  focal_loss 0.16020  dice_loss 0.75076 
Epoch [25/300] Validation [15/16] Loss: 0.71278  focal_loss 0.14116  dice_loss 0.57162 
Epoch [25/300] Validation [16/16] Loss: 0.47590  focal_loss 0.08078  dice_loss 0.39512 
Epoch [25/300] Validation metric {'Val/mean dice_metric': 0.48978039622306824, 'Val/mean miou_metric': 0.3732321262359619, 'Val/mean f1': 0.5620852708816528, 'Val/mean precision': 0.5544548630714417, 'Val/mean recall': 0.5699288249015808, 'Val/mean hd95_metric': 93.19084167480469}
Cheakpoint...
Epoch [25/300] best acc:tensor([0.4898], device='cuda:0'), Now : mean acc: tensor([0.4898], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.48978039622306824, 'Val/mean miou_metric': 0.3732321262359619, 'Val/mean f1': 0.5620852708816528, 'Val/mean precision': 0.5544548630714417, 'Val/mean recall': 0.5699288249015808, 'Val/mean hd95_metric': 93.19084167480469}
Epoch [26/300] Training [1/62] Loss: 0.69555 
Epoch [26/300] Training [2/62] Loss: 0.72698 
Epoch [26/300] Training [3/62] Loss: 0.55083 
Epoch [26/300] Training [4/62] Loss: 0.85916 
Epoch [26/300] Training [5/62] Loss: 0.62476 
Epoch [26/300] Training [6/62] Loss: 0.66101 
Epoch [26/300] Training [7/62] Loss: 0.84489 
Epoch [26/300] Training [8/62] Loss: 0.72035 
Epoch [26/300] Training [9/62] Loss: 0.67240 
Epoch [26/300] Training [10/62] Loss: 0.84154 
Epoch [26/300] Training [11/62] Loss: 0.56210 
Epoch [26/300] Training [12/62] Loss: 0.69496 
Epoch [26/300] Training [13/62] Loss: 0.61819 
Epoch [26/300] Training [14/62] Loss: 0.61076 
Epoch [26/300] Training [15/62] Loss: 0.58594 
Epoch [26/300] Training [16/62] Loss: 0.65442 
Epoch [26/300] Training [17/62] Loss: 0.74328 
Epoch [26/300] Training [18/62] Loss: 0.75394 
Epoch [26/300] Training [19/62] Loss: 0.59272 
Epoch [26/300] Training [20/62] Loss: 0.60844 
Epoch [26/300] Training [21/62] Loss: 0.57327 
Epoch [26/300] Training [22/62] Loss: 0.65774 
Epoch [26/300] Training [23/62] Loss: 0.69904 
Epoch [26/300] Training [24/62] Loss: 0.77899 
Epoch [26/300] Training [25/62] Loss: 0.61729 
Epoch [26/300] Training [26/62] Loss: 0.64498 
Epoch [26/300] Training [27/62] Loss: 0.79333 
Epoch [26/300] Training [28/62] Loss: 0.71858 
Epoch [26/300] Training [29/62] Loss: 0.77523 
Epoch [26/300] Training [30/62] Loss: 0.49735 
Epoch [26/300] Training [31/62] Loss: 0.58481 
Epoch [26/300] Training [32/62] Loss: 0.77002 
Epoch [26/300] Training [33/62] Loss: 0.76145 
Epoch [26/300] Training [34/62] Loss: 0.68197 
Epoch [26/300] Training [35/62] Loss: 0.64562 
Epoch [26/300] Training [36/62] Loss: 0.73307 
Epoch [26/300] Training [37/62] Loss: 0.68771 
Epoch [26/300] Training [38/62] Loss: 0.68294 
Epoch [26/300] Training [39/62] Loss: 0.56946 
Epoch [26/300] Training [40/62] Loss: 0.63478 
Epoch [26/300] Training [41/62] Loss: 0.61218 
Epoch [26/300] Training [42/62] Loss: 0.53682 
Epoch [26/300] Training [43/62] Loss: 0.61480 
Epoch [26/300] Training [44/62] Loss: 0.64830 
Epoch [26/300] Training [45/62] Loss: 0.55294 
Epoch [26/300] Training [46/62] Loss: 0.54771 
Epoch [26/300] Training [47/62] Loss: 0.71902 
Epoch [26/300] Training [48/62] Loss: 0.61563 
Epoch [26/300] Training [49/62] Loss: 0.63260 
Epoch [26/300] Training [50/62] Loss: 0.51732 
Epoch [26/300] Training [51/62] Loss: 0.54530 
Epoch [26/300] Training [52/62] Loss: 0.52052 
Epoch [26/300] Training [53/62] Loss: 0.47024 
Epoch [26/300] Training [54/62] Loss: 0.54013 
Epoch [26/300] Training [55/62] Loss: 0.77957 
Epoch [26/300] Training [56/62] Loss: 0.74628 
Epoch [26/300] Training [57/62] Loss: 0.68037 
Epoch [26/300] Training [58/62] Loss: 0.70100 
Epoch [26/300] Training [59/62] Loss: 0.73465 
Epoch [26/300] Training [60/62] Loss: 0.59360 
Epoch [26/300] Training [61/62] Loss: 0.71378 
Epoch [26/300] Training [62/62] Loss: 0.82270 
Epoch [26/300] Training metric {'Train/mean dice_metric': 0.518063485622406, 'Train/mean miou_metric': 0.3959328830242157, 'Train/mean f1': 0.5837123394012451, 'Train/mean precision': 0.5656024813652039, 'Train/mean recall': 0.603020191192627, 'Train/mean hd95_metric': 91.78568267822266}
Epoch [26/300] Validation [1/16] Loss: 0.72243  focal_loss 0.21839  dice_loss 0.50404 
Epoch [26/300] Validation [2/16] Loss: 0.80481  focal_loss 0.16425  dice_loss 0.64056 
Epoch [26/300] Validation [3/16] Loss: 0.70717  focal_loss 0.13174  dice_loss 0.57543 
Epoch [26/300] Validation [4/16] Loss: 0.56552  focal_loss 0.07999  dice_loss 0.48553 
Epoch [26/300] Validation [5/16] Loss: 0.53488  focal_loss 0.04195  dice_loss 0.49292 
Epoch [26/300] Validation [6/16] Loss: 0.55764  focal_loss 0.08074  dice_loss 0.47690 
Epoch [26/300] Validation [7/16] Loss: 0.54790  focal_loss 0.11742  dice_loss 0.43048 
Epoch [26/300] Validation [8/16] Loss: 0.67985  focal_loss 0.08407  dice_loss 0.59578 
Epoch [26/300] Validation [9/16] Loss: 0.63534  focal_loss 0.09355  dice_loss 0.54179 
Epoch [26/300] Validation [10/16] Loss: 0.81044  focal_loss 0.16315  dice_loss 0.64730 
Epoch [26/300] Validation [11/16] Loss: 0.61248  focal_loss 0.09716  dice_loss 0.51532 
Epoch [26/300] Validation [12/16] Loss: 0.73715  focal_loss 0.10161  dice_loss 0.63554 
Epoch [26/300] Validation [13/16] Loss: 0.46444  focal_loss 0.04839  dice_loss 0.41605 
Epoch [26/300] Validation [14/16] Loss: 0.80201  focal_loss 0.10456  dice_loss 0.69744 
Epoch [26/300] Validation [15/16] Loss: 0.57897  focal_loss 0.13593  dice_loss 0.44304 
Epoch [26/300] Validation [16/16] Loss: 0.39843  focal_loss 0.08199  dice_loss 0.31644 
Epoch [26/300] Validation metric {'Val/mean dice_metric': 0.5216074585914612, 'Val/mean miou_metric': 0.39861148595809937, 'Val/mean f1': 0.5834237337112427, 'Val/mean precision': 0.556053876876831, 'Val/mean recall': 0.6136273741722107, 'Val/mean hd95_metric': 94.08854675292969}
Cheakpoint...
Epoch [26/300] best acc:tensor([0.5216], device='cuda:0'), Now : mean acc: tensor([0.5216], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5216074585914612, 'Val/mean miou_metric': 0.39861148595809937, 'Val/mean f1': 0.5834237337112427, 'Val/mean precision': 0.556053876876831, 'Val/mean recall': 0.6136273741722107, 'Val/mean hd95_metric': 94.08854675292969}
Epoch [27/300] Training [1/62] Loss: 0.59256 
Epoch [27/300] Training [2/62] Loss: 0.76039 
Epoch [27/300] Training [3/62] Loss: 0.57033 
Epoch [27/300] Training [4/62] Loss: 0.70966 
Epoch [27/300] Training [5/62] Loss: 0.55262 
Epoch [27/300] Training [6/62] Loss: 0.58834 
Epoch [27/300] Training [7/62] Loss: 0.55007 
Epoch [27/300] Training [8/62] Loss: 0.89642 
Epoch [27/300] Training [9/62] Loss: 0.61399 
Epoch [27/300] Training [10/62] Loss: 0.63858 
Epoch [27/300] Training [11/62] Loss: 0.55565 
Epoch [27/300] Training [12/62] Loss: 0.71257 
Epoch [27/300] Training [13/62] Loss: 0.80127 
Epoch [27/300] Training [14/62] Loss: 0.66039 
Epoch [27/300] Training [15/62] Loss: 0.71309 
Epoch [27/300] Training [16/62] Loss: 0.75927 
Epoch [27/300] Training [17/62] Loss: 0.74894 
Epoch [27/300] Training [18/62] Loss: 0.85581 
Epoch [27/300] Training [19/62] Loss: 0.87010 
Epoch [27/300] Training [20/62] Loss: 0.67350 
Epoch [27/300] Training [21/62] Loss: 0.76534 
Epoch [27/300] Training [22/62] Loss: 0.53365 
Epoch [27/300] Training [23/62] Loss: 0.54568 
Epoch [27/300] Training [24/62] Loss: 0.83280 
Epoch [27/300] Training [25/62] Loss: 0.70603 
Epoch [27/300] Training [26/62] Loss: 0.72087 
Epoch [27/300] Training [27/62] Loss: 0.59747 
Epoch [27/300] Training [28/62] Loss: 0.54511 
Epoch [27/300] Training [29/62] Loss: 0.63347 
Epoch [27/300] Training [30/62] Loss: 0.59840 
Epoch [27/300] Training [31/62] Loss: 0.61619 
Epoch [27/300] Training [32/62] Loss: 0.59255 
Epoch [27/300] Training [33/62] Loss: 0.51768 
Epoch [27/300] Training [34/62] Loss: 0.70392 
Epoch [27/300] Training [35/62] Loss: 0.57918 
Epoch [27/300] Training [36/62] Loss: 0.64887 
Epoch [27/300] Training [37/62] Loss: 0.60349 
Epoch [27/300] Training [38/62] Loss: 0.75365 
Epoch [27/300] Training [39/62] Loss: 0.81685 
Epoch [27/300] Training [40/62] Loss: 0.49130 
Epoch [27/300] Training [41/62] Loss: 0.57201 
Epoch [27/300] Training [42/62] Loss: 0.77377 
Epoch [27/300] Training [43/62] Loss: 0.65822 
Epoch [27/300] Training [44/62] Loss: 0.69390 
Epoch [27/300] Training [45/62] Loss: 0.55463 
Epoch [27/300] Training [46/62] Loss: 0.52726 
Epoch [27/300] Training [47/62] Loss: 0.66691 
Epoch [27/300] Training [48/62] Loss: 0.62695 
Epoch [27/300] Training [49/62] Loss: 0.56936 
Epoch [27/300] Training [50/62] Loss: 0.69227 
Epoch [27/300] Training [51/62] Loss: 0.55178 
Epoch [27/300] Training [52/62] Loss: 0.72463 
Epoch [27/300] Training [53/62] Loss: 0.76270 
Epoch [27/300] Training [54/62] Loss: 0.70472 
Epoch [27/300] Training [55/62] Loss: 0.77377 
Epoch [27/300] Training [56/62] Loss: 0.56466 
Epoch [27/300] Training [57/62] Loss: 0.67174 
Epoch [27/300] Training [58/62] Loss: 0.59406 
Epoch [27/300] Training [59/62] Loss: 0.61480 
Epoch [27/300] Training [60/62] Loss: 0.72346 
Epoch [27/300] Training [61/62] Loss: 0.61057 
Epoch [27/300] Training [62/62] Loss: 0.83242 
Epoch [27/300] Training metric {'Train/mean dice_metric': 0.5192267894744873, 'Train/mean miou_metric': 0.4003201425075531, 'Train/mean f1': 0.5852887630462646, 'Train/mean precision': 0.5809168815612793, 'Train/mean recall': 0.589726984500885, 'Train/mean hd95_metric': 91.20255279541016}
Epoch [27/300] Validation [1/16] Loss: 1.03192  focal_loss 0.29419  dice_loss 0.73773 
Epoch [27/300] Validation [2/16] Loss: 1.00105  focal_loss 0.20158  dice_loss 0.79947 
Epoch [27/300] Validation [3/16] Loss: 0.99305  focal_loss 0.20241  dice_loss 0.79064 
Epoch [27/300] Validation [4/16] Loss: 0.93658  focal_loss 0.19029  dice_loss 0.74629 
Epoch [27/300] Validation [5/16] Loss: 0.80793  focal_loss 0.09182  dice_loss 0.71611 
Epoch [27/300] Validation [6/16] Loss: 0.84024  focal_loss 0.15161  dice_loss 0.68863 
Epoch [27/300] Validation [7/16] Loss: 0.82947  focal_loss 0.14931  dice_loss 0.68016 
Epoch [27/300] Validation [8/16] Loss: 0.92902  focal_loss 0.14127  dice_loss 0.78776 
Epoch [27/300] Validation [9/16] Loss: 0.91923  focal_loss 0.18377  dice_loss 0.73546 
Epoch [27/300] Validation [10/16] Loss: 1.01125  focal_loss 0.23012  dice_loss 0.78113 
Epoch [27/300] Validation [11/16] Loss: 0.90700  focal_loss 0.16273  dice_loss 0.74428 
Epoch [27/300] Validation [12/16] Loss: 0.86302  focal_loss 0.09184  dice_loss 0.77118 
Epoch [27/300] Validation [13/16] Loss: 0.90665  focal_loss 0.16690  dice_loss 0.73975 
Epoch [27/300] Validation [14/16] Loss: 1.13903  focal_loss 0.24102  dice_loss 0.89800 
Epoch [27/300] Validation [15/16] Loss: 0.95031  focal_loss 0.21683  dice_loss 0.73348 
Epoch [27/300] Validation [16/16] Loss: 0.81032  focal_loss 0.16394  dice_loss 0.64638 
Epoch [27/300] Validation metric {'Val/mean dice_metric': 0.462608277797699, 'Val/mean miou_metric': 0.3521463871002197, 'Val/mean f1': 0.5423307418823242, 'Val/mean precision': 0.5690970420837402, 'Val/mean recall': 0.5179691314697266, 'Val/mean hd95_metric': 95.46421813964844}
Cheakpoint...
Epoch [27/300] best acc:tensor([0.5216], device='cuda:0'), Now : mean acc: tensor([0.4626], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.462608277797699, 'Val/mean miou_metric': 0.3521463871002197, 'Val/mean f1': 0.5423307418823242, 'Val/mean precision': 0.5690970420837402, 'Val/mean recall': 0.5179691314697266, 'Val/mean hd95_metric': 95.46421813964844}
Epoch [28/300] Training [1/62] Loss: 0.58925 
Epoch [28/300] Training [2/62] Loss: 0.61928 
Epoch [28/300] Training [3/62] Loss: 0.93188 
Epoch [28/300] Training [4/62] Loss: 0.61277 
Epoch [28/300] Training [5/62] Loss: 0.77388 
Epoch [28/300] Training [6/62] Loss: 0.56032 
Epoch [28/300] Training [7/62] Loss: 0.77698 
Epoch [28/300] Training [8/62] Loss: 0.71752 
Epoch [28/300] Training [9/62] Loss: 0.74722 
Epoch [28/300] Training [10/62] Loss: 0.65942 
Epoch [28/300] Training [11/62] Loss: 0.54975 
Epoch [28/300] Training [12/62] Loss: 0.58646 
Epoch [28/300] Training [13/62] Loss: 0.61508 
Epoch [28/300] Training [14/62] Loss: 0.74419 
Epoch [28/300] Training [15/62] Loss: 0.70753 
Epoch [28/300] Training [16/62] Loss: 0.64611 
Epoch [28/300] Training [17/62] Loss: 0.59549 
Epoch [28/300] Training [18/62] Loss: 0.78285 
Epoch [28/300] Training [19/62] Loss: 0.76828 
Epoch [28/300] Training [20/62] Loss: 0.61332 
Epoch [28/300] Training [21/62] Loss: 0.53057 
Epoch [28/300] Training [22/62] Loss: 0.54799 
Epoch [28/300] Training [23/62] Loss: 0.48029 
Epoch [28/300] Training [24/62] Loss: 0.67283 
Epoch [28/300] Training [25/62] Loss: 0.66323 
Epoch [28/300] Training [26/62] Loss: 0.56108 
Epoch [28/300] Training [27/62] Loss: 0.49036 
Epoch [28/300] Training [28/62] Loss: 0.68058 
Epoch [28/300] Training [29/62] Loss: 0.71715 
Epoch [28/300] Training [30/62] Loss: 0.70910 
Epoch [28/300] Training [31/62] Loss: 0.60273 
Epoch [28/300] Training [32/62] Loss: 0.82507 
Epoch [28/300] Training [33/62] Loss: 0.76944 
Epoch [28/300] Training [34/62] Loss: 0.62215 
Epoch [28/300] Training [35/62] Loss: 0.59659 
Epoch [28/300] Training [36/62] Loss: 0.76371 
Epoch [28/300] Training [37/62] Loss: 0.69821 
Epoch [28/300] Training [38/62] Loss: 0.61522 
Epoch [28/300] Training [39/62] Loss: 0.53601 
Epoch [28/300] Training [40/62] Loss: 0.83064 
Epoch [28/300] Training [41/62] Loss: 0.51420 
Epoch [28/300] Training [42/62] Loss: 0.57178 
Epoch [28/300] Training [43/62] Loss: 0.92978 
Epoch [28/300] Training [44/62] Loss: 0.66326 
Epoch [28/300] Training [45/62] Loss: 0.61790 
Epoch [28/300] Training [46/62] Loss: 0.66674 
Epoch [28/300] Training [47/62] Loss: 0.55928 
Epoch [28/300] Training [48/62] Loss: 0.60617 
Epoch [28/300] Training [49/62] Loss: 0.45708 
Epoch [28/300] Training [50/62] Loss: 0.74943 
Epoch [28/300] Training [51/62] Loss: 0.62925 
Epoch [28/300] Training [52/62] Loss: 0.71152 
Epoch [28/300] Training [53/62] Loss: 0.56546 
Epoch [28/300] Training [54/62] Loss: 0.67062 
Epoch [28/300] Training [55/62] Loss: 0.77958 
Epoch [28/300] Training [56/62] Loss: 0.51051 
Epoch [28/300] Training [57/62] Loss: 0.63618 
Epoch [28/300] Training [58/62] Loss: 0.56497 
Epoch [28/300] Training [59/62] Loss: 0.72132 
Epoch [28/300] Training [60/62] Loss: 0.66637 
Epoch [28/300] Training [61/62] Loss: 0.58102 
Epoch [28/300] Training [62/62] Loss: 0.74555 
Epoch [28/300] Training metric {'Train/mean dice_metric': 0.5204945206642151, 'Train/mean miou_metric': 0.3995344042778015, 'Train/mean f1': 0.5887733697891235, 'Train/mean precision': 0.5790729522705078, 'Train/mean recall': 0.598804235458374, 'Train/mean hd95_metric': 92.60853576660156}
Epoch [28/300] Validation [1/16] Loss: 0.75073  focal_loss 0.21560  dice_loss 0.53512 
Epoch [28/300] Validation [2/16] Loss: 0.86158  focal_loss 0.16485  dice_loss 0.69673 
Epoch [28/300] Validation [3/16] Loss: 0.65767  focal_loss 0.09700  dice_loss 0.56067 
Epoch [28/300] Validation [4/16] Loss: 0.62625  focal_loss 0.12458  dice_loss 0.50167 
Epoch [28/300] Validation [5/16] Loss: 0.64822  focal_loss 0.10535  dice_loss 0.54287 
Epoch [28/300] Validation [6/16] Loss: 0.61538  focal_loss 0.10460  dice_loss 0.51077 
Epoch [28/300] Validation [7/16] Loss: 0.60091  focal_loss 0.08655  dice_loss 0.51437 
Epoch [28/300] Validation [8/16] Loss: 0.78579  focal_loss 0.13293  dice_loss 0.65287 
Epoch [28/300] Validation [9/16] Loss: 0.75160  focal_loss 0.15395  dice_loss 0.59765 
Epoch [28/300] Validation [10/16] Loss: 0.63723  focal_loss 0.08665  dice_loss 0.55058 
Epoch [28/300] Validation [11/16] Loss: 0.62926  focal_loss 0.09721  dice_loss 0.53206 
Epoch [28/300] Validation [12/16] Loss: 0.71534  focal_loss 0.05404  dice_loss 0.66130 
Epoch [28/300] Validation [13/16] Loss: 0.61571  focal_loss 0.08943  dice_loss 0.52628 
Epoch [28/300] Validation [14/16] Loss: 0.90452  focal_loss 0.16083  dice_loss 0.74369 
Epoch [28/300] Validation [15/16] Loss: 0.57879  focal_loss 0.07931  dice_loss 0.49949 
Epoch [28/300] Validation [16/16] Loss: 0.47658  focal_loss 0.09383  dice_loss 0.38275 
Epoch [28/300] Validation metric {'Val/mean dice_metric': 0.5187816023826599, 'Val/mean miou_metric': 0.39701515436172485, 'Val/mean f1': 0.5779673457145691, 'Val/mean precision': 0.5543018579483032, 'Val/mean recall': 0.6037436127662659, 'Val/mean hd95_metric': 94.55577850341797}
Cheakpoint...
Epoch [28/300] best acc:tensor([0.5216], device='cuda:0'), Now : mean acc: tensor([0.5188], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5187816023826599, 'Val/mean miou_metric': 0.39701515436172485, 'Val/mean f1': 0.5779673457145691, 'Val/mean precision': 0.5543018579483032, 'Val/mean recall': 0.6037436127662659, 'Val/mean hd95_metric': 94.55577850341797}
Epoch [29/300] Training [1/62] Loss: 0.62118 
Epoch [29/300] Training [2/62] Loss: 0.68643 
Epoch [29/300] Training [3/62] Loss: 0.65747 
Epoch [29/300] Training [4/62] Loss: 0.43712 
Epoch [29/300] Training [5/62] Loss: 0.63346 
Epoch [29/300] Training [6/62] Loss: 0.67573 
Epoch [29/300] Training [7/62] Loss: 0.67136 
Epoch [29/300] Training [8/62] Loss: 0.52472 
Epoch [29/300] Training [9/62] Loss: 0.61411 
Epoch [29/300] Training [10/62] Loss: 0.57934 
Epoch [29/300] Training [11/62] Loss: 0.66586 
Epoch [29/300] Training [12/62] Loss: 0.62099 
Epoch [29/300] Training [13/62] Loss: 0.60980 
Epoch [29/300] Training [14/62] Loss: 0.64496 
Epoch [29/300] Training [15/62] Loss: 0.73826 
Epoch [29/300] Training [16/62] Loss: 0.69389 
Epoch [29/300] Training [17/62] Loss: 0.63734 
Epoch [29/300] Training [18/62] Loss: 0.54762 
Epoch [29/300] Training [19/62] Loss: 0.50386 
Epoch [29/300] Training [20/62] Loss: 0.42390 
Epoch [29/300] Training [21/62] Loss: 0.51439 
Epoch [29/300] Training [22/62] Loss: 0.49090 
Epoch [29/300] Training [23/62] Loss: 0.65988 
Epoch [29/300] Training [24/62] Loss: 0.49025 
Epoch [29/300] Training [25/62] Loss: 0.57314 
Epoch [29/300] Training [26/62] Loss: 0.62124 
Epoch [29/300] Training [27/62] Loss: 0.47843 
Epoch [29/300] Training [28/62] Loss: 0.83686 
Epoch [29/300] Training [29/62] Loss: 0.55964 
Epoch [29/300] Training [30/62] Loss: 0.84585 
Epoch [29/300] Training [31/62] Loss: 0.47367 
Epoch [29/300] Training [32/62] Loss: 0.62747 
Epoch [29/300] Training [33/62] Loss: 0.56647 
Epoch [29/300] Training [34/62] Loss: 0.69305 
Epoch [29/300] Training [35/62] Loss: 0.56205 
Epoch [29/300] Training [36/62] Loss: 0.56322 
Epoch [29/300] Training [37/62] Loss: 0.48512 
Epoch [29/300] Training [38/62] Loss: 0.78457 
Epoch [29/300] Training [39/62] Loss: 0.72139 
Epoch [29/300] Training [40/62] Loss: 0.53657 
Epoch [29/300] Training [41/62] Loss: 0.62085 
Epoch [29/300] Training [42/62] Loss: 0.54215 
Epoch [29/300] Training [43/62] Loss: 0.67221 
Epoch [29/300] Training [44/62] Loss: 0.63444 
Epoch [29/300] Training [45/62] Loss: 0.53132 
Epoch [29/300] Training [46/62] Loss: 0.94736 
Epoch [29/300] Training [47/62] Loss: 0.62728 
Epoch [29/300] Training [48/62] Loss: 0.62765 
Epoch [29/300] Training [49/62] Loss: 0.86035 
Epoch [29/300] Training [50/62] Loss: 0.84793 
Epoch [29/300] Training [51/62] Loss: 0.69245 
Epoch [29/300] Training [52/62] Loss: 0.57217 
Epoch [29/300] Training [53/62] Loss: 0.68430 
Epoch [29/300] Training [54/62] Loss: 0.55276 
Epoch [29/300] Training [55/62] Loss: 0.56395 
Epoch [29/300] Training [56/62] Loss: 0.53847 
Epoch [29/300] Training [57/62] Loss: 0.82493 
Epoch [29/300] Training [58/62] Loss: 0.58254 
Epoch [29/300] Training [59/62] Loss: 0.64456 
Epoch [29/300] Training [60/62] Loss: 0.51605 
Epoch [29/300] Training [61/62] Loss: 0.57415 
Epoch [29/300] Training [62/62] Loss: 0.41578 
Epoch [29/300] Training metric {'Train/mean dice_metric': 0.5491611361503601, 'Train/mean miou_metric': 0.4282107949256897, 'Train/mean f1': 0.614960789680481, 'Train/mean precision': 0.6085095405578613, 'Train/mean recall': 0.6215503215789795, 'Train/mean hd95_metric': 88.73368835449219}
Epoch [29/300] Validation [1/16] Loss: 0.73215  focal_loss 0.16798  dice_loss 0.56417 
Epoch [29/300] Validation [2/16] Loss: 0.96883  focal_loss 0.17174  dice_loss 0.79709 
Epoch [29/300] Validation [3/16] Loss: 0.91825  focal_loss 0.17605  dice_loss 0.74220 
Epoch [29/300] Validation [4/16] Loss: 0.82385  focal_loss 0.16205  dice_loss 0.66180 
Epoch [29/300] Validation [5/16] Loss: 0.77826  focal_loss 0.09988  dice_loss 0.67838 
Epoch [29/300] Validation [6/16] Loss: 0.80141  focal_loss 0.12360  dice_loss 0.67780 
Epoch [29/300] Validation [7/16] Loss: 0.70875  focal_loss 0.12182  dice_loss 0.58692 
Epoch [29/300] Validation [8/16] Loss: 0.88435  focal_loss 0.12343  dice_loss 0.76092 
Epoch [29/300] Validation [9/16] Loss: 0.86821  focal_loss 0.16198  dice_loss 0.70623 
Epoch [29/300] Validation [10/16] Loss: 0.72160  focal_loss 0.10665  dice_loss 0.61495 
Epoch [29/300] Validation [11/16] Loss: 0.83942  focal_loss 0.14239  dice_loss 0.69704 
Epoch [29/300] Validation [12/16] Loss: 0.89742  focal_loss 0.10505  dice_loss 0.79237 
Epoch [29/300] Validation [13/16] Loss: 0.82964  focal_loss 0.12020  dice_loss 0.70943 
Epoch [29/300] Validation [14/16] Loss: 0.95301  focal_loss 0.16040  dice_loss 0.79262 
Epoch [29/300] Validation [15/16] Loss: 0.87130  focal_loss 0.16415  dice_loss 0.70716 
Epoch [29/300] Validation [16/16] Loss: 0.64764  focal_loss 0.10213  dice_loss 0.54551 
Epoch [29/300] Validation metric {'Val/mean dice_metric': 0.5009649991989136, 'Val/mean miou_metric': 0.3859996795654297, 'Val/mean f1': 0.5692726969718933, 'Val/mean precision': 0.5532702803611755, 'Val/mean recall': 0.5862283110618591, 'Val/mean hd95_metric': 97.16942596435547}
Cheakpoint...
Epoch [29/300] best acc:tensor([0.5216], device='cuda:0'), Now : mean acc: tensor([0.5010], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5009649991989136, 'Val/mean miou_metric': 0.3859996795654297, 'Val/mean f1': 0.5692726969718933, 'Val/mean precision': 0.5532702803611755, 'Val/mean recall': 0.5862283110618591, 'Val/mean hd95_metric': 97.16942596435547}
Epoch [30/300] Training [1/62] Loss: 0.51866 
Epoch [30/300] Training [2/62] Loss: 0.44849 
Epoch [30/300] Training [3/62] Loss: 0.62827 
Epoch [30/300] Training [4/62] Loss: 0.54417 
Epoch [30/300] Training [5/62] Loss: 0.69356 
Epoch [30/300] Training [6/62] Loss: 0.55650 
Epoch [30/300] Training [7/62] Loss: 0.73713 
Epoch [30/300] Training [8/62] Loss: 0.54555 
Epoch [30/300] Training [9/62] Loss: 0.51959 
Epoch [30/300] Training [10/62] Loss: 0.55590 
Epoch [30/300] Training [11/62] Loss: 0.75621 
Epoch [30/300] Training [12/62] Loss: 0.68946 
Epoch [30/300] Training [13/62] Loss: 0.61957 
Epoch [30/300] Training [14/62] Loss: 0.79058 
Epoch [30/300] Training [15/62] Loss: 0.59003 
Epoch [30/300] Training [16/62] Loss: 0.72512 
Epoch [30/300] Training [17/62] Loss: 0.68875 
Epoch [30/300] Training [18/62] Loss: 0.62291 
Epoch [30/300] Training [19/62] Loss: 0.38740 
Epoch [30/300] Training [20/62] Loss: 0.41599 
Epoch [30/300] Training [21/62] Loss: 0.57171 
Epoch [30/300] Training [22/62] Loss: 0.83329 
Epoch [30/300] Training [23/62] Loss: 0.78234 
Epoch [30/300] Training [24/62] Loss: 0.61471 
Epoch [30/300] Training [25/62] Loss: 0.59135 
Epoch [30/300] Training [26/62] Loss: 0.68779 
Epoch [30/300] Training [27/62] Loss: 0.63857 
Epoch [30/300] Training [28/62] Loss: 0.54919 
Epoch [30/300] Training [29/62] Loss: 0.75857 
Epoch [30/300] Training [30/62] Loss: 0.67959 
Epoch [30/300] Training [31/62] Loss: 0.59030 
Epoch [30/300] Training [32/62] Loss: 0.50372 
Epoch [30/300] Training [33/62] Loss: 0.66738 
Epoch [30/300] Training [34/62] Loss: 0.63955 
Epoch [30/300] Training [35/62] Loss: 0.51766 
Epoch [30/300] Training [36/62] Loss: 0.54623 
Epoch [30/300] Training [37/62] Loss: 0.59333 
Epoch [30/300] Training [38/62] Loss: 0.62060 
Epoch [30/300] Training [39/62] Loss: 0.67904 
Epoch [30/300] Training [40/62] Loss: 0.49813 
Epoch [30/300] Training [41/62] Loss: 0.68543 
Epoch [30/300] Training [42/62] Loss: 0.97609 
Epoch [30/300] Training [43/62] Loss: 0.67566 
Epoch [30/300] Training [44/62] Loss: 0.60605 
Epoch [30/300] Training [45/62] Loss: 0.67628 
Epoch [30/300] Training [46/62] Loss: 0.50340 
Epoch [30/300] Training [47/62] Loss: 0.64504 
Epoch [30/300] Training [48/62] Loss: 0.54430 
Epoch [30/300] Training [49/62] Loss: 0.71987 
Epoch [30/300] Training [50/62] Loss: 0.71468 
Epoch [30/300] Training [51/62] Loss: 0.64624 
Epoch [30/300] Training [52/62] Loss: 0.44197 
Epoch [30/300] Training [53/62] Loss: 0.58213 
Epoch [30/300] Training [54/62] Loss: 0.78916 
Epoch [30/300] Training [55/62] Loss: 0.66049 
Epoch [30/300] Training [56/62] Loss: 0.66820 
Epoch [30/300] Training [57/62] Loss: 0.72629 
Epoch [30/300] Training [58/62] Loss: 0.63589 
Epoch [30/300] Training [59/62] Loss: 0.77309 
Epoch [30/300] Training [60/62] Loss: 0.65554 
Epoch [30/300] Training [61/62] Loss: 0.72672 
Epoch [30/300] Training [62/62] Loss: 0.43534 
Epoch [30/300] Training metric {'Train/mean dice_metric': 0.5395007133483887, 'Train/mean miou_metric': 0.4210764169692993, 'Train/mean f1': 0.6008155941963196, 'Train/mean precision': 0.5875036716461182, 'Train/mean recall': 0.6147448420524597, 'Train/mean hd95_metric': 87.84188079833984}
Epoch [30/300] Validation [1/16] Loss: 0.80013  focal_loss 0.19707  dice_loss 0.60306 
Epoch [30/300] Validation [2/16] Loss: 0.76006  focal_loss 0.11778  dice_loss 0.64229 
Epoch [30/300] Validation [3/16] Loss: 0.71561  focal_loss 0.13252  dice_loss 0.58309 
Epoch [30/300] Validation [4/16] Loss: 0.81564  focal_loss 0.14291  dice_loss 0.67273 
Epoch [30/300] Validation [5/16] Loss: 0.59898  focal_loss 0.04958  dice_loss 0.54940 
Epoch [30/300] Validation [6/16] Loss: 0.56669  focal_loss 0.06266  dice_loss 0.50403 
Epoch [30/300] Validation [7/16] Loss: 0.75554  focal_loss 0.15249  dice_loss 0.60304 
Epoch [30/300] Validation [8/16] Loss: 0.85250  focal_loss 0.11568  dice_loss 0.73682 
Epoch [30/300] Validation [9/16] Loss: 0.70929  focal_loss 0.11527  dice_loss 0.59402 
Epoch [30/300] Validation [10/16] Loss: 0.90440  focal_loss 0.15254  dice_loss 0.75185 
Epoch [30/300] Validation [11/16] Loss: 0.64288  focal_loss 0.09680  dice_loss 0.54608 
Epoch [30/300] Validation [12/16] Loss: 0.72982  focal_loss 0.05615  dice_loss 0.67367 
Epoch [30/300] Validation [13/16] Loss: 0.76883  focal_loss 0.10370  dice_loss 0.66514 
Epoch [30/300] Validation [14/16] Loss: 0.91844  focal_loss 0.14445  dice_loss 0.77399 
Epoch [30/300] Validation [15/16] Loss: 0.59195  focal_loss 0.09738  dice_loss 0.49457 
Epoch [30/300] Validation [16/16] Loss: 0.38351  focal_loss 0.04848  dice_loss 0.33503 
Epoch [30/300] Validation metric {'Val/mean dice_metric': 0.5133371949195862, 'Val/mean miou_metric': 0.39964306354522705, 'Val/mean f1': 0.5866928100585938, 'Val/mean precision': 0.5969193577766418, 'Val/mean recall': 0.5768106579780579, 'Val/mean hd95_metric': 88.42066955566406}
Cheakpoint...
Epoch [30/300] best acc:tensor([0.5216], device='cuda:0'), Now : mean acc: tensor([0.5133], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5133371949195862, 'Val/mean miou_metric': 0.39964306354522705, 'Val/mean f1': 0.5866928100585938, 'Val/mean precision': 0.5969193577766418, 'Val/mean recall': 0.5768106579780579, 'Val/mean hd95_metric': 88.42066955566406}
Epoch [31/300] Training [1/62] Loss: 0.55862 
Epoch [31/300] Training [2/62] Loss: 0.54966 
Epoch [31/300] Training [3/62] Loss: 0.79402 
Epoch [31/300] Training [4/62] Loss: 0.59829 
Epoch [31/300] Training [5/62] Loss: 0.61700 
Epoch [31/300] Training [6/62] Loss: 0.71128 
Epoch [31/300] Training [7/62] Loss: 0.84911 
Epoch [31/300] Training [8/62] Loss: 0.72455 
Epoch [31/300] Training [9/62] Loss: 0.63498 
Epoch [31/300] Training [10/62] Loss: 0.77727 
Epoch [31/300] Training [11/62] Loss: 0.64555 
Epoch [31/300] Training [12/62] Loss: 0.75706 
Epoch [31/300] Training [13/62] Loss: 0.69595 
Epoch [31/300] Training [14/62] Loss: 0.60688 
Epoch [31/300] Training [15/62] Loss: 0.63441 
Epoch [31/300] Training [16/62] Loss: 0.59389 
Epoch [31/300] Training [17/62] Loss: 0.69642 
Epoch [31/300] Training [18/62] Loss: 0.61732 
Epoch [31/300] Training [19/62] Loss: 0.71970 
Epoch [31/300] Training [20/62] Loss: 0.42330 
Epoch [31/300] Training [21/62] Loss: 0.55052 
Epoch [31/300] Training [22/62] Loss: 0.52253 
Epoch [31/300] Training [23/62] Loss: 0.72910 
Epoch [31/300] Training [24/62] Loss: 0.79894 
Epoch [31/300] Training [25/62] Loss: 0.63838 
Epoch [31/300] Training [26/62] Loss: 0.66476 
Epoch [31/300] Training [27/62] Loss: 0.36224 
Epoch [31/300] Training [28/62] Loss: 0.66336 
Epoch [31/300] Training [29/62] Loss: 0.61723 
Epoch [31/300] Training [30/62] Loss: 0.61813 
Epoch [31/300] Training [31/62] Loss: 0.52062 
Epoch [31/300] Training [32/62] Loss: 0.59913 
Epoch [31/300] Training [33/62] Loss: 0.74270 
Epoch [31/300] Training [34/62] Loss: 0.74494 
Epoch [31/300] Training [35/62] Loss: 0.67278 
Epoch [31/300] Training [36/62] Loss: 0.51772 
Epoch [31/300] Training [37/62] Loss: 0.54870 
Epoch [31/300] Training [38/62] Loss: 0.45573 
Epoch [31/300] Training [39/62] Loss: 0.70960 
Epoch [31/300] Training [40/62] Loss: 0.48271 
Epoch [31/300] Training [41/62] Loss: 0.64117 
Epoch [31/300] Training [42/62] Loss: 0.59694 
Epoch [31/300] Training [43/62] Loss: 0.46444 
Epoch [31/300] Training [44/62] Loss: 0.79835 
Epoch [31/300] Training [45/62] Loss: 0.43452 
Epoch [31/300] Training [46/62] Loss: 0.68392 
Epoch [31/300] Training [47/62] Loss: 0.72356 
Epoch [31/300] Training [48/62] Loss: 0.44280 
Epoch [31/300] Training [49/62] Loss: 0.44144 
Epoch [31/300] Training [50/62] Loss: 0.69012 
Epoch [31/300] Training [51/62] Loss: 0.50732 
Epoch [31/300] Training [52/62] Loss: 0.51597 
Epoch [31/300] Training [53/62] Loss: 0.74085 
Epoch [31/300] Training [54/62] Loss: 0.55082 
Epoch [31/300] Training [55/62] Loss: 0.46121 
Epoch [31/300] Training [56/62] Loss: 0.63212 
Epoch [31/300] Training [57/62] Loss: 0.50168 
Epoch [31/300] Training [58/62] Loss: 0.51727 
Epoch [31/300] Training [59/62] Loss: 0.48675 
Epoch [31/300] Training [60/62] Loss: 0.65611 
Epoch [31/300] Training [61/62] Loss: 0.61391 
Epoch [31/300] Training [62/62] Loss: 0.37821 
Epoch [31/300] Training metric {'Train/mean dice_metric': 0.5611606240272522, 'Train/mean miou_metric': 0.4405971169471741, 'Train/mean f1': 0.6241893768310547, 'Train/mean precision': 0.6127229928970337, 'Train/mean recall': 0.6360930800437927, 'Train/mean hd95_metric': 88.28933715820312}
Epoch [31/300] Validation [1/16] Loss: 0.68840  focal_loss 0.17374  dice_loss 0.51467 
Epoch [31/300] Validation [2/16] Loss: 0.72618  focal_loss 0.10736  dice_loss 0.61882 
Epoch [31/300] Validation [3/16] Loss: 0.67597  focal_loss 0.09263  dice_loss 0.58334 
Epoch [31/300] Validation [4/16] Loss: 0.59791  focal_loss 0.10767  dice_loss 0.49024 
Epoch [31/300] Validation [5/16] Loss: 0.53571  focal_loss 0.03958  dice_loss 0.49613 
Epoch [31/300] Validation [6/16] Loss: 0.52720  focal_loss 0.06430  dice_loss 0.46291 
Epoch [31/300] Validation [7/16] Loss: 0.49837  focal_loss 0.06002  dice_loss 0.43835 
Epoch [31/300] Validation [8/16] Loss: 0.77261  focal_loss 0.13507  dice_loss 0.63754 
Epoch [31/300] Validation [9/16] Loss: 0.58403  focal_loss 0.07813  dice_loss 0.50590 
Epoch [31/300] Validation [10/16] Loss: 0.69356  focal_loss 0.10612  dice_loss 0.58744 
Epoch [31/300] Validation [11/16] Loss: 0.54694  focal_loss 0.07742  dice_loss 0.46952 
Epoch [31/300] Validation [12/16] Loss: 0.66625  focal_loss 0.05690  dice_loss 0.60935 
Epoch [31/300] Validation [13/16] Loss: 0.55287  focal_loss 0.07883  dice_loss 0.47404 
Epoch [31/300] Validation [14/16] Loss: 0.83104  focal_loss 0.11703  dice_loss 0.71401 
Epoch [31/300] Validation [15/16] Loss: 0.53203  focal_loss 0.07118  dice_loss 0.46085 
Epoch [31/300] Validation [16/16] Loss: 0.39580  focal_loss 0.04319  dice_loss 0.35261 
Epoch [31/300] Validation metric {'Val/mean dice_metric': 0.5628249049186707, 'Val/mean miou_metric': 0.4411487579345703, 'Val/mean f1': 0.6177360415458679, 'Val/mean precision': 0.5985260605812073, 'Val/mean recall': 0.6382200717926025, 'Val/mean hd95_metric': 89.57117462158203}
Cheakpoint...
Epoch [31/300] best acc:tensor([0.5628], device='cuda:0'), Now : mean acc: tensor([0.5628], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5628249049186707, 'Val/mean miou_metric': 0.4411487579345703, 'Val/mean f1': 0.6177360415458679, 'Val/mean precision': 0.5985260605812073, 'Val/mean recall': 0.6382200717926025, 'Val/mean hd95_metric': 89.57117462158203}
Epoch [32/300] Training [1/62] Loss: 0.90481 
Epoch [32/300] Training [2/62] Loss: 0.47414 
Epoch [32/300] Training [3/62] Loss: 0.60347 
Epoch [32/300] Training [4/62] Loss: 0.59962 
Epoch [32/300] Training [5/62] Loss: 0.57628 
Epoch [32/300] Training [6/62] Loss: 0.58667 
Epoch [32/300] Training [7/62] Loss: 0.68663 
Epoch [32/300] Training [8/62] Loss: 0.61429 
Epoch [32/300] Training [9/62] Loss: 0.51052 
Epoch [32/300] Training [10/62] Loss: 0.50987 
Epoch [32/300] Training [11/62] Loss: 0.59327 
Epoch [32/300] Training [12/62] Loss: 0.54663 
Epoch [32/300] Training [13/62] Loss: 0.58235 
Epoch [32/300] Training [14/62] Loss: 0.55010 
Epoch [32/300] Training [15/62] Loss: 0.69473 
Epoch [32/300] Training [16/62] Loss: 0.43031 
Epoch [32/300] Training [17/62] Loss: 0.59073 
Epoch [32/300] Training [18/62] Loss: 0.54622 
Epoch [32/300] Training [19/62] Loss: 0.74958 
Epoch [32/300] Training [20/62] Loss: 0.58767 
Epoch [32/300] Training [21/62] Loss: 0.67254 
Epoch [32/300] Training [22/62] Loss: 0.54249 
Epoch [32/300] Training [23/62] Loss: 0.74183 
Epoch [32/300] Training [24/62] Loss: 0.48887 
Epoch [32/300] Training [25/62] Loss: 0.50629 
Epoch [32/300] Training [26/62] Loss: 0.51857 
Epoch [32/300] Training [27/62] Loss: 0.51693 
Epoch [32/300] Training [28/62] Loss: 0.41926 
Epoch [32/300] Training [29/62] Loss: 0.67004 
Epoch [32/300] Training [30/62] Loss: 0.50770 
Epoch [32/300] Training [31/62] Loss: 0.71422 
Epoch [32/300] Training [32/62] Loss: 0.56501 
Epoch [32/300] Training [33/62] Loss: 0.91177 
Epoch [32/300] Training [34/62] Loss: 0.64143 
Epoch [32/300] Training [35/62] Loss: 0.66682 
Epoch [32/300] Training [36/62] Loss: 0.52073 
Epoch [32/300] Training [37/62] Loss: 0.60640 
Epoch [32/300] Training [38/62] Loss: 0.41400 
Epoch [32/300] Training [39/62] Loss: 0.71076 
Epoch [32/300] Training [40/62] Loss: 0.44475 
Epoch [32/300] Training [41/62] Loss: 0.65465 
Epoch [32/300] Training [42/62] Loss: 0.50375 
Epoch [32/300] Training [43/62] Loss: 0.56477 
Epoch [32/300] Training [44/62] Loss: 0.62818 
Epoch [32/300] Training [45/62] Loss: 0.57601 
Epoch [32/300] Training [46/62] Loss: 0.49131 
Epoch [32/300] Training [47/62] Loss: 0.44807 
Epoch [32/300] Training [48/62] Loss: 0.60723 
Epoch [32/300] Training [49/62] Loss: 0.30515 
Epoch [32/300] Training [50/62] Loss: 0.61780 
Epoch [32/300] Training [51/62] Loss: 0.54369 
Epoch [32/300] Training [52/62] Loss: 0.64682 
Epoch [32/300] Training [53/62] Loss: 0.56658 
Epoch [32/300] Training [54/62] Loss: 0.51840 
Epoch [32/300] Training [55/62] Loss: 0.72074 
Epoch [32/300] Training [56/62] Loss: 0.55925 
Epoch [32/300] Training [57/62] Loss: 0.83623 
Epoch [32/300] Training [58/62] Loss: 0.87366 
Epoch [32/300] Training [59/62] Loss: 0.55344 
Epoch [32/300] Training [60/62] Loss: 0.57737 
Epoch [32/300] Training [61/62] Loss: 0.48341 
Epoch [32/300] Training [62/62] Loss: 0.50709 
Epoch [32/300] Training metric {'Train/mean dice_metric': 0.5824173092842102, 'Train/mean miou_metric': 0.4629282057285309, 'Train/mean f1': 0.6373150944709778, 'Train/mean precision': 0.6256797909736633, 'Train/mean recall': 0.6493913531303406, 'Train/mean hd95_metric': 82.32644653320312}
Epoch [32/300] Validation [1/16] Loss: 0.66310  focal_loss 0.24366  dice_loss 0.41944 
Epoch [32/300] Validation [2/16] Loss: 0.68276  focal_loss 0.11246  dice_loss 0.57029 
Epoch [32/300] Validation [3/16] Loss: 0.64717  focal_loss 0.11085  dice_loss 0.53633 
Epoch [32/300] Validation [4/16] Loss: 0.50558  focal_loss 0.07908  dice_loss 0.42650 
Epoch [32/300] Validation [5/16] Loss: 0.50250  focal_loss 0.04822  dice_loss 0.45428 
Epoch [32/300] Validation [6/16] Loss: 0.53877  focal_loss 0.07972  dice_loss 0.45905 
Epoch [32/300] Validation [7/16] Loss: 0.51759  focal_loss 0.08315  dice_loss 0.43443 
Epoch [32/300] Validation [8/16] Loss: 0.69686  focal_loss 0.12949  dice_loss 0.56737 
Epoch [32/300] Validation [9/16] Loss: 0.56816  focal_loss 0.10002  dice_loss 0.46815 
Epoch [32/300] Validation [10/16] Loss: 0.61532  focal_loss 0.11218  dice_loss 0.50314 
Epoch [32/300] Validation [11/16] Loss: 0.42876  focal_loss 0.03889  dice_loss 0.38987 
Epoch [32/300] Validation [12/16] Loss: 0.61536  focal_loss 0.08007  dice_loss 0.53529 
Epoch [32/300] Validation [13/16] Loss: 0.43108  focal_loss 0.06149  dice_loss 0.36959 
Epoch [32/300] Validation [14/16] Loss: 0.78135  focal_loss 0.15176  dice_loss 0.62959 
Epoch [32/300] Validation [15/16] Loss: 0.49985  focal_loss 0.09729  dice_loss 0.40256 
Epoch [32/300] Validation [16/16] Loss: 0.40029  focal_loss 0.08313  dice_loss 0.31716 
Epoch [32/300] Validation metric {'Val/mean dice_metric': 0.5859035849571228, 'Val/mean miou_metric': 0.46524757146835327, 'Val/mean f1': 0.6330758929252625, 'Val/mean precision': 0.6199187636375427, 'Val/mean recall': 0.646803617477417, 'Val/mean hd95_metric': 83.71942901611328}
Cheakpoint...
Epoch [32/300] best acc:tensor([0.5859], device='cuda:0'), Now : mean acc: tensor([0.5859], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5859035849571228, 'Val/mean miou_metric': 0.46524757146835327, 'Val/mean f1': 0.6330758929252625, 'Val/mean precision': 0.6199187636375427, 'Val/mean recall': 0.646803617477417, 'Val/mean hd95_metric': 83.71942901611328}
Epoch [33/300] Training [1/62] Loss: 0.66527 
Epoch [33/300] Training [2/62] Loss: 0.52820 
Epoch [33/300] Training [3/62] Loss: 0.67114 
Epoch [33/300] Training [4/62] Loss: 0.65679 
Epoch [33/300] Training [5/62] Loss: 0.62234 
Epoch [33/300] Training [6/62] Loss: 0.58479 
Epoch [33/300] Training [7/62] Loss: 0.54435 
Epoch [33/300] Training [8/62] Loss: 0.46661 
Epoch [33/300] Training [9/62] Loss: 0.60849 
Epoch [33/300] Training [10/62] Loss: 0.45434 
Epoch [33/300] Training [11/62] Loss: 0.56540 
Epoch [33/300] Training [12/62] Loss: 0.74679 
Epoch [33/300] Training [13/62] Loss: 0.54533 
Epoch [33/300] Training [14/62] Loss: 0.53037 
Epoch [33/300] Training [15/62] Loss: 0.57883 
Epoch [33/300] Training [16/62] Loss: 0.58738 
Epoch [33/300] Training [17/62] Loss: 0.60729 
Epoch [33/300] Training [18/62] Loss: 0.50773 
Epoch [33/300] Training [19/62] Loss: 0.64948 
Epoch [33/300] Training [20/62] Loss: 0.63363 
Epoch [33/300] Training [21/62] Loss: 0.56887 
Epoch [33/300] Training [22/62] Loss: 0.54211 
Epoch [33/300] Training [23/62] Loss: 0.43509 
Epoch [33/300] Training [24/62] Loss: 0.43372 
Epoch [33/300] Training [25/62] Loss: 0.67165 
Epoch [33/300] Training [26/62] Loss: 0.63315 
Epoch [33/300] Training [27/62] Loss: 0.63879 
Epoch [33/300] Training [28/62] Loss: 0.53243 
Epoch [33/300] Training [29/62] Loss: 0.44920 
Epoch [33/300] Training [30/62] Loss: 0.69628 
Epoch [33/300] Training [31/62] Loss: 0.61240 
Epoch [33/300] Training [32/62] Loss: 0.59087 
Epoch [33/300] Training [33/62] Loss: 0.50939 
Epoch [33/300] Training [34/62] Loss: 0.62301 
Epoch [33/300] Training [35/62] Loss: 0.49438 
Epoch [33/300] Training [36/62] Loss: 0.63402 
Epoch [33/300] Training [37/62] Loss: 0.38228 
Epoch [33/300] Training [38/62] Loss: 0.60275 
Epoch [33/300] Training [39/62] Loss: 0.61403 
Epoch [33/300] Training [40/62] Loss: 0.51928 
Epoch [33/300] Training [41/62] Loss: 0.50434 
Epoch [33/300] Training [42/62] Loss: 0.36636 
Epoch [33/300] Training [43/62] Loss: 0.77975 
Epoch [33/300] Training [44/62] Loss: 0.93115 
Epoch [33/300] Training [45/62] Loss: 0.65889 
Epoch [33/300] Training [46/62] Loss: 0.61153 
Epoch [33/300] Training [47/62] Loss: 0.40456 
Epoch [33/300] Training [48/62] Loss: 0.56351 
Epoch [33/300] Training [49/62] Loss: 0.66809 
Epoch [33/300] Training [50/62] Loss: 0.54233 
Epoch [33/300] Training [51/62] Loss: 0.57246 
Epoch [33/300] Training [52/62] Loss: 0.81948 
Epoch [33/300] Training [53/62] Loss: 0.39204 
Epoch [33/300] Training [54/62] Loss: 0.50800 
Epoch [33/300] Training [55/62] Loss: 0.70840 
Epoch [33/300] Training [56/62] Loss: 0.55369 
Epoch [33/300] Training [57/62] Loss: 0.48192 
Epoch [33/300] Training [58/62] Loss: 0.55095 
Epoch [33/300] Training [59/62] Loss: 0.59518 
Epoch [33/300] Training [60/62] Loss: 0.77647 
Epoch [33/300] Training [61/62] Loss: 0.46158 
Epoch [33/300] Training [62/62] Loss: 0.76290 
Epoch [33/300] Training metric {'Train/mean dice_metric': 0.5845425724983215, 'Train/mean miou_metric': 0.46481773257255554, 'Train/mean f1': 0.6472578644752502, 'Train/mean precision': 0.6276959180831909, 'Train/mean recall': 0.6680782437324524, 'Train/mean hd95_metric': 87.92227935791016}
Epoch [33/300] Validation [1/16] Loss: 0.89386  focal_loss 0.29693  dice_loss 0.59694 
Epoch [33/300] Validation [2/16] Loss: 1.19636  focal_loss 0.42492  dice_loss 0.77144 
Epoch [33/300] Validation [3/16] Loss: 1.09465  focal_loss 0.41358  dice_loss 0.68107 
Epoch [33/300] Validation [4/16] Loss: 1.04257  focal_loss 0.35962  dice_loss 0.68294 
Epoch [33/300] Validation [5/16] Loss: 0.94143  focal_loss 0.27134  dice_loss 0.67010 
Epoch [33/300] Validation [6/16] Loss: 1.09123  focal_loss 0.36598  dice_loss 0.72525 
Epoch [33/300] Validation [7/16] Loss: 1.07617  focal_loss 0.42534  dice_loss 0.65083 
Epoch [33/300] Validation [8/16] Loss: 1.16233  focal_loss 0.36587  dice_loss 0.79645 
Epoch [33/300] Validation [9/16] Loss: 1.00512  focal_loss 0.36772  dice_loss 0.63740 
Epoch [33/300] Validation [10/16] Loss: 1.08289  focal_loss 0.38388  dice_loss 0.69900 
Epoch [33/300] Validation [11/16] Loss: 1.07989  focal_loss 0.39384  dice_loss 0.68605 
Epoch [33/300] Validation [12/16] Loss: 1.20754  focal_loss 0.41177  dice_loss 0.79577 
Epoch [33/300] Validation [13/16] Loss: 1.02979  focal_loss 0.32467  dice_loss 0.70513 
Epoch [33/300] Validation [14/16] Loss: 1.41077  focal_loss 0.55500  dice_loss 0.85577 
Epoch [33/300] Validation [15/16] Loss: 0.82605  focal_loss 0.26783  dice_loss 0.55821 
Epoch [33/300] Validation [16/16] Loss: 1.07634  focal_loss 0.43790  dice_loss 0.63844 
Epoch [33/300] Validation metric {'Val/mean dice_metric': 0.5312116742134094, 'Val/mean miou_metric': 0.41383469104766846, 'Val/mean f1': 0.5423271656036377, 'Val/mean precision': 0.4548780024051666, 'Val/mean recall': 0.6714026927947998, 'Val/mean hd95_metric': 103.23739624023438}
Cheakpoint...
Epoch [33/300] best acc:tensor([0.5859], device='cuda:0'), Now : mean acc: tensor([0.5312], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5312116742134094, 'Val/mean miou_metric': 0.41383469104766846, 'Val/mean f1': 0.5423271656036377, 'Val/mean precision': 0.4548780024051666, 'Val/mean recall': 0.6714026927947998, 'Val/mean hd95_metric': 103.23739624023438}
Epoch [34/300] Training [1/62] Loss: 0.41762 
Epoch [34/300] Training [2/62] Loss: 0.96994 
Epoch [34/300] Training [3/62] Loss: 0.39198 
Epoch [34/300] Training [4/62] Loss: 0.52528 
Epoch [34/300] Training [5/62] Loss: 0.62487 
Epoch [34/300] Training [6/62] Loss: 0.42449 
Epoch [34/300] Training [7/62] Loss: 0.53258 
Epoch [34/300] Training [8/62] Loss: 0.34515 
Epoch [34/300] Training [9/62] Loss: 0.67188 
Epoch [34/300] Training [10/62] Loss: 0.33050 
Epoch [34/300] Training [11/62] Loss: 0.43120 
Epoch [34/300] Training [12/62] Loss: 0.46074 
Epoch [34/300] Training [13/62] Loss: 0.58184 
Epoch [34/300] Training [14/62] Loss: 0.74977 
Epoch [34/300] Training [15/62] Loss: 0.52858 
Epoch [34/300] Training [16/62] Loss: 0.84463 
Epoch [34/300] Training [17/62] Loss: 0.68908 
Epoch [34/300] Training [18/62] Loss: 0.60081 
Epoch [34/300] Training [19/62] Loss: 0.54403 
Epoch [34/300] Training [20/62] Loss: 0.49384 
Epoch [34/300] Training [21/62] Loss: 0.47827 
Epoch [34/300] Training [22/62] Loss: 0.74076 
Epoch [34/300] Training [23/62] Loss: 0.49421 
Epoch [34/300] Training [24/62] Loss: 0.44891 
Epoch [34/300] Training [25/62] Loss: 0.63186 
Epoch [34/300] Training [26/62] Loss: 0.40993 
Epoch [34/300] Training [27/62] Loss: 0.53039 
Epoch [34/300] Training [28/62] Loss: 0.41813 
Epoch [34/300] Training [29/62] Loss: 0.74050 
Epoch [34/300] Training [30/62] Loss: 0.76255 
Epoch [34/300] Training [31/62] Loss: 0.71720 
Epoch [34/300] Training [32/62] Loss: 0.39894 
Epoch [34/300] Training [33/62] Loss: 0.64645 
Epoch [34/300] Training [34/62] Loss: 0.60788 
Epoch [34/300] Training [35/62] Loss: 0.61295 
Epoch [34/300] Training [36/62] Loss: 0.57392 
Epoch [34/300] Training [37/62] Loss: 0.33945 
Epoch [34/300] Training [38/62] Loss: 0.82426 
Epoch [34/300] Training [39/62] Loss: 0.60794 
Epoch [34/300] Training [40/62] Loss: 0.79553 
Epoch [34/300] Training [41/62] Loss: 0.42608 
Epoch [34/300] Training [42/62] Loss: 0.62210 
Epoch [34/300] Training [43/62] Loss: 0.81283 
Epoch [34/300] Training [44/62] Loss: 0.61106 
Epoch [34/300] Training [45/62] Loss: 0.48267 
Epoch [34/300] Training [46/62] Loss: 0.54965 
Epoch [34/300] Training [47/62] Loss: 0.46401 
Epoch [34/300] Training [48/62] Loss: 0.58602 
Epoch [34/300] Training [49/62] Loss: 0.86281 
Epoch [34/300] Training [50/62] Loss: 0.54775 
Epoch [34/300] Training [51/62] Loss: 0.72004 
Epoch [34/300] Training [52/62] Loss: 0.46016 
Epoch [34/300] Training [53/62] Loss: 0.74527 
Epoch [34/300] Training [54/62] Loss: 0.47793 
Epoch [34/300] Training [55/62] Loss: 0.38320 
Epoch [34/300] Training [56/62] Loss: 0.79341 
Epoch [34/300] Training [57/62] Loss: 0.54893 
Epoch [34/300] Training [58/62] Loss: 0.48882 
Epoch [34/300] Training [59/62] Loss: 0.67570 
Epoch [34/300] Training [60/62] Loss: 0.37920 
Epoch [34/300] Training [61/62] Loss: 0.73500 
Epoch [34/300] Training [62/62] Loss: 0.24230 
Epoch [34/300] Training metric {'Train/mean dice_metric': 0.5987483859062195, 'Train/mean miou_metric': 0.4799385368824005, 'Train/mean f1': 0.6434383392333984, 'Train/mean precision': 0.645068883895874, 'Train/mean recall': 0.6418159604072571, 'Train/mean hd95_metric': 79.06446075439453}
Epoch [34/300] Validation [1/16] Loss: 0.69251  focal_loss 0.17728  dice_loss 0.51523 
Epoch [34/300] Validation [2/16] Loss: 0.88090  focal_loss 0.22653  dice_loss 0.65437 
Epoch [34/300] Validation [3/16] Loss: 0.78283  focal_loss 0.18608  dice_loss 0.59675 
Epoch [34/300] Validation [4/16] Loss: 0.71657  focal_loss 0.15904  dice_loss 0.55753 
Epoch [34/300] Validation [5/16] Loss: 0.64497  focal_loss 0.10072  dice_loss 0.54425 
Epoch [34/300] Validation [6/16] Loss: 0.63635  focal_loss 0.12803  dice_loss 0.50832 
Epoch [34/300] Validation [7/16] Loss: 0.69792  focal_loss 0.20830  dice_loss 0.48962 
Epoch [34/300] Validation [8/16] Loss: 0.84048  focal_loss 0.18019  dice_loss 0.66029 
Epoch [34/300] Validation [9/16] Loss: 0.76720  focal_loss 0.19687  dice_loss 0.57033 
Epoch [34/300] Validation [10/16] Loss: 0.80839  focal_loss 0.21283  dice_loss 0.59556 
Epoch [34/300] Validation [11/16] Loss: 0.78308  focal_loss 0.21919  dice_loss 0.56389 
Epoch [34/300] Validation [12/16] Loss: 0.79077  focal_loss 0.13077  dice_loss 0.66000 
Epoch [34/300] Validation [13/16] Loss: 0.59363  focal_loss 0.09712  dice_loss 0.49651 
Epoch [34/300] Validation [14/16] Loss: 0.84888  focal_loss 0.15231  dice_loss 0.69657 
Epoch [34/300] Validation [15/16] Loss: 0.64144  focal_loss 0.14603  dice_loss 0.49542 
Epoch [34/300] Validation [16/16] Loss: 0.50421  focal_loss 0.11000  dice_loss 0.39422 
Epoch [34/300] Validation metric {'Val/mean dice_metric': 0.5740073919296265, 'Val/mean miou_metric': 0.4527466297149658, 'Val/mean f1': 0.605359673500061, 'Val/mean precision': 0.554063618183136, 'Val/mean recall': 0.6671229600906372, 'Val/mean hd95_metric': 88.46929168701172}
Cheakpoint...
Epoch [34/300] best acc:tensor([0.5859], device='cuda:0'), Now : mean acc: tensor([0.5740], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5740073919296265, 'Val/mean miou_metric': 0.4527466297149658, 'Val/mean f1': 0.605359673500061, 'Val/mean precision': 0.554063618183136, 'Val/mean recall': 0.6671229600906372, 'Val/mean hd95_metric': 88.46929168701172}
Epoch [35/300] Training [1/62] Loss: 0.59185 
Epoch [35/300] Training [2/62] Loss: 0.57442 
Epoch [35/300] Training [3/62] Loss: 0.38189 
Epoch [35/300] Training [4/62] Loss: 0.70528 
Epoch [35/300] Training [5/62] Loss: 0.49272 
Epoch [35/300] Training [6/62] Loss: 0.67056 
Epoch [35/300] Training [7/62] Loss: 0.33251 
Epoch [35/300] Training [8/62] Loss: 0.49194 
Epoch [35/300] Training [9/62] Loss: 0.60042 
Epoch [35/300] Training [10/62] Loss: 0.57560 
Epoch [35/300] Training [11/62] Loss: 0.40567 
Epoch [35/300] Training [12/62] Loss: 0.75580 
Epoch [35/300] Training [13/62] Loss: 0.40880 
Epoch [35/300] Training [14/62] Loss: 0.48566 
Epoch [35/300] Training [15/62] Loss: 0.55692 
Epoch [35/300] Training [16/62] Loss: 0.68980 
Epoch [35/300] Training [17/62] Loss: 0.67869 
Epoch [35/300] Training [18/62] Loss: 0.49367 
Epoch [35/300] Training [19/62] Loss: 0.48294 
Epoch [35/300] Training [20/62] Loss: 0.60598 
Epoch [35/300] Training [21/62] Loss: 0.43798 
Epoch [35/300] Training [22/62] Loss: 0.49972 
Epoch [35/300] Training [23/62] Loss: 0.51346 
Epoch [35/300] Training [24/62] Loss: 0.62152 
Epoch [35/300] Training [25/62] Loss: 0.60666 
Epoch [35/300] Training [26/62] Loss: 0.46744 
Epoch [35/300] Training [27/62] Loss: 0.78660 
Epoch [35/300] Training [28/62] Loss: 0.40457 
Epoch [35/300] Training [29/62] Loss: 0.59589 
Epoch [35/300] Training [30/62] Loss: 0.48312 
Epoch [35/300] Training [31/62] Loss: 0.50226 
Epoch [35/300] Training [32/62] Loss: 0.41812 
Epoch [35/300] Training [33/62] Loss: 0.60182 
Epoch [35/300] Training [34/62] Loss: 0.51947 
Epoch [35/300] Training [35/62] Loss: 0.38637 
Epoch [35/300] Training [36/62] Loss: 0.40363 
Epoch [35/300] Training [37/62] Loss: 0.54223 
Epoch [35/300] Training [38/62] Loss: 0.63841 
Epoch [35/300] Training [39/62] Loss: 0.52839 
Epoch [35/300] Training [40/62] Loss: 0.47501 
Epoch [35/300] Training [41/62] Loss: 0.44908 
Epoch [35/300] Training [42/62] Loss: 0.64454 
Epoch [35/300] Training [43/62] Loss: 0.68766 
Epoch [35/300] Training [44/62] Loss: 0.52990 
Epoch [35/300] Training [45/62] Loss: 0.57475 
Epoch [35/300] Training [46/62] Loss: 0.63189 
Epoch [35/300] Training [47/62] Loss: 0.53339 
Epoch [35/300] Training [48/62] Loss: 0.60039 
Epoch [35/300] Training [49/62] Loss: 0.50805 
Epoch [35/300] Training [50/62] Loss: 0.66434 
Epoch [35/300] Training [51/62] Loss: 0.43085 
Epoch [35/300] Training [52/62] Loss: 0.61752 
Epoch [35/300] Training [53/62] Loss: 0.60741 
Epoch [35/300] Training [54/62] Loss: 0.62518 
Epoch [35/300] Training [55/62] Loss: 0.67527 
Epoch [35/300] Training [56/62] Loss: 0.48702 
Epoch [35/300] Training [57/62] Loss: 0.50019 
Epoch [35/300] Training [58/62] Loss: 0.74932 
Epoch [35/300] Training [59/62] Loss: 0.53880 
Epoch [35/300] Training [60/62] Loss: 0.68903 
Epoch [35/300] Training [61/62] Loss: 0.45496 
Epoch [35/300] Training [62/62] Loss: 0.19483 
Epoch [35/300] Training metric {'Train/mean dice_metric': 0.6095285415649414, 'Train/mean miou_metric': 0.48886415362358093, 'Train/mean f1': 0.6609777808189392, 'Train/mean precision': 0.6437497138977051, 'Train/mean recall': 0.6791532635688782, 'Train/mean hd95_metric': 82.84432220458984}
Epoch [35/300] Validation [1/16] Loss: 0.65721  focal_loss 0.20041  dice_loss 0.45680 
Epoch [35/300] Validation [2/16] Loss: 0.70172  focal_loss 0.12043  dice_loss 0.58129 
Epoch [35/300] Validation [3/16] Loss: 0.60184  focal_loss 0.11704  dice_loss 0.48480 
Epoch [35/300] Validation [4/16] Loss: 0.53186  focal_loss 0.11400  dice_loss 0.41786 
Epoch [35/300] Validation [5/16] Loss: 0.42632  focal_loss 0.03537  dice_loss 0.39095 
Epoch [35/300] Validation [6/16] Loss: 0.42594  focal_loss 0.06315  dice_loss 0.36279 
Epoch [35/300] Validation [7/16] Loss: 0.45048  focal_loss 0.06543  dice_loss 0.38505 
Epoch [35/300] Validation [8/16] Loss: 0.71155  focal_loss 0.11848  dice_loss 0.59308 
Epoch [35/300] Validation [9/16] Loss: 0.55734  focal_loss 0.11023  dice_loss 0.44711 
Epoch [35/300] Validation [10/16] Loss: 0.60495  focal_loss 0.10998  dice_loss 0.49497 
Epoch [35/300] Validation [11/16] Loss: 0.60070  focal_loss 0.10010  dice_loss 0.50060 
Epoch [35/300] Validation [12/16] Loss: 0.56778  focal_loss 0.05445  dice_loss 0.51333 
Epoch [35/300] Validation [13/16] Loss: 0.52189  focal_loss 0.08787  dice_loss 0.43402 
Epoch [35/300] Validation [14/16] Loss: 0.69439  focal_loss 0.11214  dice_loss 0.58225 
Epoch [35/300] Validation [15/16] Loss: 0.46200  focal_loss 0.08519  dice_loss 0.37681 
Epoch [35/300] Validation [16/16] Loss: 0.33105  focal_loss 0.07464  dice_loss 0.25641 
Epoch [35/300] Validation metric {'Val/mean dice_metric': 0.6071049571037292, 'Val/mean miou_metric': 0.4868029057979584, 'Val/mean f1': 0.6539703607559204, 'Val/mean precision': 0.6376249194145203, 'Val/mean recall': 0.6711758375167847, 'Val/mean hd95_metric': 83.22484588623047}
Cheakpoint...
Epoch [35/300] best acc:tensor([0.6071], device='cuda:0'), Now : mean acc: tensor([0.6071], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6071049571037292, 'Val/mean miou_metric': 0.4868029057979584, 'Val/mean f1': 0.6539703607559204, 'Val/mean precision': 0.6376249194145203, 'Val/mean recall': 0.6711758375167847, 'Val/mean hd95_metric': 83.22484588623047}
Epoch [36/300] Training [1/62] Loss: 0.58273 
Epoch [36/300] Training [2/62] Loss: 0.53684 
Epoch [36/300] Training [3/62] Loss: 0.40285 
Epoch [36/300] Training [4/62] Loss: 0.63647 
Epoch [36/300] Training [5/62] Loss: 0.51053 
Epoch [36/300] Training [6/62] Loss: 0.64808 
Epoch [36/300] Training [7/62] Loss: 0.63757 
Epoch [36/300] Training [8/62] Loss: 0.67812 
Epoch [36/300] Training [9/62] Loss: 0.45879 
Epoch [36/300] Training [10/62] Loss: 0.50295 
Epoch [36/300] Training [11/62] Loss: 0.55855 
Epoch [36/300] Training [12/62] Loss: 0.61421 
Epoch [36/300] Training [13/62] Loss: 0.81135 
Epoch [36/300] Training [14/62] Loss: 0.47231 
Epoch [36/300] Training [15/62] Loss: 0.52333 
Epoch [36/300] Training [16/62] Loss: 0.45590 
Epoch [36/300] Training [17/62] Loss: 0.75913 
Epoch [36/300] Training [18/62] Loss: 0.78158 
Epoch [36/300] Training [19/62] Loss: 0.47273 
Epoch [36/300] Training [20/62] Loss: 0.58825 
Epoch [36/300] Training [21/62] Loss: 0.61277 
Epoch [36/300] Training [22/62] Loss: 0.43695 
Epoch [36/300] Training [23/62] Loss: 0.60018 
Epoch [36/300] Training [24/62] Loss: 0.65498 
Epoch [36/300] Training [25/62] Loss: 0.33791 
Epoch [36/300] Training [26/62] Loss: 0.52745 
Epoch [36/300] Training [27/62] Loss: 0.57767 
Epoch [36/300] Training [28/62] Loss: 0.74395 
Epoch [36/300] Training [29/62] Loss: 0.37249 
Epoch [36/300] Training [30/62] Loss: 0.61109 
Epoch [36/300] Training [31/62] Loss: 0.56749 
Epoch [36/300] Training [32/62] Loss: 0.43051 
Epoch [36/300] Training [33/62] Loss: 0.31194 
Epoch [36/300] Training [34/62] Loss: 0.39521 
Epoch [36/300] Training [35/62] Loss: 0.67815 
Epoch [36/300] Training [36/62] Loss: 0.47722 
Epoch [36/300] Training [37/62] Loss: 0.46308 
Epoch [36/300] Training [38/62] Loss: 0.46093 
Epoch [36/300] Training [39/62] Loss: 0.39220 
Epoch [36/300] Training [40/62] Loss: 0.35792 
Epoch [36/300] Training [41/62] Loss: 0.73776 
Epoch [36/300] Training [42/62] Loss: 0.45940 
Epoch [36/300] Training [43/62] Loss: 0.49540 
Epoch [36/300] Training [44/62] Loss: 0.67136 
Epoch [36/300] Training [45/62] Loss: 0.63020 
Epoch [36/300] Training [46/62] Loss: 0.48339 
Epoch [36/300] Training [47/62] Loss: 0.52988 
Epoch [36/300] Training [48/62] Loss: 0.61528 
Epoch [36/300] Training [49/62] Loss: 0.39268 
Epoch [36/300] Training [50/62] Loss: 0.58806 
Epoch [36/300] Training [51/62] Loss: 0.76735 
Epoch [36/300] Training [52/62] Loss: 0.47518 
Epoch [36/300] Training [53/62] Loss: 0.46602 
Epoch [36/300] Training [54/62] Loss: 0.54307 
Epoch [36/300] Training [55/62] Loss: 0.54637 
Epoch [36/300] Training [56/62] Loss: 0.50308 
Epoch [36/300] Training [57/62] Loss: 0.61378 
Epoch [36/300] Training [58/62] Loss: 0.51008 
Epoch [36/300] Training [59/62] Loss: 0.42940 
Epoch [36/300] Training [60/62] Loss: 0.68276 
Epoch [36/300] Training [61/62] Loss: 0.45649 
Epoch [36/300] Training [62/62] Loss: 0.39764 
Epoch [36/300] Training metric {'Train/mean dice_metric': 0.6233382225036621, 'Train/mean miou_metric': 0.5048487186431885, 'Train/mean f1': 0.6690323352813721, 'Train/mean precision': 0.6691210865974426, 'Train/mean recall': 0.6689435839653015, 'Train/mean hd95_metric': 77.493896484375}
Epoch [36/300] Validation [1/16] Loss: 0.74716  focal_loss 0.29248  dice_loss 0.45467 
Epoch [36/300] Validation [2/16] Loss: 0.65669  focal_loss 0.12661  dice_loss 0.53008 
Epoch [36/300] Validation [3/16] Loss: 0.65149  focal_loss 0.16993  dice_loss 0.48156 
Epoch [36/300] Validation [4/16] Loss: 0.50204  focal_loss 0.12711  dice_loss 0.37493 
Epoch [36/300] Validation [5/16] Loss: 0.52566  focal_loss 0.04658  dice_loss 0.47909 
Epoch [36/300] Validation [6/16] Loss: 0.51860  focal_loss 0.08556  dice_loss 0.43304 
Epoch [36/300] Validation [7/16] Loss: 0.49729  focal_loss 0.09859  dice_loss 0.39869 
Epoch [36/300] Validation [8/16] Loss: 0.83193  focal_loss 0.17709  dice_loss 0.65484 
Epoch [36/300] Validation [9/16] Loss: 0.60399  focal_loss 0.11860  dice_loss 0.48538 
Epoch [36/300] Validation [10/16] Loss: 0.70092  focal_loss 0.13625  dice_loss 0.56468 
Epoch [36/300] Validation [11/16] Loss: 0.47957  focal_loss 0.09260  dice_loss 0.38698 
Epoch [36/300] Validation [12/16] Loss: 0.65225  focal_loss 0.06570  dice_loss 0.58654 
Epoch [36/300] Validation [13/16] Loss: 0.55316  focal_loss 0.13433  dice_loss 0.41883 
Epoch [36/300] Validation [14/16] Loss: 0.89173  focal_loss 0.20068  dice_loss 0.69105 
Epoch [36/300] Validation [15/16] Loss: 0.57770  focal_loss 0.12606  dice_loss 0.45165 
Epoch [36/300] Validation [16/16] Loss: 0.32733  focal_loss 0.08204  dice_loss 0.24529 
Epoch [36/300] Validation metric {'Val/mean dice_metric': 0.6054444313049316, 'Val/mean miou_metric': 0.488995224237442, 'Val/mean f1': 0.6563907265663147, 'Val/mean precision': 0.6784732937812805, 'Val/mean recall': 0.6357002854347229, 'Val/mean hd95_metric': 77.2972412109375}
Cheakpoint...
Epoch [36/300] best acc:tensor([0.6071], device='cuda:0'), Now : mean acc: tensor([0.6054], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6054444313049316, 'Val/mean miou_metric': 0.488995224237442, 'Val/mean f1': 0.6563907265663147, 'Val/mean precision': 0.6784732937812805, 'Val/mean recall': 0.6357002854347229, 'Val/mean hd95_metric': 77.2972412109375}
Epoch [37/300] Training [1/62] Loss: 0.47247 
Epoch [37/300] Training [2/62] Loss: 0.50689 
Epoch [37/300] Training [3/62] Loss: 0.46710 
Epoch [37/300] Training [4/62] Loss: 0.54037 
Epoch [37/300] Training [5/62] Loss: 0.53484 
Epoch [37/300] Training [6/62] Loss: 0.59729 
Epoch [37/300] Training [7/62] Loss: 0.47771 
Epoch [37/300] Training [8/62] Loss: 0.59076 
Epoch [37/300] Training [9/62] Loss: 0.47522 
Epoch [37/300] Training [10/62] Loss: 0.48105 
Epoch [37/300] Training [11/62] Loss: 0.58266 
Epoch [37/300] Training [12/62] Loss: 0.44786 
Epoch [37/300] Training [13/62] Loss: 0.67321 
Epoch [37/300] Training [14/62] Loss: 0.62777 
Epoch [37/300] Training [15/62] Loss: 0.59130 
Epoch [37/300] Training [16/62] Loss: 0.66330 
Epoch [37/300] Training [17/62] Loss: 0.55249 
Epoch [37/300] Training [18/62] Loss: 0.47603 
Epoch [37/300] Training [19/62] Loss: 0.72334 
Epoch [37/300] Training [20/62] Loss: 0.67560 
Epoch [37/300] Training [21/62] Loss: 0.46241 
Epoch [37/300] Training [22/62] Loss: 0.42538 
Epoch [37/300] Training [23/62] Loss: 0.42208 
Epoch [37/300] Training [24/62] Loss: 0.37610 
Epoch [37/300] Training [25/62] Loss: 0.42480 
Epoch [37/300] Training [26/62] Loss: 0.55300 
Epoch [37/300] Training [27/62] Loss: 0.42437 
Epoch [37/300] Training [28/62] Loss: 0.55831 
Epoch [37/300] Training [29/62] Loss: 0.32551 
Epoch [37/300] Training [30/62] Loss: 0.61101 
Epoch [37/300] Training [31/62] Loss: 0.44035 
Epoch [37/300] Training [32/62] Loss: 0.36493 
Epoch [37/300] Training [33/62] Loss: 0.64384 
Epoch [37/300] Training [34/62] Loss: 0.68059 
Epoch [37/300] Training [35/62] Loss: 0.55596 
Epoch [37/300] Training [36/62] Loss: 0.90692 
Epoch [37/300] Training [37/62] Loss: 0.51897 
Epoch [37/300] Training [38/62] Loss: 0.59352 
Epoch [37/300] Training [39/62] Loss: 0.34150 
Epoch [37/300] Training [40/62] Loss: 0.35508 
Epoch [37/300] Training [41/62] Loss: 0.62712 
Epoch [37/300] Training [42/62] Loss: 0.55357 
Epoch [37/300] Training [43/62] Loss: 0.38850 
Epoch [37/300] Training [44/62] Loss: 0.41109 
Epoch [37/300] Training [45/62] Loss: 0.57956 
Epoch [37/300] Training [46/62] Loss: 0.39992 
Epoch [37/300] Training [47/62] Loss: 0.61593 
Epoch [37/300] Training [48/62] Loss: 0.39901 
Epoch [37/300] Training [49/62] Loss: 0.53941 
Epoch [37/300] Training [50/62] Loss: 0.48040 
Epoch [37/300] Training [51/62] Loss: 0.38572 
Epoch [37/300] Training [52/62] Loss: 0.60315 
Epoch [37/300] Training [53/62] Loss: 0.61222 
Epoch [37/300] Training [54/62] Loss: 0.73967 
Epoch [37/300] Training [55/62] Loss: 0.79644 
Epoch [37/300] Training [56/62] Loss: 0.77332 
Epoch [37/300] Training [57/62] Loss: 0.43587 
Epoch [37/300] Training [58/62] Loss: 0.50291 
Epoch [37/300] Training [59/62] Loss: 0.62960 
Epoch [37/300] Training [60/62] Loss: 0.54332 
Epoch [37/300] Training [61/62] Loss: 0.65494 
Epoch [37/300] Training [62/62] Loss: 0.38653 
Epoch [37/300] Training metric {'Train/mean dice_metric': 0.6276509165763855, 'Train/mean miou_metric': 0.5095158219337463, 'Train/mean f1': 0.6669918894767761, 'Train/mean precision': 0.6649959683418274, 'Train/mean recall': 0.6689998507499695, 'Train/mean hd95_metric': 77.29362487792969}
Epoch [37/300] Validation [1/16] Loss: 0.63181  focal_loss 0.25349  dice_loss 0.37832 
Epoch [37/300] Validation [2/16] Loss: 0.62208  focal_loss 0.10812  dice_loss 0.51396 
Epoch [37/300] Validation [3/16] Loss: 0.61853  focal_loss 0.13950  dice_loss 0.47903 
Epoch [37/300] Validation [4/16] Loss: 0.48188  focal_loss 0.09683  dice_loss 0.38504 
Epoch [37/300] Validation [5/16] Loss: 0.52738  focal_loss 0.05921  dice_loss 0.46817 
Epoch [37/300] Validation [6/16] Loss: 0.49666  focal_loss 0.09185  dice_loss 0.40481 
Epoch [37/300] Validation [7/16] Loss: 0.53192  focal_loss 0.12380  dice_loss 0.40812 
Epoch [37/300] Validation [8/16] Loss: 0.79396  focal_loss 0.16730  dice_loss 0.62666 
Epoch [37/300] Validation [9/16] Loss: 0.50808  focal_loss 0.07838  dice_loss 0.42970 
Epoch [37/300] Validation [10/16] Loss: 0.58832  focal_loss 0.11461  dice_loss 0.47371 
Epoch [37/300] Validation [11/16] Loss: 0.47079  focal_loss 0.07671  dice_loss 0.39408 
Epoch [37/300] Validation [12/16] Loss: 0.57123  focal_loss 0.06152  dice_loss 0.50971 
Epoch [37/300] Validation [13/16] Loss: 0.47681  focal_loss 0.08970  dice_loss 0.38712 
Epoch [37/300] Validation [14/16] Loss: 0.89893  focal_loss 0.19863  dice_loss 0.70030 
Epoch [37/300] Validation [15/16] Loss: 0.39418  focal_loss 0.07711  dice_loss 0.31707 
Epoch [37/300] Validation [16/16] Loss: 0.35547  focal_loss 0.06802  dice_loss 0.28745 
Epoch [37/300] Validation metric {'Val/mean dice_metric': 0.6218019723892212, 'Val/mean miou_metric': 0.5033704042434692, 'Val/mean f1': 0.6588089466094971, 'Val/mean precision': 0.6537888050079346, 'Val/mean recall': 0.6639066934585571, 'Val/mean hd95_metric': 79.56658172607422}
Cheakpoint...
Epoch [37/300] best acc:tensor([0.6218], device='cuda:0'), Now : mean acc: tensor([0.6218], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6218019723892212, 'Val/mean miou_metric': 0.5033704042434692, 'Val/mean f1': 0.6588089466094971, 'Val/mean precision': 0.6537888050079346, 'Val/mean recall': 0.6639066934585571, 'Val/mean hd95_metric': 79.56658172607422}
Epoch [38/300] Training [1/62] Loss: 0.60841 
Epoch [38/300] Training [2/62] Loss: 0.52586 
Epoch [38/300] Training [3/62] Loss: 0.40939 
Epoch [38/300] Training [4/62] Loss: 0.71262 
Epoch [38/300] Training [5/62] Loss: 0.43787 
Epoch [38/300] Training [6/62] Loss: 0.40225 
Epoch [38/300] Training [7/62] Loss: 0.75563 
Epoch [38/300] Training [8/62] Loss: 0.66187 
Epoch [38/300] Training [9/62] Loss: 0.54888 
Epoch [38/300] Training [10/62] Loss: 0.45458 
Epoch [38/300] Training [11/62] Loss: 0.68697 
Epoch [38/300] Training [12/62] Loss: 0.34410 
Epoch [38/300] Training [13/62] Loss: 0.54200 
Epoch [38/300] Training [14/62] Loss: 0.56261 
Epoch [38/300] Training [15/62] Loss: 0.42930 
Epoch [38/300] Training [16/62] Loss: 0.53274 
Epoch [38/300] Training [17/62] Loss: 0.60440 
Epoch [38/300] Training [18/62] Loss: 0.65182 
Epoch [38/300] Training [19/62] Loss: 0.62164 
Epoch [38/300] Training [20/62] Loss: 0.54048 
Epoch [38/300] Training [21/62] Loss: 0.40780 
Epoch [38/300] Training [22/62] Loss: 0.51588 
Epoch [38/300] Training [23/62] Loss: 0.74944 
Epoch [38/300] Training [24/62] Loss: 0.55681 
Epoch [38/300] Training [25/62] Loss: 0.74442 
Epoch [38/300] Training [26/62] Loss: 0.49752 
Epoch [38/300] Training [27/62] Loss: 0.43752 
Epoch [38/300] Training [28/62] Loss: 0.43702 
Epoch [38/300] Training [29/62] Loss: 0.51748 
Epoch [38/300] Training [30/62] Loss: 0.27756 
Epoch [38/300] Training [31/62] Loss: 0.41086 
Epoch [38/300] Training [32/62] Loss: 0.49733 
Epoch [38/300] Training [33/62] Loss: 0.58951 
Epoch [38/300] Training [34/62] Loss: 0.48490 
Epoch [38/300] Training [35/62] Loss: 0.47715 
Epoch [38/300] Training [36/62] Loss: 0.48064 
Epoch [38/300] Training [37/62] Loss: 0.69722 
Epoch [38/300] Training [38/62] Loss: 0.41665 
Epoch [38/300] Training [39/62] Loss: 0.46556 
Epoch [38/300] Training [40/62] Loss: 0.26521 
Epoch [38/300] Training [41/62] Loss: 0.45356 
Epoch [38/300] Training [42/62] Loss: 0.40040 
Epoch [38/300] Training [43/62] Loss: 0.43972 
Epoch [38/300] Training [44/62] Loss: 0.53476 
Epoch [38/300] Training [45/62] Loss: 0.76908 
Epoch [38/300] Training [46/62] Loss: 0.61096 
Epoch [38/300] Training [47/62] Loss: 0.34165 
Epoch [38/300] Training [48/62] Loss: 0.48332 
Epoch [38/300] Training [49/62] Loss: 0.78816 
Epoch [38/300] Training [50/62] Loss: 0.58991 
Epoch [38/300] Training [51/62] Loss: 0.48885 
Epoch [38/300] Training [52/62] Loss: 0.41659 
Epoch [38/300] Training [53/62] Loss: 0.64088 
Epoch [38/300] Training [54/62] Loss: 0.64851 
Epoch [38/300] Training [55/62] Loss: 0.47700 
Epoch [38/300] Training [56/62] Loss: 0.46687 
Epoch [38/300] Training [57/62] Loss: 0.46502 
Epoch [38/300] Training [58/62] Loss: 0.46563 
Epoch [38/300] Training [59/62] Loss: 0.42035 
Epoch [38/300] Training [60/62] Loss: 0.35233 
Epoch [38/300] Training [61/62] Loss: 0.47861 
Epoch [38/300] Training [62/62] Loss: 1.21285 
Epoch [38/300] Training metric {'Train/mean dice_metric': 0.6377431154251099, 'Train/mean miou_metric': 0.5193576812744141, 'Train/mean f1': 0.6874907612800598, 'Train/mean precision': 0.6862607598304749, 'Train/mean recall': 0.6887251734733582, 'Train/mean hd95_metric': 77.96981811523438}
Epoch [38/300] Validation [1/16] Loss: 0.57455  focal_loss 0.24259  dice_loss 0.33197 
Epoch [38/300] Validation [2/16] Loss: 0.62137  focal_loss 0.11778  dice_loss 0.50359 
Epoch [38/300] Validation [3/16] Loss: 0.67993  focal_loss 0.14366  dice_loss 0.53627 
Epoch [38/300] Validation [4/16] Loss: 0.53247  focal_loss 0.12368  dice_loss 0.40878 
Epoch [38/300] Validation [5/16] Loss: 0.46250  focal_loss 0.05398  dice_loss 0.40851 
Epoch [38/300] Validation [6/16] Loss: 0.46775  focal_loss 0.07105  dice_loss 0.39670 
Epoch [38/300] Validation [7/16] Loss: 0.46033  focal_loss 0.09989  dice_loss 0.36044 
Epoch [38/300] Validation [8/16] Loss: 0.64573  focal_loss 0.11354  dice_loss 0.53220 
Epoch [38/300] Validation [9/16] Loss: 0.51160  focal_loss 0.10758  dice_loss 0.40402 
Epoch [38/300] Validation [10/16] Loss: 1.02104  focal_loss 0.32111  dice_loss 0.69993 
Epoch [38/300] Validation [11/16] Loss: 0.43526  focal_loss 0.08122  dice_loss 0.35405 
Epoch [38/300] Validation [12/16] Loss: 0.53556  focal_loss 0.05906  dice_loss 0.47650 
Epoch [38/300] Validation [13/16] Loss: 0.38715  focal_loss 0.06407  dice_loss 0.32308 
Epoch [38/300] Validation [14/16] Loss: 0.78393  focal_loss 0.18149  dice_loss 0.60245 
Epoch [38/300] Validation [15/16] Loss: 0.61352  focal_loss 0.17873  dice_loss 0.43479 
Epoch [38/300] Validation [16/16] Loss: 0.29952  focal_loss 0.05669  dice_loss 0.24283 
Epoch [38/300] Validation metric {'Val/mean dice_metric': 0.6308008432388306, 'Val/mean miou_metric': 0.5127096176147461, 'Val/mean f1': 0.6777885556221008, 'Val/mean precision': 0.683533251285553, 'Val/mean recall': 0.6721396446228027, 'Val/mean hd95_metric': 79.09751892089844}
Cheakpoint...
Epoch [38/300] best acc:tensor([0.6308], device='cuda:0'), Now : mean acc: tensor([0.6308], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6308008432388306, 'Val/mean miou_metric': 0.5127096176147461, 'Val/mean f1': 0.6777885556221008, 'Val/mean precision': 0.683533251285553, 'Val/mean recall': 0.6721396446228027, 'Val/mean hd95_metric': 79.09751892089844}
Epoch [39/300] Training [1/62] Loss: 0.44270 
Epoch [39/300] Training [2/62] Loss: 0.39433 
Epoch [39/300] Training [3/62] Loss: 0.50417 
Epoch [39/300] Training [4/62] Loss: 0.52654 
Epoch [39/300] Training [5/62] Loss: 0.44612 
Epoch [39/300] Training [6/62] Loss: 0.88487 
Epoch [39/300] Training [7/62] Loss: 0.49716 
Epoch [39/300] Training [8/62] Loss: 0.61473 
Epoch [39/300] Training [9/62] Loss: 0.46124 
Epoch [39/300] Training [10/62] Loss: 0.55350 
Epoch [39/300] Training [11/62] Loss: 0.54672 
Epoch [39/300] Training [12/62] Loss: 0.50011 
Epoch [39/300] Training [13/62] Loss: 0.41189 
Epoch [39/300] Training [14/62] Loss: 0.51581 
Epoch [39/300] Training [15/62] Loss: 0.42171 
Epoch [39/300] Training [16/62] Loss: 0.43913 
Epoch [39/300] Training [17/62] Loss: 0.59958 
Epoch [39/300] Training [18/62] Loss: 0.50621 
Epoch [39/300] Training [19/62] Loss: 0.46311 
Epoch [39/300] Training [20/62] Loss: 0.39934 
Epoch [39/300] Training [21/62] Loss: 0.60377 
Epoch [39/300] Training [22/62] Loss: 0.52147 
Epoch [39/300] Training [23/62] Loss: 0.21922 
Epoch [39/300] Training [24/62] Loss: 0.55874 
Epoch [39/300] Training [25/62] Loss: 0.44707 
Epoch [39/300] Training [26/62] Loss: 0.51577 
Epoch [39/300] Training [27/62] Loss: 0.31624 
Epoch [39/300] Training [28/62] Loss: 0.66138 
Epoch [39/300] Training [29/62] Loss: 0.45112 
Epoch [39/300] Training [30/62] Loss: 0.58475 
Epoch [39/300] Training [31/62] Loss: 0.62015 
Epoch [39/300] Training [32/62] Loss: 0.49787 
Epoch [39/300] Training [33/62] Loss: 0.61600 
Epoch [39/300] Training [34/62] Loss: 0.59790 
Epoch [39/300] Training [35/62] Loss: 0.75016 
Epoch [39/300] Training [36/62] Loss: 0.45515 
Epoch [39/300] Training [37/62] Loss: 0.52744 
Epoch [39/300] Training [38/62] Loss: 0.65960 
Epoch [39/300] Training [39/62] Loss: 0.53142 
Epoch [39/300] Training [40/62] Loss: 0.63462 
Epoch [39/300] Training [41/62] Loss: 0.43740 
Epoch [39/300] Training [42/62] Loss: 0.50593 
Epoch [39/300] Training [43/62] Loss: 0.46779 
Epoch [39/300] Training [44/62] Loss: 0.58682 
Epoch [39/300] Training [45/62] Loss: 0.64219 
Epoch [39/300] Training [46/62] Loss: 0.58001 
Epoch [39/300] Training [47/62] Loss: 0.73834 
Epoch [39/300] Training [48/62] Loss: 0.45058 
Epoch [39/300] Training [49/62] Loss: 0.58527 
Epoch [39/300] Training [50/62] Loss: 0.53075 
Epoch [39/300] Training [51/62] Loss: 0.38440 
Epoch [39/300] Training [52/62] Loss: 0.58938 
Epoch [39/300] Training [53/62] Loss: 0.42794 
Epoch [39/300] Training [54/62] Loss: 0.51675 
Epoch [39/300] Training [55/62] Loss: 0.58989 
Epoch [39/300] Training [56/62] Loss: 0.37894 
Epoch [39/300] Training [57/62] Loss: 0.53811 
Epoch [39/300] Training [58/62] Loss: 0.61536 
Epoch [39/300] Training [59/62] Loss: 0.74495 
Epoch [39/300] Training [60/62] Loss: 0.48680 
Epoch [39/300] Training [61/62] Loss: 0.48885 
Epoch [39/300] Training [62/62] Loss: 0.58524 
Epoch [39/300] Training metric {'Train/mean dice_metric': 0.6304778456687927, 'Train/mean miou_metric': 0.5106362104415894, 'Train/mean f1': 0.6745603084564209, 'Train/mean precision': 0.660804808139801, 'Train/mean recall': 0.6889007091522217, 'Train/mean hd95_metric': 80.39083862304688}
Epoch [39/300] Validation [1/16] Loss: 0.66945  focal_loss 0.21349  dice_loss 0.45595 
Epoch [39/300] Validation [2/16] Loss: 0.75359  focal_loss 0.12421  dice_loss 0.62938 
Epoch [39/300] Validation [3/16] Loss: 0.72952  focal_loss 0.13876  dice_loss 0.59076 
Epoch [39/300] Validation [4/16] Loss: 0.64433  focal_loss 0.12047  dice_loss 0.52386 
Epoch [39/300] Validation [5/16] Loss: 0.59012  focal_loss 0.07405  dice_loss 0.51607 
Epoch [39/300] Validation [6/16] Loss: 0.57010  focal_loss 0.10378  dice_loss 0.46633 
Epoch [39/300] Validation [7/16] Loss: 0.52581  focal_loss 0.07730  dice_loss 0.44851 
Epoch [39/300] Validation [8/16] Loss: 0.70827  focal_loss 0.10400  dice_loss 0.60427 
Epoch [39/300] Validation [9/16] Loss: 0.73126  focal_loss 0.15484  dice_loss 0.57642 
Epoch [39/300] Validation [10/16] Loss: 0.67598  focal_loss 0.13859  dice_loss 0.53739 
Epoch [39/300] Validation [11/16] Loss: 0.54213  focal_loss 0.08699  dice_loss 0.45514 
Epoch [39/300] Validation [12/16] Loss: 0.72251  focal_loss 0.07097  dice_loss 0.65154 
Epoch [39/300] Validation [13/16] Loss: 0.52403  focal_loss 0.06156  dice_loss 0.46247 
Epoch [39/300] Validation [14/16] Loss: 0.79755  focal_loss 0.12717  dice_loss 0.67038 
Epoch [39/300] Validation [15/16] Loss: 0.50826  focal_loss 0.08450  dice_loss 0.42375 
Epoch [39/300] Validation [16/16] Loss: 0.43832  focal_loss 0.08237  dice_loss 0.35595 
Epoch [39/300] Validation metric {'Val/mean dice_metric': 0.6136525869369507, 'Val/mean miou_metric': 0.4916086494922638, 'Val/mean f1': 0.6500713229179382, 'Val/mean precision': 0.6095916032791138, 'Val/mean recall': 0.6963095664978027, 'Val/mean hd95_metric': 87.6469955444336}
Cheakpoint...
Epoch [39/300] best acc:tensor([0.6308], device='cuda:0'), Now : mean acc: tensor([0.6137], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6136525869369507, 'Val/mean miou_metric': 0.4916086494922638, 'Val/mean f1': 0.6500713229179382, 'Val/mean precision': 0.6095916032791138, 'Val/mean recall': 0.6963095664978027, 'Val/mean hd95_metric': 87.6469955444336}
Epoch [40/300] Training [1/62] Loss: 0.58840 
Epoch [40/300] Training [2/62] Loss: 0.33620 
Epoch [40/300] Training [3/62] Loss: 0.52984 
Epoch [40/300] Training [4/62] Loss: 0.52699 
Epoch [40/300] Training [5/62] Loss: 0.61069 
Epoch [40/300] Training [6/62] Loss: 0.35077 
Epoch [40/300] Training [7/62] Loss: 0.44218 
Epoch [40/300] Training [8/62] Loss: 0.49756 
Epoch [40/300] Training [9/62] Loss: 0.47354 
Epoch [40/300] Training [10/62] Loss: 0.60589 
Epoch [40/300] Training [11/62] Loss: 0.43703 
Epoch [40/300] Training [12/62] Loss: 0.70457 
Epoch [40/300] Training [13/62] Loss: 0.46707 
Epoch [40/300] Training [14/62] Loss: 0.50139 
Epoch [40/300] Training [15/62] Loss: 0.32105 
Epoch [40/300] Training [16/62] Loss: 0.58053 
Epoch [40/300] Training [17/62] Loss: 0.52492 
Epoch [40/300] Training [18/62] Loss: 0.56672 
Epoch [40/300] Training [19/62] Loss: 0.54512 
Epoch [40/300] Training [20/62] Loss: 0.57098 
Epoch [40/300] Training [21/62] Loss: 0.36193 
Epoch [40/300] Training [22/62] Loss: 0.65287 
Epoch [40/300] Training [23/62] Loss: 0.51262 
Epoch [40/300] Training [24/62] Loss: 0.45650 
Epoch [40/300] Training [25/62] Loss: 0.51656 
Epoch [40/300] Training [26/62] Loss: 0.45030 
Epoch [40/300] Training [27/62] Loss: 0.44127 
Epoch [40/300] Training [28/62] Loss: 0.39270 
Epoch [40/300] Training [29/62] Loss: 0.65057 
Epoch [40/300] Training [30/62] Loss: 0.39670 
Epoch [40/300] Training [31/62] Loss: 0.43858 
Epoch [40/300] Training [32/62] Loss: 0.50993 
Epoch [40/300] Training [33/62] Loss: 0.59355 
Epoch [40/300] Training [34/62] Loss: 0.59606 
Epoch [40/300] Training [35/62] Loss: 0.27885 
Epoch [40/300] Training [36/62] Loss: 0.40740 
Epoch [40/300] Training [37/62] Loss: 0.48540 
Epoch [40/300] Training [38/62] Loss: 0.40618 
Epoch [40/300] Training [39/62] Loss: 0.40655 
Epoch [40/300] Training [40/62] Loss: 0.59931 
Epoch [40/300] Training [41/62] Loss: 0.42601 
Epoch [40/300] Training [42/62] Loss: 0.63908 
Epoch [40/300] Training [43/62] Loss: 0.37868 
Epoch [40/300] Training [44/62] Loss: 0.35443 
Epoch [40/300] Training [45/62] Loss: 0.44695 
Epoch [40/300] Training [46/62] Loss: 0.60627 
Epoch [40/300] Training [47/62] Loss: 0.42094 
Epoch [40/300] Training [48/62] Loss: 0.42399 
Epoch [40/300] Training [49/62] Loss: 0.46491 
Epoch [40/300] Training [50/62] Loss: 0.56653 
Epoch [40/300] Training [51/62] Loss: 0.76490 
Epoch [40/300] Training [52/62] Loss: 0.28178 
Epoch [40/300] Training [53/62] Loss: 0.60113 
Epoch [40/300] Training [54/62] Loss: 0.32913 
Epoch [40/300] Training [55/62] Loss: 0.40443 
Epoch [40/300] Training [56/62] Loss: 0.50974 
Epoch [40/300] Training [57/62] Loss: 0.68886 
Epoch [40/300] Training [58/62] Loss: 0.39243 
Epoch [40/300] Training [59/62] Loss: 0.61167 
Epoch [40/300] Training [60/62] Loss: 0.57031 
Epoch [40/300] Training [61/62] Loss: 0.59837 
Epoch [40/300] Training [62/62] Loss: 0.40252 
Epoch [40/300] Training metric {'Train/mean dice_metric': 0.6576815843582153, 'Train/mean miou_metric': 0.5414504408836365, 'Train/mean f1': 0.7000162601470947, 'Train/mean precision': 0.6906868815422058, 'Train/mean recall': 0.7096011638641357, 'Train/mean hd95_metric': 75.03692626953125}
Epoch [40/300] Validation [1/16] Loss: 0.81493  focal_loss 0.31336  dice_loss 0.50157 
Epoch [40/300] Validation [2/16] Loss: 0.63014  focal_loss 0.13393  dice_loss 0.49621 
Epoch [40/300] Validation [3/16] Loss: 0.78691  focal_loss 0.20963  dice_loss 0.57728 
Epoch [40/300] Validation [4/16] Loss: 0.60131  focal_loss 0.14062  dice_loss 0.46069 
Epoch [40/300] Validation [5/16] Loss: 0.57852  focal_loss 0.07523  dice_loss 0.50328 
Epoch [40/300] Validation [6/16] Loss: 0.52728  focal_loss 0.09179  dice_loss 0.43549 
Epoch [40/300] Validation [7/16] Loss: 0.52635  focal_loss 0.11005  dice_loss 0.41630 
Epoch [40/300] Validation [8/16] Loss: 0.79867  focal_loss 0.16516  dice_loss 0.63351 
Epoch [40/300] Validation [9/16] Loss: 0.56555  focal_loss 0.10543  dice_loss 0.46012 
Epoch [40/300] Validation [10/16] Loss: 0.73246  focal_loss 0.18332  dice_loss 0.54914 
Epoch [40/300] Validation [11/16] Loss: 0.60480  focal_loss 0.11751  dice_loss 0.48729 
Epoch [40/300] Validation [12/16] Loss: 0.71197  focal_loss 0.07908  dice_loss 0.63289 
Epoch [40/300] Validation [13/16] Loss: 0.49934  focal_loss 0.11127  dice_loss 0.38807 
Epoch [40/300] Validation [14/16] Loss: 0.96957  focal_loss 0.19977  dice_loss 0.76980 
Epoch [40/300] Validation [15/16] Loss: 0.63596  focal_loss 0.16465  dice_loss 0.47131 
Epoch [40/300] Validation [16/16] Loss: 0.34389  focal_loss 0.07769  dice_loss 0.26620 
Epoch [40/300] Validation metric {'Val/mean dice_metric': 0.6300816535949707, 'Val/mean miou_metric': 0.5162563920021057, 'Val/mean f1': 0.6798816919326782, 'Val/mean precision': 0.6982079744338989, 'Val/mean recall': 0.6624927520751953, 'Val/mean hd95_metric': 76.6747817993164}
Cheakpoint...
Epoch [40/300] best acc:tensor([0.6308], device='cuda:0'), Now : mean acc: tensor([0.6301], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6300816535949707, 'Val/mean miou_metric': 0.5162563920021057, 'Val/mean f1': 0.6798816919326782, 'Val/mean precision': 0.6982079744338989, 'Val/mean recall': 0.6624927520751953, 'Val/mean hd95_metric': 76.6747817993164}
Epoch [41/300] Training [1/62] Loss: 0.48309 
Epoch [41/300] Training [2/62] Loss: 0.45402 
Epoch [41/300] Training [3/62] Loss: 0.36437 
Epoch [41/300] Training [4/62] Loss: 0.36320 
Epoch [41/300] Training [5/62] Loss: 0.59072 
Epoch [41/300] Training [6/62] Loss: 0.60916 
Epoch [41/300] Training [7/62] Loss: 0.48801 
Epoch [41/300] Training [8/62] Loss: 0.48412 
Epoch [41/300] Training [9/62] Loss: 0.55559 
Epoch [41/300] Training [10/62] Loss: 0.41275 
Epoch [41/300] Training [11/62] Loss: 0.38972 
Epoch [41/300] Training [12/62] Loss: 0.41777 
Epoch [41/300] Training [13/62] Loss: 0.56167 
Epoch [41/300] Training [14/62] Loss: 0.46494 
Epoch [41/300] Training [15/62] Loss: 0.38482 
Epoch [41/300] Training [16/62] Loss: 0.41827 
Epoch [41/300] Training [17/62] Loss: 0.50642 
Epoch [41/300] Training [18/62] Loss: 0.48826 
Epoch [41/300] Training [19/62] Loss: 0.77222 
Epoch [41/300] Training [20/62] Loss: 0.71521 
Epoch [41/300] Training [21/62] Loss: 0.46767 
Epoch [41/300] Training [22/62] Loss: 0.34215 
Epoch [41/300] Training [23/62] Loss: 0.37426 
Epoch [41/300] Training [24/62] Loss: 0.65673 
Epoch [41/300] Training [25/62] Loss: 0.74754 
Epoch [41/300] Training [26/62] Loss: 0.58256 
Epoch [41/300] Training [27/62] Loss: 0.95113 
Epoch [41/300] Training [28/62] Loss: 0.55982 
Epoch [41/300] Training [29/62] Loss: 0.76079 
Epoch [41/300] Training [30/62] Loss: 0.66442 
Epoch [41/300] Training [31/62] Loss: 0.46080 
Epoch [41/300] Training [32/62] Loss: 0.38754 
Epoch [41/300] Training [33/62] Loss: 0.67349 
Epoch [41/300] Training [34/62] Loss: 0.52205 
Epoch [41/300] Training [35/62] Loss: 0.53886 
Epoch [41/300] Training [36/62] Loss: 0.32661 
Epoch [41/300] Training [37/62] Loss: 0.59503 
Epoch [41/300] Training [38/62] Loss: 0.56523 
Epoch [41/300] Training [39/62] Loss: 0.27567 
Epoch [41/300] Training [40/62] Loss: 0.51906 
Epoch [41/300] Training [41/62] Loss: 0.38228 
Epoch [41/300] Training [42/62] Loss: 0.47971 
Epoch [41/300] Training [43/62] Loss: 0.45911 
Epoch [41/300] Training [44/62] Loss: 0.40659 
Epoch [41/300] Training [45/62] Loss: 0.29878 
Epoch [41/300] Training [46/62] Loss: 0.44761 
Epoch [41/300] Training [47/62] Loss: 0.54281 
Epoch [41/300] Training [48/62] Loss: 0.39611 
Epoch [41/300] Training [49/62] Loss: 0.64631 
Epoch [41/300] Training [50/62] Loss: 0.40675 
Epoch [41/300] Training [51/62] Loss: 0.49810 
Epoch [41/300] Training [52/62] Loss: 0.47600 
Epoch [41/300] Training [53/62] Loss: 0.39550 
Epoch [41/300] Training [54/62] Loss: 0.62269 
Epoch [41/300] Training [55/62] Loss: 0.47150 
Epoch [41/300] Training [56/62] Loss: 0.47353 
Epoch [41/300] Training [57/62] Loss: 0.44736 
Epoch [41/300] Training [58/62] Loss: 0.46157 
Epoch [41/300] Training [59/62] Loss: 0.41116 
Epoch [41/300] Training [60/62] Loss: 0.28101 
Epoch [41/300] Training [61/62] Loss: 0.59343 
Epoch [41/300] Training [62/62] Loss: 0.15565 
Epoch [41/300] Training metric {'Train/mean dice_metric': 0.6568930745124817, 'Train/mean miou_metric': 0.5392627120018005, 'Train/mean f1': 0.6982977986335754, 'Train/mean precision': 0.704825758934021, 'Train/mean recall': 0.6918897032737732, 'Train/mean hd95_metric': 73.07356262207031}
Epoch [41/300] Validation [1/16] Loss: 0.74380  focal_loss 0.32272  dice_loss 0.42108 
Epoch [41/300] Validation [2/16] Loss: 0.64742  focal_loss 0.13988  dice_loss 0.50755 
Epoch [41/300] Validation [3/16] Loss: 0.58961  focal_loss 0.13967  dice_loss 0.44993 
Epoch [41/300] Validation [4/16] Loss: 0.52436  focal_loss 0.15694  dice_loss 0.36742 
Epoch [41/300] Validation [5/16] Loss: 0.42185  focal_loss 0.05140  dice_loss 0.37045 
Epoch [41/300] Validation [6/16] Loss: 0.51695  focal_loss 0.11628  dice_loss 0.40067 
Epoch [41/300] Validation [7/16] Loss: 0.46027  focal_loss 0.11312  dice_loss 0.34715 
Epoch [41/300] Validation [8/16] Loss: 0.72980  focal_loss 0.14307  dice_loss 0.58673 
Epoch [41/300] Validation [9/16] Loss: 0.47381  focal_loss 0.11288  dice_loss 0.36094 
Epoch [41/300] Validation [10/16] Loss: 0.62074  focal_loss 0.13231  dice_loss 0.48843 
Epoch [41/300] Validation [11/16] Loss: 0.41030  focal_loss 0.07814  dice_loss 0.33215 
Epoch [41/300] Validation [12/16] Loss: 0.59008  focal_loss 0.07088  dice_loss 0.51920 
Epoch [41/300] Validation [13/16] Loss: 0.34509  focal_loss 0.07260  dice_loss 0.27249 
Epoch [41/300] Validation [14/16] Loss: 0.88278  focal_loss 0.22061  dice_loss 0.66217 
Epoch [41/300] Validation [15/16] Loss: 0.44894  focal_loss 0.12670  dice_loss 0.32224 
Epoch [41/300] Validation [16/16] Loss: 0.30420  focal_loss 0.07057  dice_loss 0.23363 
Epoch [41/300] Validation metric {'Val/mean dice_metric': 0.6471297144889832, 'Val/mean miou_metric': 0.5312332510948181, 'Val/mean f1': 0.690030574798584, 'Val/mean precision': 0.7057504653930664, 'Val/mean recall': 0.6749957203865051, 'Val/mean hd95_metric': 72.5504379272461}
Cheakpoint...
Epoch [41/300] best acc:tensor([0.6471], device='cuda:0'), Now : mean acc: tensor([0.6471], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6471297144889832, 'Val/mean miou_metric': 0.5312332510948181, 'Val/mean f1': 0.690030574798584, 'Val/mean precision': 0.7057504653930664, 'Val/mean recall': 0.6749957203865051, 'Val/mean hd95_metric': 72.5504379272461}
Epoch [42/300] Training [1/62] Loss: 0.55768 
Epoch [42/300] Training [2/62] Loss: 0.53803 
Epoch [42/300] Training [3/62] Loss: 0.49604 
Epoch [42/300] Training [4/62] Loss: 0.51481 
Epoch [42/300] Training [5/62] Loss: 0.33028 
Epoch [42/300] Training [6/62] Loss: 0.58965 
Epoch [42/300] Training [7/62] Loss: 0.47142 
Epoch [42/300] Training [8/62] Loss: 0.43206 
Epoch [42/300] Training [9/62] Loss: 0.57005 
Epoch [42/300] Training [10/62] Loss: 0.57703 
Epoch [42/300] Training [11/62] Loss: 0.38618 
Epoch [42/300] Training [12/62] Loss: 0.51937 
Epoch [42/300] Training [13/62] Loss: 0.44587 
Epoch [42/300] Training [14/62] Loss: 0.43843 
Epoch [42/300] Training [15/62] Loss: 0.40976 
Epoch [42/300] Training [16/62] Loss: 0.33717 
Epoch [42/300] Training [17/62] Loss: 0.39783 
Epoch [42/300] Training [18/62] Loss: 0.34548 
Epoch [42/300] Training [19/62] Loss: 0.45327 
Epoch [42/300] Training [20/62] Loss: 0.52789 
Epoch [42/300] Training [21/62] Loss: 0.70875 
Epoch [42/300] Training [22/62] Loss: 0.46190 
Epoch [42/300] Training [23/62] Loss: 0.36631 
Epoch [42/300] Training [24/62] Loss: 0.41933 
Epoch [42/300] Training [25/62] Loss: 0.68345 
Epoch [42/300] Training [26/62] Loss: 0.58303 
Epoch [42/300] Training [27/62] Loss: 0.37489 
Epoch [42/300] Training [28/62] Loss: 0.69655 
Epoch [42/300] Training [29/62] Loss: 0.33481 
Epoch [42/300] Training [30/62] Loss: 0.36050 
Epoch [42/300] Training [31/62] Loss: 0.32878 
Epoch [42/300] Training [32/62] Loss: 0.46109 
Epoch [42/300] Training [33/62] Loss: 0.49840 
Epoch [42/300] Training [34/62] Loss: 0.55465 
Epoch [42/300] Training [35/62] Loss: 0.40101 
Epoch [42/300] Training [36/62] Loss: 0.37369 
Epoch [42/300] Training [37/62] Loss: 0.25640 
Epoch [42/300] Training [38/62] Loss: 0.37940 
Epoch [42/300] Training [39/62] Loss: 0.62077 
Epoch [42/300] Training [40/62] Loss: 0.58964 
Epoch [42/300] Training [41/62] Loss: 0.61943 
Epoch [42/300] Training [42/62] Loss: 0.49363 
Epoch [42/300] Training [43/62] Loss: 0.35689 
Epoch [42/300] Training [44/62] Loss: 0.45062 
Epoch [42/300] Training [45/62] Loss: 0.33785 
Epoch [42/300] Training [46/62] Loss: 0.65188 
Epoch [42/300] Training [47/62] Loss: 0.68813 
Epoch [42/300] Training [48/62] Loss: 0.59909 
Epoch [42/300] Training [49/62] Loss: 0.67225 
Epoch [42/300] Training [50/62] Loss: 0.47825 
Epoch [42/300] Training [51/62] Loss: 0.46646 
Epoch [42/300] Training [52/62] Loss: 0.30409 
Epoch [42/300] Training [53/62] Loss: 0.27502 
Epoch [42/300] Training [54/62] Loss: 0.42753 
Epoch [42/300] Training [55/62] Loss: 0.67358 
Epoch [42/300] Training [56/62] Loss: 0.66831 
Epoch [42/300] Training [57/62] Loss: 0.73851 
Epoch [42/300] Training [58/62] Loss: 0.48321 
Epoch [42/300] Training [59/62] Loss: 0.54355 
Epoch [42/300] Training [60/62] Loss: 0.41871 
Epoch [42/300] Training [61/62] Loss: 0.62698 
Epoch [42/300] Training [62/62] Loss: 0.35580 
Epoch [42/300] Training metric {'Train/mean dice_metric': 0.6658841967582703, 'Train/mean miou_metric': 0.5493698120117188, 'Train/mean f1': 0.7009246349334717, 'Train/mean precision': 0.6937025785446167, 'Train/mean recall': 0.7082986831665039, 'Train/mean hd95_metric': 76.22618103027344}
Epoch [42/300] Validation [1/16] Loss: 0.54629  focal_loss 0.20552  dice_loss 0.34077 
Epoch [42/300] Validation [2/16] Loss: 0.63826  focal_loss 0.12324  dice_loss 0.51502 
Epoch [42/300] Validation [3/16] Loss: 0.55843  focal_loss 0.09381  dice_loss 0.46462 
Epoch [42/300] Validation [4/16] Loss: 0.59216  focal_loss 0.14897  dice_loss 0.44319 
Epoch [42/300] Validation [5/16] Loss: 0.52921  focal_loss 0.05801  dice_loss 0.47120 
Epoch [42/300] Validation [6/16] Loss: 0.49122  focal_loss 0.09651  dice_loss 0.39470 
Epoch [42/300] Validation [7/16] Loss: 0.38889  focal_loss 0.06541  dice_loss 0.32348 
Epoch [42/300] Validation [8/16] Loss: 0.69475  focal_loss 0.10937  dice_loss 0.58538 
Epoch [42/300] Validation [9/16] Loss: 0.50742  focal_loss 0.08980  dice_loss 0.41762 
Epoch [42/300] Validation [10/16] Loss: 0.56666  focal_loss 0.09781  dice_loss 0.46885 
Epoch [42/300] Validation [11/16] Loss: 0.55774  focal_loss 0.11343  dice_loss 0.44432 
Epoch [42/300] Validation [12/16] Loss: 0.56381  focal_loss 0.05570  dice_loss 0.50811 
Epoch [42/300] Validation [13/16] Loss: 0.38601  focal_loss 0.04441  dice_loss 0.34160 
Epoch [42/300] Validation [14/16] Loss: 0.75387  focal_loss 0.13166  dice_loss 0.62222 
Epoch [42/300] Validation [15/16] Loss: 0.41796  focal_loss 0.07683  dice_loss 0.34112 
Epoch [42/300] Validation [16/16] Loss: 0.39197  focal_loss 0.08395  dice_loss 0.30802 
Epoch [42/300] Validation metric {'Val/mean dice_metric': 0.6588137745857239, 'Val/mean miou_metric': 0.540459930896759, 'Val/mean f1': 0.6927273869514465, 'Val/mean precision': 0.6801073551177979, 'Val/mean recall': 0.7058246731758118, 'Val/mean hd95_metric': 79.46943664550781}
Cheakpoint...
Epoch [42/300] best acc:tensor([0.6588], device='cuda:0'), Now : mean acc: tensor([0.6588], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6588137745857239, 'Val/mean miou_metric': 0.540459930896759, 'Val/mean f1': 0.6927273869514465, 'Val/mean precision': 0.6801073551177979, 'Val/mean recall': 0.7058246731758118, 'Val/mean hd95_metric': 79.46943664550781}
Epoch [43/300] Training [1/62] Loss: 0.50988 
Epoch [43/300] Training [2/62] Loss: 0.37661 
Epoch [43/300] Training [3/62] Loss: 0.84575 
Epoch [43/300] Training [4/62] Loss: 0.37816 
Epoch [43/300] Training [5/62] Loss: 0.34738 
Epoch [43/300] Training [6/62] Loss: 0.43852 
Epoch [43/300] Training [7/62] Loss: 0.35221 
Epoch [43/300] Training [8/62] Loss: 0.32195 
Epoch [43/300] Training [9/62] Loss: 0.53569 
Epoch [43/300] Training [10/62] Loss: 0.53781 
Epoch [43/300] Training [11/62] Loss: 0.41314 
Epoch [43/300] Training [12/62] Loss: 0.69024 
Epoch [43/300] Training [13/62] Loss: 0.55642 
Epoch [43/300] Training [14/62] Loss: 0.34502 
Epoch [43/300] Training [15/62] Loss: 0.52420 
Epoch [43/300] Training [16/62] Loss: 0.37987 
Epoch [43/300] Training [17/62] Loss: 0.65644 
Epoch [43/300] Training [18/62] Loss: 0.49185 
Epoch [43/300] Training [19/62] Loss: 0.42035 
Epoch [43/300] Training [20/62] Loss: 0.43570 
Epoch [43/300] Training [21/62] Loss: 0.35454 
Epoch [43/300] Training [22/62] Loss: 0.60247 
Epoch [43/300] Training [23/62] Loss: 0.59614 
Epoch [43/300] Training [24/62] Loss: 0.40882 
Epoch [43/300] Training [25/62] Loss: 0.62019 
Epoch [43/300] Training [26/62] Loss: 0.46330 
Epoch [43/300] Training [27/62] Loss: 0.42795 
Epoch [43/300] Training [28/62] Loss: 0.51530 
Epoch [43/300] Training [29/62] Loss: 0.44970 
Epoch [43/300] Training [30/62] Loss: 0.45599 
Epoch [43/300] Training [31/62] Loss: 0.73400 
Epoch [43/300] Training [32/62] Loss: 0.30444 
Epoch [43/300] Training [33/62] Loss: 0.41958 
Epoch [43/300] Training [34/62] Loss: 0.48485 
Epoch [43/300] Training [35/62] Loss: 0.30592 
Epoch [43/300] Training [36/62] Loss: 0.44236 
Epoch [43/300] Training [37/62] Loss: 0.33046 
Epoch [43/300] Training [38/62] Loss: 0.42576 
Epoch [43/300] Training [39/62] Loss: 0.60406 
Epoch [43/300] Training [40/62] Loss: 0.51592 
Epoch [43/300] Training [41/62] Loss: 0.74984 
Epoch [43/300] Training [42/62] Loss: 0.31355 
Epoch [43/300] Training [43/62] Loss: 0.60150 
Epoch [43/300] Training [44/62] Loss: 0.46634 
Epoch [43/300] Training [45/62] Loss: 0.34543 
Epoch [43/300] Training [46/62] Loss: 0.55729 
Epoch [43/300] Training [47/62] Loss: 0.36157 
Epoch [43/300] Training [48/62] Loss: 0.39147 
Epoch [43/300] Training [49/62] Loss: 0.48474 
Epoch [43/300] Training [50/62] Loss: 0.38224 
Epoch [43/300] Training [51/62] Loss: 0.46488 
Epoch [43/300] Training [52/62] Loss: 0.45396 
Epoch [43/300] Training [53/62] Loss: 0.41448 
Epoch [43/300] Training [54/62] Loss: 0.30866 
Epoch [43/300] Training [55/62] Loss: 0.55189 
Epoch [43/300] Training [56/62] Loss: 0.47969 
Epoch [43/300] Training [57/62] Loss: 0.49396 
Epoch [43/300] Training [58/62] Loss: 0.43661 
Epoch [43/300] Training [59/62] Loss: 0.38939 
Epoch [43/300] Training [60/62] Loss: 0.35240 
Epoch [43/300] Training [61/62] Loss: 0.49113 
Epoch [43/300] Training [62/62] Loss: 0.96843 
Epoch [43/300] Training metric {'Train/mean dice_metric': 0.6782439947128296, 'Train/mean miou_metric': 0.5624534487724304, 'Train/mean f1': 0.717171311378479, 'Train/mean precision': 0.7199168801307678, 'Train/mean recall': 0.7144466638565063, 'Train/mean hd95_metric': 69.8089599609375}
Epoch [43/300] Validation [1/16] Loss: 0.58601  focal_loss 0.24697  dice_loss 0.33903 
Epoch [43/300] Validation [2/16] Loss: 0.64546  focal_loss 0.13109  dice_loss 0.51437 
Epoch [43/300] Validation [3/16] Loss: 0.71571  focal_loss 0.18099  dice_loss 0.53472 
Epoch [43/300] Validation [4/16] Loss: 0.47718  focal_loss 0.12200  dice_loss 0.35518 
Epoch [43/300] Validation [5/16] Loss: 0.54101  focal_loss 0.09596  dice_loss 0.44505 
Epoch [43/300] Validation [6/16] Loss: 0.50195  focal_loss 0.11422  dice_loss 0.38773 
Epoch [43/300] Validation [7/16] Loss: 0.40723  focal_loss 0.09157  dice_loss 0.31566 
Epoch [43/300] Validation [8/16] Loss: 0.82997  focal_loss 0.20919  dice_loss 0.62078 
Epoch [43/300] Validation [9/16] Loss: 0.60710  focal_loss 0.16486  dice_loss 0.44224 
Epoch [43/300] Validation [10/16] Loss: 0.68330  focal_loss 0.16574  dice_loss 0.51755 
Epoch [43/300] Validation [11/16] Loss: 0.43549  focal_loss 0.08211  dice_loss 0.35338 
Epoch [43/300] Validation [12/16] Loss: 0.59556  focal_loss 0.06554  dice_loss 0.53002 
Epoch [43/300] Validation [13/16] Loss: 0.52259  focal_loss 0.15602  dice_loss 0.36657 
Epoch [43/300] Validation [14/16] Loss: 0.75225  focal_loss 0.16652  dice_loss 0.58573 
Epoch [43/300] Validation [15/16] Loss: 0.39384  focal_loss 0.10195  dice_loss 0.29189 
Epoch [43/300] Validation [16/16] Loss: 0.32181  focal_loss 0.07011  dice_loss 0.25170 
Epoch [43/300] Validation metric {'Val/mean dice_metric': 0.6638223528862, 'Val/mean miou_metric': 0.5483266711235046, 'Val/mean f1': 0.7034212946891785, 'Val/mean precision': 0.709730327129364, 'Val/mean recall': 0.6972233653068542, 'Val/mean hd95_metric': 73.2735366821289}
Cheakpoint...
Epoch [43/300] best acc:tensor([0.6638], device='cuda:0'), Now : mean acc: tensor([0.6638], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6638223528862, 'Val/mean miou_metric': 0.5483266711235046, 'Val/mean f1': 0.7034212946891785, 'Val/mean precision': 0.709730327129364, 'Val/mean recall': 0.6972233653068542, 'Val/mean hd95_metric': 73.2735366821289}
Epoch [44/300] Training [1/62] Loss: 0.39599 
Epoch [44/300] Training [2/62] Loss: 0.44897 
Epoch [44/300] Training [3/62] Loss: 0.37049 
Epoch [44/300] Training [4/62] Loss: 0.48393 
Epoch [44/300] Training [5/62] Loss: 0.35954 
Epoch [44/300] Training [6/62] Loss: 0.51315 
Epoch [44/300] Training [7/62] Loss: 0.47828 
Epoch [44/300] Training [8/62] Loss: 0.65873 
Epoch [44/300] Training [9/62] Loss: 0.46729 
Epoch [44/300] Training [10/62] Loss: 0.33802 
Epoch [44/300] Training [11/62] Loss: 0.38245 
Epoch [44/300] Training [12/62] Loss: 0.67017 
Epoch [44/300] Training [13/62] Loss: 0.28752 
Epoch [44/300] Training [14/62] Loss: 0.41737 
Epoch [44/300] Training [15/62] Loss: 0.28676 
Epoch [44/300] Training [16/62] Loss: 0.31618 
Epoch [44/300] Training [17/62] Loss: 0.46868 
Epoch [44/300] Training [18/62] Loss: 0.57487 
Epoch [44/300] Training [19/62] Loss: 0.45111 
Epoch [44/300] Training [20/62] Loss: 0.28736 
Epoch [44/300] Training [21/62] Loss: 0.40503 
Epoch [44/300] Training [22/62] Loss: 0.71361 
Epoch [44/300] Training [23/62] Loss: 0.44311 
Epoch [44/300] Training [24/62] Loss: 0.35372 
Epoch [44/300] Training [25/62] Loss: 0.38114 
Epoch [44/300] Training [26/62] Loss: 0.60746 
Epoch [44/300] Training [27/62] Loss: 0.51621 
Epoch [44/300] Training [28/62] Loss: 0.42690 
Epoch [44/300] Training [29/62] Loss: 0.43351 
Epoch [44/300] Training [30/62] Loss: 0.45850 
Epoch [44/300] Training [31/62] Loss: 0.37263 
Epoch [44/300] Training [32/62] Loss: 0.42527 
Epoch [44/300] Training [33/62] Loss: 0.54185 
Epoch [44/300] Training [34/62] Loss: 0.51333 
Epoch [44/300] Training [35/62] Loss: 0.53625 
Epoch [44/300] Training [36/62] Loss: 0.46805 
Epoch [44/300] Training [37/62] Loss: 0.39269 
Epoch [44/300] Training [38/62] Loss: 0.63154 
Epoch [44/300] Training [39/62] Loss: 0.80556 
Epoch [44/300] Training [40/62] Loss: 0.60926 
Epoch [44/300] Training [41/62] Loss: 0.49826 
Epoch [44/300] Training [42/62] Loss: 0.31650 
Epoch [44/300] Training [43/62] Loss: 0.44979 
Epoch [44/300] Training [44/62] Loss: 0.34886 
Epoch [44/300] Training [45/62] Loss: 0.42886 
Epoch [44/300] Training [46/62] Loss: 0.32680 
Epoch [44/300] Training [47/62] Loss: 0.59168 
Epoch [44/300] Training [48/62] Loss: 0.56248 
Epoch [44/300] Training [49/62] Loss: 0.47282 
Epoch [44/300] Training [50/62] Loss: 0.64627 
Epoch [44/300] Training [51/62] Loss: 0.56322 
Epoch [44/300] Training [52/62] Loss: 0.39632 
Epoch [44/300] Training [53/62] Loss: 0.50959 
Epoch [44/300] Training [54/62] Loss: 0.26175 
Epoch [44/300] Training [55/62] Loss: 0.45866 
Epoch [44/300] Training [56/62] Loss: 0.39297 
Epoch [44/300] Training [57/62] Loss: 0.48583 
Epoch [44/300] Training [58/62] Loss: 0.46652 
Epoch [44/300] Training [59/62] Loss: 0.55006 
Epoch [44/300] Training [60/62] Loss: 0.45276 
Epoch [44/300] Training [61/62] Loss: 0.37126 
Epoch [44/300] Training [62/62] Loss: 0.22034 
Epoch [44/300] Training metric {'Train/mean dice_metric': 0.6890383958816528, 'Train/mean miou_metric': 0.5730201601982117, 'Train/mean f1': 0.7218034267425537, 'Train/mean precision': 0.7226756811141968, 'Train/mean recall': 0.7209333181381226, 'Train/mean hd95_metric': 71.68062591552734}
Epoch [44/300] Validation [1/16] Loss: 0.52656  focal_loss 0.23147  dice_loss 0.29509 
Epoch [44/300] Validation [2/16] Loss: 0.58991  focal_loss 0.12483  dice_loss 0.46508 
Epoch [44/300] Validation [3/16] Loss: 0.56559  focal_loss 0.16605  dice_loss 0.39954 
Epoch [44/300] Validation [4/16] Loss: 0.50511  focal_loss 0.13795  dice_loss 0.36716 
Epoch [44/300] Validation [5/16] Loss: 0.46695  focal_loss 0.07701  dice_loss 0.38994 
Epoch [44/300] Validation [6/16] Loss: 0.49209  focal_loss 0.11791  dice_loss 0.37419 
Epoch [44/300] Validation [7/16] Loss: 0.36027  focal_loss 0.06778  dice_loss 0.29249 
Epoch [44/300] Validation [8/16] Loss: 0.71943  focal_loss 0.15583  dice_loss 0.56361 
Epoch [44/300] Validation [9/16] Loss: 0.42134  focal_loss 0.11151  dice_loss 0.30983 
Epoch [44/300] Validation [10/16] Loss: 0.57817  focal_loss 0.11075  dice_loss 0.46742 
Epoch [44/300] Validation [11/16] Loss: 0.45126  focal_loss 0.10668  dice_loss 0.34458 
Epoch [44/300] Validation [12/16] Loss: 0.66173  focal_loss 0.09090  dice_loss 0.57083 
Epoch [44/300] Validation [13/16] Loss: 0.55902  focal_loss 0.12920  dice_loss 0.42982 
Epoch [44/300] Validation [14/16] Loss: 0.60311  focal_loss 0.10628  dice_loss 0.49683 
Epoch [44/300] Validation [15/16] Loss: 0.29504  focal_loss 0.04846  dice_loss 0.24658 
Epoch [44/300] Validation [16/16] Loss: 0.31315  focal_loss 0.06699  dice_loss 0.24616 
Epoch [44/300] Validation metric {'Val/mean dice_metric': 0.680246889591217, 'Val/mean miou_metric': 0.5650905966758728, 'Val/mean f1': 0.7146282196044922, 'Val/mean precision': 0.7079132795333862, 'Val/mean recall': 0.7214716672897339, 'Val/mean hd95_metric': 74.49806213378906}
Cheakpoint...
Epoch [44/300] best acc:tensor([0.6802], device='cuda:0'), Now : mean acc: tensor([0.6802], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.680246889591217, 'Val/mean miou_metric': 0.5650905966758728, 'Val/mean f1': 0.7146282196044922, 'Val/mean precision': 0.7079132795333862, 'Val/mean recall': 0.7214716672897339, 'Val/mean hd95_metric': 74.49806213378906}
Epoch [45/300] Training [1/62] Loss: 0.50909 
Epoch [45/300] Training [2/62] Loss: 0.32983 
Epoch [45/300] Training [3/62] Loss: 0.50577 
Epoch [45/300] Training [4/62] Loss: 0.35538 
Epoch [45/300] Training [5/62] Loss: 0.29320 
Epoch [45/300] Training [6/62] Loss: 0.39009 
Epoch [45/300] Training [7/62] Loss: 0.34035 
Epoch [45/300] Training [8/62] Loss: 0.47210 
Epoch [45/300] Training [9/62] Loss: 0.63338 
Epoch [45/300] Training [10/62] Loss: 0.42077 
Epoch [45/300] Training [11/62] Loss: 0.50707 
Epoch [45/300] Training [12/62] Loss: 0.51853 
Epoch [45/300] Training [13/62] Loss: 0.39656 
Epoch [45/300] Training [14/62] Loss: 0.50538 
Epoch [45/300] Training [15/62] Loss: 0.45868 
Epoch [45/300] Training [16/62] Loss: 0.40655 
Epoch [45/300] Training [17/62] Loss: 0.30178 
Epoch [45/300] Training [18/62] Loss: 0.44236 
Epoch [45/300] Training [19/62] Loss: 0.40460 
Epoch [45/300] Training [20/62] Loss: 0.33788 
Epoch [45/300] Training [21/62] Loss: 0.70746 
Epoch [45/300] Training [22/62] Loss: 0.64242 
Epoch [45/300] Training [23/62] Loss: 0.51567 
Epoch [45/300] Training [24/62] Loss: 0.36971 
Epoch [45/300] Training [25/62] Loss: 0.35205 
Epoch [45/300] Training [26/62] Loss: 0.46141 
Epoch [45/300] Training [27/62] Loss: 0.33615 
Epoch [45/300] Training [28/62] Loss: 0.49322 
Epoch [45/300] Training [29/62] Loss: 0.45562 
Epoch [45/300] Training [30/62] Loss: 0.50284 
Epoch [45/300] Training [31/62] Loss: 0.38735 
Epoch [45/300] Training [32/62] Loss: 0.37729 
Epoch [45/300] Training [33/62] Loss: 0.38140 
Epoch [45/300] Training [34/62] Loss: 0.30296 
Epoch [45/300] Training [35/62] Loss: 0.41889 
Epoch [45/300] Training [36/62] Loss: 0.43041 
Epoch [45/300] Training [37/62] Loss: 0.54490 
Epoch [45/300] Training [38/62] Loss: 0.65046 
Epoch [45/300] Training [39/62] Loss: 0.57705 
Epoch [45/300] Training [40/62] Loss: 0.78056 
Epoch [45/300] Training [41/62] Loss: 0.52693 
Epoch [45/300] Training [42/62] Loss: 0.53799 
Epoch [45/300] Training [43/62] Loss: 0.43680 
Epoch [45/300] Training [44/62] Loss: 0.34361 
Epoch [45/300] Training [45/62] Loss: 0.37269 
Epoch [45/300] Training [46/62] Loss: 0.40165 
Epoch [45/300] Training [47/62] Loss: 0.51332 
Epoch [45/300] Training [48/62] Loss: 0.51983 
Epoch [45/300] Training [49/62] Loss: 0.48161 
Epoch [45/300] Training [50/62] Loss: 0.39584 
Epoch [45/300] Training [51/62] Loss: 0.68663 
Epoch [45/300] Training [52/62] Loss: 0.40490 
Epoch [45/300] Training [53/62] Loss: 0.28188 
Epoch [45/300] Training [54/62] Loss: 0.28987 
Epoch [45/300] Training [55/62] Loss: 0.39734 
Epoch [45/300] Training [56/62] Loss: 0.44964 
Epoch [45/300] Training [57/62] Loss: 0.39934 
Epoch [45/300] Training [58/62] Loss: 0.56708 
Epoch [45/300] Training [59/62] Loss: 0.33477 
Epoch [45/300] Training [60/62] Loss: 0.40881 
Epoch [45/300] Training [61/62] Loss: 0.42340 
Epoch [45/300] Training [62/62] Loss: 0.15038 
Epoch [45/300] Training metric {'Train/mean dice_metric': 0.6969382166862488, 'Train/mean miou_metric': 0.5846573710441589, 'Train/mean f1': 0.7336219549179077, 'Train/mean precision': 0.7409594058990479, 'Train/mean recall': 0.7264282703399658, 'Train/mean hd95_metric': 70.91337585449219}
Epoch [45/300] Validation [1/16] Loss: 1.05733  focal_loss 0.41543  dice_loss 0.64190 
Epoch [45/300] Validation [2/16] Loss: 0.94327  focal_loss 0.22753  dice_loss 0.71574 
Epoch [45/300] Validation [3/16] Loss: 0.94147  focal_loss 0.28801  dice_loss 0.65347 
Epoch [45/300] Validation [4/16] Loss: 0.75065  focal_loss 0.19680  dice_loss 0.55385 
Epoch [45/300] Validation [5/16] Loss: 0.64759  focal_loss 0.10108  dice_loss 0.54651 
Epoch [45/300] Validation [6/16] Loss: 0.74087  focal_loss 0.16525  dice_loss 0.57562 
Epoch [45/300] Validation [7/16] Loss: 0.88874  focal_loss 0.28323  dice_loss 0.60550 
Epoch [45/300] Validation [8/16] Loss: 0.77011  focal_loss 0.16908  dice_loss 0.60103 
Epoch [45/300] Validation [9/16] Loss: 0.79559  focal_loss 0.21317  dice_loss 0.58242 
Epoch [45/300] Validation [10/16] Loss: 1.37011  focal_loss 0.46191  dice_loss 0.90820 
Epoch [45/300] Validation [11/16] Loss: 0.74012  focal_loss 0.19242  dice_loss 0.54771 
Epoch [45/300] Validation [12/16] Loss: 0.77483  focal_loss 0.09981  dice_loss 0.67502 
Epoch [45/300] Validation [13/16] Loss: 0.89748  focal_loss 0.26115  dice_loss 0.63634 
Epoch [45/300] Validation [14/16] Loss: 0.86717  focal_loss 0.22482  dice_loss 0.64236 
Epoch [45/300] Validation [15/16] Loss: 1.05784  focal_loss 0.36518  dice_loss 0.69266 
Epoch [45/300] Validation [16/16] Loss: 0.69909  focal_loss 0.20618  dice_loss 0.49291 
Epoch [45/300] Validation metric {'Val/mean dice_metric': 0.6318214535713196, 'Val/mean miou_metric': 0.5264967679977417, 'Val/mean f1': 0.6893981695175171, 'Val/mean precision': 0.7445797324180603, 'Val/mean recall': 0.6418313980102539, 'Val/mean hd95_metric': 75.07981872558594}
Cheakpoint...
Epoch [45/300] best acc:tensor([0.6802], device='cuda:0'), Now : mean acc: tensor([0.6318], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6318214535713196, 'Val/mean miou_metric': 0.5264967679977417, 'Val/mean f1': 0.6893981695175171, 'Val/mean precision': 0.7445797324180603, 'Val/mean recall': 0.6418313980102539, 'Val/mean hd95_metric': 75.07981872558594}
Epoch [46/300] Training [1/62] Loss: 0.49544 
Epoch [46/300] Training [2/62] Loss: 0.41586 
Epoch [46/300] Training [3/62] Loss: 0.39873 
Epoch [46/300] Training [4/62] Loss: 0.43347 
Epoch [46/300] Training [5/62] Loss: 0.62498 
Epoch [46/300] Training [6/62] Loss: 0.41381 
Epoch [46/300] Training [7/62] Loss: 0.45814 
Epoch [46/300] Training [8/62] Loss: 0.43990 
Epoch [46/300] Training [9/62] Loss: 0.22174 
Epoch [46/300] Training [10/62] Loss: 0.34702 
Epoch [46/300] Training [11/62] Loss: 0.44924 
Epoch [46/300] Training [12/62] Loss: 0.81829 
Epoch [46/300] Training [13/62] Loss: 0.52577 
Epoch [46/300] Training [14/62] Loss: 0.58957 
Epoch [46/300] Training [15/62] Loss: 0.30571 
Epoch [46/300] Training [16/62] Loss: 0.53926 
Epoch [46/300] Training [17/62] Loss: 0.88432 
Epoch [46/300] Training [18/62] Loss: 0.42640 
Epoch [46/300] Training [19/62] Loss: 0.42580 
Epoch [46/300] Training [20/62] Loss: 0.38457 
Epoch [46/300] Training [21/62] Loss: 0.27517 
Epoch [46/300] Training [22/62] Loss: 0.47142 
Epoch [46/300] Training [23/62] Loss: 0.34589 
Epoch [46/300] Training [24/62] Loss: 0.42116 
Epoch [46/300] Training [25/62] Loss: 0.45090 
Epoch [46/300] Training [26/62] Loss: 0.36003 
Epoch [46/300] Training [27/62] Loss: 0.59976 
Epoch [46/300] Training [28/62] Loss: 0.50634 
Epoch [46/300] Training [29/62] Loss: 0.50524 
Epoch [46/300] Training [30/62] Loss: 0.44710 
Epoch [46/300] Training [31/62] Loss: 0.37773 
Epoch [46/300] Training [32/62] Loss: 0.35285 
Epoch [46/300] Training [33/62] Loss: 0.37405 
Epoch [46/300] Training [34/62] Loss: 0.45236 
Epoch [46/300] Training [35/62] Loss: 0.43191 
Epoch [46/300] Training [36/62] Loss: 0.41993 
Epoch [46/300] Training [37/62] Loss: 0.43055 
Epoch [46/300] Training [38/62] Loss: 0.38433 
Epoch [46/300] Training [39/62] Loss: 0.52589 
Epoch [46/300] Training [40/62] Loss: 0.55934 
Epoch [46/300] Training [41/62] Loss: 0.41860 
Epoch [46/300] Training [42/62] Loss: 0.42413 
Epoch [46/300] Training [43/62] Loss: 0.45604 
Epoch [46/300] Training [44/62] Loss: 0.37043 
Epoch [46/300] Training [45/62] Loss: 0.40595 
Epoch [46/300] Training [46/62] Loss: 0.22824 
Epoch [46/300] Training [47/62] Loss: 0.51567 
Epoch [46/300] Training [48/62] Loss: 0.28394 
Epoch [46/300] Training [49/62] Loss: 0.36288 
Epoch [46/300] Training [50/62] Loss: 0.37050 
Epoch [46/300] Training [51/62] Loss: 0.75878 
Epoch [46/300] Training [52/62] Loss: 0.50758 
Epoch [46/300] Training [53/62] Loss: 0.61555 
Epoch [46/300] Training [54/62] Loss: 0.55658 
Epoch [46/300] Training [55/62] Loss: 0.57082 
Epoch [46/300] Training [56/62] Loss: 0.39037 
Epoch [46/300] Training [57/62] Loss: 0.55094 
Epoch [46/300] Training [58/62] Loss: 0.60673 
Epoch [46/300] Training [59/62] Loss: 0.53314 
Epoch [46/300] Training [60/62] Loss: 0.27375 
Epoch [46/300] Training [61/62] Loss: 0.39096 
Epoch [46/300] Training [62/62] Loss: 1.20467 
Epoch [46/300] Training metric {'Train/mean dice_metric': 0.6841867566108704, 'Train/mean miou_metric': 0.5702023506164551, 'Train/mean f1': 0.7267355918884277, 'Train/mean precision': 0.7320827841758728, 'Train/mean recall': 0.7214658856391907, 'Train/mean hd95_metric': 70.0226058959961}
Epoch [46/300] Validation [1/16] Loss: 0.59493  focal_loss 0.27046  dice_loss 0.32447 
Epoch [46/300] Validation [2/16] Loss: 0.65719  focal_loss 0.16954  dice_loss 0.48766 
Epoch [46/300] Validation [3/16] Loss: 0.62855  focal_loss 0.19351  dice_loss 0.43504 
Epoch [46/300] Validation [4/16] Loss: 0.47645  focal_loss 0.12526  dice_loss 0.35119 
Epoch [46/300] Validation [5/16] Loss: 0.51993  focal_loss 0.09757  dice_loss 0.42236 
Epoch [46/300] Validation [6/16] Loss: 0.49413  focal_loss 0.09231  dice_loss 0.40183 
Epoch [46/300] Validation [7/16] Loss: 0.39489  focal_loss 0.09973  dice_loss 0.29515 
Epoch [46/300] Validation [8/16] Loss: 0.56987  focal_loss 0.14798  dice_loss 0.42189 
Epoch [46/300] Validation [9/16] Loss: 0.58014  focal_loss 0.16720  dice_loss 0.41294 
Epoch [46/300] Validation [10/16] Loss: 0.67745  focal_loss 0.17601  dice_loss 0.50144 
Epoch [46/300] Validation [11/16] Loss: 0.39008  focal_loss 0.11124  dice_loss 0.27883 
Epoch [46/300] Validation [12/16] Loss: 0.61444  focal_loss 0.09982  dice_loss 0.51462 
Epoch [46/300] Validation [13/16] Loss: 0.40219  focal_loss 0.07793  dice_loss 0.32427 
Epoch [46/300] Validation [14/16] Loss: 0.80265  focal_loss 0.20206  dice_loss 0.60060 
Epoch [46/300] Validation [15/16] Loss: 0.44136  focal_loss 0.14128  dice_loss 0.30007 
Epoch [46/300] Validation [16/16] Loss: 0.40752  focal_loss 0.12192  dice_loss 0.28560 
Epoch [46/300] Validation metric {'Val/mean dice_metric': 0.6725856065750122, 'Val/mean miou_metric': 0.5574225187301636, 'Val/mean f1': 0.7086710929870605, 'Val/mean precision': 0.6952230334281921, 'Val/mean recall': 0.7226496934890747, 'Val/mean hd95_metric': 72.77967834472656}
Cheakpoint...
Epoch [46/300] best acc:tensor([0.6802], device='cuda:0'), Now : mean acc: tensor([0.6726], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6725856065750122, 'Val/mean miou_metric': 0.5574225187301636, 'Val/mean f1': 0.7086710929870605, 'Val/mean precision': 0.6952230334281921, 'Val/mean recall': 0.7226496934890747, 'Val/mean hd95_metric': 72.77967834472656}
Epoch [47/300] Training [1/62] Loss: 0.39427 
Epoch [47/300] Training [2/62] Loss: 0.50287 
Epoch [47/300] Training [3/62] Loss: 0.55696 
Epoch [47/300] Training [4/62] Loss: 0.52592 
Epoch [47/300] Training [5/62] Loss: 0.48936 
Epoch [47/300] Training [6/62] Loss: 0.47136 
Epoch [47/300] Training [7/62] Loss: 0.57038 
Epoch [47/300] Training [8/62] Loss: 0.42487 
Epoch [47/300] Training [9/62] Loss: 0.36532 
Epoch [47/300] Training [10/62] Loss: 0.49778 
Epoch [47/300] Training [11/62] Loss: 0.34952 
Epoch [47/300] Training [12/62] Loss: 0.31967 
Epoch [47/300] Training [13/62] Loss: 0.28380 
Epoch [47/300] Training [14/62] Loss: 0.42339 
Epoch [47/300] Training [15/62] Loss: 0.33970 
Epoch [47/300] Training [16/62] Loss: 0.72206 
Epoch [47/300] Training [17/62] Loss: 0.43602 
Epoch [47/300] Training [18/62] Loss: 0.57823 
Epoch [47/300] Training [19/62] Loss: 0.46494 
Epoch [47/300] Training [20/62] Loss: 0.37276 
Epoch [47/300] Training [21/62] Loss: 0.35844 
Epoch [47/300] Training [22/62] Loss: 0.42710 
Epoch [47/300] Training [23/62] Loss: 0.32642 
Epoch [47/300] Training [24/62] Loss: 0.22138 
Epoch [47/300] Training [25/62] Loss: 0.62900 
Epoch [47/300] Training [26/62] Loss: 0.23115 
Epoch [47/300] Training [27/62] Loss: 0.31502 
Epoch [47/300] Training [28/62] Loss: 0.51401 
Epoch [47/300] Training [29/62] Loss: 0.29134 
Epoch [47/300] Training [30/62] Loss: 0.39171 
Epoch [47/300] Training [31/62] Loss: 0.48251 
Epoch [47/300] Training [32/62] Loss: 0.44774 
Epoch [47/300] Training [33/62] Loss: 0.59414 
Epoch [47/300] Training [34/62] Loss: 0.43964 
Epoch [47/300] Training [35/62] Loss: 0.43031 
Epoch [47/300] Training [36/62] Loss: 0.58693 
Epoch [47/300] Training [37/62] Loss: 0.42226 
Epoch [47/300] Training [38/62] Loss: 0.45928 
Epoch [47/300] Training [39/62] Loss: 0.45722 
Epoch [47/300] Training [40/62] Loss: 0.36877 
Epoch [47/300] Training [41/62] Loss: 0.52059 
Epoch [47/300] Training [42/62] Loss: 0.58302 
Epoch [47/300] Training [43/62] Loss: 0.61263 
Epoch [47/300] Training [44/62] Loss: 0.61631 
Epoch [47/300] Training [45/62] Loss: 0.73416 
Epoch [47/300] Training [46/62] Loss: 0.49970 
Epoch [47/300] Training [47/62] Loss: 0.54570 
Epoch [47/300] Training [48/62] Loss: 0.47595 
Epoch [47/300] Training [49/62] Loss: 0.47466 
Epoch [47/300] Training [50/62] Loss: 0.60063 
Epoch [47/300] Training [51/62] Loss: 0.44495 
Epoch [47/300] Training [52/62] Loss: 0.28757 
Epoch [47/300] Training [53/62] Loss: 0.35207 
Epoch [47/300] Training [54/62] Loss: 0.56567 
Epoch [47/300] Training [55/62] Loss: 0.60752 
Epoch [47/300] Training [56/62] Loss: 0.52134 
Epoch [47/300] Training [57/62] Loss: 0.64204 
Epoch [47/300] Training [58/62] Loss: 0.56064 
Epoch [47/300] Training [59/62] Loss: 0.30132 
Epoch [47/300] Training [60/62] Loss: 0.35220 
Epoch [47/300] Training [61/62] Loss: 0.56676 
Epoch [47/300] Training [62/62] Loss: 0.18500 
Epoch [47/300] Training metric {'Train/mean dice_metric': 0.6857933402061462, 'Train/mean miou_metric': 0.5719483494758606, 'Train/mean f1': 0.7234781384468079, 'Train/mean precision': 0.7264960408210754, 'Train/mean recall': 0.7204851508140564, 'Train/mean hd95_metric': 73.1302490234375}
Epoch [47/300] Validation [1/16] Loss: 0.91618  focal_loss 0.40731  dice_loss 0.50888 
Epoch [47/300] Validation [2/16] Loss: 0.67017  focal_loss 0.15330  dice_loss 0.51687 
Epoch [47/300] Validation [3/16] Loss: 0.58705  focal_loss 0.16708  dice_loss 0.41997 
Epoch [47/300] Validation [4/16] Loss: 0.51959  focal_loss 0.15753  dice_loss 0.36207 
Epoch [47/300] Validation [5/16] Loss: 0.49849  focal_loss 0.07653  dice_loss 0.42195 
Epoch [47/300] Validation [6/16] Loss: 0.49505  focal_loss 0.11210  dice_loss 0.38295 
Epoch [47/300] Validation [7/16] Loss: 0.62051  focal_loss 0.14814  dice_loss 0.47237 
Epoch [47/300] Validation [8/16] Loss: 0.73728  focal_loss 0.17652  dice_loss 0.56076 
Epoch [47/300] Validation [9/16] Loss: 0.69670  focal_loss 0.18996  dice_loss 0.50675 
Epoch [47/300] Validation [10/16] Loss: 0.81526  focal_loss 0.19801  dice_loss 0.61725 
Epoch [47/300] Validation [11/16] Loss: 0.57240  focal_loss 0.11508  dice_loss 0.45731 
Epoch [47/300] Validation [12/16] Loss: 0.56081  focal_loss 0.07548  dice_loss 0.48533 
Epoch [47/300] Validation [13/16] Loss: 0.45964  focal_loss 0.11030  dice_loss 0.34934 
Epoch [47/300] Validation [14/16] Loss: 0.83092  focal_loss 0.20581  dice_loss 0.62511 
Epoch [47/300] Validation [15/16] Loss: 0.65469  focal_loss 0.23449  dice_loss 0.42020 
Epoch [47/300] Validation [16/16] Loss: 0.36121  focal_loss 0.08648  dice_loss 0.27473 
Epoch [47/300] Validation metric {'Val/mean dice_metric': 0.6601900458335876, 'Val/mean miou_metric': 0.5471041798591614, 'Val/mean f1': 0.7001549005508423, 'Val/mean precision': 0.7157803773880005, 'Val/mean recall': 0.6851970553398132, 'Val/mean hd95_metric': 74.89754486083984}
Cheakpoint...
Epoch [47/300] best acc:tensor([0.6802], device='cuda:0'), Now : mean acc: tensor([0.6602], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6601900458335876, 'Val/mean miou_metric': 0.5471041798591614, 'Val/mean f1': 0.7001549005508423, 'Val/mean precision': 0.7157803773880005, 'Val/mean recall': 0.6851970553398132, 'Val/mean hd95_metric': 74.89754486083984}
Epoch [48/300] Training [1/62] Loss: 0.44515 
Epoch [48/300] Training [2/62] Loss: 0.63229 
Epoch [48/300] Training [3/62] Loss: 0.44294 
Epoch [48/300] Training [4/62] Loss: 0.52680 
Epoch [48/300] Training [5/62] Loss: 0.49808 
Epoch [48/300] Training [6/62] Loss: 0.31190 
Epoch [48/300] Training [7/62] Loss: 0.40967 
Epoch [48/300] Training [8/62] Loss: 0.36719 
Epoch [48/300] Training [9/62] Loss: 0.45933 
Epoch [48/300] Training [10/62] Loss: 0.33934 
Epoch [48/300] Training [11/62] Loss: 0.61956 
Epoch [48/300] Training [12/62] Loss: 0.44574 
Epoch [48/300] Training [13/62] Loss: 0.39783 
Epoch [48/300] Training [14/62] Loss: 0.39447 
Epoch [48/300] Training [15/62] Loss: 0.36592 
Epoch [48/300] Training [16/62] Loss: 0.38397 
Epoch [48/300] Training [17/62] Loss: 0.26969 
Epoch [48/300] Training [18/62] Loss: 0.33127 
Epoch [48/300] Training [19/62] Loss: 0.79244 
Epoch [48/300] Training [20/62] Loss: 0.25346 
Epoch [48/300] Training [21/62] Loss: 0.44676 
Epoch [48/300] Training [22/62] Loss: 0.30766 
Epoch [48/300] Training [23/62] Loss: 0.51699 
Epoch [48/300] Training [24/62] Loss: 0.56861 
Epoch [48/300] Training [25/62] Loss: 0.29761 
Epoch [48/300] Training [26/62] Loss: 0.54426 
Epoch [48/300] Training [27/62] Loss: 0.43513 
Epoch [48/300] Training [28/62] Loss: 0.41383 
Epoch [48/300] Training [29/62] Loss: 0.49959 
Epoch [48/300] Training [30/62] Loss: 0.27718 
Epoch [48/300] Training [31/62] Loss: 0.43140 
Epoch [48/300] Training [32/62] Loss: 0.49645 
Epoch [48/300] Training [33/62] Loss: 0.44340 
Epoch [48/300] Training [34/62] Loss: 0.70013 
Epoch [48/300] Training [35/62] Loss: 0.39821 
Epoch [48/300] Training [36/62] Loss: 0.59793 
Epoch [48/300] Training [37/62] Loss: 0.55736 
Epoch [48/300] Training [38/62] Loss: 0.38477 
Epoch [48/300] Training [39/62] Loss: 0.58523 
Epoch [48/300] Training [40/62] Loss: 0.25972 
Epoch [48/300] Training [41/62] Loss: 0.32084 
Epoch [48/300] Training [42/62] Loss: 0.33227 
Epoch [48/300] Training [43/62] Loss: 0.68621 
Epoch [48/300] Training [44/62] Loss: 0.40192 
Epoch [48/300] Training [45/62] Loss: 0.47973 
Epoch [48/300] Training [46/62] Loss: 0.45257 
Epoch [48/300] Training [47/62] Loss: 0.61037 
Epoch [48/300] Training [48/62] Loss: 0.35681 
Epoch [48/300] Training [49/62] Loss: 0.21088 
Epoch [48/300] Training [50/62] Loss: 0.38949 
Epoch [48/300] Training [51/62] Loss: 0.43629 
Epoch [48/300] Training [52/62] Loss: 0.36454 
Epoch [48/300] Training [53/62] Loss: 0.47775 
Epoch [48/300] Training [54/62] Loss: 0.52335 
Epoch [48/300] Training [55/62] Loss: 0.56594 
Epoch [48/300] Training [56/62] Loss: 0.42269 
Epoch [48/300] Training [57/62] Loss: 0.45732 
Epoch [48/300] Training [58/62] Loss: 0.43025 
Epoch [48/300] Training [59/62] Loss: 0.46439 
Epoch [48/300] Training [60/62] Loss: 0.27221 
Epoch [48/300] Training [61/62] Loss: 0.26260 
Epoch [48/300] Training [62/62] Loss: 0.37611 
Epoch [48/300] Training metric {'Train/mean dice_metric': 0.7009227871894836, 'Train/mean miou_metric': 0.5871185064315796, 'Train/mean f1': 0.7372735738754272, 'Train/mean precision': 0.7547599673271179, 'Train/mean recall': 0.7205790877342224, 'Train/mean hd95_metric': 65.95915985107422}
Epoch [48/300] Validation [1/16] Loss: 0.72642  focal_loss 0.26192  dice_loss 0.46450 
Epoch [48/300] Validation [2/16] Loss: 0.80704  focal_loss 0.18029  dice_loss 0.62674 
Epoch [48/300] Validation [3/16] Loss: 0.86192  focal_loss 0.25999  dice_loss 0.60193 
Epoch [48/300] Validation [4/16] Loss: 0.65122  focal_loss 0.14626  dice_loss 0.50496 
Epoch [48/300] Validation [5/16] Loss: 0.52936  focal_loss 0.06334  dice_loss 0.46602 
Epoch [48/300] Validation [6/16] Loss: 0.52689  focal_loss 0.08462  dice_loss 0.44227 
Epoch [48/300] Validation [7/16] Loss: 0.65037  focal_loss 0.14219  dice_loss 0.50818 
Epoch [48/300] Validation [8/16] Loss: 0.84791  focal_loss 0.18176  dice_loss 0.66616 
Epoch [48/300] Validation [9/16] Loss: 0.72536  focal_loss 0.16300  dice_loss 0.56236 
Epoch [48/300] Validation [10/16] Loss: 0.89311  focal_loss 0.26242  dice_loss 0.63070 
Epoch [48/300] Validation [11/16] Loss: 0.69285  focal_loss 0.15759  dice_loss 0.53526 
Epoch [48/300] Validation [12/16] Loss: 0.67965  focal_loss 0.08837  dice_loss 0.59128 
Epoch [48/300] Validation [13/16] Loss: 0.67024  focal_loss 0.15067  dice_loss 0.51957 
Epoch [48/300] Validation [14/16] Loss: 1.01694  focal_loss 0.28934  dice_loss 0.72761 
Epoch [48/300] Validation [15/16] Loss: 0.73139  focal_loss 0.20275  dice_loss 0.52864 
Epoch [48/300] Validation [16/16] Loss: 0.49385  focal_loss 0.13052  dice_loss 0.36334 
Epoch [48/300] Validation metric {'Val/mean dice_metric': 0.6598080396652222, 'Val/mean miou_metric': 0.5453519225120544, 'Val/mean f1': 0.6945849657058716, 'Val/mean precision': 0.7014321684837341, 'Val/mean recall': 0.6878702044487, 'Val/mean hd95_metric': 73.62873077392578}
Cheakpoint...
Epoch [48/300] best acc:tensor([0.6802], device='cuda:0'), Now : mean acc: tensor([0.6598], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6598080396652222, 'Val/mean miou_metric': 0.5453519225120544, 'Val/mean f1': 0.6945849657058716, 'Val/mean precision': 0.7014321684837341, 'Val/mean recall': 0.6878702044487, 'Val/mean hd95_metric': 73.62873077392578}
Epoch [49/300] Training [1/62] Loss: 0.46700 
Epoch [49/300] Training [2/62] Loss: 0.29999 
Epoch [49/300] Training [3/62] Loss: 0.42385 
Epoch [49/300] Training [4/62] Loss: 0.40999 
Epoch [49/300] Training [5/62] Loss: 0.48941 
Epoch [49/300] Training [6/62] Loss: 0.50450 
Epoch [49/300] Training [7/62] Loss: 0.30494 
Epoch [49/300] Training [8/62] Loss: 0.53128 
Epoch [49/300] Training [9/62] Loss: 0.59076 
Epoch [49/300] Training [10/62] Loss: 0.37197 
Epoch [49/300] Training [11/62] Loss: 0.23739 
Epoch [49/300] Training [12/62] Loss: 0.48801 
Epoch [49/300] Training [13/62] Loss: 0.32477 
Epoch [49/300] Training [14/62] Loss: 0.58423 
Epoch [49/300] Training [15/62] Loss: 0.72840 
Epoch [49/300] Training [16/62] Loss: 0.38928 
Epoch [49/300] Training [17/62] Loss: 0.32599 
Epoch [49/300] Training [18/62] Loss: 0.43339 
Epoch [49/300] Training [19/62] Loss: 0.27830 
Epoch [49/300] Training [20/62] Loss: 0.41144 
Epoch [49/300] Training [21/62] Loss: 0.52014 
Epoch [49/300] Training [22/62] Loss: 0.37764 
Epoch [49/300] Training [23/62] Loss: 0.33136 
Epoch [49/300] Training [24/62] Loss: 0.48291 
Epoch [49/300] Training [25/62] Loss: 0.27351 
Epoch [49/300] Training [26/62] Loss: 0.46858 
Epoch [49/300] Training [27/62] Loss: 0.65307 
Epoch [49/300] Training [28/62] Loss: 0.44544 
Epoch [49/300] Training [29/62] Loss: 0.50032 
Epoch [49/300] Training [30/62] Loss: 0.46030 
Epoch [49/300] Training [31/62] Loss: 0.46309 
Epoch [49/300] Training [32/62] Loss: 0.32644 
Epoch [49/300] Training [33/62] Loss: 0.43228 
Epoch [49/300] Training [34/62] Loss: 0.60467 
Epoch [49/300] Training [35/62] Loss: 0.36515 
Epoch [49/300] Training [36/62] Loss: 0.51685 
Epoch [49/300] Training [37/62] Loss: 0.35778 
Epoch [49/300] Training [38/62] Loss: 0.35644 
Epoch [49/300] Training [39/62] Loss: 0.41814 
Epoch [49/300] Training [40/62] Loss: 0.46019 
Epoch [49/300] Training [41/62] Loss: 0.33550 
Epoch [49/300] Training [42/62] Loss: 0.50208 
Epoch [49/300] Training [43/62] Loss: 0.45449 
Epoch [49/300] Training [44/62] Loss: 0.59323 
Epoch [49/300] Training [45/62] Loss: 0.38525 
Epoch [49/300] Training [46/62] Loss: 0.66249 
Epoch [49/300] Training [47/62] Loss: 0.24346 
Epoch [49/300] Training [48/62] Loss: 0.45583 
Epoch [49/300] Training [49/62] Loss: 0.65402 
Epoch [49/300] Training [50/62] Loss: 0.38095 
Epoch [49/300] Training [51/62] Loss: 0.53451 
Epoch [49/300] Training [52/62] Loss: 0.43841 
Epoch [49/300] Training [53/62] Loss: 0.46224 
Epoch [49/300] Training [54/62] Loss: 0.85502 
Epoch [49/300] Training [55/62] Loss: 0.43532 
Epoch [49/300] Training [56/62] Loss: 0.34507 
Epoch [49/300] Training [57/62] Loss: 0.22101 
Epoch [49/300] Training [58/62] Loss: 0.40727 
Epoch [49/300] Training [59/62] Loss: 0.33516 
Epoch [49/300] Training [60/62] Loss: 0.49578 
Epoch [49/300] Training [61/62] Loss: 0.22686 
Epoch [49/300] Training [62/62] Loss: 0.49944 
Epoch [49/300] Training metric {'Train/mean dice_metric': 0.7023556232452393, 'Train/mean miou_metric': 0.5893116593360901, 'Train/mean f1': 0.7322847843170166, 'Train/mean precision': 0.7412500381469727, 'Train/mean recall': 0.7235336899757385, 'Train/mean hd95_metric': 67.12274932861328}
Epoch [49/300] Validation [1/16] Loss: 0.60434  focal_loss 0.25826  dice_loss 0.34608 
Epoch [49/300] Validation [2/16] Loss: 0.66623  focal_loss 0.17691  dice_loss 0.48932 
Epoch [49/300] Validation [3/16] Loss: 0.63382  focal_loss 0.17976  dice_loss 0.45406 
Epoch [49/300] Validation [4/16] Loss: 0.56777  focal_loss 0.15517  dice_loss 0.41259 
Epoch [49/300] Validation [5/16] Loss: 0.42231  focal_loss 0.05897  dice_loss 0.36334 
Epoch [49/300] Validation [6/16] Loss: 0.52108  focal_loss 0.12669  dice_loss 0.39439 
Epoch [49/300] Validation [7/16] Loss: 0.73944  focal_loss 0.21588  dice_loss 0.52356 
Epoch [49/300] Validation [8/16] Loss: 0.60392  focal_loss 0.11297  dice_loss 0.49095 
Epoch [49/300] Validation [9/16] Loss: 0.50993  focal_loss 0.14123  dice_loss 0.36870 
Epoch [49/300] Validation [10/16] Loss: 0.81640  focal_loss 0.24393  dice_loss 0.57246 
Epoch [49/300] Validation [11/16] Loss: 0.60701  focal_loss 0.16692  dice_loss 0.44009 
Epoch [49/300] Validation [12/16] Loss: 0.51572  focal_loss 0.06653  dice_loss 0.44919 
Epoch [49/300] Validation [13/16] Loss: 0.45495  focal_loss 0.10158  dice_loss 0.35336 
Epoch [49/300] Validation [14/16] Loss: 1.01622  focal_loss 0.28313  dice_loss 0.73309 
Epoch [49/300] Validation [15/16] Loss: 0.62328  focal_loss 0.21290  dice_loss 0.41038 
Epoch [49/300] Validation [16/16] Loss: 0.27482  focal_loss 0.07559  dice_loss 0.19923 
Epoch [49/300] Validation metric {'Val/mean dice_metric': 0.6790990233421326, 'Val/mean miou_metric': 0.5669224262237549, 'Val/mean f1': 0.7146152257919312, 'Val/mean precision': 0.7478653192520142, 'Val/mean recall': 0.6841958165168762, 'Val/mean hd95_metric': 67.8006362915039}
Cheakpoint...
Epoch [49/300] best acc:tensor([0.6802], device='cuda:0'), Now : mean acc: tensor([0.6791], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6790990233421326, 'Val/mean miou_metric': 0.5669224262237549, 'Val/mean f1': 0.7146152257919312, 'Val/mean precision': 0.7478653192520142, 'Val/mean recall': 0.6841958165168762, 'Val/mean hd95_metric': 67.8006362915039}
Epoch [50/300] Training [1/62] Loss: 0.26592 
Epoch [50/300] Training [2/62] Loss: 0.24961 
Epoch [50/300] Training [3/62] Loss: 0.24831 
Epoch [50/300] Training [4/62] Loss: 0.54463 
Epoch [50/300] Training [5/62] Loss: 0.49985 
Epoch [50/300] Training [6/62] Loss: 0.36014 
Epoch [50/300] Training [7/62] Loss: 0.35798 
Epoch [50/300] Training [8/62] Loss: 0.34191 
Epoch [50/300] Training [9/62] Loss: 0.40549 
Epoch [50/300] Training [10/62] Loss: 0.32834 
Epoch [50/300] Training [11/62] Loss: 0.44228 
Epoch [50/300] Training [12/62] Loss: 0.23637 
Epoch [50/300] Training [13/62] Loss: 0.42818 
Epoch [50/300] Training [14/62] Loss: 0.36996 
Epoch [50/300] Training [15/62] Loss: 0.45273 
Epoch [50/300] Training [16/62] Loss: 0.28433 
Epoch [50/300] Training [17/62] Loss: 0.46875 
Epoch [50/300] Training [18/62] Loss: 0.38905 
Epoch [50/300] Training [19/62] Loss: 0.34810 
Epoch [50/300] Training [20/62] Loss: 0.52870 
Epoch [50/300] Training [21/62] Loss: 0.44447 
Epoch [50/300] Training [22/62] Loss: 0.84434 
Epoch [50/300] Training [23/62] Loss: 0.39989 
Epoch [50/300] Training [24/62] Loss: 0.38232 
Epoch [50/300] Training [25/62] Loss: 0.32197 
Epoch [50/300] Training [26/62] Loss: 0.29540 
Epoch [50/300] Training [27/62] Loss: 0.30699 
Epoch [50/300] Training [28/62] Loss: 0.34316 
Epoch [50/300] Training [29/62] Loss: 0.28906 
Epoch [50/300] Training [30/62] Loss: 0.35840 
Epoch [50/300] Training [31/62] Loss: 0.43827 
Epoch [50/300] Training [32/62] Loss: 0.27769 
Epoch [50/300] Training [33/62] Loss: 0.41289 
Epoch [50/300] Training [34/62] Loss: 0.51642 
Epoch [50/300] Training [35/62] Loss: 0.35043 
Epoch [50/300] Training [36/62] Loss: 0.34433 
Epoch [50/300] Training [37/62] Loss: 0.28796 
Epoch [50/300] Training [38/62] Loss: 0.72298 
Epoch [50/300] Training [39/62] Loss: 0.32785 
Epoch [50/300] Training [40/62] Loss: 0.70567 
Epoch [50/300] Training [41/62] Loss: 0.55545 
Epoch [50/300] Training [42/62] Loss: 0.40116 
Epoch [50/300] Training [43/62] Loss: 0.37783 
Epoch [50/300] Training [44/62] Loss: 0.46645 
Epoch [50/300] Training [45/62] Loss: 0.71718 
Epoch [50/300] Training [46/62] Loss: 0.42555 
Epoch [50/300] Training [47/62] Loss: 0.45092 
Epoch [50/300] Training [48/62] Loss: 0.33771 
Epoch [50/300] Training [49/62] Loss: 0.27486 
Epoch [50/300] Training [50/62] Loss: 0.59501 
Epoch [50/300] Training [51/62] Loss: 0.28162 
Epoch [50/300] Training [52/62] Loss: 0.25623 
Epoch [50/300] Training [53/62] Loss: 0.57222 
Epoch [50/300] Training [54/62] Loss: 0.48322 
Epoch [50/300] Training [55/62] Loss: 0.40391 
Epoch [50/300] Training [56/62] Loss: 0.44915 
Epoch [50/300] Training [57/62] Loss: 0.38089 
Epoch [50/300] Training [58/62] Loss: 0.55608 
Epoch [50/300] Training [59/62] Loss: 0.52003 
Epoch [50/300] Training [60/62] Loss: 0.50540 
Epoch [50/300] Training [61/62] Loss: 0.36540 
Epoch [50/300] Training [62/62] Loss: 0.49831 
Epoch [50/300] Training metric {'Train/mean dice_metric': 0.7204023003578186, 'Train/mean miou_metric': 0.614964485168457, 'Train/mean f1': 0.7597576975822449, 'Train/mean precision': 0.7710297107696533, 'Train/mean recall': 0.7488105893135071, 'Train/mean hd95_metric': 63.99538803100586}
Epoch [50/300] Validation [1/16] Loss: 0.64636  focal_loss 0.30901  dice_loss 0.33735 
Epoch [50/300] Validation [2/16] Loss: 0.72120  focal_loss 0.14867  dice_loss 0.57254 
Epoch [50/300] Validation [3/16] Loss: 0.71498  focal_loss 0.18555  dice_loss 0.52943 
Epoch [50/300] Validation [4/16] Loss: 0.74523  focal_loss 0.23358  dice_loss 0.51165 
Epoch [50/300] Validation [5/16] Loss: 0.52315  focal_loss 0.10074  dice_loss 0.42241 
Epoch [50/300] Validation [6/16] Loss: 0.49768  focal_loss 0.11716  dice_loss 0.38052 
Epoch [50/300] Validation [7/16] Loss: 0.51658  focal_loss 0.10605  dice_loss 0.41053 
Epoch [50/300] Validation [8/16] Loss: 0.81086  focal_loss 0.22135  dice_loss 0.58952 
Epoch [50/300] Validation [9/16] Loss: 0.42091  focal_loss 0.06410  dice_loss 0.35681 
Epoch [50/300] Validation [10/16] Loss: 0.78360  focal_loss 0.24951  dice_loss 0.53409 
Epoch [50/300] Validation [11/16] Loss: 0.45273  focal_loss 0.08816  dice_loss 0.36457 
Epoch [50/300] Validation [12/16] Loss: 0.81672  focal_loss 0.14504  dice_loss 0.67168 
Epoch [50/300] Validation [13/16] Loss: 0.56456  focal_loss 0.12304  dice_loss 0.44152 
Epoch [50/300] Validation [14/16] Loss: 0.81948  focal_loss 0.17294  dice_loss 0.64655 
Epoch [50/300] Validation [15/16] Loss: 0.47622  focal_loss 0.10743  dice_loss 0.36879 
Epoch [50/300] Validation [16/16] Loss: 0.36257  focal_loss 0.09244  dice_loss 0.27012 
Epoch [50/300] Validation metric {'Val/mean dice_metric': 0.6877187490463257, 'Val/mean miou_metric': 0.581445574760437, 'Val/mean f1': 0.7311363816261292, 'Val/mean precision': 0.7457635402679443, 'Val/mean recall': 0.717072069644928, 'Val/mean hd95_metric': 68.34742736816406}
Cheakpoint...
Epoch [50/300] best acc:tensor([0.6877], device='cuda:0'), Now : mean acc: tensor([0.6877], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6877187490463257, 'Val/mean miou_metric': 0.581445574760437, 'Val/mean f1': 0.7311363816261292, 'Val/mean precision': 0.7457635402679443, 'Val/mean recall': 0.717072069644928, 'Val/mean hd95_metric': 68.34742736816406}
Epoch [51/300] Training [1/62] Loss: 0.24412 
Epoch [51/300] Training [2/62] Loss: 0.52306 
Epoch [51/300] Training [3/62] Loss: 0.44167 
Epoch [51/300] Training [4/62] Loss: 0.47658 
Epoch [51/300] Training [5/62] Loss: 0.43631 
Epoch [51/300] Training [6/62] Loss: 0.49997 
Epoch [51/300] Training [7/62] Loss: 0.52911 
Epoch [51/300] Training [8/62] Loss: 0.30053 
Epoch [51/300] Training [9/62] Loss: 0.38033 
Epoch [51/300] Training [10/62] Loss: 0.49921 
Epoch [51/300] Training [11/62] Loss: 0.41200 
Epoch [51/300] Training [12/62] Loss: 0.59366 
Epoch [51/300] Training [13/62] Loss: 0.36874 
Epoch [51/300] Training [14/62] Loss: 0.87068 
Epoch [51/300] Training [15/62] Loss: 0.42662 
Epoch [51/300] Training [16/62] Loss: 0.57817 
Epoch [51/300] Training [17/62] Loss: 0.42017 
Epoch [51/300] Training [18/62] Loss: 0.43635 
Epoch [51/300] Training [19/62] Loss: 0.51923 
Epoch [51/300] Training [20/62] Loss: 0.37555 
Epoch [51/300] Training [21/62] Loss: 0.40208 
Epoch [51/300] Training [22/62] Loss: 0.29801 
Epoch [51/300] Training [23/62] Loss: 0.27912 
Epoch [51/300] Training [24/62] Loss: 0.48147 
Epoch [51/300] Training [25/62] Loss: 0.27307 
Epoch [51/300] Training [26/62] Loss: 0.32043 
Epoch [51/300] Training [27/62] Loss: 0.45914 
Epoch [51/300] Training [28/62] Loss: 0.43452 
Epoch [51/300] Training [29/62] Loss: 0.30296 
Epoch [51/300] Training [30/62] Loss: 0.40987 
Epoch [51/300] Training [31/62] Loss: 0.51424 
Epoch [51/300] Training [32/62] Loss: 0.36882 
Epoch [51/300] Training [33/62] Loss: 0.28222 
Epoch [51/300] Training [34/62] Loss: 0.31539 
Epoch [51/300] Training [35/62] Loss: 0.42687 
Epoch [51/300] Training [36/62] Loss: 0.46532 
Epoch [51/300] Training [37/62] Loss: 0.31790 
Epoch [51/300] Training [38/62] Loss: 0.29115 
Epoch [51/300] Training [39/62] Loss: 0.54288 
Epoch [51/300] Training [40/62] Loss: 0.50140 
Epoch [51/300] Training [41/62] Loss: 0.21728 
Epoch [51/300] Training [42/62] Loss: 0.37457 
Epoch [51/300] Training [43/62] Loss: 0.55775 
Epoch [51/300] Training [44/62] Loss: 0.28976 
Epoch [51/300] Training [45/62] Loss: 0.21917 
Epoch [51/300] Training [46/62] Loss: 0.39777 
Epoch [51/300] Training [47/62] Loss: 0.30869 
Epoch [51/300] Training [48/62] Loss: 0.38439 
Epoch [51/300] Training [49/62] Loss: 0.37803 
Epoch [51/300] Training [50/62] Loss: 0.48948 
Epoch [51/300] Training [51/62] Loss: 0.55962 
Epoch [51/300] Training [52/62] Loss: 0.40721 
Epoch [51/300] Training [53/62] Loss: 0.36881 
Epoch [51/300] Training [54/62] Loss: 0.23697 
Epoch [51/300] Training [55/62] Loss: 0.41331 
Epoch [51/300] Training [56/62] Loss: 0.59922 
Epoch [51/300] Training [57/62] Loss: 0.39264 
Epoch [51/300] Training [58/62] Loss: 0.43508 
Epoch [51/300] Training [59/62] Loss: 0.27651 
Epoch [51/300] Training [60/62] Loss: 0.33456 
Epoch [51/300] Training [61/62] Loss: 0.40657 
Epoch [51/300] Training [62/62] Loss: 0.96500 
Epoch [51/300] Training metric {'Train/mean dice_metric': 0.7233129739761353, 'Train/mean miou_metric': 0.6148890256881714, 'Train/mean f1': 0.7576093077659607, 'Train/mean precision': 0.7734435200691223, 'Train/mean recall': 0.7424103617668152, 'Train/mean hd95_metric': 63.792823791503906}
Epoch [51/300] Validation [1/16] Loss: 0.59890  focal_loss 0.30568  dice_loss 0.29322 
Epoch [51/300] Validation [2/16] Loss: 0.51483  focal_loss 0.11190  dice_loss 0.40293 
Epoch [51/300] Validation [3/16] Loss: 0.48725  focal_loss 0.11653  dice_loss 0.37072 
Epoch [51/300] Validation [4/16] Loss: 0.55422  focal_loss 0.15668  dice_loss 0.39753 
Epoch [51/300] Validation [5/16] Loss: 0.54380  focal_loss 0.08905  dice_loss 0.45475 
Epoch [51/300] Validation [6/16] Loss: 0.50071  focal_loss 0.11756  dice_loss 0.38315 
Epoch [51/300] Validation [7/16] Loss: 0.35864  focal_loss 0.07897  dice_loss 0.27968 
Epoch [51/300] Validation [8/16] Loss: 0.53489  focal_loss 0.10364  dice_loss 0.43125 
Epoch [51/300] Validation [9/16] Loss: 0.45556  focal_loss 0.12259  dice_loss 0.33297 
Epoch [51/300] Validation [10/16] Loss: 0.45546  focal_loss 0.09946  dice_loss 0.35600 
Epoch [51/300] Validation [11/16] Loss: 0.43975  focal_loss 0.10155  dice_loss 0.33820 
Epoch [51/300] Validation [12/16] Loss: 0.53213  focal_loss 0.06605  dice_loss 0.46608 
Epoch [51/300] Validation [13/16] Loss: 0.41661  focal_loss 0.10461  dice_loss 0.31200 
Epoch [51/300] Validation [14/16] Loss: 0.74888  focal_loss 0.15259  dice_loss 0.59628 
Epoch [51/300] Validation [15/16] Loss: 0.35169  focal_loss 0.07495  dice_loss 0.27675 
Epoch [51/300] Validation [16/16] Loss: 0.25600  focal_loss 0.05896  dice_loss 0.19705 
Epoch [51/300] Validation metric {'Val/mean dice_metric': 0.7114506363868713, 'Val/mean miou_metric': 0.6012539267539978, 'Val/mean f1': 0.747552752494812, 'Val/mean precision': 0.7585926651954651, 'Val/mean recall': 0.7368295788764954, 'Val/mean hd95_metric': 66.5909652709961}
Cheakpoint...
Epoch [51/300] best acc:tensor([0.7115], device='cuda:0'), Now : mean acc: tensor([0.7115], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7114506363868713, 'Val/mean miou_metric': 0.6012539267539978, 'Val/mean f1': 0.747552752494812, 'Val/mean precision': 0.7585926651954651, 'Val/mean recall': 0.7368295788764954, 'Val/mean hd95_metric': 66.5909652709961}
Epoch [52/300] Training [1/62] Loss: 0.27874 
Epoch [52/300] Training [2/62] Loss: 0.22250 
Epoch [52/300] Training [3/62] Loss: 0.34655 
Epoch [52/300] Training [4/62] Loss: 0.53123 
Epoch [52/300] Training [5/62] Loss: 0.29230 
Epoch [52/300] Training [6/62] Loss: 0.44670 
Epoch [52/300] Training [7/62] Loss: 0.41677 
Epoch [52/300] Training [8/62] Loss: 0.25544 
Epoch [52/300] Training [9/62] Loss: 0.29999 
Epoch [52/300] Training [10/62] Loss: 0.26944 
Epoch [52/300] Training [11/62] Loss: 0.46345 
Epoch [52/300] Training [12/62] Loss: 0.28153 
Epoch [52/300] Training [13/62] Loss: 0.56774 
Epoch [52/300] Training [14/62] Loss: 0.33196 
Epoch [52/300] Training [15/62] Loss: 0.38318 
Epoch [52/300] Training [16/62] Loss: 0.44934 
Epoch [52/300] Training [17/62] Loss: 0.38519 
Epoch [52/300] Training [18/62] Loss: 0.44143 
Epoch [52/300] Training [19/62] Loss: 0.54763 
Epoch [52/300] Training [20/62] Loss: 0.50966 
Epoch [52/300] Training [21/62] Loss: 0.30689 
Epoch [52/300] Training [22/62] Loss: 0.65577 
Epoch [52/300] Training [23/62] Loss: 0.41905 
Epoch [52/300] Training [24/62] Loss: 0.57066 
Epoch [52/300] Training [25/62] Loss: 0.30466 
Epoch [52/300] Training [26/62] Loss: 0.47728 
Epoch [52/300] Training [27/62] Loss: 0.48706 
Epoch [52/300] Training [28/62] Loss: 0.34034 
Epoch [52/300] Training [29/62] Loss: 0.31652 
Epoch [52/300] Training [30/62] Loss: 0.31598 
Epoch [52/300] Training [31/62] Loss: 0.48936 
Epoch [52/300] Training [32/62] Loss: 0.55643 
Epoch [52/300] Training [33/62] Loss: 0.40379 
Epoch [52/300] Training [34/62] Loss: 0.45902 
Epoch [52/300] Training [35/62] Loss: 0.43165 
Epoch [52/300] Training [36/62] Loss: 0.38891 
Epoch [52/300] Training [37/62] Loss: 0.55079 
Epoch [52/300] Training [38/62] Loss: 0.30259 
Epoch [52/300] Training [39/62] Loss: 0.47439 
Epoch [52/300] Training [40/62] Loss: 0.44620 
Epoch [52/300] Training [41/62] Loss: 0.47166 
Epoch [52/300] Training [42/62] Loss: 0.47582 
Epoch [52/300] Training [43/62] Loss: 0.33394 
Epoch [52/300] Training [44/62] Loss: 0.39419 
Epoch [52/300] Training [45/62] Loss: 0.42974 
Epoch [52/300] Training [46/62] Loss: 0.38934 
Epoch [52/300] Training [47/62] Loss: 0.36855 
Epoch [52/300] Training [48/62] Loss: 0.35250 
Epoch [52/300] Training [49/62] Loss: 0.37284 
Epoch [52/300] Training [50/62] Loss: 0.65177 
Epoch [52/300] Training [51/62] Loss: 0.31149 
Epoch [52/300] Training [52/62] Loss: 0.44084 
Epoch [52/300] Training [53/62] Loss: 0.43919 
Epoch [52/300] Training [54/62] Loss: 0.37542 
Epoch [52/300] Training [55/62] Loss: 0.36830 
Epoch [52/300] Training [56/62] Loss: 0.35576 
Epoch [52/300] Training [57/62] Loss: 0.38020 
Epoch [52/300] Training [58/62] Loss: 0.43044 
Epoch [52/300] Training [59/62] Loss: 0.43497 
Epoch [52/300] Training [60/62] Loss: 0.44647 
Epoch [52/300] Training [61/62] Loss: 0.61122 
Epoch [52/300] Training [62/62] Loss: 0.56144 
Epoch [52/300] Training metric {'Train/mean dice_metric': 0.7150731086730957, 'Train/mean miou_metric': 0.606389582157135, 'Train/mean f1': 0.7528073191642761, 'Train/mean precision': 0.7656885981559753, 'Train/mean recall': 0.7403523325920105, 'Train/mean hd95_metric': 64.49166107177734}
Epoch [52/300] Validation [1/16] Loss: 0.64556  focal_loss 0.31963  dice_loss 0.32593 
Epoch [52/300] Validation [2/16] Loss: 0.63376  focal_loss 0.12442  dice_loss 0.50934 
Epoch [52/300] Validation [3/16] Loss: 0.48349  focal_loss 0.10490  dice_loss 0.37859 
Epoch [52/300] Validation [4/16] Loss: 0.50921  focal_loss 0.12512  dice_loss 0.38409 
Epoch [52/300] Validation [5/16] Loss: 0.47297  focal_loss 0.05257  dice_loss 0.42040 
Epoch [52/300] Validation [6/16] Loss: 0.42805  focal_loss 0.10713  dice_loss 0.32092 
Epoch [52/300] Validation [7/16] Loss: 0.33280  focal_loss 0.10060  dice_loss 0.23220 
Epoch [52/300] Validation [8/16] Loss: 0.57470  focal_loss 0.09693  dice_loss 0.47777 
Epoch [52/300] Validation [9/16] Loss: 0.41111  focal_loss 0.08963  dice_loss 0.32148 
Epoch [52/300] Validation [10/16] Loss: 0.58166  focal_loss 0.14156  dice_loss 0.44010 
Epoch [52/300] Validation [11/16] Loss: 0.41222  focal_loss 0.09478  dice_loss 0.31744 
Epoch [52/300] Validation [12/16] Loss: 0.53698  focal_loss 0.08166  dice_loss 0.45531 
Epoch [52/300] Validation [13/16] Loss: 0.34544  focal_loss 0.05839  dice_loss 0.28705 
Epoch [52/300] Validation [14/16] Loss: 0.73027  focal_loss 0.15491  dice_loss 0.57536 
Epoch [52/300] Validation [15/16] Loss: 0.31309  focal_loss 0.06938  dice_loss 0.24370 
Epoch [52/300] Validation [16/16] Loss: 0.32293  focal_loss 0.08554  dice_loss 0.23738 
Epoch [52/300] Validation metric {'Val/mean dice_metric': 0.7042307257652283, 'Val/mean miou_metric': 0.5949927568435669, 'Val/mean f1': 0.739715576171875, 'Val/mean precision': 0.7341663837432861, 'Val/mean recall': 0.7453493475914001, 'Val/mean hd95_metric': 66.87255096435547}
Cheakpoint...
Epoch [52/300] best acc:tensor([0.7115], device='cuda:0'), Now : mean acc: tensor([0.7042], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7042307257652283, 'Val/mean miou_metric': 0.5949927568435669, 'Val/mean f1': 0.739715576171875, 'Val/mean precision': 0.7341663837432861, 'Val/mean recall': 0.7453493475914001, 'Val/mean hd95_metric': 66.87255096435547}
Epoch [53/300] Training [1/62] Loss: 0.30274 
Epoch [53/300] Training [2/62] Loss: 0.41125 
Epoch [53/300] Training [3/62] Loss: 0.39638 
Epoch [53/300] Training [4/62] Loss: 0.38570 
Epoch [53/300] Training [5/62] Loss: 0.49768 
Epoch [53/300] Training [6/62] Loss: 0.41587 
Epoch [53/300] Training [7/62] Loss: 0.37117 
Epoch [53/300] Training [8/62] Loss: 0.54025 
Epoch [53/300] Training [9/62] Loss: 0.47054 
Epoch [53/300] Training [10/62] Loss: 0.35243 
Epoch [53/300] Training [11/62] Loss: 0.42502 
Epoch [53/300] Training [12/62] Loss: 0.20177 
Epoch [53/300] Training [13/62] Loss: 0.70494 
Epoch [53/300] Training [14/62] Loss: 0.23476 
Epoch [53/300] Training [15/62] Loss: 0.30531 
Epoch [53/300] Training [16/62] Loss: 0.28748 
Epoch [53/300] Training [17/62] Loss: 0.46623 
Epoch [53/300] Training [18/62] Loss: 0.60182 
Epoch [53/300] Training [19/62] Loss: 0.65804 
Epoch [53/300] Training [20/62] Loss: 0.38808 
Epoch [53/300] Training [21/62] Loss: 0.53105 
Epoch [53/300] Training [22/62] Loss: 0.45937 
Epoch [53/300] Training [23/62] Loss: 0.33207 
Epoch [53/300] Training [24/62] Loss: 0.45250 
Epoch [53/300] Training [25/62] Loss: 0.44295 
Epoch [53/300] Training [26/62] Loss: 0.30815 
Epoch [53/300] Training [27/62] Loss: 0.66289 
Epoch [53/300] Training [28/62] Loss: 0.30176 
Epoch [53/300] Training [29/62] Loss: 0.35214 
Epoch [53/300] Training [30/62] Loss: 0.53857 
Epoch [53/300] Training [31/62] Loss: 0.29620 
Epoch [53/300] Training [32/62] Loss: 0.43500 
Epoch [53/300] Training [33/62] Loss: 0.43255 
Epoch [53/300] Training [34/62] Loss: 0.52418 
Epoch [53/300] Training [35/62] Loss: 0.66073 
Epoch [53/300] Training [36/62] Loss: 0.32134 
Epoch [53/300] Training [37/62] Loss: 0.51270 
Epoch [53/300] Training [38/62] Loss: 0.43596 
Epoch [53/300] Training [39/62] Loss: 0.33519 
Epoch [53/300] Training [40/62] Loss: 0.32438 
Epoch [53/300] Training [41/62] Loss: 0.35686 
Epoch [53/300] Training [42/62] Loss: 0.30105 
Epoch [53/300] Training [43/62] Loss: 0.62530 
Epoch [53/300] Training [44/62] Loss: 0.43226 
Epoch [53/300] Training [45/62] Loss: 0.32961 
Epoch [53/300] Training [46/62] Loss: 0.32694 
Epoch [53/300] Training [47/62] Loss: 0.24676 
Epoch [53/300] Training [48/62] Loss: 0.41007 
Epoch [53/300] Training [49/62] Loss: 0.28800 
Epoch [53/300] Training [50/62] Loss: 0.29791 
Epoch [53/300] Training [51/62] Loss: 0.26708 
Epoch [53/300] Training [52/62] Loss: 0.46587 
Epoch [53/300] Training [53/62] Loss: 0.26545 
Epoch [53/300] Training [54/62] Loss: 0.48135 
Epoch [53/300] Training [55/62] Loss: 0.56509 
Epoch [53/300] Training [56/62] Loss: 0.30667 
Epoch [53/300] Training [57/62] Loss: 0.23937 
Epoch [53/300] Training [58/62] Loss: 0.23083 
Epoch [53/300] Training [59/62] Loss: 0.49965 
Epoch [53/300] Training [60/62] Loss: 0.24802 
Epoch [53/300] Training [61/62] Loss: 0.22776 
Epoch [53/300] Training [62/62] Loss: 0.29102 
Epoch [53/300] Training metric {'Train/mean dice_metric': 0.7297413349151611, 'Train/mean miou_metric': 0.6210418939590454, 'Train/mean f1': 0.7592716813087463, 'Train/mean precision': 0.773361086845398, 'Train/mean recall': 0.7456864714622498, 'Train/mean hd95_metric': 63.242889404296875}
Epoch [53/300] Validation [1/16] Loss: 0.56758  focal_loss 0.26675  dice_loss 0.30083 
Epoch [53/300] Validation [2/16] Loss: 0.56189  focal_loss 0.13466  dice_loss 0.42722 
Epoch [53/300] Validation [3/16] Loss: 0.60401  focal_loss 0.21524  dice_loss 0.38877 
Epoch [53/300] Validation [4/16] Loss: 0.50401  focal_loss 0.14381  dice_loss 0.36020 
Epoch [53/300] Validation [5/16] Loss: 0.44201  focal_loss 0.08264  dice_loss 0.35937 
Epoch [53/300] Validation [6/16] Loss: 0.47114  focal_loss 0.12255  dice_loss 0.34859 
Epoch [53/300] Validation [7/16] Loss: 0.37273  focal_loss 0.09673  dice_loss 0.27600 
Epoch [53/300] Validation [8/16] Loss: 0.62536  focal_loss 0.14441  dice_loss 0.48095 
Epoch [53/300] Validation [9/16] Loss: 0.47698  focal_loss 0.13030  dice_loss 0.34668 
Epoch [53/300] Validation [10/16] Loss: 0.61213  focal_loss 0.15898  dice_loss 0.45315 
Epoch [53/300] Validation [11/16] Loss: 0.37342  focal_loss 0.09480  dice_loss 0.27862 
Epoch [53/300] Validation [12/16] Loss: 0.49602  focal_loss 0.06611  dice_loss 0.42991 
Epoch [53/300] Validation [13/16] Loss: 0.40375  focal_loss 0.08012  dice_loss 0.32363 
Epoch [53/300] Validation [14/16] Loss: 0.68990  focal_loss 0.17544  dice_loss 0.51446 
Epoch [53/300] Validation [15/16] Loss: 0.35122  focal_loss 0.09269  dice_loss 0.25853 
Epoch [53/300] Validation [16/16] Loss: 0.32194  focal_loss 0.07409  dice_loss 0.24785 
Epoch [53/300] Validation metric {'Val/mean dice_metric': 0.717555820941925, 'Val/mean miou_metric': 0.605462908744812, 'Val/mean f1': 0.7421684861183167, 'Val/mean precision': 0.7346320748329163, 'Val/mean recall': 0.7498610615730286, 'Val/mean hd95_metric': 68.87614440917969}
Cheakpoint...
Epoch [53/300] best acc:tensor([0.7176], device='cuda:0'), Now : mean acc: tensor([0.7176], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.717555820941925, 'Val/mean miou_metric': 0.605462908744812, 'Val/mean f1': 0.7421684861183167, 'Val/mean precision': 0.7346320748329163, 'Val/mean recall': 0.7498610615730286, 'Val/mean hd95_metric': 68.87614440917969}
Epoch [54/300] Training [1/62] Loss: 0.42810 
Epoch [54/300] Training [2/62] Loss: 0.59702 
Epoch [54/300] Training [3/62] Loss: 0.34107 
Epoch [54/300] Training [4/62] Loss: 0.26654 
Epoch [54/300] Training [5/62] Loss: 0.52527 
Epoch [54/300] Training [6/62] Loss: 0.49253 
Epoch [54/300] Training [7/62] Loss: 0.56764 
Epoch [54/300] Training [8/62] Loss: 0.45576 
Epoch [54/300] Training [9/62] Loss: 0.33342 
Epoch [54/300] Training [10/62] Loss: 0.27438 
Epoch [54/300] Training [11/62] Loss: 0.47096 
Epoch [54/300] Training [12/62] Loss: 0.44986 
Epoch [54/300] Training [13/62] Loss: 0.54175 
Epoch [54/300] Training [14/62] Loss: 0.33650 
Epoch [54/300] Training [15/62] Loss: 0.50384 
Epoch [54/300] Training [16/62] Loss: 0.29074 
Epoch [54/300] Training [17/62] Loss: 0.57797 
Epoch [54/300] Training [18/62] Loss: 0.63460 
Epoch [54/300] Training [19/62] Loss: 0.26439 
Epoch [54/300] Training [20/62] Loss: 0.23059 
Epoch [54/300] Training [21/62] Loss: 0.36882 
Epoch [54/300] Training [22/62] Loss: 0.39191 
Epoch [54/300] Training [23/62] Loss: 0.31903 
Epoch [54/300] Training [24/62] Loss: 0.30627 
Epoch [54/300] Training [25/62] Loss: 0.34434 
Epoch [54/300] Training [26/62] Loss: 0.43776 
Epoch [54/300] Training [27/62] Loss: 0.43252 
Epoch [54/300] Training [28/62] Loss: 0.25806 
Epoch [54/300] Training [29/62] Loss: 0.25210 
Epoch [54/300] Training [30/62] Loss: 0.32149 
Epoch [54/300] Training [31/62] Loss: 0.41686 
Epoch [54/300] Training [32/62] Loss: 0.20556 
Epoch [54/300] Training [33/62] Loss: 0.36565 
Epoch [54/300] Training [34/62] Loss: 0.39714 
Epoch [54/300] Training [35/62] Loss: 0.43039 
Epoch [54/300] Training [36/62] Loss: 0.32929 
Epoch [54/300] Training [37/62] Loss: 0.33988 
Epoch [54/300] Training [38/62] Loss: 0.68636 
Epoch [54/300] Training [39/62] Loss: 0.24855 
Epoch [54/300] Training [40/62] Loss: 0.46794 
Epoch [54/300] Training [41/62] Loss: 0.40562 
Epoch [54/300] Training [42/62] Loss: 0.40471 
Epoch [54/300] Training [43/62] Loss: 0.62893 
Epoch [54/300] Training [44/62] Loss: 0.45624 
Epoch [54/300] Training [45/62] Loss: 0.30328 
Epoch [54/300] Training [46/62] Loss: 0.20288 
Epoch [54/300] Training [47/62] Loss: 0.25251 
Epoch [54/300] Training [48/62] Loss: 0.76663 
Epoch [54/300] Training [49/62] Loss: 0.42863 
Epoch [54/300] Training [50/62] Loss: 0.42325 
Epoch [54/300] Training [51/62] Loss: 0.38996 
Epoch [54/300] Training [52/62] Loss: 0.53556 
Epoch [54/300] Training [53/62] Loss: 0.48273 
Epoch [54/300] Training [54/62] Loss: 0.25866 
Epoch [54/300] Training [55/62] Loss: 0.43404 
Epoch [54/300] Training [56/62] Loss: 0.32878 
Epoch [54/300] Training [57/62] Loss: 0.63925 
Epoch [54/300] Training [58/62] Loss: 0.45714 
Epoch [54/300] Training [59/62] Loss: 0.36816 
Epoch [54/300] Training [60/62] Loss: 0.33357 
Epoch [54/300] Training [61/62] Loss: 0.33435 
Epoch [54/300] Training [62/62] Loss: 2.34828 
Epoch [54/300] Training metric {'Train/mean dice_metric': 0.7315874695777893, 'Train/mean miou_metric': 0.626121997833252, 'Train/mean f1': 0.7591120004653931, 'Train/mean precision': 0.779839813709259, 'Train/mean recall': 0.7394575476646423, 'Train/mean hd95_metric': 64.52579498291016}
Epoch [54/300] Validation [1/16] Loss: 0.75534  focal_loss 0.39133  dice_loss 0.36401 
Epoch [54/300] Validation [2/16] Loss: 0.51710  focal_loss 0.11760  dice_loss 0.39949 
Epoch [54/300] Validation [3/16] Loss: 0.65024  focal_loss 0.21058  dice_loss 0.43966 
Epoch [54/300] Validation [4/16] Loss: 0.44086  focal_loss 0.10145  dice_loss 0.33941 
Epoch [54/300] Validation [5/16] Loss: 0.46838  focal_loss 0.08601  dice_loss 0.38238 
Epoch [54/300] Validation [6/16] Loss: 0.47395  focal_loss 0.09751  dice_loss 0.37645 
Epoch [54/300] Validation [7/16] Loss: 0.37391  focal_loss 0.09943  dice_loss 0.27448 
Epoch [54/300] Validation [8/16] Loss: 0.67566  focal_loss 0.14728  dice_loss 0.52838 
Epoch [54/300] Validation [9/16] Loss: 0.40310  focal_loss 0.10522  dice_loss 0.29788 
Epoch [54/300] Validation [10/16] Loss: 0.81123  focal_loss 0.21358  dice_loss 0.59765 
Epoch [54/300] Validation [11/16] Loss: 0.49747  focal_loss 0.12439  dice_loss 0.37308 
Epoch [54/300] Validation [12/16] Loss: 0.68462  focal_loss 0.17325  dice_loss 0.51137 
Epoch [54/300] Validation [13/16] Loss: 0.34920  focal_loss 0.07802  dice_loss 0.27118 
Epoch [54/300] Validation [14/16] Loss: 0.66774  focal_loss 0.13900  dice_loss 0.52873 
Epoch [54/300] Validation [15/16] Loss: 0.41280  focal_loss 0.12658  dice_loss 0.28623 
Epoch [54/300] Validation [16/16] Loss: 0.28519  focal_loss 0.06576  dice_loss 0.21943 
Epoch [54/300] Validation metric {'Val/mean dice_metric': 0.7119041085243225, 'Val/mean miou_metric': 0.6043566465377808, 'Val/mean f1': 0.7429100275039673, 'Val/mean precision': 0.7508750557899475, 'Val/mean recall': 0.735112190246582, 'Val/mean hd95_metric': 69.24274444580078}
Cheakpoint...
Epoch [54/300] best acc:tensor([0.7176], device='cuda:0'), Now : mean acc: tensor([0.7119], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7119041085243225, 'Val/mean miou_metric': 0.6043566465377808, 'Val/mean f1': 0.7429100275039673, 'Val/mean precision': 0.7508750557899475, 'Val/mean recall': 0.735112190246582, 'Val/mean hd95_metric': 69.24274444580078}
Epoch [55/300] Training [1/62] Loss: 0.54805 
Epoch [55/300] Training [2/62] Loss: 0.49816 
Epoch [55/300] Training [3/62] Loss: 0.56812 
Epoch [55/300] Training [4/62] Loss: 0.49184 
Epoch [55/300] Training [5/62] Loss: 0.41588 
Epoch [55/300] Training [6/62] Loss: 0.27814 
Epoch [55/300] Training [7/62] Loss: 0.40564 
Epoch [55/300] Training [8/62] Loss: 0.38056 
Epoch [55/300] Training [9/62] Loss: 0.41252 
Epoch [55/300] Training [10/62] Loss: 0.50533 
Epoch [55/300] Training [11/62] Loss: 0.38041 
Epoch [55/300] Training [12/62] Loss: 0.42748 
Epoch [55/300] Training [13/62] Loss: 0.50802 
Epoch [55/300] Training [14/62] Loss: 0.35326 
Epoch [55/300] Training [15/62] Loss: 0.45689 
Epoch [55/300] Training [16/62] Loss: 0.45224 
Epoch [55/300] Training [17/62] Loss: 0.37909 
Epoch [55/300] Training [18/62] Loss: 0.50218 
Epoch [55/300] Training [19/62] Loss: 0.48441 
Epoch [55/300] Training [20/62] Loss: 0.25279 
Epoch [55/300] Training [21/62] Loss: 0.50062 
Epoch [55/300] Training [22/62] Loss: 0.41821 
Epoch [55/300] Training [23/62] Loss: 0.39885 
Epoch [55/300] Training [24/62] Loss: 0.38220 
Epoch [55/300] Training [25/62] Loss: 0.47455 
Epoch [55/300] Training [26/62] Loss: 0.42358 
Epoch [55/300] Training [27/62] Loss: 0.31669 
Epoch [55/300] Training [28/62] Loss: 0.30190 
Epoch [55/300] Training [29/62] Loss: 0.37046 
Epoch [55/300] Training [30/62] Loss: 0.44875 
Epoch [55/300] Training [31/62] Loss: 0.34205 
Epoch [55/300] Training [32/62] Loss: 0.34386 
Epoch [55/300] Training [33/62] Loss: 0.53444 
Epoch [55/300] Training [34/62] Loss: 0.31265 
Epoch [55/300] Training [35/62] Loss: 0.55666 
Epoch [55/300] Training [36/62] Loss: 0.31114 
Epoch [55/300] Training [37/62] Loss: 0.31945 
Epoch [55/300] Training [38/62] Loss: 0.35248 
Epoch [55/300] Training [39/62] Loss: 0.45874 
Epoch [55/300] Training [40/62] Loss: 0.37251 
Epoch [55/300] Training [41/62] Loss: 0.23996 
Epoch [55/300] Training [42/62] Loss: 0.50722 
Epoch [55/300] Training [43/62] Loss: 0.34759 
Epoch [55/300] Training [44/62] Loss: 0.44120 
Epoch [55/300] Training [45/62] Loss: 0.46504 
Epoch [55/300] Training [46/62] Loss: 0.45434 
Epoch [55/300] Training [47/62] Loss: 0.42867 
Epoch [55/300] Training [48/62] Loss: 0.21339 
Epoch [55/300] Training [49/62] Loss: 0.42814 
Epoch [55/300] Training [50/62] Loss: 0.41636 
Epoch [55/300] Training [51/62] Loss: 0.40678 
Epoch [55/300] Training [52/62] Loss: 0.51113 
Epoch [55/300] Training [53/62] Loss: 0.53218 
Epoch [55/300] Training [54/62] Loss: 0.37461 
Epoch [55/300] Training [55/62] Loss: 0.30926 
Epoch [55/300] Training [56/62] Loss: 0.26269 
Epoch [55/300] Training [57/62] Loss: 0.22428 
Epoch [55/300] Training [58/62] Loss: 0.29849 
Epoch [55/300] Training [59/62] Loss: 0.22218 
Epoch [55/300] Training [60/62] Loss: 0.58784 
Epoch [55/300] Training [61/62] Loss: 0.47391 
Epoch [55/300] Training [62/62] Loss: 0.68065 
Epoch [55/300] Training metric {'Train/mean dice_metric': 0.7265918850898743, 'Train/mean miou_metric': 0.6167378425598145, 'Train/mean f1': 0.7539657950401306, 'Train/mean precision': 0.7565203309059143, 'Train/mean recall': 0.7514285445213318, 'Train/mean hd95_metric': 66.16525268554688}
Epoch [55/300] Validation [1/16] Loss: 0.54116  focal_loss 0.26539  dice_loss 0.27576 
Epoch [55/300] Validation [2/16] Loss: 0.52617  focal_loss 0.09193  dice_loss 0.43424 
Epoch [55/300] Validation [3/16] Loss: 0.62298  focal_loss 0.19988  dice_loss 0.42309 
Epoch [55/300] Validation [4/16] Loss: 0.50250  focal_loss 0.13129  dice_loss 0.37120 
Epoch [55/300] Validation [5/16] Loss: 0.38215  focal_loss 0.05255  dice_loss 0.32960 
Epoch [55/300] Validation [6/16] Loss: 0.37825  focal_loss 0.07537  dice_loss 0.30288 
Epoch [55/300] Validation [7/16] Loss: 0.30479  focal_loss 0.06498  dice_loss 0.23981 
Epoch [55/300] Validation [8/16] Loss: 0.45709  focal_loss 0.06997  dice_loss 0.38712 
Epoch [55/300] Validation [9/16] Loss: 0.43443  focal_loss 0.09314  dice_loss 0.34129 
Epoch [55/300] Validation [10/16] Loss: 0.62667  focal_loss 0.19755  dice_loss 0.42912 
Epoch [55/300] Validation [11/16] Loss: 0.39344  focal_loss 0.09460  dice_loss 0.29884 
Epoch [55/300] Validation [12/16] Loss: 0.56163  focal_loss 0.06878  dice_loss 0.49285 
Epoch [55/300] Validation [13/16] Loss: 0.44038  focal_loss 0.11222  dice_loss 0.32815 
Epoch [55/300] Validation [14/16] Loss: 0.89458  focal_loss 0.24795  dice_loss 0.64663 
Epoch [55/300] Validation [15/16] Loss: 0.44090  focal_loss 0.12865  dice_loss 0.31225 
Epoch [55/300] Validation [16/16] Loss: 0.16202  focal_loss 0.02912  dice_loss 0.13291 
Epoch [55/300] Validation metric {'Val/mean dice_metric': 0.7145199179649353, 'Val/mean miou_metric': 0.6029701232910156, 'Val/mean f1': 0.740220308303833, 'Val/mean precision': 0.7356484532356262, 'Val/mean recall': 0.7448493838310242, 'Val/mean hd95_metric': 68.4332046508789}
Cheakpoint...
Epoch [55/300] best acc:tensor([0.7176], device='cuda:0'), Now : mean acc: tensor([0.7145], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7145199179649353, 'Val/mean miou_metric': 0.6029701232910156, 'Val/mean f1': 0.740220308303833, 'Val/mean precision': 0.7356484532356262, 'Val/mean recall': 0.7448493838310242, 'Val/mean hd95_metric': 68.4332046508789}
Epoch [56/300] Training [1/62] Loss: 0.42077 
Epoch [56/300] Training [2/62] Loss: 0.42630 
Epoch [56/300] Training [3/62] Loss: 0.52979 
Epoch [56/300] Training [4/62] Loss: 0.45754 
Epoch [56/300] Training [5/62] Loss: 0.39400 
Epoch [56/300] Training [6/62] Loss: 0.59456 
Epoch [56/300] Training [7/62] Loss: 0.40583 
Epoch [56/300] Training [8/62] Loss: 0.41089 
Epoch [56/300] Training [9/62] Loss: 0.33436 
Epoch [56/300] Training [10/62] Loss: 0.45171 
Epoch [56/300] Training [11/62] Loss: 0.30752 
Epoch [56/300] Training [12/62] Loss: 0.33666 
Epoch [56/300] Training [13/62] Loss: 0.64402 
Epoch [56/300] Training [14/62] Loss: 0.32263 
Epoch [56/300] Training [15/62] Loss: 0.37881 
Epoch [56/300] Training [16/62] Loss: 0.56655 
Epoch [56/300] Training [17/62] Loss: 0.48151 
Epoch [56/300] Training [18/62] Loss: 0.62449 
Epoch [56/300] Training [19/62] Loss: 0.22779 
Epoch [56/300] Training [20/62] Loss: 0.30371 
Epoch [56/300] Training [21/62] Loss: 0.60608 
Epoch [56/300] Training [22/62] Loss: 0.28459 
Epoch [56/300] Training [23/62] Loss: 0.61013 
Epoch [56/300] Training [24/62] Loss: 0.49288 
Epoch [56/300] Training [25/62] Loss: 0.32310 
Epoch [56/300] Training [26/62] Loss: 0.35705 
Epoch [56/300] Training [27/62] Loss: 0.58665 
Epoch [56/300] Training [28/62] Loss: 0.23233 
Epoch [56/300] Training [29/62] Loss: 0.34637 
Epoch [56/300] Training [30/62] Loss: 0.44780 
Epoch [56/300] Training [31/62] Loss: 0.33030 
Epoch [56/300] Training [32/62] Loss: 0.36732 
Epoch [56/300] Training [33/62] Loss: 0.42351 
Epoch [56/300] Training [34/62] Loss: 0.42564 
Epoch [56/300] Training [35/62] Loss: 0.53708 
Epoch [56/300] Training [36/62] Loss: 0.49475 
Epoch [56/300] Training [37/62] Loss: 0.39102 
Epoch [56/300] Training [38/62] Loss: 0.36420 
Epoch [56/300] Training [39/62] Loss: 0.34572 
Epoch [56/300] Training [40/62] Loss: 0.47242 
Epoch [56/300] Training [41/62] Loss: 0.28356 
Epoch [56/300] Training [42/62] Loss: 0.35443 
Epoch [56/300] Training [43/62] Loss: 0.44051 
Epoch [56/300] Training [44/62] Loss: 0.47315 
Epoch [56/300] Training [45/62] Loss: 0.45362 
Epoch [56/300] Training [46/62] Loss: 0.32454 
Epoch [56/300] Training [47/62] Loss: 0.56575 
Epoch [56/300] Training [48/62] Loss: 0.24401 
Epoch [56/300] Training [49/62] Loss: 0.61835 
Epoch [56/300] Training [50/62] Loss: 0.33074 
Epoch [56/300] Training [51/62] Loss: 0.30306 
Epoch [56/300] Training [52/62] Loss: 0.46812 
Epoch [56/300] Training [53/62] Loss: 0.52644 
Epoch [56/300] Training [54/62] Loss: 0.37717 
Epoch [56/300] Training [55/62] Loss: 0.32288 
Epoch [56/300] Training [56/62] Loss: 0.38012 
Epoch [56/300] Training [57/62] Loss: 0.21510 
Epoch [56/300] Training [58/62] Loss: 0.50276 
Epoch [56/300] Training [59/62] Loss: 0.44865 
Epoch [56/300] Training [60/62] Loss: 0.28775 
Epoch [56/300] Training [61/62] Loss: 0.32676 
Epoch [56/300] Training [62/62] Loss: 0.11529 
Epoch [56/300] Training metric {'Train/mean dice_metric': 0.7157691121101379, 'Train/mean miou_metric': 0.6080018877983093, 'Train/mean f1': 0.7466681599617004, 'Train/mean precision': 0.7565235495567322, 'Train/mean recall': 0.7370662093162537, 'Train/mean hd95_metric': 66.23350524902344}
Epoch [56/300] Validation [1/16] Loss: 0.79921  focal_loss 0.39144  dice_loss 0.40777 
Epoch [56/300] Validation [2/16] Loss: 0.59170  focal_loss 0.13148  dice_loss 0.46022 
Epoch [56/300] Validation [3/16] Loss: 0.62305  focal_loss 0.21543  dice_loss 0.40762 
Epoch [56/300] Validation [4/16] Loss: 0.61895  focal_loss 0.18027  dice_loss 0.43868 
Epoch [56/300] Validation [5/16] Loss: 0.46966  focal_loss 0.06222  dice_loss 0.40744 
Epoch [56/300] Validation [6/16] Loss: 0.51541  focal_loss 0.11190  dice_loss 0.40351 
Epoch [56/300] Validation [7/16] Loss: 0.46903  focal_loss 0.11619  dice_loss 0.35284 
Epoch [56/300] Validation [8/16] Loss: 0.74156  focal_loss 0.19978  dice_loss 0.54177 
Epoch [56/300] Validation [9/16] Loss: 0.53079  focal_loss 0.14281  dice_loss 0.38798 
Epoch [56/300] Validation [10/16] Loss: 0.90729  focal_loss 0.25814  dice_loss 0.64915 
Epoch [56/300] Validation [11/16] Loss: 0.50735  focal_loss 0.13792  dice_loss 0.36943 
Epoch [56/300] Validation [12/16] Loss: 0.51584  focal_loss 0.06454  dice_loss 0.45130 
Epoch [56/300] Validation [13/16] Loss: 0.44959  focal_loss 0.12173  dice_loss 0.32786 
Epoch [56/300] Validation [14/16] Loss: 0.75517  focal_loss 0.18732  dice_loss 0.56785 
Epoch [56/300] Validation [15/16] Loss: 0.55753  focal_loss 0.17293  dice_loss 0.38460 
Epoch [56/300] Validation [16/16] Loss: 0.31463  focal_loss 0.07414  dice_loss 0.24049 
Epoch [56/300] Validation metric {'Val/mean dice_metric': 0.6926843523979187, 'Val/mean miou_metric': 0.5855932235717773, 'Val/mean f1': 0.7271009683609009, 'Val/mean precision': 0.7613511085510254, 'Val/mean recall': 0.6957998871803284, 'Val/mean hd95_metric': 66.38630676269531}
Cheakpoint...
Epoch [56/300] best acc:tensor([0.7176], device='cuda:0'), Now : mean acc: tensor([0.6927], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6926843523979187, 'Val/mean miou_metric': 0.5855932235717773, 'Val/mean f1': 0.7271009683609009, 'Val/mean precision': 0.7613511085510254, 'Val/mean recall': 0.6957998871803284, 'Val/mean hd95_metric': 66.38630676269531}
Epoch [57/300] Training [1/62] Loss: 0.27988 
Epoch [57/300] Training [2/62] Loss: 0.49433 
Epoch [57/300] Training [3/62] Loss: 0.23129 
Epoch [57/300] Training [4/62] Loss: 0.34705 
Epoch [57/300] Training [5/62] Loss: 0.28627 
Epoch [57/300] Training [6/62] Loss: 0.48270 
Epoch [57/300] Training [7/62] Loss: 0.41106 
Epoch [57/300] Training [8/62] Loss: 0.23153 
Epoch [57/300] Training [9/62] Loss: 0.35672 
Epoch [57/300] Training [10/62] Loss: 0.27593 
Epoch [57/300] Training [11/62] Loss: 0.27463 
Epoch [57/300] Training [12/62] Loss: 0.45150 
Epoch [57/300] Training [13/62] Loss: 0.60764 
Epoch [57/300] Training [14/62] Loss: 0.26124 
Epoch [57/300] Training [15/62] Loss: 0.30887 
Epoch [57/300] Training [16/62] Loss: 0.51789 
Epoch [57/300] Training [17/62] Loss: 0.25909 
Epoch [57/300] Training [18/62] Loss: 0.47997 
Epoch [57/300] Training [19/62] Loss: 0.45333 
Epoch [57/300] Training [20/62] Loss: 0.49956 
Epoch [57/300] Training [21/62] Loss: 0.48974 
Epoch [57/300] Training [22/62] Loss: 0.46623 
Epoch [57/300] Training [23/62] Loss: 0.36748 
Epoch [57/300] Training [24/62] Loss: 0.43719 
Epoch [57/300] Training [25/62] Loss: 0.35431 
Epoch [57/300] Training [26/62] Loss: 0.29952 
Epoch [57/300] Training [27/62] Loss: 0.38927 
Epoch [57/300] Training [28/62] Loss: 0.20260 
Epoch [57/300] Training [29/62] Loss: 0.33140 
Epoch [57/300] Training [30/62] Loss: 0.30390 
Epoch [57/300] Training [31/62] Loss: 0.40245 
Epoch [57/300] Training [32/62] Loss: 0.34059 
Epoch [57/300] Training [33/62] Loss: 0.43079 
Epoch [57/300] Training [34/62] Loss: 0.31468 
Epoch [57/300] Training [35/62] Loss: 0.22274 
Epoch [57/300] Training [36/62] Loss: 0.17976 
Epoch [57/300] Training [37/62] Loss: 0.21419 
Epoch [57/300] Training [38/62] Loss: 0.30285 
Epoch [57/300] Training [39/62] Loss: 0.47725 
Epoch [57/300] Training [40/62] Loss: 0.24169 
Epoch [57/300] Training [41/62] Loss: 0.20182 
Epoch [57/300] Training [42/62] Loss: 0.26856 
Epoch [57/300] Training [43/62] Loss: 0.20070 
Epoch [57/300] Training [44/62] Loss: 0.33135 
Epoch [57/300] Training [45/62] Loss: 0.28251 
Epoch [57/300] Training [46/62] Loss: 0.54565 
Epoch [57/300] Training [47/62] Loss: 0.30001 
Epoch [57/300] Training [48/62] Loss: 0.58848 
Epoch [57/300] Training [49/62] Loss: 0.44533 
Epoch [57/300] Training [50/62] Loss: 0.27310 
Epoch [57/300] Training [51/62] Loss: 0.52427 
Epoch [57/300] Training [52/62] Loss: 0.40082 
Epoch [57/300] Training [53/62] Loss: 0.33403 
Epoch [57/300] Training [54/62] Loss: 0.45794 
Epoch [57/300] Training [55/62] Loss: 0.46472 
Epoch [57/300] Training [56/62] Loss: 0.43561 
Epoch [57/300] Training [57/62] Loss: 0.31788 
Epoch [57/300] Training [58/62] Loss: 0.41690 
Epoch [57/300] Training [59/62] Loss: 0.37964 
Epoch [57/300] Training [60/62] Loss: 0.50527 
Epoch [57/300] Training [61/62] Loss: 0.32508 
Epoch [57/300] Training [62/62] Loss: 1.27352 
Epoch [57/300] Training metric {'Train/mean dice_metric': 0.7470943927764893, 'Train/mean miou_metric': 0.6443958282470703, 'Train/mean f1': 0.7850742340087891, 'Train/mean precision': 0.7940488457679749, 'Train/mean recall': 0.7763001918792725, 'Train/mean hd95_metric': 60.55476760864258}
Epoch [57/300] Validation [1/16] Loss: 0.68347  focal_loss 0.36537  dice_loss 0.31810 
Epoch [57/300] Validation [2/16] Loss: 0.53852  focal_loss 0.10490  dice_loss 0.43362 
Epoch [57/300] Validation [3/16] Loss: 0.56180  focal_loss 0.18083  dice_loss 0.38097 
Epoch [57/300] Validation [4/16] Loss: 0.51463  focal_loss 0.16190  dice_loss 0.35273 
Epoch [57/300] Validation [5/16] Loss: 0.43884  focal_loss 0.06570  dice_loss 0.37314 
Epoch [57/300] Validation [6/16] Loss: 0.37508  focal_loss 0.08540  dice_loss 0.28968 
Epoch [57/300] Validation [7/16] Loss: 0.24953  focal_loss 0.06569  dice_loss 0.18384 
Epoch [57/300] Validation [8/16] Loss: 0.45490  focal_loss 0.09422  dice_loss 0.36068 
Epoch [57/300] Validation [9/16] Loss: 0.44615  focal_loss 0.10199  dice_loss 0.34416 
Epoch [57/300] Validation [10/16] Loss: 0.77839  focal_loss 0.21453  dice_loss 0.56386 
Epoch [57/300] Validation [11/16] Loss: 0.37211  focal_loss 0.08448  dice_loss 0.28763 
Epoch [57/300] Validation [12/16] Loss: 0.46901  focal_loss 0.05797  dice_loss 0.41105 
Epoch [57/300] Validation [13/16] Loss: 0.28338  focal_loss 0.04736  dice_loss 0.23602 
Epoch [57/300] Validation [14/16] Loss: 0.64298  focal_loss 0.14497  dice_loss 0.49801 
Epoch [57/300] Validation [15/16] Loss: 0.24674  focal_loss 0.05656  dice_loss 0.19019 
Epoch [57/300] Validation [16/16] Loss: 0.19945  focal_loss 0.04298  dice_loss 0.15647 
Epoch [57/300] Validation metric {'Val/mean dice_metric': 0.7351452112197876, 'Val/mean miou_metric': 0.6311137080192566, 'Val/mean f1': 0.7741004824638367, 'Val/mean precision': 0.7775892615318298, 'Val/mean recall': 0.7706429362297058, 'Val/mean hd95_metric': 64.40328216552734}
Cheakpoint...
Epoch [57/300] best acc:tensor([0.7351], device='cuda:0'), Now : mean acc: tensor([0.7351], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7351452112197876, 'Val/mean miou_metric': 0.6311137080192566, 'Val/mean f1': 0.7741004824638367, 'Val/mean precision': 0.7775892615318298, 'Val/mean recall': 0.7706429362297058, 'Val/mean hd95_metric': 64.40328216552734}
Epoch [58/300] Training [1/62] Loss: 0.36850 
Epoch [58/300] Training [2/62] Loss: 0.35496 
Epoch [58/300] Training [3/62] Loss: 0.27853 
Epoch [58/300] Training [4/62] Loss: 0.32492 
Epoch [58/300] Training [5/62] Loss: 0.45751 
Epoch [58/300] Training [6/62] Loss: 0.24013 
Epoch [58/300] Training [7/62] Loss: 0.34175 
Epoch [58/300] Training [8/62] Loss: 0.22133 
Epoch [58/300] Training [9/62] Loss: 0.28864 
Epoch [58/300] Training [10/62] Loss: 0.29557 
Epoch [58/300] Training [11/62] Loss: 0.35876 
Epoch [58/300] Training [12/62] Loss: 0.40598 
Epoch [58/300] Training [13/62] Loss: 0.46420 
Epoch [58/300] Training [14/62] Loss: 0.19424 
Epoch [58/300] Training [15/62] Loss: 0.34327 
Epoch [58/300] Training [16/62] Loss: 0.36763 
Epoch [58/300] Training [17/62] Loss: 0.37147 
Epoch [58/300] Training [18/62] Loss: 0.23202 
Epoch [58/300] Training [19/62] Loss: 0.32552 
Epoch [58/300] Training [20/62] Loss: 0.38512 
Epoch [58/300] Training [21/62] Loss: 0.41245 
Epoch [58/300] Training [22/62] Loss: 0.52903 
Epoch [58/300] Training [23/62] Loss: 0.28242 
Epoch [58/300] Training [24/62] Loss: 0.30213 
Epoch [58/300] Training [25/62] Loss: 0.38136 
Epoch [58/300] Training [26/62] Loss: 0.39067 
Epoch [58/300] Training [27/62] Loss: 0.36430 
Epoch [58/300] Training [28/62] Loss: 0.31029 
Epoch [58/300] Training [29/62] Loss: 0.34886 
Epoch [58/300] Training [30/62] Loss: 0.18388 
Epoch [58/300] Training [31/62] Loss: 0.23761 
Epoch [58/300] Training [32/62] Loss: 0.46596 
Epoch [58/300] Training [33/62] Loss: 0.51834 
Epoch [58/300] Training [34/62] Loss: 0.42810 
Epoch [58/300] Training [35/62] Loss: 0.27862 
Epoch [58/300] Training [36/62] Loss: 0.28764 
Epoch [58/300] Training [37/62] Loss: 0.52060 
Epoch [58/300] Training [38/62] Loss: 0.32261 
Epoch [58/300] Training [39/62] Loss: 0.52005 
Epoch [58/300] Training [40/62] Loss: 0.51578 
Epoch [58/300] Training [41/62] Loss: 0.44348 
Epoch [58/300] Training [42/62] Loss: 0.42624 
Epoch [58/300] Training [43/62] Loss: 0.38839 
Epoch [58/300] Training [44/62] Loss: 0.34478 
Epoch [58/300] Training [45/62] Loss: 0.42726 
Epoch [58/300] Training [46/62] Loss: 0.49268 
Epoch [58/300] Training [47/62] Loss: 0.59203 
Epoch [58/300] Training [48/62] Loss: 0.46167 
Epoch [58/300] Training [49/62] Loss: 0.35624 
Epoch [58/300] Training [50/62] Loss: 0.28301 
Epoch [58/300] Training [51/62] Loss: 0.26850 
Epoch [58/300] Training [52/62] Loss: 0.31074 
Epoch [58/300] Training [53/62] Loss: 0.56042 
Epoch [58/300] Training [54/62] Loss: 0.28782 
Epoch [58/300] Training [55/62] Loss: 0.24632 
Epoch [58/300] Training [56/62] Loss: 0.34265 
Epoch [58/300] Training [57/62] Loss: 0.33259 
Epoch [58/300] Training [58/62] Loss: 0.35822 
Epoch [58/300] Training [59/62] Loss: 0.20631 
Epoch [58/300] Training [60/62] Loss: 0.73592 
Epoch [58/300] Training [61/62] Loss: 0.36485 
Epoch [58/300] Training [62/62] Loss: 0.39090 
Epoch [58/300] Training metric {'Train/mean dice_metric': 0.7515871524810791, 'Train/mean miou_metric': 0.648148238658905, 'Train/mean f1': 0.7892881035804749, 'Train/mean precision': 0.8008697628974915, 'Train/mean recall': 0.7780366539955139, 'Train/mean hd95_metric': 58.94142150878906}
Epoch [58/300] Validation [1/16] Loss: 0.62367  focal_loss 0.25604  dice_loss 0.36763 
Epoch [58/300] Validation [2/16] Loss: 0.61685  focal_loss 0.11126  dice_loss 0.50559 
Epoch [58/300] Validation [3/16] Loss: 0.71918  focal_loss 0.24299  dice_loss 0.47619 
Epoch [58/300] Validation [4/16] Loss: 0.67160  focal_loss 0.19104  dice_loss 0.48056 
Epoch [58/300] Validation [5/16] Loss: 0.52392  focal_loss 0.10325  dice_loss 0.42067 
Epoch [58/300] Validation [6/16] Loss: 0.50269  focal_loss 0.11778  dice_loss 0.38491 
Epoch [58/300] Validation [7/16] Loss: 0.37558  focal_loss 0.07588  dice_loss 0.29970 
Epoch [58/300] Validation [8/16] Loss: 0.75024  focal_loss 0.19462  dice_loss 0.55562 
Epoch [58/300] Validation [9/16] Loss: 0.60581  focal_loss 0.16083  dice_loss 0.44498 
Epoch [58/300] Validation [10/16] Loss: 0.81834  focal_loss 0.21626  dice_loss 0.60208 
Epoch [58/300] Validation [11/16] Loss: 0.42921  focal_loss 0.09793  dice_loss 0.33128 
Epoch [58/300] Validation [12/16] Loss: 0.54361  focal_loss 0.07530  dice_loss 0.46831 
Epoch [58/300] Validation [13/16] Loss: 0.52770  focal_loss 0.14559  dice_loss 0.38211 
Epoch [58/300] Validation [14/16] Loss: 0.81525  focal_loss 0.21055  dice_loss 0.60469 
Epoch [58/300] Validation [15/16] Loss: 0.40657  focal_loss 0.10561  dice_loss 0.30096 
Epoch [58/300] Validation [16/16] Loss: 0.31290  focal_loss 0.08730  dice_loss 0.22560 
Epoch [58/300] Validation metric {'Val/mean dice_metric': 0.7213805317878723, 'Val/mean miou_metric': 0.6129431128501892, 'Val/mean f1': 0.7584972381591797, 'Val/mean precision': 0.7542044520378113, 'Val/mean recall': 0.7628390192985535, 'Val/mean hd95_metric': 65.73141479492188}
Cheakpoint...
Epoch [58/300] best acc:tensor([0.7351], device='cuda:0'), Now : mean acc: tensor([0.7214], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7213805317878723, 'Val/mean miou_metric': 0.6129431128501892, 'Val/mean f1': 0.7584972381591797, 'Val/mean precision': 0.7542044520378113, 'Val/mean recall': 0.7628390192985535, 'Val/mean hd95_metric': 65.73141479492188}
Epoch [59/300] Training [1/62] Loss: 0.44889 
Epoch [59/300] Training [2/62] Loss: 0.41596 
Epoch [59/300] Training [3/62] Loss: 0.52032 
Epoch [59/300] Training [4/62] Loss: 0.31793 
Epoch [59/300] Training [5/62] Loss: 0.39140 
Epoch [59/300] Training [6/62] Loss: 0.46431 
Epoch [59/300] Training [7/62] Loss: 0.20789 
Epoch [59/300] Training [8/62] Loss: 0.37060 
Epoch [59/300] Training [9/62] Loss: 0.32012 
Epoch [59/300] Training [10/62] Loss: 0.28725 
Epoch [59/300] Training [11/62] Loss: 0.37617 
Epoch [59/300] Training [12/62] Loss: 0.52295 
Epoch [59/300] Training [13/62] Loss: 0.36356 
Epoch [59/300] Training [14/62] Loss: 0.17148 
Epoch [59/300] Training [15/62] Loss: 0.45875 
Epoch [59/300] Training [16/62] Loss: 0.50215 
Epoch [59/300] Training [17/62] Loss: 0.48843 
Epoch [59/300] Training [18/62] Loss: 0.34308 
Epoch [59/300] Training [19/62] Loss: 0.33581 
Epoch [59/300] Training [20/62] Loss: 0.48181 
Epoch [59/300] Training [21/62] Loss: 0.21986 
Epoch [59/300] Training [22/62] Loss: 0.28254 
Epoch [59/300] Training [23/62] Loss: 0.30693 
Epoch [59/300] Training [24/62] Loss: 0.29909 
Epoch [59/300] Training [25/62] Loss: 0.46849 
Epoch [59/300] Training [26/62] Loss: 0.33257 
Epoch [59/300] Training [27/62] Loss: 0.22271 
Epoch [59/300] Training [28/62] Loss: 0.34304 
Epoch [59/300] Training [29/62] Loss: 0.49359 
Epoch [59/300] Training [30/62] Loss: 0.20453 
Epoch [59/300] Training [31/62] Loss: 0.34658 
Epoch [59/300] Training [32/62] Loss: 0.27355 
Epoch [59/300] Training [33/62] Loss: 0.41158 
Epoch [59/300] Training [34/62] Loss: 0.40262 
Epoch [59/300] Training [35/62] Loss: 0.19639 
Epoch [59/300] Training [36/62] Loss: 0.43763 
Epoch [59/300] Training [37/62] Loss: 0.52049 
Epoch [59/300] Training [38/62] Loss: 0.49243 
Epoch [59/300] Training [39/62] Loss: 0.74941 
Epoch [59/300] Training [40/62] Loss: 0.33752 
Epoch [59/300] Training [41/62] Loss: 0.46693 
Epoch [59/300] Training [42/62] Loss: 0.35226 
Epoch [59/300] Training [43/62] Loss: 0.25352 
Epoch [59/300] Training [44/62] Loss: 0.44374 
Epoch [59/300] Training [45/62] Loss: 0.33550 
Epoch [59/300] Training [46/62] Loss: 0.31083 
Epoch [59/300] Training [47/62] Loss: 0.30739 
Epoch [59/300] Training [48/62] Loss: 0.53293 
Epoch [59/300] Training [49/62] Loss: 0.27138 
Epoch [59/300] Training [50/62] Loss: 0.53638 
Epoch [59/300] Training [51/62] Loss: 0.28658 
Epoch [59/300] Training [52/62] Loss: 0.45168 
Epoch [59/300] Training [53/62] Loss: 0.45542 
Epoch [59/300] Training [54/62] Loss: 0.61619 
Epoch [59/300] Training [55/62] Loss: 0.42870 
Epoch [59/300] Training [56/62] Loss: 0.33431 
Epoch [59/300] Training [57/62] Loss: 0.35200 
Epoch [59/300] Training [58/62] Loss: 0.32073 
Epoch [59/300] Training [59/62] Loss: 0.19093 
Epoch [59/300] Training [60/62] Loss: 0.38049 
Epoch [59/300] Training [61/62] Loss: 0.19866 
Epoch [59/300] Training [62/62] Loss: 0.77435 
Epoch [59/300] Training metric {'Train/mean dice_metric': 0.7467265129089355, 'Train/mean miou_metric': 0.6409196853637695, 'Train/mean f1': 0.780143678188324, 'Train/mean precision': 0.7946832180023193, 'Train/mean recall': 0.7661265134811401, 'Train/mean hd95_metric': 65.56621551513672}
Epoch [59/300] Validation [1/16] Loss: 0.65881  focal_loss 0.24301  dice_loss 0.41580 
Epoch [59/300] Validation [2/16] Loss: 0.61356  focal_loss 0.13545  dice_loss 0.47810 
Epoch [59/300] Validation [3/16] Loss: 0.53782  focal_loss 0.17159  dice_loss 0.36624 
Epoch [59/300] Validation [4/16] Loss: 0.55496  focal_loss 0.15710  dice_loss 0.39786 
Epoch [59/300] Validation [5/16] Loss: 0.38216  focal_loss 0.05569  dice_loss 0.32647 
Epoch [59/300] Validation [6/16] Loss: 0.42735  focal_loss 0.09160  dice_loss 0.33574 
Epoch [59/300] Validation [7/16] Loss: 0.30743  focal_loss 0.06066  dice_loss 0.24677 
Epoch [59/300] Validation [8/16] Loss: 0.61509  focal_loss 0.09437  dice_loss 0.52072 
Epoch [59/300] Validation [9/16] Loss: 0.61334  focal_loss 0.17247  dice_loss 0.44088 
Epoch [59/300] Validation [10/16] Loss: 0.74429  focal_loss 0.18358  dice_loss 0.56071 
Epoch [59/300] Validation [11/16] Loss: 0.46968  focal_loss 0.10977  dice_loss 0.35992 
Epoch [59/300] Validation [12/16] Loss: 0.57939  focal_loss 0.07628  dice_loss 0.50311 
Epoch [59/300] Validation [13/16] Loss: 0.32377  focal_loss 0.05636  dice_loss 0.26741 
Epoch [59/300] Validation [14/16] Loss: 0.73428  focal_loss 0.15278  dice_loss 0.58150 
Epoch [59/300] Validation [15/16] Loss: 0.33736  focal_loss 0.07618  dice_loss 0.26118 
Epoch [59/300] Validation [16/16] Loss: 0.35340  focal_loss 0.08374  dice_loss 0.26967 
Epoch [59/300] Validation metric {'Val/mean dice_metric': 0.7238577008247375, 'Val/mean miou_metric': 0.6178674101829529, 'Val/mean f1': 0.7625386714935303, 'Val/mean precision': 0.7797911167144775, 'Val/mean recall': 0.7460330128669739, 'Val/mean hd95_metric': 67.90660858154297}
Cheakpoint...
Epoch [59/300] best acc:tensor([0.7351], device='cuda:0'), Now : mean acc: tensor([0.7239], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7238577008247375, 'Val/mean miou_metric': 0.6178674101829529, 'Val/mean f1': 0.7625386714935303, 'Val/mean precision': 0.7797911167144775, 'Val/mean recall': 0.7460330128669739, 'Val/mean hd95_metric': 67.90660858154297}
Epoch [60/300] Training [1/62] Loss: 0.39063 
Epoch [60/300] Training [2/62] Loss: 0.32377 
Epoch [60/300] Training [3/62] Loss: 0.24818 
Epoch [60/300] Training [4/62] Loss: 0.44920 
Epoch [60/300] Training [5/62] Loss: 0.66910 
Epoch [60/300] Training [6/62] Loss: 0.39182 
Epoch [60/300] Training [7/62] Loss: 0.37267 
Epoch [60/300] Training [8/62] Loss: 0.32967 
Epoch [60/300] Training [9/62] Loss: 0.19761 
Epoch [60/300] Training [10/62] Loss: 0.37940 
Epoch [60/300] Training [11/62] Loss: 0.43519 
Epoch [60/300] Training [12/62] Loss: 0.52546 
Epoch [60/300] Training [13/62] Loss: 0.34127 
Epoch [60/300] Training [14/62] Loss: 0.26217 
Epoch [60/300] Training [15/62] Loss: 0.24261 
Epoch [60/300] Training [16/62] Loss: 0.21692 
Epoch [60/300] Training [17/62] Loss: 0.26012 
Epoch [60/300] Training [18/62] Loss: 0.27525 
Epoch [60/300] Training [19/62] Loss: 0.29983 
Epoch [60/300] Training [20/62] Loss: 0.42102 
Epoch [60/300] Training [21/62] Loss: 0.26933 
Epoch [60/300] Training [22/62] Loss: 0.26447 
Epoch [60/300] Training [23/62] Loss: 0.34893 
Epoch [60/300] Training [24/62] Loss: 0.28610 
Epoch [60/300] Training [25/62] Loss: 0.41675 
Epoch [60/300] Training [26/62] Loss: 0.39467 
Epoch [60/300] Training [27/62] Loss: 0.53741 
Epoch [60/300] Training [28/62] Loss: 0.45293 
Epoch [60/300] Training [29/62] Loss: 0.33247 
Epoch [60/300] Training [30/62] Loss: 0.32853 
Epoch [60/300] Training [31/62] Loss: 0.37539 
Epoch [60/300] Training [32/62] Loss: 0.36943 
Epoch [60/300] Training [33/62] Loss: 0.29029 
Epoch [60/300] Training [34/62] Loss: 0.25243 
Epoch [60/300] Training [35/62] Loss: 0.45216 
Epoch [60/300] Training [36/62] Loss: 0.27610 
Epoch [60/300] Training [37/62] Loss: 0.50574 
Epoch [60/300] Training [38/62] Loss: 0.25661 
Epoch [60/300] Training [39/62] Loss: 0.46351 
Epoch [60/300] Training [40/62] Loss: 0.43076 
Epoch [60/300] Training [41/62] Loss: 0.34537 
Epoch [60/300] Training [42/62] Loss: 0.37122 
Epoch [60/300] Training [43/62] Loss: 0.33865 
Epoch [60/300] Training [44/62] Loss: 0.42476 
Epoch [60/300] Training [45/62] Loss: 0.41501 
Epoch [60/300] Training [46/62] Loss: 0.41689 
Epoch [60/300] Training [47/62] Loss: 0.30083 
Epoch [60/300] Training [48/62] Loss: 0.38254 
Epoch [60/300] Training [49/62] Loss: 0.34324 
Epoch [60/300] Training [50/62] Loss: 0.55123 
Epoch [60/300] Training [51/62] Loss: 0.30722 
Epoch [60/300] Training [52/62] Loss: 0.49138 
Epoch [60/300] Training [53/62] Loss: 0.44449 
Epoch [60/300] Training [54/62] Loss: 0.23880 
Epoch [60/300] Training [55/62] Loss: 0.47084 
Epoch [60/300] Training [56/62] Loss: 0.57982 
Epoch [60/300] Training [57/62] Loss: 0.27459 
Epoch [60/300] Training [58/62] Loss: 0.36559 
Epoch [60/300] Training [59/62] Loss: 0.34625 
Epoch [60/300] Training [60/62] Loss: 0.51326 
Epoch [60/300] Training [61/62] Loss: 0.42748 
Epoch [60/300] Training [62/62] Loss: 0.73199 
Epoch [60/300] Training metric {'Train/mean dice_metric': 0.7485847473144531, 'Train/mean miou_metric': 0.6439367532730103, 'Train/mean f1': 0.7773674130439758, 'Train/mean precision': 0.7876492142677307, 'Train/mean recall': 0.7673506736755371, 'Train/mean hd95_metric': 60.044673919677734}
Epoch [60/300] Validation [1/16] Loss: 0.66042  focal_loss 0.33716  dice_loss 0.32326 
Epoch [60/300] Validation [2/16] Loss: 0.56667  focal_loss 0.13074  dice_loss 0.43594 
Epoch [60/300] Validation [3/16] Loss: 0.55188  focal_loss 0.18785  dice_loss 0.36403 
Epoch [60/300] Validation [4/16] Loss: 0.41229  focal_loss 0.11649  dice_loss 0.29580 
Epoch [60/300] Validation [5/16] Loss: 0.37601  focal_loss 0.03729  dice_loss 0.33872 
Epoch [60/300] Validation [6/16] Loss: 0.38980  focal_loss 0.08323  dice_loss 0.30657 
Epoch [60/300] Validation [7/16] Loss: 0.29120  focal_loss 0.07308  dice_loss 0.21812 
Epoch [60/300] Validation [8/16] Loss: 0.68428  focal_loss 0.17220  dice_loss 0.51208 
Epoch [60/300] Validation [9/16] Loss: 0.37958  focal_loss 0.08858  dice_loss 0.29101 
Epoch [60/300] Validation [10/16] Loss: 0.59940  focal_loss 0.15456  dice_loss 0.44484 
Epoch [60/300] Validation [11/16] Loss: 0.31994  focal_loss 0.07500  dice_loss 0.24494 
Epoch [60/300] Validation [12/16] Loss: 0.48229  focal_loss 0.06114  dice_loss 0.42115 
Epoch [60/300] Validation [13/16] Loss: 0.25035  focal_loss 0.03894  dice_loss 0.21141 
Epoch [60/300] Validation [14/16] Loss: 0.65113  focal_loss 0.12566  dice_loss 0.52546 
Epoch [60/300] Validation [15/16] Loss: 0.24065  focal_loss 0.04793  dice_loss 0.19272 
Epoch [60/300] Validation [16/16] Loss: 0.28541  focal_loss 0.06236  dice_loss 0.22304 
Epoch [60/300] Validation metric {'Val/mean dice_metric': 0.7374244928359985, 'Val/mean miou_metric': 0.631523072719574, 'Val/mean f1': 0.7688083052635193, 'Val/mean precision': 0.7814199924468994, 'Val/mean recall': 0.7565972208976746, 'Val/mean hd95_metric': 61.20235061645508}
Cheakpoint...
Epoch [60/300] best acc:tensor([0.7374], device='cuda:0'), Now : mean acc: tensor([0.7374], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7374244928359985, 'Val/mean miou_metric': 0.631523072719574, 'Val/mean f1': 0.7688083052635193, 'Val/mean precision': 0.7814199924468994, 'Val/mean recall': 0.7565972208976746, 'Val/mean hd95_metric': 61.20235061645508}
Epoch [61/300] Training [1/62] Loss: 0.45152 
Epoch [61/300] Training [2/62] Loss: 0.41661 
Epoch [61/300] Training [3/62] Loss: 0.31065 
Epoch [61/300] Training [4/62] Loss: 0.32541 
Epoch [61/300] Training [5/62] Loss: 0.53356 
Epoch [61/300] Training [6/62] Loss: 0.33248 
Epoch [61/300] Training [7/62] Loss: 0.31120 
Epoch [61/300] Training [8/62] Loss: 0.27122 
Epoch [61/300] Training [9/62] Loss: 0.48496 
Epoch [61/300] Training [10/62] Loss: 0.37940 
Epoch [61/300] Training [11/62] Loss: 0.40133 
Epoch [61/300] Training [12/62] Loss: 0.42210 
Epoch [61/300] Training [13/62] Loss: 0.22798 
Epoch [61/300] Training [14/62] Loss: 0.35898 
Epoch [61/300] Training [15/62] Loss: 0.37292 
Epoch [61/300] Training [16/62] Loss: 0.36915 
Epoch [61/300] Training [17/62] Loss: 0.23355 
Epoch [61/300] Training [18/62] Loss: 0.32803 
Epoch [61/300] Training [19/62] Loss: 0.21108 
Epoch [61/300] Training [20/62] Loss: 0.33444 
Epoch [61/300] Training [21/62] Loss: 0.30403 
Epoch [61/300] Training [22/62] Loss: 0.45973 
Epoch [61/300] Training [23/62] Loss: 0.34594 
Epoch [61/300] Training [24/62] Loss: 0.26349 
Epoch [61/300] Training [25/62] Loss: 0.34257 
Epoch [61/300] Training [26/62] Loss: 0.32054 
Epoch [61/300] Training [27/62] Loss: 0.23844 
Epoch [61/300] Training [28/62] Loss: 0.55841 
Epoch [61/300] Training [29/62] Loss: 0.28118 
Epoch [61/300] Training [30/62] Loss: 0.25793 
Epoch [61/300] Training [31/62] Loss: 0.34449 
Epoch [61/300] Training [32/62] Loss: 0.24792 
Epoch [61/300] Training [33/62] Loss: 0.43228 
Epoch [61/300] Training [34/62] Loss: 0.43728 
Epoch [61/300] Training [35/62] Loss: 0.22792 
Epoch [61/300] Training [36/62] Loss: 0.35231 
Epoch [61/300] Training [37/62] Loss: 0.39054 
Epoch [61/300] Training [38/62] Loss: 0.19365 
Epoch [61/300] Training [39/62] Loss: 0.17997 
Epoch [61/300] Training [40/62] Loss: 0.40303 
Epoch [61/300] Training [41/62] Loss: 0.38656 
Epoch [61/300] Training [42/62] Loss: 0.26357 
Epoch [61/300] Training [43/62] Loss: 0.30263 
Epoch [61/300] Training [44/62] Loss: 0.33221 
Epoch [61/300] Training [45/62] Loss: 0.35236 
Epoch [61/300] Training [46/62] Loss: 0.32826 
Epoch [61/300] Training [47/62] Loss: 0.71722 
Epoch [61/300] Training [48/62] Loss: 0.36885 
Epoch [61/300] Training [49/62] Loss: 0.40971 
Epoch [61/300] Training [50/62] Loss: 0.30552 
Epoch [61/300] Training [51/62] Loss: 0.22788 
Epoch [61/300] Training [52/62] Loss: 0.35346 
Epoch [61/300] Training [53/62] Loss: 0.39283 
Epoch [61/300] Training [54/62] Loss: 0.21951 
Epoch [61/300] Training [55/62] Loss: 0.60862 
Epoch [61/300] Training [56/62] Loss: 0.20676 
Epoch [61/300] Training [57/62] Loss: 0.36995 
Epoch [61/300] Training [58/62] Loss: 0.35887 
Epoch [61/300] Training [59/62] Loss: 0.54697 
Epoch [61/300] Training [60/62] Loss: 0.29473 
Epoch [61/300] Training [61/62] Loss: 0.30784 
Epoch [61/300] Training [62/62] Loss: 0.35645 
Epoch [61/300] Training metric {'Train/mean dice_metric': 0.767891526222229, 'Train/mean miou_metric': 0.6645628213882446, 'Train/mean f1': 0.7968489527702332, 'Train/mean precision': 0.8059511780738831, 'Train/mean recall': 0.7879499793052673, 'Train/mean hd95_metric': 57.723602294921875}
Epoch [61/300] Validation [1/16] Loss: 0.54844  focal_loss 0.29434  dice_loss 0.25410 
Epoch [61/300] Validation [2/16] Loss: 0.46731  focal_loss 0.10290  dice_loss 0.36441 
Epoch [61/300] Validation [3/16] Loss: 0.53755  focal_loss 0.15313  dice_loss 0.38442 
Epoch [61/300] Validation [4/16] Loss: 0.43990  focal_loss 0.14383  dice_loss 0.29607 
Epoch [61/300] Validation [5/16] Loss: 0.44494  focal_loss 0.06628  dice_loss 0.37866 
Epoch [61/300] Validation [6/16] Loss: 0.60363  focal_loss 0.15825  dice_loss 0.44537 
Epoch [61/300] Validation [7/16] Loss: 0.25412  focal_loss 0.06049  dice_loss 0.19363 
Epoch [61/300] Validation [8/16] Loss: 0.64277  focal_loss 0.15102  dice_loss 0.49175 
Epoch [61/300] Validation [9/16] Loss: 0.32626  focal_loss 0.09041  dice_loss 0.23585 
Epoch [61/300] Validation [10/16] Loss: 0.60526  focal_loss 0.15729  dice_loss 0.44796 
Epoch [61/300] Validation [11/16] Loss: 0.46030  focal_loss 0.12424  dice_loss 0.33606 
Epoch [61/300] Validation [12/16] Loss: 0.52382  focal_loss 0.07539  dice_loss 0.44844 
Epoch [61/300] Validation [13/16] Loss: 0.49669  focal_loss 0.14430  dice_loss 0.35239 
Epoch [61/300] Validation [14/16] Loss: 0.58361  focal_loss 0.14089  dice_loss 0.44271 
Epoch [61/300] Validation [15/16] Loss: 0.28710  focal_loss 0.07945  dice_loss 0.20765 
Epoch [61/300] Validation [16/16] Loss: 0.27067  focal_loss 0.07177  dice_loss 0.19889 
Epoch [61/300] Validation metric {'Val/mean dice_metric': 0.7507530450820923, 'Val/mean miou_metric': 0.6466097831726074, 'Val/mean f1': 0.7824417352676392, 'Val/mean precision': 0.7900620102882385, 'Val/mean recall': 0.7749670743942261, 'Val/mean hd95_metric': 61.09206771850586}
Cheakpoint...
Epoch [61/300] best acc:tensor([0.7508], device='cuda:0'), Now : mean acc: tensor([0.7508], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7507530450820923, 'Val/mean miou_metric': 0.6466097831726074, 'Val/mean f1': 0.7824417352676392, 'Val/mean precision': 0.7900620102882385, 'Val/mean recall': 0.7749670743942261, 'Val/mean hd95_metric': 61.09206771850586}
Epoch [62/300] Training [1/62] Loss: 0.23785 
Epoch [62/300] Training [2/62] Loss: 0.40777 
Epoch [62/300] Training [3/62] Loss: 0.14869 
Epoch [62/300] Training [4/62] Loss: 0.31194 
Epoch [62/300] Training [5/62] Loss: 0.47913 
Epoch [62/300] Training [6/62] Loss: 0.37350 
Epoch [62/300] Training [7/62] Loss: 0.36572 
Epoch [62/300] Training [8/62] Loss: 0.40625 
Epoch [62/300] Training [9/62] Loss: 0.38087 
Epoch [62/300] Training [10/62] Loss: 0.46459 
Epoch [62/300] Training [11/62] Loss: 0.32239 
Epoch [62/300] Training [12/62] Loss: 0.21554 
Epoch [62/300] Training [13/62] Loss: 0.33937 
Epoch [62/300] Training [14/62] Loss: 0.26495 
Epoch [62/300] Training [15/62] Loss: 0.29394 
Epoch [62/300] Training [16/62] Loss: 0.33042 
Epoch [62/300] Training [17/62] Loss: 0.25202 
Epoch [62/300] Training [18/62] Loss: 0.36300 
Epoch [62/300] Training [19/62] Loss: 0.24321 
Epoch [62/300] Training [20/62] Loss: 0.42973 
Epoch [62/300] Training [21/62] Loss: 0.48924 
Epoch [62/300] Training [22/62] Loss: 0.30435 
Epoch [62/300] Training [23/62] Loss: 0.19537 
Epoch [62/300] Training [24/62] Loss: 0.25034 
Epoch [62/300] Training [25/62] Loss: 0.33583 
Epoch [62/300] Training [26/62] Loss: 0.34068 
Epoch [62/300] Training [27/62] Loss: 0.27468 
Epoch [62/300] Training [28/62] Loss: 0.28214 
Epoch [62/300] Training [29/62] Loss: 0.42383 
Epoch [62/300] Training [30/62] Loss: 0.42203 
Epoch [62/300] Training [31/62] Loss: 0.30507 
Epoch [62/300] Training [32/62] Loss: 0.51009 
Epoch [62/300] Training [33/62] Loss: 0.41268 
Epoch [62/300] Training [34/62] Loss: 0.35231 
Epoch [62/300] Training [35/62] Loss: 0.39007 
Epoch [62/300] Training [36/62] Loss: 0.30314 
Epoch [62/300] Training [37/62] Loss: 0.46118 
Epoch [62/300] Training [38/62] Loss: 0.37537 
Epoch [62/300] Training [39/62] Loss: 0.57317 
Epoch [62/300] Training [40/62] Loss: 0.31720 
Epoch [62/300] Training [41/62] Loss: 0.19557 
Epoch [62/300] Training [42/62] Loss: 0.37262 
Epoch [62/300] Training [43/62] Loss: 0.33185 
Epoch [62/300] Training [44/62] Loss: 0.23822 
Epoch [62/300] Training [45/62] Loss: 0.29531 
Epoch [62/300] Training [46/62] Loss: 0.37623 
Epoch [62/300] Training [47/62] Loss: 0.35309 
Epoch [62/300] Training [48/62] Loss: 0.19043 
Epoch [62/300] Training [49/62] Loss: 0.40461 
Epoch [62/300] Training [50/62] Loss: 0.36049 
Epoch [62/300] Training [51/62] Loss: 0.38450 
Epoch [62/300] Training [52/62] Loss: 0.33676 
Epoch [62/300] Training [53/62] Loss: 0.27615 
Epoch [62/300] Training [54/62] Loss: 0.22283 
Epoch [62/300] Training [55/62] Loss: 0.37950 
Epoch [62/300] Training [56/62] Loss: 0.30213 
Epoch [62/300] Training [57/62] Loss: 0.28813 
Epoch [62/300] Training [58/62] Loss: 0.53035 
Epoch [62/300] Training [59/62] Loss: 0.33749 
Epoch [62/300] Training [60/62] Loss: 0.36487 
Epoch [62/300] Training [61/62] Loss: 0.24006 
Epoch [62/300] Training [62/62] Loss: 0.32844 
Epoch [62/300] Training metric {'Train/mean dice_metric': 0.7692012190818787, 'Train/mean miou_metric': 0.6686253547668457, 'Train/mean f1': 0.8035340905189514, 'Train/mean precision': 0.8141723871231079, 'Train/mean recall': 0.7931700944900513, 'Train/mean hd95_metric': 57.05001449584961}
Epoch [62/300] Validation [1/16] Loss: 0.75275  focal_loss 0.33579  dice_loss 0.41696 
Epoch [62/300] Validation [2/16] Loss: 0.50563  focal_loss 0.09499  dice_loss 0.41064 
Epoch [62/300] Validation [3/16] Loss: 0.53030  focal_loss 0.12425  dice_loss 0.40605 
Epoch [62/300] Validation [4/16] Loss: 0.45062  focal_loss 0.11239  dice_loss 0.33823 
Epoch [62/300] Validation [5/16] Loss: 0.53201  focal_loss 0.07768  dice_loss 0.45433 
Epoch [62/300] Validation [6/16] Loss: 0.40521  focal_loss 0.07652  dice_loss 0.32869 
Epoch [62/300] Validation [7/16] Loss: 0.35682  focal_loss 0.06535  dice_loss 0.29146 
Epoch [62/300] Validation [8/16] Loss: 0.69476  focal_loss 0.13985  dice_loss 0.55491 
Epoch [62/300] Validation [9/16] Loss: 0.44873  focal_loss 0.09338  dice_loss 0.35536 
Epoch [62/300] Validation [10/16] Loss: 0.53774  focal_loss 0.11111  dice_loss 0.42664 
Epoch [62/300] Validation [11/16] Loss: 0.30227  focal_loss 0.05616  dice_loss 0.24611 
Epoch [62/300] Validation [12/16] Loss: 0.54693  focal_loss 0.05135  dice_loss 0.49558 
Epoch [62/300] Validation [13/16] Loss: 0.33027  focal_loss 0.04073  dice_loss 0.28954 
Epoch [62/300] Validation [14/16] Loss: 0.78163  focal_loss 0.15450  dice_loss 0.62713 
Epoch [62/300] Validation [15/16] Loss: 0.29575  focal_loss 0.05113  dice_loss 0.24461 
Epoch [62/300] Validation [16/16] Loss: 0.30701  focal_loss 0.07032  dice_loss 0.23670 
Epoch [62/300] Validation metric {'Val/mean dice_metric': 0.7462616562843323, 'Val/mean miou_metric': 0.6432862281799316, 'Val/mean f1': 0.7829272747039795, 'Val/mean precision': 0.785761296749115, 'Val/mean recall': 0.7801136374473572, 'Val/mean hd95_metric': 62.51579284667969}
Cheakpoint...
Epoch [62/300] best acc:tensor([0.7508], device='cuda:0'), Now : mean acc: tensor([0.7463], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7462616562843323, 'Val/mean miou_metric': 0.6432862281799316, 'Val/mean f1': 0.7829272747039795, 'Val/mean precision': 0.785761296749115, 'Val/mean recall': 0.7801136374473572, 'Val/mean hd95_metric': 62.51579284667969}
Epoch [63/300] Training [1/62] Loss: 0.39811 
Epoch [63/300] Training [2/62] Loss: 0.64542 
Epoch [63/300] Training [3/62] Loss: 0.32468 
Epoch [63/300] Training [4/62] Loss: 0.19496 
Epoch [63/300] Training [5/62] Loss: 0.22866 
Epoch [63/300] Training [6/62] Loss: 0.27745 
Epoch [63/300] Training [7/62] Loss: 0.32334 
Epoch [63/300] Training [8/62] Loss: 0.22667 
Epoch [63/300] Training [9/62] Loss: 0.19831 
Epoch [63/300] Training [10/62] Loss: 0.32703 
Epoch [63/300] Training [11/62] Loss: 0.37648 
Epoch [63/300] Training [12/62] Loss: 0.48154 
Epoch [63/300] Training [13/62] Loss: 0.34693 
Epoch [63/300] Training [14/62] Loss: 0.41630 
Epoch [63/300] Training [15/62] Loss: 0.38939 
Epoch [63/300] Training [16/62] Loss: 0.29394 
Epoch [63/300] Training [17/62] Loss: 0.21255 
Epoch [63/300] Training [18/62] Loss: 0.24711 
Epoch [63/300] Training [19/62] Loss: 0.29790 
Epoch [63/300] Training [20/62] Loss: 0.30798 
Epoch [63/300] Training [21/62] Loss: 0.34844 
Epoch [63/300] Training [22/62] Loss: 0.26745 
Epoch [63/300] Training [23/62] Loss: 0.25638 
Epoch [63/300] Training [24/62] Loss: 0.21705 
Epoch [63/300] Training [25/62] Loss: 0.39543 
Epoch [63/300] Training [26/62] Loss: 0.30254 
Epoch [63/300] Training [27/62] Loss: 0.34804 
Epoch [63/300] Training [28/62] Loss: 0.33462 
Epoch [63/300] Training [29/62] Loss: 0.43704 
Epoch [63/300] Training [30/62] Loss: 0.26423 
Epoch [63/300] Training [31/62] Loss: 0.33712 
Epoch [63/300] Training [32/62] Loss: 0.42277 
Epoch [63/300] Training [33/62] Loss: 0.34564 
Epoch [63/300] Training [34/62] Loss: 0.32603 
Epoch [63/300] Training [35/62] Loss: 0.31931 
Epoch [63/300] Training [36/62] Loss: 0.37001 
Epoch [63/300] Training [37/62] Loss: 0.43947 
Epoch [63/300] Training [38/62] Loss: 0.40951 
Epoch [63/300] Training [39/62] Loss: 0.19443 
Epoch [63/300] Training [40/62] Loss: 0.31987 
Epoch [63/300] Training [41/62] Loss: 0.23610 
Epoch [63/300] Training [42/62] Loss: 0.41230 
Epoch [63/300] Training [43/62] Loss: 0.35348 
Epoch [63/300] Training [44/62] Loss: 0.41188 
Epoch [63/300] Training [45/62] Loss: 0.40025 
Epoch [63/300] Training [46/62] Loss: 0.22967 
Epoch [63/300] Training [47/62] Loss: 0.42369 
Epoch [63/300] Training [48/62] Loss: 0.18522 
Epoch [63/300] Training [49/62] Loss: 0.42393 
Epoch [63/300] Training [50/62] Loss: 0.36788 
Epoch [63/300] Training [51/62] Loss: 0.18553 
Epoch [63/300] Training [52/62] Loss: 0.35745 
Epoch [63/300] Training [53/62] Loss: 0.23876 
Epoch [63/300] Training [54/62] Loss: 0.36669 
Epoch [63/300] Training [55/62] Loss: 0.26468 
Epoch [63/300] Training [56/62] Loss: 0.31553 
Epoch [63/300] Training [57/62] Loss: 0.49111 
Epoch [63/300] Training [58/62] Loss: 0.35835 
Epoch [63/300] Training [59/62] Loss: 0.27049 
Epoch [63/300] Training [60/62] Loss: 0.18349 
Epoch [63/300] Training [61/62] Loss: 0.22736 
Epoch [63/300] Training [62/62] Loss: 0.31141 
Epoch [63/300] Training metric {'Train/mean dice_metric': 0.784173309803009, 'Train/mean miou_metric': 0.6840810179710388, 'Train/mean f1': 0.8092249035835266, 'Train/mean precision': 0.8299990892410278, 'Train/mean recall': 0.7894651293754578, 'Train/mean hd95_metric': 54.968692779541016}
Epoch [63/300] Validation [1/16] Loss: 0.42988  focal_loss 0.17166  dice_loss 0.25822 
Epoch [63/300] Validation [2/16] Loss: 0.53526  focal_loss 0.11479  dice_loss 0.42047 
Epoch [63/300] Validation [3/16] Loss: 0.56468  focal_loss 0.17844  dice_loss 0.38624 
Epoch [63/300] Validation [4/16] Loss: 0.46639  focal_loss 0.12151  dice_loss 0.34488 
Epoch [63/300] Validation [5/16] Loss: 0.47854  focal_loss 0.07574  dice_loss 0.40279 
Epoch [63/300] Validation [6/16] Loss: 0.49729  focal_loss 0.12302  dice_loss 0.37428 
Epoch [63/300] Validation [7/16] Loss: 0.28287  focal_loss 0.06609  dice_loss 0.21678 
Epoch [63/300] Validation [8/16] Loss: 0.45815  focal_loss 0.09505  dice_loss 0.36310 
Epoch [63/300] Validation [9/16] Loss: 0.37682  focal_loss 0.08799  dice_loss 0.28884 
Epoch [63/300] Validation [10/16] Loss: 0.70847  focal_loss 0.18451  dice_loss 0.52396 
Epoch [63/300] Validation [11/16] Loss: 0.31442  focal_loss 0.05417  dice_loss 0.26025 
Epoch [63/300] Validation [12/16] Loss: 0.45457  focal_loss 0.05844  dice_loss 0.39613 
Epoch [63/300] Validation [13/16] Loss: 0.46663  focal_loss 0.12689  dice_loss 0.33974 
Epoch [63/300] Validation [14/16] Loss: 0.64775  focal_loss 0.11251  dice_loss 0.53523 
Epoch [63/300] Validation [15/16] Loss: 0.23707  focal_loss 0.04694  dice_loss 0.19013 
Epoch [63/300] Validation [16/16] Loss: 0.30803  focal_loss 0.08156  dice_loss 0.22647 
Epoch [63/300] Validation metric {'Val/mean dice_metric': 0.7635120749473572, 'Val/mean miou_metric': 0.6611822843551636, 'Val/mean f1': 0.7924158573150635, 'Val/mean precision': 0.8009174466133118, 'Val/mean recall': 0.7840928435325623, 'Val/mean hd95_metric': 62.3582649230957}
Cheakpoint...
Epoch [63/300] best acc:tensor([0.7635], device='cuda:0'), Now : mean acc: tensor([0.7635], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7635120749473572, 'Val/mean miou_metric': 0.6611822843551636, 'Val/mean f1': 0.7924158573150635, 'Val/mean precision': 0.8009174466133118, 'Val/mean recall': 0.7840928435325623, 'Val/mean hd95_metric': 62.3582649230957}
Epoch [64/300] Training [1/62] Loss: 0.54495 
Epoch [64/300] Training [2/62] Loss: 0.43626 
Epoch [64/300] Training [3/62] Loss: 0.33641 
Epoch [64/300] Training [4/62] Loss: 0.33508 
Epoch [64/300] Training [5/62] Loss: 0.34519 
Epoch [64/300] Training [6/62] Loss: 0.25208 
Epoch [64/300] Training [7/62] Loss: 0.30274 
Epoch [64/300] Training [8/62] Loss: 0.25542 
Epoch [64/300] Training [9/62] Loss: 0.14765 
Epoch [64/300] Training [10/62] Loss: 0.40805 
Epoch [64/300] Training [11/62] Loss: 0.31230 
Epoch [64/300] Training [12/62] Loss: 0.38403 
Epoch [64/300] Training [13/62] Loss: 0.24378 
Epoch [64/300] Training [14/62] Loss: 0.62455 
Epoch [64/300] Training [15/62] Loss: 0.35008 
Epoch [64/300] Training [16/62] Loss: 0.19266 
Epoch [64/300] Training [17/62] Loss: 0.27563 
Epoch [64/300] Training [18/62] Loss: 0.19489 
Epoch [64/300] Training [19/62] Loss: 0.28356 
Epoch [64/300] Training [20/62] Loss: 0.32242 
Epoch [64/300] Training [21/62] Loss: 0.19424 
Epoch [64/300] Training [22/62] Loss: 0.49538 
Epoch [64/300] Training [23/62] Loss: 0.42724 
Epoch [64/300] Training [24/62] Loss: 0.25692 
Epoch [64/300] Training [25/62] Loss: 0.50147 
Epoch [64/300] Training [26/62] Loss: 0.22560 
Epoch [64/300] Training [27/62] Loss: 0.27269 
Epoch [64/300] Training [28/62] Loss: 0.30994 
Epoch [64/300] Training [29/62] Loss: 0.19761 
Epoch [64/300] Training [30/62] Loss: 0.37688 
Epoch [64/300] Training [31/62] Loss: 0.24857 
Epoch [64/300] Training [32/62] Loss: 0.38445 
Epoch [64/300] Training [33/62] Loss: 0.32595 
Epoch [64/300] Training [34/62] Loss: 0.30699 
Epoch [64/300] Training [35/62] Loss: 0.22457 
Epoch [64/300] Training [36/62] Loss: 0.32789 
Epoch [64/300] Training [37/62] Loss: 0.46710 
Epoch [64/300] Training [38/62] Loss: 0.22004 
Epoch [64/300] Training [39/62] Loss: 0.31705 
Epoch [64/300] Training [40/62] Loss: 0.39530 
Epoch [64/300] Training [41/62] Loss: 0.22276 
Epoch [64/300] Training [42/62] Loss: 0.48282 
Epoch [64/300] Training [43/62] Loss: 0.42584 
Epoch [64/300] Training [44/62] Loss: 0.39974 
Epoch [64/300] Training [45/62] Loss: 0.26362 
Epoch [64/300] Training [46/62] Loss: 0.41485 
Epoch [64/300] Training [47/62] Loss: 0.70393 
Epoch [64/300] Training [48/62] Loss: 0.46422 
Epoch [64/300] Training [49/62] Loss: 0.52031 
Epoch [64/300] Training [50/62] Loss: 0.25104 
Epoch [64/300] Training [51/62] Loss: 0.33876 
Epoch [64/300] Training [52/62] Loss: 0.46530 
Epoch [64/300] Training [53/62] Loss: 0.24732 
Epoch [64/300] Training [54/62] Loss: 0.28191 
Epoch [64/300] Training [55/62] Loss: 0.57123 
Epoch [64/300] Training [56/62] Loss: 0.54416 
Epoch [64/300] Training [57/62] Loss: 0.35097 
Epoch [64/300] Training [58/62] Loss: 0.22503 
Epoch [64/300] Training [59/62] Loss: 0.22433 
Epoch [64/300] Training [60/62] Loss: 0.42946 
Epoch [64/300] Training [61/62] Loss: 0.34520 
Epoch [64/300] Training [62/62] Loss: 0.63416 
Epoch [64/300] Training metric {'Train/mean dice_metric': 0.770023763179779, 'Train/mean miou_metric': 0.6722301244735718, 'Train/mean f1': 0.7967023253440857, 'Train/mean precision': 0.8074501752853394, 'Train/mean recall': 0.7862368822097778, 'Train/mean hd95_metric': 56.15016174316406}
Epoch [64/300] Validation [1/16] Loss: 0.76022  focal_loss 0.28183  dice_loss 0.47839 
Epoch [64/300] Validation [2/16] Loss: 0.62201  focal_loss 0.13275  dice_loss 0.48926 
Epoch [64/300] Validation [3/16] Loss: 0.82373  focal_loss 0.18646  dice_loss 0.63726 
Epoch [64/300] Validation [4/16] Loss: 0.64876  focal_loss 0.15249  dice_loss 0.49627 
Epoch [64/300] Validation [5/16] Loss: 0.51900  focal_loss 0.08158  dice_loss 0.43742 
Epoch [64/300] Validation [6/16] Loss: 0.60462  focal_loss 0.10698  dice_loss 0.49763 
Epoch [64/300] Validation [7/16] Loss: 0.56312  focal_loss 0.13262  dice_loss 0.43050 
Epoch [64/300] Validation [8/16] Loss: 0.91017  focal_loss 0.19615  dice_loss 0.71402 
Epoch [64/300] Validation [9/16] Loss: 0.94694  focal_loss 0.35413  dice_loss 0.59281 
Epoch [64/300] Validation [10/16] Loss: 0.49655  focal_loss 0.08212  dice_loss 0.41443 
Epoch [64/300] Validation [11/16] Loss: 0.55630  focal_loss 0.08650  dice_loss 0.46980 
Epoch [64/300] Validation [12/16] Loss: 0.85480  focal_loss 0.15343  dice_loss 0.70136 
Epoch [64/300] Validation [13/16] Loss: 0.59849  focal_loss 0.16376  dice_loss 0.43473 
Epoch [64/300] Validation [14/16] Loss: 1.03628  focal_loss 0.23255  dice_loss 0.80373 
Epoch [64/300] Validation [15/16] Loss: 0.74184  focal_loss 0.18003  dice_loss 0.56181 
Epoch [64/300] Validation [16/16] Loss: 0.49012  focal_loss 0.13054  dice_loss 0.35959 
Epoch [64/300] Validation metric {'Val/mean dice_metric': 0.7146633863449097, 'Val/mean miou_metric': 0.6161078810691833, 'Val/mean f1': 0.7501081228256226, 'Val/mean precision': 0.7484479546546936, 'Val/mean recall': 0.7517755031585693, 'Val/mean hd95_metric': 66.04666900634766}
Cheakpoint...
Epoch [64/300] best acc:tensor([0.7635], device='cuda:0'), Now : mean acc: tensor([0.7147], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7146633863449097, 'Val/mean miou_metric': 0.6161078810691833, 'Val/mean f1': 0.7501081228256226, 'Val/mean precision': 0.7484479546546936, 'Val/mean recall': 0.7517755031585693, 'Val/mean hd95_metric': 66.04666900634766}
Epoch [65/300] Training [1/62] Loss: 0.43574 
Epoch [65/300] Training [2/62] Loss: 0.29749 
Epoch [65/300] Training [3/62] Loss: 0.36126 
Epoch [65/300] Training [4/62] Loss: 0.34715 
Epoch [65/300] Training [5/62] Loss: 0.29651 
Epoch [65/300] Training [6/62] Loss: 0.34951 
Epoch [65/300] Training [7/62] Loss: 0.40887 
Epoch [65/300] Training [8/62] Loss: 0.25025 
Epoch [65/300] Training [9/62] Loss: 0.28821 
Epoch [65/300] Training [10/62] Loss: 0.18359 
Epoch [65/300] Training [11/62] Loss: 0.28223 
Epoch [65/300] Training [12/62] Loss: 0.27731 
Epoch [65/300] Training [13/62] Loss: 0.59155 
Epoch [65/300] Training [14/62] Loss: 0.30670 
Epoch [65/300] Training [15/62] Loss: 0.31092 
Epoch [65/300] Training [16/62] Loss: 0.52159 
Epoch [65/300] Training [17/62] Loss: 0.37795 
Epoch [65/300] Training [18/62] Loss: 0.29953 
Epoch [65/300] Training [19/62] Loss: 0.28759 
Epoch [65/300] Training [20/62] Loss: 0.23038 
Epoch [65/300] Training [21/62] Loss: 0.30464 
Epoch [65/300] Training [22/62] Loss: 0.30220 
Epoch [65/300] Training [23/62] Loss: 0.56395 
Epoch [65/300] Training [24/62] Loss: 0.30511 
Epoch [65/300] Training [25/62] Loss: 0.31976 
Epoch [65/300] Training [26/62] Loss: 0.20704 
Epoch [65/300] Training [27/62] Loss: 0.36671 
Epoch [65/300] Training [28/62] Loss: 0.46086 
Epoch [65/300] Training [29/62] Loss: 0.34202 
Epoch [65/300] Training [30/62] Loss: 0.46452 
Epoch [65/300] Training [31/62] Loss: 0.31732 
Epoch [65/300] Training [32/62] Loss: 0.45021 
Epoch [65/300] Training [33/62] Loss: 0.19572 
Epoch [65/300] Training [34/62] Loss: 0.41657 
Epoch [65/300] Training [35/62] Loss: 0.25263 
Epoch [65/300] Training [36/62] Loss: 0.31355 
Epoch [65/300] Training [37/62] Loss: 0.33659 
Epoch [65/300] Training [38/62] Loss: 0.14327 
Epoch [65/300] Training [39/62] Loss: 0.35598 
Epoch [65/300] Training [40/62] Loss: 0.38456 
Epoch [65/300] Training [41/62] Loss: 0.16433 
Epoch [65/300] Training [42/62] Loss: 0.18108 
Epoch [65/300] Training [43/62] Loss: 0.32634 
Epoch [65/300] Training [44/62] Loss: 0.23228 
Epoch [65/300] Training [45/62] Loss: 0.45636 
Epoch [65/300] Training [46/62] Loss: 0.18465 
Epoch [65/300] Training [47/62] Loss: 0.45041 
Epoch [65/300] Training [48/62] Loss: 0.57263 
Epoch [65/300] Training [49/62] Loss: 0.29618 
Epoch [65/300] Training [50/62] Loss: 0.27486 
Epoch [65/300] Training [51/62] Loss: 0.25498 
Epoch [65/300] Training [52/62] Loss: 0.28872 
Epoch [65/300] Training [53/62] Loss: 0.16525 
Epoch [65/300] Training [54/62] Loss: 0.42283 
Epoch [65/300] Training [55/62] Loss: 0.22468 
Epoch [65/300] Training [56/62] Loss: 0.28456 
Epoch [65/300] Training [57/62] Loss: 0.26541 
Epoch [65/300] Training [58/62] Loss: 0.34280 
Epoch [65/300] Training [59/62] Loss: 0.25832 
Epoch [65/300] Training [60/62] Loss: 0.41636 
Epoch [65/300] Training [61/62] Loss: 0.48940 
Epoch [65/300] Training [62/62] Loss: 0.76498 
Epoch [65/300] Training metric {'Train/mean dice_metric': 0.7760673761367798, 'Train/mean miou_metric': 0.6789714097976685, 'Train/mean f1': 0.8138545751571655, 'Train/mean precision': 0.8321037292480469, 'Train/mean recall': 0.7963887453079224, 'Train/mean hd95_metric': 54.171661376953125}
Epoch [65/300] Validation [1/16] Loss: 0.78659  focal_loss 0.41404  dice_loss 0.37255 
Epoch [65/300] Validation [2/16] Loss: 0.66876  focal_loss 0.21417  dice_loss 0.45460 
Epoch [65/300] Validation [3/16] Loss: 0.68851  focal_loss 0.24548  dice_loss 0.44303 
Epoch [65/300] Validation [4/16] Loss: 0.68681  focal_loss 0.29135  dice_loss 0.39545 
Epoch [65/300] Validation [5/16] Loss: 0.50425  focal_loss 0.08948  dice_loss 0.41477 
Epoch [65/300] Validation [6/16] Loss: 0.39261  focal_loss 0.11315  dice_loss 0.27946 
Epoch [65/300] Validation [7/16] Loss: 0.49693  focal_loss 0.17032  dice_loss 0.32661 
Epoch [65/300] Validation [8/16] Loss: 0.63694  focal_loss 0.15711  dice_loss 0.47983 
Epoch [65/300] Validation [9/16] Loss: 0.65274  focal_loss 0.23049  dice_loss 0.42225 
Epoch [65/300] Validation [10/16] Loss: 0.68592  focal_loss 0.23656  dice_loss 0.44936 
Epoch [65/300] Validation [11/16] Loss: 0.35101  focal_loss 0.09290  dice_loss 0.25811 
Epoch [65/300] Validation [12/16] Loss: 0.50987  focal_loss 0.10047  dice_loss 0.40940 
Epoch [65/300] Validation [13/16] Loss: 0.38063  focal_loss 0.11329  dice_loss 0.26734 
Epoch [65/300] Validation [14/16] Loss: 0.94730  focal_loss 0.30042  dice_loss 0.64687 
Epoch [65/300] Validation [15/16] Loss: 0.48478  focal_loss 0.17419  dice_loss 0.31058 
Epoch [65/300] Validation [16/16] Loss: 0.32868  focal_loss 0.10327  dice_loss 0.22541 
Epoch [65/300] Validation metric {'Val/mean dice_metric': 0.7440869808197021, 'Val/mean miou_metric': 0.6452882289886475, 'Val/mean f1': 0.787614643573761, 'Val/mean precision': 0.8316752314567566, 'Val/mean recall': 0.747987687587738, 'Val/mean hd95_metric': 57.16996383666992}
Cheakpoint...
Epoch [65/300] best acc:tensor([0.7635], device='cuda:0'), Now : mean acc: tensor([0.7441], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7440869808197021, 'Val/mean miou_metric': 0.6452882289886475, 'Val/mean f1': 0.787614643573761, 'Val/mean precision': 0.8316752314567566, 'Val/mean recall': 0.747987687587738, 'Val/mean hd95_metric': 57.16996383666992}
Epoch [66/300] Training [1/62] Loss: 0.21904 
Epoch [66/300] Training [2/62] Loss: 0.24392 
Epoch [66/300] Training [3/62] Loss: 0.35648 
Epoch [66/300] Training [4/62] Loss: 0.34844 
Epoch [66/300] Training [5/62] Loss: 0.23166 
Epoch [66/300] Training [6/62] Loss: 0.42456 
Epoch [66/300] Training [7/62] Loss: 0.19523 
Epoch [66/300] Training [8/62] Loss: 0.32407 
Epoch [66/300] Training [9/62] Loss: 0.31245 
Epoch [66/300] Training [10/62] Loss: 0.34336 
Epoch [66/300] Training [11/62] Loss: 0.33929 
Epoch [66/300] Training [12/62] Loss: 0.36790 
Epoch [66/300] Training [13/62] Loss: 0.40442 
Epoch [66/300] Training [14/62] Loss: 0.31993 
Epoch [66/300] Training [15/62] Loss: 0.48054 
Epoch [66/300] Training [16/62] Loss: 0.56472 
Epoch [66/300] Training [17/62] Loss: 0.36712 
Epoch [66/300] Training [18/62] Loss: 0.28806 
Epoch [66/300] Training [19/62] Loss: 0.46080 
Epoch [66/300] Training [20/62] Loss: 0.42101 
Epoch [66/300] Training [21/62] Loss: 0.29689 
Epoch [66/300] Training [22/62] Loss: 0.32006 
Epoch [66/300] Training [23/62] Loss: 0.39325 
Epoch [66/300] Training [24/62] Loss: 0.48531 
Epoch [66/300] Training [25/62] Loss: 0.30599 
Epoch [66/300] Training [26/62] Loss: 0.30962 
Epoch [66/300] Training [27/62] Loss: 0.24269 
Epoch [66/300] Training [28/62] Loss: 0.22737 
Epoch [66/300] Training [29/62] Loss: 0.30338 
Epoch [66/300] Training [30/62] Loss: 0.58331 
Epoch [66/300] Training [31/62] Loss: 0.30659 
Epoch [66/300] Training [32/62] Loss: 0.29090 
Epoch [66/300] Training [33/62] Loss: 0.21404 
Epoch [66/300] Training [34/62] Loss: 0.23406 
Epoch [66/300] Training [35/62] Loss: 0.19662 
Epoch [66/300] Training [36/62] Loss: 0.27693 
Epoch [66/300] Training [37/62] Loss: 0.38131 
Epoch [66/300] Training [38/62] Loss: 0.28419 
Epoch [66/300] Training [39/62] Loss: 0.19883 
Epoch [66/300] Training [40/62] Loss: 0.56961 
Epoch [66/300] Training [41/62] Loss: 0.31445 
Epoch [66/300] Training [42/62] Loss: 0.45772 
Epoch [66/300] Training [43/62] Loss: 0.46550 
Epoch [66/300] Training [44/62] Loss: 0.22249 
Epoch [66/300] Training [45/62] Loss: 0.24691 
Epoch [66/300] Training [46/62] Loss: 0.38280 
Epoch [66/300] Training [47/62] Loss: 0.23387 
Epoch [66/300] Training [48/62] Loss: 0.24486 
Epoch [66/300] Training [49/62] Loss: 0.31481 
Epoch [66/300] Training [50/62] Loss: 0.68720 
Epoch [66/300] Training [51/62] Loss: 0.36587 
Epoch [66/300] Training [52/62] Loss: 0.37002 
Epoch [66/300] Training [53/62] Loss: 0.67898 
Epoch [66/300] Training [54/62] Loss: 0.27128 
Epoch [66/300] Training [55/62] Loss: 0.32538 
Epoch [66/300] Training [56/62] Loss: 0.49215 
Epoch [66/300] Training [57/62] Loss: 0.26331 
Epoch [66/300] Training [58/62] Loss: 0.32253 
Epoch [66/300] Training [59/62] Loss: 0.35295 
Epoch [66/300] Training [60/62] Loss: 0.52732 
Epoch [66/300] Training [61/62] Loss: 0.30838 
Epoch [66/300] Training [62/62] Loss: 1.47877 
Epoch [66/300] Training metric {'Train/mean dice_metric': 0.7667102217674255, 'Train/mean miou_metric': 0.66594398021698, 'Train/mean f1': 0.7904258966445923, 'Train/mean precision': 0.8091992735862732, 'Train/mean recall': 0.7725039124488831, 'Train/mean hd95_metric': 56.51171112060547}
Epoch [66/300] Validation [1/16] Loss: 0.76367  focal_loss 0.37918  dice_loss 0.38449 
Epoch [66/300] Validation [2/16] Loss: 0.61277  focal_loss 0.14575  dice_loss 0.46701 
Epoch [66/300] Validation [3/16] Loss: 0.69786  focal_loss 0.20720  dice_loss 0.49066 
Epoch [66/300] Validation [4/16] Loss: 0.68948  focal_loss 0.24824  dice_loss 0.44124 
Epoch [66/300] Validation [5/16] Loss: 0.53363  focal_loss 0.09873  dice_loss 0.43490 
Epoch [66/300] Validation [6/16] Loss: 0.36042  focal_loss 0.07104  dice_loss 0.28938 
Epoch [66/300] Validation [7/16] Loss: 0.43488  focal_loss 0.12877  dice_loss 0.30611 
Epoch [66/300] Validation [8/16] Loss: 0.68485  focal_loss 0.16710  dice_loss 0.51775 
Epoch [66/300] Validation [9/16] Loss: 0.62224  focal_loss 0.17378  dice_loss 0.44846 
Epoch [66/300] Validation [10/16] Loss: 0.87135  focal_loss 0.25531  dice_loss 0.61604 
Epoch [66/300] Validation [11/16] Loss: 0.47518  focal_loss 0.09390  dice_loss 0.38127 
Epoch [66/300] Validation [12/16] Loss: 0.71256  focal_loss 0.13234  dice_loss 0.58022 
Epoch [66/300] Validation [13/16] Loss: 0.37944  focal_loss 0.08392  dice_loss 0.29552 
Epoch [66/300] Validation [14/16] Loss: 0.86861  focal_loss 0.20501  dice_loss 0.66360 
Epoch [66/300] Validation [15/16] Loss: 0.26585  focal_loss 0.05820  dice_loss 0.20765 
Epoch [66/300] Validation [16/16] Loss: 0.27008  focal_loss 0.07078  dice_loss 0.19930 
Epoch [66/300] Validation metric {'Val/mean dice_metric': 0.7319245934486389, 'Val/mean miou_metric': 0.6305572986602783, 'Val/mean f1': 0.7668192982673645, 'Val/mean precision': 0.7939583659172058, 'Val/mean recall': 0.7414743304252625, 'Val/mean hd95_metric': 59.90945053100586}
Cheakpoint...
Epoch [66/300] best acc:tensor([0.7635], device='cuda:0'), Now : mean acc: tensor([0.7319], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7319245934486389, 'Val/mean miou_metric': 0.6305572986602783, 'Val/mean f1': 0.7668192982673645, 'Val/mean precision': 0.7939583659172058, 'Val/mean recall': 0.7414743304252625, 'Val/mean hd95_metric': 59.90945053100586}
Epoch [67/300] Training [1/62] Loss: 0.40999 
Epoch [67/300] Training [2/62] Loss: 0.21946 
Epoch [67/300] Training [3/62] Loss: 0.37569 
Epoch [67/300] Training [4/62] Loss: 0.29430 
Epoch [67/300] Training [5/62] Loss: 0.34390 
Epoch [67/300] Training [6/62] Loss: 0.36606 
Epoch [67/300] Training [7/62] Loss: 0.25087 
Epoch [67/300] Training [8/62] Loss: 0.28589 
Epoch [67/300] Training [9/62] Loss: 0.26740 
Epoch [67/300] Training [10/62] Loss: 0.34080 
Epoch [67/300] Training [11/62] Loss: 0.34329 
Epoch [67/300] Training [12/62] Loss: 0.51727 
Epoch [67/300] Training [13/62] Loss: 0.22870 
Epoch [67/300] Training [14/62] Loss: 0.58558 
Epoch [67/300] Training [15/62] Loss: 0.20788 
Epoch [67/300] Training [16/62] Loss: 0.34618 
Epoch [67/300] Training [17/62] Loss: 0.45590 
Epoch [67/300] Training [18/62] Loss: 0.40221 
Epoch [67/300] Training [19/62] Loss: 0.43245 
Epoch [67/300] Training [20/62] Loss: 0.19178 
Epoch [67/300] Training [21/62] Loss: 0.30543 
Epoch [67/300] Training [22/62] Loss: 0.53243 
Epoch [67/300] Training [23/62] Loss: 0.35316 
Epoch [67/300] Training [24/62] Loss: 0.37336 
Epoch [67/300] Training [25/62] Loss: 0.27249 
Epoch [67/300] Training [26/62] Loss: 0.28986 
Epoch [67/300] Training [27/62] Loss: 0.36175 
Epoch [67/300] Training [28/62] Loss: 0.40009 
Epoch [67/300] Training [29/62] Loss: 0.38365 
Epoch [67/300] Training [30/62] Loss: 0.26944 
Epoch [67/300] Training [31/62] Loss: 0.35515 
Epoch [67/300] Training [32/62] Loss: 0.27312 
Epoch [67/300] Training [33/62] Loss: 0.21106 
Epoch [67/300] Training [34/62] Loss: 0.45321 
Epoch [67/300] Training [35/62] Loss: 0.33457 
Epoch [67/300] Training [36/62] Loss: 0.32189 
Epoch [67/300] Training [37/62] Loss: 0.36337 
Epoch [67/300] Training [38/62] Loss: 0.26670 
Epoch [67/300] Training [39/62] Loss: 0.41656 
Epoch [67/300] Training [40/62] Loss: 0.18313 
Epoch [67/300] Training [41/62] Loss: 0.24701 
Epoch [67/300] Training [42/62] Loss: 0.41798 
Epoch [67/300] Training [43/62] Loss: 0.32459 
Epoch [67/300] Training [44/62] Loss: 0.33952 
Epoch [67/300] Training [45/62] Loss: 0.34122 
Epoch [67/300] Training [46/62] Loss: 0.69474 
Epoch [67/300] Training [47/62] Loss: 0.22168 
Epoch [67/300] Training [48/62] Loss: 0.23467 
Epoch [67/300] Training [49/62] Loss: 0.56229 
Epoch [67/300] Training [50/62] Loss: 0.47364 
Epoch [67/300] Training [51/62] Loss: 0.27697 
Epoch [67/300] Training [52/62] Loss: 0.37672 
Epoch [67/300] Training [53/62] Loss: 0.25107 
Epoch [67/300] Training [54/62] Loss: 0.27368 
Epoch [67/300] Training [55/62] Loss: 0.26035 
Epoch [67/300] Training [56/62] Loss: 0.37703 
Epoch [67/300] Training [57/62] Loss: 0.25441 
Epoch [67/300] Training [58/62] Loss: 0.33791 
Epoch [67/300] Training [59/62] Loss: 0.32333 
Epoch [67/300] Training [60/62] Loss: 0.21805 
Epoch [67/300] Training [61/62] Loss: 0.23902 
Epoch [67/300] Training [62/62] Loss: 0.26855 
Epoch [67/300] Training metric {'Train/mean dice_metric': 0.7739443778991699, 'Train/mean miou_metric': 0.6735320687294006, 'Train/mean f1': 0.8047767877578735, 'Train/mean precision': 0.8285037875175476, 'Train/mean recall': 0.7823708653450012, 'Train/mean hd95_metric': 57.18242645263672}
Epoch [67/300] Validation [1/16] Loss: 0.65846  focal_loss 0.34436  dice_loss 0.31410 
Epoch [67/300] Validation [2/16] Loss: 0.53538  focal_loss 0.16500  dice_loss 0.37038 
Epoch [67/300] Validation [3/16] Loss: 0.52409  focal_loss 0.18700  dice_loss 0.33709 
Epoch [67/300] Validation [4/16] Loss: 0.46838  focal_loss 0.17174  dice_loss 0.29665 
Epoch [67/300] Validation [5/16] Loss: 0.39996  focal_loss 0.09024  dice_loss 0.30973 
Epoch [67/300] Validation [6/16] Loss: 0.38301  focal_loss 0.09685  dice_loss 0.28616 
Epoch [67/300] Validation [7/16] Loss: 0.26999  focal_loss 0.06133  dice_loss 0.20866 
Epoch [67/300] Validation [8/16] Loss: 0.56273  focal_loss 0.14054  dice_loss 0.42219 
Epoch [67/300] Validation [9/16] Loss: 0.31074  focal_loss 0.07975  dice_loss 0.23100 
Epoch [67/300] Validation [10/16] Loss: 0.61401  focal_loss 0.17512  dice_loss 0.43889 
Epoch [67/300] Validation [11/16] Loss: 0.34341  focal_loss 0.07118  dice_loss 0.27223 
Epoch [67/300] Validation [12/16] Loss: 0.49358  focal_loss 0.07078  dice_loss 0.42280 
Epoch [67/300] Validation [13/16] Loss: 0.23850  focal_loss 0.05134  dice_loss 0.18716 
Epoch [67/300] Validation [14/16] Loss: 0.72471  focal_loss 0.22271  dice_loss 0.50200 
Epoch [67/300] Validation [15/16] Loss: 0.27887  focal_loss 0.08946  dice_loss 0.18941 
Epoch [67/300] Validation [16/16] Loss: 0.26541  focal_loss 0.08817  dice_loss 0.17724 
Epoch [67/300] Validation metric {'Val/mean dice_metric': 0.7599513530731201, 'Val/mean miou_metric': 0.6589476466178894, 'Val/mean f1': 0.7924630641937256, 'Val/mean precision': 0.8259108066558838, 'Val/mean recall': 0.7616189122200012, 'Val/mean hd95_metric': 57.81514358520508}
Cheakpoint...
Epoch [67/300] best acc:tensor([0.7635], device='cuda:0'), Now : mean acc: tensor([0.7600], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7599513530731201, 'Val/mean miou_metric': 0.6589476466178894, 'Val/mean f1': 0.7924630641937256, 'Val/mean precision': 0.8259108066558838, 'Val/mean recall': 0.7616189122200012, 'Val/mean hd95_metric': 57.81514358520508}
Epoch [68/300] Training [1/62] Loss: 0.16161 
Epoch [68/300] Training [2/62] Loss: 0.34457 
Epoch [68/300] Training [3/62] Loss: 0.38339 
Epoch [68/300] Training [4/62] Loss: 0.43332 
Epoch [68/300] Training [5/62] Loss: 0.32878 
Epoch [68/300] Training [6/62] Loss: 0.37987 
Epoch [68/300] Training [7/62] Loss: 0.26497 
Epoch [68/300] Training [8/62] Loss: 0.13240 
Epoch [68/300] Training [9/62] Loss: 0.27428 
Epoch [68/300] Training [10/62] Loss: 0.30479 
Epoch [68/300] Training [11/62] Loss: 0.37906 
Epoch [68/300] Training [12/62] Loss: 0.41456 
Epoch [68/300] Training [13/62] Loss: 0.24151 
Epoch [68/300] Training [14/62] Loss: 0.36068 
Epoch [68/300] Training [15/62] Loss: 0.19003 
Epoch [68/300] Training [16/62] Loss: 0.40358 
Epoch [68/300] Training [17/62] Loss: 0.20399 
Epoch [68/300] Training [18/62] Loss: 0.36306 
Epoch [68/300] Training [19/62] Loss: 0.35898 
Epoch [68/300] Training [20/62] Loss: 0.28074 
Epoch [68/300] Training [21/62] Loss: 0.30875 
Epoch [68/300] Training [22/62] Loss: 0.35339 
Epoch [68/300] Training [23/62] Loss: 0.38735 
Epoch [68/300] Training [24/62] Loss: 0.40935 
Epoch [68/300] Training [25/62] Loss: 0.63750 
Epoch [68/300] Training [26/62] Loss: 0.16177 
Epoch [68/300] Training [27/62] Loss: 0.45273 
Epoch [68/300] Training [28/62] Loss: 0.17359 
Epoch [68/300] Training [29/62] Loss: 0.20300 
Epoch [68/300] Training [30/62] Loss: 0.30853 
Epoch [68/300] Training [31/62] Loss: 0.24852 
Epoch [68/300] Training [32/62] Loss: 0.21681 
Epoch [68/300] Training [33/62] Loss: 0.49196 
Epoch [68/300] Training [34/62] Loss: 0.40984 
Epoch [68/300] Training [35/62] Loss: 0.40086 
Epoch [68/300] Training [36/62] Loss: 0.37043 
Epoch [68/300] Training [37/62] Loss: 0.17568 
Epoch [68/300] Training [38/62] Loss: 0.26563 
Epoch [68/300] Training [39/62] Loss: 0.24870 
Epoch [68/300] Training [40/62] Loss: 0.27112 
Epoch [68/300] Training [41/62] Loss: 0.15306 
Epoch [68/300] Training [42/62] Loss: 0.25414 
Epoch [68/300] Training [43/62] Loss: 0.28154 
Epoch [68/300] Training [44/62] Loss: 0.23409 
Epoch [68/300] Training [45/62] Loss: 0.58398 
Epoch [68/300] Training [46/62] Loss: 0.23486 
Epoch [68/300] Training [47/62] Loss: 0.25863 
Epoch [68/300] Training [48/62] Loss: 0.29587 
Epoch [68/300] Training [49/62] Loss: 0.30250 
Epoch [68/300] Training [50/62] Loss: 0.32440 
Epoch [68/300] Training [51/62] Loss: 0.30279 
Epoch [68/300] Training [52/62] Loss: 0.41054 
Epoch [68/300] Training [53/62] Loss: 0.26955 
Epoch [68/300] Training [54/62] Loss: 0.33889 
Epoch [68/300] Training [55/62] Loss: 0.39233 
Epoch [68/300] Training [56/62] Loss: 0.30387 
Epoch [68/300] Training [57/62] Loss: 0.18833 
Epoch [68/300] Training [58/62] Loss: 0.51911 
Epoch [68/300] Training [59/62] Loss: 0.36834 
Epoch [68/300] Training [60/62] Loss: 0.44049 
Epoch [68/300] Training [61/62] Loss: 0.26672 
Epoch [68/300] Training [62/62] Loss: 1.35609 
Epoch [68/300] Training metric {'Train/mean dice_metric': 0.7829945683479309, 'Train/mean miou_metric': 0.686676561832428, 'Train/mean f1': 0.8107869029045105, 'Train/mean precision': 0.8316723108291626, 'Train/mean recall': 0.7909247279167175, 'Train/mean hd95_metric': 51.53627014160156}
Epoch [68/300] Validation [1/16] Loss: 0.80787  focal_loss 0.45614  dice_loss 0.35173 
Epoch [68/300] Validation [2/16] Loss: 0.61509  focal_loss 0.15169  dice_loss 0.46340 
Epoch [68/300] Validation [3/16] Loss: 0.57862  focal_loss 0.21013  dice_loss 0.36848 
Epoch [68/300] Validation [4/16] Loss: 0.61507  focal_loss 0.21786  dice_loss 0.39721 
Epoch [68/300] Validation [5/16] Loss: 0.45036  focal_loss 0.08453  dice_loss 0.36583 
Epoch [68/300] Validation [6/16] Loss: 0.37382  focal_loss 0.08764  dice_loss 0.28617 
Epoch [68/300] Validation [7/16] Loss: 0.33993  focal_loss 0.11475  dice_loss 0.22518 
Epoch [68/300] Validation [8/16] Loss: 0.66389  focal_loss 0.17613  dice_loss 0.48775 
Epoch [68/300] Validation [9/16] Loss: 0.42691  focal_loss 0.11466  dice_loss 0.31225 
Epoch [68/300] Validation [10/16] Loss: 0.80032  focal_loss 0.22354  dice_loss 0.57678 
Epoch [68/300] Validation [11/16] Loss: 0.36480  focal_loss 0.09818  dice_loss 0.26663 
Epoch [68/300] Validation [12/16] Loss: 0.50651  focal_loss 0.09053  dice_loss 0.41598 
Epoch [68/300] Validation [13/16] Loss: 0.33986  focal_loss 0.09065  dice_loss 0.24922 
Epoch [68/300] Validation [14/16] Loss: 0.76268  focal_loss 0.24280  dice_loss 0.51988 
Epoch [68/300] Validation [15/16] Loss: 0.32205  focal_loss 0.08913  dice_loss 0.23292 
Epoch [68/300] Validation [16/16] Loss: 0.26456  focal_loss 0.07857  dice_loss 0.18598 
Epoch [68/300] Validation metric {'Val/mean dice_metric': 0.7580640912055969, 'Val/mean miou_metric': 0.6584374904632568, 'Val/mean f1': 0.788184404373169, 'Val/mean precision': 0.8077980279922485, 'Val/mean recall': 0.769500732421875, 'Val/mean hd95_metric': 55.64695358276367}
Cheakpoint...
Epoch [68/300] best acc:tensor([0.7635], device='cuda:0'), Now : mean acc: tensor([0.7581], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7580640912055969, 'Val/mean miou_metric': 0.6584374904632568, 'Val/mean f1': 0.788184404373169, 'Val/mean precision': 0.8077980279922485, 'Val/mean recall': 0.769500732421875, 'Val/mean hd95_metric': 55.64695358276367}
Epoch [69/300] Training [1/62] Loss: 0.38240 
Epoch [69/300] Training [2/62] Loss: 0.36756 
Epoch [69/300] Training [3/62] Loss: 0.23848 
Epoch [69/300] Training [4/62] Loss: 0.44289 
Epoch [69/300] Training [5/62] Loss: 0.25200 
Epoch [69/300] Training [6/62] Loss: 0.32503 
Epoch [69/300] Training [7/62] Loss: 0.33305 
Epoch [69/300] Training [8/62] Loss: 0.48404 
Epoch [69/300] Training [9/62] Loss: 0.47535 
Epoch [69/300] Training [10/62] Loss: 0.33153 
Epoch [69/300] Training [11/62] Loss: 0.34541 
Epoch [69/300] Training [12/62] Loss: 0.36282 
Epoch [69/300] Training [13/62] Loss: 0.41115 
Epoch [69/300] Training [14/62] Loss: 0.36560 
Epoch [69/300] Training [15/62] Loss: 0.41527 
Epoch [69/300] Training [16/62] Loss: 0.23747 
Epoch [69/300] Training [17/62] Loss: 0.35568 
Epoch [69/300] Training [18/62] Loss: 0.36838 
Epoch [69/300] Training [19/62] Loss: 0.29904 
Epoch [69/300] Training [20/62] Loss: 0.32163 
Epoch [69/300] Training [21/62] Loss: 0.21822 
Epoch [69/300] Training [22/62] Loss: 0.38856 
Epoch [69/300] Training [23/62] Loss: 0.39507 
Epoch [69/300] Training [24/62] Loss: 0.43615 
Epoch [69/300] Training [25/62] Loss: 0.23676 
Epoch [69/300] Training [26/62] Loss: 0.26883 
Epoch [69/300] Training [27/62] Loss: 0.41668 
Epoch [69/300] Training [28/62] Loss: 0.20920 
Epoch [69/300] Training [29/62] Loss: 0.33369 
Epoch [69/300] Training [30/62] Loss: 0.39279 
Epoch [69/300] Training [31/62] Loss: 0.28787 
Epoch [69/300] Training [32/62] Loss: 0.29444 
Epoch [69/300] Training [33/62] Loss: 0.26628 
Epoch [69/300] Training [34/62] Loss: 0.29495 
Epoch [69/300] Training [35/62] Loss: 0.21809 
Epoch [69/300] Training [36/62] Loss: 0.46879 
Epoch [69/300] Training [37/62] Loss: 0.29256 
Epoch [69/300] Training [38/62] Loss: 0.41055 
Epoch [69/300] Training [39/62] Loss: 0.22889 
Epoch [69/300] Training [40/62] Loss: 0.44584 
Epoch [69/300] Training [41/62] Loss: 0.18369 
Epoch [69/300] Training [42/62] Loss: 0.16860 
Epoch [69/300] Training [43/62] Loss: 0.51249 
Epoch [69/300] Training [44/62] Loss: 0.29417 
Epoch [69/300] Training [45/62] Loss: 0.24018 
Epoch [69/300] Training [46/62] Loss: 0.33103 
Epoch [69/300] Training [47/62] Loss: 0.31776 
Epoch [69/300] Training [48/62] Loss: 0.31407 
Epoch [69/300] Training [49/62] Loss: 0.42433 
Epoch [69/300] Training [50/62] Loss: 0.29978 
Epoch [69/300] Training [51/62] Loss: 0.32936 
Epoch [69/300] Training [52/62] Loss: 0.49829 
Epoch [69/300] Training [53/62] Loss: 0.30694 
Epoch [69/300] Training [54/62] Loss: 0.19294 
Epoch [69/300] Training [55/62] Loss: 0.43237 
Epoch [69/300] Training [56/62] Loss: 0.15432 
Epoch [69/300] Training [57/62] Loss: 0.29737 
Epoch [69/300] Training [58/62] Loss: 0.32508 
Epoch [69/300] Training [59/62] Loss: 0.38510 
Epoch [69/300] Training [60/62] Loss: 0.30282 
Epoch [69/300] Training [61/62] Loss: 0.28271 
Epoch [69/300] Training [62/62] Loss: 0.15767 
Epoch [69/300] Training metric {'Train/mean dice_metric': 0.7785285115242004, 'Train/mean miou_metric': 0.6808362007141113, 'Train/mean f1': 0.809181272983551, 'Train/mean precision': 0.8150156736373901, 'Train/mean recall': 0.8034297823905945, 'Train/mean hd95_metric': 55.21247482299805}
Epoch [69/300] Validation [1/16] Loss: 0.97027  focal_loss 0.42773  dice_loss 0.54254 
Epoch [69/300] Validation [2/16] Loss: 0.69698  focal_loss 0.19901  dice_loss 0.49797 
Epoch [69/300] Validation [3/16] Loss: 0.71944  focal_loss 0.20863  dice_loss 0.51080 
Epoch [69/300] Validation [4/16] Loss: 0.59065  focal_loss 0.18472  dice_loss 0.40592 
Epoch [69/300] Validation [5/16] Loss: 0.52760  focal_loss 0.09035  dice_loss 0.43725 
Epoch [69/300] Validation [6/16] Loss: 0.42099  focal_loss 0.07721  dice_loss 0.34379 
Epoch [69/300] Validation [7/16] Loss: 0.61919  focal_loss 0.16066  dice_loss 0.45853 
Epoch [69/300] Validation [8/16] Loss: 0.70037  focal_loss 0.14085  dice_loss 0.55953 
Epoch [69/300] Validation [9/16] Loss: 0.58255  focal_loss 0.16578  dice_loss 0.41678 
Epoch [69/300] Validation [10/16] Loss: 0.83708  focal_loss 0.28348  dice_loss 0.55361 
Epoch [69/300] Validation [11/16] Loss: 0.54490  focal_loss 0.14312  dice_loss 0.40177 
Epoch [69/300] Validation [12/16] Loss: 0.58968  focal_loss 0.08695  dice_loss 0.50273 
Epoch [69/300] Validation [13/16] Loss: 0.50722  focal_loss 0.12655  dice_loss 0.38068 
Epoch [69/300] Validation [14/16] Loss: 0.99524  focal_loss 0.27090  dice_loss 0.72434 
Epoch [69/300] Validation [15/16] Loss: 0.41305  focal_loss 0.09830  dice_loss 0.31475 
Epoch [69/300] Validation [16/16] Loss: 0.38457  focal_loss 0.09467  dice_loss 0.28989 
Epoch [69/300] Validation metric {'Val/mean dice_metric': 0.7354380488395691, 'Val/mean miou_metric': 0.6348856091499329, 'Val/mean f1': 0.771309494972229, 'Val/mean precision': 0.7800279259681702, 'Val/mean recall': 0.7627837061882019, 'Val/mean hd95_metric': 62.731178283691406}
Cheakpoint...
Epoch [69/300] best acc:tensor([0.7635], device='cuda:0'), Now : mean acc: tensor([0.7354], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7354380488395691, 'Val/mean miou_metric': 0.6348856091499329, 'Val/mean f1': 0.771309494972229, 'Val/mean precision': 0.7800279259681702, 'Val/mean recall': 0.7627837061882019, 'Val/mean hd95_metric': 62.731178283691406}
Epoch [70/300] Training [1/62] Loss: 0.17795 
Epoch [70/300] Training [2/62] Loss: 0.16181 
Epoch [70/300] Training [3/62] Loss: 0.22586 
Epoch [70/300] Training [4/62] Loss: 0.54660 
Epoch [70/300] Training [5/62] Loss: 0.33839 
Epoch [70/300] Training [6/62] Loss: 0.37145 
Epoch [70/300] Training [7/62] Loss: 0.20249 
Epoch [70/300] Training [8/62] Loss: 0.23457 
Epoch [70/300] Training [9/62] Loss: 0.42366 
Epoch [70/300] Training [10/62] Loss: 0.32779 
Epoch [70/300] Training [11/62] Loss: 0.32488 
Epoch [70/300] Training [12/62] Loss: 0.35727 
Epoch [70/300] Training [13/62] Loss: 0.29120 
Epoch [70/300] Training [14/62] Loss: 0.44082 
Epoch [70/300] Training [15/62] Loss: 0.31065 
Epoch [70/300] Training [16/62] Loss: 0.25777 
Epoch [70/300] Training [17/62] Loss: 0.28987 
Epoch [70/300] Training [18/62] Loss: 0.26558 
Epoch [70/300] Training [19/62] Loss: 0.43498 
Epoch [70/300] Training [20/62] Loss: 0.29775 
Epoch [70/300] Training [21/62] Loss: 0.34761 
Epoch [70/300] Training [22/62] Loss: 0.23313 
Epoch [70/300] Training [23/62] Loss: 0.26647 
Epoch [70/300] Training [24/62] Loss: 0.39409 
Epoch [70/300] Training [25/62] Loss: 0.32129 
Epoch [70/300] Training [26/62] Loss: 0.39617 
Epoch [70/300] Training [27/62] Loss: 0.17576 
Epoch [70/300] Training [28/62] Loss: 0.32762 
Epoch [70/300] Training [29/62] Loss: 0.26293 
Epoch [70/300] Training [30/62] Loss: 0.36914 
Epoch [70/300] Training [31/62] Loss: 0.22423 
Epoch [70/300] Training [32/62] Loss: 0.27768 
Epoch [70/300] Training [33/62] Loss: 0.15047 
Epoch [70/300] Training [34/62] Loss: 0.28648 
Epoch [70/300] Training [35/62] Loss: 0.41645 
Epoch [70/300] Training [36/62] Loss: 0.37266 
Epoch [70/300] Training [37/62] Loss: 0.15826 
Epoch [70/300] Training [38/62] Loss: 0.32522 
Epoch [70/300] Training [39/62] Loss: 0.36120 
Epoch [70/300] Training [40/62] Loss: 0.17180 
Epoch [70/300] Training [41/62] Loss: 0.26833 
Epoch [70/300] Training [42/62] Loss: 0.44455 
Epoch [70/300] Training [43/62] Loss: 0.20239 
Epoch [70/300] Training [44/62] Loss: 0.29962 
Epoch [70/300] Training [45/62] Loss: 0.16795 
Epoch [70/300] Training [46/62] Loss: 0.43632 
Epoch [70/300] Training [47/62] Loss: 0.30670 
Epoch [70/300] Training [48/62] Loss: 0.31513 
Epoch [70/300] Training [49/62] Loss: 0.26344 
Epoch [70/300] Training [50/62] Loss: 0.35326 
Epoch [70/300] Training [51/62] Loss: 0.27304 
Epoch [70/300] Training [52/62] Loss: 0.41901 
Epoch [70/300] Training [53/62] Loss: 0.29505 
Epoch [70/300] Training [54/62] Loss: 0.19594 
Epoch [70/300] Training [55/62] Loss: 0.21527 
Epoch [70/300] Training [56/62] Loss: 0.31721 
Epoch [70/300] Training [57/62] Loss: 0.41310 
Epoch [70/300] Training [58/62] Loss: 0.31416 
Epoch [70/300] Training [59/62] Loss: 0.37313 
Epoch [70/300] Training [60/62] Loss: 0.42214 
Epoch [70/300] Training [61/62] Loss: 0.19430 
Epoch [70/300] Training [62/62] Loss: 0.06946 
Epoch [70/300] Training metric {'Train/mean dice_metric': 0.7929619550704956, 'Train/mean miou_metric': 0.6989287734031677, 'Train/mean f1': 0.8249249458312988, 'Train/mean precision': 0.8299898505210876, 'Train/mean recall': 0.8199215531349182, 'Train/mean hd95_metric': 52.597633361816406}
Epoch [70/300] Validation [1/16] Loss: 0.68438  focal_loss 0.32953  dice_loss 0.35485 
Epoch [70/300] Validation [2/16] Loss: 0.49453  focal_loss 0.10947  dice_loss 0.38506 
Epoch [70/300] Validation [3/16] Loss: 0.60431  focal_loss 0.21435  dice_loss 0.38995 
Epoch [70/300] Validation [4/16] Loss: 0.56386  focal_loss 0.17065  dice_loss 0.39321 
Epoch [70/300] Validation [5/16] Loss: 0.47196  focal_loss 0.09857  dice_loss 0.37339 
Epoch [70/300] Validation [6/16] Loss: 0.38353  focal_loss 0.06137  dice_loss 0.32215 
Epoch [70/300] Validation [7/16] Loss: 0.30344  focal_loss 0.08820  dice_loss 0.21524 
Epoch [70/300] Validation [8/16] Loss: 0.52672  focal_loss 0.10720  dice_loss 0.41952 
Epoch [70/300] Validation [9/16] Loss: 0.47129  focal_loss 0.13143  dice_loss 0.33986 
Epoch [70/300] Validation [10/16] Loss: 0.84253  focal_loss 0.23640  dice_loss 0.60613 
Epoch [70/300] Validation [11/16] Loss: 0.45394  focal_loss 0.11688  dice_loss 0.33705 
Epoch [70/300] Validation [12/16] Loss: 0.44628  focal_loss 0.05769  dice_loss 0.38860 
Epoch [70/300] Validation [13/16] Loss: 0.36506  focal_loss 0.07866  dice_loss 0.28641 
Epoch [70/300] Validation [14/16] Loss: 0.78811  focal_loss 0.20642  dice_loss 0.58169 
Epoch [70/300] Validation [15/16] Loss: 0.41725  focal_loss 0.12084  dice_loss 0.29641 
Epoch [70/300] Validation [16/16] Loss: 0.31205  focal_loss 0.08527  dice_loss 0.22678 
Epoch [70/300] Validation metric {'Val/mean dice_metric': 0.7655666470527649, 'Val/mean miou_metric': 0.6686913967132568, 'Val/mean f1': 0.8002129793167114, 'Val/mean precision': 0.8141046762466431, 'Val/mean recall': 0.7867873311042786, 'Val/mean hd95_metric': 56.47037887573242}
Cheakpoint...
Epoch [70/300] best acc:tensor([0.7656], device='cuda:0'), Now : mean acc: tensor([0.7656], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7655666470527649, 'Val/mean miou_metric': 0.6686913967132568, 'Val/mean f1': 0.8002129793167114, 'Val/mean precision': 0.8141046762466431, 'Val/mean recall': 0.7867873311042786, 'Val/mean hd95_metric': 56.47037887573242}
Epoch [71/300] Training [1/62] Loss: 0.28107 
Epoch [71/300] Training [2/62] Loss: 0.37908 
Epoch [71/300] Training [3/62] Loss: 0.42050 
Epoch [71/300] Training [4/62] Loss: 0.46308 
Epoch [71/300] Training [5/62] Loss: 0.36146 
Epoch [71/300] Training [6/62] Loss: 0.29254 
Epoch [71/300] Training [7/62] Loss: 0.33046 
Epoch [71/300] Training [8/62] Loss: 0.18766 
Epoch [71/300] Training [9/62] Loss: 0.21272 
Epoch [71/300] Training [10/62] Loss: 0.28400 
Epoch [71/300] Training [11/62] Loss: 0.38416 
Epoch [71/300] Training [12/62] Loss: 0.33176 
Epoch [71/300] Training [13/62] Loss: 0.44940 
Epoch [71/300] Training [14/62] Loss: 0.37959 
Epoch [71/300] Training [15/62] Loss: 0.31952 
Epoch [71/300] Training [16/62] Loss: 0.22929 
Epoch [71/300] Training [17/62] Loss: 0.30599 
Epoch [71/300] Training [18/62] Loss: 0.15340 
Epoch [71/300] Training [19/62] Loss: 0.20937 
Epoch [71/300] Training [20/62] Loss: 0.43894 
Epoch [71/300] Training [21/62] Loss: 0.15803 
Epoch [71/300] Training [22/62] Loss: 0.26410 
Epoch [71/300] Training [23/62] Loss: 0.15336 
Epoch [71/300] Training [24/62] Loss: 0.35076 
Epoch [71/300] Training [25/62] Loss: 0.34564 
Epoch [71/300] Training [26/62] Loss: 0.30306 
Epoch [71/300] Training [27/62] Loss: 0.43346 
Epoch [71/300] Training [28/62] Loss: 0.28038 
Epoch [71/300] Training [29/62] Loss: 0.28706 
Epoch [71/300] Training [30/62] Loss: 0.18953 
Epoch [71/300] Training [31/62] Loss: 0.40234 
Epoch [71/300] Training [32/62] Loss: 0.37757 
Epoch [71/300] Training [33/62] Loss: 0.19961 
Epoch [71/300] Training [34/62] Loss: 0.17702 
Epoch [71/300] Training [35/62] Loss: 0.34939 
Epoch [71/300] Training [36/62] Loss: 0.22624 
Epoch [71/300] Training [37/62] Loss: 0.33627 
Epoch [71/300] Training [38/62] Loss: 0.29767 
Epoch [71/300] Training [39/62] Loss: 0.30686 
Epoch [71/300] Training [40/62] Loss: 0.29766 
Epoch [71/300] Training [41/62] Loss: 0.53205 
Epoch [71/300] Training [42/62] Loss: 0.24996 
Epoch [71/300] Training [43/62] Loss: 0.41408 
Epoch [71/300] Training [44/62] Loss: 0.37571 
Epoch [71/300] Training [45/62] Loss: 0.35554 
Epoch [71/300] Training [46/62] Loss: 0.20371 
Epoch [71/300] Training [47/62] Loss: 0.38512 
Epoch [71/300] Training [48/62] Loss: 0.20264 
Epoch [71/300] Training [49/62] Loss: 0.34860 
Epoch [71/300] Training [50/62] Loss: 0.37739 
Epoch [71/300] Training [51/62] Loss: 0.21000 
Epoch [71/300] Training [52/62] Loss: 0.29405 
Epoch [71/300] Training [53/62] Loss: 0.33222 
Epoch [71/300] Training [54/62] Loss: 0.34137 
Epoch [71/300] Training [55/62] Loss: 0.27534 
Epoch [71/300] Training [56/62] Loss: 0.34353 
Epoch [71/300] Training [57/62] Loss: 0.34733 
Epoch [71/300] Training [58/62] Loss: 0.23794 
Epoch [71/300] Training [59/62] Loss: 0.41681 
Epoch [71/300] Training [60/62] Loss: 0.15666 
Epoch [71/300] Training [61/62] Loss: 0.24186 
Epoch [71/300] Training [62/62] Loss: 0.52673 
Epoch [71/300] Training metric {'Train/mean dice_metric': 0.793265700340271, 'Train/mean miou_metric': 0.6990160942077637, 'Train/mean f1': 0.8212252259254456, 'Train/mean precision': 0.839539110660553, 'Train/mean recall': 0.8036932349205017, 'Train/mean hd95_metric': 52.6099853515625}
Epoch [71/300] Validation [1/16] Loss: 0.76880  focal_loss 0.37191  dice_loss 0.39688 
Epoch [71/300] Validation [2/16] Loss: 0.49739  focal_loss 0.13204  dice_loss 0.36535 
Epoch [71/300] Validation [3/16] Loss: 0.55260  focal_loss 0.18401  dice_loss 0.36858 
Epoch [71/300] Validation [4/16] Loss: 0.50416  focal_loss 0.17053  dice_loss 0.33363 
Epoch [71/300] Validation [5/16] Loss: 0.47812  focal_loss 0.08414  dice_loss 0.39398 
Epoch [71/300] Validation [6/16] Loss: 0.38334  focal_loss 0.08725  dice_loss 0.29609 
Epoch [71/300] Validation [7/16] Loss: 0.42029  focal_loss 0.09080  dice_loss 0.32948 
Epoch [71/300] Validation [8/16] Loss: 0.59738  focal_loss 0.14817  dice_loss 0.44921 
Epoch [71/300] Validation [9/16] Loss: 0.41045  focal_loss 0.10792  dice_loss 0.30253 
Epoch [71/300] Validation [10/16] Loss: 0.47341  focal_loss 0.10653  dice_loss 0.36688 
Epoch [71/300] Validation [11/16] Loss: 0.34484  focal_loss 0.07200  dice_loss 0.27284 
Epoch [71/300] Validation [12/16] Loss: 0.37852  focal_loss 0.05406  dice_loss 0.32446 
Epoch [71/300] Validation [13/16] Loss: 0.34693  focal_loss 0.07981  dice_loss 0.26712 
Epoch [71/300] Validation [14/16] Loss: 0.73739  focal_loss 0.17778  dice_loss 0.55961 
Epoch [71/300] Validation [15/16] Loss: 0.25656  focal_loss 0.05068  dice_loss 0.20588 
Epoch [71/300] Validation [16/16] Loss: 0.22417  focal_loss 0.06447  dice_loss 0.15970 
Epoch [71/300] Validation metric {'Val/mean dice_metric': 0.7711248397827148, 'Val/mean miou_metric': 0.6742048263549805, 'Val/mean f1': 0.8018540740013123, 'Val/mean precision': 0.8275046944618225, 'Val/mean recall': 0.7777459621429443, 'Val/mean hd95_metric': 56.58673095703125}
Cheakpoint...
Epoch [71/300] best acc:tensor([0.7711], device='cuda:0'), Now : mean acc: tensor([0.7711], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7711248397827148, 'Val/mean miou_metric': 0.6742048263549805, 'Val/mean f1': 0.8018540740013123, 'Val/mean precision': 0.8275046944618225, 'Val/mean recall': 0.7777459621429443, 'Val/mean hd95_metric': 56.58673095703125}
Epoch [72/300] Training [1/62] Loss: 0.43163 
Epoch [72/300] Training [2/62] Loss: 0.26837 
Epoch [72/300] Training [3/62] Loss: 0.24091 
Epoch [72/300] Training [4/62] Loss: 0.24254 
Epoch [72/300] Training [5/62] Loss: 0.32681 
Epoch [72/300] Training [6/62] Loss: 0.33297 
Epoch [72/300] Training [7/62] Loss: 0.39953 
Epoch [72/300] Training [8/62] Loss: 0.39621 
Epoch [72/300] Training [9/62] Loss: 0.20927 
Epoch [72/300] Training [10/62] Loss: 0.29850 
Epoch [72/300] Training [11/62] Loss: 0.28216 
Epoch [72/300] Training [12/62] Loss: 0.38534 
Epoch [72/300] Training [13/62] Loss: 0.28023 
Epoch [72/300] Training [14/62] Loss: 0.33660 
Epoch [72/300] Training [15/62] Loss: 0.16408 
Epoch [72/300] Training [16/62] Loss: 0.45104 
Epoch [72/300] Training [17/62] Loss: 0.40628 
Epoch [72/300] Training [18/62] Loss: 0.23888 
Epoch [72/300] Training [19/62] Loss: 0.28241 
Epoch [72/300] Training [20/62] Loss: 0.17131 
Epoch [72/300] Training [21/62] Loss: 0.25816 
Epoch [72/300] Training [22/62] Loss: 0.31449 
Epoch [72/300] Training [23/62] Loss: 0.27991 
Epoch [72/300] Training [24/62] Loss: 0.34037 
Epoch [72/300] Training [25/62] Loss: 0.39900 
Epoch [72/300] Training [26/62] Loss: 0.35157 
Epoch [72/300] Training [27/62] Loss: 0.21838 
Epoch [72/300] Training [28/62] Loss: 0.23588 
Epoch [72/300] Training [29/62] Loss: 0.33251 
Epoch [72/300] Training [30/62] Loss: 0.14745 
Epoch [72/300] Training [31/62] Loss: 0.29668 
Epoch [72/300] Training [32/62] Loss: 0.28734 
Epoch [72/300] Training [33/62] Loss: 0.22957 
Epoch [72/300] Training [34/62] Loss: 0.25855 
Epoch [72/300] Training [35/62] Loss: 0.30772 
Epoch [72/300] Training [36/62] Loss: 0.62802 
Epoch [72/300] Training [37/62] Loss: 0.37484 
Epoch [72/300] Training [38/62] Loss: 0.14577 
Epoch [72/300] Training [39/62] Loss: 0.43525 
Epoch [72/300] Training [40/62] Loss: 0.25328 
Epoch [72/300] Training [41/62] Loss: 0.44443 
Epoch [72/300] Training [42/62] Loss: 0.26096 
Epoch [72/300] Training [43/62] Loss: 0.13021 
Epoch [72/300] Training [44/62] Loss: 0.17408 
Epoch [72/300] Training [45/62] Loss: 0.43406 
Epoch [72/300] Training [46/62] Loss: 0.23294 
Epoch [72/300] Training [47/62] Loss: 0.43059 
Epoch [72/300] Training [48/62] Loss: 0.14077 
Epoch [72/300] Training [49/62] Loss: 0.37336 
Epoch [72/300] Training [50/62] Loss: 0.30108 
Epoch [72/300] Training [51/62] Loss: 0.37229 
Epoch [72/300] Training [52/62] Loss: 0.30220 
Epoch [72/300] Training [53/62] Loss: 0.17166 
Epoch [72/300] Training [54/62] Loss: 0.31888 
Epoch [72/300] Training [55/62] Loss: 0.22246 
Epoch [72/300] Training [56/62] Loss: 0.30293 
Epoch [72/300] Training [57/62] Loss: 0.39092 
Epoch [72/300] Training [58/62] Loss: 0.28102 
Epoch [72/300] Training [59/62] Loss: 0.48704 
Epoch [72/300] Training [60/62] Loss: 0.17326 
Epoch [72/300] Training [61/62] Loss: 0.28760 
Epoch [72/300] Training [62/62] Loss: 0.18222 
Epoch [72/300] Training metric {'Train/mean dice_metric': 0.7968801259994507, 'Train/mean miou_metric': 0.702873170375824, 'Train/mean f1': 0.8292250037193298, 'Train/mean precision': 0.8507750034332275, 'Train/mean recall': 0.8087397813796997, 'Train/mean hd95_metric': 55.42531967163086}
Epoch [72/300] Validation [1/16] Loss: 0.55407  focal_loss 0.28170  dice_loss 0.27237 
Epoch [72/300] Validation [2/16] Loss: 0.45848  focal_loss 0.12788  dice_loss 0.33060 
Epoch [72/300] Validation [3/16] Loss: 0.60211  focal_loss 0.22452  dice_loss 0.37759 
Epoch [72/300] Validation [4/16] Loss: 0.35871  focal_loss 0.12660  dice_loss 0.23211 
Epoch [72/300] Validation [5/16] Loss: 0.36603  focal_loss 0.06721  dice_loss 0.29882 
Epoch [72/300] Validation [6/16] Loss: 0.42979  focal_loss 0.10518  dice_loss 0.32461 
Epoch [72/300] Validation [7/16] Loss: 0.22738  focal_loss 0.05523  dice_loss 0.17215 
Epoch [72/300] Validation [8/16] Loss: 0.50232  focal_loss 0.09708  dice_loss 0.40524 
Epoch [72/300] Validation [9/16] Loss: 0.34905  focal_loss 0.10341  dice_loss 0.24564 
Epoch [72/300] Validation [10/16] Loss: 0.58634  focal_loss 0.14353  dice_loss 0.44280 
Epoch [72/300] Validation [11/16] Loss: 0.19583  focal_loss 0.04295  dice_loss 0.15288 
Epoch [72/300] Validation [12/16] Loss: 0.49059  focal_loss 0.07720  dice_loss 0.41339 
Epoch [72/300] Validation [13/16] Loss: 0.26260  focal_loss 0.04418  dice_loss 0.21842 
Epoch [72/300] Validation [14/16] Loss: 0.78510  focal_loss 0.25828  dice_loss 0.52682 
Epoch [72/300] Validation [15/16] Loss: 0.27998  focal_loss 0.07953  dice_loss 0.20045 
Epoch [72/300] Validation [16/16] Loss: 0.18982  focal_loss 0.03083  dice_loss 0.15899 
Epoch [72/300] Validation metric {'Val/mean dice_metric': 0.7823476195335388, 'Val/mean miou_metric': 0.6862187385559082, 'Val/mean f1': 0.8146248459815979, 'Val/mean precision': 0.8458892703056335, 'Val/mean recall': 0.7855891585350037, 'Val/mean hd95_metric': 57.31608581542969}
Cheakpoint...
Epoch [72/300] best acc:tensor([0.7823], device='cuda:0'), Now : mean acc: tensor([0.7823], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7823476195335388, 'Val/mean miou_metric': 0.6862187385559082, 'Val/mean f1': 0.8146248459815979, 'Val/mean precision': 0.8458892703056335, 'Val/mean recall': 0.7855891585350037, 'Val/mean hd95_metric': 57.31608581542969}
Epoch [73/300] Training [1/62] Loss: 0.44520 
Epoch [73/300] Training [2/62] Loss: 0.32559 
Epoch [73/300] Training [3/62] Loss: 0.31600 
Epoch [73/300] Training [4/62] Loss: 0.20561 
Epoch [73/300] Training [5/62] Loss: 0.17306 
Epoch [73/300] Training [6/62] Loss: 0.27469 
Epoch [73/300] Training [7/62] Loss: 0.25410 
Epoch [73/300] Training [8/62] Loss: 0.15948 
Epoch [73/300] Training [9/62] Loss: 0.40532 
Epoch [73/300] Training [10/62] Loss: 0.28659 
Epoch [73/300] Training [11/62] Loss: 0.11784 
Epoch [73/300] Training [12/62] Loss: 0.22774 
Epoch [73/300] Training [13/62] Loss: 0.28189 
Epoch [73/300] Training [14/62] Loss: 0.39443 
Epoch [73/300] Training [15/62] Loss: 0.46316 
Epoch [73/300] Training [16/62] Loss: 0.26644 
Epoch [73/300] Training [17/62] Loss: 0.31020 
Epoch [73/300] Training [18/62] Loss: 0.21921 
Epoch [73/300] Training [19/62] Loss: 0.19638 
Epoch [73/300] Training [20/62] Loss: 0.38854 
Epoch [73/300] Training [21/62] Loss: 0.18442 
Epoch [73/300] Training [22/62] Loss: 0.22620 
Epoch [73/300] Training [23/62] Loss: 0.44547 
Epoch [73/300] Training [24/62] Loss: 0.43377 
Epoch [73/300] Training [25/62] Loss: 0.24161 
Epoch [73/300] Training [26/62] Loss: 0.20634 
Epoch [73/300] Training [27/62] Loss: 0.24324 
Epoch [73/300] Training [28/62] Loss: 0.26401 
Epoch [73/300] Training [29/62] Loss: 0.12901 
Epoch [73/300] Training [30/62] Loss: 0.30249 
Epoch [73/300] Training [31/62] Loss: 0.49850 
Epoch [73/300] Training [32/62] Loss: 0.19322 
Epoch [73/300] Training [33/62] Loss: 0.36440 
Epoch [73/300] Training [34/62] Loss: 0.45080 
Epoch [73/300] Training [35/62] Loss: 0.20547 
Epoch [73/300] Training [36/62] Loss: 0.23294 
Epoch [73/300] Training [37/62] Loss: 0.30888 
Epoch [73/300] Training [38/62] Loss: 0.29794 
Epoch [73/300] Training [39/62] Loss: 0.38528 
Epoch [73/300] Training [40/62] Loss: 0.23868 
Epoch [73/300] Training [41/62] Loss: 0.26289 
Epoch [73/300] Training [42/62] Loss: 0.39414 
Epoch [73/300] Training [43/62] Loss: 0.23447 
Epoch [73/300] Training [44/62] Loss: 0.29610 
Epoch [73/300] Training [45/62] Loss: 0.35614 
Epoch [73/300] Training [46/62] Loss: 0.15668 
Epoch [73/300] Training [47/62] Loss: 0.26211 
Epoch [73/300] Training [48/62] Loss: 0.19729 
Epoch [73/300] Training [49/62] Loss: 0.20683 
Epoch [73/300] Training [50/62] Loss: 0.34549 
Epoch [73/300] Training [51/62] Loss: 0.24709 
Epoch [73/300] Training [52/62] Loss: 0.34519 
Epoch [73/300] Training [53/62] Loss: 0.28349 
Epoch [73/300] Training [54/62] Loss: 0.25528 
Epoch [73/300] Training [55/62] Loss: 0.26531 
Epoch [73/300] Training [56/62] Loss: 0.58334 
Epoch [73/300] Training [57/62] Loss: 0.24153 
Epoch [73/300] Training [58/62] Loss: 0.17357 
Epoch [73/300] Training [59/62] Loss: 0.29406 
Epoch [73/300] Training [60/62] Loss: 0.26662 
Epoch [73/300] Training [61/62] Loss: 0.41156 
Epoch [73/300] Training [62/62] Loss: 0.57978 
Epoch [73/300] Training metric {'Train/mean dice_metric': 0.8088303208351135, 'Train/mean miou_metric': 0.7134964466094971, 'Train/mean f1': 0.8348113298416138, 'Train/mean precision': 0.8549790978431702, 'Train/mean recall': 0.8155731558799744, 'Train/mean hd95_metric': 49.03284454345703}
Epoch [73/300] Validation [1/16] Loss: 0.67294  focal_loss 0.33712  dice_loss 0.33582 
Epoch [73/300] Validation [2/16] Loss: 0.51141  focal_loss 0.11739  dice_loss 0.39402 
Epoch [73/300] Validation [3/16] Loss: 0.57342  focal_loss 0.20488  dice_loss 0.36855 
Epoch [73/300] Validation [4/16] Loss: 0.43692  focal_loss 0.12912  dice_loss 0.30780 
Epoch [73/300] Validation [5/16] Loss: 0.51860  focal_loss 0.08997  dice_loss 0.42862 
Epoch [73/300] Validation [6/16] Loss: 0.40681  focal_loss 0.10111  dice_loss 0.30570 
Epoch [73/300] Validation [7/16] Loss: 0.39803  focal_loss 0.10546  dice_loss 0.29257 
Epoch [73/300] Validation [8/16] Loss: 0.79514  focal_loss 0.20544  dice_loss 0.58970 
Epoch [73/300] Validation [9/16] Loss: 0.42393  focal_loss 0.12844  dice_loss 0.29549 
Epoch [73/300] Validation [10/16] Loss: 0.73159  focal_loss 0.20160  dice_loss 0.52999 
Epoch [73/300] Validation [11/16] Loss: 0.38929  focal_loss 0.07910  dice_loss 0.31020 
Epoch [73/300] Validation [12/16] Loss: 0.49441  focal_loss 0.07171  dice_loss 0.42270 
Epoch [73/300] Validation [13/16] Loss: 0.57878  focal_loss 0.20276  dice_loss 0.37602 
Epoch [73/300] Validation [14/16] Loss: 0.75597  focal_loss 0.21375  dice_loss 0.54222 
Epoch [73/300] Validation [15/16] Loss: 0.36517  focal_loss 0.10532  dice_loss 0.25985 
Epoch [73/300] Validation [16/16] Loss: 0.21961  focal_loss 0.07468  dice_loss 0.14493 
Epoch [73/300] Validation metric {'Val/mean dice_metric': 0.7754982113838196, 'Val/mean miou_metric': 0.67879718542099, 'Val/mean f1': 0.8101310133934021, 'Val/mean precision': 0.8478909134864807, 'Val/mean recall': 0.7755910754203796, 'Val/mean hd95_metric': 52.04690170288086}
Cheakpoint...
Epoch [73/300] best acc:tensor([0.7823], device='cuda:0'), Now : mean acc: tensor([0.7755], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7754982113838196, 'Val/mean miou_metric': 0.67879718542099, 'Val/mean f1': 0.8101310133934021, 'Val/mean precision': 0.8478909134864807, 'Val/mean recall': 0.7755910754203796, 'Val/mean hd95_metric': 52.04690170288086}
Epoch [74/300] Training [1/62] Loss: 0.11642 
Epoch [74/300] Training [2/62] Loss: 0.26023 
Epoch [74/300] Training [3/62] Loss: 0.21341 
Epoch [74/300] Training [4/62] Loss: 0.31860 
Epoch [74/300] Training [5/62] Loss: 0.37612 
Epoch [74/300] Training [6/62] Loss: 0.19977 
Epoch [74/300] Training [7/62] Loss: 0.29134 
Epoch [74/300] Training [8/62] Loss: 0.22608 
Epoch [74/300] Training [9/62] Loss: 0.23213 
Epoch [74/300] Training [10/62] Loss: 0.26580 
Epoch [74/300] Training [11/62] Loss: 0.22009 
Epoch [74/300] Training [12/62] Loss: 0.42945 
Epoch [74/300] Training [13/62] Loss: 0.32288 
Epoch [74/300] Training [14/62] Loss: 0.28362 
Epoch [74/300] Training [15/62] Loss: 0.23697 
Epoch [74/300] Training [16/62] Loss: 0.27082 
Epoch [74/300] Training [17/62] Loss: 0.27152 
Epoch [74/300] Training [18/62] Loss: 0.18063 
Epoch [74/300] Training [19/62] Loss: 0.41304 
Epoch [74/300] Training [20/62] Loss: 0.38725 
Epoch [74/300] Training [21/62] Loss: 0.25838 
Epoch [74/300] Training [22/62] Loss: 0.29546 
Epoch [74/300] Training [23/62] Loss: 0.33798 
Epoch [74/300] Training [24/62] Loss: 0.17221 
Epoch [74/300] Training [25/62] Loss: 0.19108 
Epoch [74/300] Training [26/62] Loss: 0.16955 
Epoch [74/300] Training [27/62] Loss: 0.32802 
Epoch [74/300] Training [28/62] Loss: 0.19578 
Epoch [74/300] Training [29/62] Loss: 0.15461 
Epoch [74/300] Training [30/62] Loss: 0.20509 
Epoch [74/300] Training [31/62] Loss: 0.37021 
Epoch [74/300] Training [32/62] Loss: 0.20909 
Epoch [74/300] Training [33/62] Loss: 0.34985 
Epoch [74/300] Training [34/62] Loss: 0.40330 
Epoch [74/300] Training [35/62] Loss: 0.25633 
Epoch [74/300] Training [36/62] Loss: 0.44792 
Epoch [74/300] Training [37/62] Loss: 0.21958 
Epoch [74/300] Training [38/62] Loss: 0.18204 
Epoch [74/300] Training [39/62] Loss: 0.15613 
Epoch [74/300] Training [40/62] Loss: 0.60917 
Epoch [74/300] Training [41/62] Loss: 0.39956 
Epoch [74/300] Training [42/62] Loss: 0.32926 
Epoch [74/300] Training [43/62] Loss: 0.26484 
Epoch [74/300] Training [44/62] Loss: 0.22219 
Epoch [74/300] Training [45/62] Loss: 0.36140 
Epoch [74/300] Training [46/62] Loss: 0.35724 
Epoch [74/300] Training [47/62] Loss: 0.28253 
Epoch [74/300] Training [48/62] Loss: 0.23075 
Epoch [74/300] Training [49/62] Loss: 0.33981 
Epoch [74/300] Training [50/62] Loss: 0.29075 
Epoch [74/300] Training [51/62] Loss: 0.56291 
Epoch [74/300] Training [52/62] Loss: 0.26325 
Epoch [74/300] Training [53/62] Loss: 0.19705 
Epoch [74/300] Training [54/62] Loss: 0.34503 
Epoch [74/300] Training [55/62] Loss: 0.20821 
Epoch [74/300] Training [56/62] Loss: 0.27922 
Epoch [74/300] Training [57/62] Loss: 0.28785 
Epoch [74/300] Training [58/62] Loss: 0.29889 
Epoch [74/300] Training [59/62] Loss: 0.27624 
Epoch [74/300] Training [60/62] Loss: 0.33635 
Epoch [74/300] Training [61/62] Loss: 0.51541 
Epoch [74/300] Training [62/62] Loss: 0.11426 
Epoch [74/300] Training metric {'Train/mean dice_metric': 0.8123432397842407, 'Train/mean miou_metric': 0.7189217209815979, 'Train/mean f1': 0.8285331130027771, 'Train/mean precision': 0.848913311958313, 'Train/mean recall': 0.8091084957122803, 'Train/mean hd95_metric': 51.10086441040039}
Epoch [74/300] Validation [1/16] Loss: 0.69619  focal_loss 0.41644  dice_loss 0.27975 
Epoch [74/300] Validation [2/16] Loss: 0.52093  focal_loss 0.10938  dice_loss 0.41155 
Epoch [74/300] Validation [3/16] Loss: 0.65293  focal_loss 0.22970  dice_loss 0.42323 
Epoch [74/300] Validation [4/16] Loss: 0.47411  focal_loss 0.14820  dice_loss 0.32591 
Epoch [74/300] Validation [5/16] Loss: 0.40210  focal_loss 0.07732  dice_loss 0.32477 
Epoch [74/300] Validation [6/16] Loss: 0.37860  focal_loss 0.10382  dice_loss 0.27478 
Epoch [74/300] Validation [7/16] Loss: 0.30105  focal_loss 0.09580  dice_loss 0.20525 
Epoch [74/300] Validation [8/16] Loss: 0.51859  focal_loss 0.12633  dice_loss 0.39226 
Epoch [74/300] Validation [9/16] Loss: 0.43918  focal_loss 0.13593  dice_loss 0.30325 
Epoch [74/300] Validation [10/16] Loss: 0.65156  focal_loss 0.16712  dice_loss 0.48444 
Epoch [74/300] Validation [11/16] Loss: 0.21072  focal_loss 0.04873  dice_loss 0.16199 
Epoch [74/300] Validation [12/16] Loss: 0.48133  focal_loss 0.07804  dice_loss 0.40329 
Epoch [74/300] Validation [13/16] Loss: 0.42754  focal_loss 0.11452  dice_loss 0.31302 
Epoch [74/300] Validation [14/16] Loss: 0.46250  focal_loss 0.10651  dice_loss 0.35599 
Epoch [74/300] Validation [15/16] Loss: 0.31627  focal_loss 0.09638  dice_loss 0.21990 
Epoch [74/300] Validation [16/16] Loss: 0.16207  focal_loss 0.04793  dice_loss 0.11414 
Epoch [74/300] Validation metric {'Val/mean dice_metric': 0.7891663908958435, 'Val/mean miou_metric': 0.692874014377594, 'Val/mean f1': 0.8103434443473816, 'Val/mean precision': 0.8349187970161438, 'Val/mean recall': 0.7871733903884888, 'Val/mean hd95_metric': 54.19970703125}
Cheakpoint...
Epoch [74/300] best acc:tensor([0.7892], device='cuda:0'), Now : mean acc: tensor([0.7892], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7891663908958435, 'Val/mean miou_metric': 0.692874014377594, 'Val/mean f1': 0.8103434443473816, 'Val/mean precision': 0.8349187970161438, 'Val/mean recall': 0.7871733903884888, 'Val/mean hd95_metric': 54.19970703125}
Epoch [75/300] Training [1/62] Loss: 0.25528 
Epoch [75/300] Training [2/62] Loss: 0.22234 
Epoch [75/300] Training [3/62] Loss: 0.29865 
Epoch [75/300] Training [4/62] Loss: 0.33845 
Epoch [75/300] Training [5/62] Loss: 0.33066 
Epoch [75/300] Training [6/62] Loss: 0.37787 
Epoch [75/300] Training [7/62] Loss: 0.30781 
Epoch [75/300] Training [8/62] Loss: 0.34801 
Epoch [75/300] Training [9/62] Loss: 0.27183 
Epoch [75/300] Training [10/62] Loss: 0.40802 
Epoch [75/300] Training [11/62] Loss: 0.13692 
Epoch [75/300] Training [12/62] Loss: 0.33140 
Epoch [75/300] Training [13/62] Loss: 0.21629 
Epoch [75/300] Training [14/62] Loss: 0.45097 
Epoch [75/300] Training [15/62] Loss: 0.20991 
Epoch [75/300] Training [16/62] Loss: 0.17000 
Epoch [75/300] Training [17/62] Loss: 0.29442 
Epoch [75/300] Training [18/62] Loss: 0.17799 
Epoch [75/300] Training [19/62] Loss: 0.14723 
Epoch [75/300] Training [20/62] Loss: 0.24556 
Epoch [75/300] Training [21/62] Loss: 0.41767 
Epoch [75/300] Training [22/62] Loss: 0.26581 
Epoch [75/300] Training [23/62] Loss: 0.18175 
Epoch [75/300] Training [24/62] Loss: 0.24430 
Epoch [75/300] Training [25/62] Loss: 0.21692 
Epoch [75/300] Training [26/62] Loss: 0.23087 
Epoch [75/300] Training [27/62] Loss: 0.22598 
Epoch [75/300] Training [28/62] Loss: 0.49091 
Epoch [75/300] Training [29/62] Loss: 0.34015 
Epoch [75/300] Training [30/62] Loss: 0.29312 
Epoch [75/300] Training [31/62] Loss: 0.35529 
Epoch [75/300] Training [32/62] Loss: 0.23045 
Epoch [75/300] Training [33/62] Loss: 0.21731 
Epoch [75/300] Training [34/62] Loss: 0.29180 
Epoch [75/300] Training [35/62] Loss: 0.50217 
Epoch [75/300] Training [36/62] Loss: 0.29191 
Epoch [75/300] Training [37/62] Loss: 0.22585 
Epoch [75/300] Training [38/62] Loss: 0.16587 
Epoch [75/300] Training [39/62] Loss: 0.32871 
Epoch [75/300] Training [40/62] Loss: 0.24505 
Epoch [75/300] Training [41/62] Loss: 0.28103 
Epoch [75/300] Training [42/62] Loss: 0.27890 
Epoch [75/300] Training [43/62] Loss: 0.35792 
Epoch [75/300] Training [44/62] Loss: 0.48634 
Epoch [75/300] Training [45/62] Loss: 0.55740 
Epoch [75/300] Training [46/62] Loss: 0.26832 
Epoch [75/300] Training [47/62] Loss: 0.21418 
Epoch [75/300] Training [48/62] Loss: 0.32952 
Epoch [75/300] Training [49/62] Loss: 0.22213 
Epoch [75/300] Training [50/62] Loss: 0.27076 
Epoch [75/300] Training [51/62] Loss: 0.36149 
Epoch [75/300] Training [52/62] Loss: 0.30237 
Epoch [75/300] Training [53/62] Loss: 0.41178 
Epoch [75/300] Training [54/62] Loss: 0.23421 
Epoch [75/300] Training [55/62] Loss: 0.22558 
Epoch [75/300] Training [56/62] Loss: 0.31760 
Epoch [75/300] Training [57/62] Loss: 0.22715 
Epoch [75/300] Training [58/62] Loss: 0.64710 
Epoch [75/300] Training [59/62] Loss: 0.26821 
Epoch [75/300] Training [60/62] Loss: 0.12844 
Epoch [75/300] Training [61/62] Loss: 0.27361 
Epoch [75/300] Training [62/62] Loss: 0.42432 
Epoch [75/300] Training metric {'Train/mean dice_metric': 0.8033316135406494, 'Train/mean miou_metric': 0.7119332551956177, 'Train/mean f1': 0.8301405310630798, 'Train/mean precision': 0.8486171960830688, 'Train/mean recall': 0.8124513030052185, 'Train/mean hd95_metric': 52.30805587768555}
Epoch [75/300] Validation [1/16] Loss: 0.63443  focal_loss 0.37449  dice_loss 0.25994 
Epoch [75/300] Validation [2/16] Loss: 0.43413  focal_loss 0.08347  dice_loss 0.35066 
Epoch [75/300] Validation [3/16] Loss: 0.49969  focal_loss 0.12764  dice_loss 0.37206 
Epoch [75/300] Validation [4/16] Loss: 0.45708  focal_loss 0.16653  dice_loss 0.29055 
Epoch [75/300] Validation [5/16] Loss: 0.39857  focal_loss 0.07667  dice_loss 0.32190 
Epoch [75/300] Validation [6/16] Loss: 0.49109  focal_loss 0.14528  dice_loss 0.34581 
Epoch [75/300] Validation [7/16] Loss: 0.26719  focal_loss 0.08255  dice_loss 0.18464 
Epoch [75/300] Validation [8/16] Loss: 0.45528  focal_loss 0.09581  dice_loss 0.35946 
Epoch [75/300] Validation [9/16] Loss: 0.35842  focal_loss 0.10846  dice_loss 0.24996 
Epoch [75/300] Validation [10/16] Loss: 0.53852  focal_loss 0.14207  dice_loss 0.39645 
Epoch [75/300] Validation [11/16] Loss: 0.23456  focal_loss 0.05759  dice_loss 0.17697 
Epoch [75/300] Validation [12/16] Loss: 0.58570  focal_loss 0.11692  dice_loss 0.46878 
Epoch [75/300] Validation [13/16] Loss: 0.39583  focal_loss 0.10592  dice_loss 0.28991 
Epoch [75/300] Validation [14/16] Loss: 0.54633  focal_loss 0.12218  dice_loss 0.42416 
Epoch [75/300] Validation [15/16] Loss: 0.15831  focal_loss 0.02617  dice_loss 0.13215 
Epoch [75/300] Validation [16/16] Loss: 0.32259  focal_loss 0.09645  dice_loss 0.22614 
Epoch [75/300] Validation metric {'Val/mean dice_metric': 0.7868554592132568, 'Val/mean miou_metric': 0.6934865713119507, 'Val/mean f1': 0.8156054019927979, 'Val/mean precision': 0.8258371353149414, 'Val/mean recall': 0.80562424659729, 'Val/mean hd95_metric': 56.89775085449219}
Cheakpoint...
Epoch [75/300] best acc:tensor([0.7892], device='cuda:0'), Now : mean acc: tensor([0.7869], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7868554592132568, 'Val/mean miou_metric': 0.6934865713119507, 'Val/mean f1': 0.8156054019927979, 'Val/mean precision': 0.8258371353149414, 'Val/mean recall': 0.80562424659729, 'Val/mean hd95_metric': 56.89775085449219}
Epoch [76/300] Training [1/62] Loss: 0.34174 
Epoch [76/300] Training [2/62] Loss: 0.30773 
Epoch [76/300] Training [3/62] Loss: 0.50631 
Epoch [76/300] Training [4/62] Loss: 0.23162 
Epoch [76/300] Training [5/62] Loss: 0.20252 
Epoch [76/300] Training [6/62] Loss: 0.23357 
Epoch [76/300] Training [7/62] Loss: 0.26102 
Epoch [76/300] Training [8/62] Loss: 0.18132 
Epoch [76/300] Training [9/62] Loss: 0.30860 
Epoch [76/300] Training [10/62] Loss: 0.24313 
Epoch [76/300] Training [11/62] Loss: 0.35007 
Epoch [76/300] Training [12/62] Loss: 0.29283 
Epoch [76/300] Training [13/62] Loss: 0.44615 
Epoch [76/300] Training [14/62] Loss: 0.26555 
Epoch [76/300] Training [15/62] Loss: 0.43097 
Epoch [76/300] Training [16/62] Loss: 0.21246 
Epoch [76/300] Training [17/62] Loss: 0.24874 
Epoch [76/300] Training [18/62] Loss: 0.34710 
Epoch [76/300] Training [19/62] Loss: 0.29055 
Epoch [76/300] Training [20/62] Loss: 0.44588 
Epoch [76/300] Training [21/62] Loss: 0.22881 
Epoch [76/300] Training [22/62] Loss: 0.27964 
Epoch [76/300] Training [23/62] Loss: 0.29535 
Epoch [76/300] Training [24/62] Loss: 0.26790 
Epoch [76/300] Training [25/62] Loss: 0.31576 
Epoch [76/300] Training [26/62] Loss: 0.27457 
Epoch [76/300] Training [27/62] Loss: 0.38239 
Epoch [76/300] Training [28/62] Loss: 0.38239 
Epoch [76/300] Training [29/62] Loss: 0.20537 
Epoch [76/300] Training [30/62] Loss: 0.24032 
Epoch [76/300] Training [31/62] Loss: 0.19516 
Epoch [76/300] Training [32/62] Loss: 0.21099 
Epoch [76/300] Training [33/62] Loss: 0.19523 
Epoch [76/300] Training [34/62] Loss: 0.13396 
Epoch [76/300] Training [35/62] Loss: 0.10200 
Epoch [76/300] Training [36/62] Loss: 0.26821 
Epoch [76/300] Training [37/62] Loss: 0.23315 
Epoch [76/300] Training [38/62] Loss: 0.31849 
Epoch [76/300] Training [39/62] Loss: 0.23870 
Epoch [76/300] Training [40/62] Loss: 0.35748 
Epoch [76/300] Training [41/62] Loss: 0.29644 
Epoch [76/300] Training [42/62] Loss: 0.19308 
Epoch [76/300] Training [43/62] Loss: 0.43199 
Epoch [76/300] Training [44/62] Loss: 0.32427 
Epoch [76/300] Training [45/62] Loss: 0.22421 
Epoch [76/300] Training [46/62] Loss: 0.18170 
Epoch [76/300] Training [47/62] Loss: 0.13743 
Epoch [76/300] Training [48/62] Loss: 0.26975 
Epoch [76/300] Training [49/62] Loss: 0.43221 
Epoch [76/300] Training [50/62] Loss: 0.29764 
Epoch [76/300] Training [51/62] Loss: 0.23755 
Epoch [76/300] Training [52/62] Loss: 0.37823 
Epoch [76/300] Training [53/62] Loss: 0.23146 
Epoch [76/300] Training [54/62] Loss: 0.28387 
Epoch [76/300] Training [55/62] Loss: 0.53051 
Epoch [76/300] Training [56/62] Loss: 0.31490 
Epoch [76/300] Training [57/62] Loss: 0.32512 
Epoch [76/300] Training [58/62] Loss: 0.20655 
Epoch [76/300] Training [59/62] Loss: 0.28867 
Epoch [76/300] Training [60/62] Loss: 0.28546 
Epoch [76/300] Training [61/62] Loss: 0.51776 
Epoch [76/300] Training [62/62] Loss: 0.73784 
Epoch [76/300] Training metric {'Train/mean dice_metric': 0.8028957843780518, 'Train/mean miou_metric': 0.709682285785675, 'Train/mean f1': 0.838796854019165, 'Train/mean precision': 0.8513160943984985, 'Train/mean recall': 0.8266404867172241, 'Train/mean hd95_metric': 51.988922119140625}
Epoch [76/300] Validation [1/16] Loss: 0.64335  focal_loss 0.33107  dice_loss 0.31228 
Epoch [76/300] Validation [2/16] Loss: 0.53715  focal_loss 0.12545  dice_loss 0.41170 
Epoch [76/300] Validation [3/16] Loss: 0.61893  focal_loss 0.27121  dice_loss 0.34772 
Epoch [76/300] Validation [4/16] Loss: 0.44737  focal_loss 0.16392  dice_loss 0.28345 
Epoch [76/300] Validation [5/16] Loss: 0.38790  focal_loss 0.06719  dice_loss 0.32071 
Epoch [76/300] Validation [6/16] Loss: 0.35831  focal_loss 0.07185  dice_loss 0.28646 
Epoch [76/300] Validation [7/16] Loss: 0.26578  focal_loss 0.07099  dice_loss 0.19479 
Epoch [76/300] Validation [8/16] Loss: 0.47855  focal_loss 0.10717  dice_loss 0.37138 
Epoch [76/300] Validation [9/16] Loss: 0.26190  focal_loss 0.05652  dice_loss 0.20539 
Epoch [76/300] Validation [10/16] Loss: 0.78516  focal_loss 0.22680  dice_loss 0.55836 
Epoch [76/300] Validation [11/16] Loss: 0.37609  focal_loss 0.11017  dice_loss 0.26591 
Epoch [76/300] Validation [12/16] Loss: 0.42151  focal_loss 0.06734  dice_loss 0.35417 
Epoch [76/300] Validation [13/16] Loss: 0.35471  focal_loss 0.08089  dice_loss 0.27383 
Epoch [76/300] Validation [14/16] Loss: 0.60967  focal_loss 0.15987  dice_loss 0.44980 
Epoch [76/300] Validation [15/16] Loss: 0.18821  focal_loss 0.04308  dice_loss 0.14513 
Epoch [76/300] Validation [16/16] Loss: 0.19593  focal_loss 0.05169  dice_loss 0.14423 
Epoch [76/300] Validation metric {'Val/mean dice_metric': 0.7842771410942078, 'Val/mean miou_metric': 0.689174234867096, 'Val/mean f1': 0.8223116397857666, 'Val/mean precision': 0.8382818698883057, 'Val/mean recall': 0.8069385886192322, 'Val/mean hd95_metric': 54.138858795166016}
Cheakpoint...
Epoch [76/300] best acc:tensor([0.7892], device='cuda:0'), Now : mean acc: tensor([0.7843], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7842771410942078, 'Val/mean miou_metric': 0.689174234867096, 'Val/mean f1': 0.8223116397857666, 'Val/mean precision': 0.8382818698883057, 'Val/mean recall': 0.8069385886192322, 'Val/mean hd95_metric': 54.138858795166016}
Epoch [77/300] Training [1/62] Loss: 0.14863 
Epoch [77/300] Training [2/62] Loss: 0.40714 
Epoch [77/300] Training [3/62] Loss: 0.33855 
Epoch [77/300] Training [4/62] Loss: 0.19334 
Epoch [77/300] Training [5/62] Loss: 0.32624 
Epoch [77/300] Training [6/62] Loss: 0.40112 
Epoch [77/300] Training [7/62] Loss: 0.56855 
Epoch [77/300] Training [8/62] Loss: 0.48017 
Epoch [77/300] Training [9/62] Loss: 0.30050 
Epoch [77/300] Training [10/62] Loss: 0.27252 
Epoch [77/300] Training [11/62] Loss: 0.39266 
Epoch [77/300] Training [12/62] Loss: 0.21116 
Epoch [77/300] Training [13/62] Loss: 0.31607 
Epoch [77/300] Training [14/62] Loss: 0.36433 
Epoch [77/300] Training [15/62] Loss: 0.26771 
Epoch [77/300] Training [16/62] Loss: 0.25095 
Epoch [77/300] Training [17/62] Loss: 0.21669 
Epoch [77/300] Training [18/62] Loss: 0.35531 
Epoch [77/300] Training [19/62] Loss: 0.15713 
Epoch [77/300] Training [20/62] Loss: 0.18931 
Epoch [77/300] Training [21/62] Loss: 0.25959 
Epoch [77/300] Training [22/62] Loss: 0.16218 
Epoch [77/300] Training [23/62] Loss: 0.18872 
Epoch [77/300] Training [24/62] Loss: 0.34765 
Epoch [77/300] Training [25/62] Loss: 0.18864 
Epoch [77/300] Training [26/62] Loss: 0.21277 
Epoch [77/300] Training [27/62] Loss: 0.23629 
Epoch [77/300] Training [28/62] Loss: 0.29365 
Epoch [77/300] Training [29/62] Loss: 0.42294 
Epoch [77/300] Training [30/62] Loss: 0.24265 
Epoch [77/300] Training [31/62] Loss: 0.08841 
Epoch [77/300] Training [32/62] Loss: 0.33680 
Epoch [77/300] Training [33/62] Loss: 0.26431 
Epoch [77/300] Training [34/62] Loss: 0.33182 
Epoch [77/300] Training [35/62] Loss: 0.21914 
Epoch [77/300] Training [36/62] Loss: 0.36684 
Epoch [77/300] Training [37/62] Loss: 0.12778 
Epoch [77/300] Training [38/62] Loss: 0.38579 
Epoch [77/300] Training [39/62] Loss: 0.23788 
Epoch [77/300] Training [40/62] Loss: 0.15941 
Epoch [77/300] Training [41/62] Loss: 0.29507 
Epoch [77/300] Training [42/62] Loss: 0.37834 
Epoch [77/300] Training [43/62] Loss: 0.22132 
Epoch [77/300] Training [44/62] Loss: 0.34744 
Epoch [77/300] Training [45/62] Loss: 0.19363 
Epoch [77/300] Training [46/62] Loss: 0.19672 
Epoch [77/300] Training [47/62] Loss: 0.22065 
Epoch [77/300] Training [48/62] Loss: 0.18344 
Epoch [77/300] Training [49/62] Loss: 0.24377 
Epoch [77/300] Training [50/62] Loss: 0.32851 
Epoch [77/300] Training [51/62] Loss: 0.33257 
Epoch [77/300] Training [52/62] Loss: 0.46525 
Epoch [77/300] Training [53/62] Loss: 0.56146 
Epoch [77/300] Training [54/62] Loss: 0.13745 
Epoch [77/300] Training [55/62] Loss: 0.22507 
Epoch [77/300] Training [56/62] Loss: 0.37961 
Epoch [77/300] Training [57/62] Loss: 0.24110 
Epoch [77/300] Training [58/62] Loss: 0.17285 
Epoch [77/300] Training [59/62] Loss: 0.16478 
Epoch [77/300] Training [60/62] Loss: 0.31052 
Epoch [77/300] Training [61/62] Loss: 0.31304 
Epoch [77/300] Training [62/62] Loss: 1.93007 
Epoch [77/300] Training metric {'Train/mean dice_metric': 0.8104768395423889, 'Train/mean miou_metric': 0.720902681350708, 'Train/mean f1': 0.8386453986167908, 'Train/mean precision': 0.8536927103996277, 'Train/mean recall': 0.8241193890571594, 'Train/mean hd95_metric': 49.81978225708008}
Epoch [77/300] Validation [1/16] Loss: 0.60041  focal_loss 0.36065  dice_loss 0.23976 
Epoch [77/300] Validation [2/16] Loss: 0.54468  focal_loss 0.12378  dice_loss 0.42090 
Epoch [77/300] Validation [3/16] Loss: 0.56964  focal_loss 0.23241  dice_loss 0.33723 
Epoch [77/300] Validation [4/16] Loss: 0.35808  focal_loss 0.13164  dice_loss 0.22644 
Epoch [77/300] Validation [5/16] Loss: 0.37805  focal_loss 0.07007  dice_loss 0.30798 
Epoch [77/300] Validation [6/16] Loss: 0.37271  focal_loss 0.09567  dice_loss 0.27704 
Epoch [77/300] Validation [7/16] Loss: 0.26323  focal_loss 0.05922  dice_loss 0.20400 
Epoch [77/300] Validation [8/16] Loss: 0.61133  focal_loss 0.13744  dice_loss 0.47389 
Epoch [77/300] Validation [9/16] Loss: 0.34548  focal_loss 0.10972  dice_loss 0.23576 
Epoch [77/300] Validation [10/16] Loss: 0.60886  focal_loss 0.14518  dice_loss 0.46367 
Epoch [77/300] Validation [11/16] Loss: 0.20585  focal_loss 0.04602  dice_loss 0.15983 
Epoch [77/300] Validation [12/16] Loss: 0.36427  focal_loss 0.06630  dice_loss 0.29797 
Epoch [77/300] Validation [13/16] Loss: 0.35637  focal_loss 0.06701  dice_loss 0.28936 
Epoch [77/300] Validation [14/16] Loss: 0.58319  focal_loss 0.17756  dice_loss 0.40563 
Epoch [77/300] Validation [15/16] Loss: 0.22257  focal_loss 0.06177  dice_loss 0.16080 
Epoch [77/300] Validation [16/16] Loss: 0.14319  focal_loss 0.03131  dice_loss 0.11188 
Epoch [77/300] Validation metric {'Val/mean dice_metric': 0.7930214405059814, 'Val/mean miou_metric': 0.701210081577301, 'Val/mean f1': 0.8226268887519836, 'Val/mean precision': 0.8403266072273254, 'Val/mean recall': 0.8056573271751404, 'Val/mean hd95_metric': 52.89432144165039}
Cheakpoint...
Epoch [77/300] best acc:tensor([0.7930], device='cuda:0'), Now : mean acc: tensor([0.7930], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7930214405059814, 'Val/mean miou_metric': 0.701210081577301, 'Val/mean f1': 0.8226268887519836, 'Val/mean precision': 0.8403266072273254, 'Val/mean recall': 0.8056573271751404, 'Val/mean hd95_metric': 52.89432144165039}
Epoch [78/300] Training [1/62] Loss: 0.20089 
Epoch [78/300] Training [2/62] Loss: 0.27956 
Epoch [78/300] Training [3/62] Loss: 0.24868 
Epoch [78/300] Training [4/62] Loss: 0.18287 
Epoch [78/300] Training [5/62] Loss: 0.38670 
Epoch [78/300] Training [6/62] Loss: 0.26965 
Epoch [78/300] Training [7/62] Loss: 0.33700 
Epoch [78/300] Training [8/62] Loss: 0.24731 
Epoch [78/300] Training [9/62] Loss: 0.17803 
Epoch [78/300] Training [10/62] Loss: 0.30797 
Epoch [78/300] Training [11/62] Loss: 0.35994 
Epoch [78/300] Training [12/62] Loss: 0.22363 
Epoch [78/300] Training [13/62] Loss: 0.26317 
Epoch [78/300] Training [14/62] Loss: 0.25344 
Epoch [78/300] Training [15/62] Loss: 0.39042 
Epoch [78/300] Training [16/62] Loss: 0.32576 
Epoch [78/300] Training [17/62] Loss: 0.29151 
Epoch [78/300] Training [18/62] Loss: 0.32939 
Epoch [78/300] Training [19/62] Loss: 0.21140 
Epoch [78/300] Training [20/62] Loss: 0.31230 
Epoch [78/300] Training [21/62] Loss: 0.49515 
Epoch [78/300] Training [22/62] Loss: 0.42660 
Epoch [78/300] Training [23/62] Loss: 0.18767 
Epoch [78/300] Training [24/62] Loss: 0.41502 
Epoch [78/300] Training [25/62] Loss: 0.32319 
Epoch [78/300] Training [26/62] Loss: 0.18678 
Epoch [78/300] Training [27/62] Loss: 0.31827 
Epoch [78/300] Training [28/62] Loss: 0.21757 
Epoch [78/300] Training [29/62] Loss: 0.25117 
Epoch [78/300] Training [30/62] Loss: 0.22739 
Epoch [78/300] Training [31/62] Loss: 0.17567 
Epoch [78/300] Training [32/62] Loss: 0.39744 
Epoch [78/300] Training [33/62] Loss: 0.23732 
Epoch [78/300] Training [34/62] Loss: 0.28556 
Epoch [78/300] Training [35/62] Loss: 0.19967 
Epoch [78/300] Training [36/62] Loss: 0.36539 
Epoch [78/300] Training [37/62] Loss: 0.28270 
Epoch [78/300] Training [38/62] Loss: 0.24972 
Epoch [78/300] Training [39/62] Loss: 0.16793 
Epoch [78/300] Training [40/62] Loss: 0.37847 
Epoch [78/300] Training [41/62] Loss: 0.44957 
Epoch [78/300] Training [42/62] Loss: 0.33440 
Epoch [78/300] Training [43/62] Loss: 0.14759 
Epoch [78/300] Training [44/62] Loss: 0.24243 
Epoch [78/300] Training [45/62] Loss: 0.34663 
Epoch [78/300] Training [46/62] Loss: 0.27563 
Epoch [78/300] Training [47/62] Loss: 0.26617 
Epoch [78/300] Training [48/62] Loss: 0.46366 
Epoch [78/300] Training [49/62] Loss: 0.59647 
Epoch [78/300] Training [50/62] Loss: 0.23589 
Epoch [78/300] Training [51/62] Loss: 0.30305 
Epoch [78/300] Training [52/62] Loss: 0.23508 
Epoch [78/300] Training [53/62] Loss: 0.34787 
Epoch [78/300] Training [54/62] Loss: 0.32000 
Epoch [78/300] Training [55/62] Loss: 0.31935 
Epoch [78/300] Training [56/62] Loss: 0.23867 
Epoch [78/300] Training [57/62] Loss: 0.20070 
Epoch [78/300] Training [58/62] Loss: 0.26857 
Epoch [78/300] Training [59/62] Loss: 0.33316 
Epoch [78/300] Training [60/62] Loss: 0.19914 
Epoch [78/300] Training [61/62] Loss: 0.28361 
Epoch [78/300] Training [62/62] Loss: 0.13323 
Epoch [78/300] Training metric {'Train/mean dice_metric': 0.8087989091873169, 'Train/mean miou_metric': 0.7144193053245544, 'Train/mean f1': 0.8309291005134583, 'Train/mean precision': 0.8508101105690002, 'Train/mean recall': 0.8119559288024902, 'Train/mean hd95_metric': 49.83331298828125}
Epoch [78/300] Validation [1/16] Loss: 1.11612  focal_loss 0.53824  dice_loss 0.57788 
Epoch [78/300] Validation [2/16] Loss: 0.68344  focal_loss 0.20084  dice_loss 0.48260 
Epoch [78/300] Validation [3/16] Loss: 0.73329  focal_loss 0.23669  dice_loss 0.49661 
Epoch [78/300] Validation [4/16] Loss: 0.83529  focal_loss 0.29093  dice_loss 0.54436 
Epoch [78/300] Validation [5/16] Loss: 0.62420  focal_loss 0.12927  dice_loss 0.49493 
Epoch [78/300] Validation [6/16] Loss: 0.58565  focal_loss 0.13682  dice_loss 0.44883 
Epoch [78/300] Validation [7/16] Loss: 0.68927  focal_loss 0.22736  dice_loss 0.46191 
Epoch [78/300] Validation [8/16] Loss: 0.91010  focal_loss 0.22349  dice_loss 0.68662 
Epoch [78/300] Validation [9/16] Loss: 0.59451  focal_loss 0.19357  dice_loss 0.40094 
Epoch [78/300] Validation [10/16] Loss: 1.02357  focal_loss 0.37806  dice_loss 0.64550 
Epoch [78/300] Validation [11/16] Loss: 0.53868  focal_loss 0.12194  dice_loss 0.41674 
Epoch [78/300] Validation [12/16] Loss: 0.65297  focal_loss 0.11299  dice_loss 0.53997 
Epoch [78/300] Validation [13/16] Loss: 0.59320  focal_loss 0.19668  dice_loss 0.39652 
Epoch [78/300] Validation [14/16] Loss: 0.96926  focal_loss 0.24282  dice_loss 0.72644 
Epoch [78/300] Validation [15/16] Loss: 0.99255  focal_loss 0.36129  dice_loss 0.63126 
Epoch [78/300] Validation [16/16] Loss: 0.29668  focal_loss 0.08459  dice_loss 0.21209 
Epoch [78/300] Validation metric {'Val/mean dice_metric': 0.7441908717155457, 'Val/mean miou_metric': 0.6493200659751892, 'Val/mean f1': 0.7860508561134338, 'Val/mean precision': 0.8376217484474182, 'Val/mean recall': 0.7404618263244629, 'Val/mean hd95_metric': 56.89044189453125}
Cheakpoint...
Epoch [78/300] best acc:tensor([0.7930], device='cuda:0'), Now : mean acc: tensor([0.7442], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7441908717155457, 'Val/mean miou_metric': 0.6493200659751892, 'Val/mean f1': 0.7860508561134338, 'Val/mean precision': 0.8376217484474182, 'Val/mean recall': 0.7404618263244629, 'Val/mean hd95_metric': 56.89044189453125}
Epoch [79/300] Training [1/62] Loss: 0.20101 
Epoch [79/300] Training [2/62] Loss: 0.42247 
Epoch [79/300] Training [3/62] Loss: 0.22232 
Epoch [79/300] Training [4/62] Loss: 0.35372 
Epoch [79/300] Training [5/62] Loss: 0.21045 
Epoch [79/300] Training [6/62] Loss: 0.39016 
Epoch [79/300] Training [7/62] Loss: 0.28744 
Epoch [79/300] Training [8/62] Loss: 0.18103 
Epoch [79/300] Training [9/62] Loss: 0.32798 
Epoch [79/300] Training [10/62] Loss: 0.28729 
Epoch [79/300] Training [11/62] Loss: 0.20518 
Epoch [79/300] Training [12/62] Loss: 0.23702 
Epoch [79/300] Training [13/62] Loss: 0.36862 
Epoch [79/300] Training [14/62] Loss: 0.25119 
Epoch [79/300] Training [15/62] Loss: 0.29418 
Epoch [79/300] Training [16/62] Loss: 0.44063 
Epoch [79/300] Training [17/62] Loss: 0.20223 
Epoch [79/300] Training [18/62] Loss: 0.22606 
Epoch [79/300] Training [19/62] Loss: 0.31202 
Epoch [79/300] Training [20/62] Loss: 0.16297 
Epoch [79/300] Training [21/62] Loss: 0.12667 
Epoch [79/300] Training [22/62] Loss: 0.13498 
Epoch [79/300] Training [23/62] Loss: 0.15150 
Epoch [79/300] Training [24/62] Loss: 0.25030 
Epoch [79/300] Training [25/62] Loss: 0.33377 
Epoch [79/300] Training [26/62] Loss: 0.42927 
Epoch [79/300] Training [27/62] Loss: 0.22371 
Epoch [79/300] Training [28/62] Loss: 0.26287 
Epoch [79/300] Training [29/62] Loss: 0.18638 
Epoch [79/300] Training [30/62] Loss: 0.13289 
Epoch [79/300] Training [31/62] Loss: 0.18605 
Epoch [79/300] Training [32/62] Loss: 0.20751 
Epoch [79/300] Training [33/62] Loss: 0.36773 
Epoch [79/300] Training [34/62] Loss: 0.17612 
Epoch [79/300] Training [35/62] Loss: 0.26499 
Epoch [79/300] Training [36/62] Loss: 0.23880 
Epoch [79/300] Training [37/62] Loss: 0.32019 
Epoch [79/300] Training [38/62] Loss: 0.19095 
Epoch [79/300] Training [39/62] Loss: 0.41292 
Epoch [79/300] Training [40/62] Loss: 0.27268 
Epoch [79/300] Training [41/62] Loss: 0.35548 
Epoch [79/300] Training [42/62] Loss: 0.24757 
Epoch [79/300] Training [43/62] Loss: 0.49248 
Epoch [79/300] Training [44/62] Loss: 0.17400 
Epoch [79/300] Training [45/62] Loss: 0.26389 
Epoch [79/300] Training [46/62] Loss: 0.41320 
Epoch [79/300] Training [47/62] Loss: 0.51764 
Epoch [79/300] Training [48/62] Loss: 0.31690 
Epoch [79/300] Training [49/62] Loss: 0.37022 
Epoch [79/300] Training [50/62] Loss: 0.15099 
Epoch [79/300] Training [51/62] Loss: 0.20813 
Epoch [79/300] Training [52/62] Loss: 0.28793 
Epoch [79/300] Training [53/62] Loss: 0.28160 
Epoch [79/300] Training [54/62] Loss: 0.41743 
Epoch [79/300] Training [55/62] Loss: 0.23674 
Epoch [79/300] Training [56/62] Loss: 0.24285 
Epoch [79/300] Training [57/62] Loss: 0.14838 
Epoch [79/300] Training [58/62] Loss: 0.40525 
Epoch [79/300] Training [59/62] Loss: 0.20011 
Epoch [79/300] Training [60/62] Loss: 0.35348 
Epoch [79/300] Training [61/62] Loss: 0.43854 
Epoch [79/300] Training [62/62] Loss: 0.29678 
Epoch [79/300] Training metric {'Train/mean dice_metric': 0.8126838207244873, 'Train/mean miou_metric': 0.7241710424423218, 'Train/mean f1': 0.8390762805938721, 'Train/mean precision': 0.845063328742981, 'Train/mean recall': 0.8331735730171204, 'Train/mean hd95_metric': 47.93955612182617}
Epoch [79/300] Validation [1/16] Loss: 0.64405  focal_loss 0.34205  dice_loss 0.30200 
Epoch [79/300] Validation [2/16] Loss: 0.44007  focal_loss 0.10825  dice_loss 0.33182 
Epoch [79/300] Validation [3/16] Loss: 0.58506  focal_loss 0.25241  dice_loss 0.33265 
Epoch [79/300] Validation [4/16] Loss: 0.38403  focal_loss 0.11760  dice_loss 0.26643 
Epoch [79/300] Validation [5/16] Loss: 0.40874  focal_loss 0.07500  dice_loss 0.33374 
Epoch [79/300] Validation [6/16] Loss: 0.42495  focal_loss 0.10319  dice_loss 0.32176 
Epoch [79/300] Validation [7/16] Loss: 0.22939  focal_loss 0.05548  dice_loss 0.17391 
Epoch [79/300] Validation [8/16] Loss: 0.46043  focal_loss 0.09385  dice_loss 0.36659 
Epoch [79/300] Validation [9/16] Loss: 0.36028  focal_loss 0.10094  dice_loss 0.25933 
Epoch [79/300] Validation [10/16] Loss: 0.61910  focal_loss 0.14264  dice_loss 0.47647 
Epoch [79/300] Validation [11/16] Loss: 0.25807  focal_loss 0.07542  dice_loss 0.18265 
Epoch [79/300] Validation [12/16] Loss: 0.37653  focal_loss 0.06466  dice_loss 0.31187 
Epoch [79/300] Validation [13/16] Loss: 0.28504  focal_loss 0.06344  dice_loss 0.22160 
Epoch [79/300] Validation [14/16] Loss: 0.78274  focal_loss 0.23658  dice_loss 0.54616 
Epoch [79/300] Validation [15/16] Loss: 0.26881  focal_loss 0.07303  dice_loss 0.19578 
Epoch [79/300] Validation [16/16] Loss: 0.26147  focal_loss 0.07007  dice_loss 0.19140 
Epoch [79/300] Validation metric {'Val/mean dice_metric': 0.7935922741889954, 'Val/mean miou_metric': 0.7016433477401733, 'Val/mean f1': 0.821938157081604, 'Val/mean precision': 0.8314223885536194, 'Val/mean recall': 0.8126679062843323, 'Val/mean hd95_metric': 51.76661682128906}
Cheakpoint...
Epoch [79/300] best acc:tensor([0.7936], device='cuda:0'), Now : mean acc: tensor([0.7936], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7935922741889954, 'Val/mean miou_metric': 0.7016433477401733, 'Val/mean f1': 0.821938157081604, 'Val/mean precision': 0.8314223885536194, 'Val/mean recall': 0.8126679062843323, 'Val/mean hd95_metric': 51.76661682128906}
Epoch [80/300] Training [1/62] Loss: 0.19414 
Epoch [80/300] Training [2/62] Loss: 0.19926 
Epoch [80/300] Training [3/62] Loss: 0.16941 
Epoch [80/300] Training [4/62] Loss: 0.22193 
Epoch [80/300] Training [5/62] Loss: 0.16641 
Epoch [80/300] Training [6/62] Loss: 0.30874 
Epoch [80/300] Training [7/62] Loss: 0.30466 
Epoch [80/300] Training [8/62] Loss: 0.24363 
Epoch [80/300] Training [9/62] Loss: 0.14043 
Epoch [80/300] Training [10/62] Loss: 0.36563 
Epoch [80/300] Training [11/62] Loss: 0.29032 
Epoch [80/300] Training [12/62] Loss: 0.16536 
Epoch [80/300] Training [13/62] Loss: 0.18386 
Epoch [80/300] Training [14/62] Loss: 0.22865 
Epoch [80/300] Training [15/62] Loss: 0.12571 
Epoch [80/300] Training [16/62] Loss: 0.29445 
Epoch [80/300] Training [17/62] Loss: 0.27395 
Epoch [80/300] Training [18/62] Loss: 0.18142 
Epoch [80/300] Training [19/62] Loss: 0.27712 
Epoch [80/300] Training [20/62] Loss: 0.20113 
Epoch [80/300] Training [21/62] Loss: 0.19092 
Epoch [80/300] Training [22/62] Loss: 0.23929 
Epoch [80/300] Training [23/62] Loss: 0.20170 
Epoch [80/300] Training [24/62] Loss: 0.20651 
Epoch [80/300] Training [25/62] Loss: 0.58585 
Epoch [80/300] Training [26/62] Loss: 0.20280 
Epoch [80/300] Training [27/62] Loss: 0.20144 
Epoch [80/300] Training [28/62] Loss: 0.20132 
Epoch [80/300] Training [29/62] Loss: 0.17383 
Epoch [80/300] Training [30/62] Loss: 0.17156 
Epoch [80/300] Training [31/62] Loss: 0.32115 
Epoch [80/300] Training [32/62] Loss: 0.25892 
Epoch [80/300] Training [33/62] Loss: 0.15132 
Epoch [80/300] Training [34/62] Loss: 0.14951 
Epoch [80/300] Training [35/62] Loss: 0.60403 
Epoch [80/300] Training [36/62] Loss: 0.28362 
Epoch [80/300] Training [37/62] Loss: 0.49989 
Epoch [80/300] Training [38/62] Loss: 0.17259 
Epoch [80/300] Training [39/62] Loss: 0.15432 
Epoch [80/300] Training [40/62] Loss: 0.33219 
Epoch [80/300] Training [41/62] Loss: 0.24694 
Epoch [80/300] Training [42/62] Loss: 0.21903 
Epoch [80/300] Training [43/62] Loss: 0.28291 
Epoch [80/300] Training [44/62] Loss: 0.19160 
Epoch [80/300] Training [45/62] Loss: 0.28204 
Epoch [80/300] Training [46/62] Loss: 0.22968 
Epoch [80/300] Training [47/62] Loss: 0.27011 
Epoch [80/300] Training [48/62] Loss: 0.24743 
Epoch [80/300] Training [49/62] Loss: 0.18439 
Epoch [80/300] Training [50/62] Loss: 0.36568 
Epoch [80/300] Training [51/62] Loss: 0.40077 
Epoch [80/300] Training [52/62] Loss: 0.30930 
Epoch [80/300] Training [53/62] Loss: 0.50187 
Epoch [80/300] Training [54/62] Loss: 0.34218 
Epoch [80/300] Training [55/62] Loss: 0.17977 
Epoch [80/300] Training [56/62] Loss: 0.23510 
Epoch [80/300] Training [57/62] Loss: 0.34326 
Epoch [80/300] Training [58/62] Loss: 0.31287 
Epoch [80/300] Training [59/62] Loss: 0.29399 
Epoch [80/300] Training [60/62] Loss: 0.23661 
Epoch [80/300] Training [61/62] Loss: 0.48959 
Epoch [80/300] Training [62/62] Loss: 0.57745 
Epoch [80/300] Training metric {'Train/mean dice_metric': 0.826106071472168, 'Train/mean miou_metric': 0.7399542331695557, 'Train/mean f1': 0.8543347120285034, 'Train/mean precision': 0.8667194247245789, 'Train/mean recall': 0.8422990441322327, 'Train/mean hd95_metric': 46.80929183959961}
Epoch [80/300] Validation [1/16] Loss: 0.64601  focal_loss 0.35115  dice_loss 0.29486 
Epoch [80/300] Validation [2/16] Loss: 0.55301  focal_loss 0.14081  dice_loss 0.41220 
Epoch [80/300] Validation [3/16] Loss: 0.57672  focal_loss 0.24107  dice_loss 0.33565 
Epoch [80/300] Validation [4/16] Loss: 0.46536  focal_loss 0.16216  dice_loss 0.30320 
Epoch [80/300] Validation [5/16] Loss: 0.42362  focal_loss 0.09107  dice_loss 0.33255 
Epoch [80/300] Validation [6/16] Loss: 0.37736  focal_loss 0.09074  dice_loss 0.28661 
Epoch [80/300] Validation [7/16] Loss: 0.38063  focal_loss 0.11319  dice_loss 0.26744 
Epoch [80/300] Validation [8/16] Loss: 0.62416  focal_loss 0.15907  dice_loss 0.46509 
Epoch [80/300] Validation [9/16] Loss: 0.30865  focal_loss 0.08475  dice_loss 0.22390 
Epoch [80/300] Validation [10/16] Loss: 0.72145  focal_loss 0.19799  dice_loss 0.52345 
Epoch [80/300] Validation [11/16] Loss: 0.21850  focal_loss 0.06137  dice_loss 0.15713 
Epoch [80/300] Validation [12/16] Loss: 0.35194  focal_loss 0.05962  dice_loss 0.29232 
Epoch [80/300] Validation [13/16] Loss: 0.34309  focal_loss 0.08523  dice_loss 0.25786 
Epoch [80/300] Validation [14/16] Loss: 0.62210  focal_loss 0.15117  dice_loss 0.47092 
Epoch [80/300] Validation [15/16] Loss: 0.38484  focal_loss 0.11317  dice_loss 0.27167 
Epoch [80/300] Validation [16/16] Loss: 0.21725  focal_loss 0.05432  dice_loss 0.16293 
Epoch [80/300] Validation metric {'Val/mean dice_metric': 0.7999625205993652, 'Val/mean miou_metric': 0.7114894986152649, 'Val/mean f1': 0.8337122797966003, 'Val/mean precision': 0.8589484095573425, 'Val/mean recall': 0.8099167943000793, 'Val/mean hd95_metric': 50.68044662475586}
Cheakpoint...
Epoch [80/300] best acc:tensor([0.8000], device='cuda:0'), Now : mean acc: tensor([0.8000], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7999625205993652, 'Val/mean miou_metric': 0.7114894986152649, 'Val/mean f1': 0.8337122797966003, 'Val/mean precision': 0.8589484095573425, 'Val/mean recall': 0.8099167943000793, 'Val/mean hd95_metric': 50.68044662475586}
Epoch [81/300] Training [1/62] Loss: 0.17199 
Epoch [81/300] Training [2/62] Loss: 0.20985 
Epoch [81/300] Training [3/62] Loss: 0.24852 
Epoch [81/300] Training [4/62] Loss: 0.14709 
Epoch [81/300] Training [5/62] Loss: 0.36558 
Epoch [81/300] Training [6/62] Loss: 0.34067 
Epoch [81/300] Training [7/62] Loss: 0.13752 
Epoch [81/300] Training [8/62] Loss: 0.39119 
Epoch [81/300] Training [9/62] Loss: 0.20339 
Epoch [81/300] Training [10/62] Loss: 0.15675 
Epoch [81/300] Training [11/62] Loss: 0.27689 
Epoch [81/300] Training [12/62] Loss: 0.23549 
Epoch [81/300] Training [13/62] Loss: 0.14524 
Epoch [81/300] Training [14/62] Loss: 0.22586 
Epoch [81/300] Training [15/62] Loss: 0.24689 
Epoch [81/300] Training [16/62] Loss: 0.19530 
Epoch [81/300] Training [17/62] Loss: 0.42069 
Epoch [81/300] Training [18/62] Loss: 0.31610 
Epoch [81/300] Training [19/62] Loss: 0.31759 
Epoch [81/300] Training [20/62] Loss: 0.44204 
Epoch [81/300] Training [21/62] Loss: 0.30050 
Epoch [81/300] Training [22/62] Loss: 0.20406 
Epoch [81/300] Training [23/62] Loss: 0.48513 
Epoch [81/300] Training [24/62] Loss: 0.17510 
Epoch [81/300] Training [25/62] Loss: 0.27713 
Epoch [81/300] Training [26/62] Loss: 0.25658 
Epoch [81/300] Training [27/62] Loss: 0.20209 
Epoch [81/300] Training [28/62] Loss: 0.22223 
Epoch [81/300] Training [29/62] Loss: 0.24429 
Epoch [81/300] Training [30/62] Loss: 0.20302 
Epoch [81/300] Training [31/62] Loss: 0.24341 
Epoch [81/300] Training [32/62] Loss: 0.16788 
Epoch [81/300] Training [33/62] Loss: 0.34683 
Epoch [81/300] Training [34/62] Loss: 0.29191 
Epoch [81/300] Training [35/62] Loss: 0.26580 
Epoch [81/300] Training [36/62] Loss: 0.25476 
Epoch [81/300] Training [37/62] Loss: 0.16558 
Epoch [81/300] Training [38/62] Loss: 0.38686 
Epoch [81/300] Training [39/62] Loss: 0.20498 
Epoch [81/300] Training [40/62] Loss: 0.17406 
Epoch [81/300] Training [41/62] Loss: 0.37494 
Epoch [81/300] Training [42/62] Loss: 0.24013 
Epoch [81/300] Training [43/62] Loss: 0.16894 
Epoch [81/300] Training [44/62] Loss: 0.17873 
Epoch [81/300] Training [45/62] Loss: 0.35641 
Epoch [81/300] Training [46/62] Loss: 0.24804 
Epoch [81/300] Training [47/62] Loss: 0.22963 
Epoch [81/300] Training [48/62] Loss: 0.35111 
Epoch [81/300] Training [49/62] Loss: 0.19437 
Epoch [81/300] Training [50/62] Loss: 0.23968 
Epoch [81/300] Training [51/62] Loss: 0.29410 
Epoch [81/300] Training [52/62] Loss: 0.61725 
Epoch [81/300] Training [53/62] Loss: 0.18931 
Epoch [81/300] Training [54/62] Loss: 0.27049 
Epoch [81/300] Training [55/62] Loss: 0.29776 
Epoch [81/300] Training [56/62] Loss: 0.24044 
Epoch [81/300] Training [57/62] Loss: 0.29469 
Epoch [81/300] Training [58/62] Loss: 0.23456 
Epoch [81/300] Training [59/62] Loss: 0.19333 
Epoch [81/300] Training [60/62] Loss: 0.26578 
Epoch [81/300] Training [61/62] Loss: 0.36624 
Epoch [81/300] Training [62/62] Loss: 0.43267 
Epoch [81/300] Training metric {'Train/mean dice_metric': 0.8221982717514038, 'Train/mean miou_metric': 0.7334844470024109, 'Train/mean f1': 0.8486548662185669, 'Train/mean precision': 0.8546751141548157, 'Train/mean recall': 0.8427188396453857, 'Train/mean hd95_metric': 45.57420349121094}
Epoch [81/300] Validation [1/16] Loss: 0.52677  focal_loss 0.28184  dice_loss 0.24494 
Epoch [81/300] Validation [2/16] Loss: 0.46207  focal_loss 0.11285  dice_loss 0.34923 
Epoch [81/300] Validation [3/16] Loss: 0.66473  focal_loss 0.26756  dice_loss 0.39717 
Epoch [81/300] Validation [4/16] Loss: 0.38633  focal_loss 0.11639  dice_loss 0.26994 
Epoch [81/300] Validation [5/16] Loss: 0.43690  focal_loss 0.10491  dice_loss 0.33198 
Epoch [81/300] Validation [6/16] Loss: 0.52925  focal_loss 0.13379  dice_loss 0.39546 
Epoch [81/300] Validation [7/16] Loss: 0.21118  focal_loss 0.06153  dice_loss 0.14965 
Epoch [81/300] Validation [8/16] Loss: 0.65014  focal_loss 0.19971  dice_loss 0.45044 
Epoch [81/300] Validation [9/16] Loss: 0.38358  focal_loss 0.12737  dice_loss 0.25621 
Epoch [81/300] Validation [10/16] Loss: 0.37835  focal_loss 0.07463  dice_loss 0.30372 
Epoch [81/300] Validation [11/16] Loss: 0.36415  focal_loss 0.11298  dice_loss 0.25117 
Epoch [81/300] Validation [12/16] Loss: 0.42727  focal_loss 0.06788  dice_loss 0.35938 
Epoch [81/300] Validation [13/16] Loss: 0.32304  focal_loss 0.06359  dice_loss 0.25945 
Epoch [81/300] Validation [14/16] Loss: 0.56466  focal_loss 0.14265  dice_loss 0.42200 
Epoch [81/300] Validation [15/16] Loss: 0.19522  focal_loss 0.04437  dice_loss 0.15086 
Epoch [81/300] Validation [16/16] Loss: 0.18744  focal_loss 0.04009  dice_loss 0.14735 
Epoch [81/300] Validation metric {'Val/mean dice_metric': 0.8027064800262451, 'Val/mean miou_metric': 0.7100923657417297, 'Val/mean f1': 0.8291435837745667, 'Val/mean precision': 0.8267129063606262, 'Val/mean recall': 0.831588625907898, 'Val/mean hd95_metric': 51.07075881958008}
Cheakpoint...
Epoch [81/300] best acc:tensor([0.8027], device='cuda:0'), Now : mean acc: tensor([0.8027], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8027064800262451, 'Val/mean miou_metric': 0.7100923657417297, 'Val/mean f1': 0.8291435837745667, 'Val/mean precision': 0.8267129063606262, 'Val/mean recall': 0.831588625907898, 'Val/mean hd95_metric': 51.07075881958008}
Epoch [82/300] Training [1/62] Loss: 0.24215 
Epoch [82/300] Training [2/62] Loss: 0.15678 
Epoch [82/300] Training [3/62] Loss: 0.28562 
Epoch [82/300] Training [4/62] Loss: 0.20218 
Epoch [82/300] Training [5/62] Loss: 0.35241 
Epoch [82/300] Training [6/62] Loss: 0.25434 
Epoch [82/300] Training [7/62] Loss: 0.25414 
Epoch [82/300] Training [8/62] Loss: 0.41724 
Epoch [82/300] Training [9/62] Loss: 0.22631 
Epoch [82/300] Training [10/62] Loss: 0.16540 
Epoch [82/300] Training [11/62] Loss: 0.29596 
Epoch [82/300] Training [12/62] Loss: 0.42333 
Epoch [82/300] Training [13/62] Loss: 0.29497 
Epoch [82/300] Training [14/62] Loss: 0.23228 
Epoch [82/300] Training [15/62] Loss: 0.30823 
Epoch [82/300] Training [16/62] Loss: 0.16569 
Epoch [82/300] Training [17/62] Loss: 0.30609 
Epoch [82/300] Training [18/62] Loss: 0.25221 
Epoch [82/300] Training [19/62] Loss: 0.28995 
Epoch [82/300] Training [20/62] Loss: 0.38105 
Epoch [82/300] Training [21/62] Loss: 0.39001 
Epoch [82/300] Training [22/62] Loss: 0.22426 
Epoch [82/300] Training [23/62] Loss: 0.32138 
Epoch [82/300] Training [24/62] Loss: 0.21224 
Epoch [82/300] Training [25/62] Loss: 0.17549 
Epoch [82/300] Training [26/62] Loss: 0.24543 
Epoch [82/300] Training [27/62] Loss: 0.24512 
Epoch [82/300] Training [28/62] Loss: 0.34751 
Epoch [82/300] Training [29/62] Loss: 0.46787 
Epoch [82/300] Training [30/62] Loss: 0.20462 
Epoch [82/300] Training [31/62] Loss: 0.41279 
Epoch [82/300] Training [32/62] Loss: 0.40607 
Epoch [82/300] Training [33/62] Loss: 0.22801 
Epoch [82/300] Training [34/62] Loss: 0.33071 
Epoch [82/300] Training [35/62] Loss: 0.22603 
Epoch [82/300] Training [36/62] Loss: 0.23470 
Epoch [82/300] Training [37/62] Loss: 0.17720 
Epoch [82/300] Training [38/62] Loss: 0.24393 
Epoch [82/300] Training [39/62] Loss: 0.26342 
Epoch [82/300] Training [40/62] Loss: 0.22193 
Epoch [82/300] Training [41/62] Loss: 0.14495 
Epoch [82/300] Training [42/62] Loss: 0.31240 
Epoch [82/300] Training [43/62] Loss: 0.18796 
Epoch [82/300] Training [44/62] Loss: 0.26274 
Epoch [82/300] Training [45/62] Loss: 0.45561 
Epoch [82/300] Training [46/62] Loss: 0.16378 
Epoch [82/300] Training [47/62] Loss: 0.20532 
Epoch [82/300] Training [48/62] Loss: 0.20929 
Epoch [82/300] Training [49/62] Loss: 0.29340 
Epoch [82/300] Training [50/62] Loss: 0.14747 
Epoch [82/300] Training [51/62] Loss: 0.09509 
Epoch [82/300] Training [52/62] Loss: 0.22630 
Epoch [82/300] Training [53/62] Loss: 0.62951 
Epoch [82/300] Training [54/62] Loss: 0.41635 
Epoch [82/300] Training [55/62] Loss: 0.23529 
Epoch [82/300] Training [56/62] Loss: 0.13765 
Epoch [82/300] Training [57/62] Loss: 0.16459 
Epoch [82/300] Training [58/62] Loss: 0.39162 
Epoch [82/300] Training [59/62] Loss: 0.12956 
Epoch [82/300] Training [60/62] Loss: 0.15361 
Epoch [82/300] Training [61/62] Loss: 0.25099 
Epoch [82/300] Training [62/62] Loss: 0.33858 
Epoch [82/300] Training metric {'Train/mean dice_metric': 0.8252612352371216, 'Train/mean miou_metric': 0.7371481657028198, 'Train/mean f1': 0.8515353202819824, 'Train/mean precision': 0.8726474046707153, 'Train/mean recall': 0.8314205408096313, 'Train/mean hd95_metric': 47.599464416503906}
Epoch [82/300] Validation [1/16] Loss: 0.49304  focal_loss 0.26409  dice_loss 0.22896 
Epoch [82/300] Validation [2/16] Loss: 0.52133  focal_loss 0.14005  dice_loss 0.38128 
Epoch [82/300] Validation [3/16] Loss: 0.54816  focal_loss 0.20114  dice_loss 0.34702 
Epoch [82/300] Validation [4/16] Loss: 0.37386  focal_loss 0.13478  dice_loss 0.23908 
Epoch [82/300] Validation [5/16] Loss: 0.36978  focal_loss 0.07210  dice_loss 0.29769 
Epoch [82/300] Validation [6/16] Loss: 0.34338  focal_loss 0.07916  dice_loss 0.26422 
Epoch [82/300] Validation [7/16] Loss: 0.28405  focal_loss 0.06478  dice_loss 0.21927 
Epoch [82/300] Validation [8/16] Loss: 0.47356  focal_loss 0.10434  dice_loss 0.36923 
Epoch [82/300] Validation [9/16] Loss: 0.31381  focal_loss 0.11635  dice_loss 0.19747 
Epoch [82/300] Validation [10/16] Loss: 0.59742  focal_loss 0.14295  dice_loss 0.45446 
Epoch [82/300] Validation [11/16] Loss: 0.25877  focal_loss 0.05846  dice_loss 0.20031 
Epoch [82/300] Validation [12/16] Loss: 0.39854  focal_loss 0.08540  dice_loss 0.31314 
Epoch [82/300] Validation [13/16] Loss: 0.30813  focal_loss 0.08666  dice_loss 0.22148 
Epoch [82/300] Validation [14/16] Loss: 0.71281  focal_loss 0.23279  dice_loss 0.48002 
Epoch [82/300] Validation [15/16] Loss: 0.28624  focal_loss 0.09238  dice_loss 0.19386 
Epoch [82/300] Validation [16/16] Loss: 0.16210  focal_loss 0.04363  dice_loss 0.11847 
Epoch [82/300] Validation metric {'Val/mean dice_metric': 0.806195855140686, 'Val/mean miou_metric': 0.7153236865997314, 'Val/mean f1': 0.8326301574707031, 'Val/mean precision': 0.8603839874267578, 'Val/mean recall': 0.8066111207008362, 'Val/mean hd95_metric': 51.214691162109375}
Cheakpoint...
Epoch [82/300] best acc:tensor([0.8062], device='cuda:0'), Now : mean acc: tensor([0.8062], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.806195855140686, 'Val/mean miou_metric': 0.7153236865997314, 'Val/mean f1': 0.8326301574707031, 'Val/mean precision': 0.8603839874267578, 'Val/mean recall': 0.8066111207008362, 'Val/mean hd95_metric': 51.214691162109375}
Epoch [83/300] Training [1/62] Loss: 0.25682 
Epoch [83/300] Training [2/62] Loss: 0.28693 
Epoch [83/300] Training [3/62] Loss: 0.26456 
Epoch [83/300] Training [4/62] Loss: 0.24968 
Epoch [83/300] Training [5/62] Loss: 0.33475 
Epoch [83/300] Training [6/62] Loss: 0.23340 
Epoch [83/300] Training [7/62] Loss: 0.23815 
Epoch [83/300] Training [8/62] Loss: 0.25538 
Epoch [83/300] Training [9/62] Loss: 0.19181 
Epoch [83/300] Training [10/62] Loss: 0.52531 
Epoch [83/300] Training [11/62] Loss: 0.12367 
Epoch [83/300] Training [12/62] Loss: 0.21300 
Epoch [83/300] Training [13/62] Loss: 0.39505 
Epoch [83/300] Training [14/62] Loss: 0.40224 
Epoch [83/300] Training [15/62] Loss: 0.30900 
Epoch [83/300] Training [16/62] Loss: 0.19872 
Epoch [83/300] Training [17/62] Loss: 0.31481 
Epoch [83/300] Training [18/62] Loss: 0.34208 
Epoch [83/300] Training [19/62] Loss: 0.21999 
Epoch [83/300] Training [20/62] Loss: 0.32390 
Epoch [83/300] Training [21/62] Loss: 0.19275 
Epoch [83/300] Training [22/62] Loss: 0.25377 
Epoch [83/300] Training [23/62] Loss: 0.29143 
Epoch [83/300] Training [24/62] Loss: 0.31712 
Epoch [83/300] Training [25/62] Loss: 0.30426 
Epoch [83/300] Training [26/62] Loss: 0.12297 
Epoch [83/300] Training [27/62] Loss: 0.28890 
Epoch [83/300] Training [28/62] Loss: 0.24392 
Epoch [83/300] Training [29/62] Loss: 0.25827 
Epoch [83/300] Training [30/62] Loss: 0.29669 
Epoch [83/300] Training [31/62] Loss: 0.12536 
Epoch [83/300] Training [32/62] Loss: 0.27824 
Epoch [83/300] Training [33/62] Loss: 0.28465 
Epoch [83/300] Training [34/62] Loss: 0.10840 
Epoch [83/300] Training [35/62] Loss: 0.18357 
Epoch [83/300] Training [36/62] Loss: 0.20479 
Epoch [83/300] Training [37/62] Loss: 0.23087 
Epoch [83/300] Training [38/62] Loss: 0.22507 
Epoch [83/300] Training [39/62] Loss: 0.46930 
Epoch [83/300] Training [40/62] Loss: 0.32973 
Epoch [83/300] Training [41/62] Loss: 0.11841 
Epoch [83/300] Training [42/62] Loss: 0.32021 
Epoch [83/300] Training [43/62] Loss: 0.20845 
Epoch [83/300] Training [44/62] Loss: 0.34433 
Epoch [83/300] Training [45/62] Loss: 0.10242 
Epoch [83/300] Training [46/62] Loss: 0.22830 
Epoch [83/300] Training [47/62] Loss: 0.28757 
Epoch [83/300] Training [48/62] Loss: 0.24427 
Epoch [83/300] Training [49/62] Loss: 0.38209 
Epoch [83/300] Training [50/62] Loss: 0.28601 
Epoch [83/300] Training [51/62] Loss: 0.36650 
Epoch [83/300] Training [52/62] Loss: 0.22004 
Epoch [83/300] Training [53/62] Loss: 0.19563 
Epoch [83/300] Training [54/62] Loss: 0.18961 
Epoch [83/300] Training [55/62] Loss: 0.55907 
Epoch [83/300] Training [56/62] Loss: 0.17356 
Epoch [83/300] Training [57/62] Loss: 0.18244 
Epoch [83/300] Training [58/62] Loss: 0.30703 
Epoch [83/300] Training [59/62] Loss: 0.22256 
Epoch [83/300] Training [60/62] Loss: 0.29467 
Epoch [83/300] Training [61/62] Loss: 0.27908 
Epoch [83/300] Training [62/62] Loss: 0.09925 
Epoch [83/300] Training metric {'Train/mean dice_metric': 0.8241780400276184, 'Train/mean miou_metric': 0.7379632592201233, 'Train/mean f1': 0.8450941443443298, 'Train/mean precision': 0.8622147440910339, 'Train/mean recall': 0.828640341758728, 'Train/mean hd95_metric': 46.26536560058594}
Epoch [83/300] Validation [1/16] Loss: 1.18968  focal_loss 0.53501  dice_loss 0.65467 
Epoch [83/300] Validation [2/16] Loss: 0.75119  focal_loss 0.24622  dice_loss 0.50497 
Epoch [83/300] Validation [3/16] Loss: 0.78009  focal_loss 0.29251  dice_loss 0.48758 
Epoch [83/300] Validation [4/16] Loss: 0.62020  focal_loss 0.20726  dice_loss 0.41294 
Epoch [83/300] Validation [5/16] Loss: 0.54041  focal_loss 0.09534  dice_loss 0.44507 
Epoch [83/300] Validation [6/16] Loss: 0.60430  focal_loss 0.16030  dice_loss 0.44400 
Epoch [83/300] Validation [7/16] Loss: 0.56656  focal_loss 0.18758  dice_loss 0.37899 
Epoch [83/300] Validation [8/16] Loss: 0.73193  focal_loss 0.16832  dice_loss 0.56362 
Epoch [83/300] Validation [9/16] Loss: 0.80284  focal_loss 0.32251  dice_loss 0.48033 
Epoch [83/300] Validation [10/16] Loss: 1.01309  focal_loss 0.31830  dice_loss 0.69479 
Epoch [83/300] Validation [11/16] Loss: 0.57552  focal_loss 0.15598  dice_loss 0.41954 
Epoch [83/300] Validation [12/16] Loss: 0.58395  focal_loss 0.09437  dice_loss 0.48959 
Epoch [83/300] Validation [13/16] Loss: 0.52503  focal_loss 0.17562  dice_loss 0.34941 
Epoch [83/300] Validation [14/16] Loss: 0.99975  focal_loss 0.27124  dice_loss 0.72851 
Epoch [83/300] Validation [15/16] Loss: 0.60668  focal_loss 0.22452  dice_loss 0.38217 
Epoch [83/300] Validation [16/16] Loss: 0.41093  focal_loss 0.12600  dice_loss 0.28493 
Epoch [83/300] Validation metric {'Val/mean dice_metric': 0.7627103924751282, 'Val/mean miou_metric': 0.6747044920921326, 'Val/mean f1': 0.8034807443618774, 'Val/mean precision': 0.8585572242736816, 'Val/mean recall': 0.7550445199012756, 'Val/mean hd95_metric': 50.1755256652832}
Cheakpoint...
Epoch [83/300] best acc:tensor([0.8062], device='cuda:0'), Now : mean acc: tensor([0.7627], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7627103924751282, 'Val/mean miou_metric': 0.6747044920921326, 'Val/mean f1': 0.8034807443618774, 'Val/mean precision': 0.8585572242736816, 'Val/mean recall': 0.7550445199012756, 'Val/mean hd95_metric': 50.1755256652832}
Epoch [84/300] Training [1/62] Loss: 0.28710 
Epoch [84/300] Training [2/62] Loss: 0.36859 
Epoch [84/300] Training [3/62] Loss: 0.11257 
Epoch [84/300] Training [4/62] Loss: 0.13063 
Epoch [84/300] Training [5/62] Loss: 0.36703 
Epoch [84/300] Training [6/62] Loss: 0.31308 
Epoch [84/300] Training [7/62] Loss: 0.17324 
Epoch [84/300] Training [8/62] Loss: 0.30354 
Epoch [84/300] Training [9/62] Loss: 0.25362 
Epoch [84/300] Training [10/62] Loss: 0.23931 
Epoch [84/300] Training [11/62] Loss: 0.30973 
Epoch [84/300] Training [12/62] Loss: 0.15336 
Epoch [84/300] Training [13/62] Loss: 0.36861 
Epoch [84/300] Training [14/62] Loss: 0.25414 
Epoch [84/300] Training [15/62] Loss: 0.30828 
Epoch [84/300] Training [16/62] Loss: 0.12864 
Epoch [84/300] Training [17/62] Loss: 0.28354 
Epoch [84/300] Training [18/62] Loss: 0.31066 
Epoch [84/300] Training [19/62] Loss: 0.19358 
Epoch [84/300] Training [20/62] Loss: 0.10279 
Epoch [84/300] Training [21/62] Loss: 0.22060 
Epoch [84/300] Training [22/62] Loss: 0.24542 
Epoch [84/300] Training [23/62] Loss: 0.25470 
Epoch [84/300] Training [24/62] Loss: 0.22937 
Epoch [84/300] Training [25/62] Loss: 0.27711 
Epoch [84/300] Training [26/62] Loss: 0.16422 
Epoch [84/300] Training [27/62] Loss: 0.36056 
Epoch [84/300] Training [28/62] Loss: 0.22715 
Epoch [84/300] Training [29/62] Loss: 0.19061 
Epoch [84/300] Training [30/62] Loss: 0.19771 
Epoch [84/300] Training [31/62] Loss: 0.24876 
Epoch [84/300] Training [32/62] Loss: 0.12702 
Epoch [84/300] Training [33/62] Loss: 0.13079 
Epoch [84/300] Training [34/62] Loss: 0.30808 
Epoch [84/300] Training [35/62] Loss: 0.20204 
Epoch [84/300] Training [36/62] Loss: 0.15509 
Epoch [84/300] Training [37/62] Loss: 0.32461 
Epoch [84/300] Training [38/62] Loss: 0.30652 
Epoch [84/300] Training [39/62] Loss: 0.65033 
Epoch [84/300] Training [40/62] Loss: 0.33350 
Epoch [84/300] Training [41/62] Loss: 0.28006 
Epoch [84/300] Training [42/62] Loss: 0.15749 
Epoch [84/300] Training [43/62] Loss: 0.24648 
Epoch [84/300] Training [44/62] Loss: 0.29030 
Epoch [84/300] Training [45/62] Loss: 0.15989 
Epoch [84/300] Training [46/62] Loss: 0.26100 
Epoch [84/300] Training [47/62] Loss: 0.14082 
Epoch [84/300] Training [48/62] Loss: 0.23079 
Epoch [84/300] Training [49/62] Loss: 0.27745 
Epoch [84/300] Training [50/62] Loss: 0.27921 
Epoch [84/300] Training [51/62] Loss: 0.33946 
Epoch [84/300] Training [52/62] Loss: 0.24583 
Epoch [84/300] Training [53/62] Loss: 0.19097 
Epoch [84/300] Training [54/62] Loss: 0.46322 
Epoch [84/300] Training [55/62] Loss: 0.36257 
Epoch [84/300] Training [56/62] Loss: 0.25391 
Epoch [84/300] Training [57/62] Loss: 0.30256 
Epoch [84/300] Training [58/62] Loss: 0.59166 
Epoch [84/300] Training [59/62] Loss: 0.18411 
Epoch [84/300] Training [60/62] Loss: 0.27325 
Epoch [84/300] Training [61/62] Loss: 0.15816 
Epoch [84/300] Training [62/62] Loss: 0.86537 
Epoch [84/300] Training metric {'Train/mean dice_metric': 0.8293654918670654, 'Train/mean miou_metric': 0.7438279390335083, 'Train/mean f1': 0.8457938432693481, 'Train/mean precision': 0.8647869825363159, 'Train/mean recall': 0.8276169896125793, 'Train/mean hd95_metric': 44.69707107543945}
Epoch [84/300] Validation [1/16] Loss: 0.52420  focal_loss 0.29259  dice_loss 0.23160 
Epoch [84/300] Validation [2/16] Loss: 0.46381  focal_loss 0.10450  dice_loss 0.35930 
Epoch [84/300] Validation [3/16] Loss: 0.51597  focal_loss 0.17039  dice_loss 0.34558 
Epoch [84/300] Validation [4/16] Loss: 0.35782  focal_loss 0.12030  dice_loss 0.23752 
Epoch [84/300] Validation [5/16] Loss: 0.43995  focal_loss 0.09435  dice_loss 0.34561 
Epoch [84/300] Validation [6/16] Loss: 0.40464  focal_loss 0.10108  dice_loss 0.30356 
Epoch [84/300] Validation [7/16] Loss: 0.31000  focal_loss 0.08379  dice_loss 0.22622 
Epoch [84/300] Validation [8/16] Loss: 0.40794  focal_loss 0.08886  dice_loss 0.31909 
Epoch [84/300] Validation [9/16] Loss: 0.31134  focal_loss 0.07296  dice_loss 0.23838 
Epoch [84/300] Validation [10/16] Loss: 0.63441  focal_loss 0.15021  dice_loss 0.48420 
Epoch [84/300] Validation [11/16] Loss: 0.23283  focal_loss 0.05079  dice_loss 0.18204 
Epoch [84/300] Validation [12/16] Loss: 0.40176  focal_loss 0.07136  dice_loss 0.33040 
Epoch [84/300] Validation [13/16] Loss: 0.34466  focal_loss 0.08357  dice_loss 0.26108 
Epoch [84/300] Validation [14/16] Loss: 0.51309  focal_loss 0.10969  dice_loss 0.40340 
Epoch [84/300] Validation [15/16] Loss: 0.21830  focal_loss 0.05341  dice_loss 0.16489 
Epoch [84/300] Validation [16/16] Loss: 0.17106  focal_loss 0.03565  dice_loss 0.13541 
Epoch [84/300] Validation metric {'Val/mean dice_metric': 0.8092764019966125, 'Val/mean miou_metric': 0.7198491096496582, 'Val/mean f1': 0.8273084759712219, 'Val/mean precision': 0.840749204158783, 'Val/mean recall': 0.8142907619476318, 'Val/mean hd95_metric': 49.332183837890625}
Cheakpoint...
Epoch [84/300] best acc:tensor([0.8093], device='cuda:0'), Now : mean acc: tensor([0.8093], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8092764019966125, 'Val/mean miou_metric': 0.7198491096496582, 'Val/mean f1': 0.8273084759712219, 'Val/mean precision': 0.840749204158783, 'Val/mean recall': 0.8142907619476318, 'Val/mean hd95_metric': 49.332183837890625}
Epoch [85/300] Training [1/62] Loss: 0.39503 
Epoch [85/300] Training [2/62] Loss: 0.20268 
Epoch [85/300] Training [3/62] Loss: 0.39014 
Epoch [85/300] Training [4/62] Loss: 0.17340 
Epoch [85/300] Training [5/62] Loss: 0.20306 
Epoch [85/300] Training [6/62] Loss: 0.21735 
Epoch [85/300] Training [7/62] Loss: 0.28664 
Epoch [85/300] Training [8/62] Loss: 0.19824 
Epoch [85/300] Training [9/62] Loss: 0.39799 
Epoch [85/300] Training [10/62] Loss: 0.28958 
Epoch [85/300] Training [11/62] Loss: 0.12645 
Epoch [85/300] Training [12/62] Loss: 0.27802 
Epoch [85/300] Training [13/62] Loss: 0.18960 
Epoch [85/300] Training [14/62] Loss: 0.16511 
Epoch [85/300] Training [15/62] Loss: 0.13001 
Epoch [85/300] Training [16/62] Loss: 0.33565 
Epoch [85/300] Training [17/62] Loss: 0.13590 
Epoch [85/300] Training [18/62] Loss: 0.13546 
Epoch [85/300] Training [19/62] Loss: 0.16245 
Epoch [85/300] Training [20/62] Loss: 0.18961 
Epoch [85/300] Training [21/62] Loss: 0.35571 
Epoch [85/300] Training [22/62] Loss: 0.22330 
Epoch [85/300] Training [23/62] Loss: 0.23920 
Epoch [85/300] Training [24/62] Loss: 0.20390 
Epoch [85/300] Training [25/62] Loss: 0.18747 
Epoch [85/300] Training [26/62] Loss: 0.18978 
Epoch [85/300] Training [27/62] Loss: 0.16083 
Epoch [85/300] Training [28/62] Loss: 0.14290 
Epoch [85/300] Training [29/62] Loss: 0.18244 
Epoch [85/300] Training [30/62] Loss: 0.16750 
Epoch [85/300] Training [31/62] Loss: 0.23478 
Epoch [85/300] Training [32/62] Loss: 0.34927 
Epoch [85/300] Training [33/62] Loss: 0.35903 
Epoch [85/300] Training [34/62] Loss: 0.15413 
Epoch [85/300] Training [35/62] Loss: 0.26805 
Epoch [85/300] Training [36/62] Loss: 0.09505 
Epoch [85/300] Training [37/62] Loss: 0.35879 
Epoch [85/300] Training [38/62] Loss: 0.19533 
Epoch [85/300] Training [39/62] Loss: 0.31586 
Epoch [85/300] Training [40/62] Loss: 0.28374 
Epoch [85/300] Training [41/62] Loss: 0.17443 
Epoch [85/300] Training [42/62] Loss: 0.44400 
Epoch [85/300] Training [43/62] Loss: 0.20903 
Epoch [85/300] Training [44/62] Loss: 0.30815 
Epoch [85/300] Training [45/62] Loss: 0.34934 
Epoch [85/300] Training [46/62] Loss: 0.11383 
Epoch [85/300] Training [47/62] Loss: 0.19976 
Epoch [85/300] Training [48/62] Loss: 0.24085 
Epoch [85/300] Training [49/62] Loss: 0.23720 
Epoch [85/300] Training [50/62] Loss: 0.18920 
Epoch [85/300] Training [51/62] Loss: 0.31676 
Epoch [85/300] Training [52/62] Loss: 0.13653 
Epoch [85/300] Training [53/62] Loss: 0.11202 
Epoch [85/300] Training [54/62] Loss: 0.27961 
Epoch [85/300] Training [55/62] Loss: 0.15823 
Epoch [85/300] Training [56/62] Loss: 0.35517 
Epoch [85/300] Training [57/62] Loss: 0.39172 
Epoch [85/300] Training [58/62] Loss: 0.38817 
Epoch [85/300] Training [59/62] Loss: 0.25871 
Epoch [85/300] Training [60/62] Loss: 0.43202 
Epoch [85/300] Training [61/62] Loss: 0.20142 
Epoch [85/300] Training [62/62] Loss: 0.05653 
Epoch [85/300] Training metric {'Train/mean dice_metric': 0.8393576741218567, 'Train/mean miou_metric': 0.7560803294181824, 'Train/mean f1': 0.8636345267295837, 'Train/mean precision': 0.8767199516296387, 'Train/mean recall': 0.8509340882301331, 'Train/mean hd95_metric': 41.14667892456055}
Epoch [85/300] Validation [1/16] Loss: 0.60119  focal_loss 0.35253  dice_loss 0.24866 
Epoch [85/300] Validation [2/16] Loss: 0.47095  focal_loss 0.11207  dice_loss 0.35888 
Epoch [85/300] Validation [3/16] Loss: 0.65234  focal_loss 0.27371  dice_loss 0.37863 
Epoch [85/300] Validation [4/16] Loss: 0.32252  focal_loss 0.10305  dice_loss 0.21947 
Epoch [85/300] Validation [5/16] Loss: 0.32349  focal_loss 0.06032  dice_loss 0.26317 
Epoch [85/300] Validation [6/16] Loss: 0.31699  focal_loss 0.06716  dice_loss 0.24983 
Epoch [85/300] Validation [7/16] Loss: 0.23061  focal_loss 0.05865  dice_loss 0.17196 
Epoch [85/300] Validation [8/16] Loss: 0.48683  focal_loss 0.10212  dice_loss 0.38471 
Epoch [85/300] Validation [9/16] Loss: 0.28570  focal_loss 0.06958  dice_loss 0.21612 
Epoch [85/300] Validation [10/16] Loss: 0.46965  focal_loss 0.11017  dice_loss 0.35947 
Epoch [85/300] Validation [11/16] Loss: 0.31324  focal_loss 0.07576  dice_loss 0.23749 
Epoch [85/300] Validation [12/16] Loss: 0.45501  focal_loss 0.06928  dice_loss 0.38574 
Epoch [85/300] Validation [13/16] Loss: 0.27564  focal_loss 0.05759  dice_loss 0.21805 
Epoch [85/300] Validation [14/16] Loss: 0.59664  focal_loss 0.19031  dice_loss 0.40633 
Epoch [85/300] Validation [15/16] Loss: 0.16787  focal_loss 0.03361  dice_loss 0.13427 
Epoch [85/300] Validation [16/16] Loss: 0.14862  focal_loss 0.02414  dice_loss 0.12447 
Epoch [85/300] Validation metric {'Val/mean dice_metric': 0.8195122480392456, 'Val/mean miou_metric': 0.7328416705131531, 'Val/mean f1': 0.8469851613044739, 'Val/mean precision': 0.857408881187439, 'Val/mean recall': 0.836811900138855, 'Val/mean hd95_metric': 46.21534729003906}
Cheakpoint...
Epoch [85/300] best acc:tensor([0.8195], device='cuda:0'), Now : mean acc: tensor([0.8195], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8195122480392456, 'Val/mean miou_metric': 0.7328416705131531, 'Val/mean f1': 0.8469851613044739, 'Val/mean precision': 0.857408881187439, 'Val/mean recall': 0.836811900138855, 'Val/mean hd95_metric': 46.21534729003906}
Epoch [86/300] Training [1/62] Loss: 0.23888 
Epoch [86/300] Training [2/62] Loss: 0.43312 
Epoch [86/300] Training [3/62] Loss: 0.17660 
Epoch [86/300] Training [4/62] Loss: 0.22424 
Epoch [86/300] Training [5/62] Loss: 0.26891 
Epoch [86/300] Training [6/62] Loss: 0.28261 
Epoch [86/300] Training [7/62] Loss: 0.11051 
Epoch [86/300] Training [8/62] Loss: 0.23346 
Epoch [86/300] Training [9/62] Loss: 0.40561 
Epoch [86/300] Training [10/62] Loss: 0.33216 
Epoch [86/300] Training [11/62] Loss: 0.21814 
Epoch [86/300] Training [12/62] Loss: 0.21883 
Epoch [86/300] Training [13/62] Loss: 0.15734 
Epoch [86/300] Training [14/62] Loss: 0.40494 
Epoch [86/300] Training [15/62] Loss: 0.24493 
Epoch [86/300] Training [16/62] Loss: 0.23903 
Epoch [86/300] Training [17/62] Loss: 0.27097 
Epoch [86/300] Training [18/62] Loss: 0.22839 
Epoch [86/300] Training [19/62] Loss: 0.15104 
Epoch [86/300] Training [20/62] Loss: 0.27325 
Epoch [86/300] Training [21/62] Loss: 0.24142 
Epoch [86/300] Training [22/62] Loss: 0.31311 
Epoch [86/300] Training [23/62] Loss: 0.10849 
Epoch [86/300] Training [24/62] Loss: 0.29126 
Epoch [86/300] Training [25/62] Loss: 0.12741 
Epoch [86/300] Training [26/62] Loss: 0.31780 
Epoch [86/300] Training [27/62] Loss: 0.23767 
Epoch [86/300] Training [28/62] Loss: 0.17824 
Epoch [86/300] Training [29/62] Loss: 0.17807 
Epoch [86/300] Training [30/62] Loss: 0.30431 
Epoch [86/300] Training [31/62] Loss: 0.18600 
Epoch [86/300] Training [32/62] Loss: 0.20601 
Epoch [86/300] Training [33/62] Loss: 0.41564 
Epoch [86/300] Training [34/62] Loss: 0.27471 
Epoch [86/300] Training [35/62] Loss: 0.16076 
Epoch [86/300] Training [36/62] Loss: 0.25789 
Epoch [86/300] Training [37/62] Loss: 0.18072 
Epoch [86/300] Training [38/62] Loss: 0.29466 
Epoch [86/300] Training [39/62] Loss: 0.12443 
Epoch [86/300] Training [40/62] Loss: 0.29753 
Epoch [86/300] Training [41/62] Loss: 0.35694 
Epoch [86/300] Training [42/62] Loss: 0.11171 
Epoch [86/300] Training [43/62] Loss: 0.19234 
Epoch [86/300] Training [44/62] Loss: 0.30683 
Epoch [86/300] Training [45/62] Loss: 0.22191 
Epoch [86/300] Training [46/62] Loss: 0.48303 
Epoch [86/300] Training [47/62] Loss: 0.15091 
Epoch [86/300] Training [48/62] Loss: 0.11587 
Epoch [86/300] Training [49/62] Loss: 0.18211 
Epoch [86/300] Training [50/62] Loss: 0.15383 
Epoch [86/300] Training [51/62] Loss: 0.13138 
Epoch [86/300] Training [52/62] Loss: 0.31393 
Epoch [86/300] Training [53/62] Loss: 0.14402 
Epoch [86/300] Training [54/62] Loss: 0.23281 
Epoch [86/300] Training [55/62] Loss: 0.48931 
Epoch [86/300] Training [56/62] Loss: 0.20390 
Epoch [86/300] Training [57/62] Loss: 0.26104 
Epoch [86/300] Training [58/62] Loss: 0.19479 
Epoch [86/300] Training [59/62] Loss: 0.29873 
Epoch [86/300] Training [60/62] Loss: 0.34761 
Epoch [86/300] Training [61/62] Loss: 0.15986 
Epoch [86/300] Training [62/62] Loss: 0.13124 
Epoch [86/300] Training metric {'Train/mean dice_metric': 0.8338310718536377, 'Train/mean miou_metric': 0.7524030804634094, 'Train/mean f1': 0.8647043704986572, 'Train/mean precision': 0.8667784333229065, 'Train/mean recall': 0.8626403212547302, 'Train/mean hd95_metric': 43.3312873840332}
Epoch [86/300] Validation [1/16] Loss: 0.58443  focal_loss 0.30987  dice_loss 0.27455 
Epoch [86/300] Validation [2/16] Loss: 0.76750  focal_loss 0.20381  dice_loss 0.56370 
Epoch [86/300] Validation [3/16] Loss: 0.57759  focal_loss 0.22244  dice_loss 0.35516 
Epoch [86/300] Validation [4/16] Loss: 0.35915  focal_loss 0.13875  dice_loss 0.22040 
Epoch [86/300] Validation [5/16] Loss: 0.37763  focal_loss 0.07442  dice_loss 0.30321 
Epoch [86/300] Validation [6/16] Loss: 0.39902  focal_loss 0.12797  dice_loss 0.27105 
Epoch [86/300] Validation [7/16] Loss: 0.28442  focal_loss 0.08825  dice_loss 0.19617 
Epoch [86/300] Validation [8/16] Loss: 0.40160  focal_loss 0.07782  dice_loss 0.32378 
Epoch [86/300] Validation [9/16] Loss: 0.52133  focal_loss 0.17342  dice_loss 0.34791 
Epoch [86/300] Validation [10/16] Loss: 0.97454  focal_loss 0.35097  dice_loss 0.62357 
Epoch [86/300] Validation [11/16] Loss: 0.28651  focal_loss 0.08030  dice_loss 0.20621 
Epoch [86/300] Validation [12/16] Loss: 0.44308  focal_loss 0.06784  dice_loss 0.37524 
Epoch [86/300] Validation [13/16] Loss: 0.37219  focal_loss 0.08414  dice_loss 0.28804 
Epoch [86/300] Validation [14/16] Loss: 0.62212  focal_loss 0.16593  dice_loss 0.45619 
Epoch [86/300] Validation [15/16] Loss: 0.25715  focal_loss 0.07034  dice_loss 0.18681 
Epoch [86/300] Validation [16/16] Loss: 0.14985  focal_loss 0.02961  dice_loss 0.12023 
Epoch [86/300] Validation metric {'Val/mean dice_metric': 0.8057686686515808, 'Val/mean miou_metric': 0.7194282412528992, 'Val/mean f1': 0.8363609910011292, 'Val/mean precision': 0.8457375168800354, 'Val/mean recall': 0.8271901607513428, 'Val/mean hd95_metric': 48.58748245239258}
Cheakpoint...
Epoch [86/300] best acc:tensor([0.8195], device='cuda:0'), Now : mean acc: tensor([0.8058], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8057686686515808, 'Val/mean miou_metric': 0.7194282412528992, 'Val/mean f1': 0.8363609910011292, 'Val/mean precision': 0.8457375168800354, 'Val/mean recall': 0.8271901607513428, 'Val/mean hd95_metric': 48.58748245239258}
Epoch [87/300] Training [1/62] Loss: 0.28786 
Epoch [87/300] Training [2/62] Loss: 0.21869 
Epoch [87/300] Training [3/62] Loss: 0.13847 
Epoch [87/300] Training [4/62] Loss: 0.29801 
Epoch [87/300] Training [5/62] Loss: 0.30534 
Epoch [87/300] Training [6/62] Loss: 0.21579 
Epoch [87/300] Training [7/62] Loss: 0.31264 
Epoch [87/300] Training [8/62] Loss: 0.30802 
Epoch [87/300] Training [9/62] Loss: 0.33163 
Epoch [87/300] Training [10/62] Loss: 0.27685 
Epoch [87/300] Training [11/62] Loss: 0.22669 
Epoch [87/300] Training [12/62] Loss: 0.22210 
Epoch [87/300] Training [13/62] Loss: 0.20701 
Epoch [87/300] Training [14/62] Loss: 0.20660 
Epoch [87/300] Training [15/62] Loss: 0.32202 
Epoch [87/300] Training [16/62] Loss: 0.13410 
Epoch [87/300] Training [17/62] Loss: 0.45395 
Epoch [87/300] Training [18/62] Loss: 0.23618 
Epoch [87/300] Training [19/62] Loss: 0.23132 
Epoch [87/300] Training [20/62] Loss: 0.27581 
Epoch [87/300] Training [21/62] Loss: 0.28545 
Epoch [87/300] Training [22/62] Loss: 0.20592 
Epoch [87/300] Training [23/62] Loss: 0.18018 
Epoch [87/300] Training [24/62] Loss: 0.18251 
Epoch [87/300] Training [25/62] Loss: 0.28798 
Epoch [87/300] Training [26/62] Loss: 0.36492 
Epoch [87/300] Training [27/62] Loss: 0.27260 
Epoch [87/300] Training [28/62] Loss: 0.21795 
Epoch [87/300] Training [29/62] Loss: 0.16310 
Epoch [87/300] Training [30/62] Loss: 0.18788 
Epoch [87/300] Training [31/62] Loss: 0.18632 
Epoch [87/300] Training [32/62] Loss: 0.20468 
Epoch [87/300] Training [33/62] Loss: 0.15066 
Epoch [87/300] Training [34/62] Loss: 0.28061 
Epoch [87/300] Training [35/62] Loss: 0.18297 
Epoch [87/300] Training [36/62] Loss: 0.18311 
Epoch [87/300] Training [37/62] Loss: 0.26732 
Epoch [87/300] Training [38/62] Loss: 0.35201 
Epoch [87/300] Training [39/62] Loss: 0.15757 
Epoch [87/300] Training [40/62] Loss: 0.38635 
Epoch [87/300] Training [41/62] Loss: 0.41668 
Epoch [87/300] Training [42/62] Loss: 0.19381 
Epoch [87/300] Training [43/62] Loss: 0.31605 
Epoch [87/300] Training [44/62] Loss: 0.28543 
Epoch [87/300] Training [45/62] Loss: 0.31626 
Epoch [87/300] Training [46/62] Loss: 0.08412 
Epoch [87/300] Training [47/62] Loss: 0.37014 
Epoch [87/300] Training [48/62] Loss: 0.26935 
Epoch [87/300] Training [49/62] Loss: 0.19213 
Epoch [87/300] Training [50/62] Loss: 0.42792 
Epoch [87/300] Training [51/62] Loss: 0.17640 
Epoch [87/300] Training [52/62] Loss: 0.25031 
Epoch [87/300] Training [53/62] Loss: 0.31889 
Epoch [87/300] Training [54/62] Loss: 0.32173 
Epoch [87/300] Training [55/62] Loss: 0.16438 
Epoch [87/300] Training [56/62] Loss: 0.10543 
Epoch [87/300] Training [57/62] Loss: 0.33859 
Epoch [87/300] Training [58/62] Loss: 0.16874 
Epoch [87/300] Training [59/62] Loss: 0.21496 
Epoch [87/300] Training [60/62] Loss: 0.11717 
Epoch [87/300] Training [61/62] Loss: 0.21901 
Epoch [87/300] Training [62/62] Loss: 1.23128 
Epoch [87/300] Training metric {'Train/mean dice_metric': 0.8328460454940796, 'Train/mean miou_metric': 0.747807502746582, 'Train/mean f1': 0.8523894548416138, 'Train/mean precision': 0.8602273464202881, 'Train/mean recall': 0.8446931838989258, 'Train/mean hd95_metric': 46.03249740600586}
Epoch [87/300] Validation [1/16] Loss: 0.63455  focal_loss 0.33315  dice_loss 0.30139 
Epoch [87/300] Validation [2/16] Loss: 0.46335  focal_loss 0.14583  dice_loss 0.31752 
Epoch [87/300] Validation [3/16] Loss: 0.59257  focal_loss 0.24593  dice_loss 0.34664 
Epoch [87/300] Validation [4/16] Loss: 0.31039  focal_loss 0.11960  dice_loss 0.19080 
Epoch [87/300] Validation [5/16] Loss: 0.42391  focal_loss 0.08805  dice_loss 0.33586 
Epoch [87/300] Validation [6/16] Loss: 0.45138  focal_loss 0.13882  dice_loss 0.31256 
Epoch [87/300] Validation [7/16] Loss: 0.22396  focal_loss 0.05818  dice_loss 0.16578 
Epoch [87/300] Validation [8/16] Loss: 0.46414  focal_loss 0.09201  dice_loss 0.37212 
Epoch [87/300] Validation [9/16] Loss: 0.44007  focal_loss 0.15708  dice_loss 0.28299 
Epoch [87/300] Validation [10/16] Loss: 0.49380  focal_loss 0.11930  dice_loss 0.37450 
Epoch [87/300] Validation [11/16] Loss: 0.34274  focal_loss 0.09826  dice_loss 0.24448 
Epoch [87/300] Validation [12/16] Loss: 0.39166  focal_loss 0.06711  dice_loss 0.32455 
Epoch [87/300] Validation [13/16] Loss: 0.35047  focal_loss 0.10828  dice_loss 0.24219 
Epoch [87/300] Validation [14/16] Loss: 0.77167  focal_loss 0.23884  dice_loss 0.53283 
Epoch [87/300] Validation [15/16] Loss: 0.21258  focal_loss 0.06660  dice_loss 0.14598 
Epoch [87/300] Validation [16/16] Loss: 0.21023  focal_loss 0.04749  dice_loss 0.16274 
Epoch [87/300] Validation metric {'Val/mean dice_metric': 0.8101253509521484, 'Val/mean miou_metric': 0.7216297388076782, 'Val/mean f1': 0.8336374759674072, 'Val/mean precision': 0.8448704481124878, 'Val/mean recall': 0.822699248790741, 'Val/mean hd95_metric': 51.9844856262207}
Cheakpoint...
Epoch [87/300] best acc:tensor([0.8195], device='cuda:0'), Now : mean acc: tensor([0.8101], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8101253509521484, 'Val/mean miou_metric': 0.7216297388076782, 'Val/mean f1': 0.8336374759674072, 'Val/mean precision': 0.8448704481124878, 'Val/mean recall': 0.822699248790741, 'Val/mean hd95_metric': 51.9844856262207}
Epoch [88/300] Training [1/62] Loss: 0.22870 
Epoch [88/300] Training [2/62] Loss: 0.20100 
Epoch [88/300] Training [3/62] Loss: 0.19404 
Epoch [88/300] Training [4/62] Loss: 0.24254 
Epoch [88/300] Training [5/62] Loss: 0.25091 
Epoch [88/300] Training [6/62] Loss: 0.20396 
Epoch [88/300] Training [7/62] Loss: 0.25036 
Epoch [88/300] Training [8/62] Loss: 0.64666 
Epoch [88/300] Training [9/62] Loss: 0.27682 
Epoch [88/300] Training [10/62] Loss: 0.16787 
Epoch [88/300] Training [11/62] Loss: 0.26588 
Epoch [88/300] Training [12/62] Loss: 0.32511 
Epoch [88/300] Training [13/62] Loss: 0.20679 
Epoch [88/300] Training [14/62] Loss: 0.22378 
Epoch [88/300] Training [15/62] Loss: 0.22173 
Epoch [88/300] Training [16/62] Loss: 0.16409 
Epoch [88/300] Training [17/62] Loss: 0.26314 
Epoch [88/300] Training [18/62] Loss: 0.35327 
Epoch [88/300] Training [19/62] Loss: 0.22220 
Epoch [88/300] Training [20/62] Loss: 0.21482 
Epoch [88/300] Training [21/62] Loss: 0.25548 
Epoch [88/300] Training [22/62] Loss: 0.21708 
Epoch [88/300] Training [23/62] Loss: 0.28827 
Epoch [88/300] Training [24/62] Loss: 0.31282 
Epoch [88/300] Training [25/62] Loss: 0.22283 
Epoch [88/300] Training [26/62] Loss: 0.13179 
Epoch [88/300] Training [27/62] Loss: 0.25179 
Epoch [88/300] Training [28/62] Loss: 0.27112 
Epoch [88/300] Training [29/62] Loss: 0.16511 
Epoch [88/300] Training [30/62] Loss: 0.34880 
Epoch [88/300] Training [31/62] Loss: 0.16826 
Epoch [88/300] Training [32/62] Loss: 0.17948 
Epoch [88/300] Training [33/62] Loss: 0.24373 
Epoch [88/300] Training [34/62] Loss: 0.14488 
Epoch [88/300] Training [35/62] Loss: 0.31638 
Epoch [88/300] Training [36/62] Loss: 0.14828 
Epoch [88/300] Training [37/62] Loss: 0.13361 
Epoch [88/300] Training [38/62] Loss: 0.33968 
Epoch [88/300] Training [39/62] Loss: 0.25113 
Epoch [88/300] Training [40/62] Loss: 0.22773 
Epoch [88/300] Training [41/62] Loss: 0.15057 
Epoch [88/300] Training [42/62] Loss: 0.24334 
Epoch [88/300] Training [43/62] Loss: 0.20491 
Epoch [88/300] Training [44/62] Loss: 0.27262 
Epoch [88/300] Training [45/62] Loss: 0.16370 
Epoch [88/300] Training [46/62] Loss: 0.15176 
Epoch [88/300] Training [47/62] Loss: 0.22067 
Epoch [88/300] Training [48/62] Loss: 0.49074 
Epoch [88/300] Training [49/62] Loss: 0.22252 
Epoch [88/300] Training [50/62] Loss: 0.21793 
Epoch [88/300] Training [51/62] Loss: 0.20841 
Epoch [88/300] Training [52/62] Loss: 0.37667 
Epoch [88/300] Training [53/62] Loss: 0.21529 
Epoch [88/300] Training [54/62] Loss: 0.18452 
Epoch [88/300] Training [55/62] Loss: 0.20224 
Epoch [88/300] Training [56/62] Loss: 0.32156 
Epoch [88/300] Training [57/62] Loss: 0.22577 
Epoch [88/300] Training [58/62] Loss: 0.20583 
Epoch [88/300] Training [59/62] Loss: 0.33113 
Epoch [88/300] Training [60/62] Loss: 0.15808 
Epoch [88/300] Training [61/62] Loss: 0.27999 
Epoch [88/300] Training [62/62] Loss: 0.14141 
Epoch [88/300] Training metric {'Train/mean dice_metric': 0.8383158445358276, 'Train/mean miou_metric': 0.7557834386825562, 'Train/mean f1': 0.8636252284049988, 'Train/mean precision': 0.879578173160553, 'Train/mean recall': 0.8482406735420227, 'Train/mean hd95_metric': 46.632049560546875}
Epoch [88/300] Validation [1/16] Loss: 0.69359  focal_loss 0.33931  dice_loss 0.35428 
Epoch [88/300] Validation [2/16] Loss: 0.56688  focal_loss 0.16978  dice_loss 0.39710 
Epoch [88/300] Validation [3/16] Loss: 0.68035  focal_loss 0.25349  dice_loss 0.42686 
Epoch [88/300] Validation [4/16] Loss: 0.46881  focal_loss 0.18535  dice_loss 0.28346 
Epoch [88/300] Validation [5/16] Loss: 0.48347  focal_loss 0.11263  dice_loss 0.37083 
Epoch [88/300] Validation [6/16] Loss: 0.39943  focal_loss 0.11520  dice_loss 0.28423 
Epoch [88/300] Validation [7/16] Loss: 0.42796  focal_loss 0.09744  dice_loss 0.33052 
Epoch [88/300] Validation [8/16] Loss: 0.51098  focal_loss 0.10757  dice_loss 0.40341 
Epoch [88/300] Validation [9/16] Loss: 0.39991  focal_loss 0.12183  dice_loss 0.27808 
Epoch [88/300] Validation [10/16] Loss: 0.66407  focal_loss 0.18915  dice_loss 0.47492 
Epoch [88/300] Validation [11/16] Loss: 0.30469  focal_loss 0.07817  dice_loss 0.22652 
Epoch [88/300] Validation [12/16] Loss: 0.36589  focal_loss 0.05541  dice_loss 0.31048 
Epoch [88/300] Validation [13/16] Loss: 0.25155  focal_loss 0.04804  dice_loss 0.20351 
Epoch [88/300] Validation [14/16] Loss: 0.74153  focal_loss 0.18302  dice_loss 0.55851 
Epoch [88/300] Validation [15/16] Loss: 0.27938  focal_loss 0.08459  dice_loss 0.19479 
Epoch [88/300] Validation [16/16] Loss: 0.24007  focal_loss 0.06748  dice_loss 0.17258 
Epoch [88/300] Validation metric {'Val/mean dice_metric': 0.8081968426704407, 'Val/mean miou_metric': 0.7220227718353271, 'Val/mean f1': 0.8374021649360657, 'Val/mean precision': 0.8644552826881409, 'Val/mean recall': 0.8119910359382629, 'Val/mean hd95_metric': 51.263763427734375}
Cheakpoint...
Epoch [88/300] best acc:tensor([0.8195], device='cuda:0'), Now : mean acc: tensor([0.8082], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8081968426704407, 'Val/mean miou_metric': 0.7220227718353271, 'Val/mean f1': 0.8374021649360657, 'Val/mean precision': 0.8644552826881409, 'Val/mean recall': 0.8119910359382629, 'Val/mean hd95_metric': 51.263763427734375}
Epoch [89/300] Training [1/62] Loss: 0.24128 
Epoch [89/300] Training [2/62] Loss: 0.16849 
Epoch [89/300] Training [3/62] Loss: 0.57542 
Epoch [89/300] Training [4/62] Loss: 0.25345 
Epoch [89/300] Training [5/62] Loss: 0.14551 
Epoch [89/300] Training [6/62] Loss: 0.20581 
Epoch [89/300] Training [7/62] Loss: 0.23782 
Epoch [89/300] Training [8/62] Loss: 0.27470 
Epoch [89/300] Training [9/62] Loss: 0.15409 
Epoch [89/300] Training [10/62] Loss: 0.24366 
Epoch [89/300] Training [11/62] Loss: 0.28137 
Epoch [89/300] Training [12/62] Loss: 0.11625 
Epoch [89/300] Training [13/62] Loss: 0.07893 
Epoch [89/300] Training [14/62] Loss: 0.24376 
Epoch [89/300] Training [15/62] Loss: 0.18756 
Epoch [89/300] Training [16/62] Loss: 0.20666 
Epoch [89/300] Training [17/62] Loss: 0.18729 
Epoch [89/300] Training [18/62] Loss: 0.21347 
Epoch [89/300] Training [19/62] Loss: 0.25223 
Epoch [89/300] Training [20/62] Loss: 0.11024 
Epoch [89/300] Training [21/62] Loss: 0.26751 
Epoch [89/300] Training [22/62] Loss: 0.10391 
Epoch [89/300] Training [23/62] Loss: 0.38282 
Epoch [89/300] Training [24/62] Loss: 0.28927 
Epoch [89/300] Training [25/62] Loss: 0.15069 
Epoch [89/300] Training [26/62] Loss: 0.27194 
Epoch [89/300] Training [27/62] Loss: 0.16397 
Epoch [89/300] Training [28/62] Loss: 0.30883 
Epoch [89/300] Training [29/62] Loss: 0.14473 
Epoch [89/300] Training [30/62] Loss: 0.18545 
Epoch [89/300] Training [31/62] Loss: 0.21201 
Epoch [89/300] Training [32/62] Loss: 0.09633 
Epoch [89/300] Training [33/62] Loss: 0.15577 
Epoch [89/300] Training [34/62] Loss: 0.31500 
Epoch [89/300] Training [35/62] Loss: 0.32947 
Epoch [89/300] Training [36/62] Loss: 0.31860 
Epoch [89/300] Training [37/62] Loss: 0.12241 
Epoch [89/300] Training [38/62] Loss: 0.20875 
Epoch [89/300] Training [39/62] Loss: 0.34854 
Epoch [89/300] Training [40/62] Loss: 0.17725 
Epoch [89/300] Training [41/62] Loss: 0.10754 
Epoch [89/300] Training [42/62] Loss: 0.22765 
Epoch [89/300] Training [43/62] Loss: 0.10322 
Epoch [89/300] Training [44/62] Loss: 0.16609 
Epoch [89/300] Training [45/62] Loss: 0.16340 
Epoch [89/300] Training [46/62] Loss: 0.24214 
Epoch [89/300] Training [47/62] Loss: 0.22847 
Epoch [89/300] Training [48/62] Loss: 0.20265 
Epoch [89/300] Training [49/62] Loss: 0.40576 
Epoch [89/300] Training [50/62] Loss: 0.15585 
Epoch [89/300] Training [51/62] Loss: 0.20715 
Epoch [89/300] Training [52/62] Loss: 0.34215 
Epoch [89/300] Training [53/62] Loss: 0.21343 
Epoch [89/300] Training [54/62] Loss: 0.16011 
Epoch [89/300] Training [55/62] Loss: 0.14781 
Epoch [89/300] Training [56/62] Loss: 0.15878 
Epoch [89/300] Training [57/62] Loss: 0.25660 
Epoch [89/300] Training [58/62] Loss: 0.32643 
Epoch [89/300] Training [59/62] Loss: 0.31264 
Epoch [89/300] Training [60/62] Loss: 0.17853 
Epoch [89/300] Training [61/62] Loss: 0.25309 
Epoch [89/300] Training [62/62] Loss: 0.76193 
Epoch [89/300] Training metric {'Train/mean dice_metric': 0.8525120615959167, 'Train/mean miou_metric': 0.7723283767700195, 'Train/mean f1': 0.8746607899665833, 'Train/mean precision': 0.8847828507423401, 'Train/mean recall': 0.8647676706314087, 'Train/mean hd95_metric': 38.533424377441406}
Epoch [89/300] Validation [1/16] Loss: 0.82511  focal_loss 0.48745  dice_loss 0.33766 
Epoch [89/300] Validation [2/16] Loss: 0.55881  focal_loss 0.16915  dice_loss 0.38966 
Epoch [89/300] Validation [3/16] Loss: 0.55731  focal_loss 0.21870  dice_loss 0.33861 
Epoch [89/300] Validation [4/16] Loss: 0.49530  focal_loss 0.16163  dice_loss 0.33368 
Epoch [89/300] Validation [5/16] Loss: 0.56801  focal_loss 0.12692  dice_loss 0.44109 
Epoch [89/300] Validation [6/16] Loss: 0.32911  focal_loss 0.06798  dice_loss 0.26113 
Epoch [89/300] Validation [7/16] Loss: 0.38210  focal_loss 0.11979  dice_loss 0.26232 
Epoch [89/300] Validation [8/16] Loss: 0.68975  focal_loss 0.18333  dice_loss 0.50642 
Epoch [89/300] Validation [9/16] Loss: 0.43976  focal_loss 0.14234  dice_loss 0.29742 
Epoch [89/300] Validation [10/16] Loss: 0.69278  focal_loss 0.20528  dice_loss 0.48750 
Epoch [89/300] Validation [11/16] Loss: 0.32309  focal_loss 0.06261  dice_loss 0.26048 
Epoch [89/300] Validation [12/16] Loss: 0.55306  focal_loss 0.07916  dice_loss 0.47390 
Epoch [89/300] Validation [13/16] Loss: 0.47010  focal_loss 0.14598  dice_loss 0.32412 
Epoch [89/300] Validation [14/16] Loss: 0.90773  focal_loss 0.29785  dice_loss 0.60988 
Epoch [89/300] Validation [15/16] Loss: 0.42019  focal_loss 0.13553  dice_loss 0.28466 
Epoch [89/300] Validation [16/16] Loss: 0.32370  focal_loss 0.10147  dice_loss 0.22223 
Epoch [89/300] Validation metric {'Val/mean dice_metric': 0.8122822046279907, 'Val/mean miou_metric': 0.7260646820068359, 'Val/mean f1': 0.8415407538414001, 'Val/mean precision': 0.8531171679496765, 'Val/mean recall': 0.8302742838859558, 'Val/mean hd95_metric': 48.11664962768555}
Cheakpoint...
Epoch [89/300] best acc:tensor([0.8195], device='cuda:0'), Now : mean acc: tensor([0.8123], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8122822046279907, 'Val/mean miou_metric': 0.7260646820068359, 'Val/mean f1': 0.8415407538414001, 'Val/mean precision': 0.8531171679496765, 'Val/mean recall': 0.8302742838859558, 'Val/mean hd95_metric': 48.11664962768555}
Epoch [90/300] Training [1/62] Loss: 0.32498 
Epoch [90/300] Training [2/62] Loss: 0.07210 
Epoch [90/300] Training [3/62] Loss: 0.31993 
Epoch [90/300] Training [4/62] Loss: 0.29702 
Epoch [90/300] Training [5/62] Loss: 0.28858 
Epoch [90/300] Training [6/62] Loss: 0.12746 
Epoch [90/300] Training [7/62] Loss: 0.33173 
Epoch [90/300] Training [8/62] Loss: 0.14800 
Epoch [90/300] Training [9/62] Loss: 0.18862 
Epoch [90/300] Training [10/62] Loss: 0.19230 
Epoch [90/300] Training [11/62] Loss: 0.23293 
Epoch [90/300] Training [12/62] Loss: 0.23485 
Epoch [90/300] Training [13/62] Loss: 0.14644 
Epoch [90/300] Training [14/62] Loss: 0.14992 
Epoch [90/300] Training [15/62] Loss: 0.34363 
Epoch [90/300] Training [16/62] Loss: 0.16790 
Epoch [90/300] Training [17/62] Loss: 0.07260 
Epoch [90/300] Training [18/62] Loss: 0.26710 
Epoch [90/300] Training [19/62] Loss: 0.18336 
Epoch [90/300] Training [20/62] Loss: 0.14414 
Epoch [90/300] Training [21/62] Loss: 0.18626 
Epoch [90/300] Training [22/62] Loss: 0.29574 
Epoch [90/300] Training [23/62] Loss: 0.23371 
Epoch [90/300] Training [24/62] Loss: 0.30178 
Epoch [90/300] Training [25/62] Loss: 0.21194 
Epoch [90/300] Training [26/62] Loss: 0.23398 
Epoch [90/300] Training [27/62] Loss: 0.23773 
Epoch [90/300] Training [28/62] Loss: 0.15574 
Epoch [90/300] Training [29/62] Loss: 0.39440 
Epoch [90/300] Training [30/62] Loss: 0.15586 
Epoch [90/300] Training [31/62] Loss: 0.16569 
Epoch [90/300] Training [32/62] Loss: 0.15915 
Epoch [90/300] Training [33/62] Loss: 0.22632 
Epoch [90/300] Training [34/62] Loss: 0.27090 
Epoch [90/300] Training [35/62] Loss: 0.24768 
Epoch [90/300] Training [36/62] Loss: 0.17287 
Epoch [90/300] Training [37/62] Loss: 0.35068 
Epoch [90/300] Training [38/62] Loss: 0.16755 
Epoch [90/300] Training [39/62] Loss: 0.17874 
Epoch [90/300] Training [40/62] Loss: 0.15499 
Epoch [90/300] Training [41/62] Loss: 0.27878 
Epoch [90/300] Training [42/62] Loss: 0.26990 
Epoch [90/300] Training [43/62] Loss: 0.30466 
Epoch [90/300] Training [44/62] Loss: 0.27867 
Epoch [90/300] Training [45/62] Loss: 0.17670 
Epoch [90/300] Training [46/62] Loss: 0.24243 
Epoch [90/300] Training [47/62] Loss: 0.14120 
Epoch [90/300] Training [48/62] Loss: 0.14095 
Epoch [90/300] Training [49/62] Loss: 0.32797 
Epoch [90/300] Training [50/62] Loss: 0.22346 
Epoch [90/300] Training [51/62] Loss: 0.19047 
Epoch [90/300] Training [52/62] Loss: 0.30679 
Epoch [90/300] Training [53/62] Loss: 0.43294 
Epoch [90/300] Training [54/62] Loss: 0.18664 
Epoch [90/300] Training [55/62] Loss: 0.28715 
Epoch [90/300] Training [56/62] Loss: 0.18432 
Epoch [90/300] Training [57/62] Loss: 0.20834 
Epoch [90/300] Training [58/62] Loss: 0.20130 
Epoch [90/300] Training [59/62] Loss: 0.27875 
Epoch [90/300] Training [60/62] Loss: 0.21881 
Epoch [90/300] Training [61/62] Loss: 0.31316 
Epoch [90/300] Training [62/62] Loss: 0.07518 
Epoch [90/300] Training metric {'Train/mean dice_metric': 0.8465979695320129, 'Train/mean miou_metric': 0.7646555304527283, 'Train/mean f1': 0.8734501004219055, 'Train/mean precision': 0.8898294568061829, 'Train/mean recall': 0.8576627969741821, 'Train/mean hd95_metric': 42.322933197021484}
Epoch [90/300] Validation [1/16] Loss: 0.59572  focal_loss 0.29732  dice_loss 0.29840 
Epoch [90/300] Validation [2/16] Loss: 0.54942  focal_loss 0.13195  dice_loss 0.41747 
Epoch [90/300] Validation [3/16] Loss: 0.63893  focal_loss 0.23262  dice_loss 0.40632 
Epoch [90/300] Validation [4/16] Loss: 0.47624  focal_loss 0.17911  dice_loss 0.29712 
Epoch [90/300] Validation [5/16] Loss: 0.44376  focal_loss 0.11093  dice_loss 0.33283 
Epoch [90/300] Validation [6/16] Loss: 0.41690  focal_loss 0.10146  dice_loss 0.31544 
Epoch [90/300] Validation [7/16] Loss: 0.23894  focal_loss 0.07109  dice_loss 0.16785 
Epoch [90/300] Validation [8/16] Loss: 0.73631  focal_loss 0.19086  dice_loss 0.54545 
Epoch [90/300] Validation [9/16] Loss: 0.47641  focal_loss 0.17155  dice_loss 0.30486 
Epoch [90/300] Validation [10/16] Loss: 0.72506  focal_loss 0.20241  dice_loss 0.52265 
Epoch [90/300] Validation [11/16] Loss: 0.28277  focal_loss 0.08130  dice_loss 0.20147 
Epoch [90/300] Validation [12/16] Loss: 0.36938  focal_loss 0.06745  dice_loss 0.30194 
Epoch [90/300] Validation [13/16] Loss: 0.28685  focal_loss 0.06300  dice_loss 0.22385 
Epoch [90/300] Validation [14/16] Loss: 0.56487  focal_loss 0.14966  dice_loss 0.41521 
Epoch [90/300] Validation [15/16] Loss: 0.18073  focal_loss 0.03332  dice_loss 0.14741 
Epoch [90/300] Validation [16/16] Loss: 0.14918  focal_loss 0.04242  dice_loss 0.10676 
Epoch [90/300] Validation metric {'Val/mean dice_metric': 0.8171457648277283, 'Val/mean miou_metric': 0.7307019829750061, 'Val/mean f1': 0.8467130064964294, 'Val/mean precision': 0.8522378206253052, 'Val/mean recall': 0.8412593603134155, 'Val/mean hd95_metric': 48.45048904418945}
Cheakpoint...
Epoch [90/300] best acc:tensor([0.8195], device='cuda:0'), Now : mean acc: tensor([0.8171], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8171457648277283, 'Val/mean miou_metric': 0.7307019829750061, 'Val/mean f1': 0.8467130064964294, 'Val/mean precision': 0.8522378206253052, 'Val/mean recall': 0.8412593603134155, 'Val/mean hd95_metric': 48.45048904418945}
Epoch [91/300] Training [1/62] Loss: 0.37876 
Epoch [91/300] Training [2/62] Loss: 0.21069 
Epoch [91/300] Training [3/62] Loss: 0.27242 
Epoch [91/300] Training [4/62] Loss: 0.13292 
Epoch [91/300] Training [5/62] Loss: 0.23131 
Epoch [91/300] Training [6/62] Loss: 0.24743 
Epoch [91/300] Training [7/62] Loss: 0.30944 
Epoch [91/300] Training [8/62] Loss: 0.22113 
Epoch [91/300] Training [9/62] Loss: 0.12258 
Epoch [91/300] Training [10/62] Loss: 0.22746 
Epoch [91/300] Training [11/62] Loss: 0.13412 
Epoch [91/300] Training [12/62] Loss: 0.19780 
Epoch [91/300] Training [13/62] Loss: 0.26826 
Epoch [91/300] Training [14/62] Loss: 0.24477 
Epoch [91/300] Training [15/62] Loss: 0.19216 
Epoch [91/300] Training [16/62] Loss: 0.12138 
Epoch [91/300] Training [17/62] Loss: 0.13920 
Epoch [91/300] Training [18/62] Loss: 0.23263 
Epoch [91/300] Training [19/62] Loss: 0.28419 
Epoch [91/300] Training [20/62] Loss: 0.28014 
Epoch [91/300] Training [21/62] Loss: 0.17072 
Epoch [91/300] Training [22/62] Loss: 0.13877 
Epoch [91/300] Training [23/62] Loss: 0.19278 
Epoch [91/300] Training [24/62] Loss: 0.17267 
Epoch [91/300] Training [25/62] Loss: 0.28530 
Epoch [91/300] Training [26/62] Loss: 0.16285 
Epoch [91/300] Training [27/62] Loss: 0.54119 
Epoch [91/300] Training [28/62] Loss: 0.36897 
Epoch [91/300] Training [29/62] Loss: 0.38666 
Epoch [91/300] Training [30/62] Loss: 0.19703 
Epoch [91/300] Training [31/62] Loss: 0.15943 
Epoch [91/300] Training [32/62] Loss: 0.28630 
Epoch [91/300] Training [33/62] Loss: 0.25515 
Epoch [91/300] Training [34/62] Loss: 0.28266 
Epoch [91/300] Training [35/62] Loss: 0.31343 
Epoch [91/300] Training [36/62] Loss: 0.23253 
Epoch [91/300] Training [37/62] Loss: 0.20171 
Epoch [91/300] Training [38/62] Loss: 0.21044 
Epoch [91/300] Training [39/62] Loss: 0.09979 
Epoch [91/300] Training [40/62] Loss: 0.23432 
Epoch [91/300] Training [41/62] Loss: 0.11394 
Epoch [91/300] Training [42/62] Loss: 0.43290 
Epoch [91/300] Training [43/62] Loss: 0.35071 
Epoch [91/300] Training [44/62] Loss: 0.27350 
Epoch [91/300] Training [45/62] Loss: 0.18316 
Epoch [91/300] Training [46/62] Loss: 0.15560 
Epoch [91/300] Training [47/62] Loss: 0.21116 
Epoch [91/300] Training [48/62] Loss: 0.18531 
Epoch [91/300] Training [49/62] Loss: 0.21629 
Epoch [91/300] Training [50/62] Loss: 0.30365 
Epoch [91/300] Training [51/62] Loss: 0.34412 
Epoch [91/300] Training [52/62] Loss: 0.33591 
Epoch [91/300] Training [53/62] Loss: 0.17451 
Epoch [91/300] Training [54/62] Loss: 0.21217 
Epoch [91/300] Training [55/62] Loss: 0.11711 
Epoch [91/300] Training [56/62] Loss: 0.42596 
Epoch [91/300] Training [57/62] Loss: 0.22585 
Epoch [91/300] Training [58/62] Loss: 0.33324 
Epoch [91/300] Training [59/62] Loss: 0.20978 
Epoch [91/300] Training [60/62] Loss: 0.13021 
Epoch [91/300] Training [61/62] Loss: 0.30527 
Epoch [91/300] Training [62/62] Loss: 0.16279 
Epoch [91/300] Training metric {'Train/mean dice_metric': 0.841637372970581, 'Train/mean miou_metric': 0.760007381439209, 'Train/mean f1': 0.8652596473693848, 'Train/mean precision': 0.8738611340522766, 'Train/mean recall': 0.8568258881568909, 'Train/mean hd95_metric': 42.27659225463867}
Epoch [91/300] Validation [1/16] Loss: 0.60847  focal_loss 0.28512  dice_loss 0.32335 
Epoch [91/300] Validation [2/16] Loss: 0.51990  focal_loss 0.11798  dice_loss 0.40192 
Epoch [91/300] Validation [3/16] Loss: 0.69217  focal_loss 0.29702  dice_loss 0.39515 
Epoch [91/300] Validation [4/16] Loss: 0.40732  focal_loss 0.12323  dice_loss 0.28409 
Epoch [91/300] Validation [5/16] Loss: 0.46607  focal_loss 0.12146  dice_loss 0.34461 
Epoch [91/300] Validation [6/16] Loss: 0.38087  focal_loss 0.08600  dice_loss 0.29487 
Epoch [91/300] Validation [7/16] Loss: 0.42484  focal_loss 0.14463  dice_loss 0.28021 
Epoch [91/300] Validation [8/16] Loss: 0.50545  focal_loss 0.12080  dice_loss 0.38466 
Epoch [91/300] Validation [9/16] Loss: 0.56723  focal_loss 0.19523  dice_loss 0.37199 
Epoch [91/300] Validation [10/16] Loss: 0.70043  focal_loss 0.19866  dice_loss 0.50176 
Epoch [91/300] Validation [11/16] Loss: 0.44900  focal_loss 0.13437  dice_loss 0.31462 
Epoch [91/300] Validation [12/16] Loss: 0.52787  focal_loss 0.10691  dice_loss 0.42096 
Epoch [91/300] Validation [13/16] Loss: 0.34427  focal_loss 0.08944  dice_loss 0.25483 
Epoch [91/300] Validation [14/16] Loss: 0.63226  focal_loss 0.15236  dice_loss 0.47990 
Epoch [91/300] Validation [15/16] Loss: 0.33191  focal_loss 0.10684  dice_loss 0.22507 
Epoch [91/300] Validation [16/16] Loss: 0.24182  focal_loss 0.06129  dice_loss 0.18052 
Epoch [91/300] Validation metric {'Val/mean dice_metric': 0.8081774115562439, 'Val/mean miou_metric': 0.7188112735748291, 'Val/mean f1': 0.8324375748634338, 'Val/mean precision': 0.8301311731338501, 'Val/mean recall': 0.8347568511962891, 'Val/mean hd95_metric': 49.889625549316406}
Cheakpoint...
Epoch [91/300] best acc:tensor([0.8195], device='cuda:0'), Now : mean acc: tensor([0.8082], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8081774115562439, 'Val/mean miou_metric': 0.7188112735748291, 'Val/mean f1': 0.8324375748634338, 'Val/mean precision': 0.8301311731338501, 'Val/mean recall': 0.8347568511962891, 'Val/mean hd95_metric': 49.889625549316406}
Epoch [92/300] Training [1/62] Loss: 0.32764 
Epoch [92/300] Training [2/62] Loss: 0.15991 
Epoch [92/300] Training [3/62] Loss: 0.11917 
Epoch [92/300] Training [4/62] Loss: 0.21712 
Epoch [92/300] Training [5/62] Loss: 0.18225 
Epoch [92/300] Training [6/62] Loss: 0.13284 
Epoch [92/300] Training [7/62] Loss: 0.33109 
Epoch [92/300] Training [8/62] Loss: 0.28594 
Epoch [92/300] Training [9/62] Loss: 0.09227 
Epoch [92/300] Training [10/62] Loss: 0.11735 
Epoch [92/300] Training [11/62] Loss: 0.19236 
Epoch [92/300] Training [12/62] Loss: 0.29937 
Epoch [92/300] Training [13/62] Loss: 0.23153 
Epoch [92/300] Training [14/62] Loss: 0.19629 
Epoch [92/300] Training [15/62] Loss: 0.30263 
Epoch [92/300] Training [16/62] Loss: 0.20630 
Epoch [92/300] Training [17/62] Loss: 0.19524 
Epoch [92/300] Training [18/62] Loss: 0.21430 
Epoch [92/300] Training [19/62] Loss: 0.14836 
Epoch [92/300] Training [20/62] Loss: 0.11093 
Epoch [92/300] Training [21/62] Loss: 0.17909 
Epoch [92/300] Training [22/62] Loss: 0.24329 
Epoch [92/300] Training [23/62] Loss: 0.36636 
Epoch [92/300] Training [24/62] Loss: 0.40029 
Epoch [92/300] Training [25/62] Loss: 0.20804 
Epoch [92/300] Training [26/62] Loss: 0.19211 
Epoch [92/300] Training [27/62] Loss: 0.25008 
Epoch [92/300] Training [28/62] Loss: 0.23316 
Epoch [92/300] Training [29/62] Loss: 0.21559 
Epoch [92/300] Training [30/62] Loss: 0.10185 
Epoch [92/300] Training [31/62] Loss: 0.22709 
Epoch [92/300] Training [32/62] Loss: 0.37171 
Epoch [92/300] Training [33/62] Loss: 0.45414 
Epoch [92/300] Training [34/62] Loss: 0.24301 
Epoch [92/300] Training [35/62] Loss: 0.29366 
Epoch [92/300] Training [36/62] Loss: 0.21306 
Epoch [92/300] Training [37/62] Loss: 0.31964 
Epoch [92/300] Training [38/62] Loss: 0.18260 
Epoch [92/300] Training [39/62] Loss: 0.10816 
Epoch [92/300] Training [40/62] Loss: 0.23385 
Epoch [92/300] Training [41/62] Loss: 0.23260 
Epoch [92/300] Training [42/62] Loss: 0.31892 
Epoch [92/300] Training [43/62] Loss: 0.12265 
Epoch [92/300] Training [44/62] Loss: 0.32473 
Epoch [92/300] Training [45/62] Loss: 0.31675 
Epoch [92/300] Training [46/62] Loss: 0.24565 
Epoch [92/300] Training [47/62] Loss: 0.23272 
Epoch [92/300] Training [48/62] Loss: 0.19711 
Epoch [92/300] Training [49/62] Loss: 0.17953 
Epoch [92/300] Training [50/62] Loss: 0.13566 
Epoch [92/300] Training [51/62] Loss: 0.11677 
Epoch [92/300] Training [52/62] Loss: 0.56283 
Epoch [92/300] Training [53/62] Loss: 0.14628 
Epoch [92/300] Training [54/62] Loss: 0.16318 
Epoch [92/300] Training [55/62] Loss: 0.26246 
Epoch [92/300] Training [56/62] Loss: 0.30449 
Epoch [92/300] Training [57/62] Loss: 0.19013 
Epoch [92/300] Training [58/62] Loss: 0.29790 
Epoch [92/300] Training [59/62] Loss: 0.16659 
Epoch [92/300] Training [60/62] Loss: 0.14076 
Epoch [92/300] Training [61/62] Loss: 0.26924 
Epoch [92/300] Training [62/62] Loss: 3.03808 
Epoch [92/300] Training metric {'Train/mean dice_metric': 0.8434000015258789, 'Train/mean miou_metric': 0.7631871104240417, 'Train/mean f1': 0.8675559163093567, 'Train/mean precision': 0.8761425018310547, 'Train/mean recall': 0.8591359257698059, 'Train/mean hd95_metric': 43.458614349365234}
Epoch [92/300] Validation [1/16] Loss: 0.64846  focal_loss 0.33796  dice_loss 0.31049 
Epoch [92/300] Validation [2/16] Loss: 0.48381  focal_loss 0.11097  dice_loss 0.37284 
Epoch [92/300] Validation [3/16] Loss: 0.72981  focal_loss 0.32846  dice_loss 0.40135 
Epoch [92/300] Validation [4/16] Loss: 0.43542  focal_loss 0.16416  dice_loss 0.27126 
Epoch [92/300] Validation [5/16] Loss: 0.41621  focal_loss 0.11264  dice_loss 0.30358 
Epoch [92/300] Validation [6/16] Loss: 0.50640  focal_loss 0.12926  dice_loss 0.37714 
Epoch [92/300] Validation [7/16] Loss: 0.50421  focal_loss 0.16278  dice_loss 0.34144 
Epoch [92/300] Validation [8/16] Loss: 0.60341  focal_loss 0.15304  dice_loss 0.45037 
Epoch [92/300] Validation [9/16] Loss: 0.42003  focal_loss 0.14415  dice_loss 0.27588 
Epoch [92/300] Validation [10/16] Loss: 0.60967  focal_loss 0.16069  dice_loss 0.44898 
Epoch [92/300] Validation [11/16] Loss: 0.22761  focal_loss 0.05993  dice_loss 0.16767 
Epoch [92/300] Validation [12/16] Loss: 0.49773  focal_loss 0.08165  dice_loss 0.41608 
Epoch [92/300] Validation [13/16] Loss: 0.33602  focal_loss 0.10030  dice_loss 0.23573 
Epoch [92/300] Validation [14/16] Loss: 0.68222  focal_loss 0.22363  dice_loss 0.45860 
Epoch [92/300] Validation [15/16] Loss: 0.47078  focal_loss 0.19576  dice_loss 0.27502 
Epoch [92/300] Validation [16/16] Loss: 0.15868  focal_loss 0.04456  dice_loss 0.11412 
Epoch [92/300] Validation metric {'Val/mean dice_metric': 0.8109328150749207, 'Val/mean miou_metric': 0.7265462279319763, 'Val/mean f1': 0.8433030247688293, 'Val/mean precision': 0.8723770976066589, 'Val/mean recall': 0.8161042928695679, 'Val/mean hd95_metric': 47.89878463745117}
Cheakpoint...
Epoch [92/300] best acc:tensor([0.8195], device='cuda:0'), Now : mean acc: tensor([0.8109], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8109328150749207, 'Val/mean miou_metric': 0.7265462279319763, 'Val/mean f1': 0.8433030247688293, 'Val/mean precision': 0.8723770976066589, 'Val/mean recall': 0.8161042928695679, 'Val/mean hd95_metric': 47.89878463745117}
Epoch [93/300] Training [1/62] Loss: 0.16843 
Epoch [93/300] Training [2/62] Loss: 0.32953 
Epoch [93/300] Training [3/62] Loss: 0.26016 
Epoch [93/300] Training [4/62] Loss: 0.28385 
Epoch [93/300] Training [5/62] Loss: 0.33167 
Epoch [93/300] Training [6/62] Loss: 0.16675 
Epoch [93/300] Training [7/62] Loss: 0.28162 
Epoch [93/300] Training [8/62] Loss: 0.31992 
Epoch [93/300] Training [9/62] Loss: 0.24531 
Epoch [93/300] Training [10/62] Loss: 0.28001 
Epoch [93/300] Training [11/62] Loss: 0.18586 
Epoch [93/300] Training [12/62] Loss: 0.35498 
Epoch [93/300] Training [13/62] Loss: 0.21868 
Epoch [93/300] Training [14/62] Loss: 0.09424 
Epoch [93/300] Training [15/62] Loss: 0.25999 
Epoch [93/300] Training [16/62] Loss: 0.22894 
Epoch [93/300] Training [17/62] Loss: 0.14646 
Epoch [93/300] Training [18/62] Loss: 0.18869 
Epoch [93/300] Training [19/62] Loss: 0.28185 
Epoch [93/300] Training [20/62] Loss: 0.18863 
Epoch [93/300] Training [21/62] Loss: 0.19861 
Epoch [93/300] Training [22/62] Loss: 0.30125 
Epoch [93/300] Training [23/62] Loss: 0.29413 
Epoch [93/300] Training [24/62] Loss: 0.13812 
Epoch [93/300] Training [25/62] Loss: 0.27325 
Epoch [93/300] Training [26/62] Loss: 0.15483 
Epoch [93/300] Training [27/62] Loss: 0.31776 
Epoch [93/300] Training [28/62] Loss: 0.25378 
Epoch [93/300] Training [29/62] Loss: 0.25993 
Epoch [93/300] Training [30/62] Loss: 0.14938 
Epoch [93/300] Training [31/62] Loss: 0.28584 
Epoch [93/300] Training [32/62] Loss: 0.19187 
Epoch [93/300] Training [33/62] Loss: 0.16437 
Epoch [93/300] Training [34/62] Loss: 0.20102 
Epoch [93/300] Training [35/62] Loss: 0.32659 
Epoch [93/300] Training [36/62] Loss: 0.22822 
Epoch [93/300] Training [37/62] Loss: 0.33150 
Epoch [93/300] Training [38/62] Loss: 0.12731 
Epoch [93/300] Training [39/62] Loss: 0.19364 
Epoch [93/300] Training [40/62] Loss: 0.13820 
Epoch [93/300] Training [41/62] Loss: 0.40449 
Epoch [93/300] Training [42/62] Loss: 0.25138 
Epoch [93/300] Training [43/62] Loss: 0.14514 
Epoch [93/300] Training [44/62] Loss: 0.19281 
Epoch [93/300] Training [45/62] Loss: 0.22748 
Epoch [93/300] Training [46/62] Loss: 0.14222 
Epoch [93/300] Training [47/62] Loss: 0.11148 
Epoch [93/300] Training [48/62] Loss: 0.25738 
Epoch [93/300] Training [49/62] Loss: 0.43403 
Epoch [93/300] Training [50/62] Loss: 0.22293 
Epoch [93/300] Training [51/62] Loss: 0.10147 
Epoch [93/300] Training [52/62] Loss: 0.13855 
Epoch [93/300] Training [53/62] Loss: 0.12510 
Epoch [93/300] Training [54/62] Loss: 0.20059 
Epoch [93/300] Training [55/62] Loss: 0.25160 
Epoch [93/300] Training [56/62] Loss: 0.21941 
Epoch [93/300] Training [57/62] Loss: 0.19945 
Epoch [93/300] Training [58/62] Loss: 0.27448 
Epoch [93/300] Training [59/62] Loss: 0.22145 
Epoch [93/300] Training [60/62] Loss: 0.18641 
Epoch [93/300] Training [61/62] Loss: 0.17558 
Epoch [93/300] Training [62/62] Loss: 0.12056 
Epoch [93/300] Training metric {'Train/mean dice_metric': 0.8488342761993408, 'Train/mean miou_metric': 0.7684911489486694, 'Train/mean f1': 0.8728571534156799, 'Train/mean precision': 0.8783203363418579, 'Train/mean recall': 0.8674613237380981, 'Train/mean hd95_metric': 42.5120735168457}
Epoch [93/300] Validation [1/16] Loss: 0.75629  focal_loss 0.39821  dice_loss 0.35808 
Epoch [93/300] Validation [2/16] Loss: 0.52383  focal_loss 0.15057  dice_loss 0.37326 
Epoch [93/300] Validation [3/16] Loss: 0.70228  focal_loss 0.31436  dice_loss 0.38792 
Epoch [93/300] Validation [4/16] Loss: 0.34564  focal_loss 0.12094  dice_loss 0.22470 
Epoch [93/300] Validation [5/16] Loss: 0.46114  focal_loss 0.10700  dice_loss 0.35414 
Epoch [93/300] Validation [6/16] Loss: 0.39360  focal_loss 0.09711  dice_loss 0.29648 
Epoch [93/300] Validation [7/16] Loss: 0.46062  focal_loss 0.13739  dice_loss 0.32323 
Epoch [93/300] Validation [8/16] Loss: 0.52679  focal_loss 0.15354  dice_loss 0.37325 
Epoch [93/300] Validation [9/16] Loss: 0.51204  focal_loss 0.18608  dice_loss 0.32596 
Epoch [93/300] Validation [10/16] Loss: 0.42845  focal_loss 0.08562  dice_loss 0.34283 
Epoch [93/300] Validation [11/16] Loss: 0.28902  focal_loss 0.08441  dice_loss 0.20462 
Epoch [93/300] Validation [12/16] Loss: 0.46506  focal_loss 0.07424  dice_loss 0.39082 
Epoch [93/300] Validation [13/16] Loss: 0.34037  focal_loss 0.10659  dice_loss 0.23378 
Epoch [93/300] Validation [14/16] Loss: 0.52051  focal_loss 0.15640  dice_loss 0.36411 
Epoch [93/300] Validation [15/16] Loss: 0.28190  focal_loss 0.08966  dice_loss 0.19224 
Epoch [93/300] Validation [16/16] Loss: 0.20996  focal_loss 0.07845  dice_loss 0.13150 
Epoch [93/300] Validation metric {'Val/mean dice_metric': 0.8198823928833008, 'Val/mean miou_metric': 0.7359095811843872, 'Val/mean f1': 0.8493311405181885, 'Val/mean precision': 0.8698799014091492, 'Val/mean recall': 0.8297309279441833, 'Val/mean hd95_metric': 46.25802993774414}
Cheakpoint...
Epoch [93/300] best acc:tensor([0.8199], device='cuda:0'), Now : mean acc: tensor([0.8199], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8198823928833008, 'Val/mean miou_metric': 0.7359095811843872, 'Val/mean f1': 0.8493311405181885, 'Val/mean precision': 0.8698799014091492, 'Val/mean recall': 0.8297309279441833, 'Val/mean hd95_metric': 46.25802993774414}
Epoch [94/300] Training [1/62] Loss: 0.23454 
Epoch [94/300] Training [2/62] Loss: 0.32404 
Epoch [94/300] Training [3/62] Loss: 0.17970 
Epoch [94/300] Training [4/62] Loss: 0.22398 
Epoch [94/300] Training [5/62] Loss: 0.24264 
Epoch [94/300] Training [6/62] Loss: 0.23138 
Epoch [94/300] Training [7/62] Loss: 0.09671 
Epoch [94/300] Training [8/62] Loss: 0.14681 
Epoch [94/300] Training [9/62] Loss: 0.09495 
Epoch [94/300] Training [10/62] Loss: 0.22050 
Epoch [94/300] Training [11/62] Loss: 0.26926 
Epoch [94/300] Training [12/62] Loss: 0.12962 
Epoch [94/300] Training [13/62] Loss: 0.24997 
Epoch [94/300] Training [14/62] Loss: 0.23282 
Epoch [94/300] Training [15/62] Loss: 0.14602 
Epoch [94/300] Training [16/62] Loss: 0.31164 
Epoch [94/300] Training [17/62] Loss: 0.17705 
Epoch [94/300] Training [18/62] Loss: 0.13012 
Epoch [94/300] Training [19/62] Loss: 0.15578 
Epoch [94/300] Training [20/62] Loss: 0.17748 
Epoch [94/300] Training [21/62] Loss: 0.21228 
Epoch [94/300] Training [22/62] Loss: 0.16943 
Epoch [94/300] Training [23/62] Loss: 0.15385 
Epoch [94/300] Training [24/62] Loss: 0.10460 
Epoch [94/300] Training [25/62] Loss: 0.11738 
Epoch [94/300] Training [26/62] Loss: 0.20019 
Epoch [94/300] Training [27/62] Loss: 0.20164 
Epoch [94/300] Training [28/62] Loss: 0.20284 
Epoch [94/300] Training [29/62] Loss: 0.25426 
Epoch [94/300] Training [30/62] Loss: 0.22466 
Epoch [94/300] Training [31/62] Loss: 0.24342 
Epoch [94/300] Training [32/62] Loss: 0.07248 
Epoch [94/300] Training [33/62] Loss: 0.08094 
Epoch [94/300] Training [34/62] Loss: 0.25082 
Epoch [94/300] Training [35/62] Loss: 0.23944 
Epoch [94/300] Training [36/62] Loss: 0.31742 
Epoch [94/300] Training [37/62] Loss: 0.12875 
Epoch [94/300] Training [38/62] Loss: 0.19951 
Epoch [94/300] Training [39/62] Loss: 0.21394 
Epoch [94/300] Training [40/62] Loss: 0.23412 
Epoch [94/300] Training [41/62] Loss: 0.12778 
Epoch [94/300] Training [42/62] Loss: 0.23987 
Epoch [94/300] Training [43/62] Loss: 0.17159 
Epoch [94/300] Training [44/62] Loss: 0.32830 
Epoch [94/300] Training [45/62] Loss: 0.24719 
Epoch [94/300] Training [46/62] Loss: 0.14442 
Epoch [94/300] Training [47/62] Loss: 0.18485 
Epoch [94/300] Training [48/62] Loss: 0.18972 
Epoch [94/300] Training [49/62] Loss: 0.21301 
Epoch [94/300] Training [50/62] Loss: 0.40279 
Epoch [94/300] Training [51/62] Loss: 0.13253 
Epoch [94/300] Training [52/62] Loss: 0.10758 
Epoch [94/300] Training [53/62] Loss: 0.22901 
Epoch [94/300] Training [54/62] Loss: 0.25235 
Epoch [94/300] Training [55/62] Loss: 0.28683 
Epoch [94/300] Training [56/62] Loss: 0.25532 
Epoch [94/300] Training [57/62] Loss: 0.23368 
Epoch [94/300] Training [58/62] Loss: 0.53716 
Epoch [94/300] Training [59/62] Loss: 0.18653 
Epoch [94/300] Training [60/62] Loss: 0.27804 
Epoch [94/300] Training [61/62] Loss: 0.23413 
Epoch [94/300] Training [62/62] Loss: 0.08226 
Epoch [94/300] Training metric {'Train/mean dice_metric': 0.860051691532135, 'Train/mean miou_metric': 0.7832584381103516, 'Train/mean f1': 0.8850038051605225, 'Train/mean precision': 0.8971240520477295, 'Train/mean recall': 0.8732066750526428, 'Train/mean hd95_metric': 40.69407272338867}
Epoch [94/300] Validation [1/16] Loss: 0.60713  focal_loss 0.33359  dice_loss 0.27354 
Epoch [94/300] Validation [2/16] Loss: 0.58670  focal_loss 0.15964  dice_loss 0.42705 
Epoch [94/300] Validation [3/16] Loss: 0.61603  focal_loss 0.25070  dice_loss 0.36533 
Epoch [94/300] Validation [4/16] Loss: 0.38398  focal_loss 0.12858  dice_loss 0.25539 
Epoch [94/300] Validation [5/16] Loss: 0.39136  focal_loss 0.08137  dice_loss 0.30998 
Epoch [94/300] Validation [6/16] Loss: 0.30562  focal_loss 0.05851  dice_loss 0.24711 
Epoch [94/300] Validation [7/16] Loss: 0.25740  focal_loss 0.07659  dice_loss 0.18081 
Epoch [94/300] Validation [8/16] Loss: 0.56494  focal_loss 0.16167  dice_loss 0.40328 
Epoch [94/300] Validation [9/16] Loss: 0.34722  focal_loss 0.09098  dice_loss 0.25625 
Epoch [94/300] Validation [10/16] Loss: 0.60051  focal_loss 0.15255  dice_loss 0.44796 
Epoch [94/300] Validation [11/16] Loss: 0.23896  focal_loss 0.04072  dice_loss 0.19823 
Epoch [94/300] Validation [12/16] Loss: 0.36543  focal_loss 0.06613  dice_loss 0.29930 
Epoch [94/300] Validation [13/16] Loss: 0.21993  focal_loss 0.04138  dice_loss 0.17855 
Epoch [94/300] Validation [14/16] Loss: 0.53450  focal_loss 0.14518  dice_loss 0.38932 
Epoch [94/300] Validation [15/16] Loss: 0.25539  focal_loss 0.06465  dice_loss 0.19074 
Epoch [94/300] Validation [16/16] Loss: 0.20347  focal_loss 0.05394  dice_loss 0.14953 
Epoch [94/300] Validation metric {'Val/mean dice_metric': 0.8336315155029297, 'Val/mean miou_metric': 0.7531339526176453, 'Val/mean f1': 0.8630686402320862, 'Val/mean precision': 0.8811993598937988, 'Val/mean recall': 0.845669150352478, 'Val/mean hd95_metric': 46.21354675292969}
Cheakpoint...
Epoch [94/300] best acc:tensor([0.8336], device='cuda:0'), Now : mean acc: tensor([0.8336], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8336315155029297, 'Val/mean miou_metric': 0.7531339526176453, 'Val/mean f1': 0.8630686402320862, 'Val/mean precision': 0.8811993598937988, 'Val/mean recall': 0.845669150352478, 'Val/mean hd95_metric': 46.21354675292969}
Epoch [95/300] Training [1/62] Loss: 0.16980 
Epoch [95/300] Training [2/62] Loss: 0.17292 
Epoch [95/300] Training [3/62] Loss: 0.23701 
Epoch [95/300] Training [4/62] Loss: 0.30782 
Epoch [95/300] Training [5/62] Loss: 0.09878 
Epoch [95/300] Training [6/62] Loss: 0.26625 
Epoch [95/300] Training [7/62] Loss: 0.18158 
Epoch [95/300] Training [8/62] Loss: 0.12427 
Epoch [95/300] Training [9/62] Loss: 0.11918 
Epoch [95/300] Training [10/62] Loss: 0.15132 
Epoch [95/300] Training [11/62] Loss: 0.09960 
Epoch [95/300] Training [12/62] Loss: 0.22324 
Epoch [95/300] Training [13/62] Loss: 0.19078 
Epoch [95/300] Training [14/62] Loss: 0.27103 
Epoch [95/300] Training [15/62] Loss: 0.22549 
Epoch [95/300] Training [16/62] Loss: 0.25991 
Epoch [95/300] Training [17/62] Loss: 0.15405 
Epoch [95/300] Training [18/62] Loss: 0.24035 
Epoch [95/300] Training [19/62] Loss: 0.23465 
Epoch [95/300] Training [20/62] Loss: 0.14786 
Epoch [95/300] Training [21/62] Loss: 0.18713 
Epoch [95/300] Training [22/62] Loss: 0.12525 
Epoch [95/300] Training [23/62] Loss: 0.31596 
Epoch [95/300] Training [24/62] Loss: 0.24013 
Epoch [95/300] Training [25/62] Loss: 0.22445 
Epoch [95/300] Training [26/62] Loss: 0.24930 
Epoch [95/300] Training [27/62] Loss: 0.23208 
Epoch [95/300] Training [28/62] Loss: 0.10026 
Epoch [95/300] Training [29/62] Loss: 0.41409 
Epoch [95/300] Training [30/62] Loss: 0.29264 
Epoch [95/300] Training [31/62] Loss: 0.11408 
Epoch [95/300] Training [32/62] Loss: 0.18464 
Epoch [95/300] Training [33/62] Loss: 0.15382 
Epoch [95/300] Training [34/62] Loss: 0.43782 
Epoch [95/300] Training [35/62] Loss: 0.20649 
Epoch [95/300] Training [36/62] Loss: 0.23135 
Epoch [95/300] Training [37/62] Loss: 0.20604 
Epoch [95/300] Training [38/62] Loss: 0.18944 
Epoch [95/300] Training [39/62] Loss: 0.24655 
Epoch [95/300] Training [40/62] Loss: 0.22767 
Epoch [95/300] Training [41/62] Loss: 0.27283 
Epoch [95/300] Training [42/62] Loss: 0.27214 
Epoch [95/300] Training [43/62] Loss: 0.20282 
Epoch [95/300] Training [44/62] Loss: 0.11552 
Epoch [95/300] Training [45/62] Loss: 0.24414 
Epoch [95/300] Training [46/62] Loss: 0.17330 
Epoch [95/300] Training [47/62] Loss: 0.15041 
Epoch [95/300] Training [48/62] Loss: 0.14423 
Epoch [95/300] Training [49/62] Loss: 0.20951 
Epoch [95/300] Training [50/62] Loss: 0.18903 
Epoch [95/300] Training [51/62] Loss: 0.15793 
Epoch [95/300] Training [52/62] Loss: 0.14017 
Epoch [95/300] Training [53/62] Loss: 0.25997 
Epoch [95/300] Training [54/62] Loss: 0.25274 
Epoch [95/300] Training [55/62] Loss: 0.17282 
Epoch [95/300] Training [56/62] Loss: 0.14269 
Epoch [95/300] Training [57/62] Loss: 0.12576 
Epoch [95/300] Training [58/62] Loss: 0.16809 
Epoch [95/300] Training [59/62] Loss: 0.26905 
Epoch [95/300] Training [60/62] Loss: 0.23206 
Epoch [95/300] Training [61/62] Loss: 0.08974 
Epoch [95/300] Training [62/62] Loss: 0.13016 
Epoch [95/300] Training metric {'Train/mean dice_metric': 0.8645510077476501, 'Train/mean miou_metric': 0.7868954539299011, 'Train/mean f1': 0.8869284391403198, 'Train/mean precision': 0.8969078063964844, 'Train/mean recall': 0.877168595790863, 'Train/mean hd95_metric': 38.02304458618164}
Epoch [95/300] Validation [1/16] Loss: 0.62984  focal_loss 0.33301  dice_loss 0.29683 
Epoch [95/300] Validation [2/16] Loss: 0.51716  focal_loss 0.14561  dice_loss 0.37155 
Epoch [95/300] Validation [3/16] Loss: 0.48159  focal_loss 0.20801  dice_loss 0.27358 
Epoch [95/300] Validation [4/16] Loss: 0.38993  focal_loss 0.14598  dice_loss 0.24394 
Epoch [95/300] Validation [5/16] Loss: 0.40393  focal_loss 0.07615  dice_loss 0.32778 
Epoch [95/300] Validation [6/16] Loss: 0.33004  focal_loss 0.07245  dice_loss 0.25759 
Epoch [95/300] Validation [7/16] Loss: 0.28494  focal_loss 0.08394  dice_loss 0.20100 
Epoch [95/300] Validation [8/16] Loss: 0.50902  focal_loss 0.13349  dice_loss 0.37552 
Epoch [95/300] Validation [9/16] Loss: 0.41664  focal_loss 0.14697  dice_loss 0.26967 
Epoch [95/300] Validation [10/16] Loss: 0.54457  focal_loss 0.14134  dice_loss 0.40323 
Epoch [95/300] Validation [11/16] Loss: 0.18489  focal_loss 0.04458  dice_loss 0.14030 
Epoch [95/300] Validation [12/16] Loss: 0.47366  focal_loss 0.08538  dice_loss 0.38828 
Epoch [95/300] Validation [13/16] Loss: 0.41852  focal_loss 0.10772  dice_loss 0.31080 
Epoch [95/300] Validation [14/16] Loss: 0.51576  focal_loss 0.13179  dice_loss 0.38398 
Epoch [95/300] Validation [15/16] Loss: 0.17147  focal_loss 0.04783  dice_loss 0.12364 
Epoch [95/300] Validation [16/16] Loss: 0.21242  focal_loss 0.05972  dice_loss 0.15269 
Epoch [95/300] Validation metric {'Val/mean dice_metric': 0.8368284702301025, 'Val/mean miou_metric': 0.7552658915519714, 'Val/mean f1': 0.8648431897163391, 'Val/mean precision': 0.889863908290863, 'Val/mean recall': 0.8411909341812134, 'Val/mean hd95_metric': 41.5397834777832}
Cheakpoint...
Epoch [95/300] best acc:tensor([0.8368], device='cuda:0'), Now : mean acc: tensor([0.8368], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8368284702301025, 'Val/mean miou_metric': 0.7552658915519714, 'Val/mean f1': 0.8648431897163391, 'Val/mean precision': 0.889863908290863, 'Val/mean recall': 0.8411909341812134, 'Val/mean hd95_metric': 41.5397834777832}
Epoch [96/300] Training [1/62] Loss: 0.12151 
Epoch [96/300] Training [2/62] Loss: 0.13071 
Epoch [96/300] Training [3/62] Loss: 0.34199 
Epoch [96/300] Training [4/62] Loss: 0.22936 
Epoch [96/300] Training [5/62] Loss: 0.36664 
Epoch [96/300] Training [6/62] Loss: 0.17411 
Epoch [96/300] Training [7/62] Loss: 0.16005 
Epoch [96/300] Training [8/62] Loss: 0.15219 
Epoch [96/300] Training [9/62] Loss: 0.12405 
Epoch [96/300] Training [10/62] Loss: 0.12650 
Epoch [96/300] Training [11/62] Loss: 0.20227 
Epoch [96/300] Training [12/62] Loss: 0.20344 
Epoch [96/300] Training [13/62] Loss: 0.28787 
Epoch [96/300] Training [14/62] Loss: 0.18609 
Epoch [96/300] Training [15/62] Loss: 0.21070 
Epoch [96/300] Training [16/62] Loss: 0.12887 
Epoch [96/300] Training [17/62] Loss: 0.12478 
Epoch [96/300] Training [18/62] Loss: 0.21998 
Epoch [96/300] Training [19/62] Loss: 0.14170 
Epoch [96/300] Training [20/62] Loss: 0.25661 
Epoch [96/300] Training [21/62] Loss: 0.13879 
Epoch [96/300] Training [22/62] Loss: 0.39773 
Epoch [96/300] Training [23/62] Loss: 0.13763 
Epoch [96/300] Training [24/62] Loss: 0.19712 
Epoch [96/300] Training [25/62] Loss: 0.13203 
Epoch [96/300] Training [26/62] Loss: 0.26564 
Epoch [96/300] Training [27/62] Loss: 0.15221 
Epoch [96/300] Training [28/62] Loss: 0.12930 
Epoch [96/300] Training [29/62] Loss: 0.15579 
Epoch [96/300] Training [30/62] Loss: 0.16820 
Epoch [96/300] Training [31/62] Loss: 0.16875 
Epoch [96/300] Training [32/62] Loss: 0.23173 
Epoch [96/300] Training [33/62] Loss: 0.29775 
Epoch [96/300] Training [34/62] Loss: 0.22976 
Epoch [96/300] Training [35/62] Loss: 0.23019 
Epoch [96/300] Training [36/62] Loss: 0.19511 
Epoch [96/300] Training [37/62] Loss: 0.21970 
Epoch [96/300] Training [38/62] Loss: 0.15876 
Epoch [96/300] Training [39/62] Loss: 0.29926 
Epoch [96/300] Training [40/62] Loss: 0.14884 
Epoch [96/300] Training [41/62] Loss: 0.10651 
Epoch [96/300] Training [42/62] Loss: 0.23875 
Epoch [96/300] Training [43/62] Loss: 0.15986 
Epoch [96/300] Training [44/62] Loss: 0.13617 
Epoch [96/300] Training [45/62] Loss: 0.17374 
Epoch [96/300] Training [46/62] Loss: 0.25177 
Epoch [96/300] Training [47/62] Loss: 0.19735 
Epoch [96/300] Training [48/62] Loss: 0.22494 
Epoch [96/300] Training [49/62] Loss: 0.20982 
Epoch [96/300] Training [50/62] Loss: 0.15499 
Epoch [96/300] Training [51/62] Loss: 0.26979 
Epoch [96/300] Training [52/62] Loss: 0.39543 
Epoch [96/300] Training [53/62] Loss: 0.09255 
Epoch [96/300] Training [54/62] Loss: 0.27093 
Epoch [96/300] Training [55/62] Loss: 0.26510 
Epoch [96/300] Training [56/62] Loss: 0.13052 
Epoch [96/300] Training [57/62] Loss: 0.26178 
Epoch [96/300] Training [58/62] Loss: 0.13383 
Epoch [96/300] Training [59/62] Loss: 0.36689 
Epoch [96/300] Training [60/62] Loss: 0.25065 
Epoch [96/300] Training [61/62] Loss: 0.26890 
Epoch [96/300] Training [62/62] Loss: 0.17408 
Epoch [96/300] Training metric {'Train/mean dice_metric': 0.8642650246620178, 'Train/mean miou_metric': 0.789484977722168, 'Train/mean f1': 0.8859609961509705, 'Train/mean precision': 0.8988957405090332, 'Train/mean recall': 0.8733932375907898, 'Train/mean hd95_metric': 36.41132736206055}
Epoch [96/300] Validation [1/16] Loss: 0.57507  focal_loss 0.33556  dice_loss 0.23951 
Epoch [96/300] Validation [2/16] Loss: 0.49555  focal_loss 0.13116  dice_loss 0.36439 
Epoch [96/300] Validation [3/16] Loss: 0.48893  focal_loss 0.21387  dice_loss 0.27506 
Epoch [96/300] Validation [4/16] Loss: 0.44453  focal_loss 0.16271  dice_loss 0.28182 
Epoch [96/300] Validation [5/16] Loss: 0.43010  focal_loss 0.08903  dice_loss 0.34107 
Epoch [96/300] Validation [6/16] Loss: 0.38000  focal_loss 0.09182  dice_loss 0.28818 
Epoch [96/300] Validation [7/16] Loss: 0.21281  focal_loss 0.05809  dice_loss 0.15472 
Epoch [96/300] Validation [8/16] Loss: 0.35083  focal_loss 0.09760  dice_loss 0.25323 
Epoch [96/300] Validation [9/16] Loss: 0.31113  focal_loss 0.10105  dice_loss 0.21008 
Epoch [96/300] Validation [10/16] Loss: 0.76114  focal_loss 0.23081  dice_loss 0.53033 
Epoch [96/300] Validation [11/16] Loss: 0.17839  focal_loss 0.03757  dice_loss 0.14082 
Epoch [96/300] Validation [12/16] Loss: 0.44521  focal_loss 0.05556  dice_loss 0.38965 
Epoch [96/300] Validation [13/16] Loss: 0.31721  focal_loss 0.08468  dice_loss 0.23253 
Epoch [96/300] Validation [14/16] Loss: 0.73977  focal_loss 0.22835  dice_loss 0.51142 
Epoch [96/300] Validation [15/16] Loss: 0.16336  focal_loss 0.04002  dice_loss 0.12334 
Epoch [96/300] Validation [16/16] Loss: 0.13271  focal_loss 0.02624  dice_loss 0.10647 
Epoch [96/300] Validation metric {'Val/mean dice_metric': 0.8374651670455933, 'Val/mean miou_metric': 0.7594117522239685, 'Val/mean f1': 0.864555299282074, 'Val/mean precision': 0.8832719326019287, 'Val/mean recall': 0.8466154932975769, 'Val/mean hd95_metric': 40.846534729003906}
Cheakpoint...
Epoch [96/300] best acc:tensor([0.8375], device='cuda:0'), Now : mean acc: tensor([0.8375], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8374651670455933, 'Val/mean miou_metric': 0.7594117522239685, 'Val/mean f1': 0.864555299282074, 'Val/mean precision': 0.8832719326019287, 'Val/mean recall': 0.8466154932975769, 'Val/mean hd95_metric': 40.846534729003906}
Epoch [97/300] Training [1/62] Loss: 0.17211 
Epoch [97/300] Training [2/62] Loss: 0.24049 
Epoch [97/300] Training [3/62] Loss: 0.25416 
Epoch [97/300] Training [4/62] Loss: 0.29764 
Epoch [97/300] Training [5/62] Loss: 0.19658 
Epoch [97/300] Training [6/62] Loss: 0.10846 
Epoch [97/300] Training [7/62] Loss: 0.21208 
Epoch [97/300] Training [8/62] Loss: 0.11741 
Epoch [97/300] Training [9/62] Loss: 0.09408 
Epoch [97/300] Training [10/62] Loss: 0.14242 
Epoch [97/300] Training [11/62] Loss: 0.15080 
Epoch [97/300] Training [12/62] Loss: 0.22223 
Epoch [97/300] Training [13/62] Loss: 0.09587 
Epoch [97/300] Training [14/62] Loss: 0.21638 
Epoch [97/300] Training [15/62] Loss: 0.12202 
Epoch [97/300] Training [16/62] Loss: 0.13430 
Epoch [97/300] Training [17/62] Loss: 0.10049 
Epoch [97/300] Training [18/62] Loss: 0.14269 
Epoch [97/300] Training [19/62] Loss: 0.25708 
Epoch [97/300] Training [20/62] Loss: 0.32151 
Epoch [97/300] Training [21/62] Loss: 0.09300 
Epoch [97/300] Training [22/62] Loss: 0.16217 
Epoch [97/300] Training [23/62] Loss: 0.14184 
Epoch [97/300] Training [24/62] Loss: 0.27264 
Epoch [97/300] Training [25/62] Loss: 0.17541 
Epoch [97/300] Training [26/62] Loss: 0.15465 
Epoch [97/300] Training [27/62] Loss: 0.14706 
Epoch [97/300] Training [28/62] Loss: 0.07670 
Epoch [97/300] Training [29/62] Loss: 0.18358 
Epoch [97/300] Training [30/62] Loss: 0.20644 
Epoch [97/300] Training [31/62] Loss: 0.13780 
Epoch [97/300] Training [32/62] Loss: 0.24934 
Epoch [97/300] Training [33/62] Loss: 0.16487 
Epoch [97/300] Training [34/62] Loss: 0.30212 
Epoch [97/300] Training [35/62] Loss: 0.29369 
Epoch [97/300] Training [36/62] Loss: 0.26232 
Epoch [97/300] Training [37/62] Loss: 0.14654 
Epoch [97/300] Training [38/62] Loss: 0.15031 
Epoch [97/300] Training [39/62] Loss: 0.34895 
Epoch [97/300] Training [40/62] Loss: 0.25137 
Epoch [97/300] Training [41/62] Loss: 0.11799 
Epoch [97/300] Training [42/62] Loss: 0.20957 
Epoch [97/300] Training [43/62] Loss: 0.18872 
Epoch [97/300] Training [44/62] Loss: 0.43712 
Epoch [97/300] Training [45/62] Loss: 0.28040 
Epoch [97/300] Training [46/62] Loss: 0.54333 
Epoch [97/300] Training [47/62] Loss: 0.22148 
Epoch [97/300] Training [48/62] Loss: 0.35930 
Epoch [97/300] Training [49/62] Loss: 0.22205 
Epoch [97/300] Training [50/62] Loss: 0.22445 
Epoch [97/300] Training [51/62] Loss: 0.15574 
Epoch [97/300] Training [52/62] Loss: 0.20923 
Epoch [97/300] Training [53/62] Loss: 0.23119 
Epoch [97/300] Training [54/62] Loss: 0.23963 
Epoch [97/300] Training [55/62] Loss: 0.26697 
Epoch [97/300] Training [56/62] Loss: 0.11431 
Epoch [97/300] Training [57/62] Loss: 0.25040 
Epoch [97/300] Training [58/62] Loss: 0.15327 
Epoch [97/300] Training [59/62] Loss: 0.24662 
Epoch [97/300] Training [60/62] Loss: 0.15144 
Epoch [97/300] Training [61/62] Loss: 0.28721 
Epoch [97/300] Training [62/62] Loss: 0.17361 
Epoch [97/300] Training metric {'Train/mean dice_metric': 0.8636579513549805, 'Train/mean miou_metric': 0.788792610168457, 'Train/mean f1': 0.8868080377578735, 'Train/mean precision': 0.901610255241394, 'Train/mean recall': 0.8724839091300964, 'Train/mean hd95_metric': 35.44408416748047}
Epoch [97/300] Validation [1/16] Loss: 0.52037  focal_loss 0.29422  dice_loss 0.22615 
Epoch [97/300] Validation [2/16] Loss: 0.44908  focal_loss 0.11435  dice_loss 0.33473 
Epoch [97/300] Validation [3/16] Loss: 0.48769  focal_loss 0.20857  dice_loss 0.27912 
Epoch [97/300] Validation [4/16] Loss: 0.30120  focal_loss 0.11531  dice_loss 0.18589 
Epoch [97/300] Validation [5/16] Loss: 0.33485  focal_loss 0.07277  dice_loss 0.26208 
Epoch [97/300] Validation [6/16] Loss: 0.31403  focal_loss 0.07036  dice_loss 0.24367 
Epoch [97/300] Validation [7/16] Loss: 0.23084  focal_loss 0.06330  dice_loss 0.16753 
Epoch [97/300] Validation [8/16] Loss: 0.39759  focal_loss 0.11373  dice_loss 0.28386 
Epoch [97/300] Validation [9/16] Loss: 0.28510  focal_loss 0.09590  dice_loss 0.18920 
Epoch [97/300] Validation [10/16] Loss: 0.61194  focal_loss 0.19989  dice_loss 0.41205 
Epoch [97/300] Validation [11/16] Loss: 0.17844  focal_loss 0.05136  dice_loss 0.12708 
Epoch [97/300] Validation [12/16] Loss: 0.39558  focal_loss 0.06986  dice_loss 0.32572 
Epoch [97/300] Validation [13/16] Loss: 0.32215  focal_loss 0.08202  dice_loss 0.24013 
Epoch [97/300] Validation [14/16] Loss: 0.65714  focal_loss 0.20231  dice_loss 0.45483 
Epoch [97/300] Validation [15/16] Loss: 0.18193  focal_loss 0.04574  dice_loss 0.13620 
Epoch [97/300] Validation [16/16] Loss: 0.23246  focal_loss 0.06246  dice_loss 0.16999 
Epoch [97/300] Validation metric {'Val/mean dice_metric': 0.8424137830734253, 'Val/mean miou_metric': 0.7622759342193604, 'Val/mean f1': 0.8664429187774658, 'Val/mean precision': 0.876655101776123, 'Val/mean recall': 0.8564659357070923, 'Val/mean hd95_metric': 41.65227508544922}
Cheakpoint...
Epoch [97/300] best acc:tensor([0.8424], device='cuda:0'), Now : mean acc: tensor([0.8424], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8424137830734253, 'Val/mean miou_metric': 0.7622759342193604, 'Val/mean f1': 0.8664429187774658, 'Val/mean precision': 0.876655101776123, 'Val/mean recall': 0.8564659357070923, 'Val/mean hd95_metric': 41.65227508544922}
Epoch [98/300] Training [1/62] Loss: 0.36416 
Epoch [98/300] Training [2/62] Loss: 0.17349 
Epoch [98/300] Training [3/62] Loss: 0.13231 
Epoch [98/300] Training [4/62] Loss: 0.14411 
Epoch [98/300] Training [5/62] Loss: 0.16736 
Epoch [98/300] Training [6/62] Loss: 0.19419 
Epoch [98/300] Training [7/62] Loss: 0.23911 
Epoch [98/300] Training [8/62] Loss: 0.15185 
Epoch [98/300] Training [9/62] Loss: 0.20039 
Epoch [98/300] Training [10/62] Loss: 0.25456 
Epoch [98/300] Training [11/62] Loss: 0.26621 
Epoch [98/300] Training [12/62] Loss: 0.11727 
Epoch [98/300] Training [13/62] Loss: 0.15753 
Epoch [98/300] Training [14/62] Loss: 0.12538 
Epoch [98/300] Training [15/62] Loss: 0.23402 
Epoch [98/300] Training [16/62] Loss: 0.26996 
Epoch [98/300] Training [17/62] Loss: 0.24464 
Epoch [98/300] Training [18/62] Loss: 0.10718 
Epoch [98/300] Training [19/62] Loss: 0.21002 
Epoch [98/300] Training [20/62] Loss: 0.26761 
Epoch [98/300] Training [21/62] Loss: 0.13212 
Epoch [98/300] Training [22/62] Loss: 0.10598 
Epoch [98/300] Training [23/62] Loss: 0.23666 
Epoch [98/300] Training [24/62] Loss: 0.22514 
Epoch [98/300] Training [25/62] Loss: 0.30594 
Epoch [98/300] Training [26/62] Loss: 0.07991 
Epoch [98/300] Training [27/62] Loss: 0.21985 
Epoch [98/300] Training [28/62] Loss: 0.20894 
Epoch [98/300] Training [29/62] Loss: 0.14474 
Epoch [98/300] Training [30/62] Loss: 0.22555 
Epoch [98/300] Training [31/62] Loss: 0.17563 
Epoch [98/300] Training [32/62] Loss: 0.08795 
Epoch [98/300] Training [33/62] Loss: 0.21098 
Epoch [98/300] Training [34/62] Loss: 0.27161 
Epoch [98/300] Training [35/62] Loss: 0.24499 
Epoch [98/300] Training [36/62] Loss: 0.25225 
Epoch [98/300] Training [37/62] Loss: 0.11366 
Epoch [98/300] Training [38/62] Loss: 0.23171 
Epoch [98/300] Training [39/62] Loss: 0.13784 
Epoch [98/300] Training [40/62] Loss: 0.28094 
Epoch [98/300] Training [41/62] Loss: 0.14451 
Epoch [98/300] Training [42/62] Loss: 0.16015 
Epoch [98/300] Training [43/62] Loss: 0.18450 
Epoch [98/300] Training [44/62] Loss: 0.13136 
Epoch [98/300] Training [45/62] Loss: 0.24456 
Epoch [98/300] Training [46/62] Loss: 0.18854 
Epoch [98/300] Training [47/62] Loss: 0.27637 
Epoch [98/300] Training [48/62] Loss: 0.21316 
Epoch [98/300] Training [49/62] Loss: 0.31198 
Epoch [98/300] Training [50/62] Loss: 0.23583 
Epoch [98/300] Training [51/62] Loss: 0.11600 
Epoch [98/300] Training [52/62] Loss: 0.14275 
Epoch [98/300] Training [53/62] Loss: 0.25763 
Epoch [98/300] Training [54/62] Loss: 0.28775 
Epoch [98/300] Training [55/62] Loss: 0.16239 
Epoch [98/300] Training [56/62] Loss: 0.30992 
Epoch [98/300] Training [57/62] Loss: 0.11356 
Epoch [98/300] Training [58/62] Loss: 0.25180 
Epoch [98/300] Training [59/62] Loss: 0.12816 
Epoch [98/300] Training [60/62] Loss: 0.10219 
Epoch [98/300] Training [61/62] Loss: 0.13580 
Epoch [98/300] Training [62/62] Loss: 0.34426 
Epoch [98/300] Training metric {'Train/mean dice_metric': 0.869795560836792, 'Train/mean miou_metric': 0.7930743098258972, 'Train/mean f1': 0.8847397565841675, 'Train/mean precision': 0.8916152119636536, 'Train/mean recall': 0.8779696822166443, 'Train/mean hd95_metric': 35.849693298339844}
Epoch [98/300] Validation [1/16] Loss: 0.62751  focal_loss 0.36850  dice_loss 0.25901 
Epoch [98/300] Validation [2/16] Loss: 0.54854  focal_loss 0.15593  dice_loss 0.39262 
Epoch [98/300] Validation [3/16] Loss: 0.69048  focal_loss 0.30026  dice_loss 0.39022 
Epoch [98/300] Validation [4/16] Loss: 0.55747  focal_loss 0.20222  dice_loss 0.35524 
Epoch [98/300] Validation [5/16] Loss: 0.46267  focal_loss 0.10515  dice_loss 0.35752 
Epoch [98/300] Validation [6/16] Loss: 0.37223  focal_loss 0.11561  dice_loss 0.25662 
Epoch [98/300] Validation [7/16] Loss: 0.25344  focal_loss 0.07845  dice_loss 0.17499 
Epoch [98/300] Validation [8/16] Loss: 0.52626  focal_loss 0.15568  dice_loss 0.37059 
Epoch [98/300] Validation [9/16] Loss: 0.42429  focal_loss 0.13890  dice_loss 0.28538 
Epoch [98/300] Validation [10/16] Loss: 0.77200  focal_loss 0.27573  dice_loss 0.49627 
Epoch [98/300] Validation [11/16] Loss: 0.30122  focal_loss 0.08320  dice_loss 0.21802 
Epoch [98/300] Validation [12/16] Loss: 0.52330  focal_loss 0.09580  dice_loss 0.42749 
Epoch [98/300] Validation [13/16] Loss: 0.28053  focal_loss 0.07062  dice_loss 0.20992 
Epoch [98/300] Validation [14/16] Loss: 0.69809  focal_loss 0.18498  dice_loss 0.51311 
Epoch [98/300] Validation [15/16] Loss: 0.20714  focal_loss 0.06320  dice_loss 0.14395 
Epoch [98/300] Validation [16/16] Loss: 0.34367  focal_loss 0.12508  dice_loss 0.21859 
Epoch [98/300] Validation metric {'Val/mean dice_metric': 0.8344897031784058, 'Val/mean miou_metric': 0.7521400451660156, 'Val/mean f1': 0.855387806892395, 'Val/mean precision': 0.8679938316345215, 'Val/mean recall': 0.8431426286697388, 'Val/mean hd95_metric': 43.69270706176758}
Cheakpoint...
Epoch [98/300] best acc:tensor([0.8424], device='cuda:0'), Now : mean acc: tensor([0.8345], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8344897031784058, 'Val/mean miou_metric': 0.7521400451660156, 'Val/mean f1': 0.855387806892395, 'Val/mean precision': 0.8679938316345215, 'Val/mean recall': 0.8431426286697388, 'Val/mean hd95_metric': 43.69270706176758}
Epoch [99/300] Training [1/62] Loss: 0.16264 
Epoch [99/300] Training [2/62] Loss: 0.14391 
Epoch [99/300] Training [3/62] Loss: 0.16276 
Epoch [99/300] Training [4/62] Loss: 0.36660 
Epoch [99/300] Training [5/62] Loss: 0.22055 
Epoch [99/300] Training [6/62] Loss: 0.39363 
Epoch [99/300] Training [7/62] Loss: 0.20296 
Epoch [99/300] Training [8/62] Loss: 0.18416 
Epoch [99/300] Training [9/62] Loss: 0.18272 
Epoch [99/300] Training [10/62] Loss: 0.24885 
Epoch [99/300] Training [11/62] Loss: 0.18633 
Epoch [99/300] Training [12/62] Loss: 0.22518 
Epoch [99/300] Training [13/62] Loss: 0.28770 
Epoch [99/300] Training [14/62] Loss: 0.19248 
Epoch [99/300] Training [15/62] Loss: 0.09578 
Epoch [99/300] Training [16/62] Loss: 0.25021 
Epoch [99/300] Training [17/62] Loss: 0.15963 
Epoch [99/300] Training [18/62] Loss: 0.13457 
Epoch [99/300] Training [19/62] Loss: 0.19135 
Epoch [99/300] Training [20/62] Loss: 0.23599 
Epoch [99/300] Training [21/62] Loss: 0.15134 
Epoch [99/300] Training [22/62] Loss: 0.14562 
Epoch [99/300] Training [23/62] Loss: 0.27256 
Epoch [99/300] Training [24/62] Loss: 0.15569 
Epoch [99/300] Training [25/62] Loss: 0.24164 
Epoch [99/300] Training [26/62] Loss: 0.31644 
Epoch [99/300] Training [27/62] Loss: 0.16945 
Epoch [99/300] Training [28/62] Loss: 0.14615 
Epoch [99/300] Training [29/62] Loss: 0.10403 
Epoch [99/300] Training [30/62] Loss: 0.25405 
Epoch [99/300] Training [31/62] Loss: 0.17449 
Epoch [99/300] Training [32/62] Loss: 0.10583 
Epoch [99/300] Training [33/62] Loss: 0.20054 
Epoch [99/300] Training [34/62] Loss: 0.13669 
Epoch [99/300] Training [35/62] Loss: 0.13517 
Epoch [99/300] Training [36/62] Loss: 0.28206 
Epoch [99/300] Training [37/62] Loss: 0.13347 
Epoch [99/300] Training [38/62] Loss: 0.42280 
Epoch [99/300] Training [39/62] Loss: 0.22340 
Epoch [99/300] Training [40/62] Loss: 0.24850 
Epoch [99/300] Training [41/62] Loss: 0.22851 
Epoch [99/300] Training [42/62] Loss: 0.16984 
Epoch [99/300] Training [43/62] Loss: 0.29107 
Epoch [99/300] Training [44/62] Loss: 0.15134 
Epoch [99/300] Training [45/62] Loss: 0.22848 
Epoch [99/300] Training [46/62] Loss: 0.20732 
Epoch [99/300] Training [47/62] Loss: 0.14245 
Epoch [99/300] Training [48/62] Loss: 0.34425 
Epoch [99/300] Training [49/62] Loss: 0.22804 
Epoch [99/300] Training [50/62] Loss: 0.19073 
Epoch [99/300] Training [51/62] Loss: 0.36773 
Epoch [99/300] Training [52/62] Loss: 0.12433 
Epoch [99/300] Training [53/62] Loss: 0.19617 
Epoch [99/300] Training [54/62] Loss: 0.20522 
Epoch [99/300] Training [55/62] Loss: 0.35977 
Epoch [99/300] Training [56/62] Loss: 0.14768 
Epoch [99/300] Training [57/62] Loss: 0.45576 
Epoch [99/300] Training [58/62] Loss: 0.28993 
Epoch [99/300] Training [59/62] Loss: 0.17324 
Epoch [99/300] Training [60/62] Loss: 0.36957 
Epoch [99/300] Training [61/62] Loss: 0.18381 
Epoch [99/300] Training [62/62] Loss: 0.07404 
Epoch [99/300] Training metric {'Train/mean dice_metric': 0.8522856831550598, 'Train/mean miou_metric': 0.7762579917907715, 'Train/mean f1': 0.8804370164871216, 'Train/mean precision': 0.8934420943260193, 'Train/mean recall': 0.8678051233291626, 'Train/mean hd95_metric': 37.682193756103516}
Epoch [99/300] Validation [1/16] Loss: 0.53457  focal_loss 0.30961  dice_loss 0.22496 
Epoch [99/300] Validation [2/16] Loss: 0.49305  focal_loss 0.12868  dice_loss 0.36437 
Epoch [99/300] Validation [3/16] Loss: 0.42218  focal_loss 0.14022  dice_loss 0.28196 
Epoch [99/300] Validation [4/16] Loss: 0.24721  focal_loss 0.08814  dice_loss 0.15907 
Epoch [99/300] Validation [5/16] Loss: 0.34934  focal_loss 0.07515  dice_loss 0.27419 
Epoch [99/300] Validation [6/16] Loss: 0.33457  focal_loss 0.07316  dice_loss 0.26141 
Epoch [99/300] Validation [7/16] Loss: 0.25359  focal_loss 0.07247  dice_loss 0.18111 
Epoch [99/300] Validation [8/16] Loss: 0.43231  focal_loss 0.09118  dice_loss 0.34113 
Epoch [99/300] Validation [9/16] Loss: 0.24637  focal_loss 0.06284  dice_loss 0.18353 
Epoch [99/300] Validation [10/16] Loss: 0.65245  focal_loss 0.14932  dice_loss 0.50313 
Epoch [99/300] Validation [11/16] Loss: 0.16607  focal_loss 0.03053  dice_loss 0.13554 
Epoch [99/300] Validation [12/16] Loss: 0.49271  focal_loss 0.07384  dice_loss 0.41887 
Epoch [99/300] Validation [13/16] Loss: 0.32794  focal_loss 0.05216  dice_loss 0.27578 
Epoch [99/300] Validation [14/16] Loss: 0.58077  focal_loss 0.18368  dice_loss 0.39709 
Epoch [99/300] Validation [15/16] Loss: 0.22561  focal_loss 0.06809  dice_loss 0.15752 
Epoch [99/300] Validation [16/16] Loss: 0.26450  focal_loss 0.06348  dice_loss 0.20102 
Epoch [99/300] Validation metric {'Val/mean dice_metric': 0.8301243782043457, 'Val/mean miou_metric': 0.7501592636108398, 'Val/mean f1': 0.8604035377502441, 'Val/mean precision': 0.8754040598869324, 'Val/mean recall': 0.8459083437919617, 'Val/mean hd95_metric': 43.24127197265625}
Cheakpoint...
Epoch [99/300] best acc:tensor([0.8424], device='cuda:0'), Now : mean acc: tensor([0.8301], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8301243782043457, 'Val/mean miou_metric': 0.7501592636108398, 'Val/mean f1': 0.8604035377502441, 'Val/mean precision': 0.8754040598869324, 'Val/mean recall': 0.8459083437919617, 'Val/mean hd95_metric': 43.24127197265625}
Epoch [100/300] Training [1/62] Loss: 0.26637 
Epoch [100/300] Training [2/62] Loss: 0.12490 
Epoch [100/300] Training [3/62] Loss: 0.22620 
Epoch [100/300] Training [4/62] Loss: 0.17736 
Epoch [100/300] Training [5/62] Loss: 0.18994 
Epoch [100/300] Training [6/62] Loss: 0.17234 
Epoch [100/300] Training [7/62] Loss: 0.19025 
Epoch [100/300] Training [8/62] Loss: 0.16753 
Epoch [100/300] Training [9/62] Loss: 0.20006 
Epoch [100/300] Training [10/62] Loss: 0.22810 
Epoch [100/300] Training [11/62] Loss: 0.29025 
Epoch [100/300] Training [12/62] Loss: 0.15330 
Epoch [100/300] Training [13/62] Loss: 0.11881 
Epoch [100/300] Training [14/62] Loss: 0.11799 
Epoch [100/300] Training [15/62] Loss: 0.24831 
Epoch [100/300] Training [16/62] Loss: 0.36642 
Epoch [100/300] Training [17/62] Loss: 0.15064 
Epoch [100/300] Training [18/62] Loss: 0.11335 
Epoch [100/300] Training [19/62] Loss: 0.19603 
Epoch [100/300] Training [20/62] Loss: 0.13384 
Epoch [100/300] Training [21/62] Loss: 0.16554 
Epoch [100/300] Training [22/62] Loss: 0.26753 
Epoch [100/300] Training [23/62] Loss: 0.16905 
Epoch [100/300] Training [24/62] Loss: 0.22678 
Epoch [100/300] Training [25/62] Loss: 0.21983 
Epoch [100/300] Training [26/62] Loss: 0.31788 
Epoch [100/300] Training [27/62] Loss: 0.18038 
Epoch [100/300] Training [28/62] Loss: 0.25108 
Epoch [100/300] Training [29/62] Loss: 0.34843 
Epoch [100/300] Training [30/62] Loss: 0.16079 
Epoch [100/300] Training [31/62] Loss: 0.13355 
Epoch [100/300] Training [32/62] Loss: 0.20089 
Epoch [100/300] Training [33/62] Loss: 0.17789 
Epoch [100/300] Training [34/62] Loss: 0.19394 
Epoch [100/300] Training [35/62] Loss: 0.25713 
Epoch [100/300] Training [36/62] Loss: 0.16827 
Epoch [100/300] Training [37/62] Loss: 0.19914 
Epoch [100/300] Training [38/62] Loss: 0.25039 
Epoch [100/300] Training [39/62] Loss: 0.20805 
Epoch [100/300] Training [40/62] Loss: 0.10961 
Epoch [100/300] Training [41/62] Loss: 0.22812 
Epoch [100/300] Training [42/62] Loss: 0.21899 
Epoch [100/300] Training [43/62] Loss: 0.25370 
Epoch [100/300] Training [44/62] Loss: 0.18433 
Epoch [100/300] Training [45/62] Loss: 0.44386 
Epoch [100/300] Training [46/62] Loss: 0.22396 
Epoch [100/300] Training [47/62] Loss: 0.30143 
Epoch [100/300] Training [48/62] Loss: 0.19208 
Epoch [100/300] Training [49/62] Loss: 0.17875 
Epoch [100/300] Training [50/62] Loss: 0.14549 
Epoch [100/300] Training [51/62] Loss: 0.13556 
Epoch [100/300] Training [52/62] Loss: 0.13961 
Epoch [100/300] Training [53/62] Loss: 0.16294 
Epoch [100/300] Training [54/62] Loss: 0.11109 
Epoch [100/300] Training [55/62] Loss: 0.47171 
Epoch [100/300] Training [56/62] Loss: 0.27004 
Epoch [100/300] Training [57/62] Loss: 0.09346 
Epoch [100/300] Training [58/62] Loss: 0.33282 
Epoch [100/300] Training [59/62] Loss: 0.31396 
Epoch [100/300] Training [60/62] Loss: 0.21471 
Epoch [100/300] Training [61/62] Loss: 0.24815 
Epoch [100/300] Training [62/62] Loss: 0.49141 
Epoch [100/300] Training metric {'Train/mean dice_metric': 0.8575732707977295, 'Train/mean miou_metric': 0.7823662757873535, 'Train/mean f1': 0.8818175792694092, 'Train/mean precision': 0.8901598453521729, 'Train/mean recall': 0.873630166053772, 'Train/mean hd95_metric': 39.89515686035156}
Epoch [100/300] Validation [1/16] Loss: 0.75427  focal_loss 0.39166  dice_loss 0.36261 
Epoch [100/300] Validation [2/16] Loss: 0.61140  focal_loss 0.18150  dice_loss 0.42990 
Epoch [100/300] Validation [3/16] Loss: 0.58888  focal_loss 0.23616  dice_loss 0.35272 
Epoch [100/300] Validation [4/16] Loss: 0.52435  focal_loss 0.21797  dice_loss 0.30638 
Epoch [100/300] Validation [5/16] Loss: 0.46370  focal_loss 0.09587  dice_loss 0.36782 
Epoch [100/300] Validation [6/16] Loss: 0.33701  focal_loss 0.08225  dice_loss 0.25477 
Epoch [100/300] Validation [7/16] Loss: 0.35135  focal_loss 0.09967  dice_loss 0.25168 
Epoch [100/300] Validation [8/16] Loss: 0.77312  focal_loss 0.18020  dice_loss 0.59293 
Epoch [100/300] Validation [9/16] Loss: 0.46339  focal_loss 0.15022  dice_loss 0.31317 
Epoch [100/300] Validation [10/16] Loss: 0.76723  focal_loss 0.20834  dice_loss 0.55889 
Epoch [100/300] Validation [11/16] Loss: 0.23072  focal_loss 0.06590  dice_loss 0.16483 
Epoch [100/300] Validation [12/16] Loss: 0.47413  focal_loss 0.07552  dice_loss 0.39861 
Epoch [100/300] Validation [13/16] Loss: 0.48806  focal_loss 0.17596  dice_loss 0.31210 
Epoch [100/300] Validation [14/16] Loss: 0.92277  focal_loss 0.28599  dice_loss 0.63678 
Epoch [100/300] Validation [15/16] Loss: 0.30330  focal_loss 0.09508  dice_loss 0.20822 
Epoch [100/300] Validation [16/16] Loss: 0.31484  focal_loss 0.08924  dice_loss 0.22559 
Epoch [100/300] Validation metric {'Val/mean dice_metric': 0.8159744143486023, 'Val/mean miou_metric': 0.7358468174934387, 'Val/mean f1': 0.8516126275062561, 'Val/mean precision': 0.8810123801231384, 'Val/mean recall': 0.8241117596626282, 'Val/mean hd95_metric': 44.10582733154297}
Cheakpoint...
Epoch [100/300] best acc:tensor([0.8424], device='cuda:0'), Now : mean acc: tensor([0.8160], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8159744143486023, 'Val/mean miou_metric': 0.7358468174934387, 'Val/mean f1': 0.8516126275062561, 'Val/mean precision': 0.8810123801231384, 'Val/mean recall': 0.8241117596626282, 'Val/mean hd95_metric': 44.10582733154297}
Epoch [101/300] Training [1/62] Loss: 0.12745 
Epoch [101/300] Training [2/62] Loss: 0.09785 
Epoch [101/300] Training [3/62] Loss: 0.18378 
Epoch [101/300] Training [4/62] Loss: 0.13087 
Epoch [101/300] Training [5/62] Loss: 0.21889 
Epoch [101/300] Training [6/62] Loss: 0.17698 
Epoch [101/300] Training [7/62] Loss: 0.22074 
Epoch [101/300] Training [8/62] Loss: 0.07822 
Epoch [101/300] Training [9/62] Loss: 0.10460 
Epoch [101/300] Training [10/62] Loss: 0.25497 
Epoch [101/300] Training [11/62] Loss: 0.22210 
Epoch [101/300] Training [12/62] Loss: 0.15877 
Epoch [101/300] Training [13/62] Loss: 0.17973 
Epoch [101/300] Training [14/62] Loss: 0.20777 
Epoch [101/300] Training [15/62] Loss: 0.12200 
Epoch [101/300] Training [16/62] Loss: 0.16264 
Epoch [101/300] Training [17/62] Loss: 0.28373 
Epoch [101/300] Training [18/62] Loss: 0.29264 
Epoch [101/300] Training [19/62] Loss: 0.23015 
Epoch [101/300] Training [20/62] Loss: 0.14727 
Epoch [101/300] Training [21/62] Loss: 0.12206 
Epoch [101/300] Training [22/62] Loss: 0.24605 
Epoch [101/300] Training [23/62] Loss: 0.17871 
Epoch [101/300] Training [24/62] Loss: 0.14730 
Epoch [101/300] Training [25/62] Loss: 0.14279 
Epoch [101/300] Training [26/62] Loss: 0.28725 
Epoch [101/300] Training [27/62] Loss: 0.13697 
Epoch [101/300] Training [28/62] Loss: 0.14871 
Epoch [101/300] Training [29/62] Loss: 0.15377 
Epoch [101/300] Training [30/62] Loss: 0.16008 
Epoch [101/300] Training [31/62] Loss: 0.34582 
Epoch [101/300] Training [32/62] Loss: 0.17735 
Epoch [101/300] Training [33/62] Loss: 0.14250 
Epoch [101/300] Training [34/62] Loss: 0.15582 
Epoch [101/300] Training [35/62] Loss: 0.12220 
Epoch [101/300] Training [36/62] Loss: 0.11064 
Epoch [101/300] Training [37/62] Loss: 0.17526 
Epoch [101/300] Training [38/62] Loss: 0.18379 
Epoch [101/300] Training [39/62] Loss: 0.30768 
Epoch [101/300] Training [40/62] Loss: 0.25441 
Epoch [101/300] Training [41/62] Loss: 0.16877 
Epoch [101/300] Training [42/62] Loss: 0.13775 
Epoch [101/300] Training [43/62] Loss: 0.27372 
Epoch [101/300] Training [44/62] Loss: 0.24614 
Epoch [101/300] Training [45/62] Loss: 0.20432 
Epoch [101/300] Training [46/62] Loss: 0.08271 
Epoch [101/300] Training [47/62] Loss: 0.10641 
Epoch [101/300] Training [48/62] Loss: 0.36454 
Epoch [101/300] Training [49/62] Loss: 0.30621 
Epoch [101/300] Training [50/62] Loss: 0.24442 
Epoch [101/300] Training [51/62] Loss: 0.23766 
Epoch [101/300] Training [52/62] Loss: 0.18669 
Epoch [101/300] Training [53/62] Loss: 0.16215 
Epoch [101/300] Training [54/62] Loss: 0.53525 
Epoch [101/300] Training [55/62] Loss: 0.10895 
Epoch [101/300] Training [56/62] Loss: 0.19382 
Epoch [101/300] Training [57/62] Loss: 0.39228 
Epoch [101/300] Training [58/62] Loss: 0.21578 
Epoch [101/300] Training [59/62] Loss: 0.18193 
Epoch [101/300] Training [60/62] Loss: 0.23782 
Epoch [101/300] Training [61/62] Loss: 0.13907 
Epoch [101/300] Training [62/62] Loss: 0.51469 
Epoch [101/300] Training metric {'Train/mean dice_metric': 0.8689187169075012, 'Train/mean miou_metric': 0.7954514026641846, 'Train/mean f1': 0.8888797163963318, 'Train/mean precision': 0.9015337824821472, 'Train/mean recall': 0.8765758872032166, 'Train/mean hd95_metric': 37.6154899597168}
Epoch [101/300] Validation [1/16] Loss: 0.61068  focal_loss 0.33535  dice_loss 0.27533 
Epoch [101/300] Validation [2/16] Loss: 0.42829  focal_loss 0.10617  dice_loss 0.32212 
Epoch [101/300] Validation [3/16] Loss: 0.60297  focal_loss 0.23143  dice_loss 0.37155 
Epoch [101/300] Validation [4/16] Loss: 0.38927  focal_loss 0.13165  dice_loss 0.25762 
Epoch [101/300] Validation [5/16] Loss: 0.43257  focal_loss 0.08827  dice_loss 0.34430 
Epoch [101/300] Validation [6/16] Loss: 0.35033  focal_loss 0.07484  dice_loss 0.27549 
Epoch [101/300] Validation [7/16] Loss: 0.25162  focal_loss 0.05215  dice_loss 0.19946 
Epoch [101/300] Validation [8/16] Loss: 0.46293  focal_loss 0.09729  dice_loss 0.36564 
Epoch [101/300] Validation [9/16] Loss: 0.37443  focal_loss 0.11099  dice_loss 0.26344 
Epoch [101/300] Validation [10/16] Loss: 0.72448  focal_loss 0.14987  dice_loss 0.57461 
Epoch [101/300] Validation [11/16] Loss: 0.27819  focal_loss 0.08224  dice_loss 0.19596 
Epoch [101/300] Validation [12/16] Loss: 0.34312  focal_loss 0.04805  dice_loss 0.29507 
Epoch [101/300] Validation [13/16] Loss: 0.30234  focal_loss 0.06369  dice_loss 0.23865 
Epoch [101/300] Validation [14/16] Loss: 0.61240  focal_loss 0.17900  dice_loss 0.43340 
Epoch [101/300] Validation [15/16] Loss: 0.18892  focal_loss 0.03576  dice_loss 0.15317 
Epoch [101/300] Validation [16/16] Loss: 0.14466  focal_loss 0.02205  dice_loss 0.12261 
Epoch [101/300] Validation metric {'Val/mean dice_metric': 0.8394415378570557, 'Val/mean miou_metric': 0.7614540457725525, 'Val/mean f1': 0.8653836250305176, 'Val/mean precision': 0.8839312791824341, 'Val/mean recall': 0.8475982546806335, 'Val/mean hd95_metric': 43.020870208740234}
Cheakpoint...
Epoch [101/300] best acc:tensor([0.8424], device='cuda:0'), Now : mean acc: tensor([0.8394], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8394415378570557, 'Val/mean miou_metric': 0.7614540457725525, 'Val/mean f1': 0.8653836250305176, 'Val/mean precision': 0.8839312791824341, 'Val/mean recall': 0.8475982546806335, 'Val/mean hd95_metric': 43.020870208740234}
Epoch [102/300] Training [1/62] Loss: 0.26660 
Epoch [102/300] Training [2/62] Loss: 0.21936 
Epoch [102/300] Training [3/62] Loss: 0.19607 
Epoch [102/300] Training [4/62] Loss: 0.22042 
Epoch [102/300] Training [5/62] Loss: 0.21013 
Epoch [102/300] Training [6/62] Loss: 0.23327 
Epoch [102/300] Training [7/62] Loss: 0.10909 
Epoch [102/300] Training [8/62] Loss: 0.07856 
Epoch [102/300] Training [9/62] Loss: 0.20178 
Epoch [102/300] Training [10/62] Loss: 0.13330 
Epoch [102/300] Training [11/62] Loss: 0.21101 
Epoch [102/300] Training [12/62] Loss: 0.12061 
Epoch [102/300] Training [13/62] Loss: 0.18844 
Epoch [102/300] Training [14/62] Loss: 0.10236 
Epoch [102/300] Training [15/62] Loss: 0.31777 
Epoch [102/300] Training [16/62] Loss: 0.12855 
Epoch [102/300] Training [17/62] Loss: 0.26832 
Epoch [102/300] Training [18/62] Loss: 0.13116 
Epoch [102/300] Training [19/62] Loss: 0.21837 
Epoch [102/300] Training [20/62] Loss: 0.12760 
Epoch [102/300] Training [21/62] Loss: 0.10646 
Epoch [102/300] Training [22/62] Loss: 0.24659 
Epoch [102/300] Training [23/62] Loss: 0.16919 
Epoch [102/300] Training [24/62] Loss: 0.11641 
Epoch [102/300] Training [25/62] Loss: 0.10114 
Epoch [102/300] Training [26/62] Loss: 0.21521 
Epoch [102/300] Training [27/62] Loss: 0.21836 
Epoch [102/300] Training [28/62] Loss: 0.17922 
Epoch [102/300] Training [29/62] Loss: 0.09658 
Epoch [102/300] Training [30/62] Loss: 0.17098 
Epoch [102/300] Training [31/62] Loss: 0.10488 
Epoch [102/300] Training [32/62] Loss: 0.30779 
Epoch [102/300] Training [33/62] Loss: 0.19530 
Epoch [102/300] Training [34/62] Loss: 0.18376 
Epoch [102/300] Training [35/62] Loss: 0.20377 
Epoch [102/300] Training [36/62] Loss: 0.17517 
Epoch [102/300] Training [37/62] Loss: 0.21042 
Epoch [102/300] Training [38/62] Loss: 0.09278 
Epoch [102/300] Training [39/62] Loss: 0.13128 
Epoch [102/300] Training [40/62] Loss: 0.18992 
Epoch [102/300] Training [41/62] Loss: 0.16727 
Epoch [102/300] Training [42/62] Loss: 0.16142 
Epoch [102/300] Training [43/62] Loss: 0.23657 
Epoch [102/300] Training [44/62] Loss: 0.25089 
Epoch [102/300] Training [45/62] Loss: 0.11450 
Epoch [102/300] Training [46/62] Loss: 0.39430 
Epoch [102/300] Training [47/62] Loss: 0.21915 
Epoch [102/300] Training [48/62] Loss: 0.24143 
Epoch [102/300] Training [49/62] Loss: 0.16639 
Epoch [102/300] Training [50/62] Loss: 0.16771 
Epoch [102/300] Training [51/62] Loss: 0.13762 
Epoch [102/300] Training [52/62] Loss: 0.27570 
Epoch [102/300] Training [53/62] Loss: 0.18175 
Epoch [102/300] Training [54/62] Loss: 0.08861 
Epoch [102/300] Training [55/62] Loss: 0.29486 
Epoch [102/300] Training [56/62] Loss: 0.16006 
Epoch [102/300] Training [57/62] Loss: 0.30692 
Epoch [102/300] Training [58/62] Loss: 0.11152 
Epoch [102/300] Training [59/62] Loss: 0.10684 
Epoch [102/300] Training [60/62] Loss: 0.25480 
Epoch [102/300] Training [61/62] Loss: 0.15388 
Epoch [102/300] Training [62/62] Loss: 0.22807 
Epoch [102/300] Training metric {'Train/mean dice_metric': 0.8762385249137878, 'Train/mean miou_metric': 0.8022206425666809, 'Train/mean f1': 0.8983445763587952, 'Train/mean precision': 0.9021981954574585, 'Train/mean recall': 0.8945237398147583, 'Train/mean hd95_metric': 38.397613525390625}
Epoch [102/300] Validation [1/16] Loss: 0.63804  focal_loss 0.36194  dice_loss 0.27611 
Epoch [102/300] Validation [2/16] Loss: 0.46604  focal_loss 0.12148  dice_loss 0.34456 
Epoch [102/300] Validation [3/16] Loss: 0.50040  focal_loss 0.20219  dice_loss 0.29821 
Epoch [102/300] Validation [4/16] Loss: 0.40542  focal_loss 0.14659  dice_loss 0.25882 
Epoch [102/300] Validation [5/16] Loss: 0.44726  focal_loss 0.10145  dice_loss 0.34581 
Epoch [102/300] Validation [6/16] Loss: 0.42586  focal_loss 0.13295  dice_loss 0.29291 
Epoch [102/300] Validation [7/16] Loss: 0.25249  focal_loss 0.07373  dice_loss 0.17876 
Epoch [102/300] Validation [8/16] Loss: 0.50551  focal_loss 0.12577  dice_loss 0.37974 
Epoch [102/300] Validation [9/16] Loss: 0.35433  focal_loss 0.09167  dice_loss 0.26267 
Epoch [102/300] Validation [10/16] Loss: 0.38133  focal_loss 0.08113  dice_loss 0.30021 
Epoch [102/300] Validation [11/16] Loss: 0.26952  focal_loss 0.04485  dice_loss 0.22467 
Epoch [102/300] Validation [12/16] Loss: 0.39364  focal_loss 0.06634  dice_loss 0.32730 
Epoch [102/300] Validation [13/16] Loss: 0.34217  focal_loss 0.09729  dice_loss 0.24489 
Epoch [102/300] Validation [14/16] Loss: 0.61243  focal_loss 0.18035  dice_loss 0.43209 
Epoch [102/300] Validation [15/16] Loss: 0.19956  focal_loss 0.04424  dice_loss 0.15532 
Epoch [102/300] Validation [16/16] Loss: 0.19297  focal_loss 0.04906  dice_loss 0.14391 
Epoch [102/300] Validation metric {'Val/mean dice_metric': 0.8478928208351135, 'Val/mean miou_metric': 0.7684922218322754, 'Val/mean f1': 0.8740730881690979, 'Val/mean precision': 0.8849649429321289, 'Val/mean recall': 0.863446056842804, 'Val/mean hd95_metric': 45.40971374511719}
Cheakpoint...
Epoch [102/300] best acc:tensor([0.8479], device='cuda:0'), Now : mean acc: tensor([0.8479], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8478928208351135, 'Val/mean miou_metric': 0.7684922218322754, 'Val/mean f1': 0.8740730881690979, 'Val/mean precision': 0.8849649429321289, 'Val/mean recall': 0.863446056842804, 'Val/mean hd95_metric': 45.40971374511719}
Epoch [103/300] Training [1/62] Loss: 0.12707 
Epoch [103/300] Training [2/62] Loss: 0.24378 
Epoch [103/300] Training [3/62] Loss: 0.13356 
Epoch [103/300] Training [4/62] Loss: 0.13625 
Epoch [103/300] Training [5/62] Loss: 0.25303 
Epoch [103/300] Training [6/62] Loss: 0.20613 
Epoch [103/300] Training [7/62] Loss: 0.08297 
Epoch [103/300] Training [8/62] Loss: 0.22758 
Epoch [103/300] Training [9/62] Loss: 0.24853 
Epoch [103/300] Training [10/62] Loss: 0.17502 
Epoch [103/300] Training [11/62] Loss: 0.23330 
Epoch [103/300] Training [12/62] Loss: 0.26848 
Epoch [103/300] Training [13/62] Loss: 0.18095 
Epoch [103/300] Training [14/62] Loss: 0.18805 
Epoch [103/300] Training [15/62] Loss: 0.20158 
Epoch [103/300] Training [16/62] Loss: 0.15638 
Epoch [103/300] Training [17/62] Loss: 0.13233 
Epoch [103/300] Training [18/62] Loss: 0.10939 
Epoch [103/300] Training [19/62] Loss: 0.11551 
Epoch [103/300] Training [20/62] Loss: 0.15225 
Epoch [103/300] Training [21/62] Loss: 0.13643 
Epoch [103/300] Training [22/62] Loss: 0.34609 
Epoch [103/300] Training [23/62] Loss: 0.25586 
Epoch [103/300] Training [24/62] Loss: 0.25908 
Epoch [103/300] Training [25/62] Loss: 0.24829 
Epoch [103/300] Training [26/62] Loss: 0.14102 
Epoch [103/300] Training [27/62] Loss: 0.12993 
Epoch [103/300] Training [28/62] Loss: 0.15104 
Epoch [103/300] Training [29/62] Loss: 0.13280 
Epoch [103/300] Training [30/62] Loss: 0.15373 
Epoch [103/300] Training [31/62] Loss: 0.20390 
Epoch [103/300] Training [32/62] Loss: 0.17065 
Epoch [103/300] Training [33/62] Loss: 0.11276 
Epoch [103/300] Training [34/62] Loss: 0.17455 
Epoch [103/300] Training [35/62] Loss: 0.29552 
Epoch [103/300] Training [36/62] Loss: 0.28928 
Epoch [103/300] Training [37/62] Loss: 0.32167 
Epoch [103/300] Training [38/62] Loss: 0.28482 
Epoch [103/300] Training [39/62] Loss: 0.09410 
Epoch [103/300] Training [40/62] Loss: 0.20560 
Epoch [103/300] Training [41/62] Loss: 0.21797 
Epoch [103/300] Training [42/62] Loss: 0.25314 
Epoch [103/300] Training [43/62] Loss: 0.23814 
Epoch [103/300] Training [44/62] Loss: 0.16440 
Epoch [103/300] Training [45/62] Loss: 0.21510 
Epoch [103/300] Training [46/62] Loss: 0.16994 
Epoch [103/300] Training [47/62] Loss: 0.18093 
Epoch [103/300] Training [48/62] Loss: 0.28166 
Epoch [103/300] Training [49/62] Loss: 0.07515 
Epoch [103/300] Training [50/62] Loss: 0.21593 
Epoch [103/300] Training [51/62] Loss: 0.13276 
Epoch [103/300] Training [52/62] Loss: 0.17196 
Epoch [103/300] Training [53/62] Loss: 0.14411 
Epoch [103/300] Training [54/62] Loss: 0.29879 
Epoch [103/300] Training [55/62] Loss: 0.26375 
Epoch [103/300] Training [56/62] Loss: 0.21388 
Epoch [103/300] Training [57/62] Loss: 0.23740 
Epoch [103/300] Training [58/62] Loss: 0.19050 
Epoch [103/300] Training [59/62] Loss: 0.28252 
Epoch [103/300] Training [60/62] Loss: 0.12149 
Epoch [103/300] Training [61/62] Loss: 0.12938 
Epoch [103/300] Training [62/62] Loss: 0.30035 
Epoch [103/300] Training metric {'Train/mean dice_metric': 0.8687911033630371, 'Train/mean miou_metric': 0.7957565188407898, 'Train/mean f1': 0.8911975026130676, 'Train/mean precision': 0.8998221158981323, 'Train/mean recall': 0.8827366232872009, 'Train/mean hd95_metric': 35.817752838134766}
Epoch [103/300] Validation [1/16] Loss: 0.70440  focal_loss 0.38918  dice_loss 0.31522 
Epoch [103/300] Validation [2/16] Loss: 0.42282  focal_loss 0.11664  dice_loss 0.30617 
Epoch [103/300] Validation [3/16] Loss: 0.56801  focal_loss 0.18306  dice_loss 0.38494 
Epoch [103/300] Validation [4/16] Loss: 0.35016  focal_loss 0.10720  dice_loss 0.24296 
Epoch [103/300] Validation [5/16] Loss: 0.39625  focal_loss 0.08872  dice_loss 0.30753 
Epoch [103/300] Validation [6/16] Loss: 0.38528  focal_loss 0.08185  dice_loss 0.30343 
Epoch [103/300] Validation [7/16] Loss: 0.26726  focal_loss 0.07645  dice_loss 0.19082 
Epoch [103/300] Validation [8/16] Loss: 0.48655  focal_loss 0.12057  dice_loss 0.36598 
Epoch [103/300] Validation [9/16] Loss: 0.31968  focal_loss 0.09795  dice_loss 0.22173 
Epoch [103/300] Validation [10/16] Loss: 0.55382  focal_loss 0.12701  dice_loss 0.42681 
Epoch [103/300] Validation [11/16] Loss: 0.18192  focal_loss 0.02800  dice_loss 0.15392 
Epoch [103/300] Validation [12/16] Loss: 0.42018  focal_loss 0.08106  dice_loss 0.33912 
Epoch [103/300] Validation [13/16] Loss: 0.30299  focal_loss 0.06264  dice_loss 0.24034 
Epoch [103/300] Validation [14/16] Loss: 0.70445  focal_loss 0.21892  dice_loss 0.48553 
Epoch [103/300] Validation [15/16] Loss: 0.17075  focal_loss 0.03159  dice_loss 0.13916 
Epoch [103/300] Validation [16/16] Loss: 0.18289  focal_loss 0.06364  dice_loss 0.11924 
Epoch [103/300] Validation metric {'Val/mean dice_metric': 0.8408452272415161, 'Val/mean miou_metric': 0.7628775238990784, 'Val/mean f1': 0.8671948313713074, 'Val/mean precision': 0.8795757293701172, 'Val/mean recall': 0.8551576137542725, 'Val/mean hd95_metric': 42.88435745239258}
Cheakpoint...
Epoch [103/300] best acc:tensor([0.8479], device='cuda:0'), Now : mean acc: tensor([0.8408], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8408452272415161, 'Val/mean miou_metric': 0.7628775238990784, 'Val/mean f1': 0.8671948313713074, 'Val/mean precision': 0.8795757293701172, 'Val/mean recall': 0.8551576137542725, 'Val/mean hd95_metric': 42.88435745239258}
Epoch [104/300] Training [1/62] Loss: 0.15298 
Epoch [104/300] Training [2/62] Loss: 0.14396 
Epoch [104/300] Training [3/62] Loss: 0.34809 
Epoch [104/300] Training [4/62] Loss: 0.23101 
Epoch [104/300] Training [5/62] Loss: 0.35582 
Epoch [104/300] Training [6/62] Loss: 0.16954 
Epoch [104/300] Training [7/62] Loss: 0.20237 
Epoch [104/300] Training [8/62] Loss: 0.12108 
Epoch [104/300] Training [9/62] Loss: 0.15652 
Epoch [104/300] Training [10/62] Loss: 0.19227 
Epoch [104/300] Training [11/62] Loss: 0.16423 
Epoch [104/300] Training [12/62] Loss: 0.37117 
Epoch [104/300] Training [13/62] Loss: 0.44644 
Epoch [104/300] Training [14/62] Loss: 0.18351 
Epoch [104/300] Training [15/62] Loss: 0.15063 
Epoch [104/300] Training [16/62] Loss: 0.30059 
Epoch [104/300] Training [17/62] Loss: 0.34141 
Epoch [104/300] Training [18/62] Loss: 0.19213 
Epoch [104/300] Training [19/62] Loss: 0.40787 
Epoch [104/300] Training [20/62] Loss: 0.12584 
Epoch [104/300] Training [21/62] Loss: 0.16436 
Epoch [104/300] Training [22/62] Loss: 0.11532 
Epoch [104/300] Training [23/62] Loss: 0.17240 
Epoch [104/300] Training [24/62] Loss: 0.16233 
Epoch [104/300] Training [25/62] Loss: 0.14107 
Epoch [104/300] Training [26/62] Loss: 0.11799 
Epoch [104/300] Training [27/62] Loss: 0.19064 
Epoch [104/300] Training [28/62] Loss: 0.30566 
Epoch [104/300] Training [29/62] Loss: 0.13860 
Epoch [104/300] Training [30/62] Loss: 0.12471 
Epoch [104/300] Training [31/62] Loss: 0.14714 
Epoch [104/300] Training [32/62] Loss: 0.20982 
Epoch [104/300] Training [33/62] Loss: 0.16773 
Epoch [104/300] Training [34/62] Loss: 0.30384 
Epoch [104/300] Training [35/62] Loss: 0.12568 
Epoch [104/300] Training [36/62] Loss: 0.19938 
Epoch [104/300] Training [37/62] Loss: 0.31020 
Epoch [104/300] Training [38/62] Loss: 0.32409 
Epoch [104/300] Training [39/62] Loss: 0.21079 
Epoch [104/300] Training [40/62] Loss: 0.17633 
Epoch [104/300] Training [41/62] Loss: 0.18444 
Epoch [104/300] Training [42/62] Loss: 0.22215 
Epoch [104/300] Training [43/62] Loss: 0.53747 
Epoch [104/300] Training [44/62] Loss: 0.07643 
Epoch [104/300] Training [45/62] Loss: 0.17997 
Epoch [104/300] Training [46/62] Loss: 0.21494 
Epoch [104/300] Training [47/62] Loss: 0.09304 
Epoch [104/300] Training [48/62] Loss: 0.25402 
Epoch [104/300] Training [49/62] Loss: 0.18280 
Epoch [104/300] Training [50/62] Loss: 0.20116 
Epoch [104/300] Training [51/62] Loss: 0.14456 
Epoch [104/300] Training [52/62] Loss: 0.25214 
Epoch [104/300] Training [53/62] Loss: 0.27298 
Epoch [104/300] Training [54/62] Loss: 0.11111 
Epoch [104/300] Training [55/62] Loss: 0.14916 
Epoch [104/300] Training [56/62] Loss: 0.36406 
Epoch [104/300] Training [57/62] Loss: 0.18903 
Epoch [104/300] Training [58/62] Loss: 0.17519 
Epoch [104/300] Training [59/62] Loss: 0.12390 
Epoch [104/300] Training [60/62] Loss: 0.14439 
Epoch [104/300] Training [61/62] Loss: 0.19599 
Epoch [104/300] Training [62/62] Loss: 0.18890 
Epoch [104/300] Training metric {'Train/mean dice_metric': 0.8633108139038086, 'Train/mean miou_metric': 0.7858104109764099, 'Train/mean f1': 0.8801863789558411, 'Train/mean precision': 0.8912013173103333, 'Train/mean recall': 0.869440495967865, 'Train/mean hd95_metric': 40.223876953125}
Epoch [104/300] Validation [1/16] Loss: 0.58764  focal_loss 0.35338  dice_loss 0.23426 
Epoch [104/300] Validation [2/16] Loss: 0.40870  focal_loss 0.10286  dice_loss 0.30584 
Epoch [104/300] Validation [3/16] Loss: 0.51747  focal_loss 0.22571  dice_loss 0.29176 
Epoch [104/300] Validation [4/16] Loss: 0.29436  focal_loss 0.10038  dice_loss 0.19398 
Epoch [104/300] Validation [5/16] Loss: 0.39027  focal_loss 0.10783  dice_loss 0.28244 
Epoch [104/300] Validation [6/16] Loss: 0.35762  focal_loss 0.09142  dice_loss 0.26620 
Epoch [104/300] Validation [7/16] Loss: 0.21313  focal_loss 0.05597  dice_loss 0.15716 
Epoch [104/300] Validation [8/16] Loss: 0.43475  focal_loss 0.10871  dice_loss 0.32604 
Epoch [104/300] Validation [9/16] Loss: 0.29349  focal_loss 0.09615  dice_loss 0.19733 
Epoch [104/300] Validation [10/16] Loss: 0.54099  focal_loss 0.11290  dice_loss 0.42810 
Epoch [104/300] Validation [11/16] Loss: 0.21896  focal_loss 0.05506  dice_loss 0.16390 
Epoch [104/300] Validation [12/16] Loss: 0.37876  focal_loss 0.07844  dice_loss 0.30032 
Epoch [104/300] Validation [13/16] Loss: 0.30216  focal_loss 0.07097  dice_loss 0.23119 
Epoch [104/300] Validation [14/16] Loss: 0.62635  focal_loss 0.20509  dice_loss 0.42126 
Epoch [104/300] Validation [15/16] Loss: 0.23937  focal_loss 0.07978  dice_loss 0.15960 
Epoch [104/300] Validation [16/16] Loss: 0.18334  focal_loss 0.06235  dice_loss 0.12099 
Epoch [104/300] Validation metric {'Val/mean dice_metric': 0.8420278429985046, 'Val/mean miou_metric': 0.760732889175415, 'Val/mean f1': 0.8617089986801147, 'Val/mean precision': 0.8792898058891296, 'Val/mean recall': 0.844817578792572, 'Val/mean hd95_metric': 44.9650993347168}
Cheakpoint...
Epoch [104/300] best acc:tensor([0.8479], device='cuda:0'), Now : mean acc: tensor([0.8420], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8420278429985046, 'Val/mean miou_metric': 0.760732889175415, 'Val/mean f1': 0.8617089986801147, 'Val/mean precision': 0.8792898058891296, 'Val/mean recall': 0.844817578792572, 'Val/mean hd95_metric': 44.9650993347168}
Epoch [105/300] Training [1/62] Loss: 0.06885 
Epoch [105/300] Training [2/62] Loss: 0.07675 
Epoch [105/300] Training [3/62] Loss: 0.06809 
Epoch [105/300] Training [4/62] Loss: 0.21044 
Epoch [105/300] Training [5/62] Loss: 0.13362 
Epoch [105/300] Training [6/62] Loss: 0.13397 
Epoch [105/300] Training [7/62] Loss: 0.13353 
Epoch [105/300] Training [8/62] Loss: 0.10608 
Epoch [105/300] Training [9/62] Loss: 0.25507 
Epoch [105/300] Training [10/62] Loss: 0.22010 
Epoch [105/300] Training [11/62] Loss: 0.28482 
Epoch [105/300] Training [12/62] Loss: 0.29571 
Epoch [105/300] Training [13/62] Loss: 0.19359 
Epoch [105/300] Training [14/62] Loss: 0.37569 
Epoch [105/300] Training [15/62] Loss: 0.15412 
Epoch [105/300] Training [16/62] Loss: 0.37133 
Epoch [105/300] Training [17/62] Loss: 0.27847 
Epoch [105/300] Training [18/62] Loss: 0.11484 
Epoch [105/300] Training [19/62] Loss: 0.27239 
Epoch [105/300] Training [20/62] Loss: 0.19440 
Epoch [105/300] Training [21/62] Loss: 0.10237 
Epoch [105/300] Training [22/62] Loss: 0.18191 
Epoch [105/300] Training [23/62] Loss: 0.35731 
Epoch [105/300] Training [24/62] Loss: 0.13301 
Epoch [105/300] Training [25/62] Loss: 0.12806 
Epoch [105/300] Training [26/62] Loss: 0.10527 
Epoch [105/300] Training [27/62] Loss: 0.30543 
Epoch [105/300] Training [28/62] Loss: 0.24078 
Epoch [105/300] Training [29/62] Loss: 0.15765 
Epoch [105/300] Training [30/62] Loss: 0.14501 
Epoch [105/300] Training [31/62] Loss: 0.17868 
Epoch [105/300] Training [32/62] Loss: 0.20070 
Epoch [105/300] Training [33/62] Loss: 0.30050 
Epoch [105/300] Training [34/62] Loss: 0.23220 
Epoch [105/300] Training [35/62] Loss: 0.34902 
Epoch [105/300] Training [36/62] Loss: 0.26021 
Epoch [105/300] Training [37/62] Loss: 0.10238 
Epoch [105/300] Training [38/62] Loss: 0.11873 
Epoch [105/300] Training [39/62] Loss: 0.21865 
Epoch [105/300] Training [40/62] Loss: 0.24500 
Epoch [105/300] Training [41/62] Loss: 0.23863 
Epoch [105/300] Training [42/62] Loss: 0.20186 
Epoch [105/300] Training [43/62] Loss: 0.24405 
Epoch [105/300] Training [44/62] Loss: 0.12239 
Epoch [105/300] Training [45/62] Loss: 0.11105 
Epoch [105/300] Training [46/62] Loss: 0.11752 
Epoch [105/300] Training [47/62] Loss: 0.15047 
Epoch [105/300] Training [48/62] Loss: 0.19784 
Epoch [105/300] Training [49/62] Loss: 0.17221 
Epoch [105/300] Training [50/62] Loss: 0.20114 
Epoch [105/300] Training [51/62] Loss: 0.20188 
Epoch [105/300] Training [52/62] Loss: 0.09457 
Epoch [105/300] Training [53/62] Loss: 0.19897 
Epoch [105/300] Training [54/62] Loss: 0.15709 
Epoch [105/300] Training [55/62] Loss: 0.11226 
Epoch [105/300] Training [56/62] Loss: 0.39460 
Epoch [105/300] Training [57/62] Loss: 0.31104 
Epoch [105/300] Training [58/62] Loss: 0.18000 
Epoch [105/300] Training [59/62] Loss: 0.13646 
Epoch [105/300] Training [60/62] Loss: 0.24162 
Epoch [105/300] Training [61/62] Loss: 0.26292 
Epoch [105/300] Training [62/62] Loss: 0.10391 
Epoch [105/300] Training metric {'Train/mean dice_metric': 0.8671904802322388, 'Train/mean miou_metric': 0.7949414849281311, 'Train/mean f1': 0.8901448845863342, 'Train/mean precision': 0.8996540307998657, 'Train/mean recall': 0.8808346390724182, 'Train/mean hd95_metric': 36.15501403808594}
Epoch [105/300] Validation [1/16] Loss: 0.67519  focal_loss 0.38767  dice_loss 0.28752 
Epoch [105/300] Validation [2/16] Loss: 0.47231  focal_loss 0.13044  dice_loss 0.34187 
Epoch [105/300] Validation [3/16] Loss: 0.57514  focal_loss 0.22425  dice_loss 0.35090 
Epoch [105/300] Validation [4/16] Loss: 0.42665  focal_loss 0.15965  dice_loss 0.26700 
Epoch [105/300] Validation [5/16] Loss: 0.58377  focal_loss 0.13745  dice_loss 0.44632 
Epoch [105/300] Validation [6/16] Loss: 0.38473  focal_loss 0.09325  dice_loss 0.29148 
Epoch [105/300] Validation [7/16] Loss: 0.25007  focal_loss 0.06554  dice_loss 0.18453 
Epoch [105/300] Validation [8/16] Loss: 0.39668  focal_loss 0.08672  dice_loss 0.30996 
Epoch [105/300] Validation [9/16] Loss: 0.26408  focal_loss 0.09264  dice_loss 0.17144 
Epoch [105/300] Validation [10/16] Loss: 0.65741  focal_loss 0.17385  dice_loss 0.48357 
Epoch [105/300] Validation [11/16] Loss: 0.30142  focal_loss 0.07026  dice_loss 0.23116 
Epoch [105/300] Validation [12/16] Loss: 0.48374  focal_loss 0.08757  dice_loss 0.39617 
Epoch [105/300] Validation [13/16] Loss: 0.28382  focal_loss 0.07680  dice_loss 0.20702 
Epoch [105/300] Validation [14/16] Loss: 0.84707  focal_loss 0.27548  dice_loss 0.57159 
Epoch [105/300] Validation [15/16] Loss: 0.23878  focal_loss 0.08591  dice_loss 0.15287 
Epoch [105/300] Validation [16/16] Loss: 0.13004  focal_loss 0.03746  dice_loss 0.09258 
Epoch [105/300] Validation metric {'Val/mean dice_metric': 0.8344296813011169, 'Val/mean miou_metric': 0.7581570744514465, 'Val/mean f1': 0.8672624826431274, 'Val/mean precision': 0.8869961500167847, 'Val/mean recall': 0.848387598991394, 'Val/mean hd95_metric': 40.7132453918457}
Cheakpoint...
Epoch [105/300] best acc:tensor([0.8479], device='cuda:0'), Now : mean acc: tensor([0.8344], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8344296813011169, 'Val/mean miou_metric': 0.7581570744514465, 'Val/mean f1': 0.8672624826431274, 'Val/mean precision': 0.8869961500167847, 'Val/mean recall': 0.848387598991394, 'Val/mean hd95_metric': 40.7132453918457}
Epoch [106/300] Training [1/62] Loss: 0.20955 
Epoch [106/300] Training [2/62] Loss: 0.21594 
Epoch [106/300] Training [3/62] Loss: 0.11940 
Epoch [106/300] Training [4/62] Loss: 0.15275 
Epoch [106/300] Training [5/62] Loss: 0.29919 
Epoch [106/300] Training [6/62] Loss: 0.10901 
Epoch [106/300] Training [7/62] Loss: 0.15202 
Epoch [106/300] Training [8/62] Loss: 0.26523 
Epoch [106/300] Training [9/62] Loss: 0.09230 
Epoch [106/300] Training [10/62] Loss: 0.16794 
Epoch [106/300] Training [11/62] Loss: 0.19527 
Epoch [106/300] Training [12/62] Loss: 0.18376 
Epoch [106/300] Training [13/62] Loss: 0.30895 
Epoch [106/300] Training [14/62] Loss: 0.27612 
Epoch [106/300] Training [15/62] Loss: 0.17015 
Epoch [106/300] Training [16/62] Loss: 0.11370 
Epoch [106/300] Training [17/62] Loss: 0.13661 
Epoch [106/300] Training [18/62] Loss: 0.10940 
Epoch [106/300] Training [19/62] Loss: 0.10853 
Epoch [106/300] Training [20/62] Loss: 0.12025 
Epoch [106/300] Training [21/62] Loss: 0.24441 
Epoch [106/300] Training [22/62] Loss: 0.15647 
Epoch [106/300] Training [23/62] Loss: 0.28372 
Epoch [106/300] Training [24/62] Loss: 0.20715 
Epoch [106/300] Training [25/62] Loss: 0.15366 
Epoch [106/300] Training [26/62] Loss: 0.11998 
Epoch [106/300] Training [27/62] Loss: 0.13043 
Epoch [106/300] Training [28/62] Loss: 0.31879 
Epoch [106/300] Training [29/62] Loss: 0.16372 
Epoch [106/300] Training [30/62] Loss: 0.09098 
Epoch [106/300] Training [31/62] Loss: 0.15721 
Epoch [106/300] Training [32/62] Loss: 0.45913 
Epoch [106/300] Training [33/62] Loss: 0.20522 
Epoch [106/300] Training [34/62] Loss: 0.07235 
Epoch [106/300] Training [35/62] Loss: 0.14322 
Epoch [106/300] Training [36/62] Loss: 0.19939 
Epoch [106/300] Training [37/62] Loss: 0.20806 
Epoch [106/300] Training [38/62] Loss: 0.23685 
Epoch [106/300] Training [39/62] Loss: 0.31889 
Epoch [106/300] Training [40/62] Loss: 0.14899 
Epoch [106/300] Training [41/62] Loss: 0.28698 
Epoch [106/300] Training [42/62] Loss: 0.12656 
Epoch [106/300] Training [43/62] Loss: 0.25980 
Epoch [106/300] Training [44/62] Loss: 0.42527 
Epoch [106/300] Training [45/62] Loss: 0.10454 
Epoch [106/300] Training [46/62] Loss: 0.20876 
Epoch [106/300] Training [47/62] Loss: 0.11554 
Epoch [106/300] Training [48/62] Loss: 0.12603 
Epoch [106/300] Training [49/62] Loss: 0.29635 
Epoch [106/300] Training [50/62] Loss: 0.17185 
Epoch [106/300] Training [51/62] Loss: 0.13802 
Epoch [106/300] Training [52/62] Loss: 0.30883 
Epoch [106/300] Training [53/62] Loss: 0.17671 
Epoch [106/300] Training [54/62] Loss: 0.15110 
Epoch [106/300] Training [55/62] Loss: 0.15324 
Epoch [106/300] Training [56/62] Loss: 0.36950 
Epoch [106/300] Training [57/62] Loss: 0.19163 
Epoch [106/300] Training [58/62] Loss: 0.07456 
Epoch [106/300] Training [59/62] Loss: 0.15072 
Epoch [106/300] Training [60/62] Loss: 0.23036 
Epoch [106/300] Training [61/62] Loss: 0.10635 
Epoch [106/300] Training [62/62] Loss: 0.39308 
Epoch [106/300] Training metric {'Train/mean dice_metric': 0.874009370803833, 'Train/mean miou_metric': 0.8033710718154907, 'Train/mean f1': 0.8911330699920654, 'Train/mean precision': 0.8959876894950867, 'Train/mean recall': 0.8863307237625122, 'Train/mean hd95_metric': 33.34669494628906}
Epoch [106/300] Validation [1/16] Loss: 0.71619  focal_loss 0.41939  dice_loss 0.29680 
Epoch [106/300] Validation [2/16] Loss: 0.49307  focal_loss 0.13203  dice_loss 0.36105 
Epoch [106/300] Validation [3/16] Loss: 0.54093  focal_loss 0.25394  dice_loss 0.28699 
Epoch [106/300] Validation [4/16] Loss: 0.25108  focal_loss 0.08294  dice_loss 0.16814 
Epoch [106/300] Validation [5/16] Loss: 0.36858  focal_loss 0.08099  dice_loss 0.28759 
Epoch [106/300] Validation [6/16] Loss: 0.37633  focal_loss 0.09095  dice_loss 0.28537 
Epoch [106/300] Validation [7/16] Loss: 0.20605  focal_loss 0.05984  dice_loss 0.14621 
Epoch [106/300] Validation [8/16] Loss: 0.54679  focal_loss 0.17020  dice_loss 0.37659 
Epoch [106/300] Validation [9/16] Loss: 0.42189  focal_loss 0.13951  dice_loss 0.28238 
Epoch [106/300] Validation [10/16] Loss: 0.57927  focal_loss 0.15358  dice_loss 0.42569 
Epoch [106/300] Validation [11/16] Loss: 0.34443  focal_loss 0.08558  dice_loss 0.25885 
Epoch [106/300] Validation [12/16] Loss: 0.34758  focal_loss 0.07223  dice_loss 0.27535 
Epoch [106/300] Validation [13/16] Loss: 0.32754  focal_loss 0.09686  dice_loss 0.23068 
Epoch [106/300] Validation [14/16] Loss: 0.58199  focal_loss 0.18281  dice_loss 0.39918 
Epoch [106/300] Validation [15/16] Loss: 0.16869  focal_loss 0.03714  dice_loss 0.13155 
Epoch [106/300] Validation [16/16] Loss: 0.18050  focal_loss 0.03958  dice_loss 0.14092 
Epoch [106/300] Validation metric {'Val/mean dice_metric': 0.847113311290741, 'Val/mean miou_metric': 0.770441472530365, 'Val/mean f1': 0.8688653707504272, 'Val/mean precision': 0.8777555823326111, 'Val/mean recall': 0.8601535558700562, 'Val/mean hd95_metric': 40.39738464355469}
Cheakpoint...
Epoch [106/300] best acc:tensor([0.8479], device='cuda:0'), Now : mean acc: tensor([0.8471], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.847113311290741, 'Val/mean miou_metric': 0.770441472530365, 'Val/mean f1': 0.8688653707504272, 'Val/mean precision': 0.8777555823326111, 'Val/mean recall': 0.8601535558700562, 'Val/mean hd95_metric': 40.39738464355469}
Epoch [107/300] Training [1/62] Loss: 0.22357 
Epoch [107/300] Training [2/62] Loss: 0.12805 
Epoch [107/300] Training [3/62] Loss: 0.14012 
Epoch [107/300] Training [4/62] Loss: 0.20535 
Epoch [107/300] Training [5/62] Loss: 0.18297 
Epoch [107/300] Training [6/62] Loss: 0.25171 
Epoch [107/300] Training [7/62] Loss: 0.14633 
Epoch [107/300] Training [8/62] Loss: 0.08831 
Epoch [107/300] Training [9/62] Loss: 0.14795 
Epoch [107/300] Training [10/62] Loss: 0.19779 
Epoch [107/300] Training [11/62] Loss: 0.22685 
Epoch [107/300] Training [12/62] Loss: 0.13641 
Epoch [107/300] Training [13/62] Loss: 0.09147 
Epoch [107/300] Training [14/62] Loss: 0.10087 
Epoch [107/300] Training [15/62] Loss: 0.17933 
Epoch [107/300] Training [16/62] Loss: 0.21012 
Epoch [107/300] Training [17/62] Loss: 0.31612 
Epoch [107/300] Training [18/62] Loss: 0.16948 
Epoch [107/300] Training [19/62] Loss: 0.30899 
Epoch [107/300] Training [20/62] Loss: 0.13347 
Epoch [107/300] Training [21/62] Loss: 0.14956 
Epoch [107/300] Training [22/62] Loss: 0.10985 
Epoch [107/300] Training [23/62] Loss: 0.16685 
Epoch [107/300] Training [24/62] Loss: 0.25564 
Epoch [107/300] Training [25/62] Loss: 0.28804 
Epoch [107/300] Training [26/62] Loss: 0.12033 
Epoch [107/300] Training [27/62] Loss: 0.12714 
Epoch [107/300] Training [28/62] Loss: 0.11617 
Epoch [107/300] Training [29/62] Loss: 0.43423 
Epoch [107/300] Training [30/62] Loss: 0.10895 
Epoch [107/300] Training [31/62] Loss: 0.09964 
Epoch [107/300] Training [32/62] Loss: 0.10074 
Epoch [107/300] Training [33/62] Loss: 0.52215 
Epoch [107/300] Training [34/62] Loss: 0.23131 
Epoch [107/300] Training [35/62] Loss: 0.10171 
Epoch [107/300] Training [36/62] Loss: 0.15431 
Epoch [107/300] Training [37/62] Loss: 0.15259 
Epoch [107/300] Training [38/62] Loss: 0.19567 
Epoch [107/300] Training [39/62] Loss: 0.22294 
Epoch [107/300] Training [40/62] Loss: 0.28863 
Epoch [107/300] Training [41/62] Loss: 0.31925 
Epoch [107/300] Training [42/62] Loss: 0.20698 
Epoch [107/300] Training [43/62] Loss: 0.14158 
Epoch [107/300] Training [44/62] Loss: 0.11700 
Epoch [107/300] Training [45/62] Loss: 0.17889 
Epoch [107/300] Training [46/62] Loss: 0.13372 
Epoch [107/300] Training [47/62] Loss: 0.19226 
Epoch [107/300] Training [48/62] Loss: 0.13281 
Epoch [107/300] Training [49/62] Loss: 0.43344 
Epoch [107/300] Training [50/62] Loss: 0.16691 
Epoch [107/300] Training [51/62] Loss: 0.08932 
Epoch [107/300] Training [52/62] Loss: 0.15035 
Epoch [107/300] Training [53/62] Loss: 0.14319 
Epoch [107/300] Training [54/62] Loss: 0.22715 
Epoch [107/300] Training [55/62] Loss: 0.13189 
Epoch [107/300] Training [56/62] Loss: 0.15948 
Epoch [107/300] Training [57/62] Loss: 0.13792 
Epoch [107/300] Training [58/62] Loss: 0.09813 
Epoch [107/300] Training [59/62] Loss: 0.19368 
Epoch [107/300] Training [60/62] Loss: 0.11901 
Epoch [107/300] Training [61/62] Loss: 0.16159 
Epoch [107/300] Training [62/62] Loss: 0.49025 
Epoch [107/300] Training metric {'Train/mean dice_metric': 0.8758569359779358, 'Train/mean miou_metric': 0.8056882619857788, 'Train/mean f1': 0.8997117280960083, 'Train/mean precision': 0.9088700413703918, 'Train/mean recall': 0.8907361030578613, 'Train/mean hd95_metric': 38.05722427368164}
Epoch [107/300] Validation [1/16] Loss: 0.86907  focal_loss 0.49470  dice_loss 0.37437 
Epoch [107/300] Validation [2/16] Loss: 0.60794  focal_loss 0.18225  dice_loss 0.42568 
Epoch [107/300] Validation [3/16] Loss: 0.56529  focal_loss 0.26143  dice_loss 0.30386 
Epoch [107/300] Validation [4/16] Loss: 0.38263  focal_loss 0.15313  dice_loss 0.22950 
Epoch [107/300] Validation [5/16] Loss: 0.42631  focal_loss 0.10886  dice_loss 0.31745 
Epoch [107/300] Validation [6/16] Loss: 0.27571  focal_loss 0.05886  dice_loss 0.21685 
Epoch [107/300] Validation [7/16] Loss: 0.25058  focal_loss 0.08625  dice_loss 0.16433 
Epoch [107/300] Validation [8/16] Loss: 0.41455  focal_loss 0.11272  dice_loss 0.30182 
Epoch [107/300] Validation [9/16] Loss: 0.41215  focal_loss 0.15164  dice_loss 0.26051 
Epoch [107/300] Validation [10/16] Loss: 0.54471  focal_loss 0.15209  dice_loss 0.39262 
Epoch [107/300] Validation [11/16] Loss: 0.33194  focal_loss 0.09724  dice_loss 0.23470 
Epoch [107/300] Validation [12/16] Loss: 0.39117  focal_loss 0.08006  dice_loss 0.31111 
Epoch [107/300] Validation [13/16] Loss: 0.35174  focal_loss 0.11984  dice_loss 0.23191 
Epoch [107/300] Validation [14/16] Loss: 0.68032  focal_loss 0.21281  dice_loss 0.46752 
Epoch [107/300] Validation [15/16] Loss: 0.16309  focal_loss 0.03994  dice_loss 0.12315 
Epoch [107/300] Validation [16/16] Loss: 0.17381  focal_loss 0.05700  dice_loss 0.11681 
Epoch [107/300] Validation metric {'Val/mean dice_metric': 0.8454514145851135, 'Val/mean miou_metric': 0.7692444324493408, 'Val/mean f1': 0.872063159942627, 'Val/mean precision': 0.8870915770530701, 'Val/mean recall': 0.8575354218482971, 'Val/mean hd95_metric': 42.99510192871094}
Cheakpoint...
Epoch [107/300] best acc:tensor([0.8479], device='cuda:0'), Now : mean acc: tensor([0.8455], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8454514145851135, 'Val/mean miou_metric': 0.7692444324493408, 'Val/mean f1': 0.872063159942627, 'Val/mean precision': 0.8870915770530701, 'Val/mean recall': 0.8575354218482971, 'Val/mean hd95_metric': 42.99510192871094}
Epoch [108/300] Training [1/62] Loss: 0.17271 
Epoch [108/300] Training [2/62] Loss: 0.16865 
Epoch [108/300] Training [3/62] Loss: 0.12079 
Epoch [108/300] Training [4/62] Loss: 0.36665 
Epoch [108/300] Training [5/62] Loss: 0.10249 
Epoch [108/300] Training [6/62] Loss: 0.22266 
Epoch [108/300] Training [7/62] Loss: 0.30534 
Epoch [108/300] Training [8/62] Loss: 0.54472 
Epoch [108/300] Training [9/62] Loss: 0.36781 
Epoch [108/300] Training [10/62] Loss: 0.21691 
Epoch [108/300] Training [11/62] Loss: 0.17727 
Epoch [108/300] Training [12/62] Loss: 0.22781 
Epoch [108/300] Training [13/62] Loss: 0.22901 
Epoch [108/300] Training [14/62] Loss: 0.14328 
Epoch [108/300] Training [15/62] Loss: 0.19257 
Epoch [108/300] Training [16/62] Loss: 0.25934 
Epoch [108/300] Training [17/62] Loss: 0.18099 
Epoch [108/300] Training [18/62] Loss: 0.07938 
Epoch [108/300] Training [19/62] Loss: 0.08760 
Epoch [108/300] Training [20/62] Loss: 0.25845 
Epoch [108/300] Training [21/62] Loss: 0.10795 
Epoch [108/300] Training [22/62] Loss: 0.15556 
Epoch [108/300] Training [23/62] Loss: 0.23884 
Epoch [108/300] Training [24/62] Loss: 0.12224 
Epoch [108/300] Training [25/62] Loss: 0.11760 
Epoch [108/300] Training [26/62] Loss: 0.31975 
Epoch [108/300] Training [27/62] Loss: 0.23109 
Epoch [108/300] Training [28/62] Loss: 0.17439 
Epoch [108/300] Training [29/62] Loss: 0.16143 
Epoch [108/300] Training [30/62] Loss: 0.10669 
Epoch [108/300] Training [31/62] Loss: 0.07370 
Epoch [108/300] Training [32/62] Loss: 0.51085 
Epoch [108/300] Training [33/62] Loss: 0.35438 
Epoch [108/300] Training [34/62] Loss: 0.24356 
Epoch [108/300] Training [35/62] Loss: 0.11140 
Epoch [108/300] Training [36/62] Loss: 0.12207 
Epoch [108/300] Training [37/62] Loss: 0.15481 
Epoch [108/300] Training [38/62] Loss: 0.23493 
Epoch [108/300] Training [39/62] Loss: 0.11089 
Epoch [108/300] Training [40/62] Loss: 0.24777 
Epoch [108/300] Training [41/62] Loss: 0.30767 
Epoch [108/300] Training [42/62] Loss: 0.15204 
Epoch [108/300] Training [43/62] Loss: 0.15449 
Epoch [108/300] Training [44/62] Loss: 0.27242 
Epoch [108/300] Training [45/62] Loss: 0.14343 
Epoch [108/300] Training [46/62] Loss: 0.14682 
Epoch [108/300] Training [47/62] Loss: 0.11096 
Epoch [108/300] Training [48/62] Loss: 0.27447 
Epoch [108/300] Training [49/62] Loss: 0.14960 
Epoch [108/300] Training [50/62] Loss: 0.11400 
Epoch [108/300] Training [51/62] Loss: 0.08206 
Epoch [108/300] Training [52/62] Loss: 0.17312 
Epoch [108/300] Training [53/62] Loss: 0.14700 
Epoch [108/300] Training [54/62] Loss: 0.16680 
Epoch [108/300] Training [55/62] Loss: 0.18593 
Epoch [108/300] Training [56/62] Loss: 0.20608 
Epoch [108/300] Training [57/62] Loss: 0.08306 
Epoch [108/300] Training [58/62] Loss: 0.09561 
Epoch [108/300] Training [59/62] Loss: 0.30305 
Epoch [108/300] Training [60/62] Loss: 0.17383 
Epoch [108/300] Training [61/62] Loss: 0.12777 
Epoch [108/300] Training [62/62] Loss: 0.80514 
Epoch [108/300] Training metric {'Train/mean dice_metric': 0.8700557947158813, 'Train/mean miou_metric': 0.797602653503418, 'Train/mean f1': 0.8879306316375732, 'Train/mean precision': 0.8956219553947449, 'Train/mean recall': 0.8803703784942627, 'Train/mean hd95_metric': 36.11552429199219}
Epoch [108/300] Validation [1/16] Loss: 0.54964  focal_loss 0.33055  dice_loss 0.21909 
Epoch [108/300] Validation [2/16] Loss: 0.48780  focal_loss 0.15051  dice_loss 0.33730 
Epoch [108/300] Validation [3/16] Loss: 0.61953  focal_loss 0.28215  dice_loss 0.33738 
Epoch [108/300] Validation [4/16] Loss: 0.37792  focal_loss 0.15328  dice_loss 0.22464 
Epoch [108/300] Validation [5/16] Loss: 0.45675  focal_loss 0.12112  dice_loss 0.33564 
Epoch [108/300] Validation [6/16] Loss: 0.39779  focal_loss 0.12902  dice_loss 0.26878 
Epoch [108/300] Validation [7/16] Loss: 0.25701  focal_loss 0.09020  dice_loss 0.16680 
Epoch [108/300] Validation [8/16] Loss: 0.46738  focal_loss 0.13987  dice_loss 0.32751 
Epoch [108/300] Validation [9/16] Loss: 0.30781  focal_loss 0.10794  dice_loss 0.19987 
Epoch [108/300] Validation [10/16] Loss: 0.63287  focal_loss 0.19596  dice_loss 0.43691 
Epoch [108/300] Validation [11/16] Loss: 0.27627  focal_loss 0.06723  dice_loss 0.20904 
Epoch [108/300] Validation [12/16] Loss: 0.41046  focal_loss 0.08474  dice_loss 0.32571 
Epoch [108/300] Validation [13/16] Loss: 0.26522  focal_loss 0.06900  dice_loss 0.19622 
Epoch [108/300] Validation [14/16] Loss: 0.52385  focal_loss 0.16604  dice_loss 0.35781 
Epoch [108/300] Validation [15/16] Loss: 0.21154  focal_loss 0.05842  dice_loss 0.15312 
Epoch [108/300] Validation [16/16] Loss: 0.14939  focal_loss 0.03392  dice_loss 0.11547 
Epoch [108/300] Validation metric {'Val/mean dice_metric': 0.8444511294364929, 'Val/mean miou_metric': 0.7671042084693909, 'Val/mean f1': 0.8657823801040649, 'Val/mean precision': 0.8748525381088257, 'Val/mean recall': 0.8568984866142273, 'Val/mean hd95_metric': 41.29081344604492}
Cheakpoint...
Epoch [108/300] best acc:tensor([0.8479], device='cuda:0'), Now : mean acc: tensor([0.8445], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8444511294364929, 'Val/mean miou_metric': 0.7671042084693909, 'Val/mean f1': 0.8657823801040649, 'Val/mean precision': 0.8748525381088257, 'Val/mean recall': 0.8568984866142273, 'Val/mean hd95_metric': 41.29081344604492}
Epoch [109/300] Training [1/62] Loss: 0.17872 
Epoch [109/300] Training [2/62] Loss: 0.16316 
Epoch [109/300] Training [3/62] Loss: 0.18040 
Epoch [109/300] Training [4/62] Loss: 0.20201 
Epoch [109/300] Training [5/62] Loss: 0.21679 
Epoch [109/300] Training [6/62] Loss: 0.30169 
Epoch [109/300] Training [7/62] Loss: 0.19582 
Epoch [109/300] Training [8/62] Loss: 0.14885 
Epoch [109/300] Training [9/62] Loss: 0.10608 
Epoch [109/300] Training [10/62] Loss: 0.15363 
Epoch [109/300] Training [11/62] Loss: 0.32123 
Epoch [109/300] Training [12/62] Loss: 0.19397 
Epoch [109/300] Training [13/62] Loss: 0.09070 
Epoch [109/300] Training [14/62] Loss: 0.30875 
Epoch [109/300] Training [15/62] Loss: 0.11310 
Epoch [109/300] Training [16/62] Loss: 0.19032 
Epoch [109/300] Training [17/62] Loss: 0.25291 
Epoch [109/300] Training [18/62] Loss: 0.22207 
Epoch [109/300] Training [19/62] Loss: 0.11817 
Epoch [109/300] Training [20/62] Loss: 0.12035 
Epoch [109/300] Training [21/62] Loss: 0.09280 
Epoch [109/300] Training [22/62] Loss: 0.30307 
Epoch [109/300] Training [23/62] Loss: 0.22227 
Epoch [109/300] Training [24/62] Loss: 0.11751 
Epoch [109/300] Training [25/62] Loss: 0.15839 
Epoch [109/300] Training [26/62] Loss: 0.19418 
Epoch [109/300] Training [27/62] Loss: 0.18013 
Epoch [109/300] Training [28/62] Loss: 0.14430 
Epoch [109/300] Training [29/62] Loss: 0.20760 
Epoch [109/300] Training [30/62] Loss: 0.14235 
Epoch [109/300] Training [31/62] Loss: 0.30396 
Epoch [109/300] Training [32/62] Loss: 0.20680 
Epoch [109/300] Training [33/62] Loss: 0.25178 
Epoch [109/300] Training [34/62] Loss: 0.07609 
Epoch [109/300] Training [35/62] Loss: 0.26991 
Epoch [109/300] Training [36/62] Loss: 0.29442 
Epoch [109/300] Training [37/62] Loss: 0.27762 
Epoch [109/300] Training [38/62] Loss: 0.18895 
Epoch [109/300] Training [39/62] Loss: 0.11709 
Epoch [109/300] Training [40/62] Loss: 0.24741 
Epoch [109/300] Training [41/62] Loss: 0.17871 
Epoch [109/300] Training [42/62] Loss: 0.13142 
Epoch [109/300] Training [43/62] Loss: 0.17220 
Epoch [109/300] Training [44/62] Loss: 0.31475 
Epoch [109/300] Training [45/62] Loss: 0.22921 
Epoch [109/300] Training [46/62] Loss: 0.13478 
Epoch [109/300] Training [47/62] Loss: 0.08868 
Epoch [109/300] Training [48/62] Loss: 0.20076 
Epoch [109/300] Training [49/62] Loss: 0.12389 
Epoch [109/300] Training [50/62] Loss: 0.11148 
Epoch [109/300] Training [51/62] Loss: 0.16753 
Epoch [109/300] Training [52/62] Loss: 0.26984 
Epoch [109/300] Training [53/62] Loss: 0.18254 
Epoch [109/300] Training [54/62] Loss: 0.12017 
Epoch [109/300] Training [55/62] Loss: 0.20249 
Epoch [109/300] Training [56/62] Loss: 0.14389 
Epoch [109/300] Training [57/62] Loss: 0.24994 
Epoch [109/300] Training [58/62] Loss: 0.17719 
Epoch [109/300] Training [59/62] Loss: 0.26437 
Epoch [109/300] Training [60/62] Loss: 0.14207 
Epoch [109/300] Training [61/62] Loss: 0.11724 
Epoch [109/300] Training [62/62] Loss: 0.06231 
Epoch [109/300] Training metric {'Train/mean dice_metric': 0.8728387951850891, 'Train/mean miou_metric': 0.7994415163993835, 'Train/mean f1': 0.8945749998092651, 'Train/mean precision': 0.89646315574646, 'Train/mean recall': 0.8926948308944702, 'Train/mean hd95_metric': 35.687896728515625}
Epoch [109/300] Validation [1/16] Loss: 0.64132  focal_loss 0.34212  dice_loss 0.29920 
Epoch [109/300] Validation [2/16] Loss: 0.47567  focal_loss 0.13501  dice_loss 0.34066 
Epoch [109/300] Validation [3/16] Loss: 0.60568  focal_loss 0.26054  dice_loss 0.34514 
Epoch [109/300] Validation [4/16] Loss: 0.31149  focal_loss 0.11580  dice_loss 0.19569 
Epoch [109/300] Validation [5/16] Loss: 0.39419  focal_loss 0.10272  dice_loss 0.29147 
Epoch [109/300] Validation [6/16] Loss: 0.34535  focal_loss 0.07228  dice_loss 0.27307 
Epoch [109/300] Validation [7/16] Loss: 0.35107  focal_loss 0.10288  dice_loss 0.24819 
Epoch [109/300] Validation [8/16] Loss: 0.38260  focal_loss 0.08319  dice_loss 0.29941 
Epoch [109/300] Validation [9/16] Loss: 0.42498  focal_loss 0.13931  dice_loss 0.28566 
Epoch [109/300] Validation [10/16] Loss: 0.41743  focal_loss 0.08955  dice_loss 0.32788 
Epoch [109/300] Validation [11/16] Loss: 0.25752  focal_loss 0.06827  dice_loss 0.18925 
Epoch [109/300] Validation [12/16] Loss: 0.37759  focal_loss 0.07172  dice_loss 0.30587 
Epoch [109/300] Validation [13/16] Loss: 0.28277  focal_loss 0.07381  dice_loss 0.20896 
Epoch [109/300] Validation [14/16] Loss: 0.57188  focal_loss 0.15233  dice_loss 0.41955 
Epoch [109/300] Validation [15/16] Loss: 0.18036  focal_loss 0.04523  dice_loss 0.13512 
Epoch [109/300] Validation [16/16] Loss: 0.19958  focal_loss 0.04707  dice_loss 0.15251 
Epoch [109/300] Validation metric {'Val/mean dice_metric': 0.8465768694877625, 'Val/mean miou_metric': 0.767299234867096, 'Val/mean f1': 0.872341513633728, 'Val/mean precision': 0.8853451609611511, 'Val/mean recall': 0.8597142100334167, 'Val/mean hd95_metric': 41.66469955444336}
Cheakpoint...
Epoch [109/300] best acc:tensor([0.8479], device='cuda:0'), Now : mean acc: tensor([0.8466], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8465768694877625, 'Val/mean miou_metric': 0.767299234867096, 'Val/mean f1': 0.872341513633728, 'Val/mean precision': 0.8853451609611511, 'Val/mean recall': 0.8597142100334167, 'Val/mean hd95_metric': 41.66469955444336}
Epoch [110/300] Training [1/62] Loss: 0.12809 
Epoch [110/300] Training [2/62] Loss: 0.12917 
Epoch [110/300] Training [3/62] Loss: 0.14538 
Epoch [110/300] Training [4/62] Loss: 0.11043 
Epoch [110/300] Training [5/62] Loss: 0.16819 
Epoch [110/300] Training [6/62] Loss: 0.17190 
Epoch [110/300] Training [7/62] Loss: 0.28028 
Epoch [110/300] Training [8/62] Loss: 0.07045 
Epoch [110/300] Training [9/62] Loss: 0.15372 
Epoch [110/300] Training [10/62] Loss: 0.21812 
Epoch [110/300] Training [11/62] Loss: 0.22414 
Epoch [110/300] Training [12/62] Loss: 0.11526 
Epoch [110/300] Training [13/62] Loss: 0.22849 
Epoch [110/300] Training [14/62] Loss: 0.15854 
Epoch [110/300] Training [15/62] Loss: 0.13304 
Epoch [110/300] Training [16/62] Loss: 0.15729 
Epoch [110/300] Training [17/62] Loss: 0.28356 
Epoch [110/300] Training [18/62] Loss: 0.05975 
Epoch [110/300] Training [19/62] Loss: 0.16066 
Epoch [110/300] Training [20/62] Loss: 0.12222 
Epoch [110/300] Training [21/62] Loss: 0.26603 
Epoch [110/300] Training [22/62] Loss: 0.08514 
Epoch [110/300] Training [23/62] Loss: 0.20606 
Epoch [110/300] Training [24/62] Loss: 0.17700 
Epoch [110/300] Training [25/62] Loss: 0.09661 
Epoch [110/300] Training [26/62] Loss: 0.11825 
Epoch [110/300] Training [27/62] Loss: 0.28703 
Epoch [110/300] Training [28/62] Loss: 0.19353 
Epoch [110/300] Training [29/62] Loss: 0.11371 
Epoch [110/300] Training [30/62] Loss: 0.08273 
Epoch [110/300] Training [31/62] Loss: 0.11556 
Epoch [110/300] Training [32/62] Loss: 0.08635 
Epoch [110/300] Training [33/62] Loss: 0.15616 
Epoch [110/300] Training [34/62] Loss: 0.17243 
Epoch [110/300] Training [35/62] Loss: 0.10098 
Epoch [110/300] Training [36/62] Loss: 0.38642 
Epoch [110/300] Training [37/62] Loss: 0.21859 
Epoch [110/300] Training [38/62] Loss: 0.08006 
Epoch [110/300] Training [39/62] Loss: 0.11120 
Epoch [110/300] Training [40/62] Loss: 0.13342 
Epoch [110/300] Training [41/62] Loss: 0.09183 
Epoch [110/300] Training [42/62] Loss: 0.17117 
Epoch [110/300] Training [43/62] Loss: 0.11070 
Epoch [110/300] Training [44/62] Loss: 0.18873 
Epoch [110/300] Training [45/62] Loss: 0.42040 
Epoch [110/300] Training [46/62] Loss: 0.18868 
Epoch [110/300] Training [47/62] Loss: 0.19652 
Epoch [110/300] Training [48/62] Loss: 0.15083 
Epoch [110/300] Training [49/62] Loss: 0.06941 
Epoch [110/300] Training [50/62] Loss: 0.24649 
Epoch [110/300] Training [51/62] Loss: 0.17390 
Epoch [110/300] Training [52/62] Loss: 0.09687 
Epoch [110/300] Training [53/62] Loss: 0.36692 
Epoch [110/300] Training [54/62] Loss: 0.14674 
Epoch [110/300] Training [55/62] Loss: 0.14046 
Epoch [110/300] Training [56/62] Loss: 0.10819 
Epoch [110/300] Training [57/62] Loss: 0.14875 
Epoch [110/300] Training [58/62] Loss: 0.16634 
Epoch [110/300] Training [59/62] Loss: 0.12883 
Epoch [110/300] Training [60/62] Loss: 0.23331 
Epoch [110/300] Training [61/62] Loss: 0.21468 
Epoch [110/300] Training [62/62] Loss: 0.25162 
Epoch [110/300] Training metric {'Train/mean dice_metric': 0.8871975541114807, 'Train/mean miou_metric': 0.8200966119766235, 'Train/mean f1': 0.909178614616394, 'Train/mean precision': 0.9138408303260803, 'Train/mean recall': 0.9045636057853699, 'Train/mean hd95_metric': 30.854921340942383}
Epoch [110/300] Validation [1/16] Loss: 0.55036  focal_loss 0.27274  dice_loss 0.27762 
Epoch [110/300] Validation [2/16] Loss: 0.52916  focal_loss 0.13166  dice_loss 0.39751 
Epoch [110/300] Validation [3/16] Loss: 0.53781  focal_loss 0.23410  dice_loss 0.30371 
Epoch [110/300] Validation [4/16] Loss: 0.31804  focal_loss 0.08134  dice_loss 0.23670 
Epoch [110/300] Validation [5/16] Loss: 0.48865  focal_loss 0.13271  dice_loss 0.35593 
Epoch [110/300] Validation [6/16] Loss: 0.36040  focal_loss 0.09016  dice_loss 0.27024 
Epoch [110/300] Validation [7/16] Loss: 0.32233  focal_loss 0.09491  dice_loss 0.22742 
Epoch [110/300] Validation [8/16] Loss: 0.49630  focal_loss 0.12999  dice_loss 0.36631 
Epoch [110/300] Validation [9/16] Loss: 0.47209  focal_loss 0.13225  dice_loss 0.33984 
Epoch [110/300] Validation [10/16] Loss: 0.55834  focal_loss 0.17196  dice_loss 0.38638 
Epoch [110/300] Validation [11/16] Loss: 0.32634  focal_loss 0.07850  dice_loss 0.24785 
Epoch [110/300] Validation [12/16] Loss: 0.48676  focal_loss 0.08451  dice_loss 0.40225 
Epoch [110/300] Validation [13/16] Loss: 0.43660  focal_loss 0.12843  dice_loss 0.30817 
Epoch [110/300] Validation [14/16] Loss: 0.61116  focal_loss 0.17075  dice_loss 0.44041 
Epoch [110/300] Validation [15/16] Loss: 0.23868  focal_loss 0.06083  dice_loss 0.17785 
Epoch [110/300] Validation [16/16] Loss: 0.23217  focal_loss 0.05868  dice_loss 0.17350 
Epoch [110/300] Validation metric {'Val/mean dice_metric': 0.8510953783988953, 'Val/mean miou_metric': 0.7731791138648987, 'Val/mean f1': 0.8718492984771729, 'Val/mean precision': 0.8625012040138245, 'Val/mean recall': 0.881402313709259, 'Val/mean hd95_metric': 41.60195541381836}
Cheakpoint...
Epoch [110/300] best acc:tensor([0.8511], device='cuda:0'), Now : mean acc: tensor([0.8511], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8510953783988953, 'Val/mean miou_metric': 0.7731791138648987, 'Val/mean f1': 0.8718492984771729, 'Val/mean precision': 0.8625012040138245, 'Val/mean recall': 0.881402313709259, 'Val/mean hd95_metric': 41.60195541381836}
Epoch [111/300] Training [1/62] Loss: 0.17741 
Epoch [111/300] Training [2/62] Loss: 0.23297 
Epoch [111/300] Training [3/62] Loss: 0.15516 
Epoch [111/300] Training [4/62] Loss: 0.20035 
Epoch [111/300] Training [5/62] Loss: 0.31636 
Epoch [111/300] Training [6/62] Loss: 0.14955 
Epoch [111/300] Training [7/62] Loss: 0.19823 
Epoch [111/300] Training [8/62] Loss: 0.09471 
Epoch [111/300] Training [9/62] Loss: 0.13506 
Epoch [111/300] Training [10/62] Loss: 0.21739 
Epoch [111/300] Training [11/62] Loss: 0.19447 
Epoch [111/300] Training [12/62] Loss: 0.16172 
Epoch [111/300] Training [13/62] Loss: 0.38538 
Epoch [111/300] Training [14/62] Loss: 0.16133 
Epoch [111/300] Training [15/62] Loss: 0.30930 
Epoch [111/300] Training [16/62] Loss: 0.33713 
Epoch [111/300] Training [17/62] Loss: 0.23797 
Epoch [111/300] Training [18/62] Loss: 0.25097 
Epoch [111/300] Training [19/62] Loss: 0.19881 
Epoch [111/300] Training [20/62] Loss: 0.39765 
Epoch [111/300] Training [21/62] Loss: 0.12598 
Epoch [111/300] Training [22/62] Loss: 0.22078 
Epoch [111/300] Training [23/62] Loss: 0.13617 
Epoch [111/300] Training [24/62] Loss: 0.28240 
Epoch [111/300] Training [25/62] Loss: 0.26067 
Epoch [111/300] Training [26/62] Loss: 0.10061 
Epoch [111/300] Training [27/62] Loss: 0.11281 
Epoch [111/300] Training [28/62] Loss: 0.12373 
Epoch [111/300] Training [29/62] Loss: 0.28150 
Epoch [111/300] Training [30/62] Loss: 0.17623 
Epoch [111/300] Training [31/62] Loss: 0.41207 
Epoch [111/300] Training [32/62] Loss: 0.19016 
Epoch [111/300] Training [33/62] Loss: 0.30046 
Epoch [111/300] Training [34/62] Loss: 0.25029 
Epoch [111/300] Training [35/62] Loss: 0.07442 
Epoch [111/300] Training [36/62] Loss: 0.15699 
Epoch [111/300] Training [37/62] Loss: 0.20426 
Epoch [111/300] Training [38/62] Loss: 0.11191 
Epoch [111/300] Training [39/62] Loss: 0.32296 
Epoch [111/300] Training [40/62] Loss: 0.18517 
Epoch [111/300] Training [41/62] Loss: 0.11737 
Epoch [111/300] Training [42/62] Loss: 0.15577 
Epoch [111/300] Training [43/62] Loss: 0.26780 
Epoch [111/300] Training [44/62] Loss: 0.15308 
Epoch [111/300] Training [45/62] Loss: 0.21432 
Epoch [111/300] Training [46/62] Loss: 0.25581 
Epoch [111/300] Training [47/62] Loss: 0.17973 
Epoch [111/300] Training [48/62] Loss: 0.14410 
Epoch [111/300] Training [49/62] Loss: 0.19616 
Epoch [111/300] Training [50/62] Loss: 0.11618 
Epoch [111/300] Training [51/62] Loss: 0.50004 
Epoch [111/300] Training [52/62] Loss: 0.07996 
Epoch [111/300] Training [53/62] Loss: 0.16756 
Epoch [111/300] Training [54/62] Loss: 0.34800 
Epoch [111/300] Training [55/62] Loss: 0.16677 
Epoch [111/300] Training [56/62] Loss: 0.10550 
Epoch [111/300] Training [57/62] Loss: 0.16286 
Epoch [111/300] Training [58/62] Loss: 0.08923 
Epoch [111/300] Training [59/62] Loss: 0.11040 
Epoch [111/300] Training [60/62] Loss: 0.38691 
Epoch [111/300] Training [61/62] Loss: 0.09062 
Epoch [111/300] Training [62/62] Loss: 0.05796 
Epoch [111/300] Training metric {'Train/mean dice_metric': 0.8616880178451538, 'Train/mean miou_metric': 0.7869342565536499, 'Train/mean f1': 0.8861449956893921, 'Train/mean precision': 0.8927284479141235, 'Train/mean recall': 0.8796579241752625, 'Train/mean hd95_metric': 37.55588912963867}
Epoch [111/300] Validation [1/16] Loss: 0.74037  focal_loss 0.42528  dice_loss 0.31509 
Epoch [111/300] Validation [2/16] Loss: 0.53187  focal_loss 0.16885  dice_loss 0.36302 
Epoch [111/300] Validation [3/16] Loss: 0.67389  focal_loss 0.31781  dice_loss 0.35608 
Epoch [111/300] Validation [4/16] Loss: 0.33473  focal_loss 0.14715  dice_loss 0.18757 
Epoch [111/300] Validation [5/16] Loss: 0.39052  focal_loss 0.07902  dice_loss 0.31150 
Epoch [111/300] Validation [6/16] Loss: 0.34344  focal_loss 0.08135  dice_loss 0.26209 
Epoch [111/300] Validation [7/16] Loss: 0.23456  focal_loss 0.07971  dice_loss 0.15485 
Epoch [111/300] Validation [8/16] Loss: 0.43322  focal_loss 0.12629  dice_loss 0.30693 
Epoch [111/300] Validation [9/16] Loss: 0.35761  focal_loss 0.13906  dice_loss 0.21855 
Epoch [111/300] Validation [10/16] Loss: 0.69816  focal_loss 0.22039  dice_loss 0.47778 
Epoch [111/300] Validation [11/16] Loss: 0.28868  focal_loss 0.06870  dice_loss 0.21997 
Epoch [111/300] Validation [12/16] Loss: 0.43703  focal_loss 0.09565  dice_loss 0.34138 
Epoch [111/300] Validation [13/16] Loss: 0.32382  focal_loss 0.09112  dice_loss 0.23270 
Epoch [111/300] Validation [14/16] Loss: 0.61356  focal_loss 0.21200  dice_loss 0.40156 
Epoch [111/300] Validation [15/16] Loss: 0.30354  focal_loss 0.10672  dice_loss 0.19682 
Epoch [111/300] Validation [16/16] Loss: 0.25448  focal_loss 0.07700  dice_loss 0.17747 
Epoch [111/300] Validation metric {'Val/mean dice_metric': 0.8340407013893127, 'Val/mean miou_metric': 0.7544276714324951, 'Val/mean f1': 0.8616383671760559, 'Val/mean precision': 0.8854005336761475, 'Val/mean recall': 0.839118242263794, 'Val/mean hd95_metric': 41.72848129272461}
Cheakpoint...
Epoch [111/300] best acc:tensor([0.8511], device='cuda:0'), Now : mean acc: tensor([0.8340], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8340407013893127, 'Val/mean miou_metric': 0.7544276714324951, 'Val/mean f1': 0.8616383671760559, 'Val/mean precision': 0.8854005336761475, 'Val/mean recall': 0.839118242263794, 'Val/mean hd95_metric': 41.72848129272461}
Epoch [112/300] Training [1/62] Loss: 0.12580 
Epoch [112/300] Training [2/62] Loss: 0.10781 
Epoch [112/300] Training [3/62] Loss: 0.09081 
Epoch [112/300] Training [4/62] Loss: 0.27404 
Epoch [112/300] Training [5/62] Loss: 0.12875 
Epoch [112/300] Training [6/62] Loss: 0.24850 
Epoch [112/300] Training [7/62] Loss: 0.14304 
Epoch [112/300] Training [8/62] Loss: 0.13584 
Epoch [112/300] Training [9/62] Loss: 0.17339 
Epoch [112/300] Training [10/62] Loss: 0.26384 
Epoch [112/300] Training [11/62] Loss: 0.13967 
Epoch [112/300] Training [12/62] Loss: 0.09531 
Epoch [112/300] Training [13/62] Loss: 0.09577 
Epoch [112/300] Training [14/62] Loss: 0.22553 
Epoch [112/300] Training [15/62] Loss: 0.24600 
Epoch [112/300] Training [16/62] Loss: 0.12647 
Epoch [112/300] Training [17/62] Loss: 0.15362 
Epoch [112/300] Training [18/62] Loss: 0.23182 
Epoch [112/300] Training [19/62] Loss: 0.24736 
Epoch [112/300] Training [20/62] Loss: 0.31965 
Epoch [112/300] Training [21/62] Loss: 0.08137 
Epoch [112/300] Training [22/62] Loss: 0.19981 
Epoch [112/300] Training [23/62] Loss: 0.15372 
Epoch [112/300] Training [24/62] Loss: 0.18019 
Epoch [112/300] Training [25/62] Loss: 0.31248 
Epoch [112/300] Training [26/62] Loss: 0.24204 
Epoch [112/300] Training [27/62] Loss: 0.12775 
Epoch [112/300] Training [28/62] Loss: 0.12188 
Epoch [112/300] Training [29/62] Loss: 0.11389 
Epoch [112/300] Training [30/62] Loss: 0.16465 
Epoch [112/300] Training [31/62] Loss: 0.28465 
Epoch [112/300] Training [32/62] Loss: 0.14363 
Epoch [112/300] Training [33/62] Loss: 0.15196 
Epoch [112/300] Training [34/62] Loss: 0.11657 
Epoch [112/300] Training [35/62] Loss: 0.15644 
Epoch [112/300] Training [36/62] Loss: 0.20985 
Epoch [112/300] Training [37/62] Loss: 0.24150 
Epoch [112/300] Training [38/62] Loss: 0.33517 
Epoch [112/300] Training [39/62] Loss: 0.32048 
Epoch [112/300] Training [40/62] Loss: 0.31796 
Epoch [112/300] Training [41/62] Loss: 0.16397 
Epoch [112/300] Training [42/62] Loss: 0.14594 
Epoch [112/300] Training [43/62] Loss: 0.23461 
Epoch [112/300] Training [44/62] Loss: 0.20673 
Epoch [112/300] Training [45/62] Loss: 0.12062 
Epoch [112/300] Training [46/62] Loss: 0.11430 
Epoch [112/300] Training [47/62] Loss: 0.13445 
Epoch [112/300] Training [48/62] Loss: 0.14877 
Epoch [112/300] Training [49/62] Loss: 0.15303 
Epoch [112/300] Training [50/62] Loss: 0.14233 
Epoch [112/300] Training [51/62] Loss: 0.11621 
Epoch [112/300] Training [52/62] Loss: 0.19327 
Epoch [112/300] Training [53/62] Loss: 0.16432 
Epoch [112/300] Training [54/62] Loss: 0.14194 
Epoch [112/300] Training [55/62] Loss: 0.12240 
Epoch [112/300] Training [56/62] Loss: 0.19823 
Epoch [112/300] Training [57/62] Loss: 0.24021 
Epoch [112/300] Training [58/62] Loss: 0.27103 
Epoch [112/300] Training [59/62] Loss: 0.09355 
Epoch [112/300] Training [60/62] Loss: 0.12870 
Epoch [112/300] Training [61/62] Loss: 0.18999 
Epoch [112/300] Training [62/62] Loss: 0.22213 
Epoch [112/300] Training metric {'Train/mean dice_metric': 0.8794682025909424, 'Train/mean miou_metric': 0.8101764917373657, 'Train/mean f1': 0.8977960348129272, 'Train/mean precision': 0.9091009497642517, 'Train/mean recall': 0.8867688775062561, 'Train/mean hd95_metric': 37.193702697753906}
Epoch [112/300] Validation [1/16] Loss: 0.73939  focal_loss 0.46308  dice_loss 0.27630 
Epoch [112/300] Validation [2/16] Loss: 0.60041  focal_loss 0.18588  dice_loss 0.41452 
Epoch [112/300] Validation [3/16] Loss: 0.60315  focal_loss 0.29912  dice_loss 0.30403 
Epoch [112/300] Validation [4/16] Loss: 0.45744  focal_loss 0.19172  dice_loss 0.26571 
Epoch [112/300] Validation [5/16] Loss: 0.42070  focal_loss 0.11109  dice_loss 0.30961 
Epoch [112/300] Validation [6/16] Loss: 0.35380  focal_loss 0.10189  dice_loss 0.25191 
Epoch [112/300] Validation [7/16] Loss: 0.35427  focal_loss 0.10200  dice_loss 0.25227 
Epoch [112/300] Validation [8/16] Loss: 0.66462  focal_loss 0.22612  dice_loss 0.43850 
Epoch [112/300] Validation [9/16] Loss: 0.26837  focal_loss 0.09122  dice_loss 0.17715 
Epoch [112/300] Validation [10/16] Loss: 0.79429  focal_loss 0.27129  dice_loss 0.52300 
Epoch [112/300] Validation [11/16] Loss: 0.25825  focal_loss 0.07413  dice_loss 0.18412 
Epoch [112/300] Validation [12/16] Loss: 0.47991  focal_loss 0.09829  dice_loss 0.38162 
Epoch [112/300] Validation [13/16] Loss: 0.39179  focal_loss 0.11469  dice_loss 0.27710 
Epoch [112/300] Validation [14/16] Loss: 0.71906  focal_loss 0.24277  dice_loss 0.47629 
Epoch [112/300] Validation [15/16] Loss: 0.18455  focal_loss 0.04655  dice_loss 0.13801 
Epoch [112/300] Validation [16/16] Loss: 0.21675  focal_loss 0.06525  dice_loss 0.15150 
Epoch [112/300] Validation metric {'Val/mean dice_metric': 0.843974769115448, 'Val/mean miou_metric': 0.7694271802902222, 'Val/mean f1': 0.8703790903091431, 'Val/mean precision': 0.8993472456932068, 'Val/mean recall': 0.8432188630104065, 'Val/mean hd95_metric': 41.4432487487793}
Cheakpoint...
Epoch [112/300] best acc:tensor([0.8511], device='cuda:0'), Now : mean acc: tensor([0.8440], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.843974769115448, 'Val/mean miou_metric': 0.7694271802902222, 'Val/mean f1': 0.8703790903091431, 'Val/mean precision': 0.8993472456932068, 'Val/mean recall': 0.8432188630104065, 'Val/mean hd95_metric': 41.4432487487793}
Epoch [113/300] Training [1/62] Loss: 0.08187 
Epoch [113/300] Training [2/62] Loss: 0.10054 
Epoch [113/300] Training [3/62] Loss: 0.15068 
Epoch [113/300] Training [4/62] Loss: 0.28003 
Epoch [113/300] Training [5/62] Loss: 0.11884 
Epoch [113/300] Training [6/62] Loss: 0.26245 
Epoch [113/300] Training [7/62] Loss: 0.15263 
Epoch [113/300] Training [8/62] Loss: 0.15285 
Epoch [113/300] Training [9/62] Loss: 0.08459 
Epoch [113/300] Training [10/62] Loss: 0.19797 
Epoch [113/300] Training [11/62] Loss: 0.14397 
Epoch [113/300] Training [12/62] Loss: 0.28419 
Epoch [113/300] Training [13/62] Loss: 0.08601 
Epoch [113/300] Training [14/62] Loss: 0.13815 
Epoch [113/300] Training [15/62] Loss: 0.08995 
Epoch [113/300] Training [16/62] Loss: 0.22629 
Epoch [113/300] Training [17/62] Loss: 0.18528 
Epoch [113/300] Training [18/62] Loss: 0.22043 
Epoch [113/300] Training [19/62] Loss: 0.19858 
Epoch [113/300] Training [20/62] Loss: 0.07050 
Epoch [113/300] Training [21/62] Loss: 0.10903 
Epoch [113/300] Training [22/62] Loss: 0.11144 
Epoch [113/300] Training [23/62] Loss: 0.10718 
Epoch [113/300] Training [24/62] Loss: 0.13655 
Epoch [113/300] Training [25/62] Loss: 0.13438 
Epoch [113/300] Training [26/62] Loss: 0.23842 
Epoch [113/300] Training [27/62] Loss: 0.16402 
Epoch [113/300] Training [28/62] Loss: 0.20309 
Epoch [113/300] Training [29/62] Loss: 0.16396 
Epoch [113/300] Training [30/62] Loss: 0.11735 
Epoch [113/300] Training [31/62] Loss: 0.19068 
Epoch [113/300] Training [32/62] Loss: 0.07978 
Epoch [113/300] Training [33/62] Loss: 0.31514 
Epoch [113/300] Training [34/62] Loss: 0.16509 
Epoch [113/300] Training [35/62] Loss: 0.17634 
Epoch [113/300] Training [36/62] Loss: 0.06848 
Epoch [113/300] Training [37/62] Loss: 0.18647 
Epoch [113/300] Training [38/62] Loss: 0.13562 
Epoch [113/300] Training [39/62] Loss: 0.11041 
Epoch [113/300] Training [40/62] Loss: 0.09203 
Epoch [113/300] Training [41/62] Loss: 0.30760 
Epoch [113/300] Training [42/62] Loss: 0.19244 
Epoch [113/300] Training [43/62] Loss: 0.11151 
Epoch [113/300] Training [44/62] Loss: 0.08953 
Epoch [113/300] Training [45/62] Loss: 0.19627 
Epoch [113/300] Training [46/62] Loss: 0.24767 
Epoch [113/300] Training [47/62] Loss: 0.21786 
Epoch [113/300] Training [48/62] Loss: 0.12866 
Epoch [113/300] Training [49/62] Loss: 0.14367 
Epoch [113/300] Training [50/62] Loss: 0.10768 
Epoch [113/300] Training [51/62] Loss: 0.08887 
Epoch [113/300] Training [52/62] Loss: 0.12206 
Epoch [113/300] Training [53/62] Loss: 0.12800 
Epoch [113/300] Training [54/62] Loss: 0.20868 
Epoch [113/300] Training [55/62] Loss: 0.16343 
Epoch [113/300] Training [56/62] Loss: 0.25271 
Epoch [113/300] Training [57/62] Loss: 0.13649 
Epoch [113/300] Training [58/62] Loss: 0.14538 
Epoch [113/300] Training [59/62] Loss: 0.13730 
Epoch [113/300] Training [60/62] Loss: 0.24441 
Epoch [113/300] Training [61/62] Loss: 0.17441 
Epoch [113/300] Training [62/62] Loss: 0.08248 
Epoch [113/300] Training metric {'Train/mean dice_metric': 0.889848530292511, 'Train/mean miou_metric': 0.8231958150863647, 'Train/mean f1': 0.9126642942428589, 'Train/mean precision': 0.9088742733001709, 'Train/mean recall': 0.9164860248565674, 'Train/mean hd95_metric': 29.765493392944336}
Epoch [113/300] Validation [1/16] Loss: 0.74961  focal_loss 0.42791  dice_loss 0.32170 
Epoch [113/300] Validation [2/16] Loss: 0.43248  focal_loss 0.11688  dice_loss 0.31560 
Epoch [113/300] Validation [3/16] Loss: 0.63849  focal_loss 0.30665  dice_loss 0.33185 
Epoch [113/300] Validation [4/16] Loss: 0.40900  focal_loss 0.14325  dice_loss 0.26575 
Epoch [113/300] Validation [5/16] Loss: 0.41839  focal_loss 0.10560  dice_loss 0.31279 
Epoch [113/300] Validation [6/16] Loss: 0.42414  focal_loss 0.13354  dice_loss 0.29060 
Epoch [113/300] Validation [7/16] Loss: 0.27384  focal_loss 0.10620  dice_loss 0.16764 
Epoch [113/300] Validation [8/16] Loss: 0.50573  focal_loss 0.15531  dice_loss 0.35043 
Epoch [113/300] Validation [9/16] Loss: 0.32826  focal_loss 0.09882  dice_loss 0.22944 
Epoch [113/300] Validation [10/16] Loss: 0.64578  focal_loss 0.16971  dice_loss 0.47607 
Epoch [113/300] Validation [11/16] Loss: 0.26426  focal_loss 0.07705  dice_loss 0.18721 
Epoch [113/300] Validation [12/16] Loss: 0.53125  focal_loss 0.09808  dice_loss 0.43317 
Epoch [113/300] Validation [13/16] Loss: 0.39224  focal_loss 0.12787  dice_loss 0.26437 
Epoch [113/300] Validation [14/16] Loss: 0.57314  focal_loss 0.16918  dice_loss 0.40396 
Epoch [113/300] Validation [15/16] Loss: 0.29815  focal_loss 0.11086  dice_loss 0.18729 
Epoch [113/300] Validation [16/16] Loss: 0.16436  focal_loss 0.04959  dice_loss 0.11477 
Epoch [113/300] Validation metric {'Val/mean dice_metric': 0.8550881743431091, 'Val/mean miou_metric': 0.7804442048072815, 'Val/mean f1': 0.8833311796188354, 'Val/mean precision': 0.8927835822105408, 'Val/mean recall': 0.8740768432617188, 'Val/mean hd95_metric': 35.99180221557617}
Cheakpoint...
Epoch [113/300] best acc:tensor([0.8551], device='cuda:0'), Now : mean acc: tensor([0.8551], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8550881743431091, 'Val/mean miou_metric': 0.7804442048072815, 'Val/mean f1': 0.8833311796188354, 'Val/mean precision': 0.8927835822105408, 'Val/mean recall': 0.8740768432617188, 'Val/mean hd95_metric': 35.99180221557617}
Epoch [114/300] Training [1/62] Loss: 0.13327 
Epoch [114/300] Training [2/62] Loss: 0.29641 
Epoch [114/300] Training [3/62] Loss: 0.10915 
Epoch [114/300] Training [4/62] Loss: 0.24359 
Epoch [114/300] Training [5/62] Loss: 0.10345 
Epoch [114/300] Training [6/62] Loss: 0.11430 
Epoch [114/300] Training [7/62] Loss: 0.16229 
Epoch [114/300] Training [8/62] Loss: 0.10902 
Epoch [114/300] Training [9/62] Loss: 0.09539 
Epoch [114/300] Training [10/62] Loss: 0.08784 
Epoch [114/300] Training [11/62] Loss: 0.31398 
Epoch [114/300] Training [12/62] Loss: 0.25047 
Epoch [114/300] Training [13/62] Loss: 0.23577 
Epoch [114/300] Training [14/62] Loss: 0.11292 
Epoch [114/300] Training [15/62] Loss: 0.12890 
Epoch [114/300] Training [16/62] Loss: 0.16459 
Epoch [114/300] Training [17/62] Loss: 0.09095 
Epoch [114/300] Training [18/62] Loss: 0.17193 
Epoch [114/300] Training [19/62] Loss: 0.09166 
Epoch [114/300] Training [20/62] Loss: 0.28331 
Epoch [114/300] Training [21/62] Loss: 0.33819 
Epoch [114/300] Training [22/62] Loss: 0.32064 
Epoch [114/300] Training [23/62] Loss: 0.07883 
Epoch [114/300] Training [24/62] Loss: 0.23868 
Epoch [114/300] Training [25/62] Loss: 0.17562 
Epoch [114/300] Training [26/62] Loss: 0.12362 
Epoch [114/300] Training [27/62] Loss: 0.36962 
Epoch [114/300] Training [28/62] Loss: 0.11527 
Epoch [114/300] Training [29/62] Loss: 0.10840 
Epoch [114/300] Training [30/62] Loss: 0.12671 
Epoch [114/300] Training [31/62] Loss: 0.14325 
Epoch [114/300] Training [32/62] Loss: 0.21087 
Epoch [114/300] Training [33/62] Loss: 0.19215 
Epoch [114/300] Training [34/62] Loss: 0.11992 
Epoch [114/300] Training [35/62] Loss: 0.25488 
Epoch [114/300] Training [36/62] Loss: 0.21282 
Epoch [114/300] Training [37/62] Loss: 0.21333 
Epoch [114/300] Training [38/62] Loss: 0.20462 
Epoch [114/300] Training [39/62] Loss: 0.14368 
Epoch [114/300] Training [40/62] Loss: 0.21561 
Epoch [114/300] Training [41/62] Loss: 0.14098 
Epoch [114/300] Training [42/62] Loss: 0.14435 
Epoch [114/300] Training [43/62] Loss: 0.18521 
Epoch [114/300] Training [44/62] Loss: 0.15300 
Epoch [114/300] Training [45/62] Loss: 0.11539 
Epoch [114/300] Training [46/62] Loss: 0.16125 
Epoch [114/300] Training [47/62] Loss: 0.11926 
Epoch [114/300] Training [48/62] Loss: 0.15113 
Epoch [114/300] Training [49/62] Loss: 0.21840 
Epoch [114/300] Training [50/62] Loss: 0.18543 
Epoch [114/300] Training [51/62] Loss: 0.08001 
Epoch [114/300] Training [52/62] Loss: 0.30065 
Epoch [114/300] Training [53/62] Loss: 0.12598 
Epoch [114/300] Training [54/62] Loss: 0.09740 
Epoch [114/300] Training [55/62] Loss: 0.16860 
Epoch [114/300] Training [56/62] Loss: 0.17498 
Epoch [114/300] Training [57/62] Loss: 0.10781 
Epoch [114/300] Training [58/62] Loss: 0.14041 
Epoch [114/300] Training [59/62] Loss: 0.08231 
Epoch [114/300] Training [60/62] Loss: 0.25058 
Epoch [114/300] Training [61/62] Loss: 0.12000 
Epoch [114/300] Training [62/62] Loss: 0.04761 
Epoch [114/300] Training metric {'Train/mean dice_metric': 0.8829517960548401, 'Train/mean miou_metric': 0.8166428208351135, 'Train/mean f1': 0.9058018922805786, 'Train/mean precision': 0.9063655734062195, 'Train/mean recall': 0.9052390456199646, 'Train/mean hd95_metric': 30.182235717773438}
Epoch [114/300] Validation [1/16] Loss: 0.61084  focal_loss 0.34343  dice_loss 0.26741 
Epoch [114/300] Validation [2/16] Loss: 0.57292  focal_loss 0.18169  dice_loss 0.39123 
Epoch [114/300] Validation [3/16] Loss: 0.62333  focal_loss 0.27237  dice_loss 0.35096 
Epoch [114/300] Validation [4/16] Loss: 0.40643  focal_loss 0.15357  dice_loss 0.25286 
Epoch [114/300] Validation [5/16] Loss: 0.45682  focal_loss 0.10340  dice_loss 0.35342 
Epoch [114/300] Validation [6/16] Loss: 0.44079  focal_loss 0.12974  dice_loss 0.31105 
Epoch [114/300] Validation [7/16] Loss: 0.32974  focal_loss 0.10393  dice_loss 0.22581 
Epoch [114/300] Validation [8/16] Loss: 0.56188  focal_loss 0.11952  dice_loss 0.44236 
Epoch [114/300] Validation [9/16] Loss: 0.57750  focal_loss 0.24519  dice_loss 0.33231 
Epoch [114/300] Validation [10/16] Loss: 0.46822  focal_loss 0.13155  dice_loss 0.33667 
Epoch [114/300] Validation [11/16] Loss: 0.48424  focal_loss 0.13276  dice_loss 0.35148 
Epoch [114/300] Validation [12/16] Loss: 0.58417  focal_loss 0.12854  dice_loss 0.45563 
Epoch [114/300] Validation [13/16] Loss: 0.36612  focal_loss 0.08583  dice_loss 0.28029 
Epoch [114/300] Validation [14/16] Loss: 0.81649  focal_loss 0.25293  dice_loss 0.56357 
Epoch [114/300] Validation [15/16] Loss: 0.23107  focal_loss 0.07480  dice_loss 0.15627 
Epoch [114/300] Validation [16/16] Loss: 0.30970  focal_loss 0.09739  dice_loss 0.21231 
Epoch [114/300] Validation metric {'Val/mean dice_metric': 0.8415352702140808, 'Val/mean miou_metric': 0.7673918604850769, 'Val/mean f1': 0.8703230023384094, 'Val/mean precision': 0.8648545742034912, 'Val/mean recall': 0.8758611083030701, 'Val/mean hd95_metric': 41.752403259277344}
Cheakpoint...
Epoch [114/300] best acc:tensor([0.8551], device='cuda:0'), Now : mean acc: tensor([0.8415], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8415352702140808, 'Val/mean miou_metric': 0.7673918604850769, 'Val/mean f1': 0.8703230023384094, 'Val/mean precision': 0.8648545742034912, 'Val/mean recall': 0.8758611083030701, 'Val/mean hd95_metric': 41.752403259277344}
Epoch [115/300] Training [1/62] Loss: 0.08270 
Epoch [115/300] Training [2/62] Loss: 0.27633 
Epoch [115/300] Training [3/62] Loss: 0.17014 
Epoch [115/300] Training [4/62] Loss: 0.16114 
Epoch [115/300] Training [5/62] Loss: 0.14791 
Epoch [115/300] Training [6/62] Loss: 0.18888 
Epoch [115/300] Training [7/62] Loss: 0.33217 
Epoch [115/300] Training [8/62] Loss: 0.08343 
Epoch [115/300] Training [9/62] Loss: 0.19574 
Epoch [115/300] Training [10/62] Loss: 0.28989 
Epoch [115/300] Training [11/62] Loss: 0.13132 
Epoch [115/300] Training [12/62] Loss: 0.09167 
Epoch [115/300] Training [13/62] Loss: 0.14622 
Epoch [115/300] Training [14/62] Loss: 0.16520 
Epoch [115/300] Training [15/62] Loss: 0.09400 
Epoch [115/300] Training [16/62] Loss: 0.11543 
Epoch [115/300] Training [17/62] Loss: 0.34564 
Epoch [115/300] Training [18/62] Loss: 0.12663 
Epoch [115/300] Training [19/62] Loss: 0.09374 
Epoch [115/300] Training [20/62] Loss: 0.22221 
Epoch [115/300] Training [21/62] Loss: 0.10239 
Epoch [115/300] Training [22/62] Loss: 0.19381 
Epoch [115/300] Training [23/62] Loss: 0.11153 
Epoch [115/300] Training [24/62] Loss: 0.29930 
Epoch [115/300] Training [25/62] Loss: 0.10893 
Epoch [115/300] Training [26/62] Loss: 0.07458 
Epoch [115/300] Training [27/62] Loss: 0.27889 
Epoch [115/300] Training [28/62] Loss: 0.11293 
Epoch [115/300] Training [29/62] Loss: 0.09209 
Epoch [115/300] Training [30/62] Loss: 0.12288 
Epoch [115/300] Training [31/62] Loss: 0.10134 
Epoch [115/300] Training [32/62] Loss: 0.12491 
Epoch [115/300] Training [33/62] Loss: 0.20952 
Epoch [115/300] Training [34/62] Loss: 0.12481 
Epoch [115/300] Training [35/62] Loss: 0.17644 
Epoch [115/300] Training [36/62] Loss: 0.31886 
Epoch [115/300] Training [37/62] Loss: 0.09928 
Epoch [115/300] Training [38/62] Loss: 0.18170 
Epoch [115/300] Training [39/62] Loss: 0.18481 
Epoch [115/300] Training [40/62] Loss: 0.10614 
Epoch [115/300] Training [41/62] Loss: 0.15316 
Epoch [115/300] Training [42/62] Loss: 0.29832 
Epoch [115/300] Training [43/62] Loss: 0.20935 
Epoch [115/300] Training [44/62] Loss: 0.10818 
Epoch [115/300] Training [45/62] Loss: 0.19942 
Epoch [115/300] Training [46/62] Loss: 0.10317 
Epoch [115/300] Training [47/62] Loss: 0.19076 
Epoch [115/300] Training [48/62] Loss: 0.21997 
Epoch [115/300] Training [49/62] Loss: 0.10544 
Epoch [115/300] Training [50/62] Loss: 0.28809 
Epoch [115/300] Training [51/62] Loss: 0.20570 
Epoch [115/300] Training [52/62] Loss: 0.20363 
Epoch [115/300] Training [53/62] Loss: 0.12768 
Epoch [115/300] Training [54/62] Loss: 0.22190 
Epoch [115/300] Training [55/62] Loss: 0.08269 
Epoch [115/300] Training [56/62] Loss: 0.31026 
Epoch [115/300] Training [57/62] Loss: 0.16865 
Epoch [115/300] Training [58/62] Loss: 0.19141 
Epoch [115/300] Training [59/62] Loss: 0.21455 
Epoch [115/300] Training [60/62] Loss: 0.12759 
Epoch [115/300] Training [61/62] Loss: 0.15883 
Epoch [115/300] Training [62/62] Loss: 0.18688 
Epoch [115/300] Training metric {'Train/mean dice_metric': 0.8849371075630188, 'Train/mean miou_metric': 0.8165040016174316, 'Train/mean f1': 0.9052733778953552, 'Train/mean precision': 0.9065383672714233, 'Train/mean recall': 0.9040119051933289, 'Train/mean hd95_metric': 33.00368118286133}
Epoch [115/300] Validation [1/16] Loss: 0.66121  focal_loss 0.37316  dice_loss 0.28805 
Epoch [115/300] Validation [2/16] Loss: 0.45916  focal_loss 0.14588  dice_loss 0.31328 
Epoch [115/300] Validation [3/16] Loss: 0.62474  focal_loss 0.28963  dice_loss 0.33511 
Epoch [115/300] Validation [4/16] Loss: 0.40773  focal_loss 0.16531  dice_loss 0.24242 
Epoch [115/300] Validation [5/16] Loss: 0.33715  focal_loss 0.09675  dice_loss 0.24040 
Epoch [115/300] Validation [6/16] Loss: 0.30199  focal_loss 0.08173  dice_loss 0.22026 
Epoch [115/300] Validation [7/16] Loss: 0.25052  focal_loss 0.08361  dice_loss 0.16691 
Epoch [115/300] Validation [8/16] Loss: 0.46031  focal_loss 0.15067  dice_loss 0.30963 
Epoch [115/300] Validation [9/16] Loss: 0.30558  focal_loss 0.09541  dice_loss 0.21018 
Epoch [115/300] Validation [10/16] Loss: 0.44852  focal_loss 0.11808  dice_loss 0.33044 
Epoch [115/300] Validation [11/16] Loss: 0.25287  focal_loss 0.08204  dice_loss 0.17083 
Epoch [115/300] Validation [12/16] Loss: 0.43517  focal_loss 0.09898  dice_loss 0.33619 
Epoch [115/300] Validation [13/16] Loss: 0.26837  focal_loss 0.07801  dice_loss 0.19036 
Epoch [115/300] Validation [14/16] Loss: 0.64200  focal_loss 0.18888  dice_loss 0.45312 
Epoch [115/300] Validation [15/16] Loss: 0.22030  focal_loss 0.07431  dice_loss 0.14599 
Epoch [115/300] Validation [16/16] Loss: 0.27821  focal_loss 0.08554  dice_loss 0.19267 
Epoch [115/300] Validation metric {'Val/mean dice_metric': 0.8580543398857117, 'Val/mean miou_metric': 0.7832400798797607, 'Val/mean f1': 0.882045567035675, 'Val/mean precision': 0.8965440988540649, 'Val/mean recall': 0.868008553981781, 'Val/mean hd95_metric': 37.650054931640625}
Cheakpoint...
Epoch [115/300] best acc:tensor([0.8581], device='cuda:0'), Now : mean acc: tensor([0.8581], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8580543398857117, 'Val/mean miou_metric': 0.7832400798797607, 'Val/mean f1': 0.882045567035675, 'Val/mean precision': 0.8965440988540649, 'Val/mean recall': 0.868008553981781, 'Val/mean hd95_metric': 37.650054931640625}
Epoch [116/300] Training [1/62] Loss: 0.13625 
Epoch [116/300] Training [2/62] Loss: 0.07825 
Epoch [116/300] Training [3/62] Loss: 0.13282 
Epoch [116/300] Training [4/62] Loss: 0.20792 
Epoch [116/300] Training [5/62] Loss: 0.11139 
Epoch [116/300] Training [6/62] Loss: 0.10692 
Epoch [116/300] Training [7/62] Loss: 0.16261 
Epoch [116/300] Training [8/62] Loss: 0.24214 
Epoch [116/300] Training [9/62] Loss: 0.15537 
Epoch [116/300] Training [10/62] Loss: 0.17732 
Epoch [116/300] Training [11/62] Loss: 0.21350 
Epoch [116/300] Training [12/62] Loss: 0.31104 
Epoch [116/300] Training [13/62] Loss: 0.17106 
Epoch [116/300] Training [14/62] Loss: 0.23163 
Epoch [116/300] Training [15/62] Loss: 0.23567 
Epoch [116/300] Training [16/62] Loss: 0.12494 
Epoch [116/300] Training [17/62] Loss: 0.14729 
Epoch [116/300] Training [18/62] Loss: 0.16641 
Epoch [116/300] Training [19/62] Loss: 0.13179 
Epoch [116/300] Training [20/62] Loss: 0.12068 
Epoch [116/300] Training [21/62] Loss: 0.20440 
Epoch [116/300] Training [22/62] Loss: 0.13299 
Epoch [116/300] Training [23/62] Loss: 0.23364 
Epoch [116/300] Training [24/62] Loss: 0.09259 
Epoch [116/300] Training [25/62] Loss: 0.28265 
Epoch [116/300] Training [26/62] Loss: 0.21058 
Epoch [116/300] Training [27/62] Loss: 0.08681 
Epoch [116/300] Training [28/62] Loss: 0.17099 
Epoch [116/300] Training [29/62] Loss: 0.11207 
Epoch [116/300] Training [30/62] Loss: 0.12006 
Epoch [116/300] Training [31/62] Loss: 0.10417 
Epoch [116/300] Training [32/62] Loss: 0.22357 
Epoch [116/300] Training [33/62] Loss: 0.09896 
Epoch [116/300] Training [34/62] Loss: 0.10997 
Epoch [116/300] Training [35/62] Loss: 0.10255 
Epoch [116/300] Training [36/62] Loss: 0.15340 
Epoch [116/300] Training [37/62] Loss: 0.37295 
Epoch [116/300] Training [38/62] Loss: 0.20303 
Epoch [116/300] Training [39/62] Loss: 0.10127 
Epoch [116/300] Training [40/62] Loss: 0.18186 
Epoch [116/300] Training [41/62] Loss: 0.17936 
Epoch [116/300] Training [42/62] Loss: 0.18141 
Epoch [116/300] Training [43/62] Loss: 0.21616 
Epoch [116/300] Training [44/62] Loss: 0.21263 
Epoch [116/300] Training [45/62] Loss: 0.31102 
Epoch [116/300] Training [46/62] Loss: 0.10736 
Epoch [116/300] Training [47/62] Loss: 0.11847 
Epoch [116/300] Training [48/62] Loss: 0.25814 
Epoch [116/300] Training [49/62] Loss: 0.13408 
Epoch [116/300] Training [50/62] Loss: 0.09208 
Epoch [116/300] Training [51/62] Loss: 0.23860 
Epoch [116/300] Training [52/62] Loss: 0.26433 
Epoch [116/300] Training [53/62] Loss: 0.25292 
Epoch [116/300] Training [54/62] Loss: 0.13011 
Epoch [116/300] Training [55/62] Loss: 0.08727 
Epoch [116/300] Training [56/62] Loss: 0.35301 
Epoch [116/300] Training [57/62] Loss: 0.21718 
Epoch [116/300] Training [58/62] Loss: 0.27919 
Epoch [116/300] Training [59/62] Loss: 0.11023 
Epoch [116/300] Training [60/62] Loss: 0.14311 
Epoch [116/300] Training [61/62] Loss: 0.07761 
Epoch [116/300] Training [62/62] Loss: 0.39411 
Epoch [116/300] Training metric {'Train/mean dice_metric': 0.882291853427887, 'Train/mean miou_metric': 0.8115925788879395, 'Train/mean f1': 0.9032952785491943, 'Train/mean precision': 0.909613847732544, 'Train/mean recall': 0.8970640301704407, 'Train/mean hd95_metric': 34.561607360839844}
Epoch [116/300] Validation [1/16] Loss: 0.63929  focal_loss 0.36981  dice_loss 0.26948 
Epoch [116/300] Validation [2/16] Loss: 0.50713  focal_loss 0.17361  dice_loss 0.33352 
Epoch [116/300] Validation [3/16] Loss: 0.50780  focal_loss 0.20516  dice_loss 0.30265 
Epoch [116/300] Validation [4/16] Loss: 0.42681  focal_loss 0.17188  dice_loss 0.25493 
Epoch [116/300] Validation [5/16] Loss: 0.45508  focal_loss 0.11403  dice_loss 0.34105 
Epoch [116/300] Validation [6/16] Loss: 0.37472  focal_loss 0.07860  dice_loss 0.29611 
Epoch [116/300] Validation [7/16] Loss: 0.20903  focal_loss 0.06414  dice_loss 0.14489 
Epoch [116/300] Validation [8/16] Loss: 0.52157  focal_loss 0.15706  dice_loss 0.36450 
Epoch [116/300] Validation [9/16] Loss: 0.41458  focal_loss 0.15732  dice_loss 0.25727 
Epoch [116/300] Validation [10/16] Loss: 0.47489  focal_loss 0.15517  dice_loss 0.31972 
Epoch [116/300] Validation [11/16] Loss: 0.22307  focal_loss 0.06309  dice_loss 0.15998 
Epoch [116/300] Validation [12/16] Loss: 0.40465  focal_loss 0.08629  dice_loss 0.31837 
Epoch [116/300] Validation [13/16] Loss: 0.29447  focal_loss 0.08947  dice_loss 0.20500 
Epoch [116/300] Validation [14/16] Loss: 0.61906  focal_loss 0.20434  dice_loss 0.41472 
Epoch [116/300] Validation [15/16] Loss: 0.19852  focal_loss 0.06210  dice_loss 0.13641 
Epoch [116/300] Validation [16/16] Loss: 0.21155  focal_loss 0.06850  dice_loss 0.14305 
Epoch [116/300] Validation metric {'Val/mean dice_metric': 0.8551161885261536, 'Val/mean miou_metric': 0.7786284685134888, 'Val/mean f1': 0.8779435753822327, 'Val/mean precision': 0.8986436724662781, 'Val/mean recall': 0.8581756353378296, 'Val/mean hd95_metric': 40.787784576416016}
Cheakpoint...
Epoch [116/300] best acc:tensor([0.8581], device='cuda:0'), Now : mean acc: tensor([0.8551], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8551161885261536, 'Val/mean miou_metric': 0.7786284685134888, 'Val/mean f1': 0.8779435753822327, 'Val/mean precision': 0.8986436724662781, 'Val/mean recall': 0.8581756353378296, 'Val/mean hd95_metric': 40.787784576416016}
Epoch [117/300] Training [1/62] Loss: 0.35327 
Epoch [117/300] Training [2/62] Loss: 0.26932 
Epoch [117/300] Training [3/62] Loss: 0.15037 
Epoch [117/300] Training [4/62] Loss: 0.15325 
Epoch [117/300] Training [5/62] Loss: 0.17625 
Epoch [117/300] Training [6/62] Loss: 0.11824 
Epoch [117/300] Training [7/62] Loss: 0.16874 
Epoch [117/300] Training [8/62] Loss: 0.23886 
Epoch [117/300] Training [9/62] Loss: 0.17892 
Epoch [117/300] Training [10/62] Loss: 0.15409 
Epoch [117/300] Training [11/62] Loss: 0.13766 
Epoch [117/300] Training [12/62] Loss: 0.08394 
Epoch [117/300] Training [13/62] Loss: 0.15802 
Epoch [117/300] Training [14/62] Loss: 0.18444 
Epoch [117/300] Training [15/62] Loss: 0.15535 
Epoch [117/300] Training [16/62] Loss: 0.13140 
Epoch [117/300] Training [17/62] Loss: 0.16224 
Epoch [117/300] Training [18/62] Loss: 0.16238 
Epoch [117/300] Training [19/62] Loss: 0.09365 
Epoch [117/300] Training [20/62] Loss: 0.22036 
Epoch [117/300] Training [21/62] Loss: 0.19967 
Epoch [117/300] Training [22/62] Loss: 0.19363 
Epoch [117/300] Training [23/62] Loss: 0.10149 
Epoch [117/300] Training [24/62] Loss: 0.09404 
Epoch [117/300] Training [25/62] Loss: 0.18645 
Epoch [117/300] Training [26/62] Loss: 0.11715 
Epoch [117/300] Training [27/62] Loss: 0.13651 
Epoch [117/300] Training [28/62] Loss: 0.21298 
Epoch [117/300] Training [29/62] Loss: 0.33144 
Epoch [117/300] Training [30/62] Loss: 0.17344 
Epoch [117/300] Training [31/62] Loss: 0.09978 
Epoch [117/300] Training [32/62] Loss: 0.07313 
Epoch [117/300] Training [33/62] Loss: 0.25909 
Epoch [117/300] Training [34/62] Loss: 0.12646 
Epoch [117/300] Training [35/62] Loss: 0.26920 
Epoch [117/300] Training [36/62] Loss: 0.13020 
Epoch [117/300] Training [37/62] Loss: 0.10367 
Epoch [117/300] Training [38/62] Loss: 0.09179 
Epoch [117/300] Training [39/62] Loss: 0.13499 
Epoch [117/300] Training [40/62] Loss: 0.22818 
Epoch [117/300] Training [41/62] Loss: 0.11458 
Epoch [117/300] Training [42/62] Loss: 0.09916 
Epoch [117/300] Training [43/62] Loss: 0.14112 
Epoch [117/300] Training [44/62] Loss: 0.18798 
Epoch [117/300] Training [45/62] Loss: 0.11883 
Epoch [117/300] Training [46/62] Loss: 0.18267 
Epoch [117/300] Training [47/62] Loss: 0.05899 
Epoch [117/300] Training [48/62] Loss: 0.23831 
Epoch [117/300] Training [49/62] Loss: 0.28108 
Epoch [117/300] Training [50/62] Loss: 0.11029 
Epoch [117/300] Training [51/62] Loss: 0.25484 
Epoch [117/300] Training [52/62] Loss: 0.13962 
Epoch [117/300] Training [53/62] Loss: 0.26531 
Epoch [117/300] Training [54/62] Loss: 0.23222 
Epoch [117/300] Training [55/62] Loss: 0.18547 
Epoch [117/300] Training [56/62] Loss: 0.08713 
Epoch [117/300] Training [57/62] Loss: 0.10104 
Epoch [117/300] Training [58/62] Loss: 0.20210 
Epoch [117/300] Training [59/62] Loss: 0.22806 
Epoch [117/300] Training [60/62] Loss: 0.12694 
Epoch [117/300] Training [61/62] Loss: 0.30505 
Epoch [117/300] Training [62/62] Loss: 0.22651 
Epoch [117/300] Training metric {'Train/mean dice_metric': 0.8900976181030273, 'Train/mean miou_metric': 0.8238883018493652, 'Train/mean f1': 0.901581883430481, 'Train/mean precision': 0.9146122336387634, 'Train/mean recall': 0.8889176845550537, 'Train/mean hd95_metric': 32.36346435546875}
Epoch [117/300] Validation [1/16] Loss: 0.63830  focal_loss 0.35375  dice_loss 0.28455 
Epoch [117/300] Validation [2/16] Loss: 0.45864  focal_loss 0.13782  dice_loss 0.32082 
Epoch [117/300] Validation [3/16] Loss: 0.62500  focal_loss 0.28672  dice_loss 0.33828 
Epoch [117/300] Validation [4/16] Loss: 0.30080  focal_loss 0.13505  dice_loss 0.16575 
Epoch [117/300] Validation [5/16] Loss: 0.33106  focal_loss 0.07980  dice_loss 0.25126 
Epoch [117/300] Validation [6/16] Loss: 0.33981  focal_loss 0.07731  dice_loss 0.26250 
Epoch [117/300] Validation [7/16] Loss: 0.27049  focal_loss 0.08528  dice_loss 0.18521 
Epoch [117/300] Validation [8/16] Loss: 0.77013  focal_loss 0.21865  dice_loss 0.55148 
Epoch [117/300] Validation [9/16] Loss: 0.32329  focal_loss 0.09441  dice_loss 0.22888 
Epoch [117/300] Validation [10/16] Loss: 0.54544  focal_loss 0.10878  dice_loss 0.43666 
Epoch [117/300] Validation [11/16] Loss: 0.19635  focal_loss 0.04903  dice_loss 0.14732 
Epoch [117/300] Validation [12/16] Loss: 0.41930  focal_loss 0.10709  dice_loss 0.31220 
Epoch [117/300] Validation [13/16] Loss: 0.30604  focal_loss 0.08886  dice_loss 0.21719 
Epoch [117/300] Validation [14/16] Loss: 0.70646  focal_loss 0.23932  dice_loss 0.46714 
Epoch [117/300] Validation [15/16] Loss: 0.28630  focal_loss 0.11312  dice_loss 0.17318 
Epoch [117/300] Validation [16/16] Loss: 0.27382  focal_loss 0.07837  dice_loss 0.19546 
Epoch [117/300] Validation metric {'Val/mean dice_metric': 0.856574535369873, 'Val/mean miou_metric': 0.7839124202728271, 'Val/mean f1': 0.8769084811210632, 'Val/mean precision': 0.9002758264541626, 'Val/mean recall': 0.854723334312439, 'Val/mean hd95_metric': 39.5740966796875}
Cheakpoint...
Epoch [117/300] best acc:tensor([0.8581], device='cuda:0'), Now : mean acc: tensor([0.8566], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.856574535369873, 'Val/mean miou_metric': 0.7839124202728271, 'Val/mean f1': 0.8769084811210632, 'Val/mean precision': 0.9002758264541626, 'Val/mean recall': 0.854723334312439, 'Val/mean hd95_metric': 39.5740966796875}
Epoch [118/300] Training [1/62] Loss: 0.20604 
Epoch [118/300] Training [2/62] Loss: 0.17399 
Epoch [118/300] Training [3/62] Loss: 0.09369 
Epoch [118/300] Training [4/62] Loss: 0.10530 
Epoch [118/300] Training [5/62] Loss: 0.10174 
Epoch [118/300] Training [6/62] Loss: 0.07806 
Epoch [118/300] Training [7/62] Loss: 0.15189 
Epoch [118/300] Training [8/62] Loss: 0.09395 
Epoch [118/300] Training [9/62] Loss: 0.12414 
Epoch [118/300] Training [10/62] Loss: 0.08682 
Epoch [118/300] Training [11/62] Loss: 0.19411 
Epoch [118/300] Training [12/62] Loss: 0.27777 
Epoch [118/300] Training [13/62] Loss: 0.12861 
Epoch [118/300] Training [14/62] Loss: 0.17161 
Epoch [118/300] Training [15/62] Loss: 0.09243 
Epoch [118/300] Training [16/62] Loss: 0.13244 
Epoch [118/300] Training [17/62] Loss: 0.15565 
Epoch [118/300] Training [18/62] Loss: 0.15695 
Epoch [118/300] Training [19/62] Loss: 0.18931 
Epoch [118/300] Training [20/62] Loss: 0.09126 
Epoch [118/300] Training [21/62] Loss: 0.12238 
Epoch [118/300] Training [22/62] Loss: 0.10188 
Epoch [118/300] Training [23/62] Loss: 0.09446 
Epoch [118/300] Training [24/62] Loss: 0.15025 
Epoch [118/300] Training [25/62] Loss: 0.07474 
Epoch [118/300] Training [26/62] Loss: 0.18734 
Epoch [118/300] Training [27/62] Loss: 0.23773 
Epoch [118/300] Training [28/62] Loss: 0.15345 
Epoch [118/300] Training [29/62] Loss: 0.23782 
Epoch [118/300] Training [30/62] Loss: 0.11949 
Epoch [118/300] Training [31/62] Loss: 0.18976 
Epoch [118/300] Training [32/62] Loss: 0.07478 
Epoch [118/300] Training [33/62] Loss: 0.15980 
Epoch [118/300] Training [34/62] Loss: 0.22503 
Epoch [118/300] Training [35/62] Loss: 0.12574 
Epoch [118/300] Training [36/62] Loss: 0.20615 
Epoch [118/300] Training [37/62] Loss: 0.17865 
Epoch [118/300] Training [38/62] Loss: 0.17886 
Epoch [118/300] Training [39/62] Loss: 0.24746 
Epoch [118/300] Training [40/62] Loss: 0.15843 
Epoch [118/300] Training [41/62] Loss: 0.19559 
Epoch [118/300] Training [42/62] Loss: 0.29054 
Epoch [118/300] Training [43/62] Loss: 0.13813 
Epoch [118/300] Training [44/62] Loss: 0.12765 
Epoch [118/300] Training [45/62] Loss: 0.28951 
Epoch [118/300] Training [46/62] Loss: 0.14844 
Epoch [118/300] Training [47/62] Loss: 0.08777 
Epoch [118/300] Training [48/62] Loss: 0.14247 
Epoch [118/300] Training [49/62] Loss: 0.20954 
Epoch [118/300] Training [50/62] Loss: 0.14184 
Epoch [118/300] Training [51/62] Loss: 0.12408 
Epoch [118/300] Training [52/62] Loss: 0.21727 
Epoch [118/300] Training [53/62] Loss: 0.09002 
Epoch [118/300] Training [54/62] Loss: 0.17768 
Epoch [118/300] Training [55/62] Loss: 0.11111 
Epoch [118/300] Training [56/62] Loss: 0.19740 
Epoch [118/300] Training [57/62] Loss: 0.15155 
Epoch [118/300] Training [58/62] Loss: 0.21044 
Epoch [118/300] Training [59/62] Loss: 0.12123 
Epoch [118/300] Training [60/62] Loss: 0.10409 
Epoch [118/300] Training [61/62] Loss: 0.11384 
Epoch [118/300] Training [62/62] Loss: 1.70159 
Epoch [118/300] Training metric {'Train/mean dice_metric': 0.8947409391403198, 'Train/mean miou_metric': 0.8292623162269592, 'Train/mean f1': 0.9105690121650696, 'Train/mean precision': 0.9144364595413208, 'Train/mean recall': 0.9067341685295105, 'Train/mean hd95_metric': 31.37260627746582}
Epoch [118/300] Validation [1/16] Loss: 0.60282  focal_loss 0.37489  dice_loss 0.22793 
Epoch [118/300] Validation [2/16] Loss: 0.53154  focal_loss 0.16842  dice_loss 0.36312 
Epoch [118/300] Validation [3/16] Loss: 0.61169  focal_loss 0.27778  dice_loss 0.33391 
Epoch [118/300] Validation [4/16] Loss: 0.35458  focal_loss 0.12411  dice_loss 0.23047 
Epoch [118/300] Validation [5/16] Loss: 0.41078  focal_loss 0.09897  dice_loss 0.31181 
Epoch [118/300] Validation [6/16] Loss: 0.34515  focal_loss 0.07897  dice_loss 0.26618 
Epoch [118/300] Validation [7/16] Loss: 0.19875  focal_loss 0.07109  dice_loss 0.12766 
Epoch [118/300] Validation [8/16] Loss: 0.55969  focal_loss 0.11073  dice_loss 0.44896 
Epoch [118/300] Validation [9/16] Loss: 0.22246  focal_loss 0.07532  dice_loss 0.14714 
Epoch [118/300] Validation [10/16] Loss: 0.57136  focal_loss 0.16929  dice_loss 0.40207 
Epoch [118/300] Validation [11/16] Loss: 0.15663  focal_loss 0.04175  dice_loss 0.11487 
Epoch [118/300] Validation [12/16] Loss: 0.37017  focal_loss 0.07190  dice_loss 0.29827 
Epoch [118/300] Validation [13/16] Loss: 0.19498  focal_loss 0.04540  dice_loss 0.14958 
Epoch [118/300] Validation [14/16] Loss: 0.73998  focal_loss 0.26280  dice_loss 0.47718 
Epoch [118/300] Validation [15/16] Loss: 0.15891  focal_loss 0.04232  dice_loss 0.11658 
Epoch [118/300] Validation [16/16] Loss: 0.21840  focal_loss 0.07307  dice_loss 0.14533 
Epoch [118/300] Validation metric {'Val/mean dice_metric': 0.864981472492218, 'Val/mean miou_metric': 0.7941404581069946, 'Val/mean f1': 0.8876705169677734, 'Val/mean precision': 0.9032742977142334, 'Val/mean recall': 0.8725966811180115, 'Val/mean hd95_metric': 37.16718292236328}
Cheakpoint...
Epoch [118/300] best acc:tensor([0.8650], device='cuda:0'), Now : mean acc: tensor([0.8650], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.864981472492218, 'Val/mean miou_metric': 0.7941404581069946, 'Val/mean f1': 0.8876705169677734, 'Val/mean precision': 0.9032742977142334, 'Val/mean recall': 0.8725966811180115, 'Val/mean hd95_metric': 37.16718292236328}
Epoch [119/300] Training [1/62] Loss: 0.19719 
Epoch [119/300] Training [2/62] Loss: 0.11977 
Epoch [119/300] Training [3/62] Loss: 0.10857 
Epoch [119/300] Training [4/62] Loss: 0.17603 
Epoch [119/300] Training [5/62] Loss: 0.18682 
Epoch [119/300] Training [6/62] Loss: 0.20208 
Epoch [119/300] Training [7/62] Loss: 0.13362 
Epoch [119/300] Training [8/62] Loss: 0.13698 
Epoch [119/300] Training [9/62] Loss: 0.15759 
Epoch [119/300] Training [10/62] Loss: 0.12600 
Epoch [119/300] Training [11/62] Loss: 0.18193 
Epoch [119/300] Training [12/62] Loss: 0.44973 
Epoch [119/300] Training [13/62] Loss: 0.13172 
Epoch [119/300] Training [14/62] Loss: 0.08659 
Epoch [119/300] Training [15/62] Loss: 0.11782 
Epoch [119/300] Training [16/62] Loss: 0.11063 
Epoch [119/300] Training [17/62] Loss: 0.12979 
Epoch [119/300] Training [18/62] Loss: 0.10499 
Epoch [119/300] Training [19/62] Loss: 0.19501 
Epoch [119/300] Training [20/62] Loss: 0.26942 
Epoch [119/300] Training [21/62] Loss: 0.23888 
Epoch [119/300] Training [22/62] Loss: 0.07317 
Epoch [119/300] Training [23/62] Loss: 0.15520 
Epoch [119/300] Training [24/62] Loss: 0.10950 
Epoch [119/300] Training [25/62] Loss: 0.19702 
Epoch [119/300] Training [26/62] Loss: 0.24113 
Epoch [119/300] Training [27/62] Loss: 0.18828 
Epoch [119/300] Training [28/62] Loss: 0.11338 
Epoch [119/300] Training [29/62] Loss: 0.12596 
Epoch [119/300] Training [30/62] Loss: 0.25217 
Epoch [119/300] Training [31/62] Loss: 0.06301 
Epoch [119/300] Training [32/62] Loss: 0.20047 
Epoch [119/300] Training [33/62] Loss: 0.11285 
Epoch [119/300] Training [34/62] Loss: 0.11794 
Epoch [119/300] Training [35/62] Loss: 0.20763 
Epoch [119/300] Training [36/62] Loss: 0.17210 
Epoch [119/300] Training [37/62] Loss: 0.28401 
Epoch [119/300] Training [38/62] Loss: 0.25909 
Epoch [119/300] Training [39/62] Loss: 0.29783 
Epoch [119/300] Training [40/62] Loss: 0.27106 
Epoch [119/300] Training [41/62] Loss: 0.10985 
Epoch [119/300] Training [42/62] Loss: 0.09633 
Epoch [119/300] Training [43/62] Loss: 0.19624 
Epoch [119/300] Training [44/62] Loss: 0.20218 
Epoch [119/300] Training [45/62] Loss: 0.19917 
Epoch [119/300] Training [46/62] Loss: 0.18899 
Epoch [119/300] Training [47/62] Loss: 0.20336 
Epoch [119/300] Training [48/62] Loss: 0.11897 
Epoch [119/300] Training [49/62] Loss: 0.10437 
Epoch [119/300] Training [50/62] Loss: 0.21511 
Epoch [119/300] Training [51/62] Loss: 0.26718 
Epoch [119/300] Training [52/62] Loss: 0.09256 
Epoch [119/300] Training [53/62] Loss: 0.07717 
Epoch [119/300] Training [54/62] Loss: 0.08654 
Epoch [119/300] Training [55/62] Loss: 0.12474 
Epoch [119/300] Training [56/62] Loss: 0.09958 
Epoch [119/300] Training [57/62] Loss: 0.14774 
Epoch [119/300] Training [58/62] Loss: 0.23144 
Epoch [119/300] Training [59/62] Loss: 0.12391 
Epoch [119/300] Training [60/62] Loss: 0.11283 
Epoch [119/300] Training [61/62] Loss: 0.29452 
Epoch [119/300] Training [62/62] Loss: 0.07081 
Epoch [119/300] Training metric {'Train/mean dice_metric': 0.8865851759910583, 'Train/mean miou_metric': 0.8207253813743591, 'Train/mean f1': 0.9060799479484558, 'Train/mean precision': 0.9087934494018555, 'Train/mean recall': 0.9033826589584351, 'Train/mean hd95_metric': 31.506078720092773}
Epoch [119/300] Validation [1/16] Loss: 0.55310  focal_loss 0.24746  dice_loss 0.30565 
Epoch [119/300] Validation [2/16] Loss: 0.56786  focal_loss 0.15690  dice_loss 0.41096 
Epoch [119/300] Validation [3/16] Loss: 0.59855  focal_loss 0.26134  dice_loss 0.33722 
Epoch [119/300] Validation [4/16] Loss: 0.51333  focal_loss 0.18455  dice_loss 0.32878 
Epoch [119/300] Validation [5/16] Loss: 0.48749  focal_loss 0.12940  dice_loss 0.35808 
Epoch [119/300] Validation [6/16] Loss: 0.41577  focal_loss 0.09677  dice_loss 0.31900 
Epoch [119/300] Validation [7/16] Loss: 0.28057  focal_loss 0.07853  dice_loss 0.20204 
Epoch [119/300] Validation [8/16] Loss: 0.50460  focal_loss 0.08800  dice_loss 0.41660 
Epoch [119/300] Validation [9/16] Loss: 0.46834  focal_loss 0.15487  dice_loss 0.31347 
Epoch [119/300] Validation [10/16] Loss: 0.60398  focal_loss 0.14392  dice_loss 0.46006 
Epoch [119/300] Validation [11/16] Loss: 0.32447  focal_loss 0.08304  dice_loss 0.24143 
Epoch [119/300] Validation [12/16] Loss: 0.34455  focal_loss 0.05313  dice_loss 0.29142 
Epoch [119/300] Validation [13/16] Loss: 0.26760  focal_loss 0.06816  dice_loss 0.19944 
Epoch [119/300] Validation [14/16] Loss: 0.88205  focal_loss 0.26694  dice_loss 0.61512 
Epoch [119/300] Validation [15/16] Loss: 0.16214  focal_loss 0.03607  dice_loss 0.12607 
Epoch [119/300] Validation [16/16] Loss: 0.23788  focal_loss 0.07427  dice_loss 0.16361 
Epoch [119/300] Validation metric {'Val/mean dice_metric': 0.8478409647941589, 'Val/mean miou_metric': 0.7746284008026123, 'Val/mean f1': 0.873030424118042, 'Val/mean precision': 0.8825049996376038, 'Val/mean recall': 0.8637570142745972, 'Val/mean hd95_metric': 40.92402648925781}
Cheakpoint...
Epoch [119/300] best acc:tensor([0.8650], device='cuda:0'), Now : mean acc: tensor([0.8478], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8478409647941589, 'Val/mean miou_metric': 0.7746284008026123, 'Val/mean f1': 0.873030424118042, 'Val/mean precision': 0.8825049996376038, 'Val/mean recall': 0.8637570142745972, 'Val/mean hd95_metric': 40.92402648925781}
Epoch [120/300] Training [1/62] Loss: 0.07206 
Epoch [120/300] Training [2/62] Loss: 0.17027 
Epoch [120/300] Training [3/62] Loss: 0.09145 
Epoch [120/300] Training [4/62] Loss: 0.08168 
Epoch [120/300] Training [5/62] Loss: 0.16087 
Epoch [120/300] Training [6/62] Loss: 0.17694 
Epoch [120/300] Training [7/62] Loss: 0.07125 
Epoch [120/300] Training [8/62] Loss: 0.35090 
Epoch [120/300] Training [9/62] Loss: 0.14699 
Epoch [120/300] Training [10/62] Loss: 0.12800 
Epoch [120/300] Training [11/62] Loss: 0.21369 
Epoch [120/300] Training [12/62] Loss: 0.14226 
Epoch [120/300] Training [13/62] Loss: 0.20583 
Epoch [120/300] Training [14/62] Loss: 0.15674 
Epoch [120/300] Training [15/62] Loss: 0.15591 
Epoch [120/300] Training [16/62] Loss: 0.15944 
Epoch [120/300] Training [17/62] Loss: 0.10461 
Epoch [120/300] Training [18/62] Loss: 0.19485 
Epoch [120/300] Training [19/62] Loss: 0.18232 
Epoch [120/300] Training [20/62] Loss: 0.09275 
Epoch [120/300] Training [21/62] Loss: 0.18388 
Epoch [120/300] Training [22/62] Loss: 0.08351 
Epoch [120/300] Training [23/62] Loss: 0.19517 
Epoch [120/300] Training [24/62] Loss: 0.12050 
Epoch [120/300] Training [25/62] Loss: 0.07476 
Epoch [120/300] Training [26/62] Loss: 0.07614 
Epoch [120/300] Training [27/62] Loss: 0.09962 
Epoch [120/300] Training [28/62] Loss: 0.16487 
Epoch [120/300] Training [29/62] Loss: 0.11385 
Epoch [120/300] Training [30/62] Loss: 0.22655 
Epoch [120/300] Training [31/62] Loss: 0.06887 
Epoch [120/300] Training [32/62] Loss: 0.19517 
Epoch [120/300] Training [33/62] Loss: 0.14694 
Epoch [120/300] Training [34/62] Loss: 0.16313 
Epoch [120/300] Training [35/62] Loss: 0.18611 
Epoch [120/300] Training [36/62] Loss: 0.10209 
Epoch [120/300] Training [37/62] Loss: 0.13135 
Epoch [120/300] Training [38/62] Loss: 0.09347 
Epoch [120/300] Training [39/62] Loss: 0.16022 
Epoch [120/300] Training [40/62] Loss: 0.12733 
Epoch [120/300] Training [41/62] Loss: 0.22306 
Epoch [120/300] Training [42/62] Loss: 0.08567 
Epoch [120/300] Training [43/62] Loss: 0.12692 
Epoch [120/300] Training [44/62] Loss: 0.12991 
Epoch [120/300] Training [45/62] Loss: 0.17754 
Epoch [120/300] Training [46/62] Loss: 0.06034 
Epoch [120/300] Training [47/62] Loss: 0.17520 
Epoch [120/300] Training [48/62] Loss: 0.19671 
Epoch [120/300] Training [49/62] Loss: 0.18247 
Epoch [120/300] Training [50/62] Loss: 0.21401 
Epoch [120/300] Training [51/62] Loss: 0.09129 
Epoch [120/300] Training [52/62] Loss: 0.09214 
Epoch [120/300] Training [53/62] Loss: 0.24866 
Epoch [120/300] Training [54/62] Loss: 0.29749 
Epoch [120/300] Training [55/62] Loss: 0.20309 
Epoch [120/300] Training [56/62] Loss: 0.07489 
Epoch [120/300] Training [57/62] Loss: 0.13755 
Epoch [120/300] Training [58/62] Loss: 0.31366 
Epoch [120/300] Training [59/62] Loss: 0.20030 
Epoch [120/300] Training [60/62] Loss: 0.21501 
Epoch [120/300] Training [61/62] Loss: 0.14600 
Epoch [120/300] Training [62/62] Loss: 0.06485 
Epoch [120/300] Training metric {'Train/mean dice_metric': 0.8983480334281921, 'Train/mean miou_metric': 0.8346945643424988, 'Train/mean f1': 0.9128851294517517, 'Train/mean precision': 0.9179096221923828, 'Train/mean recall': 0.9079152941703796, 'Train/mean hd95_metric': 29.729328155517578}
Epoch [120/300] Validation [1/16] Loss: 0.67539  focal_loss 0.39111  dice_loss 0.28428 
Epoch [120/300] Validation [2/16] Loss: 0.49786  focal_loss 0.19743  dice_loss 0.30043 
Epoch [120/300] Validation [3/16] Loss: 0.51623  focal_loss 0.23178  dice_loss 0.28445 
Epoch [120/300] Validation [4/16] Loss: 0.31408  focal_loss 0.10294  dice_loss 0.21114 
Epoch [120/300] Validation [5/16] Loss: 0.57008  focal_loss 0.14615  dice_loss 0.42393 
Epoch [120/300] Validation [6/16] Loss: 0.36619  focal_loss 0.08568  dice_loss 0.28051 
Epoch [120/300] Validation [7/16] Loss: 0.26874  focal_loss 0.09656  dice_loss 0.17217 
Epoch [120/300] Validation [8/16] Loss: 0.56489  focal_loss 0.14888  dice_loss 0.41601 
Epoch [120/300] Validation [9/16] Loss: 0.37775  focal_loss 0.13230  dice_loss 0.24545 
Epoch [120/300] Validation [10/16] Loss: 0.72632  focal_loss 0.25280  dice_loss 0.47352 
Epoch [120/300] Validation [11/16] Loss: 0.30872  focal_loss 0.09826  dice_loss 0.21046 
Epoch [120/300] Validation [12/16] Loss: 0.43830  focal_loss 0.06993  dice_loss 0.36837 
Epoch [120/300] Validation [13/16] Loss: 0.31003  focal_loss 0.08962  dice_loss 0.22041 
Epoch [120/300] Validation [14/16] Loss: 0.61833  focal_loss 0.20243  dice_loss 0.41590 
Epoch [120/300] Validation [15/16] Loss: 0.30265  focal_loss 0.11553  dice_loss 0.18712 
Epoch [120/300] Validation [16/16] Loss: 0.36998  focal_loss 0.12129  dice_loss 0.24869 
Epoch [120/300] Validation metric {'Val/mean dice_metric': 0.8615093231201172, 'Val/mean miou_metric': 0.7891694903373718, 'Val/mean f1': 0.8812666535377502, 'Val/mean precision': 0.891858696937561, 'Val/mean recall': 0.8709233999252319, 'Val/mean hd95_metric': 39.21945571899414}
Cheakpoint...
Epoch [120/300] best acc:tensor([0.8650], device='cuda:0'), Now : mean acc: tensor([0.8615], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8615093231201172, 'Val/mean miou_metric': 0.7891694903373718, 'Val/mean f1': 0.8812666535377502, 'Val/mean precision': 0.891858696937561, 'Val/mean recall': 0.8709233999252319, 'Val/mean hd95_metric': 39.21945571899414}
Epoch [121/300] Training [1/62] Loss: 0.21385 
Epoch [121/300] Training [2/62] Loss: 0.08673 
Epoch [121/300] Training [3/62] Loss: 0.14916 
Epoch [121/300] Training [4/62] Loss: 0.33575 
Epoch [121/300] Training [5/62] Loss: 0.13447 
Epoch [121/300] Training [6/62] Loss: 0.12791 
Epoch [121/300] Training [7/62] Loss: 0.26141 
Epoch [121/300] Training [8/62] Loss: 0.14301 
Epoch [121/300] Training [9/62] Loss: 0.11369 
Epoch [121/300] Training [10/62] Loss: 0.10043 
Epoch [121/300] Training [11/62] Loss: 0.16650 
Epoch [121/300] Training [12/62] Loss: 0.07508 
Epoch [121/300] Training [13/62] Loss: 0.14293 
Epoch [121/300] Training [14/62] Loss: 0.19743 
Epoch [121/300] Training [15/62] Loss: 0.13259 
Epoch [121/300] Training [16/62] Loss: 0.10931 
Epoch [121/300] Training [17/62] Loss: 0.18436 
Epoch [121/300] Training [18/62] Loss: 0.10335 
Epoch [121/300] Training [19/62] Loss: 0.08900 
Epoch [121/300] Training [20/62] Loss: 0.10451 
Epoch [121/300] Training [21/62] Loss: 0.07094 
Epoch [121/300] Training [22/62] Loss: 0.16755 
Epoch [121/300] Training [23/62] Loss: 0.32004 
Epoch [121/300] Training [24/62] Loss: 0.14873 
Epoch [121/300] Training [25/62] Loss: 0.30111 
Epoch [121/300] Training [26/62] Loss: 0.13647 
Epoch [121/300] Training [27/62] Loss: 0.13784 
Epoch [121/300] Training [28/62] Loss: 0.15302 
Epoch [121/300] Training [29/62] Loss: 0.25928 
Epoch [121/300] Training [30/62] Loss: 0.22048 
Epoch [121/300] Training [31/62] Loss: 0.10908 
Epoch [121/300] Training [32/62] Loss: 0.14997 
Epoch [121/300] Training [33/62] Loss: 0.13438 
Epoch [121/300] Training [34/62] Loss: 0.28038 
Epoch [121/300] Training [35/62] Loss: 0.21177 
Epoch [121/300] Training [36/62] Loss: 0.15676 
Epoch [121/300] Training [37/62] Loss: 0.09174 
Epoch [121/300] Training [38/62] Loss: 0.18053 
Epoch [121/300] Training [39/62] Loss: 0.16019 
Epoch [121/300] Training [40/62] Loss: 0.16975 
Epoch [121/300] Training [41/62] Loss: 0.12577 
Epoch [121/300] Training [42/62] Loss: 0.17739 
Epoch [121/300] Training [43/62] Loss: 0.08059 
Epoch [121/300] Training [44/62] Loss: 0.11394 
Epoch [121/300] Training [45/62] Loss: 0.11757 
Epoch [121/300] Training [46/62] Loss: 0.12293 
Epoch [121/300] Training [47/62] Loss: 0.23398 
Epoch [121/300] Training [48/62] Loss: 0.05924 
Epoch [121/300] Training [49/62] Loss: 0.14635 
Epoch [121/300] Training [50/62] Loss: 0.08797 
Epoch [121/300] Training [51/62] Loss: 0.15764 
Epoch [121/300] Training [52/62] Loss: 0.08423 
Epoch [121/300] Training [53/62] Loss: 0.11893 
Epoch [121/300] Training [54/62] Loss: 0.13694 
Epoch [121/300] Training [55/62] Loss: 0.10153 
Epoch [121/300] Training [56/62] Loss: 0.08508 
Epoch [121/300] Training [57/62] Loss: 0.17067 
Epoch [121/300] Training [58/62] Loss: 0.32233 
Epoch [121/300] Training [59/62] Loss: 0.11381 
Epoch [121/300] Training [60/62] Loss: 0.08774 
Epoch [121/300] Training [61/62] Loss: 0.26032 
Epoch [121/300] Training [62/62] Loss: 0.38639 
Epoch [121/300] Training metric {'Train/mean dice_metric': 0.8968547582626343, 'Train/mean miou_metric': 0.8322961926460266, 'Train/mean f1': 0.9080379009246826, 'Train/mean precision': 0.9110031723976135, 'Train/mean recall': 0.9050919413566589, 'Train/mean hd95_metric': 29.58704376220703}
Epoch [121/300] Validation [1/16] Loss: 0.52061  focal_loss 0.30751  dice_loss 0.21311 
Epoch [121/300] Validation [2/16] Loss: 0.50667  focal_loss 0.17070  dice_loss 0.33597 
Epoch [121/300] Validation [3/16] Loss: 0.54609  focal_loss 0.23392  dice_loss 0.31217 
Epoch [121/300] Validation [4/16] Loss: 0.25582  focal_loss 0.09325  dice_loss 0.16257 
Epoch [121/300] Validation [5/16] Loss: 0.34289  focal_loss 0.08281  dice_loss 0.26008 
Epoch [121/300] Validation [6/16] Loss: 0.30803  focal_loss 0.07941  dice_loss 0.22863 
Epoch [121/300] Validation [7/16] Loss: 0.27046  focal_loss 0.06892  dice_loss 0.20155 
Epoch [121/300] Validation [8/16] Loss: 0.50358  focal_loss 0.17329  dice_loss 0.33030 
Epoch [121/300] Validation [9/16] Loss: 0.22704  focal_loss 0.05802  dice_loss 0.16903 
Epoch [121/300] Validation [10/16] Loss: 0.47514  focal_loss 0.11004  dice_loss 0.36510 
Epoch [121/300] Validation [11/16] Loss: 0.21870  focal_loss 0.05861  dice_loss 0.16009 
Epoch [121/300] Validation [12/16] Loss: 0.35963  focal_loss 0.07304  dice_loss 0.28659 
Epoch [121/300] Validation [13/16] Loss: 0.23888  focal_loss 0.05520  dice_loss 0.18368 
Epoch [121/300] Validation [14/16] Loss: 0.54204  focal_loss 0.16891  dice_loss 0.37313 
Epoch [121/300] Validation [15/16] Loss: 0.21924  focal_loss 0.07674  dice_loss 0.14251 
Epoch [121/300] Validation [16/16] Loss: 0.08726  focal_loss 0.01556  dice_loss 0.07171 
Epoch [121/300] Validation metric {'Val/mean dice_metric': 0.8709306120872498, 'Val/mean miou_metric': 0.8003425002098083, 'Val/mean f1': 0.8875192403793335, 'Val/mean precision': 0.8983358144760132, 'Val/mean recall': 0.8769599795341492, 'Val/mean hd95_metric': 34.464759826660156}
Cheakpoint...
Epoch [121/300] best acc:tensor([0.8709], device='cuda:0'), Now : mean acc: tensor([0.8709], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8709306120872498, 'Val/mean miou_metric': 0.8003425002098083, 'Val/mean f1': 0.8875192403793335, 'Val/mean precision': 0.8983358144760132, 'Val/mean recall': 0.8769599795341492, 'Val/mean hd95_metric': 34.464759826660156}
Epoch [122/300] Training [1/62] Loss: 0.10203 
Epoch [122/300] Training [2/62] Loss: 0.27797 
Epoch [122/300] Training [3/62] Loss: 0.13750 
Epoch [122/300] Training [4/62] Loss: 0.14764 
Epoch [122/300] Training [5/62] Loss: 0.22612 
Epoch [122/300] Training [6/62] Loss: 0.16821 
Epoch [122/300] Training [7/62] Loss: 0.08630 
Epoch [122/300] Training [8/62] Loss: 0.17758 
Epoch [122/300] Training [9/62] Loss: 0.14840 
Epoch [122/300] Training [10/62] Loss: 0.10501 
Epoch [122/300] Training [11/62] Loss: 0.09993 
Epoch [122/300] Training [12/62] Loss: 0.25441 
Epoch [122/300] Training [13/62] Loss: 0.18501 
Epoch [122/300] Training [14/62] Loss: 0.20362 
Epoch [122/300] Training [15/62] Loss: 0.14149 
Epoch [122/300] Training [16/62] Loss: 0.24324 
Epoch [122/300] Training [17/62] Loss: 0.12065 
Epoch [122/300] Training [18/62] Loss: 0.11478 
Epoch [122/300] Training [19/62] Loss: 0.15132 
Epoch [122/300] Training [20/62] Loss: 0.19493 
Epoch [122/300] Training [21/62] Loss: 0.12195 
Epoch [122/300] Training [22/62] Loss: 0.17852 
Epoch [122/300] Training [23/62] Loss: 0.07577 
Epoch [122/300] Training [24/62] Loss: 0.10785 
Epoch [122/300] Training [25/62] Loss: 0.24121 
Epoch [122/300] Training [26/62] Loss: 0.29019 
Epoch [122/300] Training [27/62] Loss: 0.06857 
Epoch [122/300] Training [28/62] Loss: 0.19609 
Epoch [122/300] Training [29/62] Loss: 0.10813 
Epoch [122/300] Training [30/62] Loss: 0.16612 
Epoch [122/300] Training [31/62] Loss: 0.08448 
Epoch [122/300] Training [32/62] Loss: 0.09542 
Epoch [122/300] Training [33/62] Loss: 0.09202 
Epoch [122/300] Training [34/62] Loss: 0.13311 
Epoch [122/300] Training [35/62] Loss: 0.09789 
Epoch [122/300] Training [36/62] Loss: 0.10167 
Epoch [122/300] Training [37/62] Loss: 0.10555 
Epoch [122/300] Training [38/62] Loss: 0.30676 
Epoch [122/300] Training [39/62] Loss: 0.31014 
Epoch [122/300] Training [40/62] Loss: 0.24829 
Epoch [122/300] Training [41/62] Loss: 0.13728 
Epoch [122/300] Training [42/62] Loss: 0.08803 
Epoch [122/300] Training [43/62] Loss: 0.33154 
Epoch [122/300] Training [44/62] Loss: 0.19214 
Epoch [122/300] Training [45/62] Loss: 0.11119 
Epoch [122/300] Training [46/62] Loss: 0.06474 
Epoch [122/300] Training [47/62] Loss: 0.10869 
Epoch [122/300] Training [48/62] Loss: 0.15316 
Epoch [122/300] Training [49/62] Loss: 0.13554 
Epoch [122/300] Training [50/62] Loss: 0.11047 
Epoch [122/300] Training [51/62] Loss: 0.16209 
Epoch [122/300] Training [52/62] Loss: 0.14862 
Epoch [122/300] Training [53/62] Loss: 0.09256 
Epoch [122/300] Training [54/62] Loss: 0.37123 
Epoch [122/300] Training [55/62] Loss: 0.31968 
Epoch [122/300] Training [56/62] Loss: 0.25450 
Epoch [122/300] Training [57/62] Loss: 0.07472 
Epoch [122/300] Training [58/62] Loss: 0.10524 
Epoch [122/300] Training [59/62] Loss: 0.11417 
Epoch [122/300] Training [60/62] Loss: 0.26180 
Epoch [122/300] Training [61/62] Loss: 0.21854 
Epoch [122/300] Training [62/62] Loss: 0.08771 
Epoch [122/300] Training metric {'Train/mean dice_metric': 0.8891334533691406, 'Train/mean miou_metric': 0.8240315914154053, 'Train/mean f1': 0.9095368385314941, 'Train/mean precision': 0.9108614325523376, 'Train/mean recall': 0.9082160592079163, 'Train/mean hd95_metric': 29.34238052368164}
Epoch [122/300] Validation [1/16] Loss: 0.65067  focal_loss 0.40473  dice_loss 0.24595 
Epoch [122/300] Validation [2/16] Loss: 0.53416  focal_loss 0.19296  dice_loss 0.34121 
Epoch [122/300] Validation [3/16] Loss: 0.54825  focal_loss 0.19583  dice_loss 0.35241 
Epoch [122/300] Validation [4/16] Loss: 0.37279  focal_loss 0.16055  dice_loss 0.21225 
Epoch [122/300] Validation [5/16] Loss: 0.41491  focal_loss 0.10992  dice_loss 0.30499 
Epoch [122/300] Validation [6/16] Loss: 0.35474  focal_loss 0.11654  dice_loss 0.23820 
Epoch [122/300] Validation [7/16] Loss: 0.17702  focal_loss 0.04992  dice_loss 0.12710 
Epoch [122/300] Validation [8/16] Loss: 0.41311  focal_loss 0.13111  dice_loss 0.28199 
Epoch [122/300] Validation [9/16] Loss: 0.26632  focal_loss 0.10029  dice_loss 0.16603 
Epoch [122/300] Validation [10/16] Loss: 0.61880  focal_loss 0.15012  dice_loss 0.46868 
Epoch [122/300] Validation [11/16] Loss: 0.16985  focal_loss 0.04309  dice_loss 0.12676 
Epoch [122/300] Validation [12/16] Loss: 0.40811  focal_loss 0.09800  dice_loss 0.31011 
Epoch [122/300] Validation [13/16] Loss: 0.21519  focal_loss 0.04517  dice_loss 0.17002 
Epoch [122/300] Validation [14/16] Loss: 0.58360  focal_loss 0.21843  dice_loss 0.36518 
Epoch [122/300] Validation [15/16] Loss: 0.17319  focal_loss 0.05407  dice_loss 0.11912 
Epoch [122/300] Validation [16/16] Loss: 0.16704  focal_loss 0.05017  dice_loss 0.11687 
Epoch [122/300] Validation metric {'Val/mean dice_metric': 0.8632505536079407, 'Val/mean miou_metric': 0.7925624251365662, 'Val/mean f1': 0.8872199654579163, 'Val/mean precision': 0.9039527773857117, 'Val/mean recall': 0.8710954189300537, 'Val/mean hd95_metric': 33.42146301269531}
Cheakpoint...
Epoch [122/300] best acc:tensor([0.8709], device='cuda:0'), Now : mean acc: tensor([0.8633], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8632505536079407, 'Val/mean miou_metric': 0.7925624251365662, 'Val/mean f1': 0.8872199654579163, 'Val/mean precision': 0.9039527773857117, 'Val/mean recall': 0.8710954189300537, 'Val/mean hd95_metric': 33.42146301269531}
Epoch [123/300] Training [1/62] Loss: 0.14276 
Epoch [123/300] Training [2/62] Loss: 0.08402 
Epoch [123/300] Training [3/62] Loss: 0.07304 
Epoch [123/300] Training [4/62] Loss: 0.23081 
Epoch [123/300] Training [5/62] Loss: 0.18174 
Epoch [123/300] Training [6/62] Loss: 0.16952 
Epoch [123/300] Training [7/62] Loss: 0.07357 
Epoch [123/300] Training [8/62] Loss: 0.19769 
Epoch [123/300] Training [9/62] Loss: 0.12096 
Epoch [123/300] Training [10/62] Loss: 0.23225 
Epoch [123/300] Training [11/62] Loss: 0.08764 
Epoch [123/300] Training [12/62] Loss: 0.21625 
Epoch [123/300] Training [13/62] Loss: 0.27638 
Epoch [123/300] Training [14/62] Loss: 0.09254 
Epoch [123/300] Training [15/62] Loss: 0.23950 
Epoch [123/300] Training [16/62] Loss: 0.12647 
Epoch [123/300] Training [17/62] Loss: 0.24438 
Epoch [123/300] Training [18/62] Loss: 0.14848 
Epoch [123/300] Training [19/62] Loss: 0.12312 
Epoch [123/300] Training [20/62] Loss: 0.07728 
Epoch [123/300] Training [21/62] Loss: 0.32064 
Epoch [123/300] Training [22/62] Loss: 0.21830 
Epoch [123/300] Training [23/62] Loss: 0.06372 
Epoch [123/300] Training [24/62] Loss: 0.11073 
Epoch [123/300] Training [25/62] Loss: 0.23316 
Epoch [123/300] Training [26/62] Loss: 0.19620 
Epoch [123/300] Training [27/62] Loss: 0.11732 
Epoch [123/300] Training [28/62] Loss: 0.17961 
Epoch [123/300] Training [29/62] Loss: 0.17509 
Epoch [123/300] Training [30/62] Loss: 0.18784 
Epoch [123/300] Training [31/62] Loss: 0.11349 
Epoch [123/300] Training [32/62] Loss: 0.09046 
Epoch [123/300] Training [33/62] Loss: 0.25600 
Epoch [123/300] Training [34/62] Loss: 0.18640 
Epoch [123/300] Training [35/62] Loss: 0.11489 
Epoch [123/300] Training [36/62] Loss: 0.09943 
Epoch [123/300] Training [37/62] Loss: 0.08918 
Epoch [123/300] Training [38/62] Loss: 0.21584 
Epoch [123/300] Training [39/62] Loss: 0.08027 
Epoch [123/300] Training [40/62] Loss: 0.13348 
Epoch [123/300] Training [41/62] Loss: 0.10088 
Epoch [123/300] Training [42/62] Loss: 0.06620 
Epoch [123/300] Training [43/62] Loss: 0.16328 
Epoch [123/300] Training [44/62] Loss: 0.08652 
Epoch [123/300] Training [45/62] Loss: 0.16525 
Epoch [123/300] Training [46/62] Loss: 0.11046 
Epoch [123/300] Training [47/62] Loss: 0.12282 
Epoch [123/300] Training [48/62] Loss: 0.20175 
Epoch [123/300] Training [49/62] Loss: 0.13824 
Epoch [123/300] Training [50/62] Loss: 0.08473 
Epoch [123/300] Training [51/62] Loss: 0.22529 
Epoch [123/300] Training [52/62] Loss: 0.13590 
Epoch [123/300] Training [53/62] Loss: 0.12306 
Epoch [123/300] Training [54/62] Loss: 0.20612 
Epoch [123/300] Training [55/62] Loss: 0.08485 
Epoch [123/300] Training [56/62] Loss: 0.10915 
Epoch [123/300] Training [57/62] Loss: 0.22508 
Epoch [123/300] Training [58/62] Loss: 0.07932 
Epoch [123/300] Training [59/62] Loss: 0.15951 
Epoch [123/300] Training [60/62] Loss: 0.24792 
Epoch [123/300] Training [61/62] Loss: 0.16625 
Epoch [123/300] Training [62/62] Loss: 0.07522 
Epoch [123/300] Training metric {'Train/mean dice_metric': 0.8962098956108093, 'Train/mean miou_metric': 0.8330910801887512, 'Train/mean f1': 0.9175530076026917, 'Train/mean precision': 0.9210985898971558, 'Train/mean recall': 0.9140346646308899, 'Train/mean hd95_metric': 30.310699462890625}
Epoch [123/300] Validation [1/16] Loss: 0.61737  focal_loss 0.36456  dice_loss 0.25280 
Epoch [123/300] Validation [2/16] Loss: 0.42730  focal_loss 0.14303  dice_loss 0.28427 
Epoch [123/300] Validation [3/16] Loss: 0.60796  focal_loss 0.26344  dice_loss 0.34452 
Epoch [123/300] Validation [4/16] Loss: 0.34272  focal_loss 0.11837  dice_loss 0.22435 
Epoch [123/300] Validation [5/16] Loss: 0.44213  focal_loss 0.10869  dice_loss 0.33345 
Epoch [123/300] Validation [6/16] Loss: 0.37015  focal_loss 0.09976  dice_loss 0.27038 
Epoch [123/300] Validation [7/16] Loss: 0.23968  focal_loss 0.07762  dice_loss 0.16206 
Epoch [123/300] Validation [8/16] Loss: 0.57281  focal_loss 0.18083  dice_loss 0.39197 
Epoch [123/300] Validation [9/16] Loss: 0.36069  focal_loss 0.11813  dice_loss 0.24256 
Epoch [123/300] Validation [10/16] Loss: 0.53647  focal_loss 0.15772  dice_loss 0.37875 
Epoch [123/300] Validation [11/16] Loss: 0.25029  focal_loss 0.07130  dice_loss 0.17899 
Epoch [123/300] Validation [12/16] Loss: 0.41452  focal_loss 0.09190  dice_loss 0.32263 
Epoch [123/300] Validation [13/16] Loss: 0.28813  focal_loss 0.08771  dice_loss 0.20042 
Epoch [123/300] Validation [14/16] Loss: 0.84336  focal_loss 0.29020  dice_loss 0.55316 
Epoch [123/300] Validation [15/16] Loss: 0.17556  focal_loss 0.04513  dice_loss 0.13043 
Epoch [123/300] Validation [16/16] Loss: 0.19397  focal_loss 0.04909  dice_loss 0.14488 
Epoch [123/300] Validation metric {'Val/mean dice_metric': 0.8630899786949158, 'Val/mean miou_metric': 0.7930158972740173, 'Val/mean f1': 0.8896756768226624, 'Val/mean precision': 0.9038633108139038, 'Val/mean recall': 0.8759265542030334, 'Val/mean hd95_metric': 37.683650970458984}
Cheakpoint...
Epoch [123/300] best acc:tensor([0.8709], device='cuda:0'), Now : mean acc: tensor([0.8631], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8630899786949158, 'Val/mean miou_metric': 0.7930158972740173, 'Val/mean f1': 0.8896756768226624, 'Val/mean precision': 0.9038633108139038, 'Val/mean recall': 0.8759265542030334, 'Val/mean hd95_metric': 37.683650970458984}
Epoch [124/300] Training [1/62] Loss: 0.22039 
Epoch [124/300] Training [2/62] Loss: 0.11034 
Epoch [124/300] Training [3/62] Loss: 0.14035 
Epoch [124/300] Training [4/62] Loss: 0.08341 
Epoch [124/300] Training [5/62] Loss: 0.16386 
Epoch [124/300] Training [6/62] Loss: 0.23966 
Epoch [124/300] Training [7/62] Loss: 0.16023 
Epoch [124/300] Training [8/62] Loss: 0.44862 
Epoch [124/300] Training [9/62] Loss: 0.09773 
Epoch [124/300] Training [10/62] Loss: 0.07606 
Epoch [124/300] Training [11/62] Loss: 0.08548 
Epoch [124/300] Training [12/62] Loss: 0.12048 
Epoch [124/300] Training [13/62] Loss: 0.08506 
Epoch [124/300] Training [14/62] Loss: 0.13310 
Epoch [124/300] Training [15/62] Loss: 0.08802 
Epoch [124/300] Training [16/62] Loss: 0.09547 
Epoch [124/300] Training [17/62] Loss: 0.15094 
Epoch [124/300] Training [18/62] Loss: 0.17925 
Epoch [124/300] Training [19/62] Loss: 0.47220 
Epoch [124/300] Training [20/62] Loss: 0.30989 
Epoch [124/300] Training [21/62] Loss: 0.10187 
Epoch [124/300] Training [22/62] Loss: 0.09197 
Epoch [124/300] Training [23/62] Loss: 0.23090 
Epoch [124/300] Training [24/62] Loss: 0.21515 
Epoch [124/300] Training [25/62] Loss: 0.09506 
Epoch [124/300] Training [26/62] Loss: 0.14470 
Epoch [124/300] Training [27/62] Loss: 0.24772 
Epoch [124/300] Training [28/62] Loss: 0.25512 
Epoch [124/300] Training [29/62] Loss: 0.08816 
Epoch [124/300] Training [30/62] Loss: 0.12920 
Epoch [124/300] Training [31/62] Loss: 0.16285 
Epoch [124/300] Training [32/62] Loss: 0.10131 
Epoch [124/300] Training [33/62] Loss: 0.10123 
Epoch [124/300] Training [34/62] Loss: 0.28643 
Epoch [124/300] Training [35/62] Loss: 0.30277 
Epoch [124/300] Training [36/62] Loss: 0.26009 
Epoch [124/300] Training [37/62] Loss: 0.07042 
Epoch [124/300] Training [38/62] Loss: 0.11731 
Epoch [124/300] Training [39/62] Loss: 0.16947 
Epoch [124/300] Training [40/62] Loss: 0.11287 
Epoch [124/300] Training [41/62] Loss: 0.09424 
Epoch [124/300] Training [42/62] Loss: 0.09854 
Epoch [124/300] Training [43/62] Loss: 0.24150 
Epoch [124/300] Training [44/62] Loss: 0.13218 
Epoch [124/300] Training [45/62] Loss: 0.15949 
Epoch [124/300] Training [46/62] Loss: 0.24046 
Epoch [124/300] Training [47/62] Loss: 0.17803 
Epoch [124/300] Training [48/62] Loss: 0.15640 
Epoch [124/300] Training [49/62] Loss: 0.10285 
Epoch [124/300] Training [50/62] Loss: 0.16898 
Epoch [124/300] Training [51/62] Loss: 0.15780 
Epoch [124/300] Training [52/62] Loss: 0.10748 
Epoch [124/300] Training [53/62] Loss: 0.09496 
Epoch [124/300] Training [54/62] Loss: 0.09978 
Epoch [124/300] Training [55/62] Loss: 0.29474 
Epoch [124/300] Training [56/62] Loss: 0.11069 
Epoch [124/300] Training [57/62] Loss: 0.11367 
Epoch [124/300] Training [58/62] Loss: 0.10759 
Epoch [124/300] Training [59/62] Loss: 0.12293 
Epoch [124/300] Training [60/62] Loss: 0.21249 
Epoch [124/300] Training [61/62] Loss: 0.10015 
Epoch [124/300] Training [62/62] Loss: 0.05808 
Epoch [124/300] Training metric {'Train/mean dice_metric': 0.8938028216362, 'Train/mean miou_metric': 0.8292036652565002, 'Train/mean f1': 0.9086883664131165, 'Train/mean precision': 0.9150838851928711, 'Train/mean recall': 0.9023816585540771, 'Train/mean hd95_metric': 31.209308624267578}
Epoch [124/300] Validation [1/16] Loss: 0.53723  focal_loss 0.32879  dice_loss 0.20844 
Epoch [124/300] Validation [2/16] Loss: 0.62704  focal_loss 0.20171  dice_loss 0.42533 
Epoch [124/300] Validation [3/16] Loss: 0.51731  focal_loss 0.22459  dice_loss 0.29272 
Epoch [124/300] Validation [4/16] Loss: 0.39034  focal_loss 0.15518  dice_loss 0.23516 
Epoch [124/300] Validation [5/16] Loss: 0.37675  focal_loss 0.10476  dice_loss 0.27199 
Epoch [124/300] Validation [6/16] Loss: 0.35615  focal_loss 0.10242  dice_loss 0.25373 
Epoch [124/300] Validation [7/16] Loss: 0.24076  focal_loss 0.07169  dice_loss 0.16907 
Epoch [124/300] Validation [8/16] Loss: 0.53293  focal_loss 0.14747  dice_loss 0.38546 
Epoch [124/300] Validation [9/16] Loss: 0.32349  focal_loss 0.08899  dice_loss 0.23450 
Epoch [124/300] Validation [10/16] Loss: 0.53935  focal_loss 0.15285  dice_loss 0.38650 
Epoch [124/300] Validation [11/16] Loss: 0.25412  focal_loss 0.06022  dice_loss 0.19390 
Epoch [124/300] Validation [12/16] Loss: 0.33530  focal_loss 0.05027  dice_loss 0.28503 
Epoch [124/300] Validation [13/16] Loss: 0.29390  focal_loss 0.07177  dice_loss 0.22213 
Epoch [124/300] Validation [14/16] Loss: 0.64376  focal_loss 0.21224  dice_loss 0.43152 
Epoch [124/300] Validation [15/16] Loss: 0.15553  focal_loss 0.04084  dice_loss 0.11470 
Epoch [124/300] Validation [16/16] Loss: 0.24876  focal_loss 0.06774  dice_loss 0.18102 
Epoch [124/300] Validation metric {'Val/mean dice_metric': 0.8629994988441467, 'Val/mean miou_metric': 0.7909833192825317, 'Val/mean f1': 0.8831364512443542, 'Val/mean precision': 0.8914085626602173, 'Val/mean recall': 0.8750163912773132, 'Val/mean hd95_metric': 38.088260650634766}
Cheakpoint...
Epoch [124/300] best acc:tensor([0.8709], device='cuda:0'), Now : mean acc: tensor([0.8630], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8629994988441467, 'Val/mean miou_metric': 0.7909833192825317, 'Val/mean f1': 0.8831364512443542, 'Val/mean precision': 0.8914085626602173, 'Val/mean recall': 0.8750163912773132, 'Val/mean hd95_metric': 38.088260650634766}
Epoch [125/300] Training [1/62] Loss: 0.08362 
Epoch [125/300] Training [2/62] Loss: 0.08194 
Epoch [125/300] Training [3/62] Loss: 0.12115 
Epoch [125/300] Training [4/62] Loss: 0.11451 
Epoch [125/300] Training [5/62] Loss: 0.16789 
Epoch [125/300] Training [6/62] Loss: 0.20556 
Epoch [125/300] Training [7/62] Loss: 0.14501 
Epoch [125/300] Training [8/62] Loss: 0.12831 
Epoch [125/300] Training [9/62] Loss: 0.08775 
Epoch [125/300] Training [10/62] Loss: 0.07996 
Epoch [125/300] Training [11/62] Loss: 0.24083 
Epoch [125/300] Training [12/62] Loss: 0.09907 
Epoch [125/300] Training [13/62] Loss: 0.08699 
Epoch [125/300] Training [14/62] Loss: 0.08684 
Epoch [125/300] Training [15/62] Loss: 0.16626 
Epoch [125/300] Training [16/62] Loss: 0.10768 
Epoch [125/300] Training [17/62] Loss: 0.09692 
Epoch [125/300] Training [18/62] Loss: 0.13207 
Epoch [125/300] Training [19/62] Loss: 0.16099 
Epoch [125/300] Training [20/62] Loss: 0.07785 
Epoch [125/300] Training [21/62] Loss: 0.07094 
Epoch [125/300] Training [22/62] Loss: 0.23622 
Epoch [125/300] Training [23/62] Loss: 0.11906 
Epoch [125/300] Training [24/62] Loss: 0.09466 
Epoch [125/300] Training [25/62] Loss: 0.09952 
Epoch [125/300] Training [26/62] Loss: 0.09415 
Epoch [125/300] Training [27/62] Loss: 0.19930 
Epoch [125/300] Training [28/62] Loss: 0.20450 
Epoch [125/300] Training [29/62] Loss: 0.13620 
Epoch [125/300] Training [30/62] Loss: 0.12012 
Epoch [125/300] Training [31/62] Loss: 0.16453 
Epoch [125/300] Training [32/62] Loss: 0.18863 
Epoch [125/300] Training [33/62] Loss: 0.14712 
Epoch [125/300] Training [34/62] Loss: 0.09681 
Epoch [125/300] Training [35/62] Loss: 0.09239 
Epoch [125/300] Training [36/62] Loss: 0.06301 
Epoch [125/300] Training [37/62] Loss: 0.07202 
Epoch [125/300] Training [38/62] Loss: 0.18168 
Epoch [125/300] Training [39/62] Loss: 0.12962 
Epoch [125/300] Training [40/62] Loss: 0.20837 
Epoch [125/300] Training [41/62] Loss: 0.11475 
Epoch [125/300] Training [42/62] Loss: 0.17897 
Epoch [125/300] Training [43/62] Loss: 0.13011 
Epoch [125/300] Training [44/62] Loss: 0.08810 
Epoch [125/300] Training [45/62] Loss: 0.10143 
Epoch [125/300] Training [46/62] Loss: 0.28286 
Epoch [125/300] Training [47/62] Loss: 0.17017 
Epoch [125/300] Training [48/62] Loss: 0.18007 
Epoch [125/300] Training [49/62] Loss: 0.18610 
Epoch [125/300] Training [50/62] Loss: 0.13937 
Epoch [125/300] Training [51/62] Loss: 0.17563 
Epoch [125/300] Training [52/62] Loss: 0.16726 
Epoch [125/300] Training [53/62] Loss: 0.14552 
Epoch [125/300] Training [54/62] Loss: 0.11702 
Epoch [125/300] Training [55/62] Loss: 0.16548 
Epoch [125/300] Training [56/62] Loss: 0.08866 
Epoch [125/300] Training [57/62] Loss: 0.16064 
Epoch [125/300] Training [58/62] Loss: 0.13406 
Epoch [125/300] Training [59/62] Loss: 0.15238 
Epoch [125/300] Training [60/62] Loss: 0.11049 
Epoch [125/300] Training [61/62] Loss: 0.24605 
Epoch [125/300] Training [62/62] Loss: 0.04274 
Epoch [125/300] Training metric {'Train/mean dice_metric': 0.905988872051239, 'Train/mean miou_metric': 0.8452811241149902, 'Train/mean f1': 0.9231411814689636, 'Train/mean precision': 0.92210853099823, 'Train/mean recall': 0.9241761565208435, 'Train/mean hd95_metric': 25.741382598876953}
Epoch [125/300] Validation [1/16] Loss: 0.94539  focal_loss 0.54039  dice_loss 0.40500 
Epoch [125/300] Validation [2/16] Loss: 0.60663  focal_loss 0.18930  dice_loss 0.41733 
Epoch [125/300] Validation [3/16] Loss: 0.60528  focal_loss 0.29061  dice_loss 0.31467 
Epoch [125/300] Validation [4/16] Loss: 0.34620  focal_loss 0.14443  dice_loss 0.20177 
Epoch [125/300] Validation [5/16] Loss: 0.44184  focal_loss 0.12404  dice_loss 0.31781 
Epoch [125/300] Validation [6/16] Loss: 0.40546  focal_loss 0.10204  dice_loss 0.30341 
Epoch [125/300] Validation [7/16] Loss: 0.54919  focal_loss 0.19473  dice_loss 0.35446 
Epoch [125/300] Validation [8/16] Loss: 0.55506  focal_loss 0.14242  dice_loss 0.41264 
Epoch [125/300] Validation [9/16] Loss: 0.70719  focal_loss 0.30158  dice_loss 0.40561 
Epoch [125/300] Validation [10/16] Loss: 0.58671  focal_loss 0.19515  dice_loss 0.39156 
Epoch [125/300] Validation [11/16] Loss: 0.59024  focal_loss 0.19492  dice_loss 0.39531 
Epoch [125/300] Validation [12/16] Loss: 0.49036  focal_loss 0.08377  dice_loss 0.40659 
Epoch [125/300] Validation [13/16] Loss: 0.42686  focal_loss 0.17093  dice_loss 0.25593 
Epoch [125/300] Validation [14/16] Loss: 0.62777  focal_loss 0.19832  dice_loss 0.42945 
Epoch [125/300] Validation [15/16] Loss: 0.24729  focal_loss 0.07994  dice_loss 0.16735 
Epoch [125/300] Validation [16/16] Loss: 0.19841  focal_loss 0.05655  dice_loss 0.14185 
Epoch [125/300] Validation metric {'Val/mean dice_metric': 0.8585174083709717, 'Val/mean miou_metric': 0.7900478839874268, 'Val/mean f1': 0.8874862194061279, 'Val/mean precision': 0.8971049189567566, 'Val/mean recall': 0.8780716061592102, 'Val/mean hd95_metric': 34.069610595703125}
Cheakpoint...
Epoch [125/300] best acc:tensor([0.8709], device='cuda:0'), Now : mean acc: tensor([0.8585], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8585174083709717, 'Val/mean miou_metric': 0.7900478839874268, 'Val/mean f1': 0.8874862194061279, 'Val/mean precision': 0.8971049189567566, 'Val/mean recall': 0.8780716061592102, 'Val/mean hd95_metric': 34.069610595703125}
Epoch [126/300] Training [1/62] Loss: 0.12860 
Epoch [126/300] Training [2/62] Loss: 0.07894 
Epoch [126/300] Training [3/62] Loss: 0.12663 
Epoch [126/300] Training [4/62] Loss: 0.13402 
Epoch [126/300] Training [5/62] Loss: 0.09182 
Epoch [126/300] Training [6/62] Loss: 0.19328 
Epoch [126/300] Training [7/62] Loss: 0.19506 
Epoch [126/300] Training [8/62] Loss: 0.11631 
Epoch [126/300] Training [9/62] Loss: 0.10253 
Epoch [126/300] Training [10/62] Loss: 0.12912 
Epoch [126/300] Training [11/62] Loss: 0.14995 
Epoch [126/300] Training [12/62] Loss: 0.12630 
Epoch [126/300] Training [13/62] Loss: 0.16081 
Epoch [126/300] Training [14/62] Loss: 0.20818 
Epoch [126/300] Training [15/62] Loss: 0.15082 
Epoch [126/300] Training [16/62] Loss: 0.13392 
Epoch [126/300] Training [17/62] Loss: 0.12914 
Epoch [126/300] Training [18/62] Loss: 0.11447 
Epoch [126/300] Training [19/62] Loss: 0.17785 
Epoch [126/300] Training [20/62] Loss: 0.27228 
Epoch [126/300] Training [21/62] Loss: 0.08737 
Epoch [126/300] Training [22/62] Loss: 0.08887 
Epoch [126/300] Training [23/62] Loss: 0.16609 
Epoch [126/300] Training [24/62] Loss: 0.07508 
Epoch [126/300] Training [25/62] Loss: 0.11454 
Epoch [126/300] Training [26/62] Loss: 0.07559 
Epoch [126/300] Training [27/62] Loss: 0.09153 
Epoch [126/300] Training [28/62] Loss: 0.11014 
Epoch [126/300] Training [29/62] Loss: 0.29042 
Epoch [126/300] Training [30/62] Loss: 0.14444 
Epoch [126/300] Training [31/62] Loss: 0.26025 
Epoch [126/300] Training [32/62] Loss: 0.13593 
Epoch [126/300] Training [33/62] Loss: 0.15642 
Epoch [126/300] Training [34/62] Loss: 0.24532 
Epoch [126/300] Training [35/62] Loss: 0.09216 
Epoch [126/300] Training [36/62] Loss: 0.12869 
Epoch [126/300] Training [37/62] Loss: 0.19033 
Epoch [126/300] Training [38/62] Loss: 0.17775 
Epoch [126/300] Training [39/62] Loss: 0.14223 
Epoch [126/300] Training [40/62] Loss: 0.15415 
Epoch [126/300] Training [41/62] Loss: 0.20742 
Epoch [126/300] Training [42/62] Loss: 0.10076 
Epoch [126/300] Training [43/62] Loss: 0.12197 
Epoch [126/300] Training [44/62] Loss: 0.07173 
Epoch [126/300] Training [45/62] Loss: 0.12172 
Epoch [126/300] Training [46/62] Loss: 0.09995 
Epoch [126/300] Training [47/62] Loss: 0.13490 
Epoch [126/300] Training [48/62] Loss: 0.16229 
Epoch [126/300] Training [49/62] Loss: 0.07207 
Epoch [126/300] Training [50/62] Loss: 0.28550 
Epoch [126/300] Training [51/62] Loss: 0.08440 
Epoch [126/300] Training [52/62] Loss: 0.23034 
Epoch [126/300] Training [53/62] Loss: 0.23267 
Epoch [126/300] Training [54/62] Loss: 0.13054 
Epoch [126/300] Training [55/62] Loss: 0.29145 
Epoch [126/300] Training [56/62] Loss: 0.07744 
Epoch [126/300] Training [57/62] Loss: 0.12502 
Epoch [126/300] Training [58/62] Loss: 0.08562 
Epoch [126/300] Training [59/62] Loss: 0.06845 
Epoch [126/300] Training [60/62] Loss: 0.15720 
Epoch [126/300] Training [61/62] Loss: 0.08844 
Epoch [126/300] Training [62/62] Loss: 0.20670 
Epoch [126/300] Training metric {'Train/mean dice_metric': 0.9019820094108582, 'Train/mean miou_metric': 0.8410243988037109, 'Train/mean f1': 0.9182443618774414, 'Train/mean precision': 0.9175461530685425, 'Train/mean recall': 0.9189435839653015, 'Train/mean hd95_metric': 29.84712028503418}
Epoch [126/300] Validation [1/16] Loss: 0.63819  focal_loss 0.36449  dice_loss 0.27370 
Epoch [126/300] Validation [2/16] Loss: 0.42134  focal_loss 0.13779  dice_loss 0.28356 
Epoch [126/300] Validation [3/16] Loss: 0.66979  focal_loss 0.32408  dice_loss 0.34571 
Epoch [126/300] Validation [4/16] Loss: 0.35503  focal_loss 0.13482  dice_loss 0.22022 
Epoch [126/300] Validation [5/16] Loss: 0.29926  focal_loss 0.07602  dice_loss 0.22324 
Epoch [126/300] Validation [6/16] Loss: 0.37157  focal_loss 0.09720  dice_loss 0.27437 
Epoch [126/300] Validation [7/16] Loss: 0.34892  focal_loss 0.10688  dice_loss 0.24203 
Epoch [126/300] Validation [8/16] Loss: 0.57942  focal_loss 0.17310  dice_loss 0.40632 
Epoch [126/300] Validation [9/16] Loss: 0.27929  focal_loss 0.10453  dice_loss 0.17476 
Epoch [126/300] Validation [10/16] Loss: 0.40755  focal_loss 0.08921  dice_loss 0.31834 
Epoch [126/300] Validation [11/16] Loss: 0.22352  focal_loss 0.06326  dice_loss 0.16026 
Epoch [126/300] Validation [12/16] Loss: 0.35174  focal_loss 0.06822  dice_loss 0.28351 
Epoch [126/300] Validation [13/16] Loss: 0.27203  focal_loss 0.07929  dice_loss 0.19274 
Epoch [126/300] Validation [14/16] Loss: 0.64926  focal_loss 0.20210  dice_loss 0.44716 
Epoch [126/300] Validation [15/16] Loss: 0.16444  focal_loss 0.05088  dice_loss 0.11356 
Epoch [126/300] Validation [16/16] Loss: 0.12334  focal_loss 0.03796  dice_loss 0.08539 
Epoch [126/300] Validation metric {'Val/mean dice_metric': 0.8718253970146179, 'Val/mean miou_metric': 0.804962694644928, 'Val/mean f1': 0.8951246738433838, 'Val/mean precision': 0.9066244959831238, 'Val/mean recall': 0.8839129209518433, 'Val/mean hd95_metric': 35.85382080078125}
Cheakpoint...
Epoch [126/300] best acc:tensor([0.8718], device='cuda:0'), Now : mean acc: tensor([0.8718], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8718253970146179, 'Val/mean miou_metric': 0.804962694644928, 'Val/mean f1': 0.8951246738433838, 'Val/mean precision': 0.9066244959831238, 'Val/mean recall': 0.8839129209518433, 'Val/mean hd95_metric': 35.85382080078125}
Epoch [127/300] Training [1/62] Loss: 0.10436 
Epoch [127/300] Training [2/62] Loss: 0.08337 
Epoch [127/300] Training [3/62] Loss: 0.23938 
Epoch [127/300] Training [4/62] Loss: 0.07802 
Epoch [127/300] Training [5/62] Loss: 0.11436 
Epoch [127/300] Training [6/62] Loss: 0.13823 
Epoch [127/300] Training [7/62] Loss: 0.14358 
Epoch [127/300] Training [8/62] Loss: 0.20222 
Epoch [127/300] Training [9/62] Loss: 0.23074 
Epoch [127/300] Training [10/62] Loss: 0.26313 
Epoch [127/300] Training [11/62] Loss: 0.10093 
Epoch [127/300] Training [12/62] Loss: 0.13151 
Epoch [127/300] Training [13/62] Loss: 0.15801 
Epoch [127/300] Training [14/62] Loss: 0.13940 
Epoch [127/300] Training [15/62] Loss: 0.13664 
Epoch [127/300] Training [16/62] Loss: 0.12135 
Epoch [127/300] Training [17/62] Loss: 0.14774 
Epoch [127/300] Training [18/62] Loss: 0.13948 
Epoch [127/300] Training [19/62] Loss: 0.11650 
Epoch [127/300] Training [20/62] Loss: 0.16800 
Epoch [127/300] Training [21/62] Loss: 0.12180 
Epoch [127/300] Training [22/62] Loss: 0.22290 
Epoch [127/300] Training [23/62] Loss: 0.12126 
Epoch [127/300] Training [24/62] Loss: 0.19478 
Epoch [127/300] Training [25/62] Loss: 0.14215 
Epoch [127/300] Training [26/62] Loss: 0.16594 
Epoch [127/300] Training [27/62] Loss: 0.10879 
Epoch [127/300] Training [28/62] Loss: 0.11618 
Epoch [127/300] Training [29/62] Loss: 0.17934 
Epoch [127/300] Training [30/62] Loss: 0.12871 
Epoch [127/300] Training [31/62] Loss: 0.07980 
Epoch [127/300] Training [32/62] Loss: 0.13715 
Epoch [127/300] Training [33/62] Loss: 0.06544 
Epoch [127/300] Training [34/62] Loss: 0.09511 
Epoch [127/300] Training [35/62] Loss: 0.14881 
Epoch [127/300] Training [36/62] Loss: 0.22728 
Epoch [127/300] Training [37/62] Loss: 0.13444 
Epoch [127/300] Training [38/62] Loss: 0.11025 
Epoch [127/300] Training [39/62] Loss: 0.06241 
Epoch [127/300] Training [40/62] Loss: 0.06811 
Epoch [127/300] Training [41/62] Loss: 0.08314 
Epoch [127/300] Training [42/62] Loss: 0.16236 
Epoch [127/300] Training [43/62] Loss: 0.10645 
Epoch [127/300] Training [44/62] Loss: 0.11597 
Epoch [127/300] Training [45/62] Loss: 0.06436 
Epoch [127/300] Training [46/62] Loss: 0.08066 
Epoch [127/300] Training [47/62] Loss: 0.12004 
Epoch [127/300] Training [48/62] Loss: 0.12247 
Epoch [127/300] Training [49/62] Loss: 0.09240 
Epoch [127/300] Training [50/62] Loss: 0.14998 
Epoch [127/300] Training [51/62] Loss: 0.11331 
Epoch [127/300] Training [52/62] Loss: 0.26640 
Epoch [127/300] Training [53/62] Loss: 0.13317 
Epoch [127/300] Training [54/62] Loss: 0.12321 
Epoch [127/300] Training [55/62] Loss: 0.11428 
Epoch [127/300] Training [56/62] Loss: 0.23343 
Epoch [127/300] Training [57/62] Loss: 0.07533 
Epoch [127/300] Training [58/62] Loss: 0.12831 
Epoch [127/300] Training [59/62] Loss: 0.21390 
Epoch [127/300] Training [60/62] Loss: 0.17145 
Epoch [127/300] Training [61/62] Loss: 0.10013 
Epoch [127/300] Training [62/62] Loss: 0.06358 
Epoch [127/300] Training metric {'Train/mean dice_metric': 0.9090451598167419, 'Train/mean miou_metric': 0.8489530086517334, 'Train/mean f1': 0.9195027351379395, 'Train/mean precision': 0.9253243207931519, 'Train/mean recall': 0.9137540459632874, 'Train/mean hd95_metric': 27.302194595336914}
Epoch [127/300] Validation [1/16] Loss: 0.57360  focal_loss 0.32382  dice_loss 0.24979 
Epoch [127/300] Validation [2/16] Loss: 0.39921  focal_loss 0.11539  dice_loss 0.28382 
Epoch [127/300] Validation [3/16] Loss: 0.53733  focal_loss 0.24666  dice_loss 0.29067 
Epoch [127/300] Validation [4/16] Loss: 0.43211  focal_loss 0.18951  dice_loss 0.24259 
Epoch [127/300] Validation [5/16] Loss: 0.32427  focal_loss 0.06717  dice_loss 0.25710 
Epoch [127/300] Validation [6/16] Loss: 0.35378  focal_loss 0.08447  dice_loss 0.26931 
Epoch [127/300] Validation [7/16] Loss: 0.17694  focal_loss 0.05705  dice_loss 0.11989 
Epoch [127/300] Validation [8/16] Loss: 0.43659  focal_loss 0.12314  dice_loss 0.31345 
Epoch [127/300] Validation [9/16] Loss: 0.32915  focal_loss 0.11606  dice_loss 0.21309 
Epoch [127/300] Validation [10/16] Loss: 0.52500  focal_loss 0.13253  dice_loss 0.39247 
Epoch [127/300] Validation [11/16] Loss: 0.18533  focal_loss 0.04967  dice_loss 0.13566 
Epoch [127/300] Validation [12/16] Loss: 0.38922  focal_loss 0.09580  dice_loss 0.29342 
Epoch [127/300] Validation [13/16] Loss: 0.32723  focal_loss 0.08529  dice_loss 0.24195 
Epoch [127/300] Validation [14/16] Loss: 0.55538  focal_loss 0.15908  dice_loss 0.39631 
Epoch [127/300] Validation [15/16] Loss: 0.14806  focal_loss 0.03554  dice_loss 0.11252 
Epoch [127/300] Validation [16/16] Loss: 0.20086  focal_loss 0.05820  dice_loss 0.14266 
Epoch [127/300] Validation metric {'Val/mean dice_metric': 0.8791951537132263, 'Val/mean miou_metric': 0.812706470489502, 'Val/mean f1': 0.896607518196106, 'Val/mean precision': 0.9093208909034729, 'Val/mean recall': 0.8842447996139526, 'Val/mean hd95_metric': 33.644325256347656}
Cheakpoint...
Epoch [127/300] best acc:tensor([0.8792], device='cuda:0'), Now : mean acc: tensor([0.8792], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8791951537132263, 'Val/mean miou_metric': 0.812706470489502, 'Val/mean f1': 0.896607518196106, 'Val/mean precision': 0.9093208909034729, 'Val/mean recall': 0.8842447996139526, 'Val/mean hd95_metric': 33.644325256347656}
Epoch [128/300] Training [1/62] Loss: 0.10846 
Epoch [128/300] Training [2/62] Loss: 0.18790 
Epoch [128/300] Training [3/62] Loss: 0.18653 
Epoch [128/300] Training [4/62] Loss: 0.12630 
Epoch [128/300] Training [5/62] Loss: 0.16492 
Epoch [128/300] Training [6/62] Loss: 0.09347 
Epoch [128/300] Training [7/62] Loss: 0.15504 
Epoch [128/300] Training [8/62] Loss: 0.09546 
Epoch [128/300] Training [9/62] Loss: 0.22769 
Epoch [128/300] Training [10/62] Loss: 0.08597 
Epoch [128/300] Training [11/62] Loss: 0.11338 
Epoch [128/300] Training [12/62] Loss: 0.08004 
Epoch [128/300] Training [13/62] Loss: 0.21619 
Epoch [128/300] Training [14/62] Loss: 0.17074 
Epoch [128/300] Training [15/62] Loss: 0.12783 
Epoch [128/300] Training [16/62] Loss: 0.14221 
Epoch [128/300] Training [17/62] Loss: 0.10926 
Epoch [128/300] Training [18/62] Loss: 0.09815 
Epoch [128/300] Training [19/62] Loss: 0.20814 
Epoch [128/300] Training [20/62] Loss: 0.15600 
Epoch [128/300] Training [21/62] Loss: 0.14147 
Epoch [128/300] Training [22/62] Loss: 0.12362 
Epoch [128/300] Training [23/62] Loss: 0.22512 
Epoch [128/300] Training [24/62] Loss: 0.06082 
Epoch [128/300] Training [25/62] Loss: 0.09759 
Epoch [128/300] Training [26/62] Loss: 0.10474 
Epoch [128/300] Training [27/62] Loss: 0.17315 
Epoch [128/300] Training [28/62] Loss: 0.15459 
Epoch [128/300] Training [29/62] Loss: 0.07457 
Epoch [128/300] Training [30/62] Loss: 0.10580 
Epoch [128/300] Training [31/62] Loss: 0.18657 
Epoch [128/300] Training [32/62] Loss: 0.08662 
Epoch [128/300] Training [33/62] Loss: 0.07519 
Epoch [128/300] Training [34/62] Loss: 0.15129 
Epoch [128/300] Training [35/62] Loss: 0.20043 
Epoch [128/300] Training [36/62] Loss: 0.10751 
Epoch [128/300] Training [37/62] Loss: 0.22573 
Epoch [128/300] Training [38/62] Loss: 0.11276 
Epoch [128/300] Training [39/62] Loss: 0.08328 
Epoch [128/300] Training [40/62] Loss: 0.15944 
Epoch [128/300] Training [41/62] Loss: 0.06712 
Epoch [128/300] Training [42/62] Loss: 0.14585 
Epoch [128/300] Training [43/62] Loss: 0.16635 
Epoch [128/300] Training [44/62] Loss: 0.18308 
Epoch [128/300] Training [45/62] Loss: 0.22262 
Epoch [128/300] Training [46/62] Loss: 0.15288 
Epoch [128/300] Training [47/62] Loss: 0.13612 
Epoch [128/300] Training [48/62] Loss: 0.10292 
Epoch [128/300] Training [49/62] Loss: 0.18723 
Epoch [128/300] Training [50/62] Loss: 0.09670 
Epoch [128/300] Training [51/62] Loss: 0.10483 
Epoch [128/300] Training [52/62] Loss: 0.19171 
Epoch [128/300] Training [53/62] Loss: 0.07977 
Epoch [128/300] Training [54/62] Loss: 0.15604 
Epoch [128/300] Training [55/62] Loss: 0.21340 
Epoch [128/300] Training [56/62] Loss: 0.07833 
Epoch [128/300] Training [57/62] Loss: 0.15157 
Epoch [128/300] Training [58/62] Loss: 0.14238 
Epoch [128/300] Training [59/62] Loss: 0.23564 
Epoch [128/300] Training [60/62] Loss: 0.06735 
Epoch [128/300] Training [61/62] Loss: 0.06261 
Epoch [128/300] Training [62/62] Loss: 0.08807 
Epoch [128/300] Training metric {'Train/mean dice_metric': 0.9053323864936829, 'Train/mean miou_metric': 0.8465394973754883, 'Train/mean f1': 0.9227136969566345, 'Train/mean precision': 0.9257928133010864, 'Train/mean recall': 0.9196550250053406, 'Train/mean hd95_metric': 25.906858444213867}
Epoch [128/300] Validation [1/16] Loss: 0.83070  focal_loss 0.46461  dice_loss 0.36609 
Epoch [128/300] Validation [2/16] Loss: 0.62016  focal_loss 0.17543  dice_loss 0.44474 
Epoch [128/300] Validation [3/16] Loss: 0.62457  focal_loss 0.29431  dice_loss 0.33025 
Epoch [128/300] Validation [4/16] Loss: 0.51763  focal_loss 0.23816  dice_loss 0.27947 
Epoch [128/300] Validation [5/16] Loss: 0.44714  focal_loss 0.11288  dice_loss 0.33426 
Epoch [128/300] Validation [6/16] Loss: 0.26547  focal_loss 0.06599  dice_loss 0.19949 
Epoch [128/300] Validation [7/16] Loss: 0.55206  focal_loss 0.20339  dice_loss 0.34867 
Epoch [128/300] Validation [8/16] Loss: 0.58719  focal_loss 0.18945  dice_loss 0.39774 
Epoch [128/300] Validation [9/16] Loss: 0.69933  focal_loss 0.27088  dice_loss 0.42845 
Epoch [128/300] Validation [10/16] Loss: 0.61695  focal_loss 0.16104  dice_loss 0.45590 
Epoch [128/300] Validation [11/16] Loss: 0.45835  focal_loss 0.12217  dice_loss 0.33618 
Epoch [128/300] Validation [12/16] Loss: 0.43316  focal_loss 0.09058  dice_loss 0.34258 
Epoch [128/300] Validation [13/16] Loss: 0.38074  focal_loss 0.11655  dice_loss 0.26419 
Epoch [128/300] Validation [14/16] Loss: 0.69348  focal_loss 0.21488  dice_loss 0.47859 
Epoch [128/300] Validation [15/16] Loss: 0.29382  focal_loss 0.10341  dice_loss 0.19041 
Epoch [128/300] Validation [16/16] Loss: 0.19439  focal_loss 0.05329  dice_loss 0.14110 
Epoch [128/300] Validation metric {'Val/mean dice_metric': 0.8578532934188843, 'Val/mean miou_metric': 0.7910216450691223, 'Val/mean f1': 0.8878904581069946, 'Val/mean precision': 0.9090452194213867, 'Val/mean recall': 0.8676978349685669, 'Val/mean hd95_metric': 34.68569564819336}
Cheakpoint...
Epoch [128/300] best acc:tensor([0.8792], device='cuda:0'), Now : mean acc: tensor([0.8579], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8578532934188843, 'Val/mean miou_metric': 0.7910216450691223, 'Val/mean f1': 0.8878904581069946, 'Val/mean precision': 0.9090452194213867, 'Val/mean recall': 0.8676978349685669, 'Val/mean hd95_metric': 34.68569564819336}
Epoch [129/300] Training [1/62] Loss: 0.14485 
Epoch [129/300] Training [2/62] Loss: 0.12982 
Epoch [129/300] Training [3/62] Loss: 0.12982 
Epoch [129/300] Training [4/62] Loss: 0.14336 
Epoch [129/300] Training [5/62] Loss: 0.16670 
Epoch [129/300] Training [6/62] Loss: 0.12725 
Epoch [129/300] Training [7/62] Loss: 0.21259 
Epoch [129/300] Training [8/62] Loss: 0.07333 
Epoch [129/300] Training [9/62] Loss: 0.10954 
Epoch [129/300] Training [10/62] Loss: 0.11299 
Epoch [129/300] Training [11/62] Loss: 0.09961 
Epoch [129/300] Training [12/62] Loss: 0.18313 
Epoch [129/300] Training [13/62] Loss: 0.18908 
Epoch [129/300] Training [14/62] Loss: 0.07519 
Epoch [129/300] Training [15/62] Loss: 0.11743 
Epoch [129/300] Training [16/62] Loss: 0.09817 
Epoch [129/300] Training [17/62] Loss: 0.12374 
Epoch [129/300] Training [18/62] Loss: 0.09155 
Epoch [129/300] Training [19/62] Loss: 0.22337 
Epoch [129/300] Training [20/62] Loss: 0.10089 
Epoch [129/300] Training [21/62] Loss: 0.27291 
Epoch [129/300] Training [22/62] Loss: 0.15130 
Epoch [129/300] Training [23/62] Loss: 0.11009 
Epoch [129/300] Training [24/62] Loss: 0.24550 
Epoch [129/300] Training [25/62] Loss: 0.07904 
Epoch [129/300] Training [26/62] Loss: 0.09494 
Epoch [129/300] Training [27/62] Loss: 0.06212 
Epoch [129/300] Training [28/62] Loss: 0.20626 
Epoch [129/300] Training [29/62] Loss: 0.08581 
Epoch [129/300] Training [30/62] Loss: 0.09738 
Epoch [129/300] Training [31/62] Loss: 0.16680 
Epoch [129/300] Training [32/62] Loss: 0.08109 
Epoch [129/300] Training [33/62] Loss: 0.10554 
Epoch [129/300] Training [34/62] Loss: 0.08874 
Epoch [129/300] Training [35/62] Loss: 0.13028 
Epoch [129/300] Training [36/62] Loss: 0.09789 
Epoch [129/300] Training [37/62] Loss: 0.27696 
Epoch [129/300] Training [38/62] Loss: 0.19969 
Epoch [129/300] Training [39/62] Loss: 0.17642 
Epoch [129/300] Training [40/62] Loss: 0.19985 
Epoch [129/300] Training [41/62] Loss: 0.38180 
Epoch [129/300] Training [42/62] Loss: 0.08414 
Epoch [129/300] Training [43/62] Loss: 0.08242 
Epoch [129/300] Training [44/62] Loss: 0.06680 
Epoch [129/300] Training [45/62] Loss: 0.15507 
Epoch [129/300] Training [46/62] Loss: 0.08846 
Epoch [129/300] Training [47/62] Loss: 0.14579 
Epoch [129/300] Training [48/62] Loss: 0.06820 
Epoch [129/300] Training [49/62] Loss: 0.08772 
Epoch [129/300] Training [50/62] Loss: 0.12615 
Epoch [129/300] Training [51/62] Loss: 0.17122 
Epoch [129/300] Training [52/62] Loss: 0.30124 
Epoch [129/300] Training [53/62] Loss: 0.08202 
Epoch [129/300] Training [54/62] Loss: 0.07086 
Epoch [129/300] Training [55/62] Loss: 0.25888 
Epoch [129/300] Training [56/62] Loss: 0.08372 
Epoch [129/300] Training [57/62] Loss: 0.28304 
Epoch [129/300] Training [58/62] Loss: 0.15573 
Epoch [129/300] Training [59/62] Loss: 0.11738 
Epoch [129/300] Training [60/62] Loss: 0.10736 
Epoch [129/300] Training [61/62] Loss: 0.10371 
Epoch [129/300] Training [62/62] Loss: 0.12224 
Epoch [129/300] Training metric {'Train/mean dice_metric': 0.9032750129699707, 'Train/mean miou_metric': 0.84490966796875, 'Train/mean f1': 0.9239084124565125, 'Train/mean precision': 0.9250046610832214, 'Train/mean recall': 0.9228149652481079, 'Train/mean hd95_metric': 25.24384117126465}
Epoch [129/300] Validation [1/16] Loss: 0.77155  focal_loss 0.45114  dice_loss 0.32041 
Epoch [129/300] Validation [2/16] Loss: 0.45270  focal_loss 0.13988  dice_loss 0.31282 
Epoch [129/300] Validation [3/16] Loss: 0.65680  focal_loss 0.29612  dice_loss 0.36068 
Epoch [129/300] Validation [4/16] Loss: 0.37105  focal_loss 0.15698  dice_loss 0.21407 
Epoch [129/300] Validation [5/16] Loss: 0.47580  focal_loss 0.10907  dice_loss 0.36673 
Epoch [129/300] Validation [6/16] Loss: 0.31204  focal_loss 0.05966  dice_loss 0.25238 
Epoch [129/300] Validation [7/16] Loss: 0.23237  focal_loss 0.08134  dice_loss 0.15103 
Epoch [129/300] Validation [8/16] Loss: 0.58087  focal_loss 0.15098  dice_loss 0.42989 
Epoch [129/300] Validation [9/16] Loss: 0.50741  focal_loss 0.21251  dice_loss 0.29490 
Epoch [129/300] Validation [10/16] Loss: 0.71143  focal_loss 0.21209  dice_loss 0.49934 
Epoch [129/300] Validation [11/16] Loss: 0.28129  focal_loss 0.08483  dice_loss 0.19645 
Epoch [129/300] Validation [12/16] Loss: 0.55545  focal_loss 0.12191  dice_loss 0.43354 
Epoch [129/300] Validation [13/16] Loss: 0.28064  focal_loss 0.11022  dice_loss 0.17041 
Epoch [129/300] Validation [14/16] Loss: 0.54224  focal_loss 0.16242  dice_loss 0.37981 
Epoch [129/300] Validation [15/16] Loss: 0.16534  focal_loss 0.05186  dice_loss 0.11348 
Epoch [129/300] Validation [16/16] Loss: 0.10893  focal_loss 0.02853  dice_loss 0.08040 
Epoch [129/300] Validation metric {'Val/mean dice_metric': 0.8650074005126953, 'Val/mean miou_metric': 0.8003420233726501, 'Val/mean f1': 0.8967642188072205, 'Val/mean precision': 0.9099931716918945, 'Val/mean recall': 0.8839142918586731, 'Val/mean hd95_metric': 32.15194320678711}
Cheakpoint...
Epoch [129/300] best acc:tensor([0.8792], device='cuda:0'), Now : mean acc: tensor([0.8650], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8650074005126953, 'Val/mean miou_metric': 0.8003420233726501, 'Val/mean f1': 0.8967642188072205, 'Val/mean precision': 0.9099931716918945, 'Val/mean recall': 0.8839142918586731, 'Val/mean hd95_metric': 32.15194320678711}
Epoch [130/300] Training [1/62] Loss: 0.14197 
Epoch [130/300] Training [2/62] Loss: 0.08546 
Epoch [130/300] Training [3/62] Loss: 0.15875 
Epoch [130/300] Training [4/62] Loss: 0.12827 
Epoch [130/300] Training [5/62] Loss: 0.09996 
Epoch [130/300] Training [6/62] Loss: 0.16521 
Epoch [130/300] Training [7/62] Loss: 0.08313 
Epoch [130/300] Training [8/62] Loss: 0.11182 
Epoch [130/300] Training [9/62] Loss: 0.12059 
Epoch [130/300] Training [10/62] Loss: 0.09892 
Epoch [130/300] Training [11/62] Loss: 0.06035 
Epoch [130/300] Training [12/62] Loss: 0.05963 
Epoch [130/300] Training [13/62] Loss: 0.17837 
Epoch [130/300] Training [14/62] Loss: 0.15104 
Epoch [130/300] Training [15/62] Loss: 0.19023 
Epoch [130/300] Training [16/62] Loss: 0.12197 
Epoch [130/300] Training [17/62] Loss: 0.13447 
Epoch [130/300] Training [18/62] Loss: 0.11667 
Epoch [130/300] Training [19/62] Loss: 0.26185 
Epoch [130/300] Training [20/62] Loss: 0.08705 
Epoch [130/300] Training [21/62] Loss: 0.10580 
Epoch [130/300] Training [22/62] Loss: 0.20305 
Epoch [130/300] Training [23/62] Loss: 0.14379 
Epoch [130/300] Training [24/62] Loss: 0.13004 
Epoch [130/300] Training [25/62] Loss: 0.16069 
Epoch [130/300] Training [26/62] Loss: 0.14943 
Epoch [130/300] Training [27/62] Loss: 0.18768 
Epoch [130/300] Training [28/62] Loss: 0.23378 
Epoch [130/300] Training [29/62] Loss: 0.12415 
Epoch [130/300] Training [30/62] Loss: 0.20526 
Epoch [130/300] Training [31/62] Loss: 0.06833 
Epoch [130/300] Training [32/62] Loss: 0.09373 
Epoch [130/300] Training [33/62] Loss: 0.18750 
Epoch [130/300] Training [34/62] Loss: 0.23693 
Epoch [130/300] Training [35/62] Loss: 0.05685 
Epoch [130/300] Training [36/62] Loss: 0.14956 
Epoch [130/300] Training [37/62] Loss: 0.08618 
Epoch [130/300] Training [38/62] Loss: 0.10272 
Epoch [130/300] Training [39/62] Loss: 0.21354 
Epoch [130/300] Training [40/62] Loss: 0.13422 
Epoch [130/300] Training [41/62] Loss: 0.11511 
Epoch [130/300] Training [42/62] Loss: 0.15219 
Epoch [130/300] Training [43/62] Loss: 0.09176 
Epoch [130/300] Training [44/62] Loss: 0.05790 
Epoch [130/300] Training [45/62] Loss: 0.08185 
Epoch [130/300] Training [46/62] Loss: 0.26625 
Epoch [130/300] Training [47/62] Loss: 0.14584 
Epoch [130/300] Training [48/62] Loss: 0.14547 
Epoch [130/300] Training [49/62] Loss: 0.07740 
Epoch [130/300] Training [50/62] Loss: 0.15259 
Epoch [130/300] Training [51/62] Loss: 0.11051 
Epoch [130/300] Training [52/62] Loss: 0.34815 
Epoch [130/300] Training [53/62] Loss: 0.15106 
Epoch [130/300] Training [54/62] Loss: 0.10939 
Epoch [130/300] Training [55/62] Loss: 0.10569 
Epoch [130/300] Training [56/62] Loss: 0.18248 
Epoch [130/300] Training [57/62] Loss: 0.19249 
Epoch [130/300] Training [58/62] Loss: 0.10999 
Epoch [130/300] Training [59/62] Loss: 0.11158 
Epoch [130/300] Training [60/62] Loss: 0.07074 
Epoch [130/300] Training [61/62] Loss: 0.14244 
Epoch [130/300] Training [62/62] Loss: 0.03390 
Epoch [130/300] Training metric {'Train/mean dice_metric': 0.9072074890136719, 'Train/mean miou_metric': 0.8480492830276489, 'Train/mean f1': 0.9227238893508911, 'Train/mean precision': 0.925894021987915, 'Train/mean recall': 0.9195755124092102, 'Train/mean hd95_metric': 27.858469009399414}
Epoch [130/300] Validation [1/16] Loss: 0.85501  focal_loss 0.54919  dice_loss 0.30582 
Epoch [130/300] Validation [2/16] Loss: 0.53405  focal_loss 0.19517  dice_loss 0.33888 
Epoch [130/300] Validation [3/16] Loss: 0.57395  focal_loss 0.26998  dice_loss 0.30396 
Epoch [130/300] Validation [4/16] Loss: 0.33456  focal_loss 0.14919  dice_loss 0.18537 
Epoch [130/300] Validation [5/16] Loss: 0.45600  focal_loss 0.12344  dice_loss 0.33256 
Epoch [130/300] Validation [6/16] Loss: 0.32283  focal_loss 0.07864  dice_loss 0.24419 
Epoch [130/300] Validation [7/16] Loss: 0.43487  focal_loss 0.17117  dice_loss 0.26370 
Epoch [130/300] Validation [8/16] Loss: 0.49804  focal_loss 0.18476  dice_loss 0.31328 
Epoch [130/300] Validation [9/16] Loss: 0.42912  focal_loss 0.19946  dice_loss 0.22967 
Epoch [130/300] Validation [10/16] Loss: 0.58482  focal_loss 0.18446  dice_loss 0.40037 
Epoch [130/300] Validation [11/16] Loss: 0.32632  focal_loss 0.10975  dice_loss 0.21657 
Epoch [130/300] Validation [12/16] Loss: 0.55001  focal_loss 0.12439  dice_loss 0.42562 
Epoch [130/300] Validation [13/16] Loss: 0.31879  focal_loss 0.10475  dice_loss 0.21404 
Epoch [130/300] Validation [14/16] Loss: 0.67050  focal_loss 0.25681  dice_loss 0.41369 
Epoch [130/300] Validation [15/16] Loss: 0.22426  focal_loss 0.07217  dice_loss 0.15209 
Epoch [130/300] Validation [16/16] Loss: 0.18705  focal_loss 0.06743  dice_loss 0.11962 
Epoch [130/300] Validation metric {'Val/mean dice_metric': 0.8704074025154114, 'Val/mean miou_metric': 0.802683413028717, 'Val/mean f1': 0.8916977047920227, 'Val/mean precision': 0.9116866588592529, 'Val/mean recall': 0.8725664019584656, 'Val/mean hd95_metric': 34.42533874511719}
Cheakpoint...
Epoch [130/300] best acc:tensor([0.8792], device='cuda:0'), Now : mean acc: tensor([0.8704], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8704074025154114, 'Val/mean miou_metric': 0.802683413028717, 'Val/mean f1': 0.8916977047920227, 'Val/mean precision': 0.9116866588592529, 'Val/mean recall': 0.8725664019584656, 'Val/mean hd95_metric': 34.42533874511719}
Epoch [131/300] Training [1/62] Loss: 0.12981 
Epoch [131/300] Training [2/62] Loss: 0.07694 
Epoch [131/300] Training [3/62] Loss: 0.13917 
Epoch [131/300] Training [4/62] Loss: 0.07630 
Epoch [131/300] Training [5/62] Loss: 0.10094 
Epoch [131/300] Training [6/62] Loss: 0.09012 
Epoch [131/300] Training [7/62] Loss: 0.09298 
Epoch [131/300] Training [8/62] Loss: 0.09637 
Epoch [131/300] Training [9/62] Loss: 0.28943 
Epoch [131/300] Training [10/62] Loss: 0.12180 
Epoch [131/300] Training [11/62] Loss: 0.13469 
Epoch [131/300] Training [12/62] Loss: 0.14111 
Epoch [131/300] Training [13/62] Loss: 0.13847 
Epoch [131/300] Training [14/62] Loss: 0.25215 
Epoch [131/300] Training [15/62] Loss: 0.27595 
Epoch [131/300] Training [16/62] Loss: 0.19538 
Epoch [131/300] Training [17/62] Loss: 0.12026 
Epoch [131/300] Training [18/62] Loss: 0.10902 
Epoch [131/300] Training [19/62] Loss: 0.18537 
Epoch [131/300] Training [20/62] Loss: 0.10084 
Epoch [131/300] Training [21/62] Loss: 0.12924 
Epoch [131/300] Training [22/62] Loss: 0.12228 
Epoch [131/300] Training [23/62] Loss: 0.07610 
Epoch [131/300] Training [24/62] Loss: 0.11468 
Epoch [131/300] Training [25/62] Loss: 0.09809 
Epoch [131/300] Training [26/62] Loss: 0.11121 
Epoch [131/300] Training [27/62] Loss: 0.06362 
Epoch [131/300] Training [28/62] Loss: 0.19687 
Epoch [131/300] Training [29/62] Loss: 0.21882 
Epoch [131/300] Training [30/62] Loss: 0.17770 
Epoch [131/300] Training [31/62] Loss: 0.13998 
Epoch [131/300] Training [32/62] Loss: 0.19827 
Epoch [131/300] Training [33/62] Loss: 0.14223 
Epoch [131/300] Training [34/62] Loss: 0.06301 
Epoch [131/300] Training [35/62] Loss: 0.11442 
Epoch [131/300] Training [36/62] Loss: 0.19994 
Epoch [131/300] Training [37/62] Loss: 0.09629 
Epoch [131/300] Training [38/62] Loss: 0.09492 
Epoch [131/300] Training [39/62] Loss: 0.11389 
Epoch [131/300] Training [40/62] Loss: 0.06487 
Epoch [131/300] Training [41/62] Loss: 0.12212 
Epoch [131/300] Training [42/62] Loss: 0.10398 
Epoch [131/300] Training [43/62] Loss: 0.29701 
Epoch [131/300] Training [44/62] Loss: 0.15241 
Epoch [131/300] Training [45/62] Loss: 0.06581 
Epoch [131/300] Training [46/62] Loss: 0.10863 
Epoch [131/300] Training [47/62] Loss: 0.06848 
Epoch [131/300] Training [48/62] Loss: 0.09628 
Epoch [131/300] Training [49/62] Loss: 0.16061 
Epoch [131/300] Training [50/62] Loss: 0.08001 
Epoch [131/300] Training [51/62] Loss: 0.41508 
Epoch [131/300] Training [52/62] Loss: 0.13013 
Epoch [131/300] Training [53/62] Loss: 0.11165 
Epoch [131/300] Training [54/62] Loss: 0.10574 
Epoch [131/300] Training [55/62] Loss: 0.05637 
Epoch [131/300] Training [56/62] Loss: 0.08790 
Epoch [131/300] Training [57/62] Loss: 0.11838 
Epoch [131/300] Training [58/62] Loss: 0.22614 
Epoch [131/300] Training [59/62] Loss: 0.13636 
Epoch [131/300] Training [60/62] Loss: 0.12315 
Epoch [131/300] Training [61/62] Loss: 0.23939 
Epoch [131/300] Training [62/62] Loss: 0.16748 
Epoch [131/300] Training metric {'Train/mean dice_metric': 0.9047943949699402, 'Train/mean miou_metric': 0.8464947938919067, 'Train/mean f1': 0.9231441020965576, 'Train/mean precision': 0.9260296821594238, 'Train/mean recall': 0.9202764630317688, 'Train/mean hd95_metric': 27.469951629638672}
Epoch [131/300] Validation [1/16] Loss: 0.63598  focal_loss 0.34571  dice_loss 0.29027 
Epoch [131/300] Validation [2/16] Loss: 0.49382  focal_loss 0.16240  dice_loss 0.33142 
Epoch [131/300] Validation [3/16] Loss: 0.57034  focal_loss 0.25688  dice_loss 0.31346 
Epoch [131/300] Validation [4/16] Loss: 0.48126  focal_loss 0.21463  dice_loss 0.26663 
Epoch [131/300] Validation [5/16] Loss: 0.43180  focal_loss 0.10994  dice_loss 0.32186 
Epoch [131/300] Validation [6/16] Loss: 0.27506  focal_loss 0.07257  dice_loss 0.20249 
Epoch [131/300] Validation [7/16] Loss: 0.23740  focal_loss 0.08107  dice_loss 0.15633 
Epoch [131/300] Validation [8/16] Loss: 0.52077  focal_loss 0.14344  dice_loss 0.37733 
Epoch [131/300] Validation [9/16] Loss: 0.40716  focal_loss 0.12874  dice_loss 0.27842 
Epoch [131/300] Validation [10/16] Loss: 0.60739  focal_loss 0.17810  dice_loss 0.42930 
Epoch [131/300] Validation [11/16] Loss: 0.27603  focal_loss 0.09075  dice_loss 0.18529 
Epoch [131/300] Validation [12/16] Loss: 0.38669  focal_loss 0.07518  dice_loss 0.31151 
Epoch [131/300] Validation [13/16] Loss: 0.19811  focal_loss 0.04522  dice_loss 0.15290 
Epoch [131/300] Validation [14/16] Loss: 0.64222  focal_loss 0.19600  dice_loss 0.44621 
Epoch [131/300] Validation [15/16] Loss: 0.15305  focal_loss 0.03587  dice_loss 0.11718 
Epoch [131/300] Validation [16/16] Loss: 0.28598  focal_loss 0.08430  dice_loss 0.20168 
Epoch [131/300] Validation metric {'Val/mean dice_metric': 0.8710104823112488, 'Val/mean miou_metric': 0.8046518564224243, 'Val/mean f1': 0.8949908018112183, 'Val/mean precision': 0.9115498065948486, 'Val/mean recall': 0.8790226578712463, 'Val/mean hd95_metric': 35.24665832519531}
Cheakpoint...
Epoch [131/300] best acc:tensor([0.8792], device='cuda:0'), Now : mean acc: tensor([0.8710], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8710104823112488, 'Val/mean miou_metric': 0.8046518564224243, 'Val/mean f1': 0.8949908018112183, 'Val/mean precision': 0.9115498065948486, 'Val/mean recall': 0.8790226578712463, 'Val/mean hd95_metric': 35.24665832519531}
Epoch [132/300] Training [1/62] Loss: 0.06954 
Epoch [132/300] Training [2/62] Loss: 0.10071 
Epoch [132/300] Training [3/62] Loss: 0.06309 
Epoch [132/300] Training [4/62] Loss: 0.11264 
Epoch [132/300] Training [5/62] Loss: 0.14531 
Epoch [132/300] Training [6/62] Loss: 0.26675 
Epoch [132/300] Training [7/62] Loss: 0.14253 
Epoch [132/300] Training [8/62] Loss: 0.20316 
Epoch [132/300] Training [9/62] Loss: 0.07592 
Epoch [132/300] Training [10/62] Loss: 0.15324 
Epoch [132/300] Training [11/62] Loss: 0.25268 
Epoch [132/300] Training [12/62] Loss: 0.15354 
Epoch [132/300] Training [13/62] Loss: 0.16976 
Epoch [132/300] Training [14/62] Loss: 0.15300 
Epoch [132/300] Training [15/62] Loss: 0.23221 
Epoch [132/300] Training [16/62] Loss: 0.25036 
Epoch [132/300] Training [17/62] Loss: 0.15363 
Epoch [132/300] Training [18/62] Loss: 0.23143 
Epoch [132/300] Training [19/62] Loss: 0.21013 
Epoch [132/300] Training [20/62] Loss: 0.16467 
Epoch [132/300] Training [21/62] Loss: 0.07916 
Epoch [132/300] Training [22/62] Loss: 0.12349 
Epoch [132/300] Training [23/62] Loss: 0.11235 
Epoch [132/300] Training [24/62] Loss: 0.13853 
Epoch [132/300] Training [25/62] Loss: 0.14892 
Epoch [132/300] Training [26/62] Loss: 0.08999 
Epoch [132/300] Training [27/62] Loss: 0.13188 
Epoch [132/300] Training [28/62] Loss: 0.18171 
Epoch [132/300] Training [29/62] Loss: 0.17175 
Epoch [132/300] Training [30/62] Loss: 0.08670 
Epoch [132/300] Training [31/62] Loss: 0.08978 
Epoch [132/300] Training [32/62] Loss: 0.05980 
Epoch [132/300] Training [33/62] Loss: 0.09914 
Epoch [132/300] Training [34/62] Loss: 0.23119 
Epoch [132/300] Training [35/62] Loss: 0.11337 
Epoch [132/300] Training [36/62] Loss: 0.17502 
Epoch [132/300] Training [37/62] Loss: 0.08257 
Epoch [132/300] Training [38/62] Loss: 0.08088 
Epoch [132/300] Training [39/62] Loss: 0.22151 
Epoch [132/300] Training [40/62] Loss: 0.07284 
Epoch [132/300] Training [41/62] Loss: 0.08094 
Epoch [132/300] Training [42/62] Loss: 0.10344 
Epoch [132/300] Training [43/62] Loss: 0.12555 
Epoch [132/300] Training [44/62] Loss: 0.09719 
Epoch [132/300] Training [45/62] Loss: 0.09037 
Epoch [132/300] Training [46/62] Loss: 0.20660 
Epoch [132/300] Training [47/62] Loss: 0.07797 
Epoch [132/300] Training [48/62] Loss: 0.09704 
Epoch [132/300] Training [49/62] Loss: 0.07020 
Epoch [132/300] Training [50/62] Loss: 0.14418 
Epoch [132/300] Training [51/62] Loss: 0.12789 
Epoch [132/300] Training [52/62] Loss: 0.16276 
Epoch [132/300] Training [53/62] Loss: 0.07129 
Epoch [132/300] Training [54/62] Loss: 0.05726 
Epoch [132/300] Training [55/62] Loss: 0.09830 
Epoch [132/300] Training [56/62] Loss: 0.15846 
Epoch [132/300] Training [57/62] Loss: 0.09660 
Epoch [132/300] Training [58/62] Loss: 0.07458 
Epoch [132/300] Training [59/62] Loss: 0.17642 
Epoch [132/300] Training [60/62] Loss: 0.14738 
Epoch [132/300] Training [61/62] Loss: 0.18610 
Epoch [132/300] Training [62/62] Loss: 0.25808 
Epoch [132/300] Training metric {'Train/mean dice_metric': 0.9069281220436096, 'Train/mean miou_metric': 0.8491581678390503, 'Train/mean f1': 0.926283597946167, 'Train/mean precision': 0.9267741441726685, 'Train/mean recall': 0.9257936477661133, 'Train/mean hd95_metric': 26.323989868164062}
Epoch [132/300] Validation [1/16] Loss: 0.61668  focal_loss 0.38993  dice_loss 0.22675 
Epoch [132/300] Validation [2/16] Loss: 0.49119  focal_loss 0.16061  dice_loss 0.33058 
Epoch [132/300] Validation [3/16] Loss: 0.63814  focal_loss 0.31269  dice_loss 0.32545 
Epoch [132/300] Validation [4/16] Loss: 0.37352  focal_loss 0.15504  dice_loss 0.21849 
Epoch [132/300] Validation [5/16] Loss: 0.40809  focal_loss 0.10200  dice_loss 0.30608 
Epoch [132/300] Validation [6/16] Loss: 0.30781  focal_loss 0.07343  dice_loss 0.23438 
Epoch [132/300] Validation [7/16] Loss: 0.33842  focal_loss 0.09982  dice_loss 0.23860 
Epoch [132/300] Validation [8/16] Loss: 0.50941  focal_loss 0.16117  dice_loss 0.34824 
Epoch [132/300] Validation [9/16] Loss: 0.19340  focal_loss 0.05724  dice_loss 0.13616 
Epoch [132/300] Validation [10/16] Loss: 0.59404  focal_loss 0.17205  dice_loss 0.42199 
Epoch [132/300] Validation [11/16] Loss: 0.24991  focal_loss 0.07719  dice_loss 0.17272 
Epoch [132/300] Validation [12/16] Loss: 0.38548  focal_loss 0.08881  dice_loss 0.29667 
Epoch [132/300] Validation [13/16] Loss: 0.25602  focal_loss 0.08910  dice_loss 0.16693 
Epoch [132/300] Validation [14/16] Loss: 0.64695  focal_loss 0.23447  dice_loss 0.41247 
Epoch [132/300] Validation [15/16] Loss: 0.19493  focal_loss 0.05538  dice_loss 0.13955 
Epoch [132/300] Validation [16/16] Loss: 0.23831  focal_loss 0.06625  dice_loss 0.17206 
Epoch [132/300] Validation metric {'Val/mean dice_metric': 0.8748555779457092, 'Val/mean miou_metric': 0.8106464147567749, 'Val/mean f1': 0.9004706740379333, 'Val/mean precision': 0.9121653437614441, 'Val/mean recall': 0.889072060585022, 'Val/mean hd95_metric': 32.59111022949219}
Cheakpoint...
Epoch [132/300] best acc:tensor([0.8792], device='cuda:0'), Now : mean acc: tensor([0.8749], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8748555779457092, 'Val/mean miou_metric': 0.8106464147567749, 'Val/mean f1': 0.9004706740379333, 'Val/mean precision': 0.9121653437614441, 'Val/mean recall': 0.889072060585022, 'Val/mean hd95_metric': 32.59111022949219}
Epoch [133/300] Training [1/62] Loss: 0.12339 
Epoch [133/300] Training [2/62] Loss: 0.09776 
Epoch [133/300] Training [3/62] Loss: 0.28465 
Epoch [133/300] Training [4/62] Loss: 0.20596 
Epoch [133/300] Training [5/62] Loss: 0.15265 
Epoch [133/300] Training [6/62] Loss: 0.11488 
Epoch [133/300] Training [7/62] Loss: 0.08749 
Epoch [133/300] Training [8/62] Loss: 0.09763 
Epoch [133/300] Training [9/62] Loss: 0.24588 
Epoch [133/300] Training [10/62] Loss: 0.07941 
Epoch [133/300] Training [11/62] Loss: 0.07789 
Epoch [133/300] Training [12/62] Loss: 0.17985 
Epoch [133/300] Training [13/62] Loss: 0.11880 
Epoch [133/300] Training [14/62] Loss: 0.14586 
Epoch [133/300] Training [15/62] Loss: 0.11501 
Epoch [133/300] Training [16/62] Loss: 0.14844 
Epoch [133/300] Training [17/62] Loss: 0.15360 
Epoch [133/300] Training [18/62] Loss: 0.08921 
Epoch [133/300] Training [19/62] Loss: 0.07838 
Epoch [133/300] Training [20/62] Loss: 0.10629 
Epoch [133/300] Training [21/62] Loss: 0.15752 
Epoch [133/300] Training [22/62] Loss: 0.09740 
Epoch [133/300] Training [23/62] Loss: 0.10760 
Epoch [133/300] Training [24/62] Loss: 0.05988 
Epoch [133/300] Training [25/62] Loss: 0.11132 
Epoch [133/300] Training [26/62] Loss: 0.06601 
Epoch [133/300] Training [27/62] Loss: 0.11919 
Epoch [133/300] Training [28/62] Loss: 0.13102 
Epoch [133/300] Training [29/62] Loss: 0.08789 
Epoch [133/300] Training [30/62] Loss: 0.21090 
Epoch [133/300] Training [31/62] Loss: 0.06477 
Epoch [133/300] Training [32/62] Loss: 0.23526 
Epoch [133/300] Training [33/62] Loss: 0.24073 
Epoch [133/300] Training [34/62] Loss: 0.19736 
Epoch [133/300] Training [35/62] Loss: 0.20017 
Epoch [133/300] Training [36/62] Loss: 0.17350 
Epoch [133/300] Training [37/62] Loss: 0.07757 
Epoch [133/300] Training [38/62] Loss: 0.09079 
Epoch [133/300] Training [39/62] Loss: 0.08832 
Epoch [133/300] Training [40/62] Loss: 0.11315 
Epoch [133/300] Training [41/62] Loss: 0.20878 
Epoch [133/300] Training [42/62] Loss: 0.26120 
Epoch [133/300] Training [43/62] Loss: 0.08878 
Epoch [133/300] Training [44/62] Loss: 0.21552 
Epoch [133/300] Training [45/62] Loss: 0.08816 
Epoch [133/300] Training [46/62] Loss: 0.10870 
Epoch [133/300] Training [47/62] Loss: 0.16830 
Epoch [133/300] Training [48/62] Loss: 0.15701 
Epoch [133/300] Training [49/62] Loss: 0.14433 
Epoch [133/300] Training [50/62] Loss: 0.13372 
Epoch [133/300] Training [51/62] Loss: 0.12366 
Epoch [133/300] Training [52/62] Loss: 0.22568 
Epoch [133/300] Training [53/62] Loss: 0.13752 
Epoch [133/300] Training [54/62] Loss: 0.11663 
Epoch [133/300] Training [55/62] Loss: 0.24447 
Epoch [133/300] Training [56/62] Loss: 0.09899 
Epoch [133/300] Training [57/62] Loss: 0.08035 
Epoch [133/300] Training [58/62] Loss: 0.11252 
Epoch [133/300] Training [59/62] Loss: 0.18464 
Epoch [133/300] Training [60/62] Loss: 0.12452 
Epoch [133/300] Training [61/62] Loss: 0.06614 
Epoch [133/300] Training [62/62] Loss: 0.24799 
Epoch [133/300] Training metric {'Train/mean dice_metric': 0.9065310955047607, 'Train/mean miou_metric': 0.8469843864440918, 'Train/mean f1': 0.9221294522285461, 'Train/mean precision': 0.9211416244506836, 'Train/mean recall': 0.9231194853782654, 'Train/mean hd95_metric': 24.571945190429688}
Epoch [133/300] Validation [1/16] Loss: 0.57403  focal_loss 0.34903  dice_loss 0.22500 
Epoch [133/300] Validation [2/16] Loss: 0.48104  focal_loss 0.14055  dice_loss 0.34049 
Epoch [133/300] Validation [3/16] Loss: 0.61209  focal_loss 0.26627  dice_loss 0.34582 
Epoch [133/300] Validation [4/16] Loss: 0.26126  focal_loss 0.08812  dice_loss 0.17314 
Epoch [133/300] Validation [5/16] Loss: 0.38306  focal_loss 0.09334  dice_loss 0.28972 
Epoch [133/300] Validation [6/16] Loss: 0.29135  focal_loss 0.07525  dice_loss 0.21610 
Epoch [133/300] Validation [7/16] Loss: 0.23706  focal_loss 0.07586  dice_loss 0.16120 
Epoch [133/300] Validation [8/16] Loss: 0.66601  focal_loss 0.17968  dice_loss 0.48634 
Epoch [133/300] Validation [9/16] Loss: 0.30522  focal_loss 0.11694  dice_loss 0.18828 
Epoch [133/300] Validation [10/16] Loss: 0.49966  focal_loss 0.13951  dice_loss 0.36016 
Epoch [133/300] Validation [11/16] Loss: 0.15092  focal_loss 0.03678  dice_loss 0.11413 
Epoch [133/300] Validation [12/16] Loss: 0.36893  focal_loss 0.08029  dice_loss 0.28864 
Epoch [133/300] Validation [13/16] Loss: 0.20480  focal_loss 0.05007  dice_loss 0.15473 
Epoch [133/300] Validation [14/16] Loss: 0.59474  focal_loss 0.22107  dice_loss 0.37367 
Epoch [133/300] Validation [15/16] Loss: 0.15742  focal_loss 0.03738  dice_loss 0.12004 
Epoch [133/300] Validation [16/16] Loss: 0.17953  focal_loss 0.05135  dice_loss 0.12818 
Epoch [133/300] Validation metric {'Val/mean dice_metric': 0.8766926527023315, 'Val/mean miou_metric': 0.8111851215362549, 'Val/mean f1': 0.8977084159851074, 'Val/mean precision': 0.9029763340950012, 'Val/mean recall': 0.8925016522407532, 'Val/mean hd95_metric': 32.40892791748047}
Cheakpoint...
Epoch [133/300] best acc:tensor([0.8792], device='cuda:0'), Now : mean acc: tensor([0.8767], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8766926527023315, 'Val/mean miou_metric': 0.8111851215362549, 'Val/mean f1': 0.8977084159851074, 'Val/mean precision': 0.9029763340950012, 'Val/mean recall': 0.8925016522407532, 'Val/mean hd95_metric': 32.40892791748047}
Epoch [134/300] Training [1/62] Loss: 0.07519 
Epoch [134/300] Training [2/62] Loss: 0.08801 
Epoch [134/300] Training [3/62] Loss: 0.17039 
Epoch [134/300] Training [4/62] Loss: 0.12853 
Epoch [134/300] Training [5/62] Loss: 0.08617 
Epoch [134/300] Training [6/62] Loss: 0.19993 
Epoch [134/300] Training [7/62] Loss: 0.06657 
Epoch [134/300] Training [8/62] Loss: 0.15021 
Epoch [134/300] Training [9/62] Loss: 0.22167 
Epoch [134/300] Training [10/62] Loss: 0.11307 
Epoch [134/300] Training [11/62] Loss: 0.18374 
Epoch [134/300] Training [12/62] Loss: 0.05311 
Epoch [134/300] Training [13/62] Loss: 0.07399 
Epoch [134/300] Training [14/62] Loss: 0.13197 
Epoch [134/300] Training [15/62] Loss: 0.16900 
Epoch [134/300] Training [16/62] Loss: 0.10778 
Epoch [134/300] Training [17/62] Loss: 0.09621 
Epoch [134/300] Training [18/62] Loss: 0.14778 
Epoch [134/300] Training [19/62] Loss: 0.13462 
Epoch [134/300] Training [20/62] Loss: 0.15353 
Epoch [134/300] Training [21/62] Loss: 0.10307 
Epoch [134/300] Training [22/62] Loss: 0.16317 
Epoch [134/300] Training [23/62] Loss: 0.27056 
Epoch [134/300] Training [24/62] Loss: 0.16178 
Epoch [134/300] Training [25/62] Loss: 0.10122 
Epoch [134/300] Training [26/62] Loss: 0.11691 
Epoch [134/300] Training [27/62] Loss: 0.07982 
Epoch [134/300] Training [28/62] Loss: 0.21745 
Epoch [134/300] Training [29/62] Loss: 0.18152 
Epoch [134/300] Training [30/62] Loss: 0.17805 
Epoch [134/300] Training [31/62] Loss: 0.18405 
Epoch [134/300] Training [32/62] Loss: 0.19317 
Epoch [134/300] Training [33/62] Loss: 0.07378 
Epoch [134/300] Training [34/62] Loss: 0.27899 
Epoch [134/300] Training [35/62] Loss: 0.17011 
Epoch [134/300] Training [36/62] Loss: 0.16570 
Epoch [134/300] Training [37/62] Loss: 0.09928 
Epoch [134/300] Training [38/62] Loss: 0.10108 
Epoch [134/300] Training [39/62] Loss: 0.08865 
Epoch [134/300] Training [40/62] Loss: 0.14518 
Epoch [134/300] Training [41/62] Loss: 0.18153 
Epoch [134/300] Training [42/62] Loss: 0.14334 
Epoch [134/300] Training [43/62] Loss: 0.08023 
Epoch [134/300] Training [44/62] Loss: 0.11163 
Epoch [134/300] Training [45/62] Loss: 0.06893 
Epoch [134/300] Training [46/62] Loss: 0.12348 
Epoch [134/300] Training [47/62] Loss: 0.15313 
Epoch [134/300] Training [48/62] Loss: 0.09824 
Epoch [134/300] Training [49/62] Loss: 0.16509 
Epoch [134/300] Training [50/62] Loss: 0.18657 
Epoch [134/300] Training [51/62] Loss: 0.07303 
Epoch [134/300] Training [52/62] Loss: 0.19182 
Epoch [134/300] Training [53/62] Loss: 0.06872 
Epoch [134/300] Training [54/62] Loss: 0.10122 
Epoch [134/300] Training [55/62] Loss: 0.19993 
Epoch [134/300] Training [56/62] Loss: 0.15699 
Epoch [134/300] Training [57/62] Loss: 0.07812 
Epoch [134/300] Training [58/62] Loss: 0.13365 
Epoch [134/300] Training [59/62] Loss: 0.09655 
Epoch [134/300] Training [60/62] Loss: 0.08401 
Epoch [134/300] Training [61/62] Loss: 0.10450 
Epoch [134/300] Training [62/62] Loss: 0.32950 
Epoch [134/300] Training metric {'Train/mean dice_metric': 0.907243549823761, 'Train/mean miou_metric': 0.8462725877761841, 'Train/mean f1': 0.9244165420532227, 'Train/mean precision': 0.9264301657676697, 'Train/mean recall': 0.9224116802215576, 'Train/mean hd95_metric': 27.0303897857666}
Epoch [134/300] Validation [1/16] Loss: 0.54890  focal_loss 0.34923  dice_loss 0.19968 
Epoch [134/300] Validation [2/16] Loss: 0.44746  focal_loss 0.12407  dice_loss 0.32338 
Epoch [134/300] Validation [3/16] Loss: 0.61022  focal_loss 0.31257  dice_loss 0.29765 
Epoch [134/300] Validation [4/16] Loss: 0.29073  focal_loss 0.09558  dice_loss 0.19515 
Epoch [134/300] Validation [5/16] Loss: 0.34978  focal_loss 0.08877  dice_loss 0.26101 
Epoch [134/300] Validation [6/16] Loss: 0.33944  focal_loss 0.08512  dice_loss 0.25432 
Epoch [134/300] Validation [7/16] Loss: 0.25188  focal_loss 0.07300  dice_loss 0.17889 
Epoch [134/300] Validation [8/16] Loss: 0.42959  focal_loss 0.12539  dice_loss 0.30421 
Epoch [134/300] Validation [9/16] Loss: 0.21607  focal_loss 0.07340  dice_loss 0.14266 
Epoch [134/300] Validation [10/16] Loss: 0.44859  focal_loss 0.10408  dice_loss 0.34451 
Epoch [134/300] Validation [11/16] Loss: 0.18088  focal_loss 0.04837  dice_loss 0.13251 
Epoch [134/300] Validation [12/16] Loss: 0.36193  focal_loss 0.07850  dice_loss 0.28342 
Epoch [134/300] Validation [13/16] Loss: 0.20577  focal_loss 0.05247  dice_loss 0.15330 
Epoch [134/300] Validation [14/16] Loss: 0.53092  focal_loss 0.15907  dice_loss 0.37185 
Epoch [134/300] Validation [15/16] Loss: 0.14512  focal_loss 0.04195  dice_loss 0.10317 
Epoch [134/300] Validation [16/16] Loss: 0.08372  focal_loss 0.02134  dice_loss 0.06238 
Epoch [134/300] Validation metric {'Val/mean dice_metric': 0.8813807964324951, 'Val/mean miou_metric': 0.8145320415496826, 'Val/mean f1': 0.903086245059967, 'Val/mean precision': 0.91483473777771, 'Val/mean recall': 0.8916357159614563, 'Val/mean hd95_metric': 31.995546340942383}
Cheakpoint...
Epoch [134/300] best acc:tensor([0.8814], device='cuda:0'), Now : mean acc: tensor([0.8814], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8813807964324951, 'Val/mean miou_metric': 0.8145320415496826, 'Val/mean f1': 0.903086245059967, 'Val/mean precision': 0.91483473777771, 'Val/mean recall': 0.8916357159614563, 'Val/mean hd95_metric': 31.995546340942383}
Epoch [135/300] Training [1/62] Loss: 0.07365 
Epoch [135/300] Training [2/62] Loss: 0.24056 
Epoch [135/300] Training [3/62] Loss: 0.15054 
Epoch [135/300] Training [4/62] Loss: 0.14248 
Epoch [135/300] Training [5/62] Loss: 0.08051 
Epoch [135/300] Training [6/62] Loss: 0.07468 
Epoch [135/300] Training [7/62] Loss: 0.06655 
Epoch [135/300] Training [8/62] Loss: 0.08697 
Epoch [135/300] Training [9/62] Loss: 0.15077 
Epoch [135/300] Training [10/62] Loss: 0.12556 
Epoch [135/300] Training [11/62] Loss: 0.07816 
Epoch [135/300] Training [12/62] Loss: 0.10025 
Epoch [135/300] Training [13/62] Loss: 0.11491 
Epoch [135/300] Training [14/62] Loss: 0.11386 
Epoch [135/300] Training [15/62] Loss: 0.08138 
Epoch [135/300] Training [16/62] Loss: 0.09394 
Epoch [135/300] Training [17/62] Loss: 0.07370 
Epoch [135/300] Training [18/62] Loss: 0.06678 
Epoch [135/300] Training [19/62] Loss: 0.11381 
Epoch [135/300] Training [20/62] Loss: 0.10518 
Epoch [135/300] Training [21/62] Loss: 0.13791 
Epoch [135/300] Training [22/62] Loss: 0.19522 
Epoch [135/300] Training [23/62] Loss: 0.12069 
Epoch [135/300] Training [24/62] Loss: 0.10714 
Epoch [135/300] Training [25/62] Loss: 0.09000 
Epoch [135/300] Training [26/62] Loss: 0.07424 
Epoch [135/300] Training [27/62] Loss: 0.15192 
Epoch [135/300] Training [28/62] Loss: 0.19659 
Epoch [135/300] Training [29/62] Loss: 0.06628 
Epoch [135/300] Training [30/62] Loss: 0.10520 
Epoch [135/300] Training [31/62] Loss: 0.22923 
Epoch [135/300] Training [32/62] Loss: 0.08950 
Epoch [135/300] Training [33/62] Loss: 0.11113 
Epoch [135/300] Training [34/62] Loss: 0.18355 
Epoch [135/300] Training [35/62] Loss: 0.14293 
Epoch [135/300] Training [36/62] Loss: 0.10495 
Epoch [135/300] Training [37/62] Loss: 0.10226 
Epoch [135/300] Training [38/62] Loss: 0.18855 
Epoch [135/300] Training [39/62] Loss: 0.09532 
Epoch [135/300] Training [40/62] Loss: 0.18940 
Epoch [135/300] Training [41/62] Loss: 0.14204 
Epoch [135/300] Training [42/62] Loss: 0.12886 
Epoch [135/300] Training [43/62] Loss: 0.16659 
Epoch [135/300] Training [44/62] Loss: 0.17072 
Epoch [135/300] Training [45/62] Loss: 0.24908 
Epoch [135/300] Training [46/62] Loss: 0.11968 
Epoch [135/300] Training [47/62] Loss: 0.09715 
Epoch [135/300] Training [48/62] Loss: 0.10104 
Epoch [135/300] Training [49/62] Loss: 0.07205 
Epoch [135/300] Training [50/62] Loss: 0.08656 
Epoch [135/300] Training [51/62] Loss: 0.13316 
Epoch [135/300] Training [52/62] Loss: 0.08099 
Epoch [135/300] Training [53/62] Loss: 0.11993 
Epoch [135/300] Training [54/62] Loss: 0.08096 
Epoch [135/300] Training [55/62] Loss: 0.13730 
Epoch [135/300] Training [56/62] Loss: 0.19715 
Epoch [135/300] Training [57/62] Loss: 0.10354 
Epoch [135/300] Training [58/62] Loss: 0.11655 
Epoch [135/300] Training [59/62] Loss: 0.26863 
Epoch [135/300] Training [60/62] Loss: 0.08317 
Epoch [135/300] Training [61/62] Loss: 0.14199 
Epoch [135/300] Training [62/62] Loss: 0.09221 
Epoch [135/300] Training metric {'Train/mean dice_metric': 0.9149538278579712, 'Train/mean miou_metric': 0.8577601313591003, 'Train/mean f1': 0.9305713772773743, 'Train/mean precision': 0.9308812618255615, 'Train/mean recall': 0.9302617311477661, 'Train/mean hd95_metric': 25.318410873413086}
Epoch [135/300] Validation [1/16] Loss: 0.61641  focal_loss 0.37486  dice_loss 0.24156 
Epoch [135/300] Validation [2/16] Loss: 0.50154  focal_loss 0.16561  dice_loss 0.33593 
Epoch [135/300] Validation [3/16] Loss: 0.56389  focal_loss 0.25876  dice_loss 0.30513 
Epoch [135/300] Validation [4/16] Loss: 0.27747  focal_loss 0.12992  dice_loss 0.14756 
Epoch [135/300] Validation [5/16] Loss: 0.35069  focal_loss 0.10045  dice_loss 0.25025 
Epoch [135/300] Validation [6/16] Loss: 0.33916  focal_loss 0.08172  dice_loss 0.25744 
Epoch [135/300] Validation [7/16] Loss: 0.26910  focal_loss 0.08940  dice_loss 0.17971 
Epoch [135/300] Validation [8/16] Loss: 0.53306  focal_loss 0.12524  dice_loss 0.40782 
Epoch [135/300] Validation [9/16] Loss: 0.29357  focal_loss 0.12010  dice_loss 0.17347 
Epoch [135/300] Validation [10/16] Loss: 0.52467  focal_loss 0.17263  dice_loss 0.35204 
Epoch [135/300] Validation [11/16] Loss: 0.14514  focal_loss 0.04110  dice_loss 0.10404 
Epoch [135/300] Validation [12/16] Loss: 0.38050  focal_loss 0.07872  dice_loss 0.30178 
Epoch [135/300] Validation [13/16] Loss: 0.32646  focal_loss 0.10199  dice_loss 0.22448 
Epoch [135/300] Validation [14/16] Loss: 0.57283  focal_loss 0.22030  dice_loss 0.35254 
Epoch [135/300] Validation [15/16] Loss: 0.14389  focal_loss 0.04689  dice_loss 0.09700 
Epoch [135/300] Validation [16/16] Loss: 0.15441  focal_loss 0.04212  dice_loss 0.11229 
Epoch [135/300] Validation metric {'Val/mean dice_metric': 0.8845195174217224, 'Val/mean miou_metric': 0.8188771605491638, 'Val/mean f1': 0.9051910638809204, 'Val/mean precision': 0.913224995136261, 'Val/mean recall': 0.8972970843315125, 'Val/mean hd95_metric': 32.3067512512207}
Cheakpoint...
Epoch [135/300] best acc:tensor([0.8845], device='cuda:0'), Now : mean acc: tensor([0.8845], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8845195174217224, 'Val/mean miou_metric': 0.8188771605491638, 'Val/mean f1': 0.9051910638809204, 'Val/mean precision': 0.913224995136261, 'Val/mean recall': 0.8972970843315125, 'Val/mean hd95_metric': 32.3067512512207}
Epoch [136/300] Training [1/62] Loss: 0.13883 
Epoch [136/300] Training [2/62] Loss: 0.06491 
Epoch [136/300] Training [3/62] Loss: 0.30976 
Epoch [136/300] Training [4/62] Loss: 0.08966 
Epoch [136/300] Training [5/62] Loss: 0.17697 
Epoch [136/300] Training [6/62] Loss: 0.08940 
Epoch [136/300] Training [7/62] Loss: 0.18544 
Epoch [136/300] Training [8/62] Loss: 0.10251 
Epoch [136/300] Training [9/62] Loss: 0.26025 
Epoch [136/300] Training [10/62] Loss: 0.12619 
Epoch [136/300] Training [11/62] Loss: 0.11103 
Epoch [136/300] Training [12/62] Loss: 0.16660 
Epoch [136/300] Training [13/62] Loss: 0.17620 
Epoch [136/300] Training [14/62] Loss: 0.06780 
Epoch [136/300] Training [15/62] Loss: 0.09840 
Epoch [136/300] Training [16/62] Loss: 0.12530 
Epoch [136/300] Training [17/62] Loss: 0.16739 
Epoch [136/300] Training [18/62] Loss: 0.09931 
Epoch [136/300] Training [19/62] Loss: 0.16633 
Epoch [136/300] Training [20/62] Loss: 0.07592 
Epoch [136/300] Training [21/62] Loss: 0.27403 
Epoch [136/300] Training [22/62] Loss: 0.22685 
Epoch [136/300] Training [23/62] Loss: 0.22570 
Epoch [136/300] Training [24/62] Loss: 0.14080 
Epoch [136/300] Training [25/62] Loss: 0.07361 
Epoch [136/300] Training [26/62] Loss: 0.19679 
Epoch [136/300] Training [27/62] Loss: 0.15034 
Epoch [136/300] Training [28/62] Loss: 0.20088 
Epoch [136/300] Training [29/62] Loss: 0.05650 
Epoch [136/300] Training [30/62] Loss: 0.11027 
Epoch [136/300] Training [31/62] Loss: 0.08035 
Epoch [136/300] Training [32/62] Loss: 0.08410 
Epoch [136/300] Training [33/62] Loss: 0.05778 
Epoch [136/300] Training [34/62] Loss: 0.06360 
Epoch [136/300] Training [35/62] Loss: 0.18442 
Epoch [136/300] Training [36/62] Loss: 0.09473 
Epoch [136/300] Training [37/62] Loss: 0.16010 
Epoch [136/300] Training [38/62] Loss: 0.11100 
Epoch [136/300] Training [39/62] Loss: 0.10494 
Epoch [136/300] Training [40/62] Loss: 0.08328 
Epoch [136/300] Training [41/62] Loss: 0.13074 
Epoch [136/300] Training [42/62] Loss: 0.06861 
Epoch [136/300] Training [43/62] Loss: 0.11698 
Epoch [136/300] Training [44/62] Loss: 0.11478 
Epoch [136/300] Training [45/62] Loss: 0.15513 
Epoch [136/300] Training [46/62] Loss: 0.08769 
Epoch [136/300] Training [47/62] Loss: 0.07734 
Epoch [136/300] Training [48/62] Loss: 0.13342 
Epoch [136/300] Training [49/62] Loss: 0.18444 
Epoch [136/300] Training [50/62] Loss: 0.12816 
Epoch [136/300] Training [51/62] Loss: 0.18937 
Epoch [136/300] Training [52/62] Loss: 0.07506 
Epoch [136/300] Training [53/62] Loss: 0.08359 
Epoch [136/300] Training [54/62] Loss: 0.11556 
Epoch [136/300] Training [55/62] Loss: 0.16306 
Epoch [136/300] Training [56/62] Loss: 0.06000 
Epoch [136/300] Training [57/62] Loss: 0.38226 
Epoch [136/300] Training [58/62] Loss: 0.10308 
Epoch [136/300] Training [59/62] Loss: 0.08886 
Epoch [136/300] Training [60/62] Loss: 0.11353 
Epoch [136/300] Training [61/62] Loss: 0.07240 
Epoch [136/300] Training [62/62] Loss: 0.10786 
Epoch [136/300] Training metric {'Train/mean dice_metric': 0.9122968316078186, 'Train/mean miou_metric': 0.8556536436080933, 'Train/mean f1': 0.9253492951393127, 'Train/mean precision': 0.932040810585022, 'Train/mean recall': 0.9187533259391785, 'Train/mean hd95_metric': 26.015405654907227}
Epoch [136/300] Validation [1/16] Loss: 0.85926  focal_loss 0.51729  dice_loss 0.34197 
Epoch [136/300] Validation [2/16] Loss: 0.57524  focal_loss 0.20244  dice_loss 0.37281 
Epoch [136/300] Validation [3/16] Loss: 0.69122  focal_loss 0.37455  dice_loss 0.31667 
Epoch [136/300] Validation [4/16] Loss: 0.45114  focal_loss 0.19659  dice_loss 0.25456 
Epoch [136/300] Validation [5/16] Loss: 0.37072  focal_loss 0.09226  dice_loss 0.27847 
Epoch [136/300] Validation [6/16] Loss: 0.34643  focal_loss 0.10122  dice_loss 0.24522 
Epoch [136/300] Validation [7/16] Loss: 0.42593  focal_loss 0.18015  dice_loss 0.24578 
Epoch [136/300] Validation [8/16] Loss: 0.51200  focal_loss 0.17232  dice_loss 0.33968 
Epoch [136/300] Validation [9/16] Loss: 0.46399  focal_loss 0.20934  dice_loss 0.25465 
Epoch [136/300] Validation [10/16] Loss: 0.74754  focal_loss 0.23028  dice_loss 0.51726 
Epoch [136/300] Validation [11/16] Loss: 0.24438  focal_loss 0.08272  dice_loss 0.16166 
Epoch [136/300] Validation [12/16] Loss: 0.48976  focal_loss 0.09188  dice_loss 0.39788 
Epoch [136/300] Validation [13/16] Loss: 0.44170  focal_loss 0.15993  dice_loss 0.28177 
Epoch [136/300] Validation [14/16] Loss: 0.67391  focal_loss 0.21603  dice_loss 0.45788 
Epoch [136/300] Validation [15/16] Loss: 0.20542  focal_loss 0.07114  dice_loss 0.13428 
Epoch [136/300] Validation [16/16] Loss: 0.11191  focal_loss 0.03358  dice_loss 0.07832 
Epoch [136/300] Validation metric {'Val/mean dice_metric': 0.870954155921936, 'Val/mean miou_metric': 0.8059859871864319, 'Val/mean f1': 0.8928711414337158, 'Val/mean precision': 0.9188804626464844, 'Val/mean recall': 0.8682936429977417, 'Val/mean hd95_metric': 32.93895721435547}
Cheakpoint...
Epoch [136/300] best acc:tensor([0.8845], device='cuda:0'), Now : mean acc: tensor([0.8710], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.870954155921936, 'Val/mean miou_metric': 0.8059859871864319, 'Val/mean f1': 0.8928711414337158, 'Val/mean precision': 0.9188804626464844, 'Val/mean recall': 0.8682936429977417, 'Val/mean hd95_metric': 32.93895721435547}
Epoch [137/300] Training [1/62] Loss: 0.07729 
Epoch [137/300] Training [2/62] Loss: 0.15186 
Epoch [137/300] Training [3/62] Loss: 0.10852 
Epoch [137/300] Training [4/62] Loss: 0.10751 
Epoch [137/300] Training [5/62] Loss: 0.07241 
Epoch [137/300] Training [6/62] Loss: 0.22623 
Epoch [137/300] Training [7/62] Loss: 0.09652 
Epoch [137/300] Training [8/62] Loss: 0.10057 
Epoch [137/300] Training [9/62] Loss: 0.15834 
Epoch [137/300] Training [10/62] Loss: 0.10428 
Epoch [137/300] Training [11/62] Loss: 0.13142 
Epoch [137/300] Training [12/62] Loss: 0.14354 
Epoch [137/300] Training [13/62] Loss: 0.08910 
Epoch [137/300] Training [14/62] Loss: 0.10389 
Epoch [137/300] Training [15/62] Loss: 0.20671 
Epoch [137/300] Training [16/62] Loss: 0.08456 
Epoch [137/300] Training [17/62] Loss: 0.10814 
Epoch [137/300] Training [18/62] Loss: 0.20953 
Epoch [137/300] Training [19/62] Loss: 0.10424 
Epoch [137/300] Training [20/62] Loss: 0.08939 
Epoch [137/300] Training [21/62] Loss: 0.18070 
Epoch [137/300] Training [22/62] Loss: 0.16565 
Epoch [137/300] Training [23/62] Loss: 0.09319 
Epoch [137/300] Training [24/62] Loss: 0.07294 
Epoch [137/300] Training [25/62] Loss: 0.12828 
Epoch [137/300] Training [26/62] Loss: 0.09156 
Epoch [137/300] Training [27/62] Loss: 0.17966 
Epoch [137/300] Training [28/62] Loss: 0.10605 
Epoch [137/300] Training [29/62] Loss: 0.07926 
Epoch [137/300] Training [30/62] Loss: 0.18541 
Epoch [137/300] Training [31/62] Loss: 0.14351 
Epoch [137/300] Training [32/62] Loss: 0.21826 
Epoch [137/300] Training [33/62] Loss: 0.09644 
Epoch [137/300] Training [34/62] Loss: 0.21815 
Epoch [137/300] Training [35/62] Loss: 0.05612 
Epoch [137/300] Training [36/62] Loss: 0.09644 
Epoch [137/300] Training [37/62] Loss: 0.16362 
Epoch [137/300] Training [38/62] Loss: 0.13086 
Epoch [137/300] Training [39/62] Loss: 0.12218 
Epoch [137/300] Training [40/62] Loss: 0.07962 
Epoch [137/300] Training [41/62] Loss: 0.12224 
Epoch [137/300] Training [42/62] Loss: 0.18925 
Epoch [137/300] Training [43/62] Loss: 0.06125 
Epoch [137/300] Training [44/62] Loss: 0.13637 
Epoch [137/300] Training [45/62] Loss: 0.11719 
Epoch [137/300] Training [46/62] Loss: 0.08921 
Epoch [137/300] Training [47/62] Loss: 0.14600 
Epoch [137/300] Training [48/62] Loss: 0.22125 
Epoch [137/300] Training [49/62] Loss: 0.09931 
Epoch [137/300] Training [50/62] Loss: 0.24737 
Epoch [137/300] Training [51/62] Loss: 0.10750 
Epoch [137/300] Training [52/62] Loss: 0.11817 
Epoch [137/300] Training [53/62] Loss: 0.20043 
Epoch [137/300] Training [54/62] Loss: 0.08715 
Epoch [137/300] Training [55/62] Loss: 0.20384 
Epoch [137/300] Training [56/62] Loss: 0.15426 
Epoch [137/300] Training [57/62] Loss: 0.17745 
Epoch [137/300] Training [58/62] Loss: 0.09165 
Epoch [137/300] Training [59/62] Loss: 0.12488 
Epoch [137/300] Training [60/62] Loss: 0.11318 
Epoch [137/300] Training [61/62] Loss: 0.09959 
Epoch [137/300] Training [62/62] Loss: 0.05485 
Epoch [137/300] Training metric {'Train/mean dice_metric': 0.9115862846374512, 'Train/mean miou_metric': 0.8541585803031921, 'Train/mean f1': 0.9281690120697021, 'Train/mean precision': 0.9351236820220947, 'Train/mean recall': 0.9213169813156128, 'Train/mean hd95_metric': 24.303422927856445}
Epoch [137/300] Validation [1/16] Loss: 0.54369  focal_loss 0.34688  dice_loss 0.19681 
Epoch [137/300] Validation [2/16] Loss: 0.31324  focal_loss 0.12222  dice_loss 0.19102 
Epoch [137/300] Validation [3/16] Loss: 0.53705  focal_loss 0.26741  dice_loss 0.26964 
Epoch [137/300] Validation [4/16] Loss: 0.24682  focal_loss 0.09473  dice_loss 0.15210 
Epoch [137/300] Validation [5/16] Loss: 0.43935  focal_loss 0.10579  dice_loss 0.33356 
Epoch [137/300] Validation [6/16] Loss: 0.32932  focal_loss 0.09409  dice_loss 0.23523 
Epoch [137/300] Validation [7/16] Loss: 0.27718  focal_loss 0.07956  dice_loss 0.19762 
Epoch [137/300] Validation [8/16] Loss: 0.45994  focal_loss 0.12039  dice_loss 0.33955 
Epoch [137/300] Validation [9/16] Loss: 0.33931  focal_loss 0.14809  dice_loss 0.19121 
Epoch [137/300] Validation [10/16] Loss: 0.38728  focal_loss 0.10125  dice_loss 0.28603 
Epoch [137/300] Validation [11/16] Loss: 0.19420  focal_loss 0.06327  dice_loss 0.13093 
Epoch [137/300] Validation [12/16] Loss: 0.40284  focal_loss 0.10051  dice_loss 0.30233 
Epoch [137/300] Validation [13/16] Loss: 0.19631  focal_loss 0.04280  dice_loss 0.15351 
Epoch [137/300] Validation [14/16] Loss: 0.48185  focal_loss 0.19077  dice_loss 0.29109 
Epoch [137/300] Validation [15/16] Loss: 0.16044  focal_loss 0.04896  dice_loss 0.11148 
Epoch [137/300] Validation [16/16] Loss: 0.32370  focal_loss 0.12183  dice_loss 0.20187 
Epoch [137/300] Validation metric {'Val/mean dice_metric': 0.8861889839172363, 'Val/mean miou_metric': 0.8214660286903381, 'Val/mean f1': 0.9048891067504883, 'Val/mean precision': 0.9143432378768921, 'Val/mean recall': 0.8956285119056702, 'Val/mean hd95_metric': 30.552682876586914}
Cheakpoint...
Epoch [137/300] best acc:tensor([0.8862], device='cuda:0'), Now : mean acc: tensor([0.8862], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8861889839172363, 'Val/mean miou_metric': 0.8214660286903381, 'Val/mean f1': 0.9048891067504883, 'Val/mean precision': 0.9143432378768921, 'Val/mean recall': 0.8956285119056702, 'Val/mean hd95_metric': 30.552682876586914}
Epoch [138/300] Training [1/62] Loss: 0.11984 
Epoch [138/300] Training [2/62] Loss: 0.12824 
Epoch [138/300] Training [3/62] Loss: 0.11408 
Epoch [138/300] Training [4/62] Loss: 0.05752 
Epoch [138/300] Training [5/62] Loss: 0.15290 
Epoch [138/300] Training [6/62] Loss: 0.07952 
Epoch [138/300] Training [7/62] Loss: 0.13259 
Epoch [138/300] Training [8/62] Loss: 0.13358 
Epoch [138/300] Training [9/62] Loss: 0.09106 
Epoch [138/300] Training [10/62] Loss: 0.07387 
Epoch [138/300] Training [11/62] Loss: 0.09759 
Epoch [138/300] Training [12/62] Loss: 0.20992 
Epoch [138/300] Training [13/62] Loss: 0.07258 
Epoch [138/300] Training [14/62] Loss: 0.11749 
Epoch [138/300] Training [15/62] Loss: 0.14573 
Epoch [138/300] Training [16/62] Loss: 0.09790 
Epoch [138/300] Training [17/62] Loss: 0.06004 
Epoch [138/300] Training [18/62] Loss: 0.06674 
Epoch [138/300] Training [19/62] Loss: 0.08252 
Epoch [138/300] Training [20/62] Loss: 0.23527 
Epoch [138/300] Training [21/62] Loss: 0.29004 
Epoch [138/300] Training [22/62] Loss: 0.07595 
Epoch [138/300] Training [23/62] Loss: 0.06955 
Epoch [138/300] Training [24/62] Loss: 0.09216 
Epoch [138/300] Training [25/62] Loss: 0.18730 
Epoch [138/300] Training [26/62] Loss: 0.19849 
Epoch [138/300] Training [27/62] Loss: 0.23792 
Epoch [138/300] Training [28/62] Loss: 0.31036 
Epoch [138/300] Training [29/62] Loss: 0.09767 
Epoch [138/300] Training [30/62] Loss: 0.19438 
Epoch [138/300] Training [31/62] Loss: 0.05838 
Epoch [138/300] Training [32/62] Loss: 0.09495 
Epoch [138/300] Training [33/62] Loss: 0.30095 
Epoch [138/300] Training [34/62] Loss: 0.12329 
Epoch [138/300] Training [35/62] Loss: 0.12291 
Epoch [138/300] Training [36/62] Loss: 0.17644 
Epoch [138/300] Training [37/62] Loss: 0.14226 
Epoch [138/300] Training [38/62] Loss: 0.09697 
Epoch [138/300] Training [39/62] Loss: 0.12745 
Epoch [138/300] Training [40/62] Loss: 0.11299 
Epoch [138/300] Training [41/62] Loss: 0.17245 
Epoch [138/300] Training [42/62] Loss: 0.05953 
Epoch [138/300] Training [43/62] Loss: 0.09512 
Epoch [138/300] Training [44/62] Loss: 0.08912 
Epoch [138/300] Training [45/62] Loss: 0.10960 
Epoch [138/300] Training [46/62] Loss: 0.06237 
Epoch [138/300] Training [47/62] Loss: 0.10969 
Epoch [138/300] Training [48/62] Loss: 0.18851 
Epoch [138/300] Training [49/62] Loss: 0.10047 
Epoch [138/300] Training [50/62] Loss: 0.11652 
Epoch [138/300] Training [51/62] Loss: 0.10731 
Epoch [138/300] Training [52/62] Loss: 0.12603 
Epoch [138/300] Training [53/62] Loss: 0.05021 
Epoch [138/300] Training [54/62] Loss: 0.22547 
Epoch [138/300] Training [55/62] Loss: 0.04925 
Epoch [138/300] Training [56/62] Loss: 0.12107 
Epoch [138/300] Training [57/62] Loss: 0.10537 
Epoch [138/300] Training [58/62] Loss: 0.22947 
Epoch [138/300] Training [59/62] Loss: 0.18253 
Epoch [138/300] Training [60/62] Loss: 0.10706 
Epoch [138/300] Training [61/62] Loss: 0.09848 
Epoch [138/300] Training [62/62] Loss: 0.10744 
Epoch [138/300] Training metric {'Train/mean dice_metric': 0.9112207293510437, 'Train/mean miou_metric': 0.857403039932251, 'Train/mean f1': 0.931316077709198, 'Train/mean precision': 0.9340048432350159, 'Train/mean recall': 0.9286426901817322, 'Train/mean hd95_metric': 23.623994827270508}
Epoch [138/300] Validation [1/16] Loss: 0.90113  focal_loss 0.56047  dice_loss 0.34065 
Epoch [138/300] Validation [2/16] Loss: 0.65438  focal_loss 0.22995  dice_loss 0.42443 
Epoch [138/300] Validation [3/16] Loss: 0.75156  focal_loss 0.30363  dice_loss 0.44793 
Epoch [138/300] Validation [4/16] Loss: 0.43453  focal_loss 0.18252  dice_loss 0.25201 
Epoch [138/300] Validation [5/16] Loss: 0.40170  focal_loss 0.10384  dice_loss 0.29786 
Epoch [138/300] Validation [6/16] Loss: 0.31126  focal_loss 0.06975  dice_loss 0.24151 
Epoch [138/300] Validation [7/16] Loss: 0.28253  focal_loss 0.11268  dice_loss 0.16985 
Epoch [138/300] Validation [8/16] Loss: 0.61006  focal_loss 0.16304  dice_loss 0.44702 
Epoch [138/300] Validation [9/16] Loss: 0.45752  focal_loss 0.19863  dice_loss 0.25889 
Epoch [138/300] Validation [10/16] Loss: 0.55127  focal_loss 0.16782  dice_loss 0.38345 
Epoch [138/300] Validation [11/16] Loss: 0.35964  focal_loss 0.08859  dice_loss 0.27105 
Epoch [138/300] Validation [12/16] Loss: 0.41852  focal_loss 0.08406  dice_loss 0.33446 
Epoch [138/300] Validation [13/16] Loss: 0.38435  focal_loss 0.12403  dice_loss 0.26032 
Epoch [138/300] Validation [14/16] Loss: 0.62626  focal_loss 0.19452  dice_loss 0.43174 
Epoch [138/300] Validation [15/16] Loss: 0.21549  focal_loss 0.08271  dice_loss 0.13277 
Epoch [138/300] Validation [16/16] Loss: 0.13322  focal_loss 0.05184  dice_loss 0.08138 
Epoch [138/300] Validation metric {'Val/mean dice_metric': 0.8687251210212708, 'Val/mean miou_metric': 0.8063856363296509, 'Val/mean f1': 0.9001380801200867, 'Val/mean precision': 0.9236972332000732, 'Val/mean recall': 0.8777507543563843, 'Val/mean hd95_metric': 29.346771240234375}
Cheakpoint...
Epoch [138/300] best acc:tensor([0.8862], device='cuda:0'), Now : mean acc: tensor([0.8687], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8687251210212708, 'Val/mean miou_metric': 0.8063856363296509, 'Val/mean f1': 0.9001380801200867, 'Val/mean precision': 0.9236972332000732, 'Val/mean recall': 0.8777507543563843, 'Val/mean hd95_metric': 29.346771240234375}
Epoch [139/300] Training [1/62] Loss: 0.09172 
Epoch [139/300] Training [2/62] Loss: 0.16208 
Epoch [139/300] Training [3/62] Loss: 0.09933 
Epoch [139/300] Training [4/62] Loss: 0.13344 
Epoch [139/300] Training [5/62] Loss: 0.17630 
Epoch [139/300] Training [6/62] Loss: 0.18759 
Epoch [139/300] Training [7/62] Loss: 0.15404 
Epoch [139/300] Training [8/62] Loss: 0.18987 
Epoch [139/300] Training [9/62] Loss: 0.09222 
Epoch [139/300] Training [10/62] Loss: 0.24354 
Epoch [139/300] Training [11/62] Loss: 0.10702 
Epoch [139/300] Training [12/62] Loss: 0.12262 
Epoch [139/300] Training [13/62] Loss: 0.19638 
Epoch [139/300] Training [14/62] Loss: 0.22855 
Epoch [139/300] Training [15/62] Loss: 0.09373 
Epoch [139/300] Training [16/62] Loss: 0.08843 
Epoch [139/300] Training [17/62] Loss: 0.05235 
Epoch [139/300] Training [18/62] Loss: 0.10703 
Epoch [139/300] Training [19/62] Loss: 0.24697 
Epoch [139/300] Training [20/62] Loss: 0.08578 
Epoch [139/300] Training [21/62] Loss: 0.10488 
Epoch [139/300] Training [22/62] Loss: 0.07513 
Epoch [139/300] Training [23/62] Loss: 0.09994 
Epoch [139/300] Training [24/62] Loss: 0.07926 
Epoch [139/300] Training [25/62] Loss: 0.22324 
Epoch [139/300] Training [26/62] Loss: 0.23534 
Epoch [139/300] Training [27/62] Loss: 0.17207 
Epoch [139/300] Training [28/62] Loss: 0.08246 
Epoch [139/300] Training [29/62] Loss: 0.11332 
Epoch [139/300] Training [30/62] Loss: 0.15437 
Epoch [139/300] Training [31/62] Loss: 0.05480 
Epoch [139/300] Training [32/62] Loss: 0.16329 
Epoch [139/300] Training [33/62] Loss: 0.05920 
Epoch [139/300] Training [34/62] Loss: 0.12735 
Epoch [139/300] Training [35/62] Loss: 0.14772 
Epoch [139/300] Training [36/62] Loss: 0.12133 
Epoch [139/300] Training [37/62] Loss: 0.15541 
Epoch [139/300] Training [38/62] Loss: 0.09942 
Epoch [139/300] Training [39/62] Loss: 0.13139 
Epoch [139/300] Training [40/62] Loss: 0.15656 
Epoch [139/300] Training [41/62] Loss: 0.16857 
Epoch [139/300] Training [42/62] Loss: 0.08963 
Epoch [139/300] Training [43/62] Loss: 0.05014 
Epoch [139/300] Training [44/62] Loss: 0.08825 
Epoch [139/300] Training [45/62] Loss: 0.13530 
Epoch [139/300] Training [46/62] Loss: 0.09203 
Epoch [139/300] Training [47/62] Loss: 0.09795 
Epoch [139/300] Training [48/62] Loss: 0.11314 
Epoch [139/300] Training [49/62] Loss: 0.07292 
Epoch [139/300] Training [50/62] Loss: 0.07364 
Epoch [139/300] Training [51/62] Loss: 0.11733 
Epoch [139/300] Training [52/62] Loss: 0.11954 
Epoch [139/300] Training [53/62] Loss: 0.17787 
Epoch [139/300] Training [54/62] Loss: 0.19883 
Epoch [139/300] Training [55/62] Loss: 0.09171 
Epoch [139/300] Training [56/62] Loss: 0.12946 
Epoch [139/300] Training [57/62] Loss: 0.11029 
Epoch [139/300] Training [58/62] Loss: 0.08047 
Epoch [139/300] Training [59/62] Loss: 0.28130 
Epoch [139/300] Training [60/62] Loss: 0.18057 
Epoch [139/300] Training [61/62] Loss: 0.14788 
Epoch [139/300] Training [62/62] Loss: 0.03541 
Epoch [139/300] Training metric {'Train/mean dice_metric': 0.9085168838500977, 'Train/mean miou_metric': 0.8522250056266785, 'Train/mean f1': 0.9297638535499573, 'Train/mean precision': 0.929668128490448, 'Train/mean recall': 0.9298595190048218, 'Train/mean hd95_metric': 26.569684982299805}
Epoch [139/300] Validation [1/16] Loss: 0.77979  focal_loss 0.47767  dice_loss 0.30212 
Epoch [139/300] Validation [2/16] Loss: 0.55634  focal_loss 0.20212  dice_loss 0.35422 
Epoch [139/300] Validation [3/16] Loss: 0.55649  focal_loss 0.23820  dice_loss 0.31829 
Epoch [139/300] Validation [4/16] Loss: 0.43321  focal_loss 0.19029  dice_loss 0.24292 
Epoch [139/300] Validation [5/16] Loss: 0.39050  focal_loss 0.10408  dice_loss 0.28642 
Epoch [139/300] Validation [6/16] Loss: 0.37007  focal_loss 0.10713  dice_loss 0.26294 
Epoch [139/300] Validation [7/16] Loss: 0.24266  focal_loss 0.08078  dice_loss 0.16188 
Epoch [139/300] Validation [8/16] Loss: 0.66200  focal_loss 0.18263  dice_loss 0.47937 
Epoch [139/300] Validation [9/16] Loss: 0.23325  focal_loss 0.08247  dice_loss 0.15077 
Epoch [139/300] Validation [10/16] Loss: 0.41363  focal_loss 0.12540  dice_loss 0.28823 
Epoch [139/300] Validation [11/16] Loss: 0.17714  focal_loss 0.04952  dice_loss 0.12762 
Epoch [139/300] Validation [12/16] Loss: 0.36582  focal_loss 0.07705  dice_loss 0.28877 
Epoch [139/300] Validation [13/16] Loss: 0.24105  focal_loss 0.06555  dice_loss 0.17550 
Epoch [139/300] Validation [14/16] Loss: 0.55888  focal_loss 0.18351  dice_loss 0.37536 
Epoch [139/300] Validation [15/16] Loss: 0.13364  focal_loss 0.04018  dice_loss 0.09346 
Epoch [139/300] Validation [16/16] Loss: 0.17662  focal_loss 0.05605  dice_loss 0.12057 
Epoch [139/300] Validation metric {'Val/mean dice_metric': 0.8770809769630432, 'Val/mean miou_metric': 0.8133471012115479, 'Val/mean f1': 0.9022848606109619, 'Val/mean precision': 0.9205561280250549, 'Val/mean recall': 0.8847247958183289, 'Val/mean hd95_metric': 32.882259368896484}
Cheakpoint...
Epoch [139/300] best acc:tensor([0.8862], device='cuda:0'), Now : mean acc: tensor([0.8771], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8770809769630432, 'Val/mean miou_metric': 0.8133471012115479, 'Val/mean f1': 0.9022848606109619, 'Val/mean precision': 0.9205561280250549, 'Val/mean recall': 0.8847247958183289, 'Val/mean hd95_metric': 32.882259368896484}
Epoch [140/300] Training [1/62] Loss: 0.08284 
Epoch [140/300] Training [2/62] Loss: 0.05273 
Epoch [140/300] Training [3/62] Loss: 0.21158 
Epoch [140/300] Training [4/62] Loss: 0.08333 
Epoch [140/300] Training [5/62] Loss: 0.08601 
Epoch [140/300] Training [6/62] Loss: 0.31970 
Epoch [140/300] Training [7/62] Loss: 0.07929 
Epoch [140/300] Training [8/62] Loss: 0.08492 
Epoch [140/300] Training [9/62] Loss: 0.09023 
Epoch [140/300] Training [10/62] Loss: 0.12452 
Epoch [140/300] Training [11/62] Loss: 0.08908 
Epoch [140/300] Training [12/62] Loss: 0.20585 
Epoch [140/300] Training [13/62] Loss: 0.08082 
Epoch [140/300] Training [14/62] Loss: 0.26831 
Epoch [140/300] Training [15/62] Loss: 0.21030 
Epoch [140/300] Training [16/62] Loss: 0.08268 
Epoch [140/300] Training [17/62] Loss: 0.16529 
Epoch [140/300] Training [18/62] Loss: 0.08545 
Epoch [140/300] Training [19/62] Loss: 0.05740 
Epoch [140/300] Training [20/62] Loss: 0.08683 
Epoch [140/300] Training [21/62] Loss: 0.06554 
Epoch [140/300] Training [22/62] Loss: 0.07870 
Epoch [140/300] Training [23/62] Loss: 0.11771 
Epoch [140/300] Training [24/62] Loss: 0.10539 
Epoch [140/300] Training [25/62] Loss: 0.12073 
Epoch [140/300] Training [26/62] Loss: 0.16597 
Epoch [140/300] Training [27/62] Loss: 0.13212 
Epoch [140/300] Training [28/62] Loss: 0.10723 
Epoch [140/300] Training [29/62] Loss: 0.05102 
Epoch [140/300] Training [30/62] Loss: 0.24892 
Epoch [140/300] Training [31/62] Loss: 0.16669 
Epoch [140/300] Training [32/62] Loss: 0.18132 
Epoch [140/300] Training [33/62] Loss: 0.06565 
Epoch [140/300] Training [34/62] Loss: 0.13346 
Epoch [140/300] Training [35/62] Loss: 0.08719 
Epoch [140/300] Training [36/62] Loss: 0.10838 
Epoch [140/300] Training [37/62] Loss: 0.17892 
Epoch [140/300] Training [38/62] Loss: 0.11389 
Epoch [140/300] Training [39/62] Loss: 0.10224 
Epoch [140/300] Training [40/62] Loss: 0.11295 
Epoch [140/300] Training [41/62] Loss: 0.05662 
Epoch [140/300] Training [42/62] Loss: 0.12552 
Epoch [140/300] Training [43/62] Loss: 0.10342 
Epoch [140/300] Training [44/62] Loss: 0.08878 
Epoch [140/300] Training [45/62] Loss: 0.22484 
Epoch [140/300] Training [46/62] Loss: 0.11135 
Epoch [140/300] Training [47/62] Loss: 0.20951 
Epoch [140/300] Training [48/62] Loss: 0.08641 
Epoch [140/300] Training [49/62] Loss: 0.08122 
Epoch [140/300] Training [50/62] Loss: 0.12363 
Epoch [140/300] Training [51/62] Loss: 0.07426 
Epoch [140/300] Training [52/62] Loss: 0.06636 
Epoch [140/300] Training [53/62] Loss: 0.05648 
Epoch [140/300] Training [54/62] Loss: 0.08200 
Epoch [140/300] Training [55/62] Loss: 0.15479 
Epoch [140/300] Training [56/62] Loss: 0.11495 
Epoch [140/300] Training [57/62] Loss: 0.08297 
Epoch [140/300] Training [58/62] Loss: 0.09648 
Epoch [140/300] Training [59/62] Loss: 0.06997 
Epoch [140/300] Training [60/62] Loss: 0.12816 
Epoch [140/300] Training [61/62] Loss: 0.19367 
Epoch [140/300] Training [62/62] Loss: 0.07062 
Epoch [140/300] Training metric {'Train/mean dice_metric': 0.9171510934829712, 'Train/mean miou_metric': 0.8632640242576599, 'Train/mean f1': 0.9339340925216675, 'Train/mean precision': 0.9358267784118652, 'Train/mean recall': 0.9320492148399353, 'Train/mean hd95_metric': 21.54939079284668}
Epoch [140/300] Validation [1/16] Loss: 0.94461  focal_loss 0.55747  dice_loss 0.38715 
Epoch [140/300] Validation [2/16] Loss: 0.61705  focal_loss 0.21205  dice_loss 0.40500 
Epoch [140/300] Validation [3/16] Loss: 0.80573  focal_loss 0.34392  dice_loss 0.46181 
Epoch [140/300] Validation [4/16] Loss: 0.46501  focal_loss 0.20755  dice_loss 0.25746 
Epoch [140/300] Validation [5/16] Loss: 0.38985  focal_loss 0.10206  dice_loss 0.28780 
Epoch [140/300] Validation [6/16] Loss: 0.33068  focal_loss 0.07745  dice_loss 0.25323 
Epoch [140/300] Validation [7/16] Loss: 0.43799  focal_loss 0.14317  dice_loss 0.29482 
Epoch [140/300] Validation [8/16] Loss: 0.57223  focal_loss 0.19310  dice_loss 0.37913 
Epoch [140/300] Validation [9/16] Loss: 0.58846  focal_loss 0.25420  dice_loss 0.33425 
Epoch [140/300] Validation [10/16] Loss: 0.63704  focal_loss 0.20319  dice_loss 0.43385 
Epoch [140/300] Validation [11/16] Loss: 0.33731  focal_loss 0.11935  dice_loss 0.21796 
Epoch [140/300] Validation [12/16] Loss: 0.50875  focal_loss 0.09735  dice_loss 0.41140 
Epoch [140/300] Validation [13/16] Loss: 0.34042  focal_loss 0.10648  dice_loss 0.23394 
Epoch [140/300] Validation [14/16] Loss: 0.93898  focal_loss 0.37579  dice_loss 0.56320 
Epoch [140/300] Validation [15/16] Loss: 0.23366  focal_loss 0.07540  dice_loss 0.15827 
Epoch [140/300] Validation [16/16] Loss: 0.18679  focal_loss 0.06822  dice_loss 0.11858 
Epoch [140/300] Validation metric {'Val/mean dice_metric': 0.8682091236114502, 'Val/mean miou_metric': 0.8049265146255493, 'Val/mean f1': 0.8977384567260742, 'Val/mean precision': 0.916408896446228, 'Val/mean recall': 0.8798136115074158, 'Val/mean hd95_metric': 29.13810157775879}
Cheakpoint...
Epoch [140/300] best acc:tensor([0.8862], device='cuda:0'), Now : mean acc: tensor([0.8682], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8682091236114502, 'Val/mean miou_metric': 0.8049265146255493, 'Val/mean f1': 0.8977384567260742, 'Val/mean precision': 0.916408896446228, 'Val/mean recall': 0.8798136115074158, 'Val/mean hd95_metric': 29.13810157775879}
Epoch [141/300] Training [1/62] Loss: 0.11717 
Epoch [141/300] Training [2/62] Loss: 0.05009 
Epoch [141/300] Training [3/62] Loss: 0.09889 
Epoch [141/300] Training [4/62] Loss: 0.11910 
Epoch [141/300] Training [5/62] Loss: 0.14918 
Epoch [141/300] Training [6/62] Loss: 0.17481 
Epoch [141/300] Training [7/62] Loss: 0.20743 
Epoch [141/300] Training [8/62] Loss: 0.08212 
Epoch [141/300] Training [9/62] Loss: 0.08625 
Epoch [141/300] Training [10/62] Loss: 0.06828 
Epoch [141/300] Training [11/62] Loss: 0.06826 
Epoch [141/300] Training [12/62] Loss: 0.06605 
Epoch [141/300] Training [13/62] Loss: 0.05998 
Epoch [141/300] Training [14/62] Loss: 0.13620 
Epoch [141/300] Training [15/62] Loss: 0.06971 
Epoch [141/300] Training [16/62] Loss: 0.15633 
Epoch [141/300] Training [17/62] Loss: 0.12191 
Epoch [141/300] Training [18/62] Loss: 0.11710 
Epoch [141/300] Training [19/62] Loss: 0.29999 
Epoch [141/300] Training [20/62] Loss: 0.11450 
Epoch [141/300] Training [21/62] Loss: 0.07824 
Epoch [141/300] Training [22/62] Loss: 0.10286 
Epoch [141/300] Training [23/62] Loss: 0.09083 
Epoch [141/300] Training [24/62] Loss: 0.15873 
Epoch [141/300] Training [25/62] Loss: 0.15443 
Epoch [141/300] Training [26/62] Loss: 0.06793 
Epoch [141/300] Training [27/62] Loss: 0.21804 
Epoch [141/300] Training [28/62] Loss: 0.07445 
Epoch [141/300] Training [29/62] Loss: 0.43202 
Epoch [141/300] Training [30/62] Loss: 0.05366 
Epoch [141/300] Training [31/62] Loss: 0.16017 
Epoch [141/300] Training [32/62] Loss: 0.05168 
Epoch [141/300] Training [33/62] Loss: 0.07784 
Epoch [141/300] Training [34/62] Loss: 0.06226 
Epoch [141/300] Training [35/62] Loss: 0.20542 
Epoch [141/300] Training [36/62] Loss: 0.16741 
Epoch [141/300] Training [37/62] Loss: 0.11818 
Epoch [141/300] Training [38/62] Loss: 0.07865 
Epoch [141/300] Training [39/62] Loss: 0.14797 
Epoch [141/300] Training [40/62] Loss: 0.09628 
Epoch [141/300] Training [41/62] Loss: 0.21981 
Epoch [141/300] Training [42/62] Loss: 0.19885 
Epoch [141/300] Training [43/62] Loss: 0.18748 
Epoch [141/300] Training [44/62] Loss: 0.15983 
Epoch [141/300] Training [45/62] Loss: 0.18433 
Epoch [141/300] Training [46/62] Loss: 0.17650 
Epoch [141/300] Training [47/62] Loss: 0.10105 
Epoch [141/300] Training [48/62] Loss: 0.15302 
Epoch [141/300] Training [49/62] Loss: 0.11298 
Epoch [141/300] Training [50/62] Loss: 0.07302 
Epoch [141/300] Training [51/62] Loss: 0.12468 
Epoch [141/300] Training [52/62] Loss: 0.12839 
Epoch [141/300] Training [53/62] Loss: 0.14819 
Epoch [141/300] Training [54/62] Loss: 0.09812 
Epoch [141/300] Training [55/62] Loss: 0.08347 
Epoch [141/300] Training [56/62] Loss: 0.10422 
Epoch [141/300] Training [57/62] Loss: 0.09831 
Epoch [141/300] Training [58/62] Loss: 0.07258 
Epoch [141/300] Training [59/62] Loss: 0.06421 
Epoch [141/300] Training [60/62] Loss: 0.16206 
Epoch [141/300] Training [61/62] Loss: 0.07639 
Epoch [141/300] Training [62/62] Loss: 0.04519 
Epoch [141/300] Training metric {'Train/mean dice_metric': 0.9176749587059021, 'Train/mean miou_metric': 0.8622083067893982, 'Train/mean f1': 0.9259284138679504, 'Train/mean precision': 0.9265230894088745, 'Train/mean recall': 0.9253344535827637, 'Train/mean hd95_metric': 22.209300994873047}
Epoch [141/300] Validation [1/16] Loss: 0.65885  focal_loss 0.40489  dice_loss 0.25396 
Epoch [141/300] Validation [2/16] Loss: 0.48801  focal_loss 0.13076  dice_loss 0.35726 
Epoch [141/300] Validation [3/16] Loss: 0.56782  focal_loss 0.26992  dice_loss 0.29790 
Epoch [141/300] Validation [4/16] Loss: 0.31327  focal_loss 0.12720  dice_loss 0.18608 
Epoch [141/300] Validation [5/16] Loss: 0.38154  focal_loss 0.11629  dice_loss 0.26525 
Epoch [141/300] Validation [6/16] Loss: 0.41368  focal_loss 0.14538  dice_loss 0.26830 
Epoch [141/300] Validation [7/16] Loss: 0.17923  focal_loss 0.05829  dice_loss 0.12094 
Epoch [141/300] Validation [8/16] Loss: 0.47059  focal_loss 0.16495  dice_loss 0.30563 
Epoch [141/300] Validation [9/16] Loss: 0.26853  focal_loss 0.10117  dice_loss 0.16735 
Epoch [141/300] Validation [10/16] Loss: 0.41764  focal_loss 0.08994  dice_loss 0.32770 
Epoch [141/300] Validation [11/16] Loss: 0.23298  focal_loss 0.07090  dice_loss 0.16207 
Epoch [141/300] Validation [12/16] Loss: 0.39642  focal_loss 0.08437  dice_loss 0.31204 
Epoch [141/300] Validation [13/16] Loss: 0.22075  focal_loss 0.04220  dice_loss 0.17855 
Epoch [141/300] Validation [14/16] Loss: 0.56524  focal_loss 0.20328  dice_loss 0.36197 
Epoch [141/300] Validation [15/16] Loss: 0.12730  focal_loss 0.03724  dice_loss 0.09006 
Epoch [141/300] Validation [16/16] Loss: 0.11183  focal_loss 0.02604  dice_loss 0.08579 
Epoch [141/300] Validation metric {'Val/mean dice_metric': 0.8879213929176331, 'Val/mean miou_metric': 0.8246169090270996, 'Val/mean f1': 0.9017818570137024, 'Val/mean precision': 0.9019426703453064, 'Val/mean recall': 0.9016209244728088, 'Val/mean hd95_metric': 30.867557525634766}
Cheakpoint...
Epoch [141/300] best acc:tensor([0.8879], device='cuda:0'), Now : mean acc: tensor([0.8879], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8879213929176331, 'Val/mean miou_metric': 0.8246169090270996, 'Val/mean f1': 0.9017818570137024, 'Val/mean precision': 0.9019426703453064, 'Val/mean recall': 0.9016209244728088, 'Val/mean hd95_metric': 30.867557525634766}
Epoch [142/300] Training [1/62] Loss: 0.06009 
Epoch [142/300] Training [2/62] Loss: 0.21204 
Epoch [142/300] Training [3/62] Loss: 0.07563 
Epoch [142/300] Training [4/62] Loss: 0.14022 
Epoch [142/300] Training [5/62] Loss: 0.18116 
Epoch [142/300] Training [6/62] Loss: 0.12257 
Epoch [142/300] Training [7/62] Loss: 0.11214 
Epoch [142/300] Training [8/62] Loss: 0.07442 
Epoch [142/300] Training [9/62] Loss: 0.14125 
Epoch [142/300] Training [10/62] Loss: 0.16064 
Epoch [142/300] Training [11/62] Loss: 0.09087 
Epoch [142/300] Training [12/62] Loss: 0.08450 
Epoch [142/300] Training [13/62] Loss: 0.14337 
Epoch [142/300] Training [14/62] Loss: 0.09694 
Epoch [142/300] Training [15/62] Loss: 0.10020 
Epoch [142/300] Training [16/62] Loss: 0.08791 
Epoch [142/300] Training [17/62] Loss: 0.33382 
Epoch [142/300] Training [18/62] Loss: 0.09226 
Epoch [142/300] Training [19/62] Loss: 0.11858 
Epoch [142/300] Training [20/62] Loss: 0.08797 
Epoch [142/300] Training [21/62] Loss: 0.13190 
Epoch [142/300] Training [22/62] Loss: 0.08927 
Epoch [142/300] Training [23/62] Loss: 0.06253 
Epoch [142/300] Training [24/62] Loss: 0.08799 
Epoch [142/300] Training [25/62] Loss: 0.12945 
Epoch [142/300] Training [26/62] Loss: 0.11128 
Epoch [142/300] Training [27/62] Loss: 0.20573 
Epoch [142/300] Training [28/62] Loss: 0.14855 
Epoch [142/300] Training [29/62] Loss: 0.09643 
Epoch [142/300] Training [30/62] Loss: 0.23190 
Epoch [142/300] Training [31/62] Loss: 0.05758 
Epoch [142/300] Training [32/62] Loss: 0.09375 
Epoch [142/300] Training [33/62] Loss: 0.11256 
Epoch [142/300] Training [34/62] Loss: 0.20333 
Epoch [142/300] Training [35/62] Loss: 0.09698 
Epoch [142/300] Training [36/62] Loss: 0.14661 
Epoch [142/300] Training [37/62] Loss: 0.08685 
Epoch [142/300] Training [38/62] Loss: 0.14894 
Epoch [142/300] Training [39/62] Loss: 0.07113 
Epoch [142/300] Training [40/62] Loss: 0.10484 
Epoch [142/300] Training [41/62] Loss: 0.08029 
Epoch [142/300] Training [42/62] Loss: 0.27408 
Epoch [142/300] Training [43/62] Loss: 0.20480 
Epoch [142/300] Training [44/62] Loss: 0.08260 
Epoch [142/300] Training [45/62] Loss: 0.28630 
Epoch [142/300] Training [46/62] Loss: 0.15632 
Epoch [142/300] Training [47/62] Loss: 0.06406 
Epoch [142/300] Training [48/62] Loss: 0.12327 
Epoch [142/300] Training [49/62] Loss: 0.08513 
Epoch [142/300] Training [50/62] Loss: 0.10486 
Epoch [142/300] Training [51/62] Loss: 0.07706 
Epoch [142/300] Training [52/62] Loss: 0.04996 
Epoch [142/300] Training [53/62] Loss: 0.08335 
Epoch [142/300] Training [54/62] Loss: 0.10841 
Epoch [142/300] Training [55/62] Loss: 0.09577 
Epoch [142/300] Training [56/62] Loss: 0.07588 
Epoch [142/300] Training [57/62] Loss: 0.14666 
Epoch [142/300] Training [58/62] Loss: 0.05851 
Epoch [142/300] Training [59/62] Loss: 0.11973 
Epoch [142/300] Training [60/62] Loss: 0.11910 
Epoch [142/300] Training [61/62] Loss: 0.11505 
Epoch [142/300] Training [62/62] Loss: 0.08867 
Epoch [142/300] Training metric {'Train/mean dice_metric': 0.9183709025382996, 'Train/mean miou_metric': 0.8661314249038696, 'Train/mean f1': 0.9311397075653076, 'Train/mean precision': 0.9317305088043213, 'Train/mean recall': 0.9305496215820312, 'Train/mean hd95_metric': 22.517414093017578}
Epoch [142/300] Validation [1/16] Loss: 0.65030  focal_loss 0.40121  dice_loss 0.24909 
Epoch [142/300] Validation [2/16] Loss: 0.52953  focal_loss 0.16642  dice_loss 0.36311 
Epoch [142/300] Validation [3/16] Loss: 0.49855  focal_loss 0.24005  dice_loss 0.25850 
Epoch [142/300] Validation [4/16] Loss: 0.32538  focal_loss 0.13737  dice_loss 0.18801 
Epoch [142/300] Validation [5/16] Loss: 0.36212  focal_loss 0.10431  dice_loss 0.25782 
Epoch [142/300] Validation [6/16] Loss: 0.34570  focal_loss 0.09122  dice_loss 0.25448 
Epoch [142/300] Validation [7/16] Loss: 0.23470  focal_loss 0.08153  dice_loss 0.15317 
Epoch [142/300] Validation [8/16] Loss: 0.51688  focal_loss 0.15641  dice_loss 0.36047 
Epoch [142/300] Validation [9/16] Loss: 0.41699  focal_loss 0.17023  dice_loss 0.24676 
Epoch [142/300] Validation [10/16] Loss: 0.67654  focal_loss 0.20383  dice_loss 0.47272 
Epoch [142/300] Validation [11/16] Loss: 0.24144  focal_loss 0.05556  dice_loss 0.18588 
Epoch [142/300] Validation [12/16] Loss: 0.40451  focal_loss 0.07858  dice_loss 0.32593 
Epoch [142/300] Validation [13/16] Loss: 0.36528  focal_loss 0.11898  dice_loss 0.24630 
Epoch [142/300] Validation [14/16] Loss: 0.68433  focal_loss 0.29420  dice_loss 0.39012 
Epoch [142/300] Validation [15/16] Loss: 0.27120  focal_loss 0.10918  dice_loss 0.16202 
Epoch [142/300] Validation [16/16] Loss: 0.16750  focal_loss 0.02976  dice_loss 0.13775 
Epoch [142/300] Validation metric {'Val/mean dice_metric': 0.8824596405029297, 'Val/mean miou_metric': 0.8215105533599854, 'Val/mean f1': 0.9014033079147339, 'Val/mean precision': 0.9177177548408508, 'Val/mean recall': 0.8856587409973145, 'Val/mean hd95_metric': 29.741804122924805}
Cheakpoint...
Epoch [142/300] best acc:tensor([0.8879], device='cuda:0'), Now : mean acc: tensor([0.8825], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8824596405029297, 'Val/mean miou_metric': 0.8215105533599854, 'Val/mean f1': 0.9014033079147339, 'Val/mean precision': 0.9177177548408508, 'Val/mean recall': 0.8856587409973145, 'Val/mean hd95_metric': 29.741804122924805}
Epoch [143/300] Training [1/62] Loss: 0.09891 
Epoch [143/300] Training [2/62] Loss: 0.07593 
Epoch [143/300] Training [3/62] Loss: 0.08195 
Epoch [143/300] Training [4/62] Loss: 0.16408 
Epoch [143/300] Training [5/62] Loss: 0.20163 
Epoch [143/300] Training [6/62] Loss: 0.05316 
Epoch [143/300] Training [7/62] Loss: 0.05175 
Epoch [143/300] Training [8/62] Loss: 0.08774 
Epoch [143/300] Training [9/62] Loss: 0.09528 
Epoch [143/300] Training [10/62] Loss: 0.08054 
Epoch [143/300] Training [11/62] Loss: 0.11458 
Epoch [143/300] Training [12/62] Loss: 0.09189 
Epoch [143/300] Training [13/62] Loss: 0.08567 
Epoch [143/300] Training [14/62] Loss: 0.11003 
Epoch [143/300] Training [15/62] Loss: 0.12234 
Epoch [143/300] Training [16/62] Loss: 0.06791 
Epoch [143/300] Training [17/62] Loss: 0.07404 
Epoch [143/300] Training [18/62] Loss: 0.12810 
Epoch [143/300] Training [19/62] Loss: 0.13443 
Epoch [143/300] Training [20/62] Loss: 0.19480 
Epoch [143/300] Training [21/62] Loss: 0.11851 
Epoch [143/300] Training [22/62] Loss: 0.24950 
Epoch [143/300] Training [23/62] Loss: 0.07504 
Epoch [143/300] Training [24/62] Loss: 0.09300 
Epoch [143/300] Training [25/62] Loss: 0.06801 
Epoch [143/300] Training [26/62] Loss: 0.09108 
Epoch [143/300] Training [27/62] Loss: 0.12223 
Epoch [143/300] Training [28/62] Loss: 0.23400 
Epoch [143/300] Training [29/62] Loss: 0.18483 
Epoch [143/300] Training [30/62] Loss: 0.10816 
Epoch [143/300] Training [31/62] Loss: 0.14843 
Epoch [143/300] Training [32/62] Loss: 0.24659 
Epoch [143/300] Training [33/62] Loss: 0.08357 
Epoch [143/300] Training [34/62] Loss: 0.06478 
Epoch [143/300] Training [35/62] Loss: 0.21474 
Epoch [143/300] Training [36/62] Loss: 0.06203 
Epoch [143/300] Training [37/62] Loss: 0.10239 
Epoch [143/300] Training [38/62] Loss: 0.16059 
Epoch [143/300] Training [39/62] Loss: 0.11477 
Epoch [143/300] Training [40/62] Loss: 0.12422 
Epoch [143/300] Training [41/62] Loss: 0.10648 
Epoch [143/300] Training [42/62] Loss: 0.12537 
Epoch [143/300] Training [43/62] Loss: 0.09241 
Epoch [143/300] Training [44/62] Loss: 0.06775 
Epoch [143/300] Training [45/62] Loss: 0.08972 
Epoch [143/300] Training [46/62] Loss: 0.11933 
Epoch [143/300] Training [47/62] Loss: 0.18064 
Epoch [143/300] Training [48/62] Loss: 0.16753 
Epoch [143/300] Training [49/62] Loss: 0.16323 
Epoch [143/300] Training [50/62] Loss: 0.11605 
Epoch [143/300] Training [51/62] Loss: 0.08014 
Epoch [143/300] Training [52/62] Loss: 0.10079 
Epoch [143/300] Training [53/62] Loss: 0.09204 
Epoch [143/300] Training [54/62] Loss: 0.09068 
Epoch [143/300] Training [55/62] Loss: 0.05801 
Epoch [143/300] Training [56/62] Loss: 0.16262 
Epoch [143/300] Training [57/62] Loss: 0.06440 
Epoch [143/300] Training [58/62] Loss: 0.12552 
Epoch [143/300] Training [59/62] Loss: 0.06503 
Epoch [143/300] Training [60/62] Loss: 0.14293 
Epoch [143/300] Training [61/62] Loss: 0.10695 
Epoch [143/300] Training [62/62] Loss: 0.56929 
Epoch [143/300] Training metric {'Train/mean dice_metric': 0.9218952059745789, 'Train/mean miou_metric': 0.8683445453643799, 'Train/mean f1': 0.9332152009010315, 'Train/mean precision': 0.9335800409317017, 'Train/mean recall': 0.9328506588935852, 'Train/mean hd95_metric': 21.458717346191406}
Epoch [143/300] Validation [1/16] Loss: 0.60654  focal_loss 0.36413  dice_loss 0.24241 
Epoch [143/300] Validation [2/16] Loss: 0.45206  focal_loss 0.15018  dice_loss 0.30188 
Epoch [143/300] Validation [3/16] Loss: 0.52261  focal_loss 0.23783  dice_loss 0.28478 
Epoch [143/300] Validation [4/16] Loss: 0.34354  focal_loss 0.12531  dice_loss 0.21824 
Epoch [143/300] Validation [5/16] Loss: 0.35010  focal_loss 0.11080  dice_loss 0.23930 
Epoch [143/300] Validation [6/16] Loss: 0.43197  focal_loss 0.13542  dice_loss 0.29655 
Epoch [143/300] Validation [7/16] Loss: 0.32292  focal_loss 0.09886  dice_loss 0.22406 
Epoch [143/300] Validation [8/16] Loss: 0.49737  focal_loss 0.16638  dice_loss 0.33099 
Epoch [143/300] Validation [9/16] Loss: 0.28765  focal_loss 0.10398  dice_loss 0.18367 
Epoch [143/300] Validation [10/16] Loss: 0.53394  focal_loss 0.14649  dice_loss 0.38745 
Epoch [143/300] Validation [11/16] Loss: 0.18651  focal_loss 0.06064  dice_loss 0.12587 
Epoch [143/300] Validation [12/16] Loss: 0.36574  focal_loss 0.08433  dice_loss 0.28142 
Epoch [143/300] Validation [13/16] Loss: 0.33320  focal_loss 0.13005  dice_loss 0.20315 
Epoch [143/300] Validation [14/16] Loss: 0.55746  focal_loss 0.20840  dice_loss 0.34907 
Epoch [143/300] Validation [15/16] Loss: 0.15172  focal_loss 0.04872  dice_loss 0.10301 
Epoch [143/300] Validation [16/16] Loss: 0.16406  focal_loss 0.06109  dice_loss 0.10297 
Epoch [143/300] Validation metric {'Val/mean dice_metric': 0.8895576596260071, 'Val/mean miou_metric': 0.826964259147644, 'Val/mean f1': 0.907191812992096, 'Val/mean precision': 0.9211872220039368, 'Val/mean recall': 0.8936154246330261, 'Val/mean hd95_metric': 28.449142456054688}
Cheakpoint...
Epoch [143/300] best acc:tensor([0.8896], device='cuda:0'), Now : mean acc: tensor([0.8896], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8895576596260071, 'Val/mean miou_metric': 0.826964259147644, 'Val/mean f1': 0.907191812992096, 'Val/mean precision': 0.9211872220039368, 'Val/mean recall': 0.8936154246330261, 'Val/mean hd95_metric': 28.449142456054688}
Epoch [144/300] Training [1/62] Loss: 0.10624 
Epoch [144/300] Training [2/62] Loss: 0.10052 
Epoch [144/300] Training [3/62] Loss: 0.05559 
Epoch [144/300] Training [4/62] Loss: 0.10147 
Epoch [144/300] Training [5/62] Loss: 0.08214 
Epoch [144/300] Training [6/62] Loss: 0.09485 
Epoch [144/300] Training [7/62] Loss: 0.11867 
Epoch [144/300] Training [8/62] Loss: 0.13717 
Epoch [144/300] Training [9/62] Loss: 0.07282 
Epoch [144/300] Training [10/62] Loss: 0.06646 
Epoch [144/300] Training [11/62] Loss: 0.16306 
Epoch [144/300] Training [12/62] Loss: 0.24064 
Epoch [144/300] Training [13/62] Loss: 0.08383 
Epoch [144/300] Training [14/62] Loss: 0.11625 
Epoch [144/300] Training [15/62] Loss: 0.11577 
Epoch [144/300] Training [16/62] Loss: 0.13968 
Epoch [144/300] Training [17/62] Loss: 0.09871 
Epoch [144/300] Training [18/62] Loss: 0.07939 
Epoch [144/300] Training [19/62] Loss: 0.18202 
Epoch [144/300] Training [20/62] Loss: 0.18647 
Epoch [144/300] Training [21/62] Loss: 0.11231 
Epoch [144/300] Training [22/62] Loss: 0.06403 
Epoch [144/300] Training [23/62] Loss: 0.16813 
Epoch [144/300] Training [24/62] Loss: 0.16158 
Epoch [144/300] Training [25/62] Loss: 0.18669 
Epoch [144/300] Training [26/62] Loss: 0.22420 
Epoch [144/300] Training [27/62] Loss: 0.18252 
Epoch [144/300] Training [28/62] Loss: 0.08674 
Epoch [144/300] Training [29/62] Loss: 0.08168 
Epoch [144/300] Training [30/62] Loss: 0.07057 
Epoch [144/300] Training [31/62] Loss: 0.21703 
Epoch [144/300] Training [32/62] Loss: 0.06532 
Epoch [144/300] Training [33/62] Loss: 0.19309 
Epoch [144/300] Training [34/62] Loss: 0.31644 
Epoch [144/300] Training [35/62] Loss: 0.07022 
Epoch [144/300] Training [36/62] Loss: 0.07120 
Epoch [144/300] Training [37/62] Loss: 0.08581 
Epoch [144/300] Training [38/62] Loss: 0.18229 
Epoch [144/300] Training [39/62] Loss: 0.07911 
Epoch [144/300] Training [40/62] Loss: 0.10795 
Epoch [144/300] Training [41/62] Loss: 0.11955 
Epoch [144/300] Training [42/62] Loss: 0.10871 
Epoch [144/300] Training [43/62] Loss: 0.11446 
Epoch [144/300] Training [44/62] Loss: 0.06162 
Epoch [144/300] Training [45/62] Loss: 0.11305 
Epoch [144/300] Training [46/62] Loss: 0.15933 
Epoch [144/300] Training [47/62] Loss: 0.06405 
Epoch [144/300] Training [48/62] Loss: 0.09102 
Epoch [144/300] Training [49/62] Loss: 0.07852 
Epoch [144/300] Training [50/62] Loss: 0.17714 
Epoch [144/300] Training [51/62] Loss: 0.06521 
Epoch [144/300] Training [52/62] Loss: 0.21802 
Epoch [144/300] Training [53/62] Loss: 0.05739 
Epoch [144/300] Training [54/62] Loss: 0.12346 
Epoch [144/300] Training [55/62] Loss: 0.14355 
Epoch [144/300] Training [56/62] Loss: 0.05705 
Epoch [144/300] Training [57/62] Loss: 0.05183 
Epoch [144/300] Training [58/62] Loss: 0.13635 
Epoch [144/300] Training [59/62] Loss: 0.07523 
Epoch [144/300] Training [60/62] Loss: 0.10862 
Epoch [144/300] Training [61/62] Loss: 0.05456 
Epoch [144/300] Training [62/62] Loss: 0.23712 
Epoch [144/300] Training metric {'Train/mean dice_metric': 0.9200998544692993, 'Train/mean miou_metric': 0.868008553981781, 'Train/mean f1': 0.9332259893417358, 'Train/mean precision': 0.9353978037834167, 'Train/mean recall': 0.9310643076896667, 'Train/mean hd95_metric': 22.214420318603516}
Epoch [144/300] Validation [1/16] Loss: 0.69675  focal_loss 0.44661  dice_loss 0.25014 
Epoch [144/300] Validation [2/16] Loss: 0.51558  focal_loss 0.15953  dice_loss 0.35604 
Epoch [144/300] Validation [3/16] Loss: 0.58621  focal_loss 0.28115  dice_loss 0.30506 
Epoch [144/300] Validation [4/16] Loss: 0.38147  focal_loss 0.15193  dice_loss 0.22955 
Epoch [144/300] Validation [5/16] Loss: 0.33048  focal_loss 0.08037  dice_loss 0.25011 
Epoch [144/300] Validation [6/16] Loss: 0.33512  focal_loss 0.07949  dice_loss 0.25563 
Epoch [144/300] Validation [7/16] Loss: 0.34705  focal_loss 0.10170  dice_loss 0.24535 
Epoch [144/300] Validation [8/16] Loss: 0.41942  focal_loss 0.12091  dice_loss 0.29851 
Epoch [144/300] Validation [9/16] Loss: 0.25790  focal_loss 0.09083  dice_loss 0.16707 
Epoch [144/300] Validation [10/16] Loss: 0.43563  focal_loss 0.10675  dice_loss 0.32888 
Epoch [144/300] Validation [11/16] Loss: 0.22312  focal_loss 0.04619  dice_loss 0.17693 
Epoch [144/300] Validation [12/16] Loss: 0.42145  focal_loss 0.07839  dice_loss 0.34306 
Epoch [144/300] Validation [13/16] Loss: 0.23558  focal_loss 0.05540  dice_loss 0.18017 
Epoch [144/300] Validation [14/16] Loss: 0.70701  focal_loss 0.24057  dice_loss 0.46644 
Epoch [144/300] Validation [15/16] Loss: 0.18935  focal_loss 0.06486  dice_loss 0.12449 
Epoch [144/300] Validation [16/16] Loss: 0.15640  focal_loss 0.04068  dice_loss 0.11571 
Epoch [144/300] Validation metric {'Val/mean dice_metric': 0.8859087228775024, 'Val/mean miou_metric': 0.825410008430481, 'Val/mean f1': 0.9052994847297668, 'Val/mean precision': 0.9177783727645874, 'Val/mean recall': 0.8931554555892944, 'Val/mean hd95_metric': 29.11043930053711}
Cheakpoint...
Epoch [144/300] best acc:tensor([0.8896], device='cuda:0'), Now : mean acc: tensor([0.8859], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8859087228775024, 'Val/mean miou_metric': 0.825410008430481, 'Val/mean f1': 0.9052994847297668, 'Val/mean precision': 0.9177783727645874, 'Val/mean recall': 0.8931554555892944, 'Val/mean hd95_metric': 29.11043930053711}
Epoch [145/300] Training [1/62] Loss: 0.14450 
Epoch [145/300] Training [2/62] Loss: 0.11840 
Epoch [145/300] Training [3/62] Loss: 0.08997 
Epoch [145/300] Training [4/62] Loss: 0.17729 
Epoch [145/300] Training [5/62] Loss: 0.21464 
Epoch [145/300] Training [6/62] Loss: 0.09772 
Epoch [145/300] Training [7/62] Loss: 0.07622 
Epoch [145/300] Training [8/62] Loss: 0.07459 
Epoch [145/300] Training [9/62] Loss: 0.21916 
Epoch [145/300] Training [10/62] Loss: 0.22540 
Epoch [145/300] Training [11/62] Loss: 0.07184 
Epoch [145/300] Training [12/62] Loss: 0.10003 
Epoch [145/300] Training [13/62] Loss: 0.18486 
Epoch [145/300] Training [14/62] Loss: 0.12209 
Epoch [145/300] Training [15/62] Loss: 0.17573 
Epoch [145/300] Training [16/62] Loss: 0.11239 
Epoch [145/300] Training [17/62] Loss: 0.07181 
Epoch [145/300] Training [18/62] Loss: 0.16964 
Epoch [145/300] Training [19/62] Loss: 0.27647 
Epoch [145/300] Training [20/62] Loss: 0.11243 
Epoch [145/300] Training [21/62] Loss: 0.13280 
Epoch [145/300] Training [22/62] Loss: 0.12936 
Epoch [145/300] Training [23/62] Loss: 0.08589 
Epoch [145/300] Training [24/62] Loss: 0.09289 
Epoch [145/300] Training [25/62] Loss: 0.09886 
Epoch [145/300] Training [26/62] Loss: 0.17671 
Epoch [145/300] Training [27/62] Loss: 0.11800 
Epoch [145/300] Training [28/62] Loss: 0.11959 
Epoch [145/300] Training [29/62] Loss: 0.07086 
Epoch [145/300] Training [30/62] Loss: 0.07468 
Epoch [145/300] Training [31/62] Loss: 0.12740 
Epoch [145/300] Training [32/62] Loss: 0.08822 
Epoch [145/300] Training [33/62] Loss: 0.19968 
Epoch [145/300] Training [34/62] Loss: 0.05998 
Epoch [145/300] Training [35/62] Loss: 0.06973 
Epoch [145/300] Training [36/62] Loss: 0.05727 
Epoch [145/300] Training [37/62] Loss: 0.13886 
Epoch [145/300] Training [38/62] Loss: 0.11325 
Epoch [145/300] Training [39/62] Loss: 0.07316 
Epoch [145/300] Training [40/62] Loss: 0.10294 
Epoch [145/300] Training [41/62] Loss: 0.06280 
Epoch [145/300] Training [42/62] Loss: 0.09569 
Epoch [145/300] Training [43/62] Loss: 0.10783 
Epoch [145/300] Training [44/62] Loss: 0.11584 
Epoch [145/300] Training [45/62] Loss: 0.11425 
Epoch [145/300] Training [46/62] Loss: 0.13924 
Epoch [145/300] Training [47/62] Loss: 0.08470 
Epoch [145/300] Training [48/62] Loss: 0.28759 
Epoch [145/300] Training [49/62] Loss: 0.11504 
Epoch [145/300] Training [50/62] Loss: 0.10675 
Epoch [145/300] Training [51/62] Loss: 0.05905 
Epoch [145/300] Training [52/62] Loss: 0.15842 
Epoch [145/300] Training [53/62] Loss: 0.06189 
Epoch [145/300] Training [54/62] Loss: 0.18653 
Epoch [145/300] Training [55/62] Loss: 0.14127 
Epoch [145/300] Training [56/62] Loss: 0.07247 
Epoch [145/300] Training [57/62] Loss: 0.07113 
Epoch [145/300] Training [58/62] Loss: 0.15791 
Epoch [145/300] Training [59/62] Loss: 0.06855 
Epoch [145/300] Training [60/62] Loss: 0.14715 
Epoch [145/300] Training [61/62] Loss: 0.17532 
Epoch [145/300] Training [62/62] Loss: 0.05057 
Epoch [145/300] Training metric {'Train/mean dice_metric': 0.9188452959060669, 'Train/mean miou_metric': 0.8652036190032959, 'Train/mean f1': 0.9306838512420654, 'Train/mean precision': 0.9328616261482239, 'Train/mean recall': 0.9285162687301636, 'Train/mean hd95_metric': 21.627595901489258}
Epoch [145/300] Validation [1/16] Loss: 0.67272  focal_loss 0.44567  dice_loss 0.22705 
Epoch [145/300] Validation [2/16] Loss: 0.46534  focal_loss 0.16166  dice_loss 0.30367 
Epoch [145/300] Validation [3/16] Loss: 0.56134  focal_loss 0.28766  dice_loss 0.27368 
Epoch [145/300] Validation [4/16] Loss: 0.32924  focal_loss 0.13808  dice_loss 0.19116 
Epoch [145/300] Validation [5/16] Loss: 0.33197  focal_loss 0.08706  dice_loss 0.24491 
Epoch [145/300] Validation [6/16] Loss: 0.33572  focal_loss 0.08663  dice_loss 0.24910 
Epoch [145/300] Validation [7/16] Loss: 0.20900  focal_loss 0.08127  dice_loss 0.12773 
Epoch [145/300] Validation [8/16] Loss: 0.38031  focal_loss 0.10946  dice_loss 0.27086 
Epoch [145/300] Validation [9/16] Loss: 0.27443  focal_loss 0.10291  dice_loss 0.17152 
Epoch [145/300] Validation [10/16] Loss: 0.57172  focal_loss 0.14885  dice_loss 0.42287 
Epoch [145/300] Validation [11/16] Loss: 0.19002  focal_loss 0.05799  dice_loss 0.13203 
Epoch [145/300] Validation [12/16] Loss: 0.42292  focal_loss 0.10494  dice_loss 0.31798 
Epoch [145/300] Validation [13/16] Loss: 0.21864  focal_loss 0.06141  dice_loss 0.15723 
Epoch [145/300] Validation [14/16] Loss: 0.64470  focal_loss 0.24850  dice_loss 0.39621 
Epoch [145/300] Validation [15/16] Loss: 0.14940  focal_loss 0.04919  dice_loss 0.10021 
Epoch [145/300] Validation [16/16] Loss: 0.17106  focal_loss 0.05345  dice_loss 0.11760 
Epoch [145/300] Validation metric {'Val/mean dice_metric': 0.8896352648735046, 'Val/mean miou_metric': 0.8280560970306396, 'Val/mean f1': 0.9062731862068176, 'Val/mean precision': 0.9186866283416748, 'Val/mean recall': 0.8941908478736877, 'Val/mean hd95_metric': 29.453134536743164}
Cheakpoint...
Epoch [145/300] best acc:tensor([0.8896], device='cuda:0'), Now : mean acc: tensor([0.8896], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8896352648735046, 'Val/mean miou_metric': 0.8280560970306396, 'Val/mean f1': 0.9062731862068176, 'Val/mean precision': 0.9186866283416748, 'Val/mean recall': 0.8941908478736877, 'Val/mean hd95_metric': 29.453134536743164}
Epoch [146/300] Training [1/62] Loss: 0.17690 
Epoch [146/300] Training [2/62] Loss: 0.10839 
Epoch [146/300] Training [3/62] Loss: 0.08945 
Epoch [146/300] Training [4/62] Loss: 0.18642 
Epoch [146/300] Training [5/62] Loss: 0.10075 
Epoch [146/300] Training [6/62] Loss: 0.15581 
Epoch [146/300] Training [7/62] Loss: 0.10883 
Epoch [146/300] Training [8/62] Loss: 0.07086 
Epoch [146/300] Training [9/62] Loss: 0.18200 
Epoch [146/300] Training [10/62] Loss: 0.14052 
Epoch [146/300] Training [11/62] Loss: 0.07817 
Epoch [146/300] Training [12/62] Loss: 0.08046 
Epoch [146/300] Training [13/62] Loss: 0.08991 
Epoch [146/300] Training [14/62] Loss: 0.07909 
Epoch [146/300] Training [15/62] Loss: 0.09158 
Epoch [146/300] Training [16/62] Loss: 0.08454 
Epoch [146/300] Training [17/62] Loss: 0.06975 
Epoch [146/300] Training [18/62] Loss: 0.05830 
Epoch [146/300] Training [19/62] Loss: 0.16159 
Epoch [146/300] Training [20/62] Loss: 0.20248 
Epoch [146/300] Training [21/62] Loss: 0.06268 
Epoch [146/300] Training [22/62] Loss: 0.11128 
Epoch [146/300] Training [23/62] Loss: 0.16692 
Epoch [146/300] Training [24/62] Loss: 0.16000 
Epoch [146/300] Training [25/62] Loss: 0.07835 
Epoch [146/300] Training [26/62] Loss: 0.06549 
Epoch [146/300] Training [27/62] Loss: 0.06052 
Epoch [146/300] Training [28/62] Loss: 0.07410 
Epoch [146/300] Training [29/62] Loss: 0.06290 
Epoch [146/300] Training [30/62] Loss: 0.11147 
Epoch [146/300] Training [31/62] Loss: 0.05776 
Epoch [146/300] Training [32/62] Loss: 0.08640 
Epoch [146/300] Training [33/62] Loss: 0.13239 
Epoch [146/300] Training [34/62] Loss: 0.09267 
Epoch [146/300] Training [35/62] Loss: 0.07126 
Epoch [146/300] Training [36/62] Loss: 0.05666 
Epoch [146/300] Training [37/62] Loss: 0.20010 
Epoch [146/300] Training [38/62] Loss: 0.15542 
Epoch [146/300] Training [39/62] Loss: 0.08099 
Epoch [146/300] Training [40/62] Loss: 0.11609 
Epoch [146/300] Training [41/62] Loss: 0.07550 
Epoch [146/300] Training [42/62] Loss: 0.08119 
Epoch [146/300] Training [43/62] Loss: 0.15445 
Epoch [146/300] Training [44/62] Loss: 0.10239 
Epoch [146/300] Training [45/62] Loss: 0.06376 
Epoch [146/300] Training [46/62] Loss: 0.20934 
Epoch [146/300] Training [47/62] Loss: 0.08045 
Epoch [146/300] Training [48/62] Loss: 0.22968 
Epoch [146/300] Training [49/62] Loss: 0.06549 
Epoch [146/300] Training [50/62] Loss: 0.12508 
Epoch [146/300] Training [51/62] Loss: 0.09915 
Epoch [146/300] Training [52/62] Loss: 0.08509 
Epoch [146/300] Training [53/62] Loss: 0.10023 
Epoch [146/300] Training [54/62] Loss: 0.05713 
Epoch [146/300] Training [55/62] Loss: 0.06539 
Epoch [146/300] Training [56/62] Loss: 0.09404 
Epoch [146/300] Training [57/62] Loss: 0.11780 
Epoch [146/300] Training [58/62] Loss: 0.06819 
Epoch [146/300] Training [59/62] Loss: 0.09890 
Epoch [146/300] Training [60/62] Loss: 0.16211 
Epoch [146/300] Training [61/62] Loss: 0.08395 
Epoch [146/300] Training [62/62] Loss: 0.08067 
Epoch [146/300] Training metric {'Train/mean dice_metric': 0.9277135133743286, 'Train/mean miou_metric': 0.8774516582489014, 'Train/mean f1': 0.9390480518341064, 'Train/mean precision': 0.9382608532905579, 'Train/mean recall': 0.9398366808891296, 'Train/mean hd95_metric': 20.251171112060547}
Epoch [146/300] Validation [1/16] Loss: 0.55978  focal_loss 0.34907  dice_loss 0.21070 
Epoch [146/300] Validation [2/16] Loss: 0.46025  focal_loss 0.14641  dice_loss 0.31385 
Epoch [146/300] Validation [3/16] Loss: 0.52424  focal_loss 0.22617  dice_loss 0.29807 
Epoch [146/300] Validation [4/16] Loss: 0.43593  focal_loss 0.17029  dice_loss 0.26564 
Epoch [146/300] Validation [5/16] Loss: 0.37373  focal_loss 0.11922  dice_loss 0.25451 
Epoch [146/300] Validation [6/16] Loss: 0.34365  focal_loss 0.10444  dice_loss 0.23921 
Epoch [146/300] Validation [7/16] Loss: 0.18233  focal_loss 0.05744  dice_loss 0.12489 
Epoch [146/300] Validation [8/16] Loss: 0.42713  focal_loss 0.14902  dice_loss 0.27811 
Epoch [146/300] Validation [9/16] Loss: 0.30178  focal_loss 0.09954  dice_loss 0.20224 
Epoch [146/300] Validation [10/16] Loss: 0.45946  focal_loss 0.16330  dice_loss 0.29616 
Epoch [146/300] Validation [11/16] Loss: 0.28219  focal_loss 0.07253  dice_loss 0.20966 
Epoch [146/300] Validation [12/16] Loss: 0.40177  focal_loss 0.09425  dice_loss 0.30753 
Epoch [146/300] Validation [13/16] Loss: 0.23453  focal_loss 0.05985  dice_loss 0.17468 
Epoch [146/300] Validation [14/16] Loss: 0.76111  focal_loss 0.27522  dice_loss 0.48589 
Epoch [146/300] Validation [15/16] Loss: 0.11591  focal_loss 0.03150  dice_loss 0.08441 
Epoch [146/300] Validation [16/16] Loss: 0.23247  focal_loss 0.06614  dice_loss 0.16633 
Epoch [146/300] Validation metric {'Val/mean dice_metric': 0.8947187662124634, 'Val/mean miou_metric': 0.835538923740387, 'Val/mean f1': 0.9094833135604858, 'Val/mean precision': 0.909066379070282, 'Val/mean recall': 0.9099006056785583, 'Val/mean hd95_metric': 29.428800582885742}
Cheakpoint...
Epoch [146/300] best acc:tensor([0.8947], device='cuda:0'), Now : mean acc: tensor([0.8947], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8947187662124634, 'Val/mean miou_metric': 0.835538923740387, 'Val/mean f1': 0.9094833135604858, 'Val/mean precision': 0.909066379070282, 'Val/mean recall': 0.9099006056785583, 'Val/mean hd95_metric': 29.428800582885742}
Epoch [147/300] Training [1/62] Loss: 0.07978 
Epoch [147/300] Training [2/62] Loss: 0.11270 
Epoch [147/300] Training [3/62] Loss: 0.16228 
Epoch [147/300] Training [4/62] Loss: 0.10584 
Epoch [147/300] Training [5/62] Loss: 0.07481 
Epoch [147/300] Training [6/62] Loss: 0.11097 
Epoch [147/300] Training [7/62] Loss: 0.12877 
Epoch [147/300] Training [8/62] Loss: 0.12531 
Epoch [147/300] Training [9/62] Loss: 0.06654 
Epoch [147/300] Training [10/62] Loss: 0.09685 
Epoch [147/300] Training [11/62] Loss: 0.19448 
Epoch [147/300] Training [12/62] Loss: 0.09583 
Epoch [147/300] Training [13/62] Loss: 0.13098 
Epoch [147/300] Training [14/62] Loss: 0.05731 
Epoch [147/300] Training [15/62] Loss: 0.09516 
Epoch [147/300] Training [16/62] Loss: 0.06611 
Epoch [147/300] Training [17/62] Loss: 0.09961 
Epoch [147/300] Training [18/62] Loss: 0.08942 
Epoch [147/300] Training [19/62] Loss: 0.09108 
Epoch [147/300] Training [20/62] Loss: 0.07239 
Epoch [147/300] Training [21/62] Loss: 0.06558 
Epoch [147/300] Training [22/62] Loss: 0.15967 
Epoch [147/300] Training [23/62] Loss: 0.11728 
Epoch [147/300] Training [24/62] Loss: 0.10134 
Epoch [147/300] Training [25/62] Loss: 0.34827 
Epoch [147/300] Training [26/62] Loss: 0.20050 
Epoch [147/300] Training [27/62] Loss: 0.10568 
Epoch [147/300] Training [28/62] Loss: 0.24056 
Epoch [147/300] Training [29/62] Loss: 0.12882 
Epoch [147/300] Training [30/62] Loss: 0.05748 
Epoch [147/300] Training [31/62] Loss: 0.19064 
Epoch [147/300] Training [32/62] Loss: 0.15848 
Epoch [147/300] Training [33/62] Loss: 0.08547 
Epoch [147/300] Training [34/62] Loss: 0.13518 
Epoch [147/300] Training [35/62] Loss: 0.12981 
Epoch [147/300] Training [36/62] Loss: 0.07037 
Epoch [147/300] Training [37/62] Loss: 0.13984 
Epoch [147/300] Training [38/62] Loss: 0.07648 
Epoch [147/300] Training [39/62] Loss: 0.07506 
Epoch [147/300] Training [40/62] Loss: 0.10815 
Epoch [147/300] Training [41/62] Loss: 0.07355 
Epoch [147/300] Training [42/62] Loss: 0.06207 
Epoch [147/300] Training [43/62] Loss: 0.06677 
Epoch [147/300] Training [44/62] Loss: 0.06833 
Epoch [147/300] Training [45/62] Loss: 0.06839 
Epoch [147/300] Training [46/62] Loss: 0.07165 
Epoch [147/300] Training [47/62] Loss: 0.19328 
Epoch [147/300] Training [48/62] Loss: 0.16290 
Epoch [147/300] Training [49/62] Loss: 0.05682 
Epoch [147/300] Training [50/62] Loss: 0.10643 
Epoch [147/300] Training [51/62] Loss: 0.16623 
Epoch [147/300] Training [52/62] Loss: 0.09113 
Epoch [147/300] Training [53/62] Loss: 0.12243 
Epoch [147/300] Training [54/62] Loss: 0.10989 
Epoch [147/300] Training [55/62] Loss: 0.08066 
Epoch [147/300] Training [56/62] Loss: 0.14967 
Epoch [147/300] Training [57/62] Loss: 0.14514 
Epoch [147/300] Training [58/62] Loss: 0.06612 
Epoch [147/300] Training [59/62] Loss: 0.06979 
Epoch [147/300] Training [60/62] Loss: 0.13931 
Epoch [147/300] Training [61/62] Loss: 0.10413 
Epoch [147/300] Training [62/62] Loss: 0.17760 
Epoch [147/300] Training metric {'Train/mean dice_metric': 0.9229992032051086, 'Train/mean miou_metric': 0.8702176213264465, 'Train/mean f1': 0.9359936118125916, 'Train/mean precision': 0.9325374960899353, 'Train/mean recall': 0.9394753575325012, 'Train/mean hd95_metric': 21.500722885131836}
Epoch [147/300] Validation [1/16] Loss: 0.65039  focal_loss 0.36142  dice_loss 0.28897 
Epoch [147/300] Validation [2/16] Loss: 0.42692  focal_loss 0.13078  dice_loss 0.29614 
Epoch [147/300] Validation [3/16] Loss: 0.60986  focal_loss 0.31801  dice_loss 0.29185 
Epoch [147/300] Validation [4/16] Loss: 0.34400  focal_loss 0.11999  dice_loss 0.22401 
Epoch [147/300] Validation [5/16] Loss: 0.44880  focal_loss 0.12615  dice_loss 0.32265 
Epoch [147/300] Validation [6/16] Loss: 0.38261  focal_loss 0.12362  dice_loss 0.25899 
Epoch [147/300] Validation [7/16] Loss: 0.22727  focal_loss 0.06139  dice_loss 0.16588 
Epoch [147/300] Validation [8/16] Loss: 0.53150  focal_loss 0.16362  dice_loss 0.36788 
Epoch [147/300] Validation [9/16] Loss: 0.28737  focal_loss 0.08595  dice_loss 0.20142 
Epoch [147/300] Validation [10/16] Loss: 0.50588  focal_loss 0.12375  dice_loss 0.38213 
Epoch [147/300] Validation [11/16] Loss: 0.24329  focal_loss 0.08794  dice_loss 0.15535 
Epoch [147/300] Validation [12/16] Loss: 0.41176  focal_loss 0.09429  dice_loss 0.31747 
Epoch [147/300] Validation [13/16] Loss: 0.40671  focal_loss 0.13276  dice_loss 0.27395 
Epoch [147/300] Validation [14/16] Loss: 0.62329  focal_loss 0.20568  dice_loss 0.41761 
Epoch [147/300] Validation [15/16] Loss: 0.17700  focal_loss 0.05395  dice_loss 0.12305 
Epoch [147/300] Validation [16/16] Loss: 0.14272  focal_loss 0.03850  dice_loss 0.10422 
Epoch [147/300] Validation metric {'Val/mean dice_metric': 0.8863316178321838, 'Val/mean miou_metric': 0.8245510458946228, 'Val/mean f1': 0.908087968826294, 'Val/mean precision': 0.9138687252998352, 'Val/mean recall': 0.9023799896240234, 'Val/mean hd95_metric': 29.841285705566406}
Cheakpoint...
Epoch [147/300] best acc:tensor([0.8947], device='cuda:0'), Now : mean acc: tensor([0.8863], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8863316178321838, 'Val/mean miou_metric': 0.8245510458946228, 'Val/mean f1': 0.908087968826294, 'Val/mean precision': 0.9138687252998352, 'Val/mean recall': 0.9023799896240234, 'Val/mean hd95_metric': 29.841285705566406}
Epoch [148/300] Training [1/62] Loss: 0.12406 
Epoch [148/300] Training [2/62] Loss: 0.09587 
Epoch [148/300] Training [3/62] Loss: 0.09168 
Epoch [148/300] Training [4/62] Loss: 0.06871 
Epoch [148/300] Training [5/62] Loss: 0.05960 
Epoch [148/300] Training [6/62] Loss: 0.13981 
Epoch [148/300] Training [7/62] Loss: 0.21810 
Epoch [148/300] Training [8/62] Loss: 0.15102 
Epoch [148/300] Training [9/62] Loss: 0.07044 
Epoch [148/300] Training [10/62] Loss: 0.10980 
Epoch [148/300] Training [11/62] Loss: 0.23870 
Epoch [148/300] Training [12/62] Loss: 0.07885 
Epoch [148/300] Training [13/62] Loss: 0.21059 
Epoch [148/300] Training [14/62] Loss: 0.22715 
Epoch [148/300] Training [15/62] Loss: 0.08577 
Epoch [148/300] Training [16/62] Loss: 0.15931 
Epoch [148/300] Training [17/62] Loss: 0.07099 
Epoch [148/300] Training [18/62] Loss: 0.11667 
Epoch [148/300] Training [19/62] Loss: 0.18325 
Epoch [148/300] Training [20/62] Loss: 0.09477 
Epoch [148/300] Training [21/62] Loss: 0.09926 
Epoch [148/300] Training [22/62] Loss: 0.10679 
Epoch [148/300] Training [23/62] Loss: 0.07054 
Epoch [148/300] Training [24/62] Loss: 0.10354 
Epoch [148/300] Training [25/62] Loss: 0.16387 
Epoch [148/300] Training [26/62] Loss: 0.14786 
Epoch [148/300] Training [27/62] Loss: 0.11485 
Epoch [148/300] Training [28/62] Loss: 0.09867 
Epoch [148/300] Training [29/62] Loss: 0.09192 
Epoch [148/300] Training [30/62] Loss: 0.08527 
Epoch [148/300] Training [31/62] Loss: 0.12137 
Epoch [148/300] Training [32/62] Loss: 0.09874 
Epoch [148/300] Training [33/62] Loss: 0.08100 
Epoch [148/300] Training [34/62] Loss: 0.07465 
Epoch [148/300] Training [35/62] Loss: 0.08358 
Epoch [148/300] Training [36/62] Loss: 0.23213 
Epoch [148/300] Training [37/62] Loss: 0.06306 
Epoch [148/300] Training [38/62] Loss: 0.07783 
Epoch [148/300] Training [39/62] Loss: 0.13940 
Epoch [148/300] Training [40/62] Loss: 0.06271 
Epoch [148/300] Training [41/62] Loss: 0.07755 
Epoch [148/300] Training [42/62] Loss: 0.11291 
Epoch [148/300] Training [43/62] Loss: 0.04838 
Epoch [148/300] Training [44/62] Loss: 0.21086 
Epoch [148/300] Training [45/62] Loss: 0.04848 
Epoch [148/300] Training [46/62] Loss: 0.05785 
Epoch [148/300] Training [47/62] Loss: 0.09045 
Epoch [148/300] Training [48/62] Loss: 0.19750 
Epoch [148/300] Training [49/62] Loss: 0.18286 
Epoch [148/300] Training [50/62] Loss: 0.12550 
Epoch [148/300] Training [51/62] Loss: 0.05644 
Epoch [148/300] Training [52/62] Loss: 0.07881 
Epoch [148/300] Training [53/62] Loss: 0.14259 
Epoch [148/300] Training [54/62] Loss: 0.12924 
Epoch [148/300] Training [55/62] Loss: 0.12763 
Epoch [148/300] Training [56/62] Loss: 0.22272 
Epoch [148/300] Training [57/62] Loss: 0.08600 
Epoch [148/300] Training [58/62] Loss: 0.07375 
Epoch [148/300] Training [59/62] Loss: 0.08460 
Epoch [148/300] Training [60/62] Loss: 0.19002 
Epoch [148/300] Training [61/62] Loss: 0.06440 
Epoch [148/300] Training [62/62] Loss: 0.06036 
Epoch [148/300] Training metric {'Train/mean dice_metric': 0.9230788946151733, 'Train/mean miou_metric': 0.8715752959251404, 'Train/mean f1': 0.9350296258926392, 'Train/mean precision': 0.9399057626724243, 'Train/mean recall': 0.9302037954330444, 'Train/mean hd95_metric': 22.380311965942383}
Epoch [148/300] Validation [1/16] Loss: 0.95419  focal_loss 0.58527  dice_loss 0.36892 
Epoch [148/300] Validation [2/16] Loss: 0.57699  focal_loss 0.19279  dice_loss 0.38420 
Epoch [148/300] Validation [3/16] Loss: 0.61186  focal_loss 0.29699  dice_loss 0.31488 
Epoch [148/300] Validation [4/16] Loss: 0.52332  focal_loss 0.24256  dice_loss 0.28076 
Epoch [148/300] Validation [5/16] Loss: 0.33602  focal_loss 0.11130  dice_loss 0.22472 
Epoch [148/300] Validation [6/16] Loss: 0.30890  focal_loss 0.08759  dice_loss 0.22132 
Epoch [148/300] Validation [7/16] Loss: 0.27866  focal_loss 0.12027  dice_loss 0.15838 
Epoch [148/300] Validation [8/16] Loss: 0.47790  focal_loss 0.17101  dice_loss 0.30689 
Epoch [148/300] Validation [9/16] Loss: 0.53983  focal_loss 0.21821  dice_loss 0.32162 
Epoch [148/300] Validation [10/16] Loss: 0.58622  focal_loss 0.17101  dice_loss 0.41521 
Epoch [148/300] Validation [11/16] Loss: 0.50025  focal_loss 0.12728  dice_loss 0.37296 
Epoch [148/300] Validation [12/16] Loss: 0.51952  focal_loss 0.11299  dice_loss 0.40653 
Epoch [148/300] Validation [13/16] Loss: 0.35009  focal_loss 0.13971  dice_loss 0.21038 
Epoch [148/300] Validation [14/16] Loss: 0.54944  focal_loss 0.18929  dice_loss 0.36015 
Epoch [148/300] Validation [15/16] Loss: 0.15052  focal_loss 0.05024  dice_loss 0.10028 
Epoch [148/300] Validation [16/16] Loss: 0.21010  focal_loss 0.06719  dice_loss 0.14290 
Epoch [148/300] Validation metric {'Val/mean dice_metric': 0.8811326622962952, 'Val/mean miou_metric': 0.8212093710899353, 'Val/mean f1': 0.9027731418609619, 'Val/mean precision': 0.9199402332305908, 'Val/mean recall': 0.8862348794937134, 'Val/mean hd95_metric': 29.24925994873047}
Cheakpoint...
Epoch [148/300] best acc:tensor([0.8947], device='cuda:0'), Now : mean acc: tensor([0.8811], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8811326622962952, 'Val/mean miou_metric': 0.8212093710899353, 'Val/mean f1': 0.9027731418609619, 'Val/mean precision': 0.9199402332305908, 'Val/mean recall': 0.8862348794937134, 'Val/mean hd95_metric': 29.24925994873047}
Epoch [149/300] Training [1/62] Loss: 0.05810 
Epoch [149/300] Training [2/62] Loss: 0.09929 
Epoch [149/300] Training [3/62] Loss: 0.21467 
Epoch [149/300] Training [4/62] Loss: 0.09684 
Epoch [149/300] Training [5/62] Loss: 0.12566 
Epoch [149/300] Training [6/62] Loss: 0.06262 
Epoch [149/300] Training [7/62] Loss: 0.07837 
Epoch [149/300] Training [8/62] Loss: 0.07756 
Epoch [149/300] Training [9/62] Loss: 0.09490 
Epoch [149/300] Training [10/62] Loss: 0.15931 
Epoch [149/300] Training [11/62] Loss: 0.09291 
Epoch [149/300] Training [12/62] Loss: 0.09025 
Epoch [149/300] Training [13/62] Loss: 0.10192 
Epoch [149/300] Training [14/62] Loss: 0.11875 
Epoch [149/300] Training [15/62] Loss: 0.17931 
Epoch [149/300] Training [16/62] Loss: 0.07708 
Epoch [149/300] Training [17/62] Loss: 0.15170 
Epoch [149/300] Training [18/62] Loss: 0.12509 
Epoch [149/300] Training [19/62] Loss: 0.12981 
Epoch [149/300] Training [20/62] Loss: 0.12587 
Epoch [149/300] Training [21/62] Loss: 0.09449 
Epoch [149/300] Training [22/62] Loss: 0.09981 
Epoch [149/300] Training [23/62] Loss: 0.05730 
Epoch [149/300] Training [24/62] Loss: 0.32649 
Epoch [149/300] Training [25/62] Loss: 0.09214 
Epoch [149/300] Training [26/62] Loss: 0.12478 
Epoch [149/300] Training [27/62] Loss: 0.15721 
Epoch [149/300] Training [28/62] Loss: 0.07712 
Epoch [149/300] Training [29/62] Loss: 0.20773 
Epoch [149/300] Training [30/62] Loss: 0.09751 
Epoch [149/300] Training [31/62] Loss: 0.07430 
Epoch [149/300] Training [32/62] Loss: 0.24908 
Epoch [149/300] Training [33/62] Loss: 0.18726 
Epoch [149/300] Training [34/62] Loss: 0.06390 
Epoch [149/300] Training [35/62] Loss: 0.13768 
Epoch [149/300] Training [36/62] Loss: 0.23770 
Epoch [149/300] Training [37/62] Loss: 0.04931 
Epoch [149/300] Training [38/62] Loss: 0.12059 
Epoch [149/300] Training [39/62] Loss: 0.08510 
Epoch [149/300] Training [40/62] Loss: 0.06538 
Epoch [149/300] Training [41/62] Loss: 0.09128 
Epoch [149/300] Training [42/62] Loss: 0.11520 
Epoch [149/300] Training [43/62] Loss: 0.11133 
Epoch [149/300] Training [44/62] Loss: 0.08085 
Epoch [149/300] Training [45/62] Loss: 0.08021 
Epoch [149/300] Training [46/62] Loss: 0.06489 
Epoch [149/300] Training [47/62] Loss: 0.22608 
Epoch [149/300] Training [48/62] Loss: 0.06639 
Epoch [149/300] Training [49/62] Loss: 0.10641 
Epoch [149/300] Training [50/62] Loss: 0.18635 
Epoch [149/300] Training [51/62] Loss: 0.06575 
Epoch [149/300] Training [52/62] Loss: 0.09026 
Epoch [149/300] Training [53/62] Loss: 0.06310 
Epoch [149/300] Training [54/62] Loss: 0.07300 
Epoch [149/300] Training [55/62] Loss: 0.08087 
Epoch [149/300] Training [56/62] Loss: 0.09964 
Epoch [149/300] Training [57/62] Loss: 0.10354 
Epoch [149/300] Training [58/62] Loss: 0.13306 
Epoch [149/300] Training [59/62] Loss: 0.11431 
Epoch [149/300] Training [60/62] Loss: 0.12836 
Epoch [149/300] Training [61/62] Loss: 0.14194 
Epoch [149/300] Training [62/62] Loss: 0.03581 
Epoch [149/300] Training metric {'Train/mean dice_metric': 0.9233758449554443, 'Train/mean miou_metric': 0.871461808681488, 'Train/mean f1': 0.9343467950820923, 'Train/mean precision': 0.9393131732940674, 'Train/mean recall': 0.9294328093528748, 'Train/mean hd95_metric': 22.495412826538086}
Epoch [149/300] Validation [1/16] Loss: 0.54968  focal_loss 0.32902  dice_loss 0.22066 
Epoch [149/300] Validation [2/16] Loss: 0.45828  focal_loss 0.12768  dice_loss 0.33060 
Epoch [149/300] Validation [3/16] Loss: 0.60593  focal_loss 0.31059  dice_loss 0.29533 
Epoch [149/300] Validation [4/16] Loss: 0.35415  focal_loss 0.15338  dice_loss 0.20077 
Epoch [149/300] Validation [5/16] Loss: 0.32581  focal_loss 0.09203  dice_loss 0.23378 
Epoch [149/300] Validation [6/16] Loss: 0.37054  focal_loss 0.11417  dice_loss 0.25637 
Epoch [149/300] Validation [7/16] Loss: 0.16183  focal_loss 0.05563  dice_loss 0.10620 
Epoch [149/300] Validation [8/16] Loss: 0.45460  focal_loss 0.14349  dice_loss 0.31110 
Epoch [149/300] Validation [9/16] Loss: 0.32784  focal_loss 0.10914  dice_loss 0.21870 
Epoch [149/300] Validation [10/16] Loss: 0.54137  focal_loss 0.15240  dice_loss 0.38897 
Epoch [149/300] Validation [11/16] Loss: 0.21539  focal_loss 0.05593  dice_loss 0.15945 
Epoch [149/300] Validation [12/16] Loss: 0.41715  focal_loss 0.10479  dice_loss 0.31237 
Epoch [149/300] Validation [13/16] Loss: 0.22473  focal_loss 0.05337  dice_loss 0.17137 
Epoch [149/300] Validation [14/16] Loss: 0.49282  focal_loss 0.15883  dice_loss 0.33398 
Epoch [149/300] Validation [15/16] Loss: 0.16783  focal_loss 0.04824  dice_loss 0.11959 
Epoch [149/300] Validation [16/16] Loss: 0.27397  focal_loss 0.09197  dice_loss 0.18200 
Epoch [149/300] Validation metric {'Val/mean dice_metric': 0.8922019600868225, 'Val/mean miou_metric': 0.8314107060432434, 'Val/mean f1': 0.9075856804847717, 'Val/mean precision': 0.9126346111297607, 'Val/mean recall': 0.9025922417640686, 'Val/mean hd95_metric': 32.26581573486328}
Cheakpoint...
Epoch [149/300] best acc:tensor([0.8947], device='cuda:0'), Now : mean acc: tensor([0.8922], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8922019600868225, 'Val/mean miou_metric': 0.8314107060432434, 'Val/mean f1': 0.9075856804847717, 'Val/mean precision': 0.9126346111297607, 'Val/mean recall': 0.9025922417640686, 'Val/mean hd95_metric': 32.26581573486328}
Epoch [150/300] Training [1/62] Loss: 0.08509 
Epoch [150/300] Training [2/62] Loss: 0.15966 
Epoch [150/300] Training [3/62] Loss: 0.07408 
Epoch [150/300] Training [4/62] Loss: 0.18514 
Epoch [150/300] Training [5/62] Loss: 0.21165 
Epoch [150/300] Training [6/62] Loss: 0.16981 
Epoch [150/300] Training [7/62] Loss: 0.09722 
Epoch [150/300] Training [8/62] Loss: 0.06999 
Epoch [150/300] Training [9/62] Loss: 0.04830 
Epoch [150/300] Training [10/62] Loss: 0.06682 
Epoch [150/300] Training [11/62] Loss: 0.05826 
Epoch [150/300] Training [12/62] Loss: 0.06314 
Epoch [150/300] Training [13/62] Loss: 0.11030 
Epoch [150/300] Training [14/62] Loss: 0.30753 
Epoch [150/300] Training [15/62] Loss: 0.05250 
Epoch [150/300] Training [16/62] Loss: 0.06482 
Epoch [150/300] Training [17/62] Loss: 0.06450 
Epoch [150/300] Training [18/62] Loss: 0.16117 
Epoch [150/300] Training [19/62] Loss: 0.09553 
Epoch [150/300] Training [20/62] Loss: 0.05620 
Epoch [150/300] Training [21/62] Loss: 0.08645 
Epoch [150/300] Training [22/62] Loss: 0.11168 
Epoch [150/300] Training [23/62] Loss: 0.07210 
Epoch [150/300] Training [24/62] Loss: 0.18692 
Epoch [150/300] Training [25/62] Loss: 0.26607 
Epoch [150/300] Training [26/62] Loss: 0.05222 
Epoch [150/300] Training [27/62] Loss: 0.07190 
Epoch [150/300] Training [28/62] Loss: 0.05305 
Epoch [150/300] Training [29/62] Loss: 0.13611 
Epoch [150/300] Training [30/62] Loss: 0.18671 
Epoch [150/300] Training [31/62] Loss: 0.11552 
Epoch [150/300] Training [32/62] Loss: 0.08979 
Epoch [150/300] Training [33/62] Loss: 0.08680 
Epoch [150/300] Training [34/62] Loss: 0.13506 
Epoch [150/300] Training [35/62] Loss: 0.05315 
Epoch [150/300] Training [36/62] Loss: 0.10680 
Epoch [150/300] Training [37/62] Loss: 0.05909 
Epoch [150/300] Training [38/62] Loss: 0.12343 
Epoch [150/300] Training [39/62] Loss: 0.06431 
Epoch [150/300] Training [40/62] Loss: 0.21642 
Epoch [150/300] Training [41/62] Loss: 0.14311 
Epoch [150/300] Training [42/62] Loss: 0.07065 
Epoch [150/300] Training [43/62] Loss: 0.12885 
Epoch [150/300] Training [44/62] Loss: 0.08998 
Epoch [150/300] Training [45/62] Loss: 0.04962 
Epoch [150/300] Training [46/62] Loss: 0.15467 
Epoch [150/300] Training [47/62] Loss: 0.04717 
Epoch [150/300] Training [48/62] Loss: 0.12764 
Epoch [150/300] Training [49/62] Loss: 0.11034 
Epoch [150/300] Training [50/62] Loss: 0.19675 
Epoch [150/300] Training [51/62] Loss: 0.09765 
Epoch [150/300] Training [52/62] Loss: 0.06784 
Epoch [150/300] Training [53/62] Loss: 0.09941 
Epoch [150/300] Training [54/62] Loss: 0.11220 
Epoch [150/300] Training [55/62] Loss: 0.10449 
Epoch [150/300] Training [56/62] Loss: 0.08421 
Epoch [150/300] Training [57/62] Loss: 0.05570 
Epoch [150/300] Training [58/62] Loss: 0.11232 
Epoch [150/300] Training [59/62] Loss: 0.06484 
Epoch [150/300] Training [60/62] Loss: 0.16542 
Epoch [150/300] Training [61/62] Loss: 0.07942 
Epoch [150/300] Training [62/62] Loss: 0.06575 
Epoch [150/300] Training metric {'Train/mean dice_metric': 0.926703691482544, 'Train/mean miou_metric': 0.8778743743896484, 'Train/mean f1': 0.9394069910049438, 'Train/mean precision': 0.9399545788764954, 'Train/mean recall': 0.9388599991798401, 'Train/mean hd95_metric': 20.299240112304688}
Epoch [150/300] Validation [1/16] Loss: 0.66543  focal_loss 0.41839  dice_loss 0.24703 
Epoch [150/300] Validation [2/16] Loss: 0.53175  focal_loss 0.18731  dice_loss 0.34444 
Epoch [150/300] Validation [3/16] Loss: 0.63331  focal_loss 0.30166  dice_loss 0.33165 
Epoch [150/300] Validation [4/16] Loss: 0.40378  focal_loss 0.16217  dice_loss 0.24161 
Epoch [150/300] Validation [5/16] Loss: 0.31001  focal_loss 0.10022  dice_loss 0.20978 
Epoch [150/300] Validation [6/16] Loss: 0.30495  focal_loss 0.09981  dice_loss 0.20514 
Epoch [150/300] Validation [7/16] Loss: 0.38665  focal_loss 0.12871  dice_loss 0.25794 
Epoch [150/300] Validation [8/16] Loss: 0.51566  focal_loss 0.16177  dice_loss 0.35389 
Epoch [150/300] Validation [9/16] Loss: 0.28875  focal_loss 0.10495  dice_loss 0.18381 
Epoch [150/300] Validation [10/16] Loss: 0.56499  focal_loss 0.17367  dice_loss 0.39132 
Epoch [150/300] Validation [11/16] Loss: 0.20975  focal_loss 0.05088  dice_loss 0.15888 
Epoch [150/300] Validation [12/16] Loss: 0.42054  focal_loss 0.09324  dice_loss 0.32730 
Epoch [150/300] Validation [13/16] Loss: 0.34656  focal_loss 0.10313  dice_loss 0.24343 
Epoch [150/300] Validation [14/16] Loss: 0.61451  focal_loss 0.24816  dice_loss 0.36635 
Epoch [150/300] Validation [15/16] Loss: 0.11905  focal_loss 0.03524  dice_loss 0.08381 
Epoch [150/300] Validation [16/16] Loss: 0.19230  focal_loss 0.06549  dice_loss 0.12681 
Epoch [150/300] Validation metric {'Val/mean dice_metric': 0.8907055854797363, 'Val/mean miou_metric': 0.8321101665496826, 'Val/mean f1': 0.9103214740753174, 'Val/mean precision': 0.917754590511322, 'Val/mean recall': 0.9030078053474426, 'Val/mean hd95_metric': 27.86781883239746}
Cheakpoint...
Epoch [150/300] best acc:tensor([0.8947], device='cuda:0'), Now : mean acc: tensor([0.8907], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8907055854797363, 'Val/mean miou_metric': 0.8321101665496826, 'Val/mean f1': 0.9103214740753174, 'Val/mean precision': 0.917754590511322, 'Val/mean recall': 0.9030078053474426, 'Val/mean hd95_metric': 27.86781883239746}
Epoch [151/300] Training [1/62] Loss: 0.14645 
Epoch [151/300] Training [2/62] Loss: 0.07203 
Epoch [151/300] Training [3/62] Loss: 0.07293 
Epoch [151/300] Training [4/62] Loss: 0.10326 
Epoch [151/300] Training [5/62] Loss: 0.06913 
Epoch [151/300] Training [6/62] Loss: 0.09845 
Epoch [151/300] Training [7/62] Loss: 0.09715 
Epoch [151/300] Training [8/62] Loss: 0.05008 
Epoch [151/300] Training [9/62] Loss: 0.08307 
Epoch [151/300] Training [10/62] Loss: 0.11740 
Epoch [151/300] Training [11/62] Loss: 0.11909 
Epoch [151/300] Training [12/62] Loss: 0.13754 
Epoch [151/300] Training [13/62] Loss: 0.07590 
Epoch [151/300] Training [14/62] Loss: 0.10956 
Epoch [151/300] Training [15/62] Loss: 0.05569 
Epoch [151/300] Training [16/62] Loss: 0.08979 
Epoch [151/300] Training [17/62] Loss: 0.07063 
Epoch [151/300] Training [18/62] Loss: 0.06654 
Epoch [151/300] Training [19/62] Loss: 0.10633 
Epoch [151/300] Training [20/62] Loss: 0.09381 
Epoch [151/300] Training [21/62] Loss: 0.11868 
Epoch [151/300] Training [22/62] Loss: 0.13547 
Epoch [151/300] Training [23/62] Loss: 0.24266 
Epoch [151/300] Training [24/62] Loss: 0.12402 
Epoch [151/300] Training [25/62] Loss: 0.07627 
Epoch [151/300] Training [26/62] Loss: 0.19261 
Epoch [151/300] Training [27/62] Loss: 0.04235 
Epoch [151/300] Training [28/62] Loss: 0.08807 
Epoch [151/300] Training [29/62] Loss: 0.06714 
Epoch [151/300] Training [30/62] Loss: 0.05382 
Epoch [151/300] Training [31/62] Loss: 0.09965 
Epoch [151/300] Training [32/62] Loss: 0.13628 
Epoch [151/300] Training [33/62] Loss: 0.08948 
Epoch [151/300] Training [34/62] Loss: 0.06805 
Epoch [151/300] Training [35/62] Loss: 0.05655 
Epoch [151/300] Training [36/62] Loss: 0.16880 
Epoch [151/300] Training [37/62] Loss: 0.18322 
Epoch [151/300] Training [38/62] Loss: 0.08567 
Epoch [151/300] Training [39/62] Loss: 0.07775 
Epoch [151/300] Training [40/62] Loss: 0.07142 
Epoch [151/300] Training [41/62] Loss: 0.17829 
Epoch [151/300] Training [42/62] Loss: 0.09922 
Epoch [151/300] Training [43/62] Loss: 0.39368 
Epoch [151/300] Training [44/62] Loss: 0.08348 
Epoch [151/300] Training [45/62] Loss: 0.08179 
Epoch [151/300] Training [46/62] Loss: 0.07108 
Epoch [151/300] Training [47/62] Loss: 0.05743 
Epoch [151/300] Training [48/62] Loss: 0.08583 
Epoch [151/300] Training [49/62] Loss: 0.15842 
Epoch [151/300] Training [50/62] Loss: 0.10115 
Epoch [151/300] Training [51/62] Loss: 0.14826 
Epoch [151/300] Training [52/62] Loss: 0.07900 
Epoch [151/300] Training [53/62] Loss: 0.08451 
Epoch [151/300] Training [54/62] Loss: 0.08706 
Epoch [151/300] Training [55/62] Loss: 0.14658 
Epoch [151/300] Training [56/62] Loss: 0.13043 
Epoch [151/300] Training [57/62] Loss: 0.22973 
Epoch [151/300] Training [58/62] Loss: 0.14630 
Epoch [151/300] Training [59/62] Loss: 0.10401 
Epoch [151/300] Training [60/62] Loss: 0.06090 
Epoch [151/300] Training [61/62] Loss: 0.06632 
Epoch [151/300] Training [62/62] Loss: 0.08383 
Epoch [151/300] Training metric {'Train/mean dice_metric': 0.9298422932624817, 'Train/mean miou_metric': 0.8796647787094116, 'Train/mean f1': 0.9374220967292786, 'Train/mean precision': 0.940873384475708, 'Train/mean recall': 0.9339959621429443, 'Train/mean hd95_metric': 19.338027954101562}
Epoch [151/300] Validation [1/16] Loss: 0.70477  focal_loss 0.43323  dice_loss 0.27154 
Epoch [151/300] Validation [2/16] Loss: 0.46531  focal_loss 0.16452  dice_loss 0.30079 
Epoch [151/300] Validation [3/16] Loss: 0.59004  focal_loss 0.27786  dice_loss 0.31218 
Epoch [151/300] Validation [4/16] Loss: 0.31556  focal_loss 0.14127  dice_loss 0.17429 
Epoch [151/300] Validation [5/16] Loss: 0.34448  focal_loss 0.10294  dice_loss 0.24154 
Epoch [151/300] Validation [6/16] Loss: 0.33209  focal_loss 0.11956  dice_loss 0.21253 
Epoch [151/300] Validation [7/16] Loss: 0.37043  focal_loss 0.12602  dice_loss 0.24441 
Epoch [151/300] Validation [8/16] Loss: 0.48698  focal_loss 0.13488  dice_loss 0.35211 
Epoch [151/300] Validation [9/16] Loss: 0.38449  focal_loss 0.12753  dice_loss 0.25696 
Epoch [151/300] Validation [10/16] Loss: 0.54712  focal_loss 0.14985  dice_loss 0.39726 
Epoch [151/300] Validation [11/16] Loss: 0.22209  focal_loss 0.05184  dice_loss 0.17026 
Epoch [151/300] Validation [12/16] Loss: 0.38548  focal_loss 0.10125  dice_loss 0.28422 
Epoch [151/300] Validation [13/16] Loss: 0.28968  focal_loss 0.10179  dice_loss 0.18789 
Epoch [151/300] Validation [14/16] Loss: 0.57746  focal_loss 0.21514  dice_loss 0.36231 
Epoch [151/300] Validation [15/16] Loss: 0.16921  focal_loss 0.05191  dice_loss 0.11729 
Epoch [151/300] Validation [16/16] Loss: 0.15263  focal_loss 0.05498  dice_loss 0.09764 
Epoch [151/300] Validation metric {'Val/mean dice_metric': 0.89404296875, 'Val/mean miou_metric': 0.8352226614952087, 'Val/mean f1': 0.9089707136154175, 'Val/mean precision': 0.9268560409545898, 'Val/mean recall': 0.8917624950408936, 'Val/mean hd95_metric': 25.75164222717285}
Cheakpoint...
Epoch [151/300] best acc:tensor([0.8947], device='cuda:0'), Now : mean acc: tensor([0.8940], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.89404296875, 'Val/mean miou_metric': 0.8352226614952087, 'Val/mean f1': 0.9089707136154175, 'Val/mean precision': 0.9268560409545898, 'Val/mean recall': 0.8917624950408936, 'Val/mean hd95_metric': 25.75164222717285}
Epoch [152/300] Training [1/62] Loss: 0.11055 
Epoch [152/300] Training [2/62] Loss: 0.20115 
Epoch [152/300] Training [3/62] Loss: 0.12497 
Epoch [152/300] Training [4/62] Loss: 0.09500 
Epoch [152/300] Training [5/62] Loss: 0.13277 
Epoch [152/300] Training [6/62] Loss: 0.09206 
Epoch [152/300] Training [7/62] Loss: 0.05340 
Epoch [152/300] Training [8/62] Loss: 0.06773 
Epoch [152/300] Training [9/62] Loss: 0.14602 
Epoch [152/300] Training [10/62] Loss: 0.07208 
Epoch [152/300] Training [11/62] Loss: 0.05158 
Epoch [152/300] Training [12/62] Loss: 0.07361 
Epoch [152/300] Training [13/62] Loss: 0.16301 
Epoch [152/300] Training [14/62] Loss: 0.12949 
Epoch [152/300] Training [15/62] Loss: 0.17996 
Epoch [152/300] Training [16/62] Loss: 0.11863 
Epoch [152/300] Training [17/62] Loss: 0.06923 
Epoch [152/300] Training [18/62] Loss: 0.09399 
Epoch [152/300] Training [19/62] Loss: 0.08553 
Epoch [152/300] Training [20/62] Loss: 0.22300 
Epoch [152/300] Training [21/62] Loss: 0.06192 
Epoch [152/300] Training [22/62] Loss: 0.05672 
Epoch [152/300] Training [23/62] Loss: 0.10649 
Epoch [152/300] Training [24/62] Loss: 0.08574 
Epoch [152/300] Training [25/62] Loss: 0.12385 
Epoch [152/300] Training [26/62] Loss: 0.12553 
Epoch [152/300] Training [27/62] Loss: 0.06643 
Epoch [152/300] Training [28/62] Loss: 0.14845 
Epoch [152/300] Training [29/62] Loss: 0.43082 
Epoch [152/300] Training [30/62] Loss: 0.14166 
Epoch [152/300] Training [31/62] Loss: 0.09316 
Epoch [152/300] Training [32/62] Loss: 0.07837 
Epoch [152/300] Training [33/62] Loss: 0.08534 
Epoch [152/300] Training [34/62] Loss: 0.09287 
Epoch [152/300] Training [35/62] Loss: 0.07312 
Epoch [152/300] Training [36/62] Loss: 0.11849 
Epoch [152/300] Training [37/62] Loss: 0.08059 
Epoch [152/300] Training [38/62] Loss: 0.13280 
Epoch [152/300] Training [39/62] Loss: 0.13130 
Epoch [152/300] Training [40/62] Loss: 0.11124 
Epoch [152/300] Training [41/62] Loss: 0.09260 
Epoch [152/300] Training [42/62] Loss: 0.08523 
Epoch [152/300] Training [43/62] Loss: 0.19408 
Epoch [152/300] Training [44/62] Loss: 0.10858 
Epoch [152/300] Training [45/62] Loss: 0.06072 
Epoch [152/300] Training [46/62] Loss: 0.06531 
Epoch [152/300] Training [47/62] Loss: 0.10422 
Epoch [152/300] Training [48/62] Loss: 0.08252 
Epoch [152/300] Training [49/62] Loss: 0.07310 
Epoch [152/300] Training [50/62] Loss: 0.10871 
Epoch [152/300] Training [51/62] Loss: 0.04911 
Epoch [152/300] Training [52/62] Loss: 0.07252 
Epoch [152/300] Training [53/62] Loss: 0.09693 
Epoch [152/300] Training [54/62] Loss: 0.09216 
Epoch [152/300] Training [55/62] Loss: 0.06216 
Epoch [152/300] Training [56/62] Loss: 0.12383 
Epoch [152/300] Training [57/62] Loss: 0.05532 
Epoch [152/300] Training [58/62] Loss: 0.05626 
Epoch [152/300] Training [59/62] Loss: 0.08031 
Epoch [152/300] Training [60/62] Loss: 0.13715 
Epoch [152/300] Training [61/62] Loss: 0.05382 
Epoch [152/300] Training [62/62] Loss: 0.04569 
Epoch [152/300] Training metric {'Train/mean dice_metric': 0.9293248057365417, 'Train/mean miou_metric': 0.8797487616539001, 'Train/mean f1': 0.9383974075317383, 'Train/mean precision': 0.9403699636459351, 'Train/mean recall': 0.9364332556724548, 'Train/mean hd95_metric': 20.48062515258789}
Epoch [152/300] Validation [1/16] Loss: 0.55816  focal_loss 0.36784  dice_loss 0.19032 
Epoch [152/300] Validation [2/16] Loss: 0.46155  focal_loss 0.13325  dice_loss 0.32829 
Epoch [152/300] Validation [3/16] Loss: 0.67494  focal_loss 0.35451  dice_loss 0.32042 
Epoch [152/300] Validation [4/16] Loss: 0.38739  focal_loss 0.16597  dice_loss 0.22141 
Epoch [152/300] Validation [5/16] Loss: 0.50600  focal_loss 0.14447  dice_loss 0.36153 
Epoch [152/300] Validation [6/16] Loss: 0.34740  focal_loss 0.12201  dice_loss 0.22539 
Epoch [152/300] Validation [7/16] Loss: 0.21164  focal_loss 0.08402  dice_loss 0.12763 
Epoch [152/300] Validation [8/16] Loss: 0.48038  focal_loss 0.15410  dice_loss 0.32628 
Epoch [152/300] Validation [9/16] Loss: 0.23562  focal_loss 0.08688  dice_loss 0.14874 
Epoch [152/300] Validation [10/16] Loss: 0.66928  focal_loss 0.27302  dice_loss 0.39625 
Epoch [152/300] Validation [11/16] Loss: 0.18182  focal_loss 0.05282  dice_loss 0.12900 
Epoch [152/300] Validation [12/16] Loss: 0.39909  focal_loss 0.10867  dice_loss 0.29042 
Epoch [152/300] Validation [13/16] Loss: 0.32710  focal_loss 0.10339  dice_loss 0.22372 
Epoch [152/300] Validation [14/16] Loss: 0.53965  focal_loss 0.20330  dice_loss 0.33635 
Epoch [152/300] Validation [15/16] Loss: 0.13360  focal_loss 0.03908  dice_loss 0.09452 
Epoch [152/300] Validation [16/16] Loss: 0.18642  focal_loss 0.05172  dice_loss 0.13470 
Epoch [152/300] Validation metric {'Val/mean dice_metric': 0.895910918712616, 'Val/mean miou_metric': 0.8376181721687317, 'Val/mean f1': 0.9089301824569702, 'Val/mean precision': 0.9094990491867065, 'Val/mean recall': 0.9083619117736816, 'Val/mean hd95_metric': 28.901147842407227}
Cheakpoint...
Epoch [152/300] best acc:tensor([0.8959], device='cuda:0'), Now : mean acc: tensor([0.8959], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.895910918712616, 'Val/mean miou_metric': 0.8376181721687317, 'Val/mean f1': 0.9089301824569702, 'Val/mean precision': 0.9094990491867065, 'Val/mean recall': 0.9083619117736816, 'Val/mean hd95_metric': 28.901147842407227}
Epoch [153/300] Training [1/62] Loss: 0.05690 
Epoch [153/300] Training [2/62] Loss: 0.06220 
Epoch [153/300] Training [3/62] Loss: 0.19163 
Epoch [153/300] Training [4/62] Loss: 0.09543 
Epoch [153/300] Training [5/62] Loss: 0.08349 
Epoch [153/300] Training [6/62] Loss: 0.12137 
Epoch [153/300] Training [7/62] Loss: 0.16432 
Epoch [153/300] Training [8/62] Loss: 0.19341 
Epoch [153/300] Training [9/62] Loss: 0.11751 
Epoch [153/300] Training [10/62] Loss: 0.07924 
Epoch [153/300] Training [11/62] Loss: 0.15966 
Epoch [153/300] Training [12/62] Loss: 0.10203 
Epoch [153/300] Training [13/62] Loss: 0.17166 
Epoch [153/300] Training [14/62] Loss: 0.08607 
Epoch [153/300] Training [15/62] Loss: 0.12061 
Epoch [153/300] Training [16/62] Loss: 0.09038 
Epoch [153/300] Training [17/62] Loss: 0.08864 
Epoch [153/300] Training [18/62] Loss: 0.06524 
Epoch [153/300] Training [19/62] Loss: 0.13641 
Epoch [153/300] Training [20/62] Loss: 0.10986 
Epoch [153/300] Training [21/62] Loss: 0.08813 
Epoch [153/300] Training [22/62] Loss: 0.18210 
Epoch [153/300] Training [23/62] Loss: 0.27983 
Epoch [153/300] Training [24/62] Loss: 0.07421 
Epoch [153/300] Training [25/62] Loss: 0.09345 
Epoch [153/300] Training [26/62] Loss: 0.10761 
Epoch [153/300] Training [27/62] Loss: 0.30857 
Epoch [153/300] Training [28/62] Loss: 0.13465 
Epoch [153/300] Training [29/62] Loss: 0.11105 
Epoch [153/300] Training [30/62] Loss: 0.19552 
Epoch [153/300] Training [31/62] Loss: 0.11522 
Epoch [153/300] Training [32/62] Loss: 0.12987 
Epoch [153/300] Training [33/62] Loss: 0.07667 
Epoch [153/300] Training [34/62] Loss: 0.12087 
Epoch [153/300] Training [35/62] Loss: 0.09640 
Epoch [153/300] Training [36/62] Loss: 0.09301 
Epoch [153/300] Training [37/62] Loss: 0.11185 
Epoch [153/300] Training [38/62] Loss: 0.14320 
Epoch [153/300] Training [39/62] Loss: 0.08173 
Epoch [153/300] Training [40/62] Loss: 0.07130 
Epoch [153/300] Training [41/62] Loss: 0.09003 
Epoch [153/300] Training [42/62] Loss: 0.13389 
Epoch [153/300] Training [43/62] Loss: 0.12442 
Epoch [153/300] Training [44/62] Loss: 0.08454 
Epoch [153/300] Training [45/62] Loss: 0.06701 
Epoch [153/300] Training [46/62] Loss: 0.07141 
Epoch [153/300] Training [47/62] Loss: 0.06086 
Epoch [153/300] Training [48/62] Loss: 0.07125 
Epoch [153/300] Training [49/62] Loss: 0.12436 
Epoch [153/300] Training [50/62] Loss: 0.09116 
Epoch [153/300] Training [51/62] Loss: 0.05902 
Epoch [153/300] Training [52/62] Loss: 0.05313 
Epoch [153/300] Training [53/62] Loss: 0.10333 
Epoch [153/300] Training [54/62] Loss: 0.13293 
Epoch [153/300] Training [55/62] Loss: 0.08081 
Epoch [153/300] Training [56/62] Loss: 0.15273 
Epoch [153/300] Training [57/62] Loss: 0.08207 
Epoch [153/300] Training [58/62] Loss: 0.06440 
Epoch [153/300] Training [59/62] Loss: 0.06275 
Epoch [153/300] Training [60/62] Loss: 0.09779 
Epoch [153/300] Training [61/62] Loss: 0.04057 
Epoch [153/300] Training [62/62] Loss: 0.04100 
Epoch [153/300] Training metric {'Train/mean dice_metric': 0.9248048067092896, 'Train/mean miou_metric': 0.8751250505447388, 'Train/mean f1': 0.9349791407585144, 'Train/mean precision': 0.9336215257644653, 'Train/mean recall': 0.9363408088684082, 'Train/mean hd95_metric': 20.817947387695312}
Epoch [153/300] Validation [1/16] Loss: 0.59348  focal_loss 0.39181  dice_loss 0.20167 
Epoch [153/300] Validation [2/16] Loss: 0.48159  focal_loss 0.17482  dice_loss 0.30677 
Epoch [153/300] Validation [3/16] Loss: 0.58821  focal_loss 0.30847  dice_loss 0.27974 
Epoch [153/300] Validation [4/16] Loss: 0.35759  focal_loss 0.15341  dice_loss 0.20419 
Epoch [153/300] Validation [5/16] Loss: 0.42353  focal_loss 0.11004  dice_loss 0.31349 
Epoch [153/300] Validation [6/16] Loss: 0.28066  focal_loss 0.07296  dice_loss 0.20770 
Epoch [153/300] Validation [7/16] Loss: 0.16832  focal_loss 0.06168  dice_loss 0.10664 
Epoch [153/300] Validation [8/16] Loss: 0.51151  focal_loss 0.17360  dice_loss 0.33791 
Epoch [153/300] Validation [9/16] Loss: 0.23419  focal_loss 0.08256  dice_loss 0.15162 
Epoch [153/300] Validation [10/16] Loss: 0.40879  focal_loss 0.10643  dice_loss 0.30235 
Epoch [153/300] Validation [11/16] Loss: 0.19010  focal_loss 0.06656  dice_loss 0.12354 
Epoch [153/300] Validation [12/16] Loss: 0.37484  focal_loss 0.10291  dice_loss 0.27193 
Epoch [153/300] Validation [13/16] Loss: 0.26858  focal_loss 0.09337  dice_loss 0.17521 
Epoch [153/300] Validation [14/16] Loss: 0.56078  focal_loss 0.22497  dice_loss 0.33581 
Epoch [153/300] Validation [15/16] Loss: 0.18752  focal_loss 0.06166  dice_loss 0.12586 
Epoch [153/300] Validation [16/16] Loss: 0.12395  focal_loss 0.03943  dice_loss 0.08452 
Epoch [153/300] Validation metric {'Val/mean dice_metric': 0.8962434530258179, 'Val/mean miou_metric': 0.8385704159736633, 'Val/mean f1': 0.9112323522567749, 'Val/mean precision': 0.920813262462616, 'Val/mean recall': 0.9018486738204956, 'Val/mean hd95_metric': 28.419179916381836}
Cheakpoint...
Epoch [153/300] best acc:tensor([0.8962], device='cuda:0'), Now : mean acc: tensor([0.8962], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8962434530258179, 'Val/mean miou_metric': 0.8385704159736633, 'Val/mean f1': 0.9112323522567749, 'Val/mean precision': 0.920813262462616, 'Val/mean recall': 0.9018486738204956, 'Val/mean hd95_metric': 28.419179916381836}
Epoch [154/300] Training [1/62] Loss: 0.05236 
Epoch [154/300] Training [2/62] Loss: 0.19134 
Epoch [154/300] Training [3/62] Loss: 0.15052 
Epoch [154/300] Training [4/62] Loss: 0.08402 
Epoch [154/300] Training [5/62] Loss: 0.07388 
Epoch [154/300] Training [6/62] Loss: 0.17195 
Epoch [154/300] Training [7/62] Loss: 0.07212 
Epoch [154/300] Training [8/62] Loss: 0.05965 
Epoch [154/300] Training [9/62] Loss: 0.08239 
Epoch [154/300] Training [10/62] Loss: 0.04679 
Epoch [154/300] Training [11/62] Loss: 0.06166 
Epoch [154/300] Training [12/62] Loss: 0.23149 
Epoch [154/300] Training [13/62] Loss: 0.10955 
Epoch [154/300] Training [14/62] Loss: 0.07880 
Epoch [154/300] Training [15/62] Loss: 0.08146 
Epoch [154/300] Training [16/62] Loss: 0.17065 
Epoch [154/300] Training [17/62] Loss: 0.09430 
Epoch [154/300] Training [18/62] Loss: 0.06330 
Epoch [154/300] Training [19/62] Loss: 0.07464 
Epoch [154/300] Training [20/62] Loss: 0.16881 
Epoch [154/300] Training [21/62] Loss: 0.07694 
Epoch [154/300] Training [22/62] Loss: 0.10389 
Epoch [154/300] Training [23/62] Loss: 0.08344 
Epoch [154/300] Training [24/62] Loss: 0.05884 
Epoch [154/300] Training [25/62] Loss: 0.26925 
Epoch [154/300] Training [26/62] Loss: 0.14085 
Epoch [154/300] Training [27/62] Loss: 0.12330 
Epoch [154/300] Training [28/62] Loss: 0.10252 
Epoch [154/300] Training [29/62] Loss: 0.05920 
Epoch [154/300] Training [30/62] Loss: 0.06981 
Epoch [154/300] Training [31/62] Loss: 0.06134 
Epoch [154/300] Training [32/62] Loss: 0.06081 
Epoch [154/300] Training [33/62] Loss: 0.08216 
Epoch [154/300] Training [34/62] Loss: 0.07699 
Epoch [154/300] Training [35/62] Loss: 0.11153 
Epoch [154/300] Training [36/62] Loss: 0.10528 
Epoch [154/300] Training [37/62] Loss: 0.06694 
Epoch [154/300] Training [38/62] Loss: 0.04988 
Epoch [154/300] Training [39/62] Loss: 0.10190 
Epoch [154/300] Training [40/62] Loss: 0.05430 
Epoch [154/300] Training [41/62] Loss: 0.06299 
Epoch [154/300] Training [42/62] Loss: 0.13879 
Epoch [154/300] Training [43/62] Loss: 0.15311 
Epoch [154/300] Training [44/62] Loss: 0.17046 
Epoch [154/300] Training [45/62] Loss: 0.07347 
Epoch [154/300] Training [46/62] Loss: 0.07825 
Epoch [154/300] Training [47/62] Loss: 0.06073 
Epoch [154/300] Training [48/62] Loss: 0.05914 
Epoch [154/300] Training [49/62] Loss: 0.14710 
Epoch [154/300] Training [50/62] Loss: 0.14509 
Epoch [154/300] Training [51/62] Loss: 0.04983 
Epoch [154/300] Training [52/62] Loss: 0.05776 
Epoch [154/300] Training [53/62] Loss: 0.14744 
Epoch [154/300] Training [54/62] Loss: 0.07259 
Epoch [154/300] Training [55/62] Loss: 0.21156 
Epoch [154/300] Training [56/62] Loss: 0.07167 
Epoch [154/300] Training [57/62] Loss: 0.09054 
Epoch [154/300] Training [58/62] Loss: 0.11096 
Epoch [154/300] Training [59/62] Loss: 0.09433 
Epoch [154/300] Training [60/62] Loss: 0.27760 
Epoch [154/300] Training [61/62] Loss: 0.12591 
Epoch [154/300] Training [62/62] Loss: 0.39451 
Epoch [154/300] Training metric {'Train/mean dice_metric': 0.9292623400688171, 'Train/mean miou_metric': 0.8818590641021729, 'Train/mean f1': 0.9409847259521484, 'Train/mean precision': 0.9390407204627991, 'Train/mean recall': 0.9429366588592529, 'Train/mean hd95_metric': 19.933626174926758}
Epoch [154/300] Validation [1/16] Loss: 0.67855  focal_loss 0.43072  dice_loss 0.24783 
Epoch [154/300] Validation [2/16] Loss: 0.43442  focal_loss 0.14054  dice_loss 0.29388 
Epoch [154/300] Validation [3/16] Loss: 0.61476  focal_loss 0.33449  dice_loss 0.28027 
Epoch [154/300] Validation [4/16] Loss: 0.32984  focal_loss 0.14506  dice_loss 0.18478 
Epoch [154/300] Validation [5/16] Loss: 0.24696  focal_loss 0.08583  dice_loss 0.16113 
Epoch [154/300] Validation [6/16] Loss: 0.30068  focal_loss 0.08429  dice_loss 0.21639 
Epoch [154/300] Validation [7/16] Loss: 0.27302  focal_loss 0.08378  dice_loss 0.18924 
Epoch [154/300] Validation [8/16] Loss: 0.54692  focal_loss 0.13950  dice_loss 0.40742 
Epoch [154/300] Validation [9/16] Loss: 0.24817  focal_loss 0.09314  dice_loss 0.15503 
Epoch [154/300] Validation [10/16] Loss: 0.38978  focal_loss 0.09402  dice_loss 0.29576 
Epoch [154/300] Validation [11/16] Loss: 0.17234  focal_loss 0.05131  dice_loss 0.12103 
Epoch [154/300] Validation [12/16] Loss: 0.38107  focal_loss 0.10165  dice_loss 0.27942 
Epoch [154/300] Validation [13/16] Loss: 0.23285  focal_loss 0.08284  dice_loss 0.15001 
Epoch [154/300] Validation [14/16] Loss: 0.70368  focal_loss 0.25399  dice_loss 0.44969 
Epoch [154/300] Validation [15/16] Loss: 0.14571  focal_loss 0.04820  dice_loss 0.09751 
Epoch [154/300] Validation [16/16] Loss: 0.14683  focal_loss 0.03629  dice_loss 0.11054 
Epoch [154/300] Validation metric {'Val/mean dice_metric': 0.8984459638595581, 'Val/mean miou_metric': 0.8426418900489807, 'Val/mean f1': 0.9162675142288208, 'Val/mean precision': 0.927413284778595, 'Val/mean recall': 0.9053863286972046, 'Val/mean hd95_metric': 26.47472381591797}
Cheakpoint...
Epoch [154/300] best acc:tensor([0.8984], device='cuda:0'), Now : mean acc: tensor([0.8984], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8984459638595581, 'Val/mean miou_metric': 0.8426418900489807, 'Val/mean f1': 0.9162675142288208, 'Val/mean precision': 0.927413284778595, 'Val/mean recall': 0.9053863286972046, 'Val/mean hd95_metric': 26.47472381591797}
Epoch [155/300] Training [1/62] Loss: 0.12459 
Epoch [155/300] Training [2/62] Loss: 0.15791 
Epoch [155/300] Training [3/62] Loss: 0.06217 
Epoch [155/300] Training [4/62] Loss: 0.09706 
Epoch [155/300] Training [5/62] Loss: 0.07682 
Epoch [155/300] Training [6/62] Loss: 0.19102 
Epoch [155/300] Training [7/62] Loss: 0.13703 
Epoch [155/300] Training [8/62] Loss: 0.10837 
Epoch [155/300] Training [9/62] Loss: 0.12644 
Epoch [155/300] Training [10/62] Loss: 0.08216 
Epoch [155/300] Training [11/62] Loss: 0.08041 
Epoch [155/300] Training [12/62] Loss: 0.08124 
Epoch [155/300] Training [13/62] Loss: 0.12731 
Epoch [155/300] Training [14/62] Loss: 0.12175 
Epoch [155/300] Training [15/62] Loss: 0.10486 
Epoch [155/300] Training [16/62] Loss: 0.10162 
Epoch [155/300] Training [17/62] Loss: 0.08866 
Epoch [155/300] Training [18/62] Loss: 0.07038 
Epoch [155/300] Training [19/62] Loss: 0.06550 
Epoch [155/300] Training [20/62] Loss: 0.12303 
Epoch [155/300] Training [21/62] Loss: 0.19634 
Epoch [155/300] Training [22/62] Loss: 0.08467 
Epoch [155/300] Training [23/62] Loss: 0.11883 
Epoch [155/300] Training [24/62] Loss: 0.20746 
Epoch [155/300] Training [25/62] Loss: 0.10717 
Epoch [155/300] Training [26/62] Loss: 0.06259 
Epoch [155/300] Training [27/62] Loss: 0.12256 
Epoch [155/300] Training [28/62] Loss: 0.09383 
Epoch [155/300] Training [29/62] Loss: 0.12612 
Epoch [155/300] Training [30/62] Loss: 0.06366 
Epoch [155/300] Training [31/62] Loss: 0.06199 
Epoch [155/300] Training [32/62] Loss: 0.15793 
Epoch [155/300] Training [33/62] Loss: 0.10191 
Epoch [155/300] Training [34/62] Loss: 0.06278 
Epoch [155/300] Training [35/62] Loss: 0.10026 
Epoch [155/300] Training [36/62] Loss: 0.05600 
Epoch [155/300] Training [37/62] Loss: 0.07851 
Epoch [155/300] Training [38/62] Loss: 0.06997 
Epoch [155/300] Training [39/62] Loss: 0.11998 
Epoch [155/300] Training [40/62] Loss: 0.07406 
Epoch [155/300] Training [41/62] Loss: 0.05423 
Epoch [155/300] Training [42/62] Loss: 0.09632 
Epoch [155/300] Training [43/62] Loss: 0.15561 
Epoch [155/300] Training [44/62] Loss: 0.12859 
Epoch [155/300] Training [45/62] Loss: 0.14120 
Epoch [155/300] Training [46/62] Loss: 0.17958 
Epoch [155/300] Training [47/62] Loss: 0.13638 
Epoch [155/300] Training [48/62] Loss: 0.07223 
Epoch [155/300] Training [49/62] Loss: 0.11795 
Epoch [155/300] Training [50/62] Loss: 0.17252 
Epoch [155/300] Training [51/62] Loss: 0.14962 
Epoch [155/300] Training [52/62] Loss: 0.18510 
Epoch [155/300] Training [53/62] Loss: 0.11605 
Epoch [155/300] Training [54/62] Loss: 0.10958 
Epoch [155/300] Training [55/62] Loss: 0.09162 
Epoch [155/300] Training [56/62] Loss: 0.08077 
Epoch [155/300] Training [57/62] Loss: 0.06544 
Epoch [155/300] Training [58/62] Loss: 0.08548 
Epoch [155/300] Training [59/62] Loss: 0.06212 
Epoch [155/300] Training [60/62] Loss: 0.05236 
Epoch [155/300] Training [61/62] Loss: 0.15261 
Epoch [155/300] Training [62/62] Loss: 0.07039 
Epoch [155/300] Training metric {'Train/mean dice_metric': 0.9280349612236023, 'Train/mean miou_metric': 0.8769049644470215, 'Train/mean f1': 0.9350813031196594, 'Train/mean precision': 0.9386690855026245, 'Train/mean recall': 0.9315208196640015, 'Train/mean hd95_metric': 19.644611358642578}
Epoch [155/300] Validation [1/16] Loss: 0.75936  focal_loss 0.49420  dice_loss 0.26516 
Epoch [155/300] Validation [2/16] Loss: 0.56982  focal_loss 0.19891  dice_loss 0.37091 
Epoch [155/300] Validation [3/16] Loss: 0.80201  focal_loss 0.35266  dice_loss 0.44935 
Epoch [155/300] Validation [4/16] Loss: 0.48662  focal_loss 0.24039  dice_loss 0.24623 
Epoch [155/300] Validation [5/16] Loss: 0.41972  focal_loss 0.13423  dice_loss 0.28549 
Epoch [155/300] Validation [6/16] Loss: 0.36966  focal_loss 0.14432  dice_loss 0.22535 
Epoch [155/300] Validation [7/16] Loss: 0.44295  focal_loss 0.16511  dice_loss 0.27784 
Epoch [155/300] Validation [8/16] Loss: 0.64703  focal_loss 0.23420  dice_loss 0.41283 
Epoch [155/300] Validation [9/16] Loss: 0.39807  focal_loss 0.17865  dice_loss 0.21942 
Epoch [155/300] Validation [10/16] Loss: 0.57707  focal_loss 0.17052  dice_loss 0.40655 
Epoch [155/300] Validation [11/16] Loss: 0.23733  focal_loss 0.07904  dice_loss 0.15830 
Epoch [155/300] Validation [12/16] Loss: 0.50584  focal_loss 0.14609  dice_loss 0.35975 
Epoch [155/300] Validation [13/16] Loss: 0.37384  focal_loss 0.14079  dice_loss 0.23305 
Epoch [155/300] Validation [14/16] Loss: 0.71383  focal_loss 0.25975  dice_loss 0.45408 
Epoch [155/300] Validation [15/16] Loss: 0.15562  focal_loss 0.05062  dice_loss 0.10500 
Epoch [155/300] Validation [16/16] Loss: 0.15665  focal_loss 0.05226  dice_loss 0.10439 
Epoch [155/300] Validation metric {'Val/mean dice_metric': 0.8844770789146423, 'Val/mean miou_metric': 0.8253126740455627, 'Val/mean f1': 0.9053457379341125, 'Val/mean precision': 0.9270505309104919, 'Val/mean recall': 0.8846340775489807, 'Val/mean hd95_metric': 25.967453002929688}
Cheakpoint...
Epoch [155/300] best acc:tensor([0.8984], device='cuda:0'), Now : mean acc: tensor([0.8845], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8844770789146423, 'Val/mean miou_metric': 0.8253126740455627, 'Val/mean f1': 0.9053457379341125, 'Val/mean precision': 0.9270505309104919, 'Val/mean recall': 0.8846340775489807, 'Val/mean hd95_metric': 25.967453002929688}
Epoch [156/300] Training [1/62] Loss: 0.07358 
Epoch [156/300] Training [2/62] Loss: 0.14311 
Epoch [156/300] Training [3/62] Loss: 0.07475 
Epoch [156/300] Training [4/62] Loss: 0.09057 
Epoch [156/300] Training [5/62] Loss: 0.06410 
Epoch [156/300] Training [6/62] Loss: 0.19408 
Epoch [156/300] Training [7/62] Loss: 0.13121 
Epoch [156/300] Training [8/62] Loss: 0.18812 
Epoch [156/300] Training [9/62] Loss: 0.11997 
Epoch [156/300] Training [10/62] Loss: 0.07658 
Epoch [156/300] Training [11/62] Loss: 0.09691 
Epoch [156/300] Training [12/62] Loss: 0.07857 
Epoch [156/300] Training [13/62] Loss: 0.10817 
Epoch [156/300] Training [14/62] Loss: 0.08734 
Epoch [156/300] Training [15/62] Loss: 0.17044 
Epoch [156/300] Training [16/62] Loss: 0.05350 
Epoch [156/300] Training [17/62] Loss: 0.06353 
Epoch [156/300] Training [18/62] Loss: 0.04505 
Epoch [156/300] Training [19/62] Loss: 0.11858 
Epoch [156/300] Training [20/62] Loss: 0.11336 
Epoch [156/300] Training [21/62] Loss: 0.10743 
Epoch [156/300] Training [22/62] Loss: 0.09633 
Epoch [156/300] Training [23/62] Loss: 0.10810 
Epoch [156/300] Training [24/62] Loss: 0.06879 
Epoch [156/300] Training [25/62] Loss: 0.09071 
Epoch [156/300] Training [26/62] Loss: 0.08682 
Epoch [156/300] Training [27/62] Loss: 0.10437 
Epoch [156/300] Training [28/62] Loss: 0.08451 
Epoch [156/300] Training [29/62] Loss: 0.08624 
Epoch [156/300] Training [30/62] Loss: 0.11945 
Epoch [156/300] Training [31/62] Loss: 0.17159 
Epoch [156/300] Training [32/62] Loss: 0.06331 
Epoch [156/300] Training [33/62] Loss: 0.08506 
Epoch [156/300] Training [34/62] Loss: 0.09170 
Epoch [156/300] Training [35/62] Loss: 0.05635 
Epoch [156/300] Training [36/62] Loss: 0.16926 
Epoch [156/300] Training [37/62] Loss: 0.07920 
Epoch [156/300] Training [38/62] Loss: 0.18730 
Epoch [156/300] Training [39/62] Loss: 0.13199 
Epoch [156/300] Training [40/62] Loss: 0.05737 
Epoch [156/300] Training [41/62] Loss: 0.20713 
Epoch [156/300] Training [42/62] Loss: 0.06252 
Epoch [156/300] Training [43/62] Loss: 0.14691 
Epoch [156/300] Training [44/62] Loss: 0.08452 
Epoch [156/300] Training [45/62] Loss: 0.07940 
Epoch [156/300] Training [46/62] Loss: 0.10165 
Epoch [156/300] Training [47/62] Loss: 0.07432 
Epoch [156/300] Training [48/62] Loss: 0.09411 
Epoch [156/300] Training [49/62] Loss: 0.09366 
Epoch [156/300] Training [50/62] Loss: 0.05162 
Epoch [156/300] Training [51/62] Loss: 0.08316 
Epoch [156/300] Training [52/62] Loss: 0.07241 
Epoch [156/300] Training [53/62] Loss: 0.09064 
Epoch [156/300] Training [54/62] Loss: 0.07787 
Epoch [156/300] Training [55/62] Loss: 0.12812 
Epoch [156/300] Training [56/62] Loss: 0.07697 
Epoch [156/300] Training [57/62] Loss: 0.13295 
Epoch [156/300] Training [58/62] Loss: 0.08106 
Epoch [156/300] Training [59/62] Loss: 0.25693 
Epoch [156/300] Training [60/62] Loss: 0.18579 
Epoch [156/300] Training [61/62] Loss: 0.10353 
Epoch [156/300] Training [62/62] Loss: 0.04404 
Epoch [156/300] Training metric {'Train/mean dice_metric': 0.9296656847000122, 'Train/mean miou_metric': 0.8808895945549011, 'Train/mean f1': 0.9386219382286072, 'Train/mean precision': 0.9399026036262512, 'Train/mean recall': 0.9373446106910706, 'Train/mean hd95_metric': 18.363037109375}
Epoch [156/300] Validation [1/16] Loss: 0.62655  focal_loss 0.40939  dice_loss 0.21716 
Epoch [156/300] Validation [2/16] Loss: 0.50857  focal_loss 0.15728  dice_loss 0.35129 
Epoch [156/300] Validation [3/16] Loss: 0.53679  focal_loss 0.27267  dice_loss 0.26413 
Epoch [156/300] Validation [4/16] Loss: 0.29640  focal_loss 0.12939  dice_loss 0.16701 
Epoch [156/300] Validation [5/16] Loss: 0.42391  focal_loss 0.12776  dice_loss 0.29614 
Epoch [156/300] Validation [6/16] Loss: 0.28960  focal_loss 0.08184  dice_loss 0.20775 
Epoch [156/300] Validation [7/16] Loss: 0.17273  focal_loss 0.06068  dice_loss 0.11206 
Epoch [156/300] Validation [8/16] Loss: 0.48026  focal_loss 0.15921  dice_loss 0.32105 
Epoch [156/300] Validation [9/16] Loss: 0.32171  focal_loss 0.12741  dice_loss 0.19430 
Epoch [156/300] Validation [10/16] Loss: 0.46078  focal_loss 0.14727  dice_loss 0.31352 
Epoch [156/300] Validation [11/16] Loss: 0.15823  focal_loss 0.04862  dice_loss 0.10961 
Epoch [156/300] Validation [12/16] Loss: 0.39697  focal_loss 0.10441  dice_loss 0.29256 
Epoch [156/300] Validation [13/16] Loss: 0.28213  focal_loss 0.09008  dice_loss 0.19205 
Epoch [156/300] Validation [14/16] Loss: 0.52192  focal_loss 0.19562  dice_loss 0.32630 
Epoch [156/300] Validation [15/16] Loss: 0.14367  focal_loss 0.04162  dice_loss 0.10205 
Epoch [156/300] Validation [16/16] Loss: 0.17119  focal_loss 0.04648  dice_loss 0.12471 
Epoch [156/300] Validation metric {'Val/mean dice_metric': 0.899743378162384, 'Val/mean miou_metric': 0.8417118787765503, 'Val/mean f1': 0.9129434823989868, 'Val/mean precision': 0.9172496199607849, 'Val/mean recall': 0.9086778163909912, 'Val/mean hd95_metric': 25.81984519958496}
Cheakpoint...
Epoch [156/300] best acc:tensor([0.8997], device='cuda:0'), Now : mean acc: tensor([0.8997], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.899743378162384, 'Val/mean miou_metric': 0.8417118787765503, 'Val/mean f1': 0.9129434823989868, 'Val/mean precision': 0.9172496199607849, 'Val/mean recall': 0.9086778163909912, 'Val/mean hd95_metric': 25.81984519958496}
Epoch [157/300] Training [1/62] Loss: 0.06701 
Epoch [157/300] Training [2/62] Loss: 0.11419 
Epoch [157/300] Training [3/62] Loss: 0.16007 
Epoch [157/300] Training [4/62] Loss: 0.10684 
Epoch [157/300] Training [5/62] Loss: 0.05720 
Epoch [157/300] Training [6/62] Loss: 0.08356 
Epoch [157/300] Training [7/62] Loss: 0.09146 
Epoch [157/300] Training [8/62] Loss: 0.11475 
Epoch [157/300] Training [9/62] Loss: 0.14070 
Epoch [157/300] Training [10/62] Loss: 0.17391 
Epoch [157/300] Training [11/62] Loss: 0.06312 
Epoch [157/300] Training [12/62] Loss: 0.18392 
Epoch [157/300] Training [13/62] Loss: 0.07447 
Epoch [157/300] Training [14/62] Loss: 0.12783 
Epoch [157/300] Training [15/62] Loss: 0.05436 
Epoch [157/300] Training [16/62] Loss: 0.12993 
Epoch [157/300] Training [17/62] Loss: 0.13667 
Epoch [157/300] Training [18/62] Loss: 0.09357 
Epoch [157/300] Training [19/62] Loss: 0.08050 
Epoch [157/300] Training [20/62] Loss: 0.06710 
Epoch [157/300] Training [21/62] Loss: 0.04205 
Epoch [157/300] Training [22/62] Loss: 0.13763 
Epoch [157/300] Training [23/62] Loss: 0.26069 
Epoch [157/300] Training [24/62] Loss: 0.08206 
Epoch [157/300] Training [25/62] Loss: 0.06852 
Epoch [157/300] Training [26/62] Loss: 0.09958 
Epoch [157/300] Training [27/62] Loss: 0.09753 
Epoch [157/300] Training [28/62] Loss: 0.08827 
Epoch [157/300] Training [29/62] Loss: 0.05861 
Epoch [157/300] Training [30/62] Loss: 0.15644 
Epoch [157/300] Training [31/62] Loss: 0.07881 
Epoch [157/300] Training [32/62] Loss: 0.09098 
Epoch [157/300] Training [33/62] Loss: 0.06421 
Epoch [157/300] Training [34/62] Loss: 0.07197 
Epoch [157/300] Training [35/62] Loss: 0.04404 
Epoch [157/300] Training [36/62] Loss: 0.07202 
Epoch [157/300] Training [37/62] Loss: 0.07059 
Epoch [157/300] Training [38/62] Loss: 0.07862 
Epoch [157/300] Training [39/62] Loss: 0.06678 
Epoch [157/300] Training [40/62] Loss: 0.09837 
Epoch [157/300] Training [41/62] Loss: 0.14845 
Epoch [157/300] Training [42/62] Loss: 0.05337 
Epoch [157/300] Training [43/62] Loss: 0.11666 
Epoch [157/300] Training [44/62] Loss: 0.08728 
Epoch [157/300] Training [45/62] Loss: 0.06989 
Epoch [157/300] Training [46/62] Loss: 0.08555 
Epoch [157/300] Training [47/62] Loss: 0.21995 
Epoch [157/300] Training [48/62] Loss: 0.12972 
Epoch [157/300] Training [49/62] Loss: 0.05546 
Epoch [157/300] Training [50/62] Loss: 0.06893 
Epoch [157/300] Training [51/62] Loss: 0.06677 
Epoch [157/300] Training [52/62] Loss: 0.09276 
Epoch [157/300] Training [53/62] Loss: 0.11050 
Epoch [157/300] Training [54/62] Loss: 0.07807 
Epoch [157/300] Training [55/62] Loss: 0.11933 
Epoch [157/300] Training [56/62] Loss: 0.10933 
Epoch [157/300] Training [57/62] Loss: 0.05715 
Epoch [157/300] Training [58/62] Loss: 0.17774 
Epoch [157/300] Training [59/62] Loss: 0.09083 
Epoch [157/300] Training [60/62] Loss: 0.07569 
Epoch [157/300] Training [61/62] Loss: 0.06111 
Epoch [157/300] Training [62/62] Loss: 0.89336 
Epoch [157/300] Training metric {'Train/mean dice_metric': 0.9314442873001099, 'Train/mean miou_metric': 0.8835422992706299, 'Train/mean f1': 0.9422364234924316, 'Train/mean precision': 0.940481424331665, 'Train/mean recall': 0.9439979791641235, 'Train/mean hd95_metric': 19.13340187072754}
Epoch [157/300] Validation [1/16] Loss: 0.70973  focal_loss 0.44971  dice_loss 0.26002 
Epoch [157/300] Validation [2/16] Loss: 0.53381  focal_loss 0.16805  dice_loss 0.36577 
Epoch [157/300] Validation [3/16] Loss: 0.60450  focal_loss 0.30662  dice_loss 0.29788 
Epoch [157/300] Validation [4/16] Loss: 0.37100  focal_loss 0.15671  dice_loss 0.21429 
Epoch [157/300] Validation [5/16] Loss: 0.35959  focal_loss 0.12358  dice_loss 0.23601 
Epoch [157/300] Validation [6/16] Loss: 0.33140  focal_loss 0.09332  dice_loss 0.23808 
Epoch [157/300] Validation [7/16] Loss: 0.18947  focal_loss 0.06247  dice_loss 0.12701 
Epoch [157/300] Validation [8/16] Loss: 0.60278  focal_loss 0.15848  dice_loss 0.44430 
Epoch [157/300] Validation [9/16] Loss: 0.48028  focal_loss 0.19560  dice_loss 0.28468 
Epoch [157/300] Validation [10/16] Loss: 0.64541  focal_loss 0.22940  dice_loss 0.41601 
Epoch [157/300] Validation [11/16] Loss: 0.34504  focal_loss 0.11580  dice_loss 0.22924 
Epoch [157/300] Validation [12/16] Loss: 0.38160  focal_loss 0.09113  dice_loss 0.29047 
Epoch [157/300] Validation [13/16] Loss: 0.41749  focal_loss 0.15681  dice_loss 0.26069 
Epoch [157/300] Validation [14/16] Loss: 0.56526  focal_loss 0.19376  dice_loss 0.37150 
Epoch [157/300] Validation [15/16] Loss: 0.13356  focal_loss 0.03837  dice_loss 0.09519 
Epoch [157/300] Validation [16/16] Loss: 0.14654  focal_loss 0.03508  dice_loss 0.11145 
Epoch [157/300] Validation metric {'Val/mean dice_metric': 0.8923683166503906, 'Val/mean miou_metric': 0.8348632454872131, 'Val/mean f1': 0.9122779965400696, 'Val/mean precision': 0.9191561341285706, 'Val/mean recall': 0.9055020213127136, 'Val/mean hd95_metric': 27.834135055541992}
Cheakpoint...
Epoch [157/300] best acc:tensor([0.8997], device='cuda:0'), Now : mean acc: tensor([0.8924], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8923683166503906, 'Val/mean miou_metric': 0.8348632454872131, 'Val/mean f1': 0.9122779965400696, 'Val/mean precision': 0.9191561341285706, 'Val/mean recall': 0.9055020213127136, 'Val/mean hd95_metric': 27.834135055541992}
Epoch [158/300] Training [1/62] Loss: 0.14858 
Epoch [158/300] Training [2/62] Loss: 0.07134 
Epoch [158/300] Training [3/62] Loss: 0.06923 
Epoch [158/300] Training [4/62] Loss: 0.12025 
Epoch [158/300] Training [5/62] Loss: 0.20679 
Epoch [158/300] Training [6/62] Loss: 0.19158 
Epoch [158/300] Training [7/62] Loss: 0.09716 
Epoch [158/300] Training [8/62] Loss: 0.05830 
Epoch [158/300] Training [9/62] Loss: 0.09339 
Epoch [158/300] Training [10/62] Loss: 0.08031 
Epoch [158/300] Training [11/62] Loss: 0.07860 
Epoch [158/300] Training [12/62] Loss: 0.15287 
Epoch [158/300] Training [13/62] Loss: 0.16322 
Epoch [158/300] Training [14/62] Loss: 0.19562 
Epoch [158/300] Training [15/62] Loss: 0.07942 
Epoch [158/300] Training [16/62] Loss: 0.16335 
Epoch [158/300] Training [17/62] Loss: 0.04814 
Epoch [158/300] Training [18/62] Loss: 0.22924 
Epoch [158/300] Training [19/62] Loss: 0.14512 
Epoch [158/300] Training [20/62] Loss: 0.15875 
Epoch [158/300] Training [21/62] Loss: 0.09651 
Epoch [158/300] Training [22/62] Loss: 0.10787 
Epoch [158/300] Training [23/62] Loss: 0.21779 
Epoch [158/300] Training [24/62] Loss: 0.09335 
Epoch [158/300] Training [25/62] Loss: 0.10305 
Epoch [158/300] Training [26/62] Loss: 0.18116 
Epoch [158/300] Training [27/62] Loss: 0.07193 
Epoch [158/300] Training [28/62] Loss: 0.06269 
Epoch [158/300] Training [29/62] Loss: 0.08642 
Epoch [158/300] Training [30/62] Loss: 0.08831 
Epoch [158/300] Training [31/62] Loss: 0.06064 
Epoch [158/300] Training [32/62] Loss: 0.10549 
Epoch [158/300] Training [33/62] Loss: 0.11849 
Epoch [158/300] Training [34/62] Loss: 0.07826 
Epoch [158/300] Training [35/62] Loss: 0.06194 
Epoch [158/300] Training [36/62] Loss: 0.05546 
Epoch [158/300] Training [37/62] Loss: 0.11027 
Epoch [158/300] Training [38/62] Loss: 0.09947 
Epoch [158/300] Training [39/62] Loss: 0.21306 
Epoch [158/300] Training [40/62] Loss: 0.07679 
Epoch [158/300] Training [41/62] Loss: 0.06360 
Epoch [158/300] Training [42/62] Loss: 0.06670 
Epoch [158/300] Training [43/62] Loss: 0.15054 
Epoch [158/300] Training [44/62] Loss: 0.07302 
Epoch [158/300] Training [45/62] Loss: 0.09566 
Epoch [158/300] Training [46/62] Loss: 0.06770 
Epoch [158/300] Training [47/62] Loss: 0.08859 
Epoch [158/300] Training [48/62] Loss: 0.07747 
Epoch [158/300] Training [49/62] Loss: 0.07114 
Epoch [158/300] Training [50/62] Loss: 0.11328 
Epoch [158/300] Training [51/62] Loss: 0.19008 
Epoch [158/300] Training [52/62] Loss: 0.06836 
Epoch [158/300] Training [53/62] Loss: 0.12091 
Epoch [158/300] Training [54/62] Loss: 0.14184 
Epoch [158/300] Training [55/62] Loss: 0.06225 
Epoch [158/300] Training [56/62] Loss: 0.10753 
Epoch [158/300] Training [57/62] Loss: 0.05036 
Epoch [158/300] Training [58/62] Loss: 0.09334 
Epoch [158/300] Training [59/62] Loss: 0.14664 
Epoch [158/300] Training [60/62] Loss: 0.10594 
Epoch [158/300] Training [61/62] Loss: 0.10587 
Epoch [158/300] Training [62/62] Loss: 0.04700 
Epoch [158/300] Training metric {'Train/mean dice_metric': 0.9236482381820679, 'Train/mean miou_metric': 0.8748547434806824, 'Train/mean f1': 0.9404082894325256, 'Train/mean precision': 0.9402344822883606, 'Train/mean recall': 0.9405822157859802, 'Train/mean hd95_metric': 21.824737548828125}
Epoch [158/300] Validation [1/16] Loss: 0.62631  focal_loss 0.40427  dice_loss 0.22204 
Epoch [158/300] Validation [2/16] Loss: 0.53590  focal_loss 0.18650  dice_loss 0.34940 
Epoch [158/300] Validation [3/16] Loss: 0.60049  focal_loss 0.27962  dice_loss 0.32088 
Epoch [158/300] Validation [4/16] Loss: 0.32926  focal_loss 0.13308  dice_loss 0.19617 
Epoch [158/300] Validation [5/16] Loss: 0.33213  focal_loss 0.09715  dice_loss 0.23498 
Epoch [158/300] Validation [6/16] Loss: 0.33480  focal_loss 0.08438  dice_loss 0.25042 
Epoch [158/300] Validation [7/16] Loss: 0.23453  focal_loss 0.07460  dice_loss 0.15993 
Epoch [158/300] Validation [8/16] Loss: 0.50829  focal_loss 0.14612  dice_loss 0.36218 
Epoch [158/300] Validation [9/16] Loss: 0.23366  focal_loss 0.07304  dice_loss 0.16062 
Epoch [158/300] Validation [10/16] Loss: 0.53113  focal_loss 0.15862  dice_loss 0.37251 
Epoch [158/300] Validation [11/16] Loss: 0.19630  focal_loss 0.05689  dice_loss 0.13941 
Epoch [158/300] Validation [12/16] Loss: 0.40340  focal_loss 0.08763  dice_loss 0.31577 
Epoch [158/300] Validation [13/16] Loss: 0.21152  focal_loss 0.06077  dice_loss 0.15075 
Epoch [158/300] Validation [14/16] Loss: 0.65511  focal_loss 0.27516  dice_loss 0.37995 
Epoch [158/300] Validation [15/16] Loss: 0.13375  focal_loss 0.03829  dice_loss 0.09546 
Epoch [158/300] Validation [16/16] Loss: 0.15873  focal_loss 0.04369  dice_loss 0.11504 
Epoch [158/300] Validation metric {'Val/mean dice_metric': 0.8914576768875122, 'Val/mean miou_metric': 0.8334086537361145, 'Val/mean f1': 0.9150927066802979, 'Val/mean precision': 0.9275767207145691, 'Val/mean recall': 0.9029402732849121, 'Val/mean hd95_metric': 28.71808433532715}
Cheakpoint...
Epoch [158/300] best acc:tensor([0.8997], device='cuda:0'), Now : mean acc: tensor([0.8915], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8914576768875122, 'Val/mean miou_metric': 0.8334086537361145, 'Val/mean f1': 0.9150927066802979, 'Val/mean precision': 0.9275767207145691, 'Val/mean recall': 0.9029402732849121, 'Val/mean hd95_metric': 28.71808433532715}
Epoch [159/300] Training [1/62] Loss: 0.06864 
Epoch [159/300] Training [2/62] Loss: 0.08813 
Epoch [159/300] Training [3/62] Loss: 0.16544 
Epoch [159/300] Training [4/62] Loss: 0.08314 
Epoch [159/300] Training [5/62] Loss: 0.07495 
Epoch [159/300] Training [6/62] Loss: 0.06859 
Epoch [159/300] Training [7/62] Loss: 0.09048 
Epoch [159/300] Training [8/62] Loss: 0.07069 
Epoch [159/300] Training [9/62] Loss: 0.06080 
Epoch [159/300] Training [10/62] Loss: 0.08787 
Epoch [159/300] Training [11/62] Loss: 0.12877 
Epoch [159/300] Training [12/62] Loss: 0.06938 
Epoch [159/300] Training [13/62] Loss: 0.09818 
Epoch [159/300] Training [14/62] Loss: 0.10445 
Epoch [159/300] Training [15/62] Loss: 0.07841 
Epoch [159/300] Training [16/62] Loss: 0.09655 
Epoch [159/300] Training [17/62] Loss: 0.12863 
Epoch [159/300] Training [18/62] Loss: 0.07328 
Epoch [159/300] Training [19/62] Loss: 0.06361 
Epoch [159/300] Training [20/62] Loss: 0.10788 
Epoch [159/300] Training [21/62] Loss: 0.19590 
Epoch [159/300] Training [22/62] Loss: 0.07264 
Epoch [159/300] Training [23/62] Loss: 0.11004 
Epoch [159/300] Training [24/62] Loss: 0.05044 
Epoch [159/300] Training [25/62] Loss: 0.07784 
Epoch [159/300] Training [26/62] Loss: 0.07435 
Epoch [159/300] Training [27/62] Loss: 0.11714 
Epoch [159/300] Training [28/62] Loss: 0.06063 
Epoch [159/300] Training [29/62] Loss: 0.11969 
Epoch [159/300] Training [30/62] Loss: 0.18701 
Epoch [159/300] Training [31/62] Loss: 0.08781 
Epoch [159/300] Training [32/62] Loss: 0.15457 
Epoch [159/300] Training [33/62] Loss: 0.10917 
Epoch [159/300] Training [34/62] Loss: 0.04638 
Epoch [159/300] Training [35/62] Loss: 0.12365 
Epoch [159/300] Training [36/62] Loss: 0.06485 
Epoch [159/300] Training [37/62] Loss: 0.22905 
Epoch [159/300] Training [38/62] Loss: 0.10802 
Epoch [159/300] Training [39/62] Loss: 0.07504 
Epoch [159/300] Training [40/62] Loss: 0.07518 
Epoch [159/300] Training [41/62] Loss: 0.05450 
Epoch [159/300] Training [42/62] Loss: 0.10525 
Epoch [159/300] Training [43/62] Loss: 0.10112 
Epoch [159/300] Training [44/62] Loss: 0.06945 
Epoch [159/300] Training [45/62] Loss: 0.12910 
Epoch [159/300] Training [46/62] Loss: 0.16269 
Epoch [159/300] Training [47/62] Loss: 0.07601 
Epoch [159/300] Training [48/62] Loss: 0.06249 
Epoch [159/300] Training [49/62] Loss: 0.10187 
Epoch [159/300] Training [50/62] Loss: 0.07670 
Epoch [159/300] Training [51/62] Loss: 0.05371 
Epoch [159/300] Training [52/62] Loss: 0.05630 
Epoch [159/300] Training [53/62] Loss: 0.12723 
Epoch [159/300] Training [54/62] Loss: 0.14293 
Epoch [159/300] Training [55/62] Loss: 0.09275 
Epoch [159/300] Training [56/62] Loss: 0.14005 
Epoch [159/300] Training [57/62] Loss: 0.07177 
Epoch [159/300] Training [58/62] Loss: 0.06874 
Epoch [159/300] Training [59/62] Loss: 0.06477 
Epoch [159/300] Training [60/62] Loss: 0.12418 
Epoch [159/300] Training [61/62] Loss: 0.10469 
Epoch [159/300] Training [62/62] Loss: 0.04252 
Epoch [159/300] Training metric {'Train/mean dice_metric': 0.9340860843658447, 'Train/mean miou_metric': 0.8882311582565308, 'Train/mean f1': 0.9445351362228394, 'Train/mean precision': 0.943966269493103, 'Train/mean recall': 0.9451046586036682, 'Train/mean hd95_metric': 19.56380271911621}
Epoch [159/300] Validation [1/16] Loss: 0.65518  focal_loss 0.41487  dice_loss 0.24032 
Epoch [159/300] Validation [2/16] Loss: 0.55595  focal_loss 0.19361  dice_loss 0.36234 
Epoch [159/300] Validation [3/16] Loss: 0.51339  focal_loss 0.25695  dice_loss 0.25644 
Epoch [159/300] Validation [4/16] Loss: 0.28155  focal_loss 0.10896  dice_loss 0.17258 
Epoch [159/300] Validation [5/16] Loss: 0.37140  focal_loss 0.12896  dice_loss 0.24244 
Epoch [159/300] Validation [6/16] Loss: 0.33725  focal_loss 0.10085  dice_loss 0.23640 
Epoch [159/300] Validation [7/16] Loss: 0.23031  focal_loss 0.09660  dice_loss 0.13371 
Epoch [159/300] Validation [8/16] Loss: 0.44112  focal_loss 0.14171  dice_loss 0.29941 
Epoch [159/300] Validation [9/16] Loss: 0.22521  focal_loss 0.09150  dice_loss 0.13371 
Epoch [159/300] Validation [10/16] Loss: 0.51324  focal_loss 0.15588  dice_loss 0.35735 
Epoch [159/300] Validation [11/16] Loss: 0.19597  focal_loss 0.05788  dice_loss 0.13809 
Epoch [159/300] Validation [12/16] Loss: 0.42015  focal_loss 0.10980  dice_loss 0.31035 
Epoch [159/300] Validation [13/16] Loss: 0.27209  focal_loss 0.08496  dice_loss 0.18713 
Epoch [159/300] Validation [14/16] Loss: 0.38578  focal_loss 0.13972  dice_loss 0.24606 
Epoch [159/300] Validation [15/16] Loss: 0.13682  focal_loss 0.04176  dice_loss 0.09505 
Epoch [159/300] Validation [16/16] Loss: 0.11772  focal_loss 0.03152  dice_loss 0.08620 
Epoch [159/300] Validation metric {'Val/mean dice_metric': 0.9036971926689148, 'Val/mean miou_metric': 0.8491573929786682, 'Val/mean f1': 0.9201605319976807, 'Val/mean precision': 0.9247109293937683, 'Val/mean recall': 0.9156546592712402, 'Val/mean hd95_metric': 27.428504943847656}
Cheakpoint...
Epoch [159/300] best acc:tensor([0.9037], device='cuda:0'), Now : mean acc: tensor([0.9037], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9036971926689148, 'Val/mean miou_metric': 0.8491573929786682, 'Val/mean f1': 0.9201605319976807, 'Val/mean precision': 0.9247109293937683, 'Val/mean recall': 0.9156546592712402, 'Val/mean hd95_metric': 27.428504943847656}
Epoch [160/300] Training [1/62] Loss: 0.10848 
Epoch [160/300] Training [2/62] Loss: 0.06555 
Epoch [160/300] Training [3/62] Loss: 0.29526 
Epoch [160/300] Training [4/62] Loss: 0.09346 
Epoch [160/300] Training [5/62] Loss: 0.05679 
Epoch [160/300] Training [6/62] Loss: 0.11023 
Epoch [160/300] Training [7/62] Loss: 0.10052 
Epoch [160/300] Training [8/62] Loss: 0.11151 
Epoch [160/300] Training [9/62] Loss: 0.13155 
Epoch [160/300] Training [10/62] Loss: 0.13137 
Epoch [160/300] Training [11/62] Loss: 0.17752 
Epoch [160/300] Training [12/62] Loss: 0.06329 
Epoch [160/300] Training [13/62] Loss: 0.06662 
Epoch [160/300] Training [14/62] Loss: 0.07506 
Epoch [160/300] Training [15/62] Loss: 0.06751 
Epoch [160/300] Training [16/62] Loss: 0.06275 
Epoch [160/300] Training [17/62] Loss: 0.07521 
Epoch [160/300] Training [18/62] Loss: 0.34485 
Epoch [160/300] Training [19/62] Loss: 0.07699 
Epoch [160/300] Training [20/62] Loss: 0.07492 
Epoch [160/300] Training [21/62] Loss: 0.07515 
Epoch [160/300] Training [22/62] Loss: 0.13367 
Epoch [160/300] Training [23/62] Loss: 0.16440 
Epoch [160/300] Training [24/62] Loss: 0.19295 
Epoch [160/300] Training [25/62] Loss: 0.05601 
Epoch [160/300] Training [26/62] Loss: 0.06566 
Epoch [160/300] Training [27/62] Loss: 0.06042 
Epoch [160/300] Training [28/62] Loss: 0.06431 
Epoch [160/300] Training [29/62] Loss: 0.12822 
Epoch [160/300] Training [30/62] Loss: 0.05295 
Epoch [160/300] Training [31/62] Loss: 0.08369 
Epoch [160/300] Training [32/62] Loss: 0.05445 
Epoch [160/300] Training [33/62] Loss: 0.07331 
Epoch [160/300] Training [34/62] Loss: 0.11763 
Epoch [160/300] Training [35/62] Loss: 0.08421 
Epoch [160/300] Training [36/62] Loss: 0.12970 
Epoch [160/300] Training [37/62] Loss: 0.10091 
Epoch [160/300] Training [38/62] Loss: 0.07153 
Epoch [160/300] Training [39/62] Loss: 0.05796 
Epoch [160/300] Training [40/62] Loss: 0.05391 
Epoch [160/300] Training [41/62] Loss: 0.09429 
Epoch [160/300] Training [42/62] Loss: 0.13388 
Epoch [160/300] Training [43/62] Loss: 0.05034 
Epoch [160/300] Training [44/62] Loss: 0.06216 
Epoch [160/300] Training [45/62] Loss: 0.05336 
Epoch [160/300] Training [46/62] Loss: 0.08171 
Epoch [160/300] Training [47/62] Loss: 0.09794 
Epoch [160/300] Training [48/62] Loss: 0.05686 
Epoch [160/300] Training [49/62] Loss: 0.05481 
Epoch [160/300] Training [50/62] Loss: 0.15753 
Epoch [160/300] Training [51/62] Loss: 0.10157 
Epoch [160/300] Training [52/62] Loss: 0.11353 
Epoch [160/300] Training [53/62] Loss: 0.09189 
Epoch [160/300] Training [54/62] Loss: 0.18640 
Epoch [160/300] Training [55/62] Loss: 0.22041 
Epoch [160/300] Training [56/62] Loss: 0.08463 
Epoch [160/300] Training [57/62] Loss: 0.20694 
Epoch [160/300] Training [58/62] Loss: 0.09195 
Epoch [160/300] Training [59/62] Loss: 0.17756 
Epoch [160/300] Training [60/62] Loss: 0.08073 
Epoch [160/300] Training [61/62] Loss: 0.09962 
Epoch [160/300] Training [62/62] Loss: 0.10193 
Epoch [160/300] Training metric {'Train/mean dice_metric': 0.9270087480545044, 'Train/mean miou_metric': 0.8795982599258423, 'Train/mean f1': 0.9417974948883057, 'Train/mean precision': 0.9398872256278992, 'Train/mean recall': 0.9437155723571777, 'Train/mean hd95_metric': 19.878591537475586}
Epoch [160/300] Validation [1/16] Loss: 0.71413  focal_loss 0.47073  dice_loss 0.24340 
Epoch [160/300] Validation [2/16] Loss: 0.46427  focal_loss 0.17692  dice_loss 0.28735 
Epoch [160/300] Validation [3/16] Loss: 0.73136  focal_loss 0.36820  dice_loss 0.36315 
Epoch [160/300] Validation [4/16] Loss: 0.26634  focal_loss 0.11725  dice_loss 0.14909 
Epoch [160/300] Validation [5/16] Loss: 0.28208  focal_loss 0.07775  dice_loss 0.20433 
Epoch [160/300] Validation [6/16] Loss: 0.32518  focal_loss 0.09146  dice_loss 0.23372 
Epoch [160/300] Validation [7/16] Loss: 0.20114  focal_loss 0.07983  dice_loss 0.12131 
Epoch [160/300] Validation [8/16] Loss: 0.55075  focal_loss 0.18588  dice_loss 0.36487 
Epoch [160/300] Validation [9/16] Loss: 0.22308  focal_loss 0.08232  dice_loss 0.14076 
Epoch [160/300] Validation [10/16] Loss: 0.48795  focal_loss 0.14317  dice_loss 0.34478 
Epoch [160/300] Validation [11/16] Loss: 0.23235  focal_loss 0.07610  dice_loss 0.15625 
Epoch [160/300] Validation [12/16] Loss: 0.53857  focal_loss 0.12493  dice_loss 0.41364 
Epoch [160/300] Validation [13/16] Loss: 0.24123  focal_loss 0.09388  dice_loss 0.14735 
Epoch [160/300] Validation [14/16] Loss: 0.66298  focal_loss 0.27250  dice_loss 0.39048 
Epoch [160/300] Validation [15/16] Loss: 0.17442  focal_loss 0.05575  dice_loss 0.11868 
Epoch [160/300] Validation [16/16] Loss: 0.18651  focal_loss 0.05644  dice_loss 0.13007 
Epoch [160/300] Validation metric {'Val/mean dice_metric': 0.8943535089492798, 'Val/mean miou_metric': 0.8385716080665588, 'Val/mean f1': 0.9159009456634521, 'Val/mean precision': 0.9280246496200562, 'Val/mean recall': 0.9040899872779846, 'Val/mean hd95_metric': 26.730308532714844}
Cheakpoint...
Epoch [160/300] best acc:tensor([0.9037], device='cuda:0'), Now : mean acc: tensor([0.8944], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8943535089492798, 'Val/mean miou_metric': 0.8385716080665588, 'Val/mean f1': 0.9159009456634521, 'Val/mean precision': 0.9280246496200562, 'Val/mean recall': 0.9040899872779846, 'Val/mean hd95_metric': 26.730308532714844}
Epoch [161/300] Training [1/62] Loss: 0.11936 
Epoch [161/300] Training [2/62] Loss: 0.15274 
Epoch [161/300] Training [3/62] Loss: 0.08368 
Epoch [161/300] Training [4/62] Loss: 0.06943 
Epoch [161/300] Training [5/62] Loss: 0.05941 
Epoch [161/300] Training [6/62] Loss: 0.05385 
Epoch [161/300] Training [7/62] Loss: 0.07357 
Epoch [161/300] Training [8/62] Loss: 0.10234 
Epoch [161/300] Training [9/62] Loss: 0.12604 
Epoch [161/300] Training [10/62] Loss: 0.07805 
Epoch [161/300] Training [11/62] Loss: 0.08907 
Epoch [161/300] Training [12/62] Loss: 0.22084 
Epoch [161/300] Training [13/62] Loss: 0.09692 
Epoch [161/300] Training [14/62] Loss: 0.05914 
Epoch [161/300] Training [15/62] Loss: 0.07517 
Epoch [161/300] Training [16/62] Loss: 0.06723 
Epoch [161/300] Training [17/62] Loss: 0.08269 
Epoch [161/300] Training [18/62] Loss: 0.11073 
Epoch [161/300] Training [19/62] Loss: 0.05112 
Epoch [161/300] Training [20/62] Loss: 0.09633 
Epoch [161/300] Training [21/62] Loss: 0.09262 
Epoch [161/300] Training [22/62] Loss: 0.07603 
Epoch [161/300] Training [23/62] Loss: 0.12905 
Epoch [161/300] Training [24/62] Loss: 0.12702 
Epoch [161/300] Training [25/62] Loss: 0.15646 
Epoch [161/300] Training [26/62] Loss: 0.06264 
Epoch [161/300] Training [27/62] Loss: 0.06765 
Epoch [161/300] Training [28/62] Loss: 0.05509 
Epoch [161/300] Training [29/62] Loss: 0.06089 
Epoch [161/300] Training [30/62] Loss: 0.06559 
Epoch [161/300] Training [31/62] Loss: 0.06207 
Epoch [161/300] Training [32/62] Loss: 0.17450 
Epoch [161/300] Training [33/62] Loss: 0.10194 
Epoch [161/300] Training [34/62] Loss: 0.05161 
Epoch [161/300] Training [35/62] Loss: 0.05491 
Epoch [161/300] Training [36/62] Loss: 0.06396 
Epoch [161/300] Training [37/62] Loss: 0.06487 
Epoch [161/300] Training [38/62] Loss: 0.11721 
Epoch [161/300] Training [39/62] Loss: 0.15255 
Epoch [161/300] Training [40/62] Loss: 0.16496 
Epoch [161/300] Training [41/62] Loss: 0.07911 
Epoch [161/300] Training [42/62] Loss: 0.08326 
Epoch [161/300] Training [43/62] Loss: 0.11455 
Epoch [161/300] Training [44/62] Loss: 0.09815 
Epoch [161/300] Training [45/62] Loss: 0.11436 
Epoch [161/300] Training [46/62] Loss: 0.04841 
Epoch [161/300] Training [47/62] Loss: 0.08371 
Epoch [161/300] Training [48/62] Loss: 0.29393 
Epoch [161/300] Training [49/62] Loss: 0.09521 
Epoch [161/300] Training [50/62] Loss: 0.09330 
Epoch [161/300] Training [51/62] Loss: 0.06206 
Epoch [161/300] Training [52/62] Loss: 0.18780 
Epoch [161/300] Training [53/62] Loss: 0.08673 
Epoch [161/300] Training [54/62] Loss: 0.06708 
Epoch [161/300] Training [55/62] Loss: 0.06975 
Epoch [161/300] Training [56/62] Loss: 0.09045 
Epoch [161/300] Training [57/62] Loss: 0.14576 
Epoch [161/300] Training [58/62] Loss: 0.09412 
Epoch [161/300] Training [59/62] Loss: 0.06527 
Epoch [161/300] Training [60/62] Loss: 0.14264 
Epoch [161/300] Training [61/62] Loss: 0.06657 
Epoch [161/300] Training [62/62] Loss: 0.04305 
Epoch [161/300] Training metric {'Train/mean dice_metric': 0.9334620833396912, 'Train/mean miou_metric': 0.8865614533424377, 'Train/mean f1': 0.944050669670105, 'Train/mean precision': 0.9460076689720154, 'Train/mean recall': 0.9421018362045288, 'Train/mean hd95_metric': 17.413970947265625}
Epoch [161/300] Validation [1/16] Loss: 0.59792  focal_loss 0.32367  dice_loss 0.27425 
Epoch [161/300] Validation [2/16] Loss: 0.46255  focal_loss 0.16833  dice_loss 0.29422 
Epoch [161/300] Validation [3/16] Loss: 0.53912  focal_loss 0.25127  dice_loss 0.28785 
Epoch [161/300] Validation [4/16] Loss: 0.31894  focal_loss 0.13410  dice_loss 0.18484 
Epoch [161/300] Validation [5/16] Loss: 0.36552  focal_loss 0.11334  dice_loss 0.25218 
Epoch [161/300] Validation [6/16] Loss: 0.34740  focal_loss 0.11266  dice_loss 0.23473 
Epoch [161/300] Validation [7/16] Loss: 0.33857  focal_loss 0.09635  dice_loss 0.24221 
Epoch [161/300] Validation [8/16] Loss: 0.55568  focal_loss 0.16183  dice_loss 0.39384 
Epoch [161/300] Validation [9/16] Loss: 0.28748  focal_loss 0.08865  dice_loss 0.19883 
Epoch [161/300] Validation [10/16] Loss: 0.57796  focal_loss 0.15675  dice_loss 0.42121 
Epoch [161/300] Validation [11/16] Loss: 0.20888  focal_loss 0.04711  dice_loss 0.16177 
Epoch [161/300] Validation [12/16] Loss: 0.41772  focal_loss 0.08434  dice_loss 0.33338 
Epoch [161/300] Validation [13/16] Loss: 0.26931  focal_loss 0.06918  dice_loss 0.20013 
Epoch [161/300] Validation [14/16] Loss: 0.71931  focal_loss 0.27657  dice_loss 0.44274 
Epoch [161/300] Validation [15/16] Loss: 0.14460  focal_loss 0.04205  dice_loss 0.10255 
Epoch [161/300] Validation [16/16] Loss: 0.34889  focal_loss 0.12560  dice_loss 0.22329 
Epoch [161/300] Validation metric {'Val/mean dice_metric': 0.8953289985656738, 'Val/mean miou_metric': 0.837874174118042, 'Val/mean f1': 0.9134579300880432, 'Val/mean precision': 0.9230082631111145, 'Val/mean recall': 0.9041032195091248, 'Val/mean hd95_metric': 26.679428100585938}
Cheakpoint...
Epoch [161/300] best acc:tensor([0.9037], device='cuda:0'), Now : mean acc: tensor([0.8953], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8953289985656738, 'Val/mean miou_metric': 0.837874174118042, 'Val/mean f1': 0.9134579300880432, 'Val/mean precision': 0.9230082631111145, 'Val/mean recall': 0.9041032195091248, 'Val/mean hd95_metric': 26.679428100585938}
Epoch [162/300] Training [1/62] Loss: 0.07289 
Epoch [162/300] Training [2/62] Loss: 0.05961 
Epoch [162/300] Training [3/62] Loss: 0.17152 
Epoch [162/300] Training [4/62] Loss: 0.07044 
Epoch [162/300] Training [5/62] Loss: 0.07399 
Epoch [162/300] Training [6/62] Loss: 0.08126 
Epoch [162/300] Training [7/62] Loss: 0.06692 
Epoch [162/300] Training [8/62] Loss: 0.20450 
Epoch [162/300] Training [9/62] Loss: 0.11885 
Epoch [162/300] Training [10/62] Loss: 0.10630 
Epoch [162/300] Training [11/62] Loss: 0.08505 
Epoch [162/300] Training [12/62] Loss: 0.06907 
Epoch [162/300] Training [13/62] Loss: 0.08239 
Epoch [162/300] Training [14/62] Loss: 0.22922 
Epoch [162/300] Training [15/62] Loss: 0.06463 
Epoch [162/300] Training [16/62] Loss: 0.09755 
Epoch [162/300] Training [17/62] Loss: 0.13901 
Epoch [162/300] Training [18/62] Loss: 0.10811 
Epoch [162/300] Training [19/62] Loss: 0.06466 
Epoch [162/300] Training [20/62] Loss: 0.05669 
Epoch [162/300] Training [21/62] Loss: 0.15452 
Epoch [162/300] Training [22/62] Loss: 0.06040 
Epoch [162/300] Training [23/62] Loss: 0.12815 
Epoch [162/300] Training [24/62] Loss: 0.09372 
Epoch [162/300] Training [25/62] Loss: 0.19502 
Epoch [162/300] Training [26/62] Loss: 0.05942 
Epoch [162/300] Training [27/62] Loss: 0.06580 
Epoch [162/300] Training [28/62] Loss: 0.20423 
Epoch [162/300] Training [29/62] Loss: 0.14334 
Epoch [162/300] Training [30/62] Loss: 0.13605 
Epoch [162/300] Training [31/62] Loss: 0.06939 
Epoch [162/300] Training [32/62] Loss: 0.08828 
Epoch [162/300] Training [33/62] Loss: 0.11755 
Epoch [162/300] Training [34/62] Loss: 0.05844 
Epoch [162/300] Training [35/62] Loss: 0.11160 
Epoch [162/300] Training [36/62] Loss: 0.08851 
Epoch [162/300] Training [37/62] Loss: 0.06720 
Epoch [162/300] Training [38/62] Loss: 0.14822 
Epoch [162/300] Training [39/62] Loss: 0.05693 
Epoch [162/300] Training [40/62] Loss: 0.08749 
Epoch [162/300] Training [41/62] Loss: 0.12081 
Epoch [162/300] Training [42/62] Loss: 0.12254 
Epoch [162/300] Training [43/62] Loss: 0.05258 
Epoch [162/300] Training [44/62] Loss: 0.04519 
Epoch [162/300] Training [45/62] Loss: 0.04339 
Epoch [162/300] Training [46/62] Loss: 0.09569 
Epoch [162/300] Training [47/62] Loss: 0.06855 
Epoch [162/300] Training [48/62] Loss: 0.07511 
Epoch [162/300] Training [49/62] Loss: 0.07603 
Epoch [162/300] Training [50/62] Loss: 0.06293 
Epoch [162/300] Training [51/62] Loss: 0.08647 
Epoch [162/300] Training [52/62] Loss: 0.13333 
Epoch [162/300] Training [53/62] Loss: 0.07540 
Epoch [162/300] Training [54/62] Loss: 0.09448 
Epoch [162/300] Training [55/62] Loss: 0.06336 
Epoch [162/300] Training [56/62] Loss: 0.05957 
Epoch [162/300] Training [57/62] Loss: 0.14010 
Epoch [162/300] Training [58/62] Loss: 0.06259 
Epoch [162/300] Training [59/62] Loss: 0.08543 
Epoch [162/300] Training [60/62] Loss: 0.08141 
Epoch [162/300] Training [61/62] Loss: 0.08232 
Epoch [162/300] Training [62/62] Loss: 0.05238 
Epoch [162/300] Training metric {'Train/mean dice_metric': 0.934119701385498, 'Train/mean miou_metric': 0.8878378868103027, 'Train/mean f1': 0.9440059065818787, 'Train/mean precision': 0.943858802318573, 'Train/mean recall': 0.9441531300544739, 'Train/mean hd95_metric': 18.593921661376953}
Epoch [162/300] Validation [1/16] Loss: 0.65379  focal_loss 0.39890  dice_loss 0.25489 
Epoch [162/300] Validation [2/16] Loss: 0.54618  focal_loss 0.19466  dice_loss 0.35152 
Epoch [162/300] Validation [3/16] Loss: 0.63153  focal_loss 0.32638  dice_loss 0.30516 
Epoch [162/300] Validation [4/16] Loss: 0.31655  focal_loss 0.14129  dice_loss 0.17527 
Epoch [162/300] Validation [5/16] Loss: 0.45831  focal_loss 0.13915  dice_loss 0.31916 
Epoch [162/300] Validation [6/16] Loss: 0.25858  focal_loss 0.06662  dice_loss 0.19196 
Epoch [162/300] Validation [7/16] Loss: 0.23921  focal_loss 0.08005  dice_loss 0.15916 
Epoch [162/300] Validation [8/16] Loss: 0.46013  focal_loss 0.15002  dice_loss 0.31011 
Epoch [162/300] Validation [9/16] Loss: 0.29811  focal_loss 0.09446  dice_loss 0.20365 
Epoch [162/300] Validation [10/16] Loss: 0.62950  focal_loss 0.22704  dice_loss 0.40247 
Epoch [162/300] Validation [11/16] Loss: 0.26327  focal_loss 0.06773  dice_loss 0.19554 
Epoch [162/300] Validation [12/16] Loss: 0.38985  focal_loss 0.10066  dice_loss 0.28919 
Epoch [162/300] Validation [13/16] Loss: 0.21755  focal_loss 0.06436  dice_loss 0.15319 
Epoch [162/300] Validation [14/16] Loss: 0.52946  focal_loss 0.18604  dice_loss 0.34342 
Epoch [162/300] Validation [15/16] Loss: 0.14095  focal_loss 0.04291  dice_loss 0.09804 
Epoch [162/300] Validation [16/16] Loss: 0.24654  focal_loss 0.08007  dice_loss 0.16648 
Epoch [162/300] Validation metric {'Val/mean dice_metric': 0.899001955986023, 'Val/mean miou_metric': 0.8427750468254089, 'Val/mean f1': 0.916183352470398, 'Val/mean precision': 0.9258355498313904, 'Val/mean recall': 0.9067302346229553, 'Val/mean hd95_metric': 26.16746711730957}
Cheakpoint...
Epoch [162/300] best acc:tensor([0.9037], device='cuda:0'), Now : mean acc: tensor([0.8990], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.899001955986023, 'Val/mean miou_metric': 0.8427750468254089, 'Val/mean f1': 0.916183352470398, 'Val/mean precision': 0.9258355498313904, 'Val/mean recall': 0.9067302346229553, 'Val/mean hd95_metric': 26.16746711730957}
Epoch [163/300] Training [1/62] Loss: 0.06167 
Epoch [163/300] Training [2/62] Loss: 0.16185 
Epoch [163/300] Training [3/62] Loss: 0.05956 
Epoch [163/300] Training [4/62] Loss: 0.07058 
Epoch [163/300] Training [5/62] Loss: 0.06518 
Epoch [163/300] Training [6/62] Loss: 0.08911 
Epoch [163/300] Training [7/62] Loss: 0.04085 
Epoch [163/300] Training [8/62] Loss: 0.07379 
Epoch [163/300] Training [9/62] Loss: 0.08002 
Epoch [163/300] Training [10/62] Loss: 0.07174 
Epoch [163/300] Training [11/62] Loss: 0.12249 
Epoch [163/300] Training [12/62] Loss: 0.12132 
Epoch [163/300] Training [13/62] Loss: 0.07260 
Epoch [163/300] Training [14/62] Loss: 0.11485 
Epoch [163/300] Training [15/62] Loss: 0.08097 
Epoch [163/300] Training [16/62] Loss: 0.08375 
Epoch [163/300] Training [17/62] Loss: 0.19422 
Epoch [163/300] Training [18/62] Loss: 0.08011 
Epoch [163/300] Training [19/62] Loss: 0.04835 
Epoch [163/300] Training [20/62] Loss: 0.12023 
Epoch [163/300] Training [21/62] Loss: 0.10603 
Epoch [163/300] Training [22/62] Loss: 0.06196 
Epoch [163/300] Training [23/62] Loss: 0.05276 
Epoch [163/300] Training [24/62] Loss: 0.18338 
Epoch [163/300] Training [25/62] Loss: 0.11841 
Epoch [163/300] Training [26/62] Loss: 0.06552 
Epoch [163/300] Training [27/62] Loss: 0.26196 
Epoch [163/300] Training [28/62] Loss: 0.05370 
Epoch [163/300] Training [29/62] Loss: 0.07157 
Epoch [163/300] Training [30/62] Loss: 0.17755 
Epoch [163/300] Training [31/62] Loss: 0.06639 
Epoch [163/300] Training [32/62] Loss: 0.10884 
Epoch [163/300] Training [33/62] Loss: 0.20353 
Epoch [163/300] Training [34/62] Loss: 0.08940 
Epoch [163/300] Training [35/62] Loss: 0.15715 
Epoch [163/300] Training [36/62] Loss: 0.16651 
Epoch [163/300] Training [37/62] Loss: 0.07744 
Epoch [163/300] Training [38/62] Loss: 0.04364 
Epoch [163/300] Training [39/62] Loss: 0.09597 
Epoch [163/300] Training [40/62] Loss: 0.07980 
Epoch [163/300] Training [41/62] Loss: 0.10442 
Epoch [163/300] Training [42/62] Loss: 0.16842 
Epoch [163/300] Training [43/62] Loss: 0.06172 
Epoch [163/300] Training [44/62] Loss: 0.08219 
Epoch [163/300] Training [45/62] Loss: 0.10857 
Epoch [163/300] Training [46/62] Loss: 0.11474 
Epoch [163/300] Training [47/62] Loss: 0.07355 
Epoch [163/300] Training [48/62] Loss: 0.08006 
Epoch [163/300] Training [49/62] Loss: 0.05062 
Epoch [163/300] Training [50/62] Loss: 0.05336 
Epoch [163/300] Training [51/62] Loss: 0.09869 
Epoch [163/300] Training [52/62] Loss: 0.08741 
Epoch [163/300] Training [53/62] Loss: 0.05692 
Epoch [163/300] Training [54/62] Loss: 0.08382 
Epoch [163/300] Training [55/62] Loss: 0.07847 
Epoch [163/300] Training [56/62] Loss: 0.03736 
Epoch [163/300] Training [57/62] Loss: 0.04370 
Epoch [163/300] Training [58/62] Loss: 0.30575 
Epoch [163/300] Training [59/62] Loss: 0.10543 
Epoch [163/300] Training [60/62] Loss: 0.15630 
Epoch [163/300] Training [61/62] Loss: 0.10419 
Epoch [163/300] Training [62/62] Loss: 0.04627 
Epoch [163/300] Training metric {'Train/mean dice_metric': 0.9322305917739868, 'Train/mean miou_metric': 0.8857662677764893, 'Train/mean f1': 0.9420138001441956, 'Train/mean precision': 0.9430270791053772, 'Train/mean recall': 0.9410028457641602, 'Train/mean hd95_metric': 18.210996627807617}
Epoch [163/300] Validation [1/16] Loss: 1.07386  focal_loss 0.62792  dice_loss 0.44594 
Epoch [163/300] Validation [2/16] Loss: 0.76890  focal_loss 0.27885  dice_loss 0.49005 
Epoch [163/300] Validation [3/16] Loss: 0.81112  focal_loss 0.34312  dice_loss 0.46800 
Epoch [163/300] Validation [4/16] Loss: 0.48592  focal_loss 0.23063  dice_loss 0.25528 
Epoch [163/300] Validation [5/16] Loss: 0.48433  focal_loss 0.13883  dice_loss 0.34550 
Epoch [163/300] Validation [6/16] Loss: 0.47615  focal_loss 0.14413  dice_loss 0.33203 
Epoch [163/300] Validation [7/16] Loss: 0.62546  focal_loss 0.27715  dice_loss 0.34831 
Epoch [163/300] Validation [8/16] Loss: 0.85575  focal_loss 0.26398  dice_loss 0.59177 
Epoch [163/300] Validation [9/16] Loss: 0.94049  focal_loss 0.46051  dice_loss 0.47998 
Epoch [163/300] Validation [10/16] Loss: 0.81984  focal_loss 0.31452  dice_loss 0.50532 
Epoch [163/300] Validation [11/16] Loss: 0.55655  focal_loss 0.20316  dice_loss 0.35339 
Epoch [163/300] Validation [12/16] Loss: 0.54709  focal_loss 0.12132  dice_loss 0.42577 
Epoch [163/300] Validation [13/16] Loss: 0.45291  focal_loss 0.19676  dice_loss 0.25615 
Epoch [163/300] Validation [14/16] Loss: 0.94291  focal_loss 0.30199  dice_loss 0.64091 
Epoch [163/300] Validation [15/16] Loss: 0.35260  focal_loss 0.14433  dice_loss 0.20827 
Epoch [163/300] Validation [16/16] Loss: 0.11970  focal_loss 0.03217  dice_loss 0.08753 
Epoch [163/300] Validation metric {'Val/mean dice_metric': 0.8658801317214966, 'Val/mean miou_metric': 0.8114724159240723, 'Val/mean f1': 0.9012611508369446, 'Val/mean precision': 0.9329925179481506, 'Val/mean recall': 0.8716172575950623, 'Val/mean hd95_metric': 25.766630172729492}
Cheakpoint...
Epoch [163/300] best acc:tensor([0.9037], device='cuda:0'), Now : mean acc: tensor([0.8659], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8658801317214966, 'Val/mean miou_metric': 0.8114724159240723, 'Val/mean f1': 0.9012611508369446, 'Val/mean precision': 0.9329925179481506, 'Val/mean recall': 0.8716172575950623, 'Val/mean hd95_metric': 25.766630172729492}
Epoch [164/300] Training [1/62] Loss: 0.04284 
Epoch [164/300] Training [2/62] Loss: 0.05857 
Epoch [164/300] Training [3/62] Loss: 0.08889 
Epoch [164/300] Training [4/62] Loss: 0.07253 
Epoch [164/300] Training [5/62] Loss: 0.06128 
Epoch [164/300] Training [6/62] Loss: 0.08827 
Epoch [164/300] Training [7/62] Loss: 0.08520 
Epoch [164/300] Training [8/62] Loss: 0.13922 
Epoch [164/300] Training [9/62] Loss: 0.11681 
Epoch [164/300] Training [10/62] Loss: 0.17556 
Epoch [164/300] Training [11/62] Loss: 0.07451 
Epoch [164/300] Training [12/62] Loss: 0.15010 
Epoch [164/300] Training [13/62] Loss: 0.16392 
Epoch [164/300] Training [14/62] Loss: 0.11924 
Epoch [164/300] Training [15/62] Loss: 0.08261 
Epoch [164/300] Training [16/62] Loss: 0.06163 
Epoch [164/300] Training [17/62] Loss: 0.08515 
Epoch [164/300] Training [18/62] Loss: 0.07673 
Epoch [164/300] Training [19/62] Loss: 0.07981 
Epoch [164/300] Training [20/62] Loss: 0.09926 
Epoch [164/300] Training [21/62] Loss: 0.11807 
Epoch [164/300] Training [22/62] Loss: 0.05628 
Epoch [164/300] Training [23/62] Loss: 0.05283 
Epoch [164/300] Training [24/62] Loss: 0.04467 
Epoch [164/300] Training [25/62] Loss: 0.06977 
Epoch [164/300] Training [26/62] Loss: 0.19215 
Epoch [164/300] Training [27/62] Loss: 0.06234 
Epoch [164/300] Training [28/62] Loss: 0.04845 
Epoch [164/300] Training [29/62] Loss: 0.08975 
Epoch [164/300] Training [30/62] Loss: 0.07943 
Epoch [164/300] Training [31/62] Loss: 0.08851 
Epoch [164/300] Training [32/62] Loss: 0.08525 
Epoch [164/300] Training [33/62] Loss: 0.17189 
Epoch [164/300] Training [34/62] Loss: 0.09836 
Epoch [164/300] Training [35/62] Loss: 0.07796 
Epoch [164/300] Training [36/62] Loss: 0.05908 
Epoch [164/300] Training [37/62] Loss: 0.07946 
Epoch [164/300] Training [38/62] Loss: 0.13935 
Epoch [164/300] Training [39/62] Loss: 0.04990 
Epoch [164/300] Training [40/62] Loss: 0.21784 
Epoch [164/300] Training [41/62] Loss: 0.05051 
Epoch [164/300] Training [42/62] Loss: 0.06103 
Epoch [164/300] Training [43/62] Loss: 0.07768 
Epoch [164/300] Training [44/62] Loss: 0.09607 
Epoch [164/300] Training [45/62] Loss: 0.05704 
Epoch [164/300] Training [46/62] Loss: 0.08898 
Epoch [164/300] Training [47/62] Loss: 0.19723 
Epoch [164/300] Training [48/62] Loss: 0.16125 
Epoch [164/300] Training [49/62] Loss: 0.07603 
Epoch [164/300] Training [50/62] Loss: 0.08834 
Epoch [164/300] Training [51/62] Loss: 0.10379 
Epoch [164/300] Training [52/62] Loss: 0.07249 
Epoch [164/300] Training [53/62] Loss: 0.08146 
Epoch [164/300] Training [54/62] Loss: 0.06086 
Epoch [164/300] Training [55/62] Loss: 0.19525 
Epoch [164/300] Training [56/62] Loss: 0.08282 
Epoch [164/300] Training [57/62] Loss: 0.09264 
Epoch [164/300] Training [58/62] Loss: 0.07281 
Epoch [164/300] Training [59/62] Loss: 0.14692 
Epoch [164/300] Training [60/62] Loss: 0.05894 
Epoch [164/300] Training [61/62] Loss: 0.07744 
Epoch [164/300] Training [62/62] Loss: 0.13928 
Epoch [164/300] Training metric {'Train/mean dice_metric': 0.9367499947547913, 'Train/mean miou_metric': 0.8903084397315979, 'Train/mean f1': 0.943327009677887, 'Train/mean precision': 0.9440176486968994, 'Train/mean recall': 0.9426375031471252, 'Train/mean hd95_metric': 18.917085647583008}
Epoch [164/300] Validation [1/16] Loss: 0.73840  focal_loss 0.44002  dice_loss 0.29838 
Epoch [164/300] Validation [2/16] Loss: 0.62772  focal_loss 0.21045  dice_loss 0.41727 
Epoch [164/300] Validation [3/16] Loss: 0.63531  focal_loss 0.32830  dice_loss 0.30700 
Epoch [164/300] Validation [4/16] Loss: 0.32914  focal_loss 0.13911  dice_loss 0.19003 
Epoch [164/300] Validation [5/16] Loss: 0.38948  focal_loss 0.11648  dice_loss 0.27300 
Epoch [164/300] Validation [6/16] Loss: 0.28314  focal_loss 0.08260  dice_loss 0.20054 
Epoch [164/300] Validation [7/16] Loss: 0.33307  focal_loss 0.10628  dice_loss 0.22679 
Epoch [164/300] Validation [8/16] Loss: 0.59865  focal_loss 0.17457  dice_loss 0.42408 
Epoch [164/300] Validation [9/16] Loss: 0.45917  focal_loss 0.20487  dice_loss 0.25431 
Epoch [164/300] Validation [10/16] Loss: 0.74009  focal_loss 0.26286  dice_loss 0.47723 
Epoch [164/300] Validation [11/16] Loss: 0.26159  focal_loss 0.08462  dice_loss 0.17698 
Epoch [164/300] Validation [12/16] Loss: 0.47034  focal_loss 0.12152  dice_loss 0.34883 
Epoch [164/300] Validation [13/16] Loss: 0.26677  focal_loss 0.08863  dice_loss 0.17814 
Epoch [164/300] Validation [14/16] Loss: 0.60790  focal_loss 0.18846  dice_loss 0.41944 
Epoch [164/300] Validation [15/16] Loss: 0.12777  focal_loss 0.04163  dice_loss 0.08614 
Epoch [164/300] Validation [16/16] Loss: 0.12698  focal_loss 0.02990  dice_loss 0.09709 
Epoch [164/300] Validation metric {'Val/mean dice_metric': 0.8943284153938293, 'Val/mean miou_metric': 0.8383389115333557, 'Val/mean f1': 0.9118834137916565, 'Val/mean precision': 0.9206926822662354, 'Val/mean recall': 0.9032411575317383, 'Val/mean hd95_metric': 28.468135833740234}
Cheakpoint...
Epoch [164/300] best acc:tensor([0.9037], device='cuda:0'), Now : mean acc: tensor([0.8943], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8943284153938293, 'Val/mean miou_metric': 0.8383389115333557, 'Val/mean f1': 0.9118834137916565, 'Val/mean precision': 0.9206926822662354, 'Val/mean recall': 0.9032411575317383, 'Val/mean hd95_metric': 28.468135833740234}
Epoch [165/300] Training [1/62] Loss: 0.06581 
Epoch [165/300] Training [2/62] Loss: 0.04699 
Epoch [165/300] Training [3/62] Loss: 0.10289 
Epoch [165/300] Training [4/62] Loss: 0.04682 
Epoch [165/300] Training [5/62] Loss: 0.07412 
Epoch [165/300] Training [6/62] Loss: 0.06505 
Epoch [165/300] Training [7/62] Loss: 0.12346 
Epoch [165/300] Training [8/62] Loss: 0.32967 
Epoch [165/300] Training [9/62] Loss: 0.06542 
Epoch [165/300] Training [10/62] Loss: 0.09609 
Epoch [165/300] Training [11/62] Loss: 0.09698 
Epoch [165/300] Training [12/62] Loss: 0.17857 
Epoch [165/300] Training [13/62] Loss: 0.05034 
Epoch [165/300] Training [14/62] Loss: 0.08401 
Epoch [165/300] Training [15/62] Loss: 0.04664 
Epoch [165/300] Training [16/62] Loss: 0.09188 
Epoch [165/300] Training [17/62] Loss: 0.06463 
Epoch [165/300] Training [18/62] Loss: 0.08129 
Epoch [165/300] Training [19/62] Loss: 0.13409 
Epoch [165/300] Training [20/62] Loss: 0.05392 
Epoch [165/300] Training [21/62] Loss: 0.10413 
Epoch [165/300] Training [22/62] Loss: 0.08559 
Epoch [165/300] Training [23/62] Loss: 0.05435 
Epoch [165/300] Training [24/62] Loss: 0.05850 
Epoch [165/300] Training [25/62] Loss: 0.04739 
Epoch [165/300] Training [26/62] Loss: 0.04862 
Epoch [165/300] Training [27/62] Loss: 0.06494 
Epoch [165/300] Training [28/62] Loss: 0.07124 
Epoch [165/300] Training [29/62] Loss: 0.08227 
Epoch [165/300] Training [30/62] Loss: 0.11037 
Epoch [165/300] Training [31/62] Loss: 0.06084 
Epoch [165/300] Training [32/62] Loss: 0.09224 
Epoch [165/300] Training [33/62] Loss: 0.08409 
Epoch [165/300] Training [34/62] Loss: 0.06528 
Epoch [165/300] Training [35/62] Loss: 0.05885 
Epoch [165/300] Training [36/62] Loss: 0.10919 
Epoch [165/300] Training [37/62] Loss: 0.04333 
Epoch [165/300] Training [38/62] Loss: 0.15156 
Epoch [165/300] Training [39/62] Loss: 0.07811 
Epoch [165/300] Training [40/62] Loss: 0.05928 
Epoch [165/300] Training [41/62] Loss: 0.07186 
Epoch [165/300] Training [42/62] Loss: 0.15517 
Epoch [165/300] Training [43/62] Loss: 0.06689 
Epoch [165/300] Training [44/62] Loss: 0.17880 
Epoch [165/300] Training [45/62] Loss: 0.06504 
Epoch [165/300] Training [46/62] Loss: 0.11293 
Epoch [165/300] Training [47/62] Loss: 0.04967 
Epoch [165/300] Training [48/62] Loss: 0.08689 
Epoch [165/300] Training [49/62] Loss: 0.15689 
Epoch [165/300] Training [50/62] Loss: 0.07405 
Epoch [165/300] Training [51/62] Loss: 0.12253 
Epoch [165/300] Training [52/62] Loss: 0.08012 
Epoch [165/300] Training [53/62] Loss: 0.05584 
Epoch [165/300] Training [54/62] Loss: 0.18957 
Epoch [165/300] Training [55/62] Loss: 0.07339 
Epoch [165/300] Training [56/62] Loss: 0.08482 
Epoch [165/300] Training [57/62] Loss: 0.10374 
Epoch [165/300] Training [58/62] Loss: 0.12639 
Epoch [165/300] Training [59/62] Loss: 0.26615 
Epoch [165/300] Training [60/62] Loss: 0.12041 
Epoch [165/300] Training [61/62] Loss: 0.08773 
Epoch [165/300] Training [62/62] Loss: 0.03928 
Epoch [165/300] Training metric {'Train/mean dice_metric': 0.9378678202629089, 'Train/mean miou_metric': 0.8932509422302246, 'Train/mean f1': 0.9441688656806946, 'Train/mean precision': 0.9454672932624817, 'Train/mean recall': 0.9428738951683044, 'Train/mean hd95_metric': 19.108469009399414}
Epoch [165/300] Validation [1/16] Loss: 0.52713  focal_loss 0.31501  dice_loss 0.21212 
Epoch [165/300] Validation [2/16] Loss: 0.45655  focal_loss 0.18278  dice_loss 0.27376 
Epoch [165/300] Validation [3/16] Loss: 0.53113  focal_loss 0.25826  dice_loss 0.27287 
Epoch [165/300] Validation [4/16] Loss: 0.37623  focal_loss 0.15288  dice_loss 0.22336 
Epoch [165/300] Validation [5/16] Loss: 0.35996  focal_loss 0.12441  dice_loss 0.23555 
Epoch [165/300] Validation [6/16] Loss: 0.39390  focal_loss 0.13245  dice_loss 0.26146 
Epoch [165/300] Validation [7/16] Loss: 0.24003  focal_loss 0.10082  dice_loss 0.13921 
Epoch [165/300] Validation [8/16] Loss: 0.41250  focal_loss 0.12140  dice_loss 0.29110 
Epoch [165/300] Validation [9/16] Loss: 0.22874  focal_loss 0.08509  dice_loss 0.14365 
Epoch [165/300] Validation [10/16] Loss: 0.56283  focal_loss 0.15714  dice_loss 0.40568 
Epoch [165/300] Validation [11/16] Loss: 0.18780  focal_loss 0.06301  dice_loss 0.12479 
Epoch [165/300] Validation [12/16] Loss: 0.39049  focal_loss 0.10779  dice_loss 0.28270 
Epoch [165/300] Validation [13/16] Loss: 0.26201  focal_loss 0.08145  dice_loss 0.18056 
Epoch [165/300] Validation [14/16] Loss: 0.72652  focal_loss 0.27181  dice_loss 0.45471 
Epoch [165/300] Validation [15/16] Loss: 0.12955  focal_loss 0.04578  dice_loss 0.08377 
Epoch [165/300] Validation [16/16] Loss: 0.26349  focal_loss 0.10222  dice_loss 0.16127 
Epoch [165/300] Validation metric {'Val/mean dice_metric': 0.9042491912841797, 'Val/mean miou_metric': 0.850428581237793, 'Val/mean f1': 0.9165700674057007, 'Val/mean precision': 0.9218732118606567, 'Val/mean recall': 0.9113276600837708, 'Val/mean hd95_metric': 27.344207763671875}
Cheakpoint...
Epoch [165/300] best acc:tensor([0.9042], device='cuda:0'), Now : mean acc: tensor([0.9042], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9042491912841797, 'Val/mean miou_metric': 0.850428581237793, 'Val/mean f1': 0.9165700674057007, 'Val/mean precision': 0.9218732118606567, 'Val/mean recall': 0.9113276600837708, 'Val/mean hd95_metric': 27.344207763671875}
Epoch [166/300] Training [1/62] Loss: 0.10091 
Epoch [166/300] Training [2/62] Loss: 0.06395 
Epoch [166/300] Training [3/62] Loss: 0.06110 
Epoch [166/300] Training [4/62] Loss: 0.09627 
Epoch [166/300] Training [5/62] Loss: 0.06890 
Epoch [166/300] Training [6/62] Loss: 0.09148 
Epoch [166/300] Training [7/62] Loss: 0.13166 
Epoch [166/300] Training [8/62] Loss: 0.08504 
Epoch [166/300] Training [9/62] Loss: 0.07867 
Epoch [166/300] Training [10/62] Loss: 0.13593 
Epoch [166/300] Training [11/62] Loss: 0.05820 
Epoch [166/300] Training [12/62] Loss: 0.08107 
Epoch [166/300] Training [13/62] Loss: 0.04267 
Epoch [166/300] Training [14/62] Loss: 0.07880 
Epoch [166/300] Training [15/62] Loss: 0.16671 
Epoch [166/300] Training [16/62] Loss: 0.08656 
Epoch [166/300] Training [17/62] Loss: 0.14958 
Epoch [166/300] Training [18/62] Loss: 0.16562 
Epoch [166/300] Training [19/62] Loss: 0.06406 
Epoch [166/300] Training [20/62] Loss: 0.14794 
Epoch [166/300] Training [21/62] Loss: 0.17870 
Epoch [166/300] Training [22/62] Loss: 0.06094 
Epoch [166/300] Training [23/62] Loss: 0.07897 
Epoch [166/300] Training [24/62] Loss: 0.05799 
Epoch [166/300] Training [25/62] Loss: 0.05610 
Epoch [166/300] Training [26/62] Loss: 0.11022 
Epoch [166/300] Training [27/62] Loss: 0.06825 
Epoch [166/300] Training [28/62] Loss: 0.06005 
Epoch [166/300] Training [29/62] Loss: 0.07545 
Epoch [166/300] Training [30/62] Loss: 0.06147 
Epoch [166/300] Training [31/62] Loss: 0.23145 
Epoch [166/300] Training [32/62] Loss: 0.05733 
Epoch [166/300] Training [33/62] Loss: 0.06588 
Epoch [166/300] Training [34/62] Loss: 0.10588 
Epoch [166/300] Training [35/62] Loss: 0.11606 
Epoch [166/300] Training [36/62] Loss: 0.09604 
Epoch [166/300] Training [37/62] Loss: 0.12851 
Epoch [166/300] Training [38/62] Loss: 0.05816 
Epoch [166/300] Training [39/62] Loss: 0.13287 
Epoch [166/300] Training [40/62] Loss: 0.05335 
Epoch [166/300] Training [41/62] Loss: 0.07197 
Epoch [166/300] Training [42/62] Loss: 0.04635 
Epoch [166/300] Training [43/62] Loss: 0.09633 
Epoch [166/300] Training [44/62] Loss: 0.08267 
Epoch [166/300] Training [45/62] Loss: 0.04560 
Epoch [166/300] Training [46/62] Loss: 0.06462 
Epoch [166/300] Training [47/62] Loss: 0.07463 
Epoch [166/300] Training [48/62] Loss: 0.10703 
Epoch [166/300] Training [49/62] Loss: 0.04912 
Epoch [166/300] Training [50/62] Loss: 0.19652 
Epoch [166/300] Training [51/62] Loss: 0.15307 
Epoch [166/300] Training [52/62] Loss: 0.08810 
Epoch [166/300] Training [53/62] Loss: 0.11865 
Epoch [166/300] Training [54/62] Loss: 0.14516 
Epoch [166/300] Training [55/62] Loss: 0.12205 
Epoch [166/300] Training [56/62] Loss: 0.07471 
Epoch [166/300] Training [57/62] Loss: 0.07502 
Epoch [166/300] Training [58/62] Loss: 0.09552 
Epoch [166/300] Training [59/62] Loss: 0.04468 
Epoch [166/300] Training [60/62] Loss: 0.07484 
Epoch [166/300] Training [61/62] Loss: 0.05775 
Epoch [166/300] Training [62/62] Loss: 0.39392 
Epoch [166/300] Training metric {'Train/mean dice_metric': 0.9367929100990295, 'Train/mean miou_metric': 0.8906237483024597, 'Train/mean f1': 0.9461701512336731, 'Train/mean precision': 0.9465265274047852, 'Train/mean recall': 0.9458138942718506, 'Train/mean hd95_metric': 17.914363861083984}
Epoch [166/300] Validation [1/16] Loss: 0.61836  focal_loss 0.38004  dice_loss 0.23832 
Epoch [166/300] Validation [2/16] Loss: 0.57941  focal_loss 0.21471  dice_loss 0.36470 
Epoch [166/300] Validation [3/16] Loss: 0.47037  focal_loss 0.22111  dice_loss 0.24926 
Epoch [166/300] Validation [4/16] Loss: 0.31935  focal_loss 0.14976  dice_loss 0.16959 
Epoch [166/300] Validation [5/16] Loss: 0.35870  focal_loss 0.10192  dice_loss 0.25678 
Epoch [166/300] Validation [6/16] Loss: 0.34362  focal_loss 0.10561  dice_loss 0.23801 
Epoch [166/300] Validation [7/16] Loss: 0.19278  focal_loss 0.06978  dice_loss 0.12300 
Epoch [166/300] Validation [8/16] Loss: 0.47464  focal_loss 0.16011  dice_loss 0.31453 
Epoch [166/300] Validation [9/16] Loss: 0.27705  focal_loss 0.11011  dice_loss 0.16693 
Epoch [166/300] Validation [10/16] Loss: 0.44583  focal_loss 0.13852  dice_loss 0.30731 
Epoch [166/300] Validation [11/16] Loss: 0.16241  focal_loss 0.04344  dice_loss 0.11897 
Epoch [166/300] Validation [12/16] Loss: 0.39142  focal_loss 0.10634  dice_loss 0.28508 
Epoch [166/300] Validation [13/16] Loss: 0.24380  focal_loss 0.06242  dice_loss 0.18138 
Epoch [166/300] Validation [14/16] Loss: 0.53671  focal_loss 0.18073  dice_loss 0.35597 
Epoch [166/300] Validation [15/16] Loss: 0.12833  focal_loss 0.03748  dice_loss 0.09084 
Epoch [166/300] Validation [16/16] Loss: 0.14630  focal_loss 0.04041  dice_loss 0.10590 
Epoch [166/300] Validation metric {'Val/mean dice_metric': 0.9055818319320679, 'Val/mean miou_metric': 0.8495197296142578, 'Val/mean f1': 0.9194122552871704, 'Val/mean precision': 0.9241682291030884, 'Val/mean recall': 0.9147050380706787, 'Val/mean hd95_metric': 25.90498161315918}
Cheakpoint...
Epoch [166/300] best acc:tensor([0.9056], device='cuda:0'), Now : mean acc: tensor([0.9056], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9055818319320679, 'Val/mean miou_metric': 0.8495197296142578, 'Val/mean f1': 0.9194122552871704, 'Val/mean precision': 0.9241682291030884, 'Val/mean recall': 0.9147050380706787, 'Val/mean hd95_metric': 25.90498161315918}
Epoch [167/300] Training [1/62] Loss: 0.08441 
Epoch [167/300] Training [2/62] Loss: 0.06712 
Epoch [167/300] Training [3/62] Loss: 0.06316 
Epoch [167/300] Training [4/62] Loss: 0.07603 
Epoch [167/300] Training [5/62] Loss: 0.10374 
Epoch [167/300] Training [6/62] Loss: 0.10024 
Epoch [167/300] Training [7/62] Loss: 0.14241 
Epoch [167/300] Training [8/62] Loss: 0.04903 
Epoch [167/300] Training [9/62] Loss: 0.07200 
Epoch [167/300] Training [10/62] Loss: 0.07517 
Epoch [167/300] Training [11/62] Loss: 0.05481 
Epoch [167/300] Training [12/62] Loss: 0.09107 
Epoch [167/300] Training [13/62] Loss: 0.05439 
Epoch [167/300] Training [14/62] Loss: 0.05140 
Epoch [167/300] Training [15/62] Loss: 0.07086 
Epoch [167/300] Training [16/62] Loss: 0.11443 
Epoch [167/300] Training [17/62] Loss: 0.08155 
Epoch [167/300] Training [18/62] Loss: 0.07847 
Epoch [167/300] Training [19/62] Loss: 0.06612 
Epoch [167/300] Training [20/62] Loss: 0.06191 
Epoch [167/300] Training [21/62] Loss: 0.08287 
Epoch [167/300] Training [22/62] Loss: 0.14095 
Epoch [167/300] Training [23/62] Loss: 0.06321 
Epoch [167/300] Training [24/62] Loss: 0.13279 
Epoch [167/300] Training [25/62] Loss: 0.11327 
Epoch [167/300] Training [26/62] Loss: 0.07884 
Epoch [167/300] Training [27/62] Loss: 0.13589 
Epoch [167/300] Training [28/62] Loss: 0.07387 
Epoch [167/300] Training [29/62] Loss: 0.22961 
Epoch [167/300] Training [30/62] Loss: 0.06739 
Epoch [167/300] Training [31/62] Loss: 0.06832 
Epoch [167/300] Training [32/62] Loss: 0.07990 
Epoch [167/300] Training [33/62] Loss: 0.14372 
Epoch [167/300] Training [34/62] Loss: 0.08940 
Epoch [167/300] Training [35/62] Loss: 0.10635 
Epoch [167/300] Training [36/62] Loss: 0.10226 
Epoch [167/300] Training [37/62] Loss: 0.17100 
Epoch [167/300] Training [38/62] Loss: 0.09845 
Epoch [167/300] Training [39/62] Loss: 0.06704 
Epoch [167/300] Training [40/62] Loss: 0.04515 
Epoch [167/300] Training [41/62] Loss: 0.09145 
Epoch [167/300] Training [42/62] Loss: 0.05369 
Epoch [167/300] Training [43/62] Loss: 0.08225 
Epoch [167/300] Training [44/62] Loss: 0.12547 
Epoch [167/300] Training [45/62] Loss: 0.14136 
Epoch [167/300] Training [46/62] Loss: 0.05534 
Epoch [167/300] Training [47/62] Loss: 0.06748 
Epoch [167/300] Training [48/62] Loss: 0.06494 
Epoch [167/300] Training [49/62] Loss: 0.05286 
Epoch [167/300] Training [50/62] Loss: 0.23756 
Epoch [167/300] Training [51/62] Loss: 0.06028 
Epoch [167/300] Training [52/62] Loss: 0.05197 
Epoch [167/300] Training [53/62] Loss: 0.05755 
Epoch [167/300] Training [54/62] Loss: 0.07273 
Epoch [167/300] Training [55/62] Loss: 0.10137 
Epoch [167/300] Training [56/62] Loss: 0.14853 
Epoch [167/300] Training [57/62] Loss: 0.11806 
Epoch [167/300] Training [58/62] Loss: 0.09794 
Epoch [167/300] Training [59/62] Loss: 0.09713 
Epoch [167/300] Training [60/62] Loss: 0.08897 
Epoch [167/300] Training [61/62] Loss: 0.08761 
Epoch [167/300] Training [62/62] Loss: 0.04862 
Epoch [167/300] Training metric {'Train/mean dice_metric': 0.9374699592590332, 'Train/mean miou_metric': 0.8907129764556885, 'Train/mean f1': 0.9458475112915039, 'Train/mean precision': 0.9411398768424988, 'Train/mean recall': 0.9506024718284607, 'Train/mean hd95_metric': 18.408594131469727}
Epoch [167/300] Validation [1/16] Loss: 0.61619  focal_loss 0.40053  dice_loss 0.21566 
Epoch [167/300] Validation [2/16] Loss: 0.48480  focal_loss 0.16994  dice_loss 0.31486 
Epoch [167/300] Validation [3/16] Loss: 0.58813  focal_loss 0.28845  dice_loss 0.29967 
Epoch [167/300] Validation [4/16] Loss: 0.33510  focal_loss 0.14261  dice_loss 0.19249 
Epoch [167/300] Validation [5/16] Loss: 0.36536  focal_loss 0.11409  dice_loss 0.25126 
Epoch [167/300] Validation [6/16] Loss: 0.31186  focal_loss 0.08754  dice_loss 0.22432 
Epoch [167/300] Validation [7/16] Loss: 0.22626  focal_loss 0.07722  dice_loss 0.14905 
Epoch [167/300] Validation [8/16] Loss: 0.53979  focal_loss 0.17475  dice_loss 0.36505 
Epoch [167/300] Validation [9/16] Loss: 0.23291  focal_loss 0.08077  dice_loss 0.15213 
Epoch [167/300] Validation [10/16] Loss: 0.49708  focal_loss 0.13267  dice_loss 0.36441 
Epoch [167/300] Validation [11/16] Loss: 0.12667  focal_loss 0.03272  dice_loss 0.09396 
Epoch [167/300] Validation [12/16] Loss: 0.45857  focal_loss 0.10129  dice_loss 0.35728 
Epoch [167/300] Validation [13/16] Loss: 0.27061  focal_loss 0.08399  dice_loss 0.18663 
Epoch [167/300] Validation [14/16] Loss: 0.54836  focal_loss 0.18663  dice_loss 0.36173 
Epoch [167/300] Validation [15/16] Loss: 0.16916  focal_loss 0.06411  dice_loss 0.10504 
Epoch [167/300] Validation [16/16] Loss: 0.08257  focal_loss 0.02302  dice_loss 0.05955 
Epoch [167/300] Validation metric {'Val/mean dice_metric': 0.9038819074630737, 'Val/mean miou_metric': 0.8488467335700989, 'Val/mean f1': 0.9202709197998047, 'Val/mean precision': 0.9276152849197388, 'Val/mean recall': 0.9130418300628662, 'Val/mean hd95_metric': 25.213172912597656}
Cheakpoint...
Epoch [167/300] best acc:tensor([0.9056], device='cuda:0'), Now : mean acc: tensor([0.9039], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9038819074630737, 'Val/mean miou_metric': 0.8488467335700989, 'Val/mean f1': 0.9202709197998047, 'Val/mean precision': 0.9276152849197388, 'Val/mean recall': 0.9130418300628662, 'Val/mean hd95_metric': 25.213172912597656}
Epoch [168/300] Training [1/62] Loss: 0.09897 
Epoch [168/300] Training [2/62] Loss: 0.06752 
Epoch [168/300] Training [3/62] Loss: 0.05147 
Epoch [168/300] Training [4/62] Loss: 0.06371 
Epoch [168/300] Training [5/62] Loss: 0.09694 
Epoch [168/300] Training [6/62] Loss: 0.06723 
Epoch [168/300] Training [7/62] Loss: 0.06353 
Epoch [168/300] Training [8/62] Loss: 0.09836 
Epoch [168/300] Training [9/62] Loss: 0.04169 
Epoch [168/300] Training [10/62] Loss: 0.05724 
Epoch [168/300] Training [11/62] Loss: 0.08143 
Epoch [168/300] Training [12/62] Loss: 0.05485 
Epoch [168/300] Training [13/62] Loss: 0.04009 
Epoch [168/300] Training [14/62] Loss: 0.07901 
Epoch [168/300] Training [15/62] Loss: 0.08531 
Epoch [168/300] Training [16/62] Loss: 0.05564 
Epoch [168/300] Training [17/62] Loss: 0.11816 
Epoch [168/300] Training [18/62] Loss: 0.12533 
Epoch [168/300] Training [19/62] Loss: 0.10297 
Epoch [168/300] Training [20/62] Loss: 0.07061 
Epoch [168/300] Training [21/62] Loss: 0.11458 
Epoch [168/300] Training [22/62] Loss: 0.08610 
Epoch [168/300] Training [23/62] Loss: 0.05944 
Epoch [168/300] Training [24/62] Loss: 0.15851 
Epoch [168/300] Training [25/62] Loss: 0.05824 
Epoch [168/300] Training [26/62] Loss: 0.06510 
Epoch [168/300] Training [27/62] Loss: 0.07259 
Epoch [168/300] Training [28/62] Loss: 0.06167 
Epoch [168/300] Training [29/62] Loss: 0.08132 
Epoch [168/300] Training [30/62] Loss: 0.03960 
Epoch [168/300] Training [31/62] Loss: 0.06072 
Epoch [168/300] Training [32/62] Loss: 0.07089 
Epoch [168/300] Training [33/62] Loss: 0.06075 
Epoch [168/300] Training [34/62] Loss: 0.04286 
Epoch [168/300] Training [35/62] Loss: 0.04777 
Epoch [168/300] Training [36/62] Loss: 0.06949 
Epoch [168/300] Training [37/62] Loss: 0.30463 
Epoch [168/300] Training [38/62] Loss: 0.10228 
Epoch [168/300] Training [39/62] Loss: 0.08341 
Epoch [168/300] Training [40/62] Loss: 0.05630 
Epoch [168/300] Training [41/62] Loss: 0.15534 
Epoch [168/300] Training [42/62] Loss: 0.15766 
Epoch [168/300] Training [43/62] Loss: 0.06132 
Epoch [168/300] Training [44/62] Loss: 0.06519 
Epoch [168/300] Training [45/62] Loss: 0.13673 
Epoch [168/300] Training [46/62] Loss: 0.05141 
Epoch [168/300] Training [47/62] Loss: 0.04129 
Epoch [168/300] Training [48/62] Loss: 0.05533 
Epoch [168/300] Training [49/62] Loss: 0.04373 
Epoch [168/300] Training [50/62] Loss: 0.04747 
Epoch [168/300] Training [51/62] Loss: 0.07794 
Epoch [168/300] Training [52/62] Loss: 0.07385 
Epoch [168/300] Training [53/62] Loss: 0.03866 
Epoch [168/300] Training [54/62] Loss: 0.05949 
Epoch [168/300] Training [55/62] Loss: 0.14251 
Epoch [168/300] Training [56/62] Loss: 0.14122 
Epoch [168/300] Training [57/62] Loss: 0.04396 
Epoch [168/300] Training [58/62] Loss: 0.03933 
Epoch [168/300] Training [59/62] Loss: 0.07479 
Epoch [168/300] Training [60/62] Loss: 0.07198 
Epoch [168/300] Training [61/62] Loss: 0.04850 
Epoch [168/300] Training [62/62] Loss: 0.22313 
Epoch [168/300] Training metric {'Train/mean dice_metric': 0.9456616640090942, 'Train/mean miou_metric': 0.9049813747406006, 'Train/mean f1': 0.9537298083305359, 'Train/mean precision': 0.9507482647895813, 'Train/mean recall': 0.9567301273345947, 'Train/mean hd95_metric': 12.723495483398438}
Epoch [168/300] Validation [1/16] Loss: 0.74141  focal_loss 0.46862  dice_loss 0.27278 
Epoch [168/300] Validation [2/16] Loss: 0.49210  focal_loss 0.20077  dice_loss 0.29133 
Epoch [168/300] Validation [3/16] Loss: 0.61263  focal_loss 0.30729  dice_loss 0.30535 
Epoch [168/300] Validation [4/16] Loss: 0.32703  focal_loss 0.15650  dice_loss 0.17053 
Epoch [168/300] Validation [5/16] Loss: 0.37704  focal_loss 0.12495  dice_loss 0.25209 
Epoch [168/300] Validation [6/16] Loss: 0.28179  focal_loss 0.08322  dice_loss 0.19857 
Epoch [168/300] Validation [7/16] Loss: 0.32636  focal_loss 0.10965  dice_loss 0.21671 
Epoch [168/300] Validation [8/16] Loss: 0.42243  focal_loss 0.13156  dice_loss 0.29086 
Epoch [168/300] Validation [9/16] Loss: 0.31860  focal_loss 0.13669  dice_loss 0.18191 
Epoch [168/300] Validation [10/16] Loss: 0.66207  focal_loss 0.19005  dice_loss 0.47201 
Epoch [168/300] Validation [11/16] Loss: 0.25481  focal_loss 0.08383  dice_loss 0.17098 
Epoch [168/300] Validation [12/16] Loss: 0.45000  focal_loss 0.12337  dice_loss 0.32664 
Epoch [168/300] Validation [13/16] Loss: 0.36395  focal_loss 0.13528  dice_loss 0.22867 
Epoch [168/300] Validation [14/16] Loss: 0.60652  focal_loss 0.21103  dice_loss 0.39549 
Epoch [168/300] Validation [15/16] Loss: 0.14149  focal_loss 0.04699  dice_loss 0.09450 
Epoch [168/300] Validation [16/16] Loss: 0.12463  focal_loss 0.03652  dice_loss 0.08811 
Epoch [168/300] Validation metric {'Val/mean dice_metric': 0.9068902730941772, 'Val/mean miou_metric': 0.856682300567627, 'Val/mean f1': 0.925627589225769, 'Val/mean precision': 0.9403831362724304, 'Val/mean recall': 0.9113279581069946, 'Val/mean hd95_metric': 19.97242546081543}
Cheakpoint...
Epoch [168/300] best acc:tensor([0.9069], device='cuda:0'), Now : mean acc: tensor([0.9069], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9068902730941772, 'Val/mean miou_metric': 0.856682300567627, 'Val/mean f1': 0.925627589225769, 'Val/mean precision': 0.9403831362724304, 'Val/mean recall': 0.9113279581069946, 'Val/mean hd95_metric': 19.97242546081543}
Epoch [169/300] Training [1/62] Loss: 0.14223 
Epoch [169/300] Training [2/62] Loss: 0.10114 
Epoch [169/300] Training [3/62] Loss: 0.04658 
Epoch [169/300] Training [4/62] Loss: 0.07967 
Epoch [169/300] Training [5/62] Loss: 0.07002 
Epoch [169/300] Training [6/62] Loss: 0.07004 
Epoch [169/300] Training [7/62] Loss: 0.06060 
Epoch [169/300] Training [8/62] Loss: 0.06911 
Epoch [169/300] Training [9/62] Loss: 0.08596 
Epoch [169/300] Training [10/62] Loss: 0.06178 
Epoch [169/300] Training [11/62] Loss: 0.27504 
Epoch [169/300] Training [12/62] Loss: 0.05509 
Epoch [169/300] Training [13/62] Loss: 0.15490 
Epoch [169/300] Training [14/62] Loss: 0.08652 
Epoch [169/300] Training [15/62] Loss: 0.06588 
Epoch [169/300] Training [16/62] Loss: 0.09490 
Epoch [169/300] Training [17/62] Loss: 0.08388 
Epoch [169/300] Training [18/62] Loss: 0.07920 
Epoch [169/300] Training [19/62] Loss: 0.04998 
Epoch [169/300] Training [20/62] Loss: 0.08958 
Epoch [169/300] Training [21/62] Loss: 0.08883 
Epoch [169/300] Training [22/62] Loss: 0.08701 
Epoch [169/300] Training [23/62] Loss: 0.06146 
Epoch [169/300] Training [24/62] Loss: 0.07181 
Epoch [169/300] Training [25/62] Loss: 0.18604 
Epoch [169/300] Training [26/62] Loss: 0.04915 
Epoch [169/300] Training [27/62] Loss: 0.04688 
Epoch [169/300] Training [28/62] Loss: 0.06326 
Epoch [169/300] Training [29/62] Loss: 0.04284 
Epoch [169/300] Training [30/62] Loss: 0.07410 
Epoch [169/300] Training [31/62] Loss: 0.05414 
Epoch [169/300] Training [32/62] Loss: 0.13705 
Epoch [169/300] Training [33/62] Loss: 0.06789 
Epoch [169/300] Training [34/62] Loss: 0.05319 
Epoch [169/300] Training [35/62] Loss: 0.08060 
Epoch [169/300] Training [36/62] Loss: 0.04839 
Epoch [169/300] Training [37/62] Loss: 0.05328 
Epoch [169/300] Training [38/62] Loss: 0.07591 
Epoch [169/300] Training [39/62] Loss: 0.16867 
Epoch [169/300] Training [40/62] Loss: 0.08411 
Epoch [169/300] Training [41/62] Loss: 0.05964 
Epoch [169/300] Training [42/62] Loss: 0.11711 
Epoch [169/300] Training [43/62] Loss: 0.05881 
Epoch [169/300] Training [44/62] Loss: 0.04722 
Epoch [169/300] Training [45/62] Loss: 0.19229 
Epoch [169/300] Training [46/62] Loss: 0.05379 
Epoch [169/300] Training [47/62] Loss: 0.04764 
Epoch [169/300] Training [48/62] Loss: 0.05377 
Epoch [169/300] Training [49/62] Loss: 0.04003 
Epoch [169/300] Training [50/62] Loss: 0.10292 
Epoch [169/300] Training [51/62] Loss: 0.04082 
Epoch [169/300] Training [52/62] Loss: 0.06454 
Epoch [169/300] Training [53/62] Loss: 0.17187 
Epoch [169/300] Training [54/62] Loss: 0.06689 
Epoch [169/300] Training [55/62] Loss: 0.04488 
Epoch [169/300] Training [56/62] Loss: 0.04700 
Epoch [169/300] Training [57/62] Loss: 0.06282 
Epoch [169/300] Training [58/62] Loss: 0.05251 
Epoch [169/300] Training [59/62] Loss: 0.04899 
Epoch [169/300] Training [60/62] Loss: 0.07931 
Epoch [169/300] Training [61/62] Loss: 0.07115 
Epoch [169/300] Training [62/62] Loss: 0.61468 
Epoch [169/300] Training metric {'Train/mean dice_metric': 0.9422733783721924, 'Train/mean miou_metric': 0.9019189476966858, 'Train/mean f1': 0.9540594220161438, 'Train/mean precision': 0.9523289799690247, 'Train/mean recall': 0.9557960033416748, 'Train/mean hd95_metric': 12.775611877441406}
Epoch [169/300] Validation [1/16] Loss: 0.60091  focal_loss 0.37253  dice_loss 0.22838 
Epoch [169/300] Validation [2/16] Loss: 0.45051  focal_loss 0.15362  dice_loss 0.29689 
Epoch [169/300] Validation [3/16] Loss: 0.65329  focal_loss 0.36480  dice_loss 0.28849 
Epoch [169/300] Validation [4/16] Loss: 0.31594  focal_loss 0.15564  dice_loss 0.16030 
Epoch [169/300] Validation [5/16] Loss: 0.34278  focal_loss 0.11141  dice_loss 0.23137 
Epoch [169/300] Validation [6/16] Loss: 0.32930  focal_loss 0.10959  dice_loss 0.21971 
Epoch [169/300] Validation [7/16] Loss: 0.26183  focal_loss 0.09226  dice_loss 0.16957 
Epoch [169/300] Validation [8/16] Loss: 0.46650  focal_loss 0.14240  dice_loss 0.32409 
Epoch [169/300] Validation [9/16] Loss: 0.28280  focal_loss 0.11445  dice_loss 0.16835 
Epoch [169/300] Validation [10/16] Loss: 0.48153  focal_loss 0.12370  dice_loss 0.35784 
Epoch [169/300] Validation [11/16] Loss: 0.15721  focal_loss 0.05302  dice_loss 0.10420 
Epoch [169/300] Validation [12/16] Loss: 0.47766  focal_loss 0.12577  dice_loss 0.35189 
Epoch [169/300] Validation [13/16] Loss: 0.21642  focal_loss 0.05656  dice_loss 0.15987 
Epoch [169/300] Validation [14/16] Loss: 0.52384  focal_loss 0.21177  dice_loss 0.31207 
Epoch [169/300] Validation [15/16] Loss: 0.19071  focal_loss 0.06542  dice_loss 0.12529 
Epoch [169/300] Validation [16/16] Loss: 0.14222  focal_loss 0.04392  dice_loss 0.09830 
Epoch [169/300] Validation metric {'Val/mean dice_metric': 0.9087638258934021, 'Val/mean miou_metric': 0.8583335280418396, 'Val/mean f1': 0.9269195199012756, 'Val/mean precision': 0.9327042698860168, 'Val/mean recall': 0.921205997467041, 'Val/mean hd95_metric': 22.079729080200195}
Cheakpoint...
Epoch [169/300] best acc:tensor([0.9088], device='cuda:0'), Now : mean acc: tensor([0.9088], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9087638258934021, 'Val/mean miou_metric': 0.8583335280418396, 'Val/mean f1': 0.9269195199012756, 'Val/mean precision': 0.9327042698860168, 'Val/mean recall': 0.921205997467041, 'Val/mean hd95_metric': 22.079729080200195}
Epoch [170/300] Training [1/62] Loss: 0.06598 
Epoch [170/300] Training [2/62] Loss: 0.10775 
Epoch [170/300] Training [3/62] Loss: 0.06218 
Epoch [170/300] Training [4/62] Loss: 0.07757 
Epoch [170/300] Training [5/62] Loss: 0.14862 
Epoch [170/300] Training [6/62] Loss: 0.07603 
Epoch [170/300] Training [7/62] Loss: 0.08697 
Epoch [170/300] Training [8/62] Loss: 0.06979 
Epoch [170/300] Training [9/62] Loss: 0.09243 
Epoch [170/300] Training [10/62] Loss: 0.07881 
Epoch [170/300] Training [11/62] Loss: 0.07088 
Epoch [170/300] Training [12/62] Loss: 0.11125 
Epoch [170/300] Training [13/62] Loss: 0.10074 
Epoch [170/300] Training [14/62] Loss: 0.07567 
Epoch [170/300] Training [15/62] Loss: 0.10961 
Epoch [170/300] Training [16/62] Loss: 0.05169 
Epoch [170/300] Training [17/62] Loss: 0.08912 
Epoch [170/300] Training [18/62] Loss: 0.14856 
Epoch [170/300] Training [19/62] Loss: 0.07342 
Epoch [170/300] Training [20/62] Loss: 0.10370 
Epoch [170/300] Training [21/62] Loss: 0.05892 
Epoch [170/300] Training [22/62] Loss: 0.04923 
Epoch [170/300] Training [23/62] Loss: 0.09245 
Epoch [170/300] Training [24/62] Loss: 0.08317 
Epoch [170/300] Training [25/62] Loss: 0.10077 
Epoch [170/300] Training [26/62] Loss: 0.10977 
Epoch [170/300] Training [27/62] Loss: 0.07178 
Epoch [170/300] Training [28/62] Loss: 0.04622 
Epoch [170/300] Training [29/62] Loss: 0.05962 
Epoch [170/300] Training [30/62] Loss: 0.06635 
Epoch [170/300] Training [31/62] Loss: 0.08035 
Epoch [170/300] Training [32/62] Loss: 0.06769 
Epoch [170/300] Training [33/62] Loss: 0.10610 
Epoch [170/300] Training [34/62] Loss: 0.19125 
Epoch [170/300] Training [35/62] Loss: 0.11329 
Epoch [170/300] Training [36/62] Loss: 0.08664 
Epoch [170/300] Training [37/62] Loss: 0.05507 
Epoch [170/300] Training [38/62] Loss: 0.04507 
Epoch [170/300] Training [39/62] Loss: 0.09628 
Epoch [170/300] Training [40/62] Loss: 0.04989 
Epoch [170/300] Training [41/62] Loss: 0.08175 
Epoch [170/300] Training [42/62] Loss: 0.05585 
Epoch [170/300] Training [43/62] Loss: 0.08194 
Epoch [170/300] Training [44/62] Loss: 0.07854 
Epoch [170/300] Training [45/62] Loss: 0.09462 
Epoch [170/300] Training [46/62] Loss: 0.06878 
Epoch [170/300] Training [47/62] Loss: 0.04733 
Epoch [170/300] Training [48/62] Loss: 0.08385 
Epoch [170/300] Training [49/62] Loss: 0.08391 
Epoch [170/300] Training [50/62] Loss: 0.09816 
Epoch [170/300] Training [51/62] Loss: 0.08178 
Epoch [170/300] Training [52/62] Loss: 0.06062 
Epoch [170/300] Training [53/62] Loss: 0.05744 
Epoch [170/300] Training [54/62] Loss: 0.19059 
Epoch [170/300] Training [55/62] Loss: 0.07213 
Epoch [170/300] Training [56/62] Loss: 0.05854 
Epoch [170/300] Training [57/62] Loss: 0.05598 
Epoch [170/300] Training [58/62] Loss: 0.11097 
Epoch [170/300] Training [59/62] Loss: 0.05577 
Epoch [170/300] Training [60/62] Loss: 0.07902 
Epoch [170/300] Training [61/62] Loss: 0.18750 
Epoch [170/300] Training [62/62] Loss: 0.24203 
Epoch [170/300] Training metric {'Train/mean dice_metric': 0.9419007301330566, 'Train/mean miou_metric': 0.8984680771827698, 'Train/mean f1': 0.9486704468727112, 'Train/mean precision': 0.9473373889923096, 'Train/mean recall': 0.9500070810317993, 'Train/mean hd95_metric': 17.060142517089844}
Epoch [170/300] Validation [1/16] Loss: 0.58945  focal_loss 0.37274  dice_loss 0.21670 
Epoch [170/300] Validation [2/16] Loss: 0.46314  focal_loss 0.17617  dice_loss 0.28696 
Epoch [170/300] Validation [3/16] Loss: 0.59848  focal_loss 0.31910  dice_loss 0.27938 
Epoch [170/300] Validation [4/16] Loss: 0.28373  focal_loss 0.12952  dice_loss 0.15422 
Epoch [170/300] Validation [5/16] Loss: 0.46275  focal_loss 0.13749  dice_loss 0.32526 
Epoch [170/300] Validation [6/16] Loss: 0.28759  focal_loss 0.08343  dice_loss 0.20416 
Epoch [170/300] Validation [7/16] Loss: 0.20709  focal_loss 0.06794  dice_loss 0.13915 
Epoch [170/300] Validation [8/16] Loss: 0.44882  focal_loss 0.15301  dice_loss 0.29582 
Epoch [170/300] Validation [9/16] Loss: 0.21932  focal_loss 0.09350  dice_loss 0.12582 
Epoch [170/300] Validation [10/16] Loss: 0.44755  focal_loss 0.13037  dice_loss 0.31718 
Epoch [170/300] Validation [11/16] Loss: 0.13842  focal_loss 0.04368  dice_loss 0.09474 
Epoch [170/300] Validation [12/16] Loss: 0.37336  focal_loss 0.10801  dice_loss 0.26535 
Epoch [170/300] Validation [13/16] Loss: 0.34621  focal_loss 0.12088  dice_loss 0.22533 
Epoch [170/300] Validation [14/16] Loss: 0.56652  focal_loss 0.23359  dice_loss 0.33294 
Epoch [170/300] Validation [15/16] Loss: 0.12657  focal_loss 0.03509  dice_loss 0.09148 
Epoch [170/300] Validation [16/16] Loss: 0.15277  focal_loss 0.05292  dice_loss 0.09985 
Epoch [170/300] Validation metric {'Val/mean dice_metric': 0.9103667736053467, 'Val/mean miou_metric': 0.8581100106239319, 'Val/mean f1': 0.923350989818573, 'Val/mean precision': 0.9281545877456665, 'Val/mean recall': 0.9185968637466431, 'Val/mean hd95_metric': 24.632577896118164}
Cheakpoint...
Epoch [170/300] best acc:tensor([0.9104], device='cuda:0'), Now : mean acc: tensor([0.9104], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9103667736053467, 'Val/mean miou_metric': 0.8581100106239319, 'Val/mean f1': 0.923350989818573, 'Val/mean precision': 0.9281545877456665, 'Val/mean recall': 0.9185968637466431, 'Val/mean hd95_metric': 24.632577896118164}
Epoch [171/300] Training [1/62] Loss: 0.04451 
Epoch [171/300] Training [2/62] Loss: 0.05373 
Epoch [171/300] Training [3/62] Loss: 0.05015 
Epoch [171/300] Training [4/62] Loss: 0.06596 
Epoch [171/300] Training [5/62] Loss: 0.06099 
Epoch [171/300] Training [6/62] Loss: 0.06375 
Epoch [171/300] Training [7/62] Loss: 0.08059 
Epoch [171/300] Training [8/62] Loss: 0.09391 
Epoch [171/300] Training [9/62] Loss: 0.04657 
Epoch [171/300] Training [10/62] Loss: 0.08322 
Epoch [171/300] Training [11/62] Loss: 0.06245 
Epoch [171/300] Training [12/62] Loss: 0.06775 
Epoch [171/300] Training [13/62] Loss: 0.17782 
Epoch [171/300] Training [14/62] Loss: 0.05629 
Epoch [171/300] Training [15/62] Loss: 0.09291 
Epoch [171/300] Training [16/62] Loss: 0.10963 
Epoch [171/300] Training [17/62] Loss: 0.06386 
Epoch [171/300] Training [18/62] Loss: 0.08644 
Epoch [171/300] Training [19/62] Loss: 0.09543 
Epoch [171/300] Training [20/62] Loss: 0.08399 
Epoch [171/300] Training [21/62] Loss: 0.05283 
Epoch [171/300] Training [22/62] Loss: 0.14835 
Epoch [171/300] Training [23/62] Loss: 0.05796 
Epoch [171/300] Training [24/62] Loss: 0.09306 
Epoch [171/300] Training [25/62] Loss: 0.12191 
Epoch [171/300] Training [26/62] Loss: 0.05773 
Epoch [171/300] Training [27/62] Loss: 0.04406 
Epoch [171/300] Training [28/62] Loss: 0.06178 
Epoch [171/300] Training [29/62] Loss: 0.06175 
Epoch [171/300] Training [30/62] Loss: 0.04498 
Epoch [171/300] Training [31/62] Loss: 0.11828 
Epoch [171/300] Training [32/62] Loss: 0.14387 
Epoch [171/300] Training [33/62] Loss: 0.05387 
Epoch [171/300] Training [34/62] Loss: 0.05809 
Epoch [171/300] Training [35/62] Loss: 0.06457 
Epoch [171/300] Training [36/62] Loss: 0.06148 
Epoch [171/300] Training [37/62] Loss: 0.06275 
Epoch [171/300] Training [38/62] Loss: 0.05280 
Epoch [171/300] Training [39/62] Loss: 0.08827 
Epoch [171/300] Training [40/62] Loss: 0.12082 
Epoch [171/300] Training [41/62] Loss: 0.06454 
Epoch [171/300] Training [42/62] Loss: 0.09173 
Epoch [171/300] Training [43/62] Loss: 0.06469 
Epoch [171/300] Training [44/62] Loss: 0.08300 
Epoch [171/300] Training [45/62] Loss: 0.16774 
Epoch [171/300] Training [46/62] Loss: 0.07547 
Epoch [171/300] Training [47/62] Loss: 0.04318 
Epoch [171/300] Training [48/62] Loss: 0.06308 
Epoch [171/300] Training [49/62] Loss: 0.22654 
Epoch [171/300] Training [50/62] Loss: 0.08490 
Epoch [171/300] Training [51/62] Loss: 0.17150 
Epoch [171/300] Training [52/62] Loss: 0.04697 
Epoch [171/300] Training [53/62] Loss: 0.13433 
Epoch [171/300] Training [54/62] Loss: 0.07412 
Epoch [171/300] Training [55/62] Loss: 0.04877 
Epoch [171/300] Training [56/62] Loss: 0.06123 
Epoch [171/300] Training [57/62] Loss: 0.08359 
Epoch [171/300] Training [58/62] Loss: 0.05401 
Epoch [171/300] Training [59/62] Loss: 0.07420 
Epoch [171/300] Training [60/62] Loss: 0.17483 
Epoch [171/300] Training [61/62] Loss: 0.14234 
Epoch [171/300] Training [62/62] Loss: 0.07221 
Epoch [171/300] Training metric {'Train/mean dice_metric': 0.943432629108429, 'Train/mean miou_metric': 0.902255117893219, 'Train/mean f1': 0.9501208662986755, 'Train/mean precision': 0.9486950635910034, 'Train/mean recall': 0.9515509605407715, 'Train/mean hd95_metric': 15.56689167022705}
Epoch [171/300] Validation [1/16] Loss: 0.64689  focal_loss 0.41215  dice_loss 0.23474 
Epoch [171/300] Validation [2/16] Loss: 0.58119  focal_loss 0.19014  dice_loss 0.39105 
Epoch [171/300] Validation [3/16] Loss: 0.60511  focal_loss 0.33012  dice_loss 0.27499 
Epoch [171/300] Validation [4/16] Loss: 0.32285  focal_loss 0.13047  dice_loss 0.19238 
Epoch [171/300] Validation [5/16] Loss: 0.36138  focal_loss 0.11748  dice_loss 0.24390 
Epoch [171/300] Validation [6/16] Loss: 0.30808  focal_loss 0.08741  dice_loss 0.22067 
Epoch [171/300] Validation [7/16] Loss: 0.31430  focal_loss 0.09917  dice_loss 0.21514 
Epoch [171/300] Validation [8/16] Loss: 0.46037  focal_loss 0.14277  dice_loss 0.31760 
Epoch [171/300] Validation [9/16] Loss: 0.26269  focal_loss 0.11481  dice_loss 0.14788 
Epoch [171/300] Validation [10/16] Loss: 0.49874  focal_loss 0.13284  dice_loss 0.36590 
Epoch [171/300] Validation [11/16] Loss: 0.16250  focal_loss 0.04699  dice_loss 0.11550 
Epoch [171/300] Validation [12/16] Loss: 0.37904  focal_loss 0.10125  dice_loss 0.27779 
Epoch [171/300] Validation [13/16] Loss: 0.21124  focal_loss 0.06013  dice_loss 0.15111 
Epoch [171/300] Validation [14/16] Loss: 0.53062  focal_loss 0.20243  dice_loss 0.32819 
Epoch [171/300] Validation [15/16] Loss: 0.09742  focal_loss 0.02509  dice_loss 0.07233 
Epoch [171/300] Validation [16/16] Loss: 0.16719  focal_loss 0.05236  dice_loss 0.11483 
Epoch [171/300] Validation metric {'Val/mean dice_metric': 0.909109890460968, 'Val/mean miou_metric': 0.858496367931366, 'Val/mean f1': 0.9235838651657104, 'Val/mean precision': 0.9320027232170105, 'Val/mean recall': 0.9153156876564026, 'Val/mean hd95_metric': 23.86199378967285}
Cheakpoint...
Epoch [171/300] best acc:tensor([0.9104], device='cuda:0'), Now : mean acc: tensor([0.9091], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.909109890460968, 'Val/mean miou_metric': 0.858496367931366, 'Val/mean f1': 0.9235838651657104, 'Val/mean precision': 0.9320027232170105, 'Val/mean recall': 0.9153156876564026, 'Val/mean hd95_metric': 23.86199378967285}
Epoch [172/300] Training [1/62] Loss: 0.04818 
Epoch [172/300] Training [2/62] Loss: 0.19972 
Epoch [172/300] Training [3/62] Loss: 0.08925 
Epoch [172/300] Training [4/62] Loss: 0.04082 
Epoch [172/300] Training [5/62] Loss: 0.13861 
Epoch [172/300] Training [6/62] Loss: 0.15205 
Epoch [172/300] Training [7/62] Loss: 0.05560 
Epoch [172/300] Training [8/62] Loss: 0.05729 
Epoch [172/300] Training [9/62] Loss: 0.04965 
Epoch [172/300] Training [10/62] Loss: 0.06924 
Epoch [172/300] Training [11/62] Loss: 0.04787 
Epoch [172/300] Training [12/62] Loss: 0.05397 
Epoch [172/300] Training [13/62] Loss: 0.12632 
Epoch [172/300] Training [14/62] Loss: 0.10830 
Epoch [172/300] Training [15/62] Loss: 0.04380 
Epoch [172/300] Training [16/62] Loss: 0.13329 
Epoch [172/300] Training [17/62] Loss: 0.11354 
Epoch [172/300] Training [18/62] Loss: 0.09112 
Epoch [172/300] Training [19/62] Loss: 0.10771 
Epoch [172/300] Training [20/62] Loss: 0.17704 
Epoch [172/300] Training [21/62] Loss: 0.05243 
Epoch [172/300] Training [22/62] Loss: 0.07617 
Epoch [172/300] Training [23/62] Loss: 0.06570 
Epoch [172/300] Training [24/62] Loss: 0.11406 
Epoch [172/300] Training [25/62] Loss: 0.09476 
Epoch [172/300] Training [26/62] Loss: 0.07031 
Epoch [172/300] Training [27/62] Loss: 0.04415 
Epoch [172/300] Training [28/62] Loss: 0.06598 
Epoch [172/300] Training [29/62] Loss: 0.07825 
Epoch [172/300] Training [30/62] Loss: 0.04578 
Epoch [172/300] Training [31/62] Loss: 0.04707 
Epoch [172/300] Training [32/62] Loss: 0.03910 
Epoch [172/300] Training [33/62] Loss: 0.05925 
Epoch [172/300] Training [34/62] Loss: 0.15926 
Epoch [172/300] Training [35/62] Loss: 0.07768 
Epoch [172/300] Training [36/62] Loss: 0.05441 
Epoch [172/300] Training [37/62] Loss: 0.10391 
Epoch [172/300] Training [38/62] Loss: 0.08618 
Epoch [172/300] Training [39/62] Loss: 0.07327 
Epoch [172/300] Training [40/62] Loss: 0.29298 
Epoch [172/300] Training [41/62] Loss: 0.05863 
Epoch [172/300] Training [42/62] Loss: 0.04310 
Epoch [172/300] Training [43/62] Loss: 0.08990 
Epoch [172/300] Training [44/62] Loss: 0.05694 
Epoch [172/300] Training [45/62] Loss: 0.13509 
Epoch [172/300] Training [46/62] Loss: 0.05025 
Epoch [172/300] Training [47/62] Loss: 0.07155 
Epoch [172/300] Training [48/62] Loss: 0.04797 
Epoch [172/300] Training [49/62] Loss: 0.05121 
Epoch [172/300] Training [50/62] Loss: 0.03932 
Epoch [172/300] Training [51/62] Loss: 0.07072 
Epoch [172/300] Training [52/62] Loss: 0.12680 
Epoch [172/300] Training [53/62] Loss: 0.08231 
Epoch [172/300] Training [54/62] Loss: 0.06384 
Epoch [172/300] Training [55/62] Loss: 0.07865 
Epoch [172/300] Training [56/62] Loss: 0.17260 
Epoch [172/300] Training [57/62] Loss: 0.05985 
Epoch [172/300] Training [58/62] Loss: 0.11316 
Epoch [172/300] Training [59/62] Loss: 0.07295 
Epoch [172/300] Training [60/62] Loss: 0.07966 
Epoch [172/300] Training [61/62] Loss: 0.16447 
Epoch [172/300] Training [62/62] Loss: 0.05834 
Epoch [172/300] Training metric {'Train/mean dice_metric': 0.9401844143867493, 'Train/mean miou_metric': 0.8984703421592712, 'Train/mean f1': 0.9500963091850281, 'Train/mean precision': 0.9495436549186707, 'Train/mean recall': 0.9506494998931885, 'Train/mean hd95_metric': 15.604758262634277}
Epoch [172/300] Validation [1/16] Loss: 0.70994  focal_loss 0.47044  dice_loss 0.23950 
Epoch [172/300] Validation [2/16] Loss: 0.56480  focal_loss 0.20591  dice_loss 0.35888 
Epoch [172/300] Validation [3/16] Loss: 0.64445  focal_loss 0.35407  dice_loss 0.29038 
Epoch [172/300] Validation [4/16] Loss: 0.33527  focal_loss 0.14930  dice_loss 0.18597 
Epoch [172/300] Validation [5/16] Loss: 0.30058  focal_loss 0.09340  dice_loss 0.20718 
Epoch [172/300] Validation [6/16] Loss: 0.33826  focal_loss 0.09743  dice_loss 0.24084 
Epoch [172/300] Validation [7/16] Loss: 0.24114  focal_loss 0.09958  dice_loss 0.14157 
Epoch [172/300] Validation [8/16] Loss: 0.54302  focal_loss 0.17785  dice_loss 0.36516 
Epoch [172/300] Validation [9/16] Loss: 0.34866  focal_loss 0.15687  dice_loss 0.19178 
Epoch [172/300] Validation [10/16] Loss: 0.49150  focal_loss 0.13627  dice_loss 0.35522 
Epoch [172/300] Validation [11/16] Loss: 0.23059  focal_loss 0.07372  dice_loss 0.15686 
Epoch [172/300] Validation [12/16] Loss: 0.47759  focal_loss 0.10274  dice_loss 0.37485 
Epoch [172/300] Validation [13/16] Loss: 0.23863  focal_loss 0.06976  dice_loss 0.16888 
Epoch [172/300] Validation [14/16] Loss: 0.61018  focal_loss 0.20435  dice_loss 0.40582 
Epoch [172/300] Validation [15/16] Loss: 0.15386  focal_loss 0.04485  dice_loss 0.10902 
Epoch [172/300] Validation [16/16] Loss: 0.10084  focal_loss 0.04100  dice_loss 0.05984 
Epoch [172/300] Validation metric {'Val/mean dice_metric': 0.9037066698074341, 'Val/mean miou_metric': 0.851872980594635, 'Val/mean f1': 0.9223002195358276, 'Val/mean precision': 0.9354198575019836, 'Val/mean recall': 0.9095435738563538, 'Val/mean hd95_metric': 22.02899169921875}
Cheakpoint...
Epoch [172/300] best acc:tensor([0.9104], device='cuda:0'), Now : mean acc: tensor([0.9037], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9037066698074341, 'Val/mean miou_metric': 0.851872980594635, 'Val/mean f1': 0.9223002195358276, 'Val/mean precision': 0.9354198575019836, 'Val/mean recall': 0.9095435738563538, 'Val/mean hd95_metric': 22.02899169921875}
Epoch [173/300] Training [1/62] Loss: 0.09761 
Epoch [173/300] Training [2/62] Loss: 0.21135 
Epoch [173/300] Training [3/62] Loss: 0.04831 
Epoch [173/300] Training [4/62] Loss: 0.11530 
Epoch [173/300] Training [5/62] Loss: 0.09052 
Epoch [173/300] Training [6/62] Loss: 0.08133 
Epoch [173/300] Training [7/62] Loss: 0.05370 
Epoch [173/300] Training [8/62] Loss: 0.04772 
Epoch [173/300] Training [9/62] Loss: 0.06787 
Epoch [173/300] Training [10/62] Loss: 0.04536 
Epoch [173/300] Training [11/62] Loss: 0.08416 
Epoch [173/300] Training [12/62] Loss: 0.04521 
Epoch [173/300] Training [13/62] Loss: 0.13060 
Epoch [173/300] Training [14/62] Loss: 0.05162 
Epoch [173/300] Training [15/62] Loss: 0.08498 
Epoch [173/300] Training [16/62] Loss: 0.04332 
Epoch [173/300] Training [17/62] Loss: 0.05988 
Epoch [173/300] Training [18/62] Loss: 0.08992 
Epoch [173/300] Training [19/62] Loss: 0.11159 
Epoch [173/300] Training [20/62] Loss: 0.06162 
Epoch [173/300] Training [21/62] Loss: 0.05627 
Epoch [173/300] Training [22/62] Loss: 0.04708 
Epoch [173/300] Training [23/62] Loss: 0.05944 
Epoch [173/300] Training [24/62] Loss: 0.26520 
Epoch [173/300] Training [25/62] Loss: 0.05941 
Epoch [173/300] Training [26/62] Loss: 0.08278 
Epoch [173/300] Training [27/62] Loss: 0.05552 
Epoch [173/300] Training [28/62] Loss: 0.07754 
Epoch [173/300] Training [29/62] Loss: 0.05355 
Epoch [173/300] Training [30/62] Loss: 0.05226 
Epoch [173/300] Training [31/62] Loss: 0.09515 
Epoch [173/300] Training [32/62] Loss: 0.04381 
Epoch [173/300] Training [33/62] Loss: 0.15826 
Epoch [173/300] Training [34/62] Loss: 0.14184 
Epoch [173/300] Training [35/62] Loss: 0.06760 
Epoch [173/300] Training [36/62] Loss: 0.06146 
Epoch [173/300] Training [37/62] Loss: 0.05675 
Epoch [173/300] Training [38/62] Loss: 0.05479 
Epoch [173/300] Training [39/62] Loss: 0.08858 
Epoch [173/300] Training [40/62] Loss: 0.06122 
Epoch [173/300] Training [41/62] Loss: 0.05730 
Epoch [173/300] Training [42/62] Loss: 0.05942 
Epoch [173/300] Training [43/62] Loss: 0.08537 
Epoch [173/300] Training [44/62] Loss: 0.23107 
Epoch [173/300] Training [45/62] Loss: 0.18095 
Epoch [173/300] Training [46/62] Loss: 0.08387 
Epoch [173/300] Training [47/62] Loss: 0.08641 
Epoch [173/300] Training [48/62] Loss: 0.11856 
Epoch [173/300] Training [49/62] Loss: 0.07072 
Epoch [173/300] Training [50/62] Loss: 0.04325 
Epoch [173/300] Training [51/62] Loss: 0.04149 
Epoch [173/300] Training [52/62] Loss: 0.05454 
Epoch [173/300] Training [53/62] Loss: 0.07119 
Epoch [173/300] Training [54/62] Loss: 0.15047 
Epoch [173/300] Training [55/62] Loss: 0.15654 
Epoch [173/300] Training [56/62] Loss: 0.11835 
Epoch [173/300] Training [57/62] Loss: 0.05940 
Epoch [173/300] Training [58/62] Loss: 0.16918 
Epoch [173/300] Training [59/62] Loss: 0.09165 
Epoch [173/300] Training [60/62] Loss: 0.06707 
Epoch [173/300] Training [61/62] Loss: 0.08895 
Epoch [173/300] Training [62/62] Loss: 0.04012 
Epoch [173/300] Training metric {'Train/mean dice_metric': 0.9415929913520813, 'Train/mean miou_metric': 0.8992785215377808, 'Train/mean f1': 0.9484415054321289, 'Train/mean precision': 0.9470869898796082, 'Train/mean recall': 0.9498000144958496, 'Train/mean hd95_metric': 15.783763885498047}
Epoch [173/300] Validation [1/16] Loss: 0.61993  focal_loss 0.40467  dice_loss 0.21526 
Epoch [173/300] Validation [2/16] Loss: 0.45905  focal_loss 0.16469  dice_loss 0.29436 
Epoch [173/300] Validation [3/16] Loss: 0.55191  focal_loss 0.27131  dice_loss 0.28060 
Epoch [173/300] Validation [4/16] Loss: 0.35095  focal_loss 0.13911  dice_loss 0.21183 
Epoch [173/300] Validation [5/16] Loss: 0.47152  focal_loss 0.14384  dice_loss 0.32768 
Epoch [173/300] Validation [6/16] Loss: 0.31151  focal_loss 0.10485  dice_loss 0.20666 
Epoch [173/300] Validation [7/16] Loss: 0.17937  focal_loss 0.06749  dice_loss 0.11188 
Epoch [173/300] Validation [8/16] Loss: 0.46053  focal_loss 0.14503  dice_loss 0.31551 
Epoch [173/300] Validation [9/16] Loss: 0.31759  focal_loss 0.11656  dice_loss 0.20103 
Epoch [173/300] Validation [10/16] Loss: 0.68655  focal_loss 0.24507  dice_loss 0.44148 
Epoch [173/300] Validation [11/16] Loss: 0.22883  focal_loss 0.05435  dice_loss 0.17448 
Epoch [173/300] Validation [12/16] Loss: 0.37124  focal_loss 0.08594  dice_loss 0.28530 
Epoch [173/300] Validation [13/16] Loss: 0.21450  focal_loss 0.06186  dice_loss 0.15264 
Epoch [173/300] Validation [14/16] Loss: 0.65211  focal_loss 0.22562  dice_loss 0.42649 
Epoch [173/300] Validation [15/16] Loss: 0.11641  focal_loss 0.03516  dice_loss 0.08125 
Epoch [173/300] Validation [16/16] Loss: 0.25041  focal_loss 0.09399  dice_loss 0.15643 
Epoch [173/300] Validation metric {'Val/mean dice_metric': 0.9054607152938843, 'Val/mean miou_metric': 0.8526516556739807, 'Val/mean f1': 0.9177723526954651, 'Val/mean precision': 0.9196780920028687, 'Val/mean recall': 0.915874719619751, 'Val/mean hd95_metric': 26.85442352294922}
Cheakpoint...
Epoch [173/300] best acc:tensor([0.9104], device='cuda:0'), Now : mean acc: tensor([0.9055], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9054607152938843, 'Val/mean miou_metric': 0.8526516556739807, 'Val/mean f1': 0.9177723526954651, 'Val/mean precision': 0.9196780920028687, 'Val/mean recall': 0.915874719619751, 'Val/mean hd95_metric': 26.85442352294922}
Epoch [174/300] Training [1/62] Loss: 0.04784 
Epoch [174/300] Training [2/62] Loss: 0.12495 
Epoch [174/300] Training [3/62] Loss: 0.09974 
Epoch [174/300] Training [4/62] Loss: 0.07978 
Epoch [174/300] Training [5/62] Loss: 0.07162 
Epoch [174/300] Training [6/62] Loss: 0.07325 
Epoch [174/300] Training [7/62] Loss: 0.08879 
Epoch [174/300] Training [8/62] Loss: 0.16842 
Epoch [174/300] Training [9/62] Loss: 0.05321 
Epoch [174/300] Training [10/62] Loss: 0.11111 
Epoch [174/300] Training [11/62] Loss: 0.06959 
Epoch [174/300] Training [12/62] Loss: 0.17362 
Epoch [174/300] Training [13/62] Loss: 0.07949 
Epoch [174/300] Training [14/62] Loss: 0.07624 
Epoch [174/300] Training [15/62] Loss: 0.06646 
Epoch [174/300] Training [16/62] Loss: 0.05007 
Epoch [174/300] Training [17/62] Loss: 0.25388 
Epoch [174/300] Training [18/62] Loss: 0.07244 
Epoch [174/300] Training [19/62] Loss: 0.05931 
Epoch [174/300] Training [20/62] Loss: 0.06292 
Epoch [174/300] Training [21/62] Loss: 0.06227 
Epoch [174/300] Training [22/62] Loss: 0.08698 
Epoch [174/300] Training [23/62] Loss: 0.07342 
Epoch [174/300] Training [24/62] Loss: 0.07361 
Epoch [174/300] Training [25/62] Loss: 0.04588 
Epoch [174/300] Training [26/62] Loss: 0.09352 
Epoch [174/300] Training [27/62] Loss: 0.05789 
Epoch [174/300] Training [28/62] Loss: 0.08371 
Epoch [174/300] Training [29/62] Loss: 0.08852 
Epoch [174/300] Training [30/62] Loss: 0.05182 
Epoch [174/300] Training [31/62] Loss: 0.07343 
Epoch [174/300] Training [32/62] Loss: 0.06705 
Epoch [174/300] Training [33/62] Loss: 0.07042 
Epoch [174/300] Training [34/62] Loss: 0.06191 
Epoch [174/300] Training [35/62] Loss: 0.06072 
Epoch [174/300] Training [36/62] Loss: 0.08234 
Epoch [174/300] Training [37/62] Loss: 0.09046 
Epoch [174/300] Training [38/62] Loss: 0.06017 
Epoch [174/300] Training [39/62] Loss: 0.16358 
Epoch [174/300] Training [40/62] Loss: 0.04946 
Epoch [174/300] Training [41/62] Loss: 0.09563 
Epoch [174/300] Training [42/62] Loss: 0.05205 
Epoch [174/300] Training [43/62] Loss: 0.10219 
Epoch [174/300] Training [44/62] Loss: 0.08213 
Epoch [174/300] Training [45/62] Loss: 0.12926 
Epoch [174/300] Training [46/62] Loss: 0.06520 
Epoch [174/300] Training [47/62] Loss: 0.06309 
Epoch [174/300] Training [48/62] Loss: 0.08499 
Epoch [174/300] Training [49/62] Loss: 0.04222 
Epoch [174/300] Training [50/62] Loss: 0.06023 
Epoch [174/300] Training [51/62] Loss: 0.12191 
Epoch [174/300] Training [52/62] Loss: 0.10192 
Epoch [174/300] Training [53/62] Loss: 0.09570 
Epoch [174/300] Training [54/62] Loss: 0.11788 
Epoch [174/300] Training [55/62] Loss: 0.07580 
Epoch [174/300] Training [56/62] Loss: 0.05619 
Epoch [174/300] Training [57/62] Loss: 0.08654 
Epoch [174/300] Training [58/62] Loss: 0.09938 
Epoch [174/300] Training [59/62] Loss: 0.03916 
Epoch [174/300] Training [60/62] Loss: 0.06096 
Epoch [174/300] Training [61/62] Loss: 0.06556 
Epoch [174/300] Training [62/62] Loss: 0.25571 
Epoch [174/300] Training metric {'Train/mean dice_metric': 0.9432482123374939, 'Train/mean miou_metric': 0.9006615877151489, 'Train/mean f1': 0.9509150385856628, 'Train/mean precision': 0.9488574266433716, 'Train/mean recall': 0.9529815316200256, 'Train/mean hd95_metric': 17.49275779724121}
Epoch [174/300] Validation [1/16] Loss: 0.61692  focal_loss 0.40254  dice_loss 0.21438 
Epoch [174/300] Validation [2/16] Loss: 0.48752  focal_loss 0.17857  dice_loss 0.30895 
Epoch [174/300] Validation [3/16] Loss: 0.57514  focal_loss 0.28345  dice_loss 0.29168 
Epoch [174/300] Validation [4/16] Loss: 0.30821  focal_loss 0.13856  dice_loss 0.16965 
Epoch [174/300] Validation [5/16] Loss: 0.43640  focal_loss 0.13916  dice_loss 0.29724 
Epoch [174/300] Validation [6/16] Loss: 0.38724  focal_loss 0.13548  dice_loss 0.25175 
Epoch [174/300] Validation [7/16] Loss: 0.16317  focal_loss 0.06262  dice_loss 0.10055 
Epoch [174/300] Validation [8/16] Loss: 0.42014  focal_loss 0.13790  dice_loss 0.28223 
Epoch [174/300] Validation [9/16] Loss: 0.24576  focal_loss 0.09724  dice_loss 0.14852 
Epoch [174/300] Validation [10/16] Loss: 0.78650  focal_loss 0.30328  dice_loss 0.48322 
Epoch [174/300] Validation [11/16] Loss: 0.24750  focal_loss 0.07559  dice_loss 0.17191 
Epoch [174/300] Validation [12/16] Loss: 0.45644  focal_loss 0.11734  dice_loss 0.33910 
Epoch [174/300] Validation [13/16] Loss: 0.24974  focal_loss 0.09326  dice_loss 0.15649 
Epoch [174/300] Validation [14/16] Loss: 0.52494  focal_loss 0.20558  dice_loss 0.31936 
Epoch [174/300] Validation [15/16] Loss: 0.12542  focal_loss 0.04616  dice_loss 0.07927 
Epoch [174/300] Validation [16/16] Loss: 0.10955  focal_loss 0.03185  dice_loss 0.07771 
Epoch [174/300] Validation metric {'Val/mean dice_metric': 0.9082677364349365, 'Val/mean miou_metric': 0.8566927313804626, 'Val/mean f1': 0.9235501885414124, 'Val/mean precision': 0.9284433126449585, 'Val/mean recall': 0.9187082052230835, 'Val/mean hd95_metric': 25.122533798217773}
Cheakpoint...
Epoch [174/300] best acc:tensor([0.9104], device='cuda:0'), Now : mean acc: tensor([0.9083], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9082677364349365, 'Val/mean miou_metric': 0.8566927313804626, 'Val/mean f1': 0.9235501885414124, 'Val/mean precision': 0.9284433126449585, 'Val/mean recall': 0.9187082052230835, 'Val/mean hd95_metric': 25.122533798217773}
Epoch [175/300] Training [1/62] Loss: 0.07517 
Epoch [175/300] Training [2/62] Loss: 0.10123 
Epoch [175/300] Training [3/62] Loss: 0.08521 
Epoch [175/300] Training [4/62] Loss: 0.04976 
Epoch [175/300] Training [5/62] Loss: 0.06800 
Epoch [175/300] Training [6/62] Loss: 0.08197 
Epoch [175/300] Training [7/62] Loss: 0.04792 
Epoch [175/300] Training [8/62] Loss: 0.04744 
Epoch [175/300] Training [9/62] Loss: 0.13296 
Epoch [175/300] Training [10/62] Loss: 0.05452 
Epoch [175/300] Training [11/62] Loss: 0.05850 
Epoch [175/300] Training [12/62] Loss: 0.05957 
Epoch [175/300] Training [13/62] Loss: 0.08083 
Epoch [175/300] Training [14/62] Loss: 0.10095 
Epoch [175/300] Training [15/62] Loss: 0.07854 
Epoch [175/300] Training [16/62] Loss: 0.04586 
Epoch [175/300] Training [17/62] Loss: 0.08471 
Epoch [175/300] Training [18/62] Loss: 0.17546 
Epoch [175/300] Training [19/62] Loss: 0.05829 
Epoch [175/300] Training [20/62] Loss: 0.05314 
Epoch [175/300] Training [21/62] Loss: 0.08795 
Epoch [175/300] Training [22/62] Loss: 0.05601 
Epoch [175/300] Training [23/62] Loss: 0.05691 
Epoch [175/300] Training [24/62] Loss: 0.14281 
Epoch [175/300] Training [25/62] Loss: 0.09350 
Epoch [175/300] Training [26/62] Loss: 0.05567 
Epoch [175/300] Training [27/62] Loss: 0.10833 
Epoch [175/300] Training [28/62] Loss: 0.05233 
Epoch [175/300] Training [29/62] Loss: 0.06300 
Epoch [175/300] Training [30/62] Loss: 0.15710 
Epoch [175/300] Training [31/62] Loss: 0.11868 
Epoch [175/300] Training [32/62] Loss: 0.08979 
Epoch [175/300] Training [33/62] Loss: 0.07207 
Epoch [175/300] Training [34/62] Loss: 0.08571 
Epoch [175/300] Training [35/62] Loss: 0.07520 
Epoch [175/300] Training [36/62] Loss: 0.14550 
Epoch [175/300] Training [37/62] Loss: 0.12819 
Epoch [175/300] Training [38/62] Loss: 0.15528 
Epoch [175/300] Training [39/62] Loss: 0.04834 
Epoch [175/300] Training [40/62] Loss: 0.07581 
Epoch [175/300] Training [41/62] Loss: 0.04986 
Epoch [175/300] Training [42/62] Loss: 0.07645 
Epoch [175/300] Training [43/62] Loss: 0.07729 
Epoch [175/300] Training [44/62] Loss: 0.09023 
Epoch [175/300] Training [45/62] Loss: 0.08815 
Epoch [175/300] Training [46/62] Loss: 0.22237 
Epoch [175/300] Training [47/62] Loss: 0.05748 
Epoch [175/300] Training [48/62] Loss: 0.06353 
Epoch [175/300] Training [49/62] Loss: 0.04478 
Epoch [175/300] Training [50/62] Loss: 0.05122 
Epoch [175/300] Training [51/62] Loss: 0.05216 
Epoch [175/300] Training [52/62] Loss: 0.10737 
Epoch [175/300] Training [53/62] Loss: 0.05670 
Epoch [175/300] Training [54/62] Loss: 0.05150 
Epoch [175/300] Training [55/62] Loss: 0.09360 
Epoch [175/300] Training [56/62] Loss: 0.07224 
Epoch [175/300] Training [57/62] Loss: 0.08520 
Epoch [175/300] Training [58/62] Loss: 0.10784 
Epoch [175/300] Training [59/62] Loss: 0.05583 
Epoch [175/300] Training [60/62] Loss: 0.16707 
Epoch [175/300] Training [61/62] Loss: 0.08191 
Epoch [175/300] Training [62/62] Loss: 0.58796 
Epoch [175/300] Training metric {'Train/mean dice_metric': 0.9427444338798523, 'Train/mean miou_metric': 0.8997241258621216, 'Train/mean f1': 0.9504809379577637, 'Train/mean precision': 0.9517826437950134, 'Train/mean recall': 0.9491827487945557, 'Train/mean hd95_metric': 15.100131034851074}
Epoch [175/300] Validation [1/16] Loss: 0.69773  focal_loss 0.45495  dice_loss 0.24278 
Epoch [175/300] Validation [2/16] Loss: 0.49933  focal_loss 0.18919  dice_loss 0.31014 
Epoch [175/300] Validation [3/16] Loss: 0.63479  focal_loss 0.34506  dice_loss 0.28974 
Epoch [175/300] Validation [4/16] Loss: 0.26558  focal_loss 0.12569  dice_loss 0.13988 
Epoch [175/300] Validation [5/16] Loss: 0.37264  focal_loss 0.11778  dice_loss 0.25486 
Epoch [175/300] Validation [6/16] Loss: 0.27429  focal_loss 0.07064  dice_loss 0.20365 
Epoch [175/300] Validation [7/16] Loss: 0.16724  focal_loss 0.06735  dice_loss 0.09989 
Epoch [175/300] Validation [8/16] Loss: 0.47370  focal_loss 0.15155  dice_loss 0.32215 
Epoch [175/300] Validation [9/16] Loss: 0.17308  focal_loss 0.06296  dice_loss 0.11012 
Epoch [175/300] Validation [10/16] Loss: 0.57809  focal_loss 0.20810  dice_loss 0.36999 
Epoch [175/300] Validation [11/16] Loss: 0.16666  focal_loss 0.04725  dice_loss 0.11941 
Epoch [175/300] Validation [12/16] Loss: 0.49129  focal_loss 0.11316  dice_loss 0.37813 
Epoch [175/300] Validation [13/16] Loss: 0.23391  focal_loss 0.07984  dice_loss 0.15407 
Epoch [175/300] Validation [14/16] Loss: 0.53826  focal_loss 0.19528  dice_loss 0.34297 
Epoch [175/300] Validation [15/16] Loss: 0.12932  focal_loss 0.04350  dice_loss 0.08582 
Epoch [175/300] Validation [16/16] Loss: 0.09023  focal_loss 0.02181  dice_loss 0.06842 
Epoch [175/300] Validation metric {'Val/mean dice_metric': 0.9105510115623474, 'Val/mean miou_metric': 0.8591631650924683, 'Val/mean f1': 0.9244876503944397, 'Val/mean precision': 0.9359090924263, 'Val/mean recall': 0.9133415818214417, 'Val/mean hd95_metric': 22.00747299194336}
Cheakpoint...
Epoch [175/300] best acc:tensor([0.9106], device='cuda:0'), Now : mean acc: tensor([0.9106], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9105510115623474, 'Val/mean miou_metric': 0.8591631650924683, 'Val/mean f1': 0.9244876503944397, 'Val/mean precision': 0.9359090924263, 'Val/mean recall': 0.9133415818214417, 'Val/mean hd95_metric': 22.00747299194336}
Epoch [176/300] Training [1/62] Loss: 0.05581 
Epoch [176/300] Training [2/62] Loss: 0.05598 
Epoch [176/300] Training [3/62] Loss: 0.12429 
Epoch [176/300] Training [4/62] Loss: 0.05314 
Epoch [176/300] Training [5/62] Loss: 0.05964 
Epoch [176/300] Training [6/62] Loss: 0.09824 
Epoch [176/300] Training [7/62] Loss: 0.10287 
Epoch [176/300] Training [8/62] Loss: 0.08035 
Epoch [176/300] Training [9/62] Loss: 0.08306 
Epoch [176/300] Training [10/62] Loss: 0.05934 
Epoch [176/300] Training [11/62] Loss: 0.33355 
Epoch [176/300] Training [12/62] Loss: 0.12037 
Epoch [176/300] Training [13/62] Loss: 0.08648 
Epoch [176/300] Training [14/62] Loss: 0.04339 
Epoch [176/300] Training [15/62] Loss: 0.11163 
Epoch [176/300] Training [16/62] Loss: 0.08723 
Epoch [176/300] Training [17/62] Loss: 0.06718 
Epoch [176/300] Training [18/62] Loss: 0.05986 
Epoch [176/300] Training [19/62] Loss: 0.08734 
Epoch [176/300] Training [20/62] Loss: 0.05974 
Epoch [176/300] Training [21/62] Loss: 0.09708 
Epoch [176/300] Training [22/62] Loss: 0.06774 
Epoch [176/300] Training [23/62] Loss: 0.10790 
Epoch [176/300] Training [24/62] Loss: 0.06142 
Epoch [176/300] Training [25/62] Loss: 0.06283 
Epoch [176/300] Training [26/62] Loss: 0.05144 
Epoch [176/300] Training [27/62] Loss: 0.04692 
Epoch [176/300] Training [28/62] Loss: 0.09268 
Epoch [176/300] Training [29/62] Loss: 0.04252 
Epoch [176/300] Training [30/62] Loss: 0.05429 
Epoch [176/300] Training [31/62] Loss: 0.17536 
Epoch [176/300] Training [32/62] Loss: 0.09560 
Epoch [176/300] Training [33/62] Loss: 0.04754 
Epoch [176/300] Training [34/62] Loss: 0.05680 
Epoch [176/300] Training [35/62] Loss: 0.06874 
Epoch [176/300] Training [36/62] Loss: 0.04482 
Epoch [176/300] Training [37/62] Loss: 0.07181 
Epoch [176/300] Training [38/62] Loss: 0.04013 
Epoch [176/300] Training [39/62] Loss: 0.05225 
Epoch [176/300] Training [40/62] Loss: 0.05766 
Epoch [176/300] Training [41/62] Loss: 0.07894 
Epoch [176/300] Training [42/62] Loss: 0.05670 
Epoch [176/300] Training [43/62] Loss: 0.09591 
Epoch [176/300] Training [44/62] Loss: 0.07495 
Epoch [176/300] Training [45/62] Loss: 0.14216 
Epoch [176/300] Training [46/62] Loss: 0.05740 
Epoch [176/300] Training [47/62] Loss: 0.05717 
Epoch [176/300] Training [48/62] Loss: 0.06314 
Epoch [176/300] Training [49/62] Loss: 0.10212 
Epoch [176/300] Training [50/62] Loss: 0.05892 
Epoch [176/300] Training [51/62] Loss: 0.10001 
Epoch [176/300] Training [52/62] Loss: 0.06237 
Epoch [176/300] Training [53/62] Loss: 0.09903 
Epoch [176/300] Training [54/62] Loss: 0.17031 
Epoch [176/300] Training [55/62] Loss: 0.07814 
Epoch [176/300] Training [56/62] Loss: 0.06104 
Epoch [176/300] Training [57/62] Loss: 0.04061 
Epoch [176/300] Training [58/62] Loss: 0.05498 
Epoch [176/300] Training [59/62] Loss: 0.12268 
Epoch [176/300] Training [60/62] Loss: 0.09399 
Epoch [176/300] Training [61/62] Loss: 0.09800 
Epoch [176/300] Training [62/62] Loss: 0.40660 
Epoch [176/300] Training metric {'Train/mean dice_metric': 0.9454653263092041, 'Train/mean miou_metric': 0.9043552875518799, 'Train/mean f1': 0.9501311182975769, 'Train/mean precision': 0.9473230838775635, 'Train/mean recall': 0.9529557824134827, 'Train/mean hd95_metric': 14.649601936340332}
Epoch [176/300] Validation [1/16] Loss: 0.67195  focal_loss 0.42986  dice_loss 0.24209 
Epoch [176/300] Validation [2/16] Loss: 0.47860  focal_loss 0.17441  dice_loss 0.30418 
Epoch [176/300] Validation [3/16] Loss: 0.62740  focal_loss 0.34711  dice_loss 0.28028 
Epoch [176/300] Validation [4/16] Loss: 0.31758  focal_loss 0.13658  dice_loss 0.18100 
Epoch [176/300] Validation [5/16] Loss: 0.34116  focal_loss 0.12149  dice_loss 0.21967 
Epoch [176/300] Validation [6/16] Loss: 0.25159  focal_loss 0.06526  dice_loss 0.18633 
Epoch [176/300] Validation [7/16] Loss: 0.19778  focal_loss 0.07891  dice_loss 0.11888 
Epoch [176/300] Validation [8/16] Loss: 0.50585  focal_loss 0.17838  dice_loss 0.32748 
Epoch [176/300] Validation [9/16] Loss: 0.25794  focal_loss 0.10860  dice_loss 0.14934 
Epoch [176/300] Validation [10/16] Loss: 0.51693  focal_loss 0.16219  dice_loss 0.35473 
Epoch [176/300] Validation [11/16] Loss: 0.26216  focal_loss 0.07776  dice_loss 0.18441 
Epoch [176/300] Validation [12/16] Loss: 0.41583  focal_loss 0.12324  dice_loss 0.29258 
Epoch [176/300] Validation [13/16] Loss: 0.25285  focal_loss 0.08940  dice_loss 0.16345 
Epoch [176/300] Validation [14/16] Loss: 0.59856  focal_loss 0.22985  dice_loss 0.36871 
Epoch [176/300] Validation [15/16] Loss: 0.11539  focal_loss 0.03750  dice_loss 0.07789 
Epoch [176/300] Validation [16/16] Loss: 0.08264  focal_loss 0.02168  dice_loss 0.06096 
Epoch [176/300] Validation metric {'Val/mean dice_metric': 0.9122499823570251, 'Val/mean miou_metric': 0.861567497253418, 'Val/mean f1': 0.9236964583396912, 'Val/mean precision': 0.9349309206008911, 'Val/mean recall': 0.9127286076545715, 'Val/mean hd95_metric': 21.49677276611328}
Cheakpoint...
Epoch [176/300] best acc:tensor([0.9122], device='cuda:0'), Now : mean acc: tensor([0.9122], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9122499823570251, 'Val/mean miou_metric': 0.861567497253418, 'Val/mean f1': 0.9236964583396912, 'Val/mean precision': 0.9349309206008911, 'Val/mean recall': 0.9127286076545715, 'Val/mean hd95_metric': 21.49677276611328}
Epoch [177/300] Training [1/62] Loss: 0.09202 
Epoch [177/300] Training [2/62] Loss: 0.08045 
Epoch [177/300] Training [3/62] Loss: 0.05740 
Epoch [177/300] Training [4/62] Loss: 0.16040 
Epoch [177/300] Training [5/62] Loss: 0.09501 
Epoch [177/300] Training [6/62] Loss: 0.09981 
Epoch [177/300] Training [7/62] Loss: 0.16216 
Epoch [177/300] Training [8/62] Loss: 0.07134 
Epoch [177/300] Training [9/62] Loss: 0.04762 
Epoch [177/300] Training [10/62] Loss: 0.04655 
Epoch [177/300] Training [11/62] Loss: 0.11503 
Epoch [177/300] Training [12/62] Loss: 0.05319 
Epoch [177/300] Training [13/62] Loss: 0.05519 
Epoch [177/300] Training [14/62] Loss: 0.11025 
Epoch [177/300] Training [15/62] Loss: 0.06464 
Epoch [177/300] Training [16/62] Loss: 0.08382 
Epoch [177/300] Training [17/62] Loss: 0.06674 
Epoch [177/300] Training [18/62] Loss: 0.15868 
Epoch [177/300] Training [19/62] Loss: 0.04906 
Epoch [177/300] Training [20/62] Loss: 0.05192 
Epoch [177/300] Training [21/62] Loss: 0.05096 
Epoch [177/300] Training [22/62] Loss: 0.17705 
Epoch [177/300] Training [23/62] Loss: 0.05676 
Epoch [177/300] Training [24/62] Loss: 0.05401 
Epoch [177/300] Training [25/62] Loss: 0.10378 
Epoch [177/300] Training [26/62] Loss: 0.06882 
Epoch [177/300] Training [27/62] Loss: 0.04877 
Epoch [177/300] Training [28/62] Loss: 0.05821 
Epoch [177/300] Training [29/62] Loss: 0.04914 
Epoch [177/300] Training [30/62] Loss: 0.10461 
Epoch [177/300] Training [31/62] Loss: 0.12650 
Epoch [177/300] Training [32/62] Loss: 0.07632 
Epoch [177/300] Training [33/62] Loss: 0.14485 
Epoch [177/300] Training [34/62] Loss: 0.10186 
Epoch [177/300] Training [35/62] Loss: 0.08415 
Epoch [177/300] Training [36/62] Loss: 0.17359 
Epoch [177/300] Training [37/62] Loss: 0.12559 
Epoch [177/300] Training [38/62] Loss: 0.08154 
Epoch [177/300] Training [39/62] Loss: 0.10669 
Epoch [177/300] Training [40/62] Loss: 0.11918 
Epoch [177/300] Training [41/62] Loss: 0.08144 
Epoch [177/300] Training [42/62] Loss: 0.05318 
Epoch [177/300] Training [43/62] Loss: 0.04848 
Epoch [177/300] Training [44/62] Loss: 0.16148 
Epoch [177/300] Training [45/62] Loss: 0.04666 
Epoch [177/300] Training [46/62] Loss: 0.07924 
Epoch [177/300] Training [47/62] Loss: 0.10500 
Epoch [177/300] Training [48/62] Loss: 0.06320 
Epoch [177/300] Training [49/62] Loss: 0.04855 
Epoch [177/300] Training [50/62] Loss: 0.04561 
Epoch [177/300] Training [51/62] Loss: 0.07524 
Epoch [177/300] Training [52/62] Loss: 0.06984 
Epoch [177/300] Training [53/62] Loss: 0.06324 
Epoch [177/300] Training [54/62] Loss: 0.04863 
Epoch [177/300] Training [55/62] Loss: 0.09640 
Epoch [177/300] Training [56/62] Loss: 0.11953 
Epoch [177/300] Training [57/62] Loss: 0.06518 
Epoch [177/300] Training [58/62] Loss: 0.05191 
Epoch [177/300] Training [59/62] Loss: 0.22734 
Epoch [177/300] Training [60/62] Loss: 0.12646 
Epoch [177/300] Training [61/62] Loss: 0.12550 
Epoch [177/300] Training [62/62] Loss: 0.03908 
Epoch [177/300] Training metric {'Train/mean dice_metric': 0.9393986463546753, 'Train/mean miou_metric': 0.8973392844200134, 'Train/mean f1': 0.948188304901123, 'Train/mean precision': 0.9478707313537598, 'Train/mean recall': 0.9485059976577759, 'Train/mean hd95_metric': 18.08411407470703}
Epoch [177/300] Validation [1/16] Loss: 0.62669  focal_loss 0.40856  dice_loss 0.21813 
Epoch [177/300] Validation [2/16] Loss: 0.41629  focal_loss 0.13177  dice_loss 0.28453 
Epoch [177/300] Validation [3/16] Loss: 0.50599  focal_loss 0.23341  dice_loss 0.27258 
Epoch [177/300] Validation [4/16] Loss: 0.36540  focal_loss 0.17062  dice_loss 0.19479 
Epoch [177/300] Validation [5/16] Loss: 0.41768  focal_loss 0.12599  dice_loss 0.29169 
Epoch [177/300] Validation [6/16] Loss: 0.32970  focal_loss 0.10182  dice_loss 0.22788 
Epoch [177/300] Validation [7/16] Loss: 0.29792  focal_loss 0.07679  dice_loss 0.22113 
Epoch [177/300] Validation [8/16] Loss: 0.50442  focal_loss 0.18345  dice_loss 0.32097 
Epoch [177/300] Validation [9/16] Loss: 0.25462  focal_loss 0.07605  dice_loss 0.17858 
Epoch [177/300] Validation [10/16] Loss: 0.49234  focal_loss 0.13508  dice_loss 0.35725 
Epoch [177/300] Validation [11/16] Loss: 0.16284  focal_loss 0.04074  dice_loss 0.12209 
Epoch [177/300] Validation [12/16] Loss: 0.38939  focal_loss 0.08422  dice_loss 0.30516 
Epoch [177/300] Validation [13/16] Loss: 0.29373  focal_loss 0.08194  dice_loss 0.21180 
Epoch [177/300] Validation [14/16] Loss: 0.59034  focal_loss 0.22507  dice_loss 0.36528 
Epoch [177/300] Validation [15/16] Loss: 0.11918  focal_loss 0.03761  dice_loss 0.08156 
Epoch [177/300] Validation [16/16] Loss: 0.19585  focal_loss 0.05202  dice_loss 0.14383 
Epoch [177/300] Validation metric {'Val/mean dice_metric': 0.9053285121917725, 'Val/mean miou_metric': 0.8525919318199158, 'Val/mean f1': 0.9196569919586182, 'Val/mean precision': 0.9213199615478516, 'Val/mean recall': 0.9179999828338623, 'Val/mean hd95_metric': 28.133874893188477}
Cheakpoint...
Epoch [177/300] best acc:tensor([0.9122], device='cuda:0'), Now : mean acc: tensor([0.9053], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9053285121917725, 'Val/mean miou_metric': 0.8525919318199158, 'Val/mean f1': 0.9196569919586182, 'Val/mean precision': 0.9213199615478516, 'Val/mean recall': 0.9179999828338623, 'Val/mean hd95_metric': 28.133874893188477}
Epoch [178/300] Training [1/62] Loss: 0.09026 
Epoch [178/300] Training [2/62] Loss: 0.07053 
Epoch [178/300] Training [3/62] Loss: 0.05471 
Epoch [178/300] Training [4/62] Loss: 0.04905 
Epoch [178/300] Training [5/62] Loss: 0.05685 
Epoch [178/300] Training [6/62] Loss: 0.04425 
Epoch [178/300] Training [7/62] Loss: 0.04794 
Epoch [178/300] Training [8/62] Loss: 0.05587 
Epoch [178/300] Training [9/62] Loss: 0.05623 
Epoch [178/300] Training [10/62] Loss: 0.05337 
Epoch [178/300] Training [11/62] Loss: 0.04500 
Epoch [178/300] Training [12/62] Loss: 0.05148 
Epoch [178/300] Training [13/62] Loss: 0.15986 
Epoch [178/300] Training [14/62] Loss: 0.16672 
Epoch [178/300] Training [15/62] Loss: 0.06881 
Epoch [178/300] Training [16/62] Loss: 0.10359 
Epoch [178/300] Training [17/62] Loss: 0.08254 
Epoch [178/300] Training [18/62] Loss: 0.04943 
Epoch [178/300] Training [19/62] Loss: 0.13186 
Epoch [178/300] Training [20/62] Loss: 0.03924 
Epoch [178/300] Training [21/62] Loss: 0.09939 
Epoch [178/300] Training [22/62] Loss: 0.03694 
Epoch [178/300] Training [23/62] Loss: 0.09867 
Epoch [178/300] Training [24/62] Loss: 0.23601 
Epoch [178/300] Training [25/62] Loss: 0.03971 
Epoch [178/300] Training [26/62] Loss: 0.04191 
Epoch [178/300] Training [27/62] Loss: 0.12554 
Epoch [178/300] Training [28/62] Loss: 0.06086 
Epoch [178/300] Training [29/62] Loss: 0.06238 
Epoch [178/300] Training [30/62] Loss: 0.11940 
Epoch [178/300] Training [31/62] Loss: 0.16343 
Epoch [178/300] Training [32/62] Loss: 0.03674 
Epoch [178/300] Training [33/62] Loss: 0.06265 
Epoch [178/300] Training [34/62] Loss: 0.06393 
Epoch [178/300] Training [35/62] Loss: 0.05576 
Epoch [178/300] Training [36/62] Loss: 0.07093 
Epoch [178/300] Training [37/62] Loss: 0.08948 
Epoch [178/300] Training [38/62] Loss: 0.07036 
Epoch [178/300] Training [39/62] Loss: 0.11812 
Epoch [178/300] Training [40/62] Loss: 0.04362 
Epoch [178/300] Training [41/62] Loss: 0.12823 
Epoch [178/300] Training [42/62] Loss: 0.14217 
Epoch [178/300] Training [43/62] Loss: 0.13231 
Epoch [178/300] Training [44/62] Loss: 0.05748 
Epoch [178/300] Training [45/62] Loss: 0.05280 
Epoch [178/300] Training [46/62] Loss: 0.06086 
Epoch [178/300] Training [47/62] Loss: 0.04376 
Epoch [178/300] Training [48/62] Loss: 0.04660 
Epoch [178/300] Training [49/62] Loss: 0.04417 
Epoch [178/300] Training [50/62] Loss: 0.15210 
Epoch [178/300] Training [51/62] Loss: 0.04965 
Epoch [178/300] Training [52/62] Loss: 0.06710 
Epoch [178/300] Training [53/62] Loss: 0.11321 
Epoch [178/300] Training [54/62] Loss: 0.05560 
Epoch [178/300] Training [55/62] Loss: 0.09221 
Epoch [178/300] Training [56/62] Loss: 0.07309 
Epoch [178/300] Training [57/62] Loss: 0.08039 
Epoch [178/300] Training [58/62] Loss: 0.04184 
Epoch [178/300] Training [59/62] Loss: 0.18569 
Epoch [178/300] Training [60/62] Loss: 0.06082 
Epoch [178/300] Training [61/62] Loss: 0.06469 
Epoch [178/300] Training [62/62] Loss: 0.12887 
Epoch [178/300] Training metric {'Train/mean dice_metric': 0.9442552924156189, 'Train/mean miou_metric': 0.9043289422988892, 'Train/mean f1': 0.9538758397102356, 'Train/mean precision': 0.9515730142593384, 'Train/mean recall': 0.9561899304389954, 'Train/mean hd95_metric': 15.24178695678711}
Epoch [178/300] Validation [1/16] Loss: 0.59905  focal_loss 0.37596  dice_loss 0.22308 
Epoch [178/300] Validation [2/16] Loss: 0.42070  focal_loss 0.15428  dice_loss 0.26643 
Epoch [178/300] Validation [3/16] Loss: 0.57755  focal_loss 0.29931  dice_loss 0.27824 
Epoch [178/300] Validation [4/16] Loss: 0.34302  focal_loss 0.16361  dice_loss 0.17941 
Epoch [178/300] Validation [5/16] Loss: 0.35553  focal_loss 0.11090  dice_loss 0.24463 
Epoch [178/300] Validation [6/16] Loss: 0.31785  focal_loss 0.12271  dice_loss 0.19514 
Epoch [178/300] Validation [7/16] Loss: 0.28831  focal_loss 0.08687  dice_loss 0.20143 
Epoch [178/300] Validation [8/16] Loss: 0.44258  focal_loss 0.14922  dice_loss 0.29335 
Epoch [178/300] Validation [9/16] Loss: 0.16969  focal_loss 0.05743  dice_loss 0.11226 
Epoch [178/300] Validation [10/16] Loss: 0.51619  focal_loss 0.14249  dice_loss 0.37370 
Epoch [178/300] Validation [11/16] Loss: 0.14435  focal_loss 0.04607  dice_loss 0.09828 
Epoch [178/300] Validation [12/16] Loss: 0.37837  focal_loss 0.09741  dice_loss 0.28096 
Epoch [178/300] Validation [13/16] Loss: 0.20589  focal_loss 0.05498  dice_loss 0.15092 
Epoch [178/300] Validation [14/16] Loss: 0.56395  focal_loss 0.22507  dice_loss 0.33887 
Epoch [178/300] Validation [15/16] Loss: 0.10217  focal_loss 0.02986  dice_loss 0.07231 
Epoch [178/300] Validation [16/16] Loss: 0.14714  focal_loss 0.04321  dice_loss 0.10392 
Epoch [178/300] Validation metric {'Val/mean dice_metric': 0.9127305150032043, 'Val/mean miou_metric': 0.8641705513000488, 'Val/mean f1': 0.9284383654594421, 'Val/mean precision': 0.9329924583435059, 'Val/mean recall': 0.923928439617157, 'Val/mean hd95_metric': 23.14540672302246}
Cheakpoint...
Epoch [178/300] best acc:tensor([0.9127], device='cuda:0'), Now : mean acc: tensor([0.9127], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9127305150032043, 'Val/mean miou_metric': 0.8641705513000488, 'Val/mean f1': 0.9284383654594421, 'Val/mean precision': 0.9329924583435059, 'Val/mean recall': 0.923928439617157, 'Val/mean hd95_metric': 23.14540672302246}
Epoch [179/300] Training [1/62] Loss: 0.05449 
Epoch [179/300] Training [2/62] Loss: 0.12748 
Epoch [179/300] Training [3/62] Loss: 0.07933 
Epoch [179/300] Training [4/62] Loss: 0.04552 
Epoch [179/300] Training [5/62] Loss: 0.08480 
Epoch [179/300] Training [6/62] Loss: 0.20163 
Epoch [179/300] Training [7/62] Loss: 0.07311 
Epoch [179/300] Training [8/62] Loss: 0.07363 
Epoch [179/300] Training [9/62] Loss: 0.06468 
Epoch [179/300] Training [10/62] Loss: 0.04904 
Epoch [179/300] Training [11/62] Loss: 0.06967 
Epoch [179/300] Training [12/62] Loss: 0.04155 
Epoch [179/300] Training [13/62] Loss: 0.20162 
Epoch [179/300] Training [14/62] Loss: 0.07056 
Epoch [179/300] Training [15/62] Loss: 0.07213 
Epoch [179/300] Training [16/62] Loss: 0.06567 
Epoch [179/300] Training [17/62] Loss: 0.05169 
Epoch [179/300] Training [18/62] Loss: 0.11109 
Epoch [179/300] Training [19/62] Loss: 0.05602 
Epoch [179/300] Training [20/62] Loss: 0.04945 
Epoch [179/300] Training [21/62] Loss: 0.06568 
Epoch [179/300] Training [22/62] Loss: 0.04208 
Epoch [179/300] Training [23/62] Loss: 0.09098 
Epoch [179/300] Training [24/62] Loss: 0.07199 
Epoch [179/300] Training [25/62] Loss: 0.06329 
Epoch [179/300] Training [26/62] Loss: 0.07075 
Epoch [179/300] Training [27/62] Loss: 0.11807 
Epoch [179/300] Training [28/62] Loss: 0.10237 
Epoch [179/300] Training [29/62] Loss: 0.06618 
Epoch [179/300] Training [30/62] Loss: 0.06388 
Epoch [179/300] Training [31/62] Loss: 0.09243 
Epoch [179/300] Training [32/62] Loss: 0.13176 
Epoch [179/300] Training [33/62] Loss: 0.04176 
Epoch [179/300] Training [34/62] Loss: 0.05974 
Epoch [179/300] Training [35/62] Loss: 0.06345 
Epoch [179/300] Training [36/62] Loss: 0.09762 
Epoch [179/300] Training [37/62] Loss: 0.04681 
Epoch [179/300] Training [38/62] Loss: 0.11441 
Epoch [179/300] Training [39/62] Loss: 0.05446 
Epoch [179/300] Training [40/62] Loss: 0.05949 
Epoch [179/300] Training [41/62] Loss: 0.05280 
Epoch [179/300] Training [42/62] Loss: 0.14449 
Epoch [179/300] Training [43/62] Loss: 0.07012 
Epoch [179/300] Training [44/62] Loss: 0.03830 
Epoch [179/300] Training [45/62] Loss: 0.08786 
Epoch [179/300] Training [46/62] Loss: 0.04779 
Epoch [179/300] Training [47/62] Loss: 0.16221 
Epoch [179/300] Training [48/62] Loss: 0.04845 
Epoch [179/300] Training [49/62] Loss: 0.07085 
Epoch [179/300] Training [50/62] Loss: 0.04840 
Epoch [179/300] Training [51/62] Loss: 0.04779 
Epoch [179/300] Training [52/62] Loss: 0.05720 
Epoch [179/300] Training [53/62] Loss: 0.09791 
Epoch [179/300] Training [54/62] Loss: 0.06279 
Epoch [179/300] Training [55/62] Loss: 0.05381 
Epoch [179/300] Training [56/62] Loss: 0.07717 
Epoch [179/300] Training [57/62] Loss: 0.05591 
Epoch [179/300] Training [58/62] Loss: 0.06712 
Epoch [179/300] Training [59/62] Loss: 0.07824 
Epoch [179/300] Training [60/62] Loss: 0.04624 
Epoch [179/300] Training [61/62] Loss: 0.11291 
Epoch [179/300] Training [62/62] Loss: 0.04225 
Epoch [179/300] Training metric {'Train/mean dice_metric': 0.9476481676101685, 'Train/mean miou_metric': 0.9077532887458801, 'Train/mean f1': 0.9550176858901978, 'Train/mean precision': 0.9526172280311584, 'Train/mean recall': 0.9574301838874817, 'Train/mean hd95_metric': 14.633014678955078}
Epoch [179/300] Validation [1/16] Loss: 0.61058  focal_loss 0.39273  dice_loss 0.21785 
Epoch [179/300] Validation [2/16] Loss: 0.56495  focal_loss 0.20755  dice_loss 0.35741 
Epoch [179/300] Validation [3/16] Loss: 0.63894  focal_loss 0.35784  dice_loss 0.28111 
Epoch [179/300] Validation [4/16] Loss: 0.32621  focal_loss 0.14004  dice_loss 0.18618 
Epoch [179/300] Validation [5/16] Loss: 0.35596  focal_loss 0.11698  dice_loss 0.23898 
Epoch [179/300] Validation [6/16] Loss: 0.32204  focal_loss 0.09967  dice_loss 0.22237 
Epoch [179/300] Validation [7/16] Loss: 0.16764  focal_loss 0.06602  dice_loss 0.10162 
Epoch [179/300] Validation [8/16] Loss: 0.46154  focal_loss 0.15245  dice_loss 0.30909 
Epoch [179/300] Validation [9/16] Loss: 0.28865  focal_loss 0.13212  dice_loss 0.15653 
Epoch [179/300] Validation [10/16] Loss: 0.56044  focal_loss 0.17260  dice_loss 0.38784 
Epoch [179/300] Validation [11/16] Loss: 0.15193  focal_loss 0.05291  dice_loss 0.09902 
Epoch [179/300] Validation [12/16] Loss: 0.40851  focal_loss 0.11714  dice_loss 0.29138 
Epoch [179/300] Validation [13/16] Loss: 0.31812  focal_loss 0.10602  dice_loss 0.21210 
Epoch [179/300] Validation [14/16] Loss: 0.48343  focal_loss 0.18279  dice_loss 0.30064 
Epoch [179/300] Validation [15/16] Loss: 0.11583  focal_loss 0.03648  dice_loss 0.07935 
Epoch [179/300] Validation [16/16] Loss: 0.12941  focal_loss 0.03475  dice_loss 0.09466 
Epoch [179/300] Validation metric {'Val/mean dice_metric': 0.9138297438621521, 'Val/mean miou_metric': 0.8642497062683105, 'Val/mean f1': 0.9288031458854675, 'Val/mean precision': 0.9343088865280151, 'Val/mean recall': 0.9233619570732117, 'Val/mean hd95_metric': 23.472505569458008}
Cheakpoint...
Epoch [179/300] best acc:tensor([0.9138], device='cuda:0'), Now : mean acc: tensor([0.9138], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9138297438621521, 'Val/mean miou_metric': 0.8642497062683105, 'Val/mean f1': 0.9288031458854675, 'Val/mean precision': 0.9343088865280151, 'Val/mean recall': 0.9233619570732117, 'Val/mean hd95_metric': 23.472505569458008}
Epoch [180/300] Training [1/62] Loss: 0.09098 
Epoch [180/300] Training [2/62] Loss: 0.06160 
Epoch [180/300] Training [3/62] Loss: 0.07398 
Epoch [180/300] Training [4/62] Loss: 0.08324 
Epoch [180/300] Training [5/62] Loss: 0.05780 
Epoch [180/300] Training [6/62] Loss: 0.07786 
Epoch [180/300] Training [7/62] Loss: 0.12450 
Epoch [180/300] Training [8/62] Loss: 0.04402 
Epoch [180/300] Training [9/62] Loss: 0.05289 
Epoch [180/300] Training [10/62] Loss: 0.09677 
Epoch [180/300] Training [11/62] Loss: 0.23862 
Epoch [180/300] Training [12/62] Loss: 0.06561 
Epoch [180/300] Training [13/62] Loss: 0.06490 
Epoch [180/300] Training [14/62] Loss: 0.12095 
Epoch [180/300] Training [15/62] Loss: 0.12290 
Epoch [180/300] Training [16/62] Loss: 0.05124 
Epoch [180/300] Training [17/62] Loss: 0.05498 
Epoch [180/300] Training [18/62] Loss: 0.05304 
Epoch [180/300] Training [19/62] Loss: 0.14714 
Epoch [180/300] Training [20/62] Loss: 0.04936 
Epoch [180/300] Training [21/62] Loss: 0.06210 
Epoch [180/300] Training [22/62] Loss: 0.10277 
Epoch [180/300] Training [23/62] Loss: 0.05988 
Epoch [180/300] Training [24/62] Loss: 0.05302 
Epoch [180/300] Training [25/62] Loss: 0.15893 
Epoch [180/300] Training [26/62] Loss: 0.04880 
Epoch [180/300] Training [27/62] Loss: 0.04110 
Epoch [180/300] Training [28/62] Loss: 0.05066 
Epoch [180/300] Training [29/62] Loss: 0.03915 
Epoch [180/300] Training [30/62] Loss: 0.08126 
Epoch [180/300] Training [31/62] Loss: 0.09694 
Epoch [180/300] Training [32/62] Loss: 0.08066 
Epoch [180/300] Training [33/62] Loss: 0.10515 
Epoch [180/300] Training [34/62] Loss: 0.09461 
Epoch [180/300] Training [35/62] Loss: 0.31526 
Epoch [180/300] Training [36/62] Loss: 0.06217 
Epoch [180/300] Training [37/62] Loss: 0.16778 
Epoch [180/300] Training [38/62] Loss: 0.11012 
Epoch [180/300] Training [39/62] Loss: 0.04839 
Epoch [180/300] Training [40/62] Loss: 0.08708 
Epoch [180/300] Training [41/62] Loss: 0.04259 
Epoch [180/300] Training [42/62] Loss: 0.05295 
Epoch [180/300] Training [43/62] Loss: 0.06298 
Epoch [180/300] Training [44/62] Loss: 0.09777 
Epoch [180/300] Training [45/62] Loss: 0.06078 
Epoch [180/300] Training [46/62] Loss: 0.09844 
Epoch [180/300] Training [47/62] Loss: 0.06745 
Epoch [180/300] Training [48/62] Loss: 0.10104 
Epoch [180/300] Training [49/62] Loss: 0.08566 
Epoch [180/300] Training [50/62] Loss: 0.06765 
Epoch [180/300] Training [51/62] Loss: 0.09450 
Epoch [180/300] Training [52/62] Loss: 0.06674 
Epoch [180/300] Training [53/62] Loss: 0.06411 
Epoch [180/300] Training [54/62] Loss: 0.08064 
Epoch [180/300] Training [55/62] Loss: 0.07327 
Epoch [180/300] Training [56/62] Loss: 0.05022 
Epoch [180/300] Training [57/62] Loss: 0.08472 
Epoch [180/300] Training [58/62] Loss: 0.06412 
Epoch [180/300] Training [59/62] Loss: 0.05473 
Epoch [180/300] Training [60/62] Loss: 0.17835 
Epoch [180/300] Training [61/62] Loss: 0.04132 
Epoch [180/300] Training [62/62] Loss: 0.41976 
Epoch [180/300] Training metric {'Train/mean dice_metric': 0.9396567344665527, 'Train/mean miou_metric': 0.8983170390129089, 'Train/mean f1': 0.9527969360351562, 'Train/mean precision': 0.949332594871521, 'Train/mean recall': 0.956286609172821, 'Train/mean hd95_metric': 15.170059204101562}
Epoch [180/300] Validation [1/16] Loss: 0.55311  focal_loss 0.34864  dice_loss 0.20447 
Epoch [180/300] Validation [2/16] Loss: 0.40098  focal_loss 0.15730  dice_loss 0.24368 
Epoch [180/300] Validation [3/16] Loss: 0.60187  focal_loss 0.31890  dice_loss 0.28296 
Epoch [180/300] Validation [4/16] Loss: 0.29327  focal_loss 0.13476  dice_loss 0.15852 
Epoch [180/300] Validation [5/16] Loss: 0.28965  focal_loss 0.09524  dice_loss 0.19441 
Epoch [180/300] Validation [6/16] Loss: 0.28865  focal_loss 0.08269  dice_loss 0.20596 
Epoch [180/300] Validation [7/16] Loss: 0.16518  focal_loss 0.05447  dice_loss 0.11071 
Epoch [180/300] Validation [8/16] Loss: 0.49750  focal_loss 0.17212  dice_loss 0.32539 
Epoch [180/300] Validation [9/16] Loss: 0.18773  focal_loss 0.05787  dice_loss 0.12987 
Epoch [180/300] Validation [10/16] Loss: 0.46182  focal_loss 0.13027  dice_loss 0.33155 
Epoch [180/300] Validation [11/16] Loss: 0.16925  focal_loss 0.04834  dice_loss 0.12091 
Epoch [180/300] Validation [12/16] Loss: 0.44024  focal_loss 0.10889  dice_loss 0.33135 
Epoch [180/300] Validation [13/16] Loss: 0.25003  focal_loss 0.07915  dice_loss 0.17089 
Epoch [180/300] Validation [14/16] Loss: 0.61422  focal_loss 0.23377  dice_loss 0.38045 
Epoch [180/300] Validation [15/16] Loss: 0.12812  focal_loss 0.04644  dice_loss 0.08168 
Epoch [180/300] Validation [16/16] Loss: 0.15568  focal_loss 0.03997  dice_loss 0.11571 
Epoch [180/300] Validation metric {'Val/mean dice_metric': 0.909932553768158, 'Val/mean miou_metric': 0.859464168548584, 'Val/mean f1': 0.928723156452179, 'Val/mean precision': 0.9374372363090515, 'Val/mean recall': 0.9201695322990417, 'Val/mean hd95_metric': 23.305686950683594}
Cheakpoint...
Epoch [180/300] best acc:tensor([0.9138], device='cuda:0'), Now : mean acc: tensor([0.9099], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.909932553768158, 'Val/mean miou_metric': 0.859464168548584, 'Val/mean f1': 0.928723156452179, 'Val/mean precision': 0.9374372363090515, 'Val/mean recall': 0.9201695322990417, 'Val/mean hd95_metric': 23.305686950683594}
Epoch [181/300] Training [1/62] Loss: 0.05424 
Epoch [181/300] Training [2/62] Loss: 0.06768 
Epoch [181/300] Training [3/62] Loss: 0.08508 
Epoch [181/300] Training [4/62] Loss: 0.05558 
Epoch [181/300] Training [5/62] Loss: 0.04633 
Epoch [181/300] Training [6/62] Loss: 0.04531 
Epoch [181/300] Training [7/62] Loss: 0.05989 
Epoch [181/300] Training [8/62] Loss: 0.07370 
Epoch [181/300] Training [9/62] Loss: 0.07839 
Epoch [181/300] Training [10/62] Loss: 0.07398 
Epoch [181/300] Training [11/62] Loss: 0.05771 
Epoch [181/300] Training [12/62] Loss: 0.10734 
Epoch [181/300] Training [13/62] Loss: 0.14588 
Epoch [181/300] Training [14/62] Loss: 0.17289 
Epoch [181/300] Training [15/62] Loss: 0.07790 
Epoch [181/300] Training [16/62] Loss: 0.04792 
Epoch [181/300] Training [17/62] Loss: 0.07703 
Epoch [181/300] Training [18/62] Loss: 0.05116 
Epoch [181/300] Training [19/62] Loss: 0.06202 
Epoch [181/300] Training [20/62] Loss: 0.08916 
Epoch [181/300] Training [21/62] Loss: 0.04341 
Epoch [181/300] Training [22/62] Loss: 0.08698 
Epoch [181/300] Training [23/62] Loss: 0.09448 
Epoch [181/300] Training [24/62] Loss: 0.07435 
Epoch [181/300] Training [25/62] Loss: 0.06861 
Epoch [181/300] Training [26/62] Loss: 0.05544 
Epoch [181/300] Training [27/62] Loss: 0.05991 
Epoch [181/300] Training [28/62] Loss: 0.10547 
Epoch [181/300] Training [29/62] Loss: 0.05295 
Epoch [181/300] Training [30/62] Loss: 0.05665 
Epoch [181/300] Training [31/62] Loss: 0.11178 
Epoch [181/300] Training [32/62] Loss: 0.21491 
Epoch [181/300] Training [33/62] Loss: 0.06985 
Epoch [181/300] Training [34/62] Loss: 0.06979 
Epoch [181/300] Training [35/62] Loss: 0.05306 
Epoch [181/300] Training [36/62] Loss: 0.06310 
Epoch [181/300] Training [37/62] Loss: 0.06406 
Epoch [181/300] Training [38/62] Loss: 0.08342 
Epoch [181/300] Training [39/62] Loss: 0.05843 
Epoch [181/300] Training [40/62] Loss: 0.18207 
Epoch [181/300] Training [41/62] Loss: 0.04086 
Epoch [181/300] Training [42/62] Loss: 0.13083 
Epoch [181/300] Training [43/62] Loss: 0.08562 
Epoch [181/300] Training [44/62] Loss: 0.17532 
Epoch [181/300] Training [45/62] Loss: 0.04374 
Epoch [181/300] Training [46/62] Loss: 0.05767 
Epoch [181/300] Training [47/62] Loss: 0.06396 
Epoch [181/300] Training [48/62] Loss: 0.04917 
Epoch [181/300] Training [49/62] Loss: 0.05186 
Epoch [181/300] Training [50/62] Loss: 0.05331 
Epoch [181/300] Training [51/62] Loss: 0.05537 
Epoch [181/300] Training [52/62] Loss: 0.08687 
Epoch [181/300] Training [53/62] Loss: 0.07678 
Epoch [181/300] Training [54/62] Loss: 0.15740 
Epoch [181/300] Training [55/62] Loss: 0.09060 
Epoch [181/300] Training [56/62] Loss: 0.07602 
Epoch [181/300] Training [57/62] Loss: 0.07584 
Epoch [181/300] Training [58/62] Loss: 0.06829 
Epoch [181/300] Training [59/62] Loss: 0.08015 
Epoch [181/300] Training [60/62] Loss: 0.07613 
Epoch [181/300] Training [61/62] Loss: 0.18924 
Epoch [181/300] Training [62/62] Loss: 0.30768 
Epoch [181/300] Training metric {'Train/mean dice_metric': 0.9431249499320984, 'Train/mean miou_metric': 0.9037091135978699, 'Train/mean f1': 0.9527980089187622, 'Train/mean precision': 0.9507570862770081, 'Train/mean recall': 0.9548476934432983, 'Train/mean hd95_metric': 13.235590934753418}
Epoch [181/300] Validation [1/16] Loss: 0.63412  focal_loss 0.42334  dice_loss 0.21078 
Epoch [181/300] Validation [2/16] Loss: 0.50812  focal_loss 0.16602  dice_loss 0.34210 
Epoch [181/300] Validation [3/16] Loss: 0.61812  focal_loss 0.31575  dice_loss 0.30237 
Epoch [181/300] Validation [4/16] Loss: 0.30091  focal_loss 0.12839  dice_loss 0.17252 
Epoch [181/300] Validation [5/16] Loss: 0.43045  focal_loss 0.12912  dice_loss 0.30132 
Epoch [181/300] Validation [6/16] Loss: 0.35241  focal_loss 0.11414  dice_loss 0.23827 
Epoch [181/300] Validation [7/16] Loss: 0.24306  focal_loss 0.09255  dice_loss 0.15050 
Epoch [181/300] Validation [8/16] Loss: 0.45693  focal_loss 0.15317  dice_loss 0.30376 
Epoch [181/300] Validation [9/16] Loss: 0.19610  focal_loss 0.05822  dice_loss 0.13788 
Epoch [181/300] Validation [10/16] Loss: 0.52102  focal_loss 0.15081  dice_loss 0.37021 
Epoch [181/300] Validation [11/16] Loss: 0.15490  focal_loss 0.04645  dice_loss 0.10845 
Epoch [181/300] Validation [12/16] Loss: 0.39248  focal_loss 0.10892  dice_loss 0.28356 
Epoch [181/300] Validation [13/16] Loss: 0.25959  focal_loss 0.08850  dice_loss 0.17109 
Epoch [181/300] Validation [14/16] Loss: 0.55957  focal_loss 0.21223  dice_loss 0.34734 
Epoch [181/300] Validation [15/16] Loss: 0.12474  focal_loss 0.04399  dice_loss 0.08075 
Epoch [181/300] Validation [16/16] Loss: 0.12843  focal_loss 0.03586  dice_loss 0.09257 
Epoch [181/300] Validation metric {'Val/mean dice_metric': 0.9097224473953247, 'Val/mean miou_metric': 0.8598044514656067, 'Val/mean f1': 0.9257458448410034, 'Val/mean precision': 0.9295615553855896, 'Val/mean recall': 0.92196124792099, 'Val/mean hd95_metric': 23.177837371826172}
Cheakpoint...
Epoch [181/300] best acc:tensor([0.9138], device='cuda:0'), Now : mean acc: tensor([0.9097], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9097224473953247, 'Val/mean miou_metric': 0.8598044514656067, 'Val/mean f1': 0.9257458448410034, 'Val/mean precision': 0.9295615553855896, 'Val/mean recall': 0.92196124792099, 'Val/mean hd95_metric': 23.177837371826172}
Epoch [182/300] Training [1/62] Loss: 0.08871 
Epoch [182/300] Training [2/62] Loss: 0.12126 
Epoch [182/300] Training [3/62] Loss: 0.09144 
Epoch [182/300] Training [4/62] Loss: 0.08262 
Epoch [182/300] Training [5/62] Loss: 0.08804 
Epoch [182/300] Training [6/62] Loss: 0.04361 
Epoch [182/300] Training [7/62] Loss: 0.05500 
Epoch [182/300] Training [8/62] Loss: 0.08235 
Epoch [182/300] Training [9/62] Loss: 0.06264 
Epoch [182/300] Training [10/62] Loss: 0.11767 
Epoch [182/300] Training [11/62] Loss: 0.04251 
Epoch [182/300] Training [12/62] Loss: 0.10421 
Epoch [182/300] Training [13/62] Loss: 0.09743 
Epoch [182/300] Training [14/62] Loss: 0.05844 
Epoch [182/300] Training [15/62] Loss: 0.06653 
Epoch [182/300] Training [16/62] Loss: 0.06377 
Epoch [182/300] Training [17/62] Loss: 0.04772 
Epoch [182/300] Training [18/62] Loss: 0.10349 
Epoch [182/300] Training [19/62] Loss: 0.07316 
Epoch [182/300] Training [20/62] Loss: 0.05146 
Epoch [182/300] Training [21/62] Loss: 0.05058 
Epoch [182/300] Training [22/62] Loss: 0.06905 
Epoch [182/300] Training [23/62] Loss: 0.04285 
Epoch [182/300] Training [24/62] Loss: 0.11024 
Epoch [182/300] Training [25/62] Loss: 0.04839 
Epoch [182/300] Training [26/62] Loss: 0.08662 
Epoch [182/300] Training [27/62] Loss: 0.11235 
Epoch [182/300] Training [28/62] Loss: 0.06300 
Epoch [182/300] Training [29/62] Loss: 0.07887 
Epoch [182/300] Training [30/62] Loss: 0.05512 
Epoch [182/300] Training [31/62] Loss: 0.07916 
Epoch [182/300] Training [32/62] Loss: 0.04050 
Epoch [182/300] Training [33/62] Loss: 0.16252 
Epoch [182/300] Training [34/62] Loss: 0.12517 
Epoch [182/300] Training [35/62] Loss: 0.04217 
Epoch [182/300] Training [36/62] Loss: 0.08149 
Epoch [182/300] Training [37/62] Loss: 0.06234 
Epoch [182/300] Training [38/62] Loss: 0.06121 
Epoch [182/300] Training [39/62] Loss: 0.04862 
Epoch [182/300] Training [40/62] Loss: 0.07530 
Epoch [182/300] Training [41/62] Loss: 0.09986 
Epoch [182/300] Training [42/62] Loss: 0.15899 
Epoch [182/300] Training [43/62] Loss: 0.07221 
Epoch [182/300] Training [44/62] Loss: 0.06449 
Epoch [182/300] Training [45/62] Loss: 0.07019 
Epoch [182/300] Training [46/62] Loss: 0.09794 
Epoch [182/300] Training [47/62] Loss: 0.05600 
Epoch [182/300] Training [48/62] Loss: 0.06099 
Epoch [182/300] Training [49/62] Loss: 0.17305 
Epoch [182/300] Training [50/62] Loss: 0.05757 
Epoch [182/300] Training [51/62] Loss: 0.06033 
Epoch [182/300] Training [52/62] Loss: 0.07133 
Epoch [182/300] Training [53/62] Loss: 0.05846 
Epoch [182/300] Training [54/62] Loss: 0.04805 
Epoch [182/300] Training [55/62] Loss: 0.08922 
Epoch [182/300] Training [56/62] Loss: 0.04934 
Epoch [182/300] Training [57/62] Loss: 0.03800 
Epoch [182/300] Training [58/62] Loss: 0.07272 
Epoch [182/300] Training [59/62] Loss: 0.12214 
Epoch [182/300] Training [60/62] Loss: 0.05066 
Epoch [182/300] Training [61/62] Loss: 0.13264 
Epoch [182/300] Training [62/62] Loss: 0.03425 
Epoch [182/300] Training metric {'Train/mean dice_metric': 0.9465462565422058, 'Train/mean miou_metric': 0.9058317542076111, 'Train/mean f1': 0.9546895027160645, 'Train/mean precision': 0.95240718126297, 'Train/mean recall': 0.9569826722145081, 'Train/mean hd95_metric': 15.0751314163208}
Epoch [182/300] Validation [1/16] Loss: 0.63495  focal_loss 0.41416  dice_loss 0.22080 
Epoch [182/300] Validation [2/16] Loss: 0.47367  focal_loss 0.19655  dice_loss 0.27712 
Epoch [182/300] Validation [3/16] Loss: 0.62735  focal_loss 0.35002  dice_loss 0.27733 
Epoch [182/300] Validation [4/16] Loss: 0.31647  focal_loss 0.13046  dice_loss 0.18600 
Epoch [182/300] Validation [5/16] Loss: 0.32413  focal_loss 0.11318  dice_loss 0.21095 
Epoch [182/300] Validation [6/16] Loss: 0.38580  focal_loss 0.13477  dice_loss 0.25103 
Epoch [182/300] Validation [7/16] Loss: 0.25065  focal_loss 0.08435  dice_loss 0.16630 
Epoch [182/300] Validation [8/16] Loss: 0.42321  focal_loss 0.13839  dice_loss 0.28482 
Epoch [182/300] Validation [9/16] Loss: 0.22077  focal_loss 0.09988  dice_loss 0.12089 
Epoch [182/300] Validation [10/16] Loss: 0.52253  focal_loss 0.19236  dice_loss 0.33017 
Epoch [182/300] Validation [11/16] Loss: 0.16903  focal_loss 0.05592  dice_loss 0.11312 
Epoch [182/300] Validation [12/16] Loss: 0.38219  focal_loss 0.10709  dice_loss 0.27511 
Epoch [182/300] Validation [13/16] Loss: 0.29419  focal_loss 0.10714  dice_loss 0.18705 
Epoch [182/300] Validation [14/16] Loss: 0.54248  focal_loss 0.21037  dice_loss 0.33211 
Epoch [182/300] Validation [15/16] Loss: 0.14172  focal_loss 0.04475  dice_loss 0.09696 
Epoch [182/300] Validation [16/16] Loss: 0.18207  focal_loss 0.06728  dice_loss 0.11479 
Epoch [182/300] Validation metric {'Val/mean dice_metric': 0.9143779277801514, 'Val/mean miou_metric': 0.8628730773925781, 'Val/mean f1': 0.9272571802139282, 'Val/mean precision': 0.9300731420516968, 'Val/mean recall': 0.9244582056999207, 'Val/mean hd95_metric': 25.165569305419922}
Cheakpoint...
Epoch [182/300] best acc:tensor([0.9144], device='cuda:0'), Now : mean acc: tensor([0.9144], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9143779277801514, 'Val/mean miou_metric': 0.8628730773925781, 'Val/mean f1': 0.9272571802139282, 'Val/mean precision': 0.9300731420516968, 'Val/mean recall': 0.9244582056999207, 'Val/mean hd95_metric': 25.165569305419922}
Epoch [183/300] Training [1/62] Loss: 0.05338 
Epoch [183/300] Training [2/62] Loss: 0.11683 
Epoch [183/300] Training [3/62] Loss: 0.07979 
Epoch [183/300] Training [4/62] Loss: 0.03741 
Epoch [183/300] Training [5/62] Loss: 0.08933 
Epoch [183/300] Training [6/62] Loss: 0.04404 
Epoch [183/300] Training [7/62] Loss: 0.05120 
Epoch [183/300] Training [8/62] Loss: 0.09021 
Epoch [183/300] Training [9/62] Loss: 0.08768 
Epoch [183/300] Training [10/62] Loss: 0.04074 
Epoch [183/300] Training [11/62] Loss: 0.07811 
Epoch [183/300] Training [12/62] Loss: 0.09082 
Epoch [183/300] Training [13/62] Loss: 0.06271 
Epoch [183/300] Training [14/62] Loss: 0.17050 
Epoch [183/300] Training [15/62] Loss: 0.04914 
Epoch [183/300] Training [16/62] Loss: 0.06198 
Epoch [183/300] Training [17/62] Loss: 0.05907 
Epoch [183/300] Training [18/62] Loss: 0.04645 
Epoch [183/300] Training [19/62] Loss: 0.23383 
Epoch [183/300] Training [20/62] Loss: 0.03837 
Epoch [183/300] Training [21/62] Loss: 0.04229 
Epoch [183/300] Training [22/62] Loss: 0.07137 
Epoch [183/300] Training [23/62] Loss: 0.08347 
Epoch [183/300] Training [24/62] Loss: 0.05579 
Epoch [183/300] Training [25/62] Loss: 0.09032 
Epoch [183/300] Training [26/62] Loss: 0.05668 
Epoch [183/300] Training [27/62] Loss: 0.05745 
Epoch [183/300] Training [28/62] Loss: 0.06991 
Epoch [183/300] Training [29/62] Loss: 0.07557 
Epoch [183/300] Training [30/62] Loss: 0.07428 
Epoch [183/300] Training [31/62] Loss: 0.04375 
Epoch [183/300] Training [32/62] Loss: 0.07322 
Epoch [183/300] Training [33/62] Loss: 0.05162 
Epoch [183/300] Training [34/62] Loss: 0.06572 
Epoch [183/300] Training [35/62] Loss: 0.04882 
Epoch [183/300] Training [36/62] Loss: 0.08037 
Epoch [183/300] Training [37/62] Loss: 0.13279 
Epoch [183/300] Training [38/62] Loss: 0.05353 
Epoch [183/300] Training [39/62] Loss: 0.05950 
Epoch [183/300] Training [40/62] Loss: 0.05314 
Epoch [183/300] Training [41/62] Loss: 0.04237 
Epoch [183/300] Training [42/62] Loss: 0.07793 
Epoch [183/300] Training [43/62] Loss: 0.05025 
Epoch [183/300] Training [44/62] Loss: 0.08295 
Epoch [183/300] Training [45/62] Loss: 0.05843 
Epoch [183/300] Training [46/62] Loss: 0.08124 
Epoch [183/300] Training [47/62] Loss: 0.11624 
Epoch [183/300] Training [48/62] Loss: 0.04903 
Epoch [183/300] Training [49/62] Loss: 0.15720 
Epoch [183/300] Training [50/62] Loss: 0.07116 
Epoch [183/300] Training [51/62] Loss: 0.04190 
Epoch [183/300] Training [52/62] Loss: 0.09721 
Epoch [183/300] Training [53/62] Loss: 0.07365 
Epoch [183/300] Training [54/62] Loss: 0.10295 
Epoch [183/300] Training [55/62] Loss: 0.07786 
Epoch [183/300] Training [56/62] Loss: 0.06133 
Epoch [183/300] Training [57/62] Loss: 0.04320 
Epoch [183/300] Training [58/62] Loss: 0.07642 
Epoch [183/300] Training [59/62] Loss: 0.05505 
Epoch [183/300] Training [60/62] Loss: 0.07202 
Epoch [183/300] Training [61/62] Loss: 0.05112 
Epoch [183/300] Training [62/62] Loss: 0.03452 
Epoch [183/300] Training metric {'Train/mean dice_metric': 0.9502537250518799, 'Train/mean miou_metric': 0.9121363162994385, 'Train/mean f1': 0.956902027130127, 'Train/mean precision': 0.9536523818969727, 'Train/mean recall': 0.9601739048957825, 'Train/mean hd95_metric': 12.904163360595703}
Epoch [183/300] Validation [1/16] Loss: 0.63078  focal_loss 0.39833  dice_loss 0.23245 
Epoch [183/300] Validation [2/16] Loss: 0.48621  focal_loss 0.16266  dice_loss 0.32355 
Epoch [183/300] Validation [3/16] Loss: 0.52757  focal_loss 0.25376  dice_loss 0.27381 
Epoch [183/300] Validation [4/16] Loss: 0.28679  focal_loss 0.12004  dice_loss 0.16675 
Epoch [183/300] Validation [5/16] Loss: 0.30797  focal_loss 0.08804  dice_loss 0.21993 
Epoch [183/300] Validation [6/16] Loss: 0.28532  focal_loss 0.08144  dice_loss 0.20388 
Epoch [183/300] Validation [7/16] Loss: 0.27060  focal_loss 0.08615  dice_loss 0.18444 
Epoch [183/300] Validation [8/16] Loss: 0.43883  focal_loss 0.14496  dice_loss 0.29387 
Epoch [183/300] Validation [9/16] Loss: 0.20663  focal_loss 0.06988  dice_loss 0.13675 
Epoch [183/300] Validation [10/16] Loss: 0.51977  focal_loss 0.17972  dice_loss 0.34005 
Epoch [183/300] Validation [11/16] Loss: 0.21692  focal_loss 0.05181  dice_loss 0.16511 
Epoch [183/300] Validation [12/16] Loss: 0.35896  focal_loss 0.08222  dice_loss 0.27674 
Epoch [183/300] Validation [13/16] Loss: 0.30414  focal_loss 0.08714  dice_loss 0.21699 
Epoch [183/300] Validation [14/16] Loss: 0.47310  focal_loss 0.15422  dice_loss 0.31887 
Epoch [183/300] Validation [15/16] Loss: 0.13717  focal_loss 0.04244  dice_loss 0.09474 
Epoch [183/300] Validation [16/16] Loss: 0.12247  focal_loss 0.02367  dice_loss 0.09881 
Epoch [183/300] Validation metric {'Val/mean dice_metric': 0.9163788557052612, 'Val/mean miou_metric': 0.867178738117218, 'Val/mean f1': 0.9284316301345825, 'Val/mean precision': 0.9286085963249207, 'Val/mean recall': 0.9282547831535339, 'Val/mean hd95_metric': 23.162233352661133}
Cheakpoint...
Epoch [183/300] best acc:tensor([0.9164], device='cuda:0'), Now : mean acc: tensor([0.9164], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9163788557052612, 'Val/mean miou_metric': 0.867178738117218, 'Val/mean f1': 0.9284316301345825, 'Val/mean precision': 0.9286085963249207, 'Val/mean recall': 0.9282547831535339, 'Val/mean hd95_metric': 23.162233352661133}
Epoch [184/300] Training [1/62] Loss: 0.09956 
Epoch [184/300] Training [2/62] Loss: 0.07750 
Epoch [184/300] Training [3/62] Loss: 0.06449 
Epoch [184/300] Training [4/62] Loss: 0.06269 
Epoch [184/300] Training [5/62] Loss: 0.05829 
Epoch [184/300] Training [6/62] Loss: 0.06308 
Epoch [184/300] Training [7/62] Loss: 0.07787 
Epoch [184/300] Training [8/62] Loss: 0.05199 
Epoch [184/300] Training [9/62] Loss: 0.06146 
Epoch [184/300] Training [10/62] Loss: 0.08988 
Epoch [184/300] Training [11/62] Loss: 0.08374 
Epoch [184/300] Training [12/62] Loss: 0.05470 
Epoch [184/300] Training [13/62] Loss: 0.03758 
Epoch [184/300] Training [14/62] Loss: 0.05207 
Epoch [184/300] Training [15/62] Loss: 0.06119 
Epoch [184/300] Training [16/62] Loss: 0.08373 
Epoch [184/300] Training [17/62] Loss: 0.05055 
Epoch [184/300] Training [18/62] Loss: 0.12677 
Epoch [184/300] Training [19/62] Loss: 0.06885 
Epoch [184/300] Training [20/62] Loss: 0.10817 
Epoch [184/300] Training [21/62] Loss: 0.19770 
Epoch [184/300] Training [22/62] Loss: 0.05908 
Epoch [184/300] Training [23/62] Loss: 0.09582 
Epoch [184/300] Training [24/62] Loss: 0.03640 
Epoch [184/300] Training [25/62] Loss: 0.04286 
Epoch [184/300] Training [26/62] Loss: 0.05317 
Epoch [184/300] Training [27/62] Loss: 0.13367 
Epoch [184/300] Training [28/62] Loss: 0.12951 
Epoch [184/300] Training [29/62] Loss: 0.06802 
Epoch [184/300] Training [30/62] Loss: 0.06322 
Epoch [184/300] Training [31/62] Loss: 0.09397 
Epoch [184/300] Training [32/62] Loss: 0.05567 
Epoch [184/300] Training [33/62] Loss: 0.06720 
Epoch [184/300] Training [34/62] Loss: 0.06154 
Epoch [184/300] Training [35/62] Loss: 0.04070 
Epoch [184/300] Training [36/62] Loss: 0.03702 
Epoch [184/300] Training [37/62] Loss: 0.14598 
Epoch [184/300] Training [38/62] Loss: 0.19253 
Epoch [184/300] Training [39/62] Loss: 0.05039 
Epoch [184/300] Training [40/62] Loss: 0.06180 
Epoch [184/300] Training [41/62] Loss: 0.12432 
Epoch [184/300] Training [42/62] Loss: 0.04837 
Epoch [184/300] Training [43/62] Loss: 0.05490 
Epoch [184/300] Training [44/62] Loss: 0.16839 
Epoch [184/300] Training [45/62] Loss: 0.05968 
Epoch [184/300] Training [46/62] Loss: 0.05284 
Epoch [184/300] Training [47/62] Loss: 0.05567 
Epoch [184/300] Training [48/62] Loss: 0.11707 
Epoch [184/300] Training [49/62] Loss: 0.06809 
Epoch [184/300] Training [50/62] Loss: 0.09132 
Epoch [184/300] Training [51/62] Loss: 0.04641 
Epoch [184/300] Training [52/62] Loss: 0.07154 
Epoch [184/300] Training [53/62] Loss: 0.08438 
Epoch [184/300] Training [54/62] Loss: 0.07132 
Epoch [184/300] Training [55/62] Loss: 0.11462 
Epoch [184/300] Training [56/62] Loss: 0.14451 
Epoch [184/300] Training [57/62] Loss: 0.19664 
Epoch [184/300] Training [58/62] Loss: 0.06461 
Epoch [184/300] Training [59/62] Loss: 0.13056 
Epoch [184/300] Training [60/62] Loss: 0.07060 
Epoch [184/300] Training [61/62] Loss: 0.06137 
Epoch [184/300] Training [62/62] Loss: 0.87533 
Epoch [184/300] Training metric {'Train/mean dice_metric': 0.9424120187759399, 'Train/mean miou_metric': 0.9020496010780334, 'Train/mean f1': 0.9513166546821594, 'Train/mean precision': 0.9509585499763489, 'Train/mean recall': 0.9516749978065491, 'Train/mean hd95_metric': 15.052513122558594}
Epoch [184/300] Validation [1/16] Loss: 0.77758  focal_loss 0.52080  dice_loss 0.25677 
Epoch [184/300] Validation [2/16] Loss: 0.56111  focal_loss 0.20544  dice_loss 0.35567 
Epoch [184/300] Validation [3/16] Loss: 0.62300  focal_loss 0.34286  dice_loss 0.28014 
Epoch [184/300] Validation [4/16] Loss: 0.32072  focal_loss 0.13426  dice_loss 0.18646 
Epoch [184/300] Validation [5/16] Loss: 0.28519  focal_loss 0.10015  dice_loss 0.18504 
Epoch [184/300] Validation [6/16] Loss: 0.33267  focal_loss 0.09452  dice_loss 0.23815 
Epoch [184/300] Validation [7/16] Loss: 0.19448  focal_loss 0.07063  dice_loss 0.12385 
Epoch [184/300] Validation [8/16] Loss: 0.53554  focal_loss 0.20880  dice_loss 0.32674 
Epoch [184/300] Validation [9/16] Loss: 0.26057  focal_loss 0.10432  dice_loss 0.15626 
Epoch [184/300] Validation [10/16] Loss: 0.74123  focal_loss 0.26437  dice_loss 0.47686 
Epoch [184/300] Validation [11/16] Loss: 0.18428  focal_loss 0.05312  dice_loss 0.13116 
Epoch [184/300] Validation [12/16] Loss: 0.47978  focal_loss 0.10811  dice_loss 0.37167 
Epoch [184/300] Validation [13/16] Loss: 0.25189  focal_loss 0.07914  dice_loss 0.17275 
Epoch [184/300] Validation [14/16] Loss: 0.65446  focal_loss 0.25196  dice_loss 0.40250 
Epoch [184/300] Validation [15/16] Loss: 0.12058  focal_loss 0.03421  dice_loss 0.08637 
Epoch [184/300] Validation [16/16] Loss: 0.09998  focal_loss 0.02335  dice_loss 0.07662 
Epoch [184/300] Validation metric {'Val/mean dice_metric': 0.9057863354682922, 'Val/mean miou_metric': 0.8558313846588135, 'Val/mean f1': 0.9225417375564575, 'Val/mean precision': 0.9349159598350525, 'Val/mean recall': 0.9104909300804138, 'Val/mean hd95_metric': 21.793743133544922}
Cheakpoint...
Epoch [184/300] best acc:tensor([0.9164], device='cuda:0'), Now : mean acc: tensor([0.9058], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9057863354682922, 'Val/mean miou_metric': 0.8558313846588135, 'Val/mean f1': 0.9225417375564575, 'Val/mean precision': 0.9349159598350525, 'Val/mean recall': 0.9104909300804138, 'Val/mean hd95_metric': 21.793743133544922}
Epoch [185/300] Training [1/62] Loss: 0.07222 
Epoch [185/300] Training [2/62] Loss: 0.05349 
Epoch [185/300] Training [3/62] Loss: 0.11435 
Epoch [185/300] Training [4/62] Loss: 0.03832 
Epoch [185/300] Training [5/62] Loss: 0.03878 
Epoch [185/300] Training [6/62] Loss: 0.05581 
Epoch [185/300] Training [7/62] Loss: 0.07367 
Epoch [185/300] Training [8/62] Loss: 0.06958 
Epoch [185/300] Training [9/62] Loss: 0.11011 
Epoch [185/300] Training [10/62] Loss: 0.04596 
Epoch [185/300] Training [11/62] Loss: 0.07410 
Epoch [185/300] Training [12/62] Loss: 0.06212 
Epoch [185/300] Training [13/62] Loss: 0.07816 
Epoch [185/300] Training [14/62] Loss: 0.08298 
Epoch [185/300] Training [15/62] Loss: 0.08516 
Epoch [185/300] Training [16/62] Loss: 0.06865 
Epoch [185/300] Training [17/62] Loss: 0.06615 
Epoch [185/300] Training [18/62] Loss: 0.07994 
Epoch [185/300] Training [19/62] Loss: 0.06768 
Epoch [185/300] Training [20/62] Loss: 0.06092 
Epoch [185/300] Training [21/62] Loss: 0.17291 
Epoch [185/300] Training [22/62] Loss: 0.04364 
Epoch [185/300] Training [23/62] Loss: 0.05248 
Epoch [185/300] Training [24/62] Loss: 0.09628 
Epoch [185/300] Training [25/62] Loss: 0.06619 
Epoch [185/300] Training [26/62] Loss: 0.22695 
Epoch [185/300] Training [27/62] Loss: 0.08352 
Epoch [185/300] Training [28/62] Loss: 0.05540 
Epoch [185/300] Training [29/62] Loss: 0.09174 
Epoch [185/300] Training [30/62] Loss: 0.06815 
Epoch [185/300] Training [31/62] Loss: 0.06288 
Epoch [185/300] Training [32/62] Loss: 0.09005 
Epoch [185/300] Training [33/62] Loss: 0.05535 
Epoch [185/300] Training [34/62] Loss: 0.05541 
Epoch [185/300] Training [35/62] Loss: 0.09290 
Epoch [185/300] Training [36/62] Loss: 0.14509 
Epoch [185/300] Training [37/62] Loss: 0.04297 
Epoch [185/300] Training [38/62] Loss: 0.06242 
Epoch [185/300] Training [39/62] Loss: 0.08614 
Epoch [185/300] Training [40/62] Loss: 0.05354 
Epoch [185/300] Training [41/62] Loss: 0.06385 
Epoch [185/300] Training [42/62] Loss: 0.05968 
Epoch [185/300] Training [43/62] Loss: 0.05853 
Epoch [185/300] Training [44/62] Loss: 0.13809 
Epoch [185/300] Training [45/62] Loss: 0.06615 
Epoch [185/300] Training [46/62] Loss: 0.04942 
Epoch [185/300] Training [47/62] Loss: 0.19663 
Epoch [185/300] Training [48/62] Loss: 0.08573 
Epoch [185/300] Training [49/62] Loss: 0.07179 
Epoch [185/300] Training [50/62] Loss: 0.07051 
Epoch [185/300] Training [51/62] Loss: 0.06725 
Epoch [185/300] Training [52/62] Loss: 0.12543 
Epoch [185/300] Training [53/62] Loss: 0.05676 
Epoch [185/300] Training [54/62] Loss: 0.06714 
Epoch [185/300] Training [55/62] Loss: 0.04654 
Epoch [185/300] Training [56/62] Loss: 0.07826 
Epoch [185/300] Training [57/62] Loss: 0.06219 
Epoch [185/300] Training [58/62] Loss: 0.12450 
Epoch [185/300] Training [59/62] Loss: 0.05874 
Epoch [185/300] Training [60/62] Loss: 0.04339 
Epoch [185/300] Training [61/62] Loss: 0.22666 
Epoch [185/300] Training [62/62] Loss: 0.02127 
Epoch [185/300] Training metric {'Train/mean dice_metric': 0.9451712369918823, 'Train/mean miou_metric': 0.9050530195236206, 'Train/mean f1': 0.9546964168548584, 'Train/mean precision': 0.9508336186408997, 'Train/mean recall': 0.9585907459259033, 'Train/mean hd95_metric': 16.750837326049805}
Epoch [185/300] Validation [1/16] Loss: 0.58495  focal_loss 0.37508  dice_loss 0.20987 
Epoch [185/300] Validation [2/16] Loss: 0.52021  focal_loss 0.17885  dice_loss 0.34136 
Epoch [185/300] Validation [3/16] Loss: 0.59537  focal_loss 0.32816  dice_loss 0.26721 
Epoch [185/300] Validation [4/16] Loss: 0.28381  focal_loss 0.13386  dice_loss 0.14995 
Epoch [185/300] Validation [5/16] Loss: 0.34403  focal_loss 0.10768  dice_loss 0.23635 
Epoch [185/300] Validation [6/16] Loss: 0.30617  focal_loss 0.08736  dice_loss 0.21881 
Epoch [185/300] Validation [7/16] Loss: 0.23457  focal_loss 0.09567  dice_loss 0.13890 
Epoch [185/300] Validation [8/16] Loss: 0.45215  focal_loss 0.15202  dice_loss 0.30014 
Epoch [185/300] Validation [9/16] Loss: 0.20809  focal_loss 0.07899  dice_loss 0.12910 
Epoch [185/300] Validation [10/16] Loss: 0.40102  focal_loss 0.11076  dice_loss 0.29026 
Epoch [185/300] Validation [11/16] Loss: 0.16550  focal_loss 0.04196  dice_loss 0.12353 
Epoch [185/300] Validation [12/16] Loss: 0.49649  focal_loss 0.11242  dice_loss 0.38407 
Epoch [185/300] Validation [13/16] Loss: 0.20779  focal_loss 0.05939  dice_loss 0.14840 
Epoch [185/300] Validation [14/16] Loss: 0.62162  focal_loss 0.25891  dice_loss 0.36271 
Epoch [185/300] Validation [15/16] Loss: 0.09892  focal_loss 0.03328  dice_loss 0.06565 
Epoch [185/300] Validation [16/16] Loss: 0.07935  focal_loss 0.02118  dice_loss 0.05816 
Epoch [185/300] Validation metric {'Val/mean dice_metric': 0.9131543636322021, 'Val/mean miou_metric': 0.8643727898597717, 'Val/mean f1': 0.9294889569282532, 'Val/mean precision': 0.9345369338989258, 'Val/mean recall': 0.9244953989982605, 'Val/mean hd95_metric': 22.644323348999023}
Cheakpoint...
Epoch [185/300] best acc:tensor([0.9164], device='cuda:0'), Now : mean acc: tensor([0.9132], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9131543636322021, 'Val/mean miou_metric': 0.8643727898597717, 'Val/mean f1': 0.9294889569282532, 'Val/mean precision': 0.9345369338989258, 'Val/mean recall': 0.9244953989982605, 'Val/mean hd95_metric': 22.644323348999023}
Epoch [186/300] Training [1/62] Loss: 0.07728 
Epoch [186/300] Training [2/62] Loss: 0.15277 
Epoch [186/300] Training [3/62] Loss: 0.04426 
Epoch [186/300] Training [4/62] Loss: 0.06751 
Epoch [186/300] Training [5/62] Loss: 0.18028 
Epoch [186/300] Training [6/62] Loss: 0.06372 
Epoch [186/300] Training [7/62] Loss: 0.04950 
Epoch [186/300] Training [8/62] Loss: 0.12416 
Epoch [186/300] Training [9/62] Loss: 0.04045 
Epoch [186/300] Training [10/62] Loss: 0.05782 
Epoch [186/300] Training [11/62] Loss: 0.11519 
Epoch [186/300] Training [12/62] Loss: 0.04336 
Epoch [186/300] Training [13/62] Loss: 0.09157 
Epoch [186/300] Training [14/62] Loss: 0.05583 
Epoch [186/300] Training [15/62] Loss: 0.05466 
Epoch [186/300] Training [16/62] Loss: 0.07767 
Epoch [186/300] Training [17/62] Loss: 0.16874 
Epoch [186/300] Training [18/62] Loss: 0.05176 
Epoch [186/300] Training [19/62] Loss: 0.10084 
Epoch [186/300] Training [20/62] Loss: 0.05216 
Epoch [186/300] Training [21/62] Loss: 0.05212 
Epoch [186/300] Training [22/62] Loss: 0.05821 
Epoch [186/300] Training [23/62] Loss: 0.03992 
Epoch [186/300] Training [24/62] Loss: 0.10135 
Epoch [186/300] Training [25/62] Loss: 0.04644 
Epoch [186/300] Training [26/62] Loss: 0.07245 
Epoch [186/300] Training [27/62] Loss: 0.08273 
Epoch [186/300] Training [28/62] Loss: 0.06731 
Epoch [186/300] Training [29/62] Loss: 0.05230 
Epoch [186/300] Training [30/62] Loss: 0.03990 
Epoch [186/300] Training [31/62] Loss: 0.05197 
Epoch [186/300] Training [32/62] Loss: 0.04685 
Epoch [186/300] Training [33/62] Loss: 0.06230 
Epoch [186/300] Training [34/62] Loss: 0.20405 
Epoch [186/300] Training [35/62] Loss: 0.14369 
Epoch [186/300] Training [36/62] Loss: 0.05096 
Epoch [186/300] Training [37/62] Loss: 0.05101 
Epoch [186/300] Training [38/62] Loss: 0.05134 
Epoch [186/300] Training [39/62] Loss: 0.05945 
Epoch [186/300] Training [40/62] Loss: 0.09423 
Epoch [186/300] Training [41/62] Loss: 0.05072 
Epoch [186/300] Training [42/62] Loss: 0.07827 
Epoch [186/300] Training [43/62] Loss: 0.04951 
Epoch [186/300] Training [44/62] Loss: 0.06941 
Epoch [186/300] Training [45/62] Loss: 0.08102 
Epoch [186/300] Training [46/62] Loss: 0.14550 
Epoch [186/300] Training [47/62] Loss: 0.06247 
Epoch [186/300] Training [48/62] Loss: 0.07407 
Epoch [186/300] Training [49/62] Loss: 0.06370 
Epoch [186/300] Training [50/62] Loss: 0.08817 
Epoch [186/300] Training [51/62] Loss: 0.06121 
Epoch [186/300] Training [52/62] Loss: 0.11134 
Epoch [186/300] Training [53/62] Loss: 0.09786 
Epoch [186/300] Training [54/62] Loss: 0.07110 
Epoch [186/300] Training [55/62] Loss: 0.08745 
Epoch [186/300] Training [56/62] Loss: 0.04905 
Epoch [186/300] Training [57/62] Loss: 0.04762 
Epoch [186/300] Training [58/62] Loss: 0.03675 
Epoch [186/300] Training [59/62] Loss: 0.05499 
Epoch [186/300] Training [60/62] Loss: 0.06710 
Epoch [186/300] Training [61/62] Loss: 0.06801 
Epoch [186/300] Training [62/62] Loss: 0.04003 
Epoch [186/300] Training metric {'Train/mean dice_metric': 0.9488512277603149, 'Train/mean miou_metric': 0.9096642732620239, 'Train/mean f1': 0.9548591375350952, 'Train/mean precision': 0.9518381357192993, 'Train/mean recall': 0.9578995108604431, 'Train/mean hd95_metric': 14.116387367248535}
Epoch [186/300] Validation [1/16] Loss: 0.67126  focal_loss 0.43074  dice_loss 0.24051 
Epoch [186/300] Validation [2/16] Loss: 0.51495  focal_loss 0.19124  dice_loss 0.32371 
Epoch [186/300] Validation [3/16] Loss: 0.66968  focal_loss 0.39262  dice_loss 0.27706 
Epoch [186/300] Validation [4/16] Loss: 0.34894  focal_loss 0.16435  dice_loss 0.18459 
Epoch [186/300] Validation [5/16] Loss: 0.29081  focal_loss 0.10289  dice_loss 0.18792 
Epoch [186/300] Validation [6/16] Loss: 0.29474  focal_loss 0.11114  dice_loss 0.18360 
Epoch [186/300] Validation [7/16] Loss: 0.26134  focal_loss 0.10515  dice_loss 0.15619 
Epoch [186/300] Validation [8/16] Loss: 0.48372  focal_loss 0.18735  dice_loss 0.29637 
Epoch [186/300] Validation [9/16] Loss: 0.24507  focal_loss 0.10224  dice_loss 0.14282 
Epoch [186/300] Validation [10/16] Loss: 0.42354  focal_loss 0.12843  dice_loss 0.29512 
Epoch [186/300] Validation [11/16] Loss: 0.17325  focal_loss 0.06147  dice_loss 0.11178 
Epoch [186/300] Validation [12/16] Loss: 0.37995  focal_loss 0.10443  dice_loss 0.27552 
Epoch [186/300] Validation [13/16] Loss: 0.26563  focal_loss 0.10487  dice_loss 0.16076 
Epoch [186/300] Validation [14/16] Loss: 0.48066  focal_loss 0.20159  dice_loss 0.27907 
Epoch [186/300] Validation [15/16] Loss: 0.16243  focal_loss 0.06334  dice_loss 0.09909 
Epoch [186/300] Validation [16/16] Loss: 0.14439  focal_loss 0.04361  dice_loss 0.10079 
Epoch [186/300] Validation metric {'Val/mean dice_metric': 0.9179190993309021, 'Val/mean miou_metric': 0.8682212829589844, 'Val/mean f1': 0.9282585382461548, 'Val/mean precision': 0.9383782148361206, 'Val/mean recall': 0.9183546900749207, 'Val/mean hd95_metric': 21.019489288330078}
Cheakpoint...
Epoch [186/300] best acc:tensor([0.9179], device='cuda:0'), Now : mean acc: tensor([0.9179], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9179190993309021, 'Val/mean miou_metric': 0.8682212829589844, 'Val/mean f1': 0.9282585382461548, 'Val/mean precision': 0.9383782148361206, 'Val/mean recall': 0.9183546900749207, 'Val/mean hd95_metric': 21.019489288330078}
Epoch [187/300] Training [1/62] Loss: 0.07193 
Epoch [187/300] Training [2/62] Loss: 0.05498 
Epoch [187/300] Training [3/62] Loss: 0.09660 
Epoch [187/300] Training [4/62] Loss: 0.08840 
Epoch [187/300] Training [5/62] Loss: 0.05639 
Epoch [187/300] Training [6/62] Loss: 0.03193 
Epoch [187/300] Training [7/62] Loss: 0.03501 
Epoch [187/300] Training [8/62] Loss: 0.06288 
Epoch [187/300] Training [9/62] Loss: 0.08608 
Epoch [187/300] Training [10/62] Loss: 0.15419 
Epoch [187/300] Training [11/62] Loss: 0.04131 
Epoch [187/300] Training [12/62] Loss: 0.05072 
Epoch [187/300] Training [13/62] Loss: 0.04149 
Epoch [187/300] Training [14/62] Loss: 0.04230 
Epoch [187/300] Training [15/62] Loss: 0.09039 
Epoch [187/300] Training [16/62] Loss: 0.05856 
Epoch [187/300] Training [17/62] Loss: 0.04822 
Epoch [187/300] Training [18/62] Loss: 0.17909 
Epoch [187/300] Training [19/62] Loss: 0.06015 
Epoch [187/300] Training [20/62] Loss: 0.03352 
Epoch [187/300] Training [21/62] Loss: 0.06456 
Epoch [187/300] Training [22/62] Loss: 0.04346 
Epoch [187/300] Training [23/62] Loss: 0.04348 
Epoch [187/300] Training [24/62] Loss: 0.09424 
Epoch [187/300] Training [25/62] Loss: 0.04041 
Epoch [187/300] Training [26/62] Loss: 0.04933 
Epoch [187/300] Training [27/62] Loss: 0.09132 
Epoch [187/300] Training [28/62] Loss: 0.09186 
Epoch [187/300] Training [29/62] Loss: 0.12965 
Epoch [187/300] Training [30/62] Loss: 0.12152 
Epoch [187/300] Training [31/62] Loss: 0.07362 
Epoch [187/300] Training [32/62] Loss: 0.06757 
Epoch [187/300] Training [33/62] Loss: 0.05793 
Epoch [187/300] Training [34/62] Loss: 0.04367 
Epoch [187/300] Training [35/62] Loss: 0.07330 
Epoch [187/300] Training [36/62] Loss: 0.04037 
Epoch [187/300] Training [37/62] Loss: 0.11249 
Epoch [187/300] Training [38/62] Loss: 0.08770 
Epoch [187/300] Training [39/62] Loss: 0.04006 
Epoch [187/300] Training [40/62] Loss: 0.05606 
Epoch [187/300] Training [41/62] Loss: 0.17445 
Epoch [187/300] Training [42/62] Loss: 0.05129 
Epoch [187/300] Training [43/62] Loss: 0.06707 
Epoch [187/300] Training [44/62] Loss: 0.08615 
Epoch [187/300] Training [45/62] Loss: 0.04805 
Epoch [187/300] Training [46/62] Loss: 0.12378 
Epoch [187/300] Training [47/62] Loss: 0.04635 
Epoch [187/300] Training [48/62] Loss: 0.08870 
Epoch [187/300] Training [49/62] Loss: 0.04049 
Epoch [187/300] Training [50/62] Loss: 0.05534 
Epoch [187/300] Training [51/62] Loss: 0.05975 
Epoch [187/300] Training [52/62] Loss: 0.05855 
Epoch [187/300] Training [53/62] Loss: 0.06471 
Epoch [187/300] Training [54/62] Loss: 0.04713 
Epoch [187/300] Training [55/62] Loss: 0.06728 
Epoch [187/300] Training [56/62] Loss: 0.08466 
Epoch [187/300] Training [57/62] Loss: 0.05907 
Epoch [187/300] Training [58/62] Loss: 0.05009 
Epoch [187/300] Training [59/62] Loss: 0.06521 
Epoch [187/300] Training [60/62] Loss: 0.05576 
Epoch [187/300] Training [61/62] Loss: 0.09066 
Epoch [187/300] Training [62/62] Loss: 0.05849 
Epoch [187/300] Training metric {'Train/mean dice_metric': 0.9525915384292603, 'Train/mean miou_metric': 0.914929986000061, 'Train/mean f1': 0.9572315216064453, 'Train/mean precision': 0.9565425515174866, 'Train/mean recall': 0.9579212665557861, 'Train/mean hd95_metric': 12.207752227783203}
Epoch [187/300] Validation [1/16] Loss: 0.61999  focal_loss 0.40823  dice_loss 0.21176 
Epoch [187/300] Validation [2/16] Loss: 0.47943  focal_loss 0.16237  dice_loss 0.31706 
Epoch [187/300] Validation [3/16] Loss: 0.65291  focal_loss 0.34412  dice_loss 0.30880 
Epoch [187/300] Validation [4/16] Loss: 0.24344  focal_loss 0.10263  dice_loss 0.14082 
Epoch [187/300] Validation [5/16] Loss: 0.35499  focal_loss 0.10916  dice_loss 0.24583 
Epoch [187/300] Validation [6/16] Loss: 0.27606  focal_loss 0.06706  dice_loss 0.20900 
Epoch [187/300] Validation [7/16] Loss: 0.21322  focal_loss 0.07879  dice_loss 0.13443 
Epoch [187/300] Validation [8/16] Loss: 0.48691  focal_loss 0.15762  dice_loss 0.32929 
Epoch [187/300] Validation [9/16] Loss: 0.18779  focal_loss 0.06665  dice_loss 0.12114 
Epoch [187/300] Validation [10/16] Loss: 0.43680  focal_loss 0.11887  dice_loss 0.31793 
Epoch [187/300] Validation [11/16] Loss: 0.13709  focal_loss 0.03894  dice_loss 0.09815 
Epoch [187/300] Validation [12/16] Loss: 0.37853  focal_loss 0.09710  dice_loss 0.28143 
Epoch [187/300] Validation [13/16] Loss: 0.24897  focal_loss 0.07964  dice_loss 0.16933 
Epoch [187/300] Validation [14/16] Loss: 0.57275  focal_loss 0.21348  dice_loss 0.35927 
Epoch [187/300] Validation [15/16] Loss: 0.13435  focal_loss 0.04737  dice_loss 0.08698 
Epoch [187/300] Validation [16/16] Loss: 0.08247  focal_loss 0.02457  dice_loss 0.05790 
Epoch [187/300] Validation metric {'Val/mean dice_metric': 0.9196426272392273, 'Val/mean miou_metric': 0.8721797466278076, 'Val/mean f1': 0.9317564964294434, 'Val/mean precision': 0.9428234100341797, 'Val/mean recall': 0.9209463596343994, 'Val/mean hd95_metric': 19.638212203979492}
Cheakpoint...
Epoch [187/300] best acc:tensor([0.9196], device='cuda:0'), Now : mean acc: tensor([0.9196], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9196426272392273, 'Val/mean miou_metric': 0.8721797466278076, 'Val/mean f1': 0.9317564964294434, 'Val/mean precision': 0.9428234100341797, 'Val/mean recall': 0.9209463596343994, 'Val/mean hd95_metric': 19.638212203979492}
Epoch [188/300] Training [1/62] Loss: 0.05719 
Epoch [188/300] Training [2/62] Loss: 0.07066 
Epoch [188/300] Training [3/62] Loss: 0.04777 
Epoch [188/300] Training [4/62] Loss: 0.05679 
Epoch [188/300] Training [5/62] Loss: 0.06480 
Epoch [188/300] Training [6/62] Loss: 0.09738 
Epoch [188/300] Training [7/62] Loss: 0.06505 
Epoch [188/300] Training [8/62] Loss: 0.04744 
Epoch [188/300] Training [9/62] Loss: 0.05420 
Epoch [188/300] Training [10/62] Loss: 0.08172 
Epoch [188/300] Training [11/62] Loss: 0.12446 
Epoch [188/300] Training [12/62] Loss: 0.05590 
Epoch [188/300] Training [13/62] Loss: 0.03462 
Epoch [188/300] Training [14/62] Loss: 0.04268 
Epoch [188/300] Training [15/62] Loss: 0.04160 
Epoch [188/300] Training [16/62] Loss: 0.04337 
Epoch [188/300] Training [17/62] Loss: 0.04962 
Epoch [188/300] Training [18/62] Loss: 0.07106 
Epoch [188/300] Training [19/62] Loss: 0.04991 
Epoch [188/300] Training [20/62] Loss: 0.07304 
Epoch [188/300] Training [21/62] Loss: 0.05000 
Epoch [188/300] Training [22/62] Loss: 0.08508 
Epoch [188/300] Training [23/62] Loss: 0.06468 
Epoch [188/300] Training [24/62] Loss: 0.04060 
Epoch [188/300] Training [25/62] Loss: 0.07221 
Epoch [188/300] Training [26/62] Loss: 0.07466 
Epoch [188/300] Training [27/62] Loss: 0.04090 
Epoch [188/300] Training [28/62] Loss: 0.04585 
Epoch [188/300] Training [29/62] Loss: 0.12124 
Epoch [188/300] Training [30/62] Loss: 0.05038 
Epoch [188/300] Training [31/62] Loss: 0.05388 
Epoch [188/300] Training [32/62] Loss: 0.03420 
Epoch [188/300] Training [33/62] Loss: 0.06622 
Epoch [188/300] Training [34/62] Loss: 0.04585 
Epoch [188/300] Training [35/62] Loss: 0.04504 
Epoch [188/300] Training [36/62] Loss: 0.07441 
Epoch [188/300] Training [37/62] Loss: 0.04262 
Epoch [188/300] Training [38/62] Loss: 0.06227 
Epoch [188/300] Training [39/62] Loss: 0.05763 
Epoch [188/300] Training [40/62] Loss: 0.04782 
Epoch [188/300] Training [41/62] Loss: 0.06610 
Epoch [188/300] Training [42/62] Loss: 0.22127 
Epoch [188/300] Training [43/62] Loss: 0.03676 
Epoch [188/300] Training [44/62] Loss: 0.08397 
Epoch [188/300] Training [45/62] Loss: 0.03583 
Epoch [188/300] Training [46/62] Loss: 0.03928 
Epoch [188/300] Training [47/62] Loss: 0.07048 
Epoch [188/300] Training [48/62] Loss: 0.05943 
Epoch [188/300] Training [49/62] Loss: 0.03975 
Epoch [188/300] Training [50/62] Loss: 0.10596 
Epoch [188/300] Training [51/62] Loss: 0.04186 
Epoch [188/300] Training [52/62] Loss: 0.05592 
Epoch [188/300] Training [53/62] Loss: 0.03220 
Epoch [188/300] Training [54/62] Loss: 0.08410 
Epoch [188/300] Training [55/62] Loss: 0.06837 
Epoch [188/300] Training [56/62] Loss: 0.06474 
Epoch [188/300] Training [57/62] Loss: 0.06044 
Epoch [188/300] Training [58/62] Loss: 0.06158 
Epoch [188/300] Training [59/62] Loss: 0.07653 
Epoch [188/300] Training [60/62] Loss: 0.06885 
Epoch [188/300] Training [61/62] Loss: 0.07822 
Epoch [188/300] Training [62/62] Loss: 0.03567 
Epoch [188/300] Training metric {'Train/mean dice_metric': 0.9567378163337708, 'Train/mean miou_metric': 0.9216112494468689, 'Train/mean f1': 0.9611312747001648, 'Train/mean precision': 0.9564393162727356, 'Train/mean recall': 0.965869665145874, 'Train/mean hd95_metric': 10.079575538635254}
Epoch [188/300] Validation [1/16] Loss: 0.59127  focal_loss 0.37078  dice_loss 0.22049 
Epoch [188/300] Validation [2/16] Loss: 0.55024  focal_loss 0.20624  dice_loss 0.34400 
Epoch [188/300] Validation [3/16] Loss: 0.64174  focal_loss 0.34305  dice_loss 0.29869 
Epoch [188/300] Validation [4/16] Loss: 0.40243  focal_loss 0.20237  dice_loss 0.20006 
Epoch [188/300] Validation [5/16] Loss: 0.36030  focal_loss 0.13451  dice_loss 0.22579 
Epoch [188/300] Validation [6/16] Loss: 0.33522  focal_loss 0.10390  dice_loss 0.23132 
Epoch [188/300] Validation [7/16] Loss: 0.23495  focal_loss 0.09568  dice_loss 0.13927 
Epoch [188/300] Validation [8/16] Loss: 0.48338  focal_loss 0.17461  dice_loss 0.30877 
Epoch [188/300] Validation [9/16] Loss: 0.35558  focal_loss 0.14795  dice_loss 0.20763 
Epoch [188/300] Validation [10/16] Loss: 0.60874  focal_loss 0.20781  dice_loss 0.40092 
Epoch [188/300] Validation [11/16] Loss: 0.19946  focal_loss 0.06083  dice_loss 0.13863 
Epoch [188/300] Validation [12/16] Loss: 0.41529  focal_loss 0.12163  dice_loss 0.29367 
Epoch [188/300] Validation [13/16] Loss: 0.26842  focal_loss 0.10406  dice_loss 0.16436 
Epoch [188/300] Validation [14/16] Loss: 0.55259  focal_loss 0.21488  dice_loss 0.33771 
Epoch [188/300] Validation [15/16] Loss: 0.11229  focal_loss 0.03833  dice_loss 0.07396 
Epoch [188/300] Validation [16/16] Loss: 0.09887  focal_loss 0.02969  dice_loss 0.06917 
Epoch [188/300] Validation metric {'Val/mean dice_metric': 0.9193352460861206, 'Val/mean miou_metric': 0.8723087906837463, 'Val/mean f1': 0.930875301361084, 'Val/mean precision': 0.937874436378479, 'Val/mean recall': 0.9239799380302429, 'Val/mean hd95_metric': 18.952390670776367}
Cheakpoint...
Epoch [188/300] best acc:tensor([0.9196], device='cuda:0'), Now : mean acc: tensor([0.9193], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9193352460861206, 'Val/mean miou_metric': 0.8723087906837463, 'Val/mean f1': 0.930875301361084, 'Val/mean precision': 0.937874436378479, 'Val/mean recall': 0.9239799380302429, 'Val/mean hd95_metric': 18.952390670776367}
Epoch [189/300] Training [1/62] Loss: 0.03591 
Epoch [189/300] Training [2/62] Loss: 0.08375 
Epoch [189/300] Training [3/62] Loss: 0.07506 
Epoch [189/300] Training [4/62] Loss: 0.08453 
Epoch [189/300] Training [5/62] Loss: 0.04993 
Epoch [189/300] Training [6/62] Loss: 0.07968 
Epoch [189/300] Training [7/62] Loss: 0.04372 
Epoch [189/300] Training [8/62] Loss: 0.11160 
Epoch [189/300] Training [9/62] Loss: 0.07312 
Epoch [189/300] Training [10/62] Loss: 0.04201 
Epoch [189/300] Training [11/62] Loss: 0.06318 
Epoch [189/300] Training [12/62] Loss: 0.05424 
Epoch [189/300] Training [13/62] Loss: 0.12248 
Epoch [189/300] Training [14/62] Loss: 0.04321 
Epoch [189/300] Training [15/62] Loss: 0.06175 
Epoch [189/300] Training [16/62] Loss: 0.03775 
Epoch [189/300] Training [17/62] Loss: 0.13403 
Epoch [189/300] Training [18/62] Loss: 0.04722 
Epoch [189/300] Training [19/62] Loss: 0.10918 
Epoch [189/300] Training [20/62] Loss: 0.08900 
Epoch [189/300] Training [21/62] Loss: 0.07241 
Epoch [189/300] Training [22/62] Loss: 0.08009 
Epoch [189/300] Training [23/62] Loss: 0.04300 
Epoch [189/300] Training [24/62] Loss: 0.15258 
Epoch [189/300] Training [25/62] Loss: 0.08493 
Epoch [189/300] Training [26/62] Loss: 0.14382 
Epoch [189/300] Training [27/62] Loss: 0.03597 
Epoch [189/300] Training [28/62] Loss: 0.06162 
Epoch [189/300] Training [29/62] Loss: 0.04528 
Epoch [189/300] Training [30/62] Loss: 0.11290 
Epoch [189/300] Training [31/62] Loss: 0.05018 
Epoch [189/300] Training [32/62] Loss: 0.07913 
Epoch [189/300] Training [33/62] Loss: 0.05114 
Epoch [189/300] Training [34/62] Loss: 0.08495 
Epoch [189/300] Training [35/62] Loss: 0.09108 
Epoch [189/300] Training [36/62] Loss: 0.14644 
Epoch [189/300] Training [37/62] Loss: 0.03842 
Epoch [189/300] Training [38/62] Loss: 0.04464 
Epoch [189/300] Training [39/62] Loss: 0.05801 
Epoch [189/300] Training [40/62] Loss: 0.05649 
Epoch [189/300] Training [41/62] Loss: 0.05077 
Epoch [189/300] Training [42/62] Loss: 0.07500 
Epoch [189/300] Training [43/62] Loss: 0.05239 
Epoch [189/300] Training [44/62] Loss: 0.05233 
Epoch [189/300] Training [45/62] Loss: 0.07955 
Epoch [189/300] Training [46/62] Loss: 0.05848 
Epoch [189/300] Training [47/62] Loss: 0.06300 
Epoch [189/300] Training [48/62] Loss: 0.15905 
Epoch [189/300] Training [49/62] Loss: 0.05584 
Epoch [189/300] Training [50/62] Loss: 0.05463 
Epoch [189/300] Training [51/62] Loss: 0.02990 
Epoch [189/300] Training [52/62] Loss: 0.04854 
Epoch [189/300] Training [53/62] Loss: 0.15590 
Epoch [189/300] Training [54/62] Loss: 0.09446 
Epoch [189/300] Training [55/62] Loss: 0.05238 
Epoch [189/300] Training [56/62] Loss: 0.05456 
Epoch [189/300] Training [57/62] Loss: 0.34436 
Epoch [189/300] Training [58/62] Loss: 0.06383 
Epoch [189/300] Training [59/62] Loss: 0.07022 
Epoch [189/300] Training [60/62] Loss: 0.05903 
Epoch [189/300] Training [61/62] Loss: 0.06240 
Epoch [189/300] Training [62/62] Loss: 0.03563 
Epoch [189/300] Training metric {'Train/mean dice_metric': 0.9461401700973511, 'Train/mean miou_metric': 0.9091733694076538, 'Train/mean f1': 0.9568257331848145, 'Train/mean precision': 0.953998863697052, 'Train/mean recall': 0.9596694111824036, 'Train/mean hd95_metric': 12.839978218078613}
Epoch [189/300] Validation [1/16] Loss: 0.69597  focal_loss 0.44558  dice_loss 0.25039 
Epoch [189/300] Validation [2/16] Loss: 0.56343  focal_loss 0.20182  dice_loss 0.36161 
Epoch [189/300] Validation [3/16] Loss: 0.63010  focal_loss 0.35150  dice_loss 0.27860 
Epoch [189/300] Validation [4/16] Loss: 0.38205  focal_loss 0.17129  dice_loss 0.21077 
Epoch [189/300] Validation [5/16] Loss: 0.35043  focal_loss 0.11567  dice_loss 0.23476 
Epoch [189/300] Validation [6/16] Loss: 0.29184  focal_loss 0.08485  dice_loss 0.20699 
Epoch [189/300] Validation [7/16] Loss: 0.21649  focal_loss 0.09315  dice_loss 0.12334 
Epoch [189/300] Validation [8/16] Loss: 0.47524  focal_loss 0.15670  dice_loss 0.31854 
Epoch [189/300] Validation [9/16] Loss: 0.18466  focal_loss 0.06635  dice_loss 0.11831 
Epoch [189/300] Validation [10/16] Loss: 0.43348  focal_loss 0.13407  dice_loss 0.29941 
Epoch [189/300] Validation [11/16] Loss: 0.20600  focal_loss 0.08260  dice_loss 0.12340 
Epoch [189/300] Validation [12/16] Loss: 0.40320  focal_loss 0.11555  dice_loss 0.28765 
Epoch [189/300] Validation [13/16] Loss: 0.30504  focal_loss 0.11230  dice_loss 0.19274 
Epoch [189/300] Validation [14/16] Loss: 0.55028  focal_loss 0.24335  dice_loss 0.30692 
Epoch [189/300] Validation [15/16] Loss: 0.15018  focal_loss 0.05628  dice_loss 0.09390 
Epoch [189/300] Validation [16/16] Loss: 0.12479  focal_loss 0.03784  dice_loss 0.08694 
Epoch [189/300] Validation metric {'Val/mean dice_metric': 0.9131825566291809, 'Val/mean miou_metric': 0.8654312491416931, 'Val/mean f1': 0.9294706583023071, 'Val/mean precision': 0.9392207860946655, 'Val/mean recall': 0.9199209809303284, 'Val/mean hd95_metric': 21.161001205444336}
Cheakpoint...
Epoch [189/300] best acc:tensor([0.9196], device='cuda:0'), Now : mean acc: tensor([0.9132], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9131825566291809, 'Val/mean miou_metric': 0.8654312491416931, 'Val/mean f1': 0.9294706583023071, 'Val/mean precision': 0.9392207860946655, 'Val/mean recall': 0.9199209809303284, 'Val/mean hd95_metric': 21.161001205444336}
Epoch [190/300] Training [1/62] Loss: 0.08838 
Epoch [190/300] Training [2/62] Loss: 0.05078 
Epoch [190/300] Training [3/62] Loss: 0.22984 
Epoch [190/300] Training [4/62] Loss: 0.09043 
Epoch [190/300] Training [5/62] Loss: 0.04629 
Epoch [190/300] Training [6/62] Loss: 0.06009 
Epoch [190/300] Training [7/62] Loss: 0.03393 
Epoch [190/300] Training [8/62] Loss: 0.07455 
Epoch [190/300] Training [9/62] Loss: 0.04400 
Epoch [190/300] Training [10/62] Loss: 0.06260 
Epoch [190/300] Training [11/62] Loss: 0.09894 
Epoch [190/300] Training [12/62] Loss: 0.08466 
Epoch [190/300] Training [13/62] Loss: 0.06242 
Epoch [190/300] Training [14/62] Loss: 0.13361 
Epoch [190/300] Training [15/62] Loss: 0.10559 
Epoch [190/300] Training [16/62] Loss: 0.05713 
Epoch [190/300] Training [17/62] Loss: 0.07523 
Epoch [190/300] Training [18/62] Loss: 0.08745 
Epoch [190/300] Training [19/62] Loss: 0.04757 
Epoch [190/300] Training [20/62] Loss: 0.13006 
Epoch [190/300] Training [21/62] Loss: 0.13156 
Epoch [190/300] Training [22/62] Loss: 0.10218 
Epoch [190/300] Training [23/62] Loss: 0.08253 
Epoch [190/300] Training [24/62] Loss: 0.04176 
Epoch [190/300] Training [25/62] Loss: 0.04507 
Epoch [190/300] Training [26/62] Loss: 0.08922 
Epoch [190/300] Training [27/62] Loss: 0.04457 
Epoch [190/300] Training [28/62] Loss: 0.06887 
Epoch [190/300] Training [29/62] Loss: 0.06467 
Epoch [190/300] Training [30/62] Loss: 0.04905 
Epoch [190/300] Training [31/62] Loss: 0.05580 
Epoch [190/300] Training [32/62] Loss: 0.07833 
Epoch [190/300] Training [33/62] Loss: 0.05759 
Epoch [190/300] Training [34/62] Loss: 0.04194 
Epoch [190/300] Training [35/62] Loss: 0.08841 
Epoch [190/300] Training [36/62] Loss: 0.05072 
Epoch [190/300] Training [37/62] Loss: 0.03061 
Epoch [190/300] Training [38/62] Loss: 0.09159 
Epoch [190/300] Training [39/62] Loss: 0.06193 
Epoch [190/300] Training [40/62] Loss: 0.04329 
Epoch [190/300] Training [41/62] Loss: 0.08494 
Epoch [190/300] Training [42/62] Loss: 0.09886 
Epoch [190/300] Training [43/62] Loss: 0.07165 
Epoch [190/300] Training [44/62] Loss: 0.04856 
Epoch [190/300] Training [45/62] Loss: 0.04693 
Epoch [190/300] Training [46/62] Loss: 0.04825 
Epoch [190/300] Training [47/62] Loss: 0.07815 
Epoch [190/300] Training [48/62] Loss: 0.05249 
Epoch [190/300] Training [49/62] Loss: 0.04560 
Epoch [190/300] Training [50/62] Loss: 0.05433 
Epoch [190/300] Training [51/62] Loss: 0.05196 
Epoch [190/300] Training [52/62] Loss: 0.05089 
Epoch [190/300] Training [53/62] Loss: 0.03959 
Epoch [190/300] Training [54/62] Loss: 0.05488 
Epoch [190/300] Training [55/62] Loss: 0.06510 
Epoch [190/300] Training [56/62] Loss: 0.08280 
Epoch [190/300] Training [57/62] Loss: 0.03753 
Epoch [190/300] Training [58/62] Loss: 0.07113 
Epoch [190/300] Training [59/62] Loss: 0.04515 
Epoch [190/300] Training [60/62] Loss: 0.04072 
Epoch [190/300] Training [61/62] Loss: 0.08396 
Epoch [190/300] Training [62/62] Loss: 0.10957 
Epoch [190/300] Training metric {'Train/mean dice_metric': 0.9526174068450928, 'Train/mean miou_metric': 0.9148374795913696, 'Train/mean f1': 0.9583801627159119, 'Train/mean precision': 0.9562221765518188, 'Train/mean recall': 0.9605478644371033, 'Train/mean hd95_metric': 11.645744323730469}
Epoch [190/300] Validation [1/16] Loss: 0.62982  focal_loss 0.41653  dice_loss 0.21329 
Epoch [190/300] Validation [2/16] Loss: 0.48744  focal_loss 0.18418  dice_loss 0.30325 
Epoch [190/300] Validation [3/16] Loss: 0.59420  focal_loss 0.33119  dice_loss 0.26301 
Epoch [190/300] Validation [4/16] Loss: 0.32868  focal_loss 0.14615  dice_loss 0.18254 
Epoch [190/300] Validation [5/16] Loss: 0.37124  focal_loss 0.11348  dice_loss 0.25775 
Epoch [190/300] Validation [6/16] Loss: 0.31984  focal_loss 0.10239  dice_loss 0.21744 
Epoch [190/300] Validation [7/16] Loss: 0.24862  focal_loss 0.09201  dice_loss 0.15661 
Epoch [190/300] Validation [8/16] Loss: 0.54866  focal_loss 0.18609  dice_loss 0.36257 
Epoch [190/300] Validation [9/16] Loss: 0.18888  focal_loss 0.07438  dice_loss 0.11450 
Epoch [190/300] Validation [10/16] Loss: 0.51100  focal_loss 0.15582  dice_loss 0.35518 
Epoch [190/300] Validation [11/16] Loss: 0.16706  focal_loss 0.05481  dice_loss 0.11225 
Epoch [190/300] Validation [12/16] Loss: 0.42193  focal_loss 0.11147  dice_loss 0.31045 
Epoch [190/300] Validation [13/16] Loss: 0.21260  focal_loss 0.06807  dice_loss 0.14453 
Epoch [190/300] Validation [14/16] Loss: 0.59524  focal_loss 0.24881  dice_loss 0.34643 
Epoch [190/300] Validation [15/16] Loss: 0.12522  focal_loss 0.04398  dice_loss 0.08124 
Epoch [190/300] Validation [16/16] Loss: 0.12969  focal_loss 0.05823  dice_loss 0.07146 
Epoch [190/300] Validation metric {'Val/mean dice_metric': 0.9182878136634827, 'Val/mean miou_metric': 0.8701643347740173, 'Val/mean f1': 0.9318807721138, 'Val/mean precision': 0.9404894113540649, 'Val/mean recall': 0.9234281778335571, 'Val/mean hd95_metric': 19.946109771728516}
Cheakpoint...
Epoch [190/300] best acc:tensor([0.9196], device='cuda:0'), Now : mean acc: tensor([0.9183], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9182878136634827, 'Val/mean miou_metric': 0.8701643347740173, 'Val/mean f1': 0.9318807721138, 'Val/mean precision': 0.9404894113540649, 'Val/mean recall': 0.9234281778335571, 'Val/mean hd95_metric': 19.946109771728516}
Epoch [191/300] Training [1/62] Loss: 0.09330 
Epoch [191/300] Training [2/62] Loss: 0.05756 
Epoch [191/300] Training [3/62] Loss: 0.05617 
Epoch [191/300] Training [4/62] Loss: 0.04608 
Epoch [191/300] Training [5/62] Loss: 0.05883 
Epoch [191/300] Training [6/62] Loss: 0.25059 
Epoch [191/300] Training [7/62] Loss: 0.04661 
Epoch [191/300] Training [8/62] Loss: 0.04929 
Epoch [191/300] Training [9/62] Loss: 0.06192 
Epoch [191/300] Training [10/62] Loss: 0.04103 
Epoch [191/300] Training [11/62] Loss: 0.08349 
Epoch [191/300] Training [12/62] Loss: 0.07899 
Epoch [191/300] Training [13/62] Loss: 0.14900 
Epoch [191/300] Training [14/62] Loss: 0.09792 
Epoch [191/300] Training [15/62] Loss: 0.11403 
Epoch [191/300] Training [16/62] Loss: 0.03913 
Epoch [191/300] Training [17/62] Loss: 0.08439 
Epoch [191/300] Training [18/62] Loss: 0.04028 
Epoch [191/300] Training [19/62] Loss: 0.05120 
Epoch [191/300] Training [20/62] Loss: 0.04725 
Epoch [191/300] Training [21/62] Loss: 0.08772 
Epoch [191/300] Training [22/62] Loss: 0.07585 
Epoch [191/300] Training [23/62] Loss: 0.05360 
Epoch [191/300] Training [24/62] Loss: 0.04306 
Epoch [191/300] Training [25/62] Loss: 0.04974 
Epoch [191/300] Training [26/62] Loss: 0.07894 
Epoch [191/300] Training [27/62] Loss: 0.06847 
Epoch [191/300] Training [28/62] Loss: 0.04315 
Epoch [191/300] Training [29/62] Loss: 0.05114 
Epoch [191/300] Training [30/62] Loss: 0.07867 
Epoch [191/300] Training [31/62] Loss: 0.12383 
Epoch [191/300] Training [32/62] Loss: 0.04725 
Epoch [191/300] Training [33/62] Loss: 0.04045 
Epoch [191/300] Training [34/62] Loss: 0.04018 
Epoch [191/300] Training [35/62] Loss: 0.06704 
Epoch [191/300] Training [36/62] Loss: 0.05605 
Epoch [191/300] Training [37/62] Loss: 0.17155 
Epoch [191/300] Training [38/62] Loss: 0.04918 
Epoch [191/300] Training [39/62] Loss: 0.05106 
Epoch [191/300] Training [40/62] Loss: 0.03668 
Epoch [191/300] Training [41/62] Loss: 0.09228 
Epoch [191/300] Training [42/62] Loss: 0.06732 
Epoch [191/300] Training [43/62] Loss: 0.05464 
Epoch [191/300] Training [44/62] Loss: 0.07884 
Epoch [191/300] Training [45/62] Loss: 0.04535 
Epoch [191/300] Training [46/62] Loss: 0.04288 
Epoch [191/300] Training [47/62] Loss: 0.03639 
Epoch [191/300] Training [48/62] Loss: 0.10616 
Epoch [191/300] Training [49/62] Loss: 0.06280 
Epoch [191/300] Training [50/62] Loss: 0.03121 
Epoch [191/300] Training [51/62] Loss: 0.11905 
Epoch [191/300] Training [52/62] Loss: 0.04014 
Epoch [191/300] Training [53/62] Loss: 0.06188 
Epoch [191/300] Training [54/62] Loss: 0.05602 
Epoch [191/300] Training [55/62] Loss: 0.18734 
Epoch [191/300] Training [56/62] Loss: 0.05093 
Epoch [191/300] Training [57/62] Loss: 0.03989 
Epoch [191/300] Training [58/62] Loss: 0.04734 
Epoch [191/300] Training [59/62] Loss: 0.07523 
Epoch [191/300] Training [60/62] Loss: 0.08852 
Epoch [191/300] Training [61/62] Loss: 0.04583 
Epoch [191/300] Training [62/62] Loss: 0.08058 
Epoch [191/300] Training metric {'Train/mean dice_metric': 0.9518833160400391, 'Train/mean miou_metric': 0.9173171520233154, 'Train/mean f1': 0.9599494934082031, 'Train/mean precision': 0.9582713842391968, 'Train/mean recall': 0.9616335034370422, 'Train/mean hd95_metric': 10.406610488891602}
Epoch [191/300] Validation [1/16] Loss: 0.61291  focal_loss 0.40162  dice_loss 0.21129 
Epoch [191/300] Validation [2/16] Loss: 0.49866  focal_loss 0.16291  dice_loss 0.33576 
Epoch [191/300] Validation [3/16] Loss: 0.68302  focal_loss 0.38203  dice_loss 0.30099 
Epoch [191/300] Validation [4/16] Loss: 0.31160  focal_loss 0.14510  dice_loss 0.16650 
Epoch [191/300] Validation [5/16] Loss: 0.43246  focal_loss 0.13024  dice_loss 0.30223 
Epoch [191/300] Validation [6/16] Loss: 0.31706  focal_loss 0.10524  dice_loss 0.21182 
Epoch [191/300] Validation [7/16] Loss: 0.16947  focal_loss 0.06293  dice_loss 0.10654 
Epoch [191/300] Validation [8/16] Loss: 0.50088  focal_loss 0.18051  dice_loss 0.32037 
Epoch [191/300] Validation [9/16] Loss: 0.35787  focal_loss 0.13586  dice_loss 0.22201 
Epoch [191/300] Validation [10/16] Loss: 0.41053  focal_loss 0.11753  dice_loss 0.29300 
Epoch [191/300] Validation [11/16] Loss: 0.22407  focal_loss 0.08502  dice_loss 0.13905 
Epoch [191/300] Validation [12/16] Loss: 0.45216  focal_loss 0.10116  dice_loss 0.35100 
Epoch [191/300] Validation [13/16] Loss: 0.28119  focal_loss 0.09814  dice_loss 0.18306 
Epoch [191/300] Validation [14/16] Loss: 0.45877  focal_loss 0.16694  dice_loss 0.29183 
Epoch [191/300] Validation [15/16] Loss: 0.09628  focal_loss 0.02661  dice_loss 0.06967 
Epoch [191/300] Validation [16/16] Loss: 0.15950  focal_loss 0.05110  dice_loss 0.10840 
Epoch [191/300] Validation metric {'Val/mean dice_metric': 0.9157655239105225, 'Val/mean miou_metric': 0.8706046938896179, 'Val/mean f1': 0.9323689341545105, 'Val/mean precision': 0.941706120967865, 'Val/mean recall': 0.9232150316238403, 'Val/mean hd95_metric': 18.885854721069336}
Cheakpoint...
Epoch [191/300] best acc:tensor([0.9196], device='cuda:0'), Now : mean acc: tensor([0.9158], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9157655239105225, 'Val/mean miou_metric': 0.8706046938896179, 'Val/mean f1': 0.9323689341545105, 'Val/mean precision': 0.941706120967865, 'Val/mean recall': 0.9232150316238403, 'Val/mean hd95_metric': 18.885854721069336}
Epoch [192/300] Training [1/62] Loss: 0.05067 
Epoch [192/300] Training [2/62] Loss: 0.28144 
Epoch [192/300] Training [3/62] Loss: 0.08065 
Epoch [192/300] Training [4/62] Loss: 0.08198 
Epoch [192/300] Training [5/62] Loss: 0.06153 
Epoch [192/300] Training [6/62] Loss: 0.05912 
Epoch [192/300] Training [7/62] Loss: 0.06563 
Epoch [192/300] Training [8/62] Loss: 0.06440 
Epoch [192/300] Training [9/62] Loss: 0.03828 
Epoch [192/300] Training [10/62] Loss: 0.07588 
Epoch [192/300] Training [11/62] Loss: 0.04667 
Epoch [192/300] Training [12/62] Loss: 0.05824 
Epoch [192/300] Training [13/62] Loss: 0.04616 
Epoch [192/300] Training [14/62] Loss: 0.04777 
Epoch [192/300] Training [15/62] Loss: 0.14647 
Epoch [192/300] Training [16/62] Loss: 0.07295 
Epoch [192/300] Training [17/62] Loss: 0.06765 
Epoch [192/300] Training [18/62] Loss: 0.04799 
Epoch [192/300] Training [19/62] Loss: 0.08956 
Epoch [192/300] Training [20/62] Loss: 0.09091 
Epoch [192/300] Training [21/62] Loss: 0.04105 
Epoch [192/300] Training [22/62] Loss: 0.04069 
Epoch [192/300] Training [23/62] Loss: 0.05553 
Epoch [192/300] Training [24/62] Loss: 0.05795 
Epoch [192/300] Training [25/62] Loss: 0.04449 
Epoch [192/300] Training [26/62] Loss: 0.04516 
Epoch [192/300] Training [27/62] Loss: 0.03890 
Epoch [192/300] Training [28/62] Loss: 0.05072 
Epoch [192/300] Training [29/62] Loss: 0.03730 
Epoch [192/300] Training [30/62] Loss: 0.04587 
Epoch [192/300] Training [31/62] Loss: 0.04252 
Epoch [192/300] Training [32/62] Loss: 0.06246 
Epoch [192/300] Training [33/62] Loss: 0.03302 
Epoch [192/300] Training [34/62] Loss: 0.04942 
Epoch [192/300] Training [35/62] Loss: 0.06877 
Epoch [192/300] Training [36/62] Loss: 0.03401 
Epoch [192/300] Training [37/62] Loss: 0.04800 
Epoch [192/300] Training [38/62] Loss: 0.06277 
Epoch [192/300] Training [39/62] Loss: 0.04954 
Epoch [192/300] Training [40/62] Loss: 0.05006 
Epoch [192/300] Training [41/62] Loss: 0.07781 
Epoch [192/300] Training [42/62] Loss: 0.03689 
Epoch [192/300] Training [43/62] Loss: 0.09452 
Epoch [192/300] Training [44/62] Loss: 0.11810 
Epoch [192/300] Training [45/62] Loss: 0.04883 
Epoch [192/300] Training [46/62] Loss: 0.03828 
Epoch [192/300] Training [47/62] Loss: 0.04464 
Epoch [192/300] Training [48/62] Loss: 0.07438 
Epoch [192/300] Training [49/62] Loss: 0.12395 
Epoch [192/300] Training [50/62] Loss: 0.04254 
Epoch [192/300] Training [51/62] Loss: 0.13188 
Epoch [192/300] Training [52/62] Loss: 0.06276 
Epoch [192/300] Training [53/62] Loss: 0.06789 
Epoch [192/300] Training [54/62] Loss: 0.09368 
Epoch [192/300] Training [55/62] Loss: 0.07892 
Epoch [192/300] Training [56/62] Loss: 0.22742 
Epoch [192/300] Training [57/62] Loss: 0.17882 
Epoch [192/300] Training [58/62] Loss: 0.09801 
Epoch [192/300] Training [59/62] Loss: 0.14036 
Epoch [192/300] Training [60/62] Loss: 0.08067 
Epoch [192/300] Training [61/62] Loss: 0.07794 
Epoch [192/300] Training [62/62] Loss: 0.05622 
Epoch [192/300] Training metric {'Train/mean dice_metric': 0.9492001533508301, 'Train/mean miou_metric': 0.9141265153884888, 'Train/mean f1': 0.9578174352645874, 'Train/mean precision': 0.9568118453025818, 'Train/mean recall': 0.9588250517845154, 'Train/mean hd95_metric': 11.784902572631836}
Epoch [192/300] Validation [1/16] Loss: 0.69204  focal_loss 0.46764  dice_loss 0.22440 
Epoch [192/300] Validation [2/16] Loss: 0.45356  focal_loss 0.16931  dice_loss 0.28425 
Epoch [192/300] Validation [3/16] Loss: 0.64799  focal_loss 0.36667  dice_loss 0.28132 
Epoch [192/300] Validation [4/16] Loss: 0.29926  focal_loss 0.14414  dice_loss 0.15513 
Epoch [192/300] Validation [5/16] Loss: 0.35892  focal_loss 0.12310  dice_loss 0.23582 
Epoch [192/300] Validation [6/16] Loss: 0.35054  focal_loss 0.11731  dice_loss 0.23323 
Epoch [192/300] Validation [7/16] Loss: 0.14679  focal_loss 0.05946  dice_loss 0.08733 
Epoch [192/300] Validation [8/16] Loss: 0.52477  focal_loss 0.18682  dice_loss 0.33796 
Epoch [192/300] Validation [9/16] Loss: 0.21523  focal_loss 0.08427  dice_loss 0.13096 
Epoch [192/300] Validation [10/16] Loss: 0.51216  focal_loss 0.15381  dice_loss 0.35835 
Epoch [192/300] Validation [11/16] Loss: 0.13344  focal_loss 0.04713  dice_loss 0.08630 
Epoch [192/300] Validation [12/16] Loss: 0.41714  focal_loss 0.12795  dice_loss 0.28919 
Epoch [192/300] Validation [13/16] Loss: 0.24609  focal_loss 0.08305  dice_loss 0.16304 
Epoch [192/300] Validation [14/16] Loss: 0.50169  focal_loss 0.21831  dice_loss 0.28338 
Epoch [192/300] Validation [15/16] Loss: 0.10566  focal_loss 0.03689  dice_loss 0.06877 
Epoch [192/300] Validation [16/16] Loss: 0.17817  focal_loss 0.06151  dice_loss 0.11666 
Epoch [192/300] Validation metric {'Val/mean dice_metric': 0.9177272319793701, 'Val/mean miou_metric': 0.8718997836112976, 'Val/mean f1': 0.9326045513153076, 'Val/mean precision': 0.9419223666191101, 'Val/mean recall': 0.9234691858291626, 'Val/mean hd95_metric': 20.28875160217285}
Cheakpoint...
Epoch [192/300] best acc:tensor([0.9196], device='cuda:0'), Now : mean acc: tensor([0.9177], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9177272319793701, 'Val/mean miou_metric': 0.8718997836112976, 'Val/mean f1': 0.9326045513153076, 'Val/mean precision': 0.9419223666191101, 'Val/mean recall': 0.9234691858291626, 'Val/mean hd95_metric': 20.28875160217285}
Epoch [193/300] Training [1/62] Loss: 0.06802 
Epoch [193/300] Training [2/62] Loss: 0.05307 
Epoch [193/300] Training [3/62] Loss: 0.05398 
Epoch [193/300] Training [4/62] Loss: 0.04959 
Epoch [193/300] Training [5/62] Loss: 0.05891 
Epoch [193/300] Training [6/62] Loss: 0.03211 
Epoch [193/300] Training [7/62] Loss: 0.04524 
Epoch [193/300] Training [8/62] Loss: 0.04914 
Epoch [193/300] Training [9/62] Loss: 0.05657 
Epoch [193/300] Training [10/62] Loss: 0.09796 
Epoch [193/300] Training [11/62] Loss: 0.05657 
Epoch [193/300] Training [12/62] Loss: 0.09294 
Epoch [193/300] Training [13/62] Loss: 0.09230 
Epoch [193/300] Training [14/62] Loss: 0.04711 
Epoch [193/300] Training [15/62] Loss: 0.04486 
Epoch [193/300] Training [16/62] Loss: 0.10841 
Epoch [193/300] Training [17/62] Loss: 0.03641 
Epoch [193/300] Training [18/62] Loss: 0.05667 
Epoch [193/300] Training [19/62] Loss: 0.05011 
Epoch [193/300] Training [20/62] Loss: 0.05832 
Epoch [193/300] Training [21/62] Loss: 0.19352 
Epoch [193/300] Training [22/62] Loss: 0.04574 
Epoch [193/300] Training [23/62] Loss: 0.07579 
Epoch [193/300] Training [24/62] Loss: 0.08035 
Epoch [193/300] Training [25/62] Loss: 0.07982 
Epoch [193/300] Training [26/62] Loss: 0.08602 
Epoch [193/300] Training [27/62] Loss: 0.08450 
Epoch [193/300] Training [28/62] Loss: 0.12310 
Epoch [193/300] Training [29/62] Loss: 0.14649 
Epoch [193/300] Training [30/62] Loss: 0.04899 
Epoch [193/300] Training [31/62] Loss: 0.04628 
Epoch [193/300] Training [32/62] Loss: 0.08755 
Epoch [193/300] Training [33/62] Loss: 0.04613 
Epoch [193/300] Training [34/62] Loss: 0.08668 
Epoch [193/300] Training [35/62] Loss: 0.04624 
Epoch [193/300] Training [36/62] Loss: 0.13987 
Epoch [193/300] Training [37/62] Loss: 0.04220 
Epoch [193/300] Training [38/62] Loss: 0.04908 
Epoch [193/300] Training [39/62] Loss: 0.07279 
Epoch [193/300] Training [40/62] Loss: 0.07740 
Epoch [193/300] Training [41/62] Loss: 0.11923 
Epoch [193/300] Training [42/62] Loss: 0.03743 
Epoch [193/300] Training [43/62] Loss: 0.03667 
Epoch [193/300] Training [44/62] Loss: 0.12763 
Epoch [193/300] Training [45/62] Loss: 0.05946 
Epoch [193/300] Training [46/62] Loss: 0.03626 
Epoch [193/300] Training [47/62] Loss: 0.04081 
Epoch [193/300] Training [48/62] Loss: 0.06070 
Epoch [193/300] Training [49/62] Loss: 0.04758 
Epoch [193/300] Training [50/62] Loss: 0.09733 
Epoch [193/300] Training [51/62] Loss: 0.06655 
Epoch [193/300] Training [52/62] Loss: 0.04800 
Epoch [193/300] Training [53/62] Loss: 0.03813 
Epoch [193/300] Training [54/62] Loss: 0.10410 
Epoch [193/300] Training [55/62] Loss: 0.05364 
Epoch [193/300] Training [56/62] Loss: 0.03838 
Epoch [193/300] Training [57/62] Loss: 0.16429 
Epoch [193/300] Training [58/62] Loss: 0.10577 
Epoch [193/300] Training [59/62] Loss: 0.05402 
Epoch [193/300] Training [60/62] Loss: 0.06970 
Epoch [193/300] Training [61/62] Loss: 0.03798 
Epoch [193/300] Training [62/62] Loss: 0.04149 
Epoch [193/300] Training metric {'Train/mean dice_metric': 0.9511741399765015, 'Train/mean miou_metric': 0.9156787395477295, 'Train/mean f1': 0.9587271809577942, 'Train/mean precision': 0.9553406834602356, 'Train/mean recall': 0.962137758731842, 'Train/mean hd95_metric': 11.4782133102417}
Epoch [193/300] Validation [1/16] Loss: 0.87361  focal_loss 0.56071  dice_loss 0.31290 
Epoch [193/300] Validation [2/16] Loss: 0.59036  focal_loss 0.22457  dice_loss 0.36580 
Epoch [193/300] Validation [3/16] Loss: 0.64971  focal_loss 0.35289  dice_loss 0.29681 
Epoch [193/300] Validation [4/16] Loss: 0.40193  focal_loss 0.18701  dice_loss 0.21492 
Epoch [193/300] Validation [5/16] Loss: 0.33504  focal_loss 0.11601  dice_loss 0.21903 
Epoch [193/300] Validation [6/16] Loss: 0.30241  focal_loss 0.09343  dice_loss 0.20898 
Epoch [193/300] Validation [7/16] Loss: 0.29904  focal_loss 0.14463  dice_loss 0.15441 
Epoch [193/300] Validation [8/16] Loss: 0.44748  focal_loss 0.16844  dice_loss 0.27905 
Epoch [193/300] Validation [9/16] Loss: 0.37300  focal_loss 0.15483  dice_loss 0.21817 
Epoch [193/300] Validation [10/16] Loss: 0.45527  focal_loss 0.14841  dice_loss 0.30687 
Epoch [193/300] Validation [11/16] Loss: 0.20708  focal_loss 0.07676  dice_loss 0.13032 
Epoch [193/300] Validation [12/16] Loss: 0.43429  focal_loss 0.13037  dice_loss 0.30392 
Epoch [193/300] Validation [13/16] Loss: 0.38587  focal_loss 0.14817  dice_loss 0.23770 
Epoch [193/300] Validation [14/16] Loss: 0.54757  focal_loss 0.21911  dice_loss 0.32846 
Epoch [193/300] Validation [15/16] Loss: 0.14391  focal_loss 0.05001  dice_loss 0.09389 
Epoch [193/300] Validation [16/16] Loss: 0.13770  focal_loss 0.04978  dice_loss 0.08792 
Epoch [193/300] Validation metric {'Val/mean dice_metric': 0.913768470287323, 'Val/mean miou_metric': 0.8664588928222656, 'Val/mean f1': 0.9284415245056152, 'Val/mean precision': 0.9407703280448914, 'Val/mean recall': 0.9164317846298218, 'Val/mean hd95_metric': 19.950729370117188}
Cheakpoint...
Epoch [193/300] best acc:tensor([0.9196], device='cuda:0'), Now : mean acc: tensor([0.9138], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.913768470287323, 'Val/mean miou_metric': 0.8664588928222656, 'Val/mean f1': 0.9284415245056152, 'Val/mean precision': 0.9407703280448914, 'Val/mean recall': 0.9164317846298218, 'Val/mean hd95_metric': 19.950729370117188}
Epoch [194/300] Training [1/62] Loss: 0.17375 
Epoch [194/300] Training [2/62] Loss: 0.05231 
Epoch [194/300] Training [3/62] Loss: 0.05296 
Epoch [194/300] Training [4/62] Loss: 0.11749 
Epoch [194/300] Training [5/62] Loss: 0.04140 
Epoch [194/300] Training [6/62] Loss: 0.04780 
Epoch [194/300] Training [7/62] Loss: 0.07350 
Epoch [194/300] Training [8/62] Loss: 0.05067 
Epoch [194/300] Training [9/62] Loss: 0.06612 
Epoch [194/300] Training [10/62] Loss: 0.03979 
Epoch [194/300] Training [11/62] Loss: 0.06840 
Epoch [194/300] Training [12/62] Loss: 0.07205 
Epoch [194/300] Training [13/62] Loss: 0.04220 
Epoch [194/300] Training [14/62] Loss: 0.14180 
Epoch [194/300] Training [15/62] Loss: 0.03865 
Epoch [194/300] Training [16/62] Loss: 0.05344 
Epoch [194/300] Training [17/62] Loss: 0.05364 
Epoch [194/300] Training [18/62] Loss: 0.05443 
Epoch [194/300] Training [19/62] Loss: 0.05541 
Epoch [194/300] Training [20/62] Loss: 0.04808 
Epoch [194/300] Training [21/62] Loss: 0.06755 
Epoch [194/300] Training [22/62] Loss: 0.10470 
Epoch [194/300] Training [23/62] Loss: 0.05644 
Epoch [194/300] Training [24/62] Loss: 0.10654 
Epoch [194/300] Training [25/62] Loss: 0.04899 
Epoch [194/300] Training [26/62] Loss: 0.04625 
Epoch [194/300] Training [27/62] Loss: 0.05725 
Epoch [194/300] Training [28/62] Loss: 0.04843 
Epoch [194/300] Training [29/62] Loss: 0.06362 
Epoch [194/300] Training [30/62] Loss: 0.03800 
Epoch [194/300] Training [31/62] Loss: 0.14336 
Epoch [194/300] Training [32/62] Loss: 0.06427 
Epoch [194/300] Training [33/62] Loss: 0.04510 
Epoch [194/300] Training [34/62] Loss: 0.05530 
Epoch [194/300] Training [35/62] Loss: 0.10022 
Epoch [194/300] Training [36/62] Loss: 0.17428 
Epoch [194/300] Training [37/62] Loss: 0.17182 
Epoch [194/300] Training [38/62] Loss: 0.05010 
Epoch [194/300] Training [39/62] Loss: 0.04530 
Epoch [194/300] Training [40/62] Loss: 0.06013 
Epoch [194/300] Training [41/62] Loss: 0.10795 
Epoch [194/300] Training [42/62] Loss: 0.04521 
Epoch [194/300] Training [43/62] Loss: 0.12006 
Epoch [194/300] Training [44/62] Loss: 0.07928 
Epoch [194/300] Training [45/62] Loss: 0.03257 
Epoch [194/300] Training [46/62] Loss: 0.04145 
Epoch [194/300] Training [47/62] Loss: 0.06989 
Epoch [194/300] Training [48/62] Loss: 0.07398 
Epoch [194/300] Training [49/62] Loss: 0.04624 
Epoch [194/300] Training [50/62] Loss: 0.05037 
Epoch [194/300] Training [51/62] Loss: 0.08441 
Epoch [194/300] Training [52/62] Loss: 0.05982 
Epoch [194/300] Training [53/62] Loss: 0.09187 
Epoch [194/300] Training [54/62] Loss: 0.04505 
Epoch [194/300] Training [55/62] Loss: 0.03722 
Epoch [194/300] Training [56/62] Loss: 0.22097 
Epoch [194/300] Training [57/62] Loss: 0.06155 
Epoch [194/300] Training [58/62] Loss: 0.04144 
Epoch [194/300] Training [59/62] Loss: 0.08646 
Epoch [194/300] Training [60/62] Loss: 0.08949 
Epoch [194/300] Training [61/62] Loss: 0.07149 
Epoch [194/300] Training [62/62] Loss: 0.09103 
Epoch [194/300] Training metric {'Train/mean dice_metric': 0.9493210911750793, 'Train/mean miou_metric': 0.9137590527534485, 'Train/mean f1': 0.9597324728965759, 'Train/mean precision': 0.9581000208854675, 'Train/mean recall': 0.9613707065582275, 'Train/mean hd95_metric': 10.941048622131348}
Epoch [194/300] Validation [1/16] Loss: 0.63109  focal_loss 0.42480  dice_loss 0.20629 
Epoch [194/300] Validation [2/16] Loss: 0.43599  focal_loss 0.17457  dice_loss 0.26142 
Epoch [194/300] Validation [3/16] Loss: 0.61202  focal_loss 0.32981  dice_loss 0.28220 
Epoch [194/300] Validation [4/16] Loss: 0.26441  focal_loss 0.12674  dice_loss 0.13767 
Epoch [194/300] Validation [5/16] Loss: 0.32747  focal_loss 0.12208  dice_loss 0.20540 
Epoch [194/300] Validation [6/16] Loss: 0.34097  focal_loss 0.10970  dice_loss 0.23127 
Epoch [194/300] Validation [7/16] Loss: 0.22029  focal_loss 0.08848  dice_loss 0.13181 
Epoch [194/300] Validation [8/16] Loss: 0.52853  focal_loss 0.18410  dice_loss 0.34443 
Epoch [194/300] Validation [9/16] Loss: 0.23968  focal_loss 0.09729  dice_loss 0.14239 
Epoch [194/300] Validation [10/16] Loss: 0.51631  focal_loss 0.16517  dice_loss 0.35114 
Epoch [194/300] Validation [11/16] Loss: 0.19443  focal_loss 0.07326  dice_loss 0.12117 
Epoch [194/300] Validation [12/16] Loss: 0.39066  focal_loss 0.11751  dice_loss 0.27315 
Epoch [194/300] Validation [13/16] Loss: 0.22626  focal_loss 0.08648  dice_loss 0.13978 
Epoch [194/300] Validation [14/16] Loss: 0.60310  focal_loss 0.23761  dice_loss 0.36549 
Epoch [194/300] Validation [15/16] Loss: 0.11261  focal_loss 0.03637  dice_loss 0.07623 
Epoch [194/300] Validation [16/16] Loss: 0.14405  focal_loss 0.05024  dice_loss 0.09381 
Epoch [194/300] Validation metric {'Val/mean dice_metric': 0.9171589612960815, 'Val/mean miou_metric': 0.8713915348052979, 'Val/mean f1': 0.9327743649482727, 'Val/mean precision': 0.9373742938041687, 'Val/mean recall': 0.9282193779945374, 'Val/mean hd95_metric': 19.28647804260254}
Cheakpoint...
Epoch [194/300] best acc:tensor([0.9196], device='cuda:0'), Now : mean acc: tensor([0.9172], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9171589612960815, 'Val/mean miou_metric': 0.8713915348052979, 'Val/mean f1': 0.9327743649482727, 'Val/mean precision': 0.9373742938041687, 'Val/mean recall': 0.9282193779945374, 'Val/mean hd95_metric': 19.28647804260254}
Epoch [195/300] Training [1/62] Loss: 0.04119 
Epoch [195/300] Training [2/62] Loss: 0.04371 
Epoch [195/300] Training [3/62] Loss: 0.08657 
Epoch [195/300] Training [4/62] Loss: 0.09313 
Epoch [195/300] Training [5/62] Loss: 0.04346 
Epoch [195/300] Training [6/62] Loss: 0.08080 
Epoch [195/300] Training [7/62] Loss: 0.06438 
Epoch [195/300] Training [8/62] Loss: 0.06349 
Epoch [195/300] Training [9/62] Loss: 0.06353 
Epoch [195/300] Training [10/62] Loss: 0.05793 
Epoch [195/300] Training [11/62] Loss: 0.04488 
Epoch [195/300] Training [12/62] Loss: 0.04054 
Epoch [195/300] Training [13/62] Loss: 0.08505 
Epoch [195/300] Training [14/62] Loss: 0.08887 
Epoch [195/300] Training [15/62] Loss: 0.04108 
Epoch [195/300] Training [16/62] Loss: 0.03806 
Epoch [195/300] Training [17/62] Loss: 0.07612 
Epoch [195/300] Training [18/62] Loss: 0.03638 
Epoch [195/300] Training [19/62] Loss: 0.03937 
Epoch [195/300] Training [20/62] Loss: 0.04797 
Epoch [195/300] Training [21/62] Loss: 0.04280 
Epoch [195/300] Training [22/62] Loss: 0.05186 
Epoch [195/300] Training [23/62] Loss: 0.04671 
Epoch [195/300] Training [24/62] Loss: 0.03943 
Epoch [195/300] Training [25/62] Loss: 0.07003 
Epoch [195/300] Training [26/62] Loss: 0.04095 
Epoch [195/300] Training [27/62] Loss: 0.11160 
Epoch [195/300] Training [28/62] Loss: 0.04803 
Epoch [195/300] Training [29/62] Loss: 0.04597 
Epoch [195/300] Training [30/62] Loss: 0.04027 
Epoch [195/300] Training [31/62] Loss: 0.05103 
Epoch [195/300] Training [32/62] Loss: 0.07832 
Epoch [195/300] Training [33/62] Loss: 0.05252 
Epoch [195/300] Training [34/62] Loss: 0.09567 
Epoch [195/300] Training [35/62] Loss: 0.03758 
Epoch [195/300] Training [36/62] Loss: 0.03228 
Epoch [195/300] Training [37/62] Loss: 0.05423 
Epoch [195/300] Training [38/62] Loss: 0.02901 
Epoch [195/300] Training [39/62] Loss: 0.03870 
Epoch [195/300] Training [40/62] Loss: 0.05348 
Epoch [195/300] Training [41/62] Loss: 0.06991 
Epoch [195/300] Training [42/62] Loss: 0.04407 
Epoch [195/300] Training [43/62] Loss: 0.17652 
Epoch [195/300] Training [44/62] Loss: 0.04841 
Epoch [195/300] Training [45/62] Loss: 0.13645 
Epoch [195/300] Training [46/62] Loss: 0.09427 
Epoch [195/300] Training [47/62] Loss: 0.04177 
Epoch [195/300] Training [48/62] Loss: 0.10067 
Epoch [195/300] Training [49/62] Loss: 0.06684 
Epoch [195/300] Training [50/62] Loss: 0.07591 
Epoch [195/300] Training [51/62] Loss: 0.07991 
Epoch [195/300] Training [52/62] Loss: 0.07117 
Epoch [195/300] Training [53/62] Loss: 0.04000 
Epoch [195/300] Training [54/62] Loss: 0.10196 
Epoch [195/300] Training [55/62] Loss: 0.07158 
Epoch [195/300] Training [56/62] Loss: 0.04319 
Epoch [195/300] Training [57/62] Loss: 0.07307 
Epoch [195/300] Training [58/62] Loss: 0.08833 
Epoch [195/300] Training [59/62] Loss: 0.08373 
Epoch [195/300] Training [60/62] Loss: 0.03965 
Epoch [195/300] Training [61/62] Loss: 0.07202 
Epoch [195/300] Training [62/62] Loss: 0.02751 
Epoch [195/300] Training metric {'Train/mean dice_metric': 0.95745849609375, 'Train/mean miou_metric': 0.9233293533325195, 'Train/mean f1': 0.9610035419464111, 'Train/mean precision': 0.9573255777359009, 'Train/mean recall': 0.9647097587585449, 'Train/mean hd95_metric': 11.249749183654785}
Epoch [195/300] Validation [1/16] Loss: 0.68686  focal_loss 0.46505  dice_loss 0.22181 
Epoch [195/300] Validation [2/16] Loss: 0.47135  focal_loss 0.17225  dice_loss 0.29911 
Epoch [195/300] Validation [3/16] Loss: 0.71853  focal_loss 0.39027  dice_loss 0.32827 
Epoch [195/300] Validation [4/16] Loss: 0.37362  focal_loss 0.16928  dice_loss 0.20434 
Epoch [195/300] Validation [5/16] Loss: 0.26619  focal_loss 0.08993  dice_loss 0.17627 
Epoch [195/300] Validation [6/16] Loss: 0.30826  focal_loss 0.07899  dice_loss 0.22927 
Epoch [195/300] Validation [7/16] Loss: 0.27066  focal_loss 0.09647  dice_loss 0.17419 
Epoch [195/300] Validation [8/16] Loss: 0.48560  focal_loss 0.15620  dice_loss 0.32940 
Epoch [195/300] Validation [9/16] Loss: 0.23244  focal_loss 0.09171  dice_loss 0.14073 
Epoch [195/300] Validation [10/16] Loss: 0.55697  focal_loss 0.18581  dice_loss 0.37115 
Epoch [195/300] Validation [11/16] Loss: 0.14387  focal_loss 0.04925  dice_loss 0.09462 
Epoch [195/300] Validation [12/16] Loss: 0.45111  focal_loss 0.10898  dice_loss 0.34213 
Epoch [195/300] Validation [13/16] Loss: 0.23091  focal_loss 0.08055  dice_loss 0.15037 
Epoch [195/300] Validation [14/16] Loss: 0.57049  focal_loss 0.24135  dice_loss 0.32914 
Epoch [195/300] Validation [15/16] Loss: 0.09339  focal_loss 0.02910  dice_loss 0.06429 
Epoch [195/300] Validation [16/16] Loss: 0.12936  focal_loss 0.03791  dice_loss 0.09145 
Epoch [195/300] Validation metric {'Val/mean dice_metric': 0.9215983748435974, 'Val/mean miou_metric': 0.8772950172424316, 'Val/mean f1': 0.9346001744270325, 'Val/mean precision': 0.9429219365119934, 'Val/mean recall': 0.9264237880706787, 'Val/mean hd95_metric': 18.248281478881836}
Cheakpoint...
Epoch [195/300] best acc:tensor([0.9216], device='cuda:0'), Now : mean acc: tensor([0.9216], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9215983748435974, 'Val/mean miou_metric': 0.8772950172424316, 'Val/mean f1': 0.9346001744270325, 'Val/mean precision': 0.9429219365119934, 'Val/mean recall': 0.9264237880706787, 'Val/mean hd95_metric': 18.248281478881836}
Epoch [196/300] Training [1/62] Loss: 0.06202 
Epoch [196/300] Training [2/62] Loss: 0.09197 
Epoch [196/300] Training [3/62] Loss: 0.06726 
Epoch [196/300] Training [4/62] Loss: 0.05449 
Epoch [196/300] Training [5/62] Loss: 0.11018 
Epoch [196/300] Training [6/62] Loss: 0.05112 
Epoch [196/300] Training [7/62] Loss: 0.05611 
Epoch [196/300] Training [8/62] Loss: 0.04456 
Epoch [196/300] Training [9/62] Loss: 0.03518 
Epoch [196/300] Training [10/62] Loss: 0.04581 
Epoch [196/300] Training [11/62] Loss: 0.04393 
Epoch [196/300] Training [12/62] Loss: 0.03597 
Epoch [196/300] Training [13/62] Loss: 0.15510 
Epoch [196/300] Training [14/62] Loss: 0.06907 
Epoch [196/300] Training [15/62] Loss: 0.03590 
Epoch [196/300] Training [16/62] Loss: 0.06615 
Epoch [196/300] Training [17/62] Loss: 0.06076 
Epoch [196/300] Training [18/62] Loss: 0.07658 
Epoch [196/300] Training [19/62] Loss: 0.13931 
Epoch [196/300] Training [20/62] Loss: 0.04898 
Epoch [196/300] Training [21/62] Loss: 0.09974 
Epoch [196/300] Training [22/62] Loss: 0.15002 
Epoch [196/300] Training [23/62] Loss: 0.04609 
Epoch [196/300] Training [24/62] Loss: 0.03254 
Epoch [196/300] Training [25/62] Loss: 0.07112 
Epoch [196/300] Training [26/62] Loss: 0.05070 
Epoch [196/300] Training [27/62] Loss: 0.14389 
Epoch [196/300] Training [28/62] Loss: 0.08713 
Epoch [196/300] Training [29/62] Loss: 0.04301 
Epoch [196/300] Training [30/62] Loss: 0.05196 
Epoch [196/300] Training [31/62] Loss: 0.04332 
Epoch [196/300] Training [32/62] Loss: 0.07365 
Epoch [196/300] Training [33/62] Loss: 0.06312 
Epoch [196/300] Training [34/62] Loss: 0.16942 
Epoch [196/300] Training [35/62] Loss: 0.04384 
Epoch [196/300] Training [36/62] Loss: 0.06302 
Epoch [196/300] Training [37/62] Loss: 0.03634 
Epoch [196/300] Training [38/62] Loss: 0.09469 
Epoch [196/300] Training [39/62] Loss: 0.03240 
Epoch [196/300] Training [40/62] Loss: 0.04897 
Epoch [196/300] Training [41/62] Loss: 0.05034 
Epoch [196/300] Training [42/62] Loss: 0.04005 
Epoch [196/300] Training [43/62] Loss: 0.10420 
Epoch [196/300] Training [44/62] Loss: 0.05664 
Epoch [196/300] Training [45/62] Loss: 0.07049 
Epoch [196/300] Training [46/62] Loss: 0.04953 
Epoch [196/300] Training [47/62] Loss: 0.06454 
Epoch [196/300] Training [48/62] Loss: 0.06549 
Epoch [196/300] Training [49/62] Loss: 0.06257 
Epoch [196/300] Training [50/62] Loss: 0.04509 
Epoch [196/300] Training [51/62] Loss: 0.05223 
Epoch [196/300] Training [52/62] Loss: 0.05897 
Epoch [196/300] Training [53/62] Loss: 0.03981 
Epoch [196/300] Training [54/62] Loss: 0.06488 
Epoch [196/300] Training [55/62] Loss: 0.03372 
Epoch [196/300] Training [56/62] Loss: 0.04073 
Epoch [196/300] Training [57/62] Loss: 0.03469 
Epoch [196/300] Training [58/62] Loss: 0.04568 
Epoch [196/300] Training [59/62] Loss: 0.05206 
Epoch [196/300] Training [60/62] Loss: 0.07317 
Epoch [196/300] Training [61/62] Loss: 0.08957 
Epoch [196/300] Training [62/62] Loss: 0.05192 
Epoch [196/300] Training metric {'Train/mean dice_metric': 0.9538857340812683, 'Train/mean miou_metric': 0.9199846386909485, 'Train/mean f1': 0.9619423151016235, 'Train/mean precision': 0.9585657715797424, 'Train/mean recall': 0.9653427004814148, 'Train/mean hd95_metric': 9.699226379394531}
Epoch [196/300] Validation [1/16] Loss: 0.63050  focal_loss 0.40584  dice_loss 0.22466 
Epoch [196/300] Validation [2/16] Loss: 0.47336  focal_loss 0.17044  dice_loss 0.30292 
Epoch [196/300] Validation [3/16] Loss: 0.63461  focal_loss 0.34077  dice_loss 0.29385 
Epoch [196/300] Validation [4/16] Loss: 0.40292  focal_loss 0.18919  dice_loss 0.21373 
Epoch [196/300] Validation [5/16] Loss: 0.49874  focal_loss 0.16669  dice_loss 0.33205 
Epoch [196/300] Validation [6/16] Loss: 0.33832  focal_loss 0.10333  dice_loss 0.23499 
Epoch [196/300] Validation [7/16] Loss: 0.15969  focal_loss 0.06126  dice_loss 0.09843 
Epoch [196/300] Validation [8/16] Loss: 0.46911  focal_loss 0.16698  dice_loss 0.30213 
Epoch [196/300] Validation [9/16] Loss: 0.24266  focal_loss 0.09581  dice_loss 0.14685 
Epoch [196/300] Validation [10/16] Loss: 0.52548  focal_loss 0.16007  dice_loss 0.36541 
Epoch [196/300] Validation [11/16] Loss: 0.21530  focal_loss 0.07897  dice_loss 0.13633 
Epoch [196/300] Validation [12/16] Loss: 0.33511  focal_loss 0.08895  dice_loss 0.24616 
Epoch [196/300] Validation [13/16] Loss: 0.27442  focal_loss 0.10205  dice_loss 0.17237 
Epoch [196/300] Validation [14/16] Loss: 0.58686  focal_loss 0.21755  dice_loss 0.36931 
Epoch [196/300] Validation [15/16] Loss: 0.11159  focal_loss 0.03500  dice_loss 0.07659 
Epoch [196/300] Validation [16/16] Loss: 0.10974  focal_loss 0.03668  dice_loss 0.07307 
Epoch [196/300] Validation metric {'Val/mean dice_metric': 0.9178099632263184, 'Val/mean miou_metric': 0.873953640460968, 'Val/mean f1': 0.9334569573402405, 'Val/mean precision': 0.9378650188446045, 'Val/mean recall': 0.9290900826454163, 'Val/mean hd95_metric': 18.327390670776367}
Cheakpoint...
Epoch [196/300] best acc:tensor([0.9216], device='cuda:0'), Now : mean acc: tensor([0.9178], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9178099632263184, 'Val/mean miou_metric': 0.873953640460968, 'Val/mean f1': 0.9334569573402405, 'Val/mean precision': 0.9378650188446045, 'Val/mean recall': 0.9290900826454163, 'Val/mean hd95_metric': 18.327390670776367}
Epoch [197/300] Training [1/62] Loss: 0.04874 
Epoch [197/300] Training [2/62] Loss: 0.06700 
Epoch [197/300] Training [3/62] Loss: 0.03947 
Epoch [197/300] Training [4/62] Loss: 0.13040 
Epoch [197/300] Training [5/62] Loss: 0.04522 
Epoch [197/300] Training [6/62] Loss: 0.04726 
Epoch [197/300] Training [7/62] Loss: 0.08785 
Epoch [197/300] Training [8/62] Loss: 0.05463 
Epoch [197/300] Training [9/62] Loss: 0.05865 
Epoch [197/300] Training [10/62] Loss: 0.04347 
Epoch [197/300] Training [11/62] Loss: 0.04433 
Epoch [197/300] Training [12/62] Loss: 0.03904 
Epoch [197/300] Training [13/62] Loss: 0.03681 
Epoch [197/300] Training [14/62] Loss: 0.04429 
Epoch [197/300] Training [15/62] Loss: 0.05533 
Epoch [197/300] Training [16/62] Loss: 0.05775 
Epoch [197/300] Training [17/62] Loss: 0.14126 
Epoch [197/300] Training [18/62] Loss: 0.04807 
Epoch [197/300] Training [19/62] Loss: 0.04355 
Epoch [197/300] Training [20/62] Loss: 0.04592 
Epoch [197/300] Training [21/62] Loss: 0.05600 
Epoch [197/300] Training [22/62] Loss: 0.07205 
Epoch [197/300] Training [23/62] Loss: 0.05391 
Epoch [197/300] Training [24/62] Loss: 0.04303 
Epoch [197/300] Training [25/62] Loss: 0.04352 
Epoch [197/300] Training [26/62] Loss: 0.12241 
Epoch [197/300] Training [27/62] Loss: 0.05265 
Epoch [197/300] Training [28/62] Loss: 0.05643 
Epoch [197/300] Training [29/62] Loss: 0.03680 
Epoch [197/300] Training [30/62] Loss: 0.05881 
Epoch [197/300] Training [31/62] Loss: 0.07437 
Epoch [197/300] Training [32/62] Loss: 0.07379 
Epoch [197/300] Training [33/62] Loss: 0.04734 
Epoch [197/300] Training [34/62] Loss: 0.08510 
Epoch [197/300] Training [35/62] Loss: 0.09307 
Epoch [197/300] Training [36/62] Loss: 0.03677 
Epoch [197/300] Training [37/62] Loss: 0.07410 
Epoch [197/300] Training [38/62] Loss: 0.04842 
Epoch [197/300] Training [39/62] Loss: 0.14322 
Epoch [197/300] Training [40/62] Loss: 0.04746 
Epoch [197/300] Training [41/62] Loss: 0.04272 
Epoch [197/300] Training [42/62] Loss: 0.05010 
Epoch [197/300] Training [43/62] Loss: 0.05671 
Epoch [197/300] Training [44/62] Loss: 0.03898 
Epoch [197/300] Training [45/62] Loss: 0.03986 
Epoch [197/300] Training [46/62] Loss: 0.09033 
Epoch [197/300] Training [47/62] Loss: 0.05758 
Epoch [197/300] Training [48/62] Loss: 0.03982 
Epoch [197/300] Training [49/62] Loss: 0.04392 
Epoch [197/300] Training [50/62] Loss: 0.12693 
Epoch [197/300] Training [51/62] Loss: 0.05012 
Epoch [197/300] Training [52/62] Loss: 0.03777 
Epoch [197/300] Training [53/62] Loss: 0.05901 
Epoch [197/300] Training [54/62] Loss: 0.03883 
Epoch [197/300] Training [55/62] Loss: 0.10185 
Epoch [197/300] Training [56/62] Loss: 0.05631 
Epoch [197/300] Training [57/62] Loss: 0.05605 
Epoch [197/300] Training [58/62] Loss: 0.05289 
Epoch [197/300] Training [59/62] Loss: 0.03992 
Epoch [197/300] Training [60/62] Loss: 0.06690 
Epoch [197/300] Training [61/62] Loss: 0.04306 
Epoch [197/300] Training [62/62] Loss: 0.33101 
Epoch [197/300] Training metric {'Train/mean dice_metric': 0.9591502547264099, 'Train/mean miou_metric': 0.9261445999145508, 'Train/mean f1': 0.9622049927711487, 'Train/mean precision': 0.9585790634155273, 'Train/mean recall': 0.9658584594726562, 'Train/mean hd95_metric': 8.950706481933594}
Epoch [197/300] Validation [1/16] Loss: 0.65168  focal_loss 0.43977  dice_loss 0.21191 
Epoch [197/300] Validation [2/16] Loss: 0.51808  focal_loss 0.19741  dice_loss 0.32067 
Epoch [197/300] Validation [3/16] Loss: 0.60722  focal_loss 0.32197  dice_loss 0.28525 
Epoch [197/300] Validation [4/16] Loss: 0.29665  focal_loss 0.12934  dice_loss 0.16731 
Epoch [197/300] Validation [5/16] Loss: 0.33811  focal_loss 0.12382  dice_loss 0.21429 
Epoch [197/300] Validation [6/16] Loss: 0.22421  focal_loss 0.07945  dice_loss 0.14476 
Epoch [197/300] Validation [7/16] Loss: 0.23296  focal_loss 0.08848  dice_loss 0.14448 
Epoch [197/300] Validation [8/16] Loss: 0.39535  focal_loss 0.13713  dice_loss 0.25822 
Epoch [197/300] Validation [9/16] Loss: 0.26424  focal_loss 0.10262  dice_loss 0.16162 
Epoch [197/300] Validation [10/16] Loss: 0.45700  focal_loss 0.15708  dice_loss 0.29993 
Epoch [197/300] Validation [11/16] Loss: 0.15501  focal_loss 0.05226  dice_loss 0.10275 
Epoch [197/300] Validation [12/16] Loss: 0.37154  focal_loss 0.09172  dice_loss 0.27982 
Epoch [197/300] Validation [13/16] Loss: 0.24692  focal_loss 0.08189  dice_loss 0.16503 
Epoch [197/300] Validation [14/16] Loss: 0.63905  focal_loss 0.30023  dice_loss 0.33882 
Epoch [197/300] Validation [15/16] Loss: 0.10641  focal_loss 0.02986  dice_loss 0.07655 
Epoch [197/300] Validation [16/16] Loss: 0.13445  focal_loss 0.03854  dice_loss 0.09591 
Epoch [197/300] Validation metric {'Val/mean dice_metric': 0.9268373847007751, 'Val/mean miou_metric': 0.8825657367706299, 'Val/mean f1': 0.9352405071258545, 'Val/mean precision': 0.9404064416885376, 'Val/mean recall': 0.9301311373710632, 'Val/mean hd95_metric': 19.067760467529297}
Cheakpoint...
Epoch [197/300] best acc:tensor([0.9268], device='cuda:0'), Now : mean acc: tensor([0.9268], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9268373847007751, 'Val/mean miou_metric': 0.8825657367706299, 'Val/mean f1': 0.9352405071258545, 'Val/mean precision': 0.9404064416885376, 'Val/mean recall': 0.9301311373710632, 'Val/mean hd95_metric': 19.067760467529297}
Epoch [198/300] Training [1/62] Loss: 0.20250 
Epoch [198/300] Training [2/62] Loss: 0.06552 
Epoch [198/300] Training [3/62] Loss: 0.04507 
Epoch [198/300] Training [4/62] Loss: 0.05083 
Epoch [198/300] Training [5/62] Loss: 0.10507 
Epoch [198/300] Training [6/62] Loss: 0.04880 
Epoch [198/300] Training [7/62] Loss: 0.10283 
Epoch [198/300] Training [8/62] Loss: 0.03548 
Epoch [198/300] Training [9/62] Loss: 0.10340 
Epoch [198/300] Training [10/62] Loss: 0.03875 
Epoch [198/300] Training [11/62] Loss: 0.07732 
Epoch [198/300] Training [12/62] Loss: 0.02954 
Epoch [198/300] Training [13/62] Loss: 0.06199 
Epoch [198/300] Training [14/62] Loss: 0.05876 
Epoch [198/300] Training [15/62] Loss: 0.07362 
Epoch [198/300] Training [16/62] Loss: 0.07660 
Epoch [198/300] Training [17/62] Loss: 0.05423 
Epoch [198/300] Training [18/62] Loss: 0.07946 
Epoch [198/300] Training [19/62] Loss: 0.07183 
Epoch [198/300] Training [20/62] Loss: 0.05288 
Epoch [198/300] Training [21/62] Loss: 0.06148 
Epoch [198/300] Training [22/62] Loss: 0.03738 
Epoch [198/300] Training [23/62] Loss: 0.04245 
Epoch [198/300] Training [24/62] Loss: 0.10157 
Epoch [198/300] Training [25/62] Loss: 0.06546 
Epoch [198/300] Training [26/62] Loss: 0.06737 
Epoch [198/300] Training [27/62] Loss: 0.06487 
Epoch [198/300] Training [28/62] Loss: 0.05718 
Epoch [198/300] Training [29/62] Loss: 0.04273 
Epoch [198/300] Training [30/62] Loss: 0.04039 
Epoch [198/300] Training [31/62] Loss: 0.10963 
Epoch [198/300] Training [32/62] Loss: 0.03870 
Epoch [198/300] Training [33/62] Loss: 0.05667 
Epoch [198/300] Training [34/62] Loss: 0.05598 
Epoch [198/300] Training [35/62] Loss: 0.06744 
Epoch [198/300] Training [36/62] Loss: 0.05886 
Epoch [198/300] Training [37/62] Loss: 0.04255 
Epoch [198/300] Training [38/62] Loss: 0.06501 
Epoch [198/300] Training [39/62] Loss: 0.03527 
Epoch [198/300] Training [40/62] Loss: 0.03880 
Epoch [198/300] Training [41/62] Loss: 0.09359 
Epoch [198/300] Training [42/62] Loss: 0.08322 
Epoch [198/300] Training [43/62] Loss: 0.12275 
Epoch [198/300] Training [44/62] Loss: 0.05448 
Epoch [198/300] Training [45/62] Loss: 0.07868 
Epoch [198/300] Training [46/62] Loss: 0.07527 
Epoch [198/300] Training [47/62] Loss: 0.08101 
Epoch [198/300] Training [48/62] Loss: 0.05142 
Epoch [198/300] Training [49/62] Loss: 0.09565 
Epoch [198/300] Training [50/62] Loss: 0.04095 
Epoch [198/300] Training [51/62] Loss: 0.03135 
Epoch [198/300] Training [52/62] Loss: 0.05925 
Epoch [198/300] Training [53/62] Loss: 0.08175 
Epoch [198/300] Training [54/62] Loss: 0.06866 
Epoch [198/300] Training [55/62] Loss: 0.07465 
Epoch [198/300] Training [56/62] Loss: 0.08687 
Epoch [198/300] Training [57/62] Loss: 0.05883 
Epoch [198/300] Training [58/62] Loss: 0.03424 
Epoch [198/300] Training [59/62] Loss: 0.07720 
Epoch [198/300] Training [60/62] Loss: 0.05388 
Epoch [198/300] Training [61/62] Loss: 0.04162 
Epoch [198/300] Training [62/62] Loss: 0.09470 
Epoch [198/300] Training metric {'Train/mean dice_metric': 0.955425500869751, 'Train/mean miou_metric': 0.9199569225311279, 'Train/mean f1': 0.9600752592086792, 'Train/mean precision': 0.9600756168365479, 'Train/mean recall': 0.9600748419761658, 'Train/mean hd95_metric': 9.9586181640625}
Epoch [198/300] Validation [1/16] Loss: 0.61391  focal_loss 0.41670  dice_loss 0.19721 
Epoch [198/300] Validation [2/16] Loss: 0.44383  focal_loss 0.17344  dice_loss 0.27039 
Epoch [198/300] Validation [3/16] Loss: 0.57156  focal_loss 0.30681  dice_loss 0.26475 
Epoch [198/300] Validation [4/16] Loss: 0.27168  focal_loss 0.11534  dice_loss 0.15634 
Epoch [198/300] Validation [5/16] Loss: 0.32358  focal_loss 0.10477  dice_loss 0.21882 
Epoch [198/300] Validation [6/16] Loss: 0.29801  focal_loss 0.08881  dice_loss 0.20920 
Epoch [198/300] Validation [7/16] Loss: 0.16745  focal_loss 0.07131  dice_loss 0.09615 
Epoch [198/300] Validation [8/16] Loss: 0.55988  focal_loss 0.20777  dice_loss 0.35211 
Epoch [198/300] Validation [9/16] Loss: 0.17241  focal_loss 0.06346  dice_loss 0.10895 
Epoch [198/300] Validation [10/16] Loss: 0.50700  focal_loss 0.16952  dice_loss 0.33748 
Epoch [198/300] Validation [11/16] Loss: 0.16900  focal_loss 0.05035  dice_loss 0.11865 
Epoch [198/300] Validation [12/16] Loss: 0.48117  focal_loss 0.10631  dice_loss 0.37486 
Epoch [198/300] Validation [13/16] Loss: 0.27049  focal_loss 0.09543  dice_loss 0.17506 
Epoch [198/300] Validation [14/16] Loss: 0.56551  focal_loss 0.23170  dice_loss 0.33381 
Epoch [198/300] Validation [15/16] Loss: 0.12282  focal_loss 0.03793  dice_loss 0.08489 
Epoch [198/300] Validation [16/16] Loss: 0.16593  focal_loss 0.05572  dice_loss 0.11021 
Epoch [198/300] Validation metric {'Val/mean dice_metric': 0.9216402173042297, 'Val/mean miou_metric': 0.8764373064041138, 'Val/mean f1': 0.9332948923110962, 'Val/mean precision': 0.938530683517456, 'Val/mean recall': 0.9281173348426819, 'Val/mean hd95_metric': 19.93406105041504}
Cheakpoint...
Epoch [198/300] best acc:tensor([0.9268], device='cuda:0'), Now : mean acc: tensor([0.9216], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9216402173042297, 'Val/mean miou_metric': 0.8764373064041138, 'Val/mean f1': 0.9332948923110962, 'Val/mean precision': 0.938530683517456, 'Val/mean recall': 0.9281173348426819, 'Val/mean hd95_metric': 19.93406105041504}
Epoch [199/300] Training [1/62] Loss: 0.04482 
Epoch [199/300] Training [2/62] Loss: 0.14378 
Epoch [199/300] Training [3/62] Loss: 0.04792 
Epoch [199/300] Training [4/62] Loss: 0.14219 
Epoch [199/300] Training [5/62] Loss: 0.03711 
Epoch [199/300] Training [6/62] Loss: 0.07246 
Epoch [199/300] Training [7/62] Loss: 0.09178 
Epoch [199/300] Training [8/62] Loss: 0.05764 
Epoch [199/300] Training [9/62] Loss: 0.03283 
Epoch [199/300] Training [10/62] Loss: 0.03779 
Epoch [199/300] Training [11/62] Loss: 0.10866 
Epoch [199/300] Training [12/62] Loss: 0.08073 
Epoch [199/300] Training [13/62] Loss: 0.04839 
Epoch [199/300] Training [14/62] Loss: 0.05818 
Epoch [199/300] Training [15/62] Loss: 0.12910 
Epoch [199/300] Training [16/62] Loss: 0.03932 
Epoch [199/300] Training [17/62] Loss: 0.06705 
Epoch [199/300] Training [18/62] Loss: 0.05009 
Epoch [199/300] Training [19/62] Loss: 0.07608 
Epoch [199/300] Training [20/62] Loss: 0.04992 
Epoch [199/300] Training [21/62] Loss: 0.03738 
Epoch [199/300] Training [22/62] Loss: 0.04172 
Epoch [199/300] Training [23/62] Loss: 0.07111 
Epoch [199/300] Training [24/62] Loss: 0.05642 
Epoch [199/300] Training [25/62] Loss: 0.06081 
Epoch [199/300] Training [26/62] Loss: 0.03912 
Epoch [199/300] Training [27/62] Loss: 0.03369 
Epoch [199/300] Training [28/62] Loss: 0.04202 
Epoch [199/300] Training [29/62] Loss: 0.04603 
Epoch [199/300] Training [30/62] Loss: 0.05955 
Epoch [199/300] Training [31/62] Loss: 0.04324 
Epoch [199/300] Training [32/62] Loss: 0.05107 
Epoch [199/300] Training [33/62] Loss: 0.05090 
Epoch [199/300] Training [34/62] Loss: 0.03913 
Epoch [199/300] Training [35/62] Loss: 0.03063 
Epoch [199/300] Training [36/62] Loss: 0.04339 
Epoch [199/300] Training [37/62] Loss: 0.03105 
Epoch [199/300] Training [38/62] Loss: 0.03354 
Epoch [199/300] Training [39/62] Loss: 0.03935 
Epoch [199/300] Training [40/62] Loss: 0.07596 
Epoch [199/300] Training [41/62] Loss: 0.12665 
Epoch [199/300] Training [42/62] Loss: 0.04202 
Epoch [199/300] Training [43/62] Loss: 0.04653 
Epoch [199/300] Training [44/62] Loss: 0.06018 
Epoch [199/300] Training [45/62] Loss: 0.03756 
Epoch [199/300] Training [46/62] Loss: 0.05567 
Epoch [199/300] Training [47/62] Loss: 0.07567 
Epoch [199/300] Training [48/62] Loss: 0.03659 
Epoch [199/300] Training [49/62] Loss: 0.04375 
Epoch [199/300] Training [50/62] Loss: 0.08136 
Epoch [199/300] Training [51/62] Loss: 0.05586 
Epoch [199/300] Training [52/62] Loss: 0.03301 
Epoch [199/300] Training [53/62] Loss: 0.04787 
Epoch [199/300] Training [54/62] Loss: 0.03993 
Epoch [199/300] Training [55/62] Loss: 0.07416 
Epoch [199/300] Training [56/62] Loss: 0.07086 
Epoch [199/300] Training [57/62] Loss: 0.06087 
Epoch [199/300] Training [58/62] Loss: 0.08012 
Epoch [199/300] Training [59/62] Loss: 0.10281 
Epoch [199/300] Training [60/62] Loss: 0.04336 
Epoch [199/300] Training [61/62] Loss: 0.08172 
Epoch [199/300] Training [62/62] Loss: 0.06803 
Epoch [199/300] Training metric {'Train/mean dice_metric': 0.958901584148407, 'Train/mean miou_metric': 0.926324725151062, 'Train/mean f1': 0.9635878205299377, 'Train/mean precision': 0.9610823392868042, 'Train/mean recall': 0.9661063551902771, 'Train/mean hd95_metric': 10.053258895874023}
Epoch [199/300] Validation [1/16] Loss: 0.62770  focal_loss 0.42890  dice_loss 0.19880 
Epoch [199/300] Validation [2/16] Loss: 0.53183  focal_loss 0.20726  dice_loss 0.32458 
Epoch [199/300] Validation [3/16] Loss: 0.65740  focal_loss 0.38003  dice_loss 0.27736 
Epoch [199/300] Validation [4/16] Loss: 0.33314  focal_loss 0.17474  dice_loss 0.15840 
Epoch [199/300] Validation [5/16] Loss: 0.30077  focal_loss 0.11207  dice_loss 0.18870 
Epoch [199/300] Validation [6/16] Loss: 0.29470  focal_loss 0.09454  dice_loss 0.20017 
Epoch [199/300] Validation [7/16] Loss: 0.19211  focal_loss 0.08022  dice_loss 0.11189 
Epoch [199/300] Validation [8/16] Loss: 0.46874  focal_loss 0.19862  dice_loss 0.27013 
Epoch [199/300] Validation [9/16] Loss: 0.21196  focal_loss 0.08812  dice_loss 0.12385 
Epoch [199/300] Validation [10/16] Loss: 0.46878  focal_loss 0.15133  dice_loss 0.31745 
Epoch [199/300] Validation [11/16] Loss: 0.17471  focal_loss 0.05916  dice_loss 0.11555 
Epoch [199/300] Validation [12/16] Loss: 0.40457  focal_loss 0.12761  dice_loss 0.27696 
Epoch [199/300] Validation [13/16] Loss: 0.26255  focal_loss 0.08877  dice_loss 0.17377 
Epoch [199/300] Validation [14/16] Loss: 0.56218  focal_loss 0.24134  dice_loss 0.32084 
Epoch [199/300] Validation [15/16] Loss: 0.11299  focal_loss 0.03673  dice_loss 0.07627 
Epoch [199/300] Validation [16/16] Loss: 0.14829  focal_loss 0.05316  dice_loss 0.09514 
Epoch [199/300] Validation metric {'Val/mean dice_metric': 0.926577091217041, 'Val/mean miou_metric': 0.8830369114875793, 'Val/mean f1': 0.9372738003730774, 'Val/mean precision': 0.9469459652900696, 'Val/mean recall': 0.9277973175048828, 'Val/mean hd95_metric': 18.371522903442383}
Cheakpoint...
Epoch [199/300] best acc:tensor([0.9268], device='cuda:0'), Now : mean acc: tensor([0.9266], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.926577091217041, 'Val/mean miou_metric': 0.8830369114875793, 'Val/mean f1': 0.9372738003730774, 'Val/mean precision': 0.9469459652900696, 'Val/mean recall': 0.9277973175048828, 'Val/mean hd95_metric': 18.371522903442383}
Epoch [200/300] Training [1/62] Loss: 0.03916 
Epoch [200/300] Training [2/62] Loss: 0.03558 
Epoch [200/300] Training [3/62] Loss: 0.05566 
Epoch [200/300] Training [4/62] Loss: 0.07456 
Epoch [200/300] Training [5/62] Loss: 0.06765 
Epoch [200/300] Training [6/62] Loss: 0.06331 
Epoch [200/300] Training [7/62] Loss: 0.04465 
Epoch [200/300] Training [8/62] Loss: 0.03699 
Epoch [200/300] Training [9/62] Loss: 0.02893 
Epoch [200/300] Training [10/62] Loss: 0.10962 
Epoch [200/300] Training [11/62] Loss: 0.08089 
Epoch [200/300] Training [12/62] Loss: 0.04497 
Epoch [200/300] Training [13/62] Loss: 0.12720 
Epoch [200/300] Training [14/62] Loss: 0.05967 
Epoch [200/300] Training [15/62] Loss: 0.03841 
Epoch [200/300] Training [16/62] Loss: 0.14410 
Epoch [200/300] Training [17/62] Loss: 0.04117 
Epoch [200/300] Training [18/62] Loss: 0.04935 
Epoch [200/300] Training [19/62] Loss: 0.03227 
Epoch [200/300] Training [20/62] Loss: 0.05797 
Epoch [200/300] Training [21/62] Loss: 0.05161 
Epoch [200/300] Training [22/62] Loss: 0.03633 
Epoch [200/300] Training [23/62] Loss: 0.03559 
Epoch [200/300] Training [24/62] Loss: 0.04715 
Epoch [200/300] Training [25/62] Loss: 0.14159 
Epoch [200/300] Training [26/62] Loss: 0.06963 
Epoch [200/300] Training [27/62] Loss: 0.03804 
Epoch [200/300] Training [28/62] Loss: 0.04127 
Epoch [200/300] Training [29/62] Loss: 0.04162 
Epoch [200/300] Training [30/62] Loss: 0.05823 
Epoch [200/300] Training [31/62] Loss: 0.04481 
Epoch [200/300] Training [32/62] Loss: 0.06598 
Epoch [200/300] Training [33/62] Loss: 0.09455 
Epoch [200/300] Training [34/62] Loss: 0.06302 
Epoch [200/300] Training [35/62] Loss: 0.04474 
Epoch [200/300] Training [36/62] Loss: 0.07035 
Epoch [200/300] Training [37/62] Loss: 0.04655 
Epoch [200/300] Training [38/62] Loss: 0.12147 
Epoch [200/300] Training [39/62] Loss: 0.07337 
Epoch [200/300] Training [40/62] Loss: 0.04111 
Epoch [200/300] Training [41/62] Loss: 0.15995 
Epoch [200/300] Training [42/62] Loss: 0.03709 
Epoch [200/300] Training [43/62] Loss: 0.04340 
Epoch [200/300] Training [44/62] Loss: 0.04116 
Epoch [200/300] Training [45/62] Loss: 0.05728 
Epoch [200/300] Training [46/62] Loss: 0.13338 
Epoch [200/300] Training [47/62] Loss: 0.14822 
Epoch [200/300] Training [48/62] Loss: 0.05033 
Epoch [200/300] Training [49/62] Loss: 0.08173 
Epoch [200/300] Training [50/62] Loss: 0.10033 
Epoch [200/300] Training [51/62] Loss: 0.05003 
Epoch [200/300] Training [52/62] Loss: 0.03737 
Epoch [200/300] Training [53/62] Loss: 0.03528 
Epoch [200/300] Training [54/62] Loss: 0.04814 
Epoch [200/300] Training [55/62] Loss: 0.04718 
Epoch [200/300] Training [56/62] Loss: 0.04952 
Epoch [200/300] Training [57/62] Loss: 0.04882 
Epoch [200/300] Training [58/62] Loss: 0.06397 
Epoch [200/300] Training [59/62] Loss: 0.04765 
Epoch [200/300] Training [60/62] Loss: 0.09426 
Epoch [200/300] Training [61/62] Loss: 0.05495 
Epoch [200/300] Training [62/62] Loss: 0.05748 
Epoch [200/300] Training metric {'Train/mean dice_metric': 0.9565445780754089, 'Train/mean miou_metric': 0.9229527711868286, 'Train/mean f1': 0.961052417755127, 'Train/mean precision': 0.9571447372436523, 'Train/mean recall': 0.9649920463562012, 'Train/mean hd95_metric': 10.524153709411621}
Epoch [200/300] Validation [1/16] Loss: 0.66910  focal_loss 0.45110  dice_loss 0.21800 
Epoch [200/300] Validation [2/16] Loss: 0.52386  focal_loss 0.21287  dice_loss 0.31099 
Epoch [200/300] Validation [3/16] Loss: 0.65209  focal_loss 0.36784  dice_loss 0.28426 
Epoch [200/300] Validation [4/16] Loss: 0.33880  focal_loss 0.16090  dice_loss 0.17789 
Epoch [200/300] Validation [5/16] Loss: 0.31198  focal_loss 0.11685  dice_loss 0.19514 
Epoch [200/300] Validation [6/16] Loss: 0.30118  focal_loss 0.08366  dice_loss 0.21751 
Epoch [200/300] Validation [7/16] Loss: 0.20308  focal_loss 0.08422  dice_loss 0.11886 
Epoch [200/300] Validation [8/16] Loss: 0.54530  focal_loss 0.20485  dice_loss 0.34046 
Epoch [200/300] Validation [9/16] Loss: 0.30063  focal_loss 0.13529  dice_loss 0.16535 
Epoch [200/300] Validation [10/16] Loss: 0.54059  focal_loss 0.17749  dice_loss 0.36310 
Epoch [200/300] Validation [11/16] Loss: 0.18065  focal_loss 0.06166  dice_loss 0.11899 
Epoch [200/300] Validation [12/16] Loss: 0.46775  focal_loss 0.12442  dice_loss 0.34333 
Epoch [200/300] Validation [13/16] Loss: 0.24453  focal_loss 0.08298  dice_loss 0.16154 
Epoch [200/300] Validation [14/16] Loss: 0.61547  focal_loss 0.24937  dice_loss 0.36610 
Epoch [200/300] Validation [15/16] Loss: 0.16039  focal_loss 0.06143  dice_loss 0.09896 
Epoch [200/300] Validation [16/16] Loss: 0.10307  focal_loss 0.02912  dice_loss 0.07395 
Epoch [200/300] Validation metric {'Val/mean dice_metric': 0.9202374219894409, 'Val/mean miou_metric': 0.8757249712944031, 'Val/mean f1': 0.9329081177711487, 'Val/mean precision': 0.9412508010864258, 'Val/mean recall': 0.924712061882019, 'Val/mean hd95_metric': 18.480243682861328}
Cheakpoint...
Epoch [200/300] best acc:tensor([0.9268], device='cuda:0'), Now : mean acc: tensor([0.9202], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9202374219894409, 'Val/mean miou_metric': 0.8757249712944031, 'Val/mean f1': 0.9329081177711487, 'Val/mean precision': 0.9412508010864258, 'Val/mean recall': 0.924712061882019, 'Val/mean hd95_metric': 18.480243682861328}
Epoch [201/300] Training [1/62] Loss: 0.11070 
Epoch [201/300] Training [2/62] Loss: 0.05038 
Epoch [201/300] Training [3/62] Loss: 0.03652 
Epoch [201/300] Training [4/62] Loss: 0.04020 
Epoch [201/300] Training [5/62] Loss: 0.04142 
Epoch [201/300] Training [6/62] Loss: 0.04872 
Epoch [201/300] Training [7/62] Loss: 0.15872 
Epoch [201/300] Training [8/62] Loss: 0.07436 
Epoch [201/300] Training [9/62] Loss: 0.03372 
Epoch [201/300] Training [10/62] Loss: 0.11624 
Epoch [201/300] Training [11/62] Loss: 0.09578 
Epoch [201/300] Training [12/62] Loss: 0.03804 
Epoch [201/300] Training [13/62] Loss: 0.05793 
Epoch [201/300] Training [14/62] Loss: 0.05552 
Epoch [201/300] Training [15/62] Loss: 0.04213 
Epoch [201/300] Training [16/62] Loss: 0.06952 
Epoch [201/300] Training [17/62] Loss: 0.07810 
Epoch [201/300] Training [18/62] Loss: 0.03682 
Epoch [201/300] Training [19/62] Loss: 0.04204 
Epoch [201/300] Training [20/62] Loss: 0.05314 
Epoch [201/300] Training [21/62] Loss: 0.05515 
Epoch [201/300] Training [22/62] Loss: 0.05610 
Epoch [201/300] Training [23/62] Loss: 0.04614 
Epoch [201/300] Training [24/62] Loss: 0.06119 
Epoch [201/300] Training [25/62] Loss: 0.07450 
Epoch [201/300] Training [26/62] Loss: 0.04108 
Epoch [201/300] Training [27/62] Loss: 0.07506 
Epoch [201/300] Training [28/62] Loss: 0.08460 
Epoch [201/300] Training [29/62] Loss: 0.03446 
Epoch [201/300] Training [30/62] Loss: 0.05143 
Epoch [201/300] Training [31/62] Loss: 0.06191 
Epoch [201/300] Training [32/62] Loss: 0.05567 
Epoch [201/300] Training [33/62] Loss: 0.03731 
Epoch [201/300] Training [34/62] Loss: 0.09452 
Epoch [201/300] Training [35/62] Loss: 0.05786 
Epoch [201/300] Training [36/62] Loss: 0.03262 
Epoch [201/300] Training [37/62] Loss: 0.04454 
Epoch [201/300] Training [38/62] Loss: 0.06122 
Epoch [201/300] Training [39/62] Loss: 0.05794 
Epoch [201/300] Training [40/62] Loss: 0.04305 
Epoch [201/300] Training [41/62] Loss: 0.03460 
Epoch [201/300] Training [42/62] Loss: 0.03736 
Epoch [201/300] Training [43/62] Loss: 0.06918 
Epoch [201/300] Training [44/62] Loss: 0.14540 
Epoch [201/300] Training [45/62] Loss: 0.04601 
Epoch [201/300] Training [46/62] Loss: 0.05754 
Epoch [201/300] Training [47/62] Loss: 0.05239 
Epoch [201/300] Training [48/62] Loss: 0.05097 
Epoch [201/300] Training [49/62] Loss: 0.12867 
Epoch [201/300] Training [50/62] Loss: 0.03474 
Epoch [201/300] Training [51/62] Loss: 0.04569 
Epoch [201/300] Training [52/62] Loss: 0.04308 
Epoch [201/300] Training [53/62] Loss: 0.04896 
Epoch [201/300] Training [54/62] Loss: 0.04505 
Epoch [201/300] Training [55/62] Loss: 0.04723 
Epoch [201/300] Training [56/62] Loss: 0.06982 
Epoch [201/300] Training [57/62] Loss: 0.04530 
Epoch [201/300] Training [58/62] Loss: 0.06508 
Epoch [201/300] Training [59/62] Loss: 0.04623 
Epoch [201/300] Training [60/62] Loss: 0.07189 
Epoch [201/300] Training [61/62] Loss: 0.06623 
Epoch [201/300] Training [62/62] Loss: 0.06815 
Epoch [201/300] Training metric {'Train/mean dice_metric': 0.9586628675460815, 'Train/mean miou_metric': 0.9261755347251892, 'Train/mean f1': 0.9633148312568665, 'Train/mean precision': 0.9601467251777649, 'Train/mean recall': 0.9665038585662842, 'Train/mean hd95_metric': 8.649003028869629}
Epoch [201/300] Validation [1/16] Loss: 0.73655  focal_loss 0.48115  dice_loss 0.25540 
Epoch [201/300] Validation [2/16] Loss: 0.49855  focal_loss 0.19945  dice_loss 0.29910 
Epoch [201/300] Validation [3/16] Loss: 0.71522  focal_loss 0.41856  dice_loss 0.29665 
Epoch [201/300] Validation [4/16] Loss: 0.29278  focal_loss 0.15162  dice_loss 0.14115 
Epoch [201/300] Validation [5/16] Loss: 0.29845  focal_loss 0.09741  dice_loss 0.20103 
Epoch [201/300] Validation [6/16] Loss: 0.28033  focal_loss 0.08090  dice_loss 0.19943 
Epoch [201/300] Validation [7/16] Loss: 0.28432  focal_loss 0.12041  dice_loss 0.16391 
Epoch [201/300] Validation [8/16] Loss: 0.37074  focal_loss 0.12790  dice_loss 0.24283 
Epoch [201/300] Validation [9/16] Loss: 0.24380  focal_loss 0.09624  dice_loss 0.14757 
Epoch [201/300] Validation [10/16] Loss: 0.56711  focal_loss 0.19490  dice_loss 0.37221 
Epoch [201/300] Validation [11/16] Loss: 0.31700  focal_loss 0.12402  dice_loss 0.19298 
Epoch [201/300] Validation [12/16] Loss: 0.43793  focal_loss 0.12850  dice_loss 0.30942 
Epoch [201/300] Validation [13/16] Loss: 0.33048  focal_loss 0.12849  dice_loss 0.20199 
Epoch [201/300] Validation [14/16] Loss: 0.57435  focal_loss 0.25371  dice_loss 0.32065 
Epoch [201/300] Validation [15/16] Loss: 0.17815  focal_loss 0.06804  dice_loss 0.11011 
Epoch [201/300] Validation [16/16] Loss: 0.11367  focal_loss 0.02812  dice_loss 0.08555 
Epoch [201/300] Validation metric {'Val/mean dice_metric': 0.9226051568984985, 'Val/mean miou_metric': 0.8777369260787964, 'Val/mean f1': 0.9338140487670898, 'Val/mean precision': 0.9426925778388977, 'Val/mean recall': 0.9251011610031128, 'Val/mean hd95_metric': 17.57950210571289}
Cheakpoint...
Epoch [201/300] best acc:tensor([0.9268], device='cuda:0'), Now : mean acc: tensor([0.9226], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9226051568984985, 'Val/mean miou_metric': 0.8777369260787964, 'Val/mean f1': 0.9338140487670898, 'Val/mean precision': 0.9426925778388977, 'Val/mean recall': 0.9251011610031128, 'Val/mean hd95_metric': 17.57950210571289}
Epoch [202/300] Training [1/62] Loss: 0.08376 
Epoch [202/300] Training [2/62] Loss: 0.03617 
Epoch [202/300] Training [3/62] Loss: 0.04915 
Epoch [202/300] Training [4/62] Loss: 0.04413 
Epoch [202/300] Training [5/62] Loss: 0.04971 
Epoch [202/300] Training [6/62] Loss: 0.08777 
Epoch [202/300] Training [7/62] Loss: 0.07304 
Epoch [202/300] Training [8/62] Loss: 0.03814 
Epoch [202/300] Training [9/62] Loss: 0.12782 
Epoch [202/300] Training [10/62] Loss: 0.05652 
Epoch [202/300] Training [11/62] Loss: 0.06084 
Epoch [202/300] Training [12/62] Loss: 0.03512 
Epoch [202/300] Training [13/62] Loss: 0.04894 
Epoch [202/300] Training [14/62] Loss: 0.06354 
Epoch [202/300] Training [15/62] Loss: 0.05218 
Epoch [202/300] Training [16/62] Loss: 0.07059 
Epoch [202/300] Training [17/62] Loss: 0.06587 
Epoch [202/300] Training [18/62] Loss: 0.03766 
Epoch [202/300] Training [19/62] Loss: 0.07133 
Epoch [202/300] Training [20/62] Loss: 0.08711 
Epoch [202/300] Training [21/62] Loss: 0.05376 
Epoch [202/300] Training [22/62] Loss: 0.08565 
Epoch [202/300] Training [23/62] Loss: 0.06890 
Epoch [202/300] Training [24/62] Loss: 0.03732 
Epoch [202/300] Training [25/62] Loss: 0.05302 
Epoch [202/300] Training [26/62] Loss: 0.12457 
Epoch [202/300] Training [27/62] Loss: 0.04643 
Epoch [202/300] Training [28/62] Loss: 0.03789 
Epoch [202/300] Training [29/62] Loss: 0.03362 
Epoch [202/300] Training [30/62] Loss: 0.07493 
Epoch [202/300] Training [31/62] Loss: 0.03604 
Epoch [202/300] Training [32/62] Loss: 0.03977 
Epoch [202/300] Training [33/62] Loss: 0.04218 
Epoch [202/300] Training [34/62] Loss: 0.06670 
Epoch [202/300] Training [35/62] Loss: 0.03422 
Epoch [202/300] Training [36/62] Loss: 0.08912 
Epoch [202/300] Training [37/62] Loss: 0.04217 
Epoch [202/300] Training [38/62] Loss: 0.04106 
Epoch [202/300] Training [39/62] Loss: 0.06849 
Epoch [202/300] Training [40/62] Loss: 0.03698 
Epoch [202/300] Training [41/62] Loss: 0.08326 
Epoch [202/300] Training [42/62] Loss: 0.05804 
Epoch [202/300] Training [43/62] Loss: 0.03339 
Epoch [202/300] Training [44/62] Loss: 0.03940 
Epoch [202/300] Training [45/62] Loss: 0.03084 
Epoch [202/300] Training [46/62] Loss: 0.04011 
Epoch [202/300] Training [47/62] Loss: 0.04277 
Epoch [202/300] Training [48/62] Loss: 0.06325 
Epoch [202/300] Training [49/62] Loss: 0.04219 
Epoch [202/300] Training [50/62] Loss: 0.05630 
Epoch [202/300] Training [51/62] Loss: 0.16990 
Epoch [202/300] Training [52/62] Loss: 0.03628 
Epoch [202/300] Training [53/62] Loss: 0.13145 
Epoch [202/300] Training [54/62] Loss: 0.05954 
Epoch [202/300] Training [55/62] Loss: 0.04313 
Epoch [202/300] Training [56/62] Loss: 0.07642 
Epoch [202/300] Training [57/62] Loss: 0.03709 
Epoch [202/300] Training [58/62] Loss: 0.05253 
Epoch [202/300] Training [59/62] Loss: 0.04354 
Epoch [202/300] Training [60/62] Loss: 0.03602 
Epoch [202/300] Training [61/62] Loss: 0.06332 
Epoch [202/300] Training [62/62] Loss: 0.03091 
Epoch [202/300] Training metric {'Train/mean dice_metric': 0.9597899317741394, 'Train/mean miou_metric': 0.9276352524757385, 'Train/mean f1': 0.9637832641601562, 'Train/mean precision': 0.9601030349731445, 'Train/mean recall': 0.9674916863441467, 'Train/mean hd95_metric': 8.954737663269043}
Epoch [202/300] Validation [1/16] Loss: 0.61014  focal_loss 0.41994  dice_loss 0.19020 
Epoch [202/300] Validation [2/16] Loss: 0.43661  focal_loss 0.16203  dice_loss 0.27458 
Epoch [202/300] Validation [3/16] Loss: 0.65504  focal_loss 0.37824  dice_loss 0.27681 
Epoch [202/300] Validation [4/16] Loss: 0.31357  focal_loss 0.15301  dice_loss 0.16055 
Epoch [202/300] Validation [5/16] Loss: 0.31718  focal_loss 0.10277  dice_loss 0.21440 
Epoch [202/300] Validation [6/16] Loss: 0.32600  focal_loss 0.11214  dice_loss 0.21386 
Epoch [202/300] Validation [7/16] Loss: 0.18676  focal_loss 0.07783  dice_loss 0.10893 
Epoch [202/300] Validation [8/16] Loss: 0.46787  focal_loss 0.16805  dice_loss 0.29982 
Epoch [202/300] Validation [9/16] Loss: 0.24393  focal_loss 0.09222  dice_loss 0.15171 
Epoch [202/300] Validation [10/16] Loss: 0.50063  focal_loss 0.16005  dice_loss 0.34057 
Epoch [202/300] Validation [11/16] Loss: 0.15886  focal_loss 0.05611  dice_loss 0.10276 
Epoch [202/300] Validation [12/16] Loss: 0.37606  focal_loss 0.10606  dice_loss 0.27000 
Epoch [202/300] Validation [13/16] Loss: 0.28679  focal_loss 0.09320  dice_loss 0.19359 
Epoch [202/300] Validation [14/16] Loss: 0.53886  focal_loss 0.24271  dice_loss 0.29615 
Epoch [202/300] Validation [15/16] Loss: 0.12334  focal_loss 0.03817  dice_loss 0.08517 
Epoch [202/300] Validation [16/16] Loss: 0.10344  focal_loss 0.03074  dice_loss 0.07270 
Epoch [202/300] Validation metric {'Val/mean dice_metric': 0.9270951151847839, 'Val/mean miou_metric': 0.8838639855384827, 'Val/mean f1': 0.9360437989234924, 'Val/mean precision': 0.9373032450675964, 'Val/mean recall': 0.9347878694534302, 'Val/mean hd95_metric': 18.15861701965332}
Cheakpoint...
Epoch [202/300] best acc:tensor([0.9271], device='cuda:0'), Now : mean acc: tensor([0.9271], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9270951151847839, 'Val/mean miou_metric': 0.8838639855384827, 'Val/mean f1': 0.9360437989234924, 'Val/mean precision': 0.9373032450675964, 'Val/mean recall': 0.9347878694534302, 'Val/mean hd95_metric': 18.15861701965332}
Epoch [203/300] Training [1/62] Loss: 0.03258 
Epoch [203/300] Training [2/62] Loss: 0.11567 
Epoch [203/300] Training [3/62] Loss: 0.08230 
Epoch [203/300] Training [4/62] Loss: 0.04163 
Epoch [203/300] Training [5/62] Loss: 0.03429 
Epoch [203/300] Training [6/62] Loss: 0.11831 
Epoch [203/300] Training [7/62] Loss: 0.04251 
Epoch [203/300] Training [8/62] Loss: 0.03555 
Epoch [203/300] Training [9/62] Loss: 0.05421 
Epoch [203/300] Training [10/62] Loss: 0.05687 
Epoch [203/300] Training [11/62] Loss: 0.03377 
Epoch [203/300] Training [12/62] Loss: 0.05620 
Epoch [203/300] Training [13/62] Loss: 0.04953 
Epoch [203/300] Training [14/62] Loss: 0.04920 
Epoch [203/300] Training [15/62] Loss: 0.03341 
Epoch [203/300] Training [16/62] Loss: 0.06152 
Epoch [203/300] Training [17/62] Loss: 0.04497 
Epoch [203/300] Training [18/62] Loss: 0.03955 
Epoch [203/300] Training [19/62] Loss: 0.03593 
Epoch [203/300] Training [20/62] Loss: 0.03509 
Epoch [203/300] Training [21/62] Loss: 0.08071 
Epoch [203/300] Training [22/62] Loss: 0.18612 
Epoch [203/300] Training [23/62] Loss: 0.05606 
Epoch [203/300] Training [24/62] Loss: 0.03246 
Epoch [203/300] Training [25/62] Loss: 0.14366 
Epoch [203/300] Training [26/62] Loss: 0.11120 
Epoch [203/300] Training [27/62] Loss: 0.05391 
Epoch [203/300] Training [28/62] Loss: 0.06119 
Epoch [203/300] Training [29/62] Loss: 0.15463 
Epoch [203/300] Training [30/62] Loss: 0.09859 
Epoch [203/300] Training [31/62] Loss: 0.05104 
Epoch [203/300] Training [32/62] Loss: 0.03468 
Epoch [203/300] Training [33/62] Loss: 0.05794 
Epoch [203/300] Training [34/62] Loss: 0.05227 
Epoch [203/300] Training [35/62] Loss: 0.05376 
Epoch [203/300] Training [36/62] Loss: 0.05773 
Epoch [203/300] Training [37/62] Loss: 0.03872 
Epoch [203/300] Training [38/62] Loss: 0.03404 
Epoch [203/300] Training [39/62] Loss: 0.06483 
Epoch [203/300] Training [40/62] Loss: 0.12180 
Epoch [203/300] Training [41/62] Loss: 0.04156 
Epoch [203/300] Training [42/62] Loss: 0.03786 
Epoch [203/300] Training [43/62] Loss: 0.04979 
Epoch [203/300] Training [44/62] Loss: 0.13067 
Epoch [203/300] Training [45/62] Loss: 0.03787 
Epoch [203/300] Training [46/62] Loss: 0.06736 
Epoch [203/300] Training [47/62] Loss: 0.05838 
Epoch [203/300] Training [48/62] Loss: 0.03750 
Epoch [203/300] Training [49/62] Loss: 0.03978 
Epoch [203/300] Training [50/62] Loss: 0.08508 
Epoch [203/300] Training [51/62] Loss: 0.11768 
Epoch [203/300] Training [52/62] Loss: 0.10563 
Epoch [203/300] Training [53/62] Loss: 0.03877 
Epoch [203/300] Training [54/62] Loss: 0.04159 
Epoch [203/300] Training [55/62] Loss: 0.03447 
Epoch [203/300] Training [56/62] Loss: 0.05011 
Epoch [203/300] Training [57/62] Loss: 0.06749 
Epoch [203/300] Training [58/62] Loss: 0.06082 
Epoch [203/300] Training [59/62] Loss: 0.03601 
Epoch [203/300] Training [60/62] Loss: 0.04615 
Epoch [203/300] Training [61/62] Loss: 0.06112 
Epoch [203/300] Training [62/62] Loss: 0.41867 
Epoch [203/300] Training metric {'Train/mean dice_metric': 0.9557982087135315, 'Train/mean miou_metric': 0.9221301078796387, 'Train/mean f1': 0.9625649452209473, 'Train/mean precision': 0.960794985294342, 'Train/mean recall': 0.9643413424491882, 'Train/mean hd95_metric': 9.209336280822754}
Epoch [203/300] Validation [1/16] Loss: 0.63961  focal_loss 0.42053  dice_loss 0.21907 
Epoch [203/300] Validation [2/16] Loss: 0.46585  focal_loss 0.18469  dice_loss 0.28116 
Epoch [203/300] Validation [3/16] Loss: 0.66148  focal_loss 0.37439  dice_loss 0.28708 
Epoch [203/300] Validation [4/16] Loss: 0.29888  focal_loss 0.14619  dice_loss 0.15269 
Epoch [203/300] Validation [5/16] Loss: 0.32408  focal_loss 0.10722  dice_loss 0.21686 
Epoch [203/300] Validation [6/16] Loss: 0.30567  focal_loss 0.09255  dice_loss 0.21312 
Epoch [203/300] Validation [7/16] Loss: 0.17799  focal_loss 0.07264  dice_loss 0.10535 
Epoch [203/300] Validation [8/16] Loss: 0.57496  focal_loss 0.23376  dice_loss 0.34121 
Epoch [203/300] Validation [9/16] Loss: 0.25747  focal_loss 0.10379  dice_loss 0.15368 
Epoch [203/300] Validation [10/16] Loss: 0.49430  focal_loss 0.16051  dice_loss 0.33378 
Epoch [203/300] Validation [11/16] Loss: 0.19312  focal_loss 0.06202  dice_loss 0.13110 
Epoch [203/300] Validation [12/16] Loss: 0.40338  focal_loss 0.12857  dice_loss 0.27481 
Epoch [203/300] Validation [13/16] Loss: 0.22812  focal_loss 0.07887  dice_loss 0.14925 
Epoch [203/300] Validation [14/16] Loss: 0.46580  focal_loss 0.20917  dice_loss 0.25662 
Epoch [203/300] Validation [15/16] Loss: 0.11794  focal_loss 0.03965  dice_loss 0.07829 
Epoch [203/300] Validation [16/16] Loss: 0.09823  focal_loss 0.02710  dice_loss 0.07113 
Epoch [203/300] Validation metric {'Val/mean dice_metric': 0.923570990562439, 'Val/mean miou_metric': 0.8787443041801453, 'Val/mean f1': 0.9356011748313904, 'Val/mean precision': 0.9415537714958191, 'Val/mean recall': 0.9297234416007996, 'Val/mean hd95_metric': 17.970556259155273}
Cheakpoint...
Epoch [203/300] best acc:tensor([0.9271], device='cuda:0'), Now : mean acc: tensor([0.9236], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.923570990562439, 'Val/mean miou_metric': 0.8787443041801453, 'Val/mean f1': 0.9356011748313904, 'Val/mean precision': 0.9415537714958191, 'Val/mean recall': 0.9297234416007996, 'Val/mean hd95_metric': 17.970556259155273}
Epoch [204/300] Training [1/62] Loss: 0.16833 
Epoch [204/300] Training [2/62] Loss: 0.06202 
Epoch [204/300] Training [3/62] Loss: 0.06348 
Epoch [204/300] Training [4/62] Loss: 0.04466 
Epoch [204/300] Training [5/62] Loss: 0.05632 
Epoch [204/300] Training [6/62] Loss: 0.04526 
Epoch [204/300] Training [7/62] Loss: 0.13884 
Epoch [204/300] Training [8/62] Loss: 0.05204 
Epoch [204/300] Training [9/62] Loss: 0.05819 
Epoch [204/300] Training [10/62] Loss: 0.05273 
Epoch [204/300] Training [11/62] Loss: 0.05824 
Epoch [204/300] Training [12/62] Loss: 0.06039 
Epoch [204/300] Training [13/62] Loss: 0.03557 
Epoch [204/300] Training [14/62] Loss: 0.04059 
Epoch [204/300] Training [15/62] Loss: 0.03871 
Epoch [204/300] Training [16/62] Loss: 0.08248 
Epoch [204/300] Training [17/62] Loss: 0.07649 
Epoch [204/300] Training [18/62] Loss: 0.06158 
Epoch [204/300] Training [19/62] Loss: 0.03797 
Epoch [204/300] Training [20/62] Loss: 0.06277 
Epoch [204/300] Training [21/62] Loss: 0.05397 
Epoch [204/300] Training [22/62] Loss: 0.06344 
Epoch [204/300] Training [23/62] Loss: 0.04756 
Epoch [204/300] Training [24/62] Loss: 0.09667 
Epoch [204/300] Training [25/62] Loss: 0.08316 
Epoch [204/300] Training [26/62] Loss: 0.09778 
Epoch [204/300] Training [27/62] Loss: 0.05537 
Epoch [204/300] Training [28/62] Loss: 0.04211 
Epoch [204/300] Training [29/62] Loss: 0.03167 
Epoch [204/300] Training [30/62] Loss: 0.05410 
Epoch [204/300] Training [31/62] Loss: 0.06292 
Epoch [204/300] Training [32/62] Loss: 0.08797 
Epoch [204/300] Training [33/62] Loss: 0.09032 
Epoch [204/300] Training [34/62] Loss: 0.04508 
Epoch [204/300] Training [35/62] Loss: 0.03212 
Epoch [204/300] Training [36/62] Loss: 0.03537 
Epoch [204/300] Training [37/62] Loss: 0.13465 
Epoch [204/300] Training [38/62] Loss: 0.05916 
Epoch [204/300] Training [39/62] Loss: 0.06016 
Epoch [204/300] Training [40/62] Loss: 0.07064 
Epoch [204/300] Training [41/62] Loss: 0.04523 
Epoch [204/300] Training [42/62] Loss: 0.03666 
Epoch [204/300] Training [43/62] Loss: 0.03997 
Epoch [204/300] Training [44/62] Loss: 0.09014 
Epoch [204/300] Training [45/62] Loss: 0.03469 
Epoch [204/300] Training [46/62] Loss: 0.04947 
Epoch [204/300] Training [47/62] Loss: 0.03880 
Epoch [204/300] Training [48/62] Loss: 0.05026 
Epoch [204/300] Training [49/62] Loss: 0.03316 
Epoch [204/300] Training [50/62] Loss: 0.07481 
Epoch [204/300] Training [51/62] Loss: 0.03799 
Epoch [204/300] Training [52/62] Loss: 0.04178 
Epoch [204/300] Training [53/62] Loss: 0.03907 
Epoch [204/300] Training [54/62] Loss: 0.05843 
Epoch [204/300] Training [55/62] Loss: 0.06537 
Epoch [204/300] Training [56/62] Loss: 0.03770 
Epoch [204/300] Training [57/62] Loss: 0.03379 
Epoch [204/300] Training [58/62] Loss: 0.04330 
Epoch [204/300] Training [59/62] Loss: 0.09770 
Epoch [204/300] Training [60/62] Loss: 0.05319 
Epoch [204/300] Training [61/62] Loss: 0.13464 
Epoch [204/300] Training [62/62] Loss: 0.25211 
Epoch [204/300] Training metric {'Train/mean dice_metric': 0.9578186869621277, 'Train/mean miou_metric': 0.9245672821998596, 'Train/mean f1': 0.9626815319061279, 'Train/mean precision': 0.9606539607048035, 'Train/mean recall': 0.9647177457809448, 'Train/mean hd95_metric': 9.493966102600098}
Epoch [204/300] Validation [1/16] Loss: 0.66396  focal_loss 0.45887  dice_loss 0.20509 
Epoch [204/300] Validation [2/16] Loss: 0.46365  focal_loss 0.18390  dice_loss 0.27975 
Epoch [204/300] Validation [3/16] Loss: 0.63374  focal_loss 0.36909  dice_loss 0.26465 
Epoch [204/300] Validation [4/16] Loss: 0.33438  focal_loss 0.15541  dice_loss 0.17897 
Epoch [204/300] Validation [5/16] Loss: 0.33638  focal_loss 0.11549  dice_loss 0.22088 
Epoch [204/300] Validation [6/16] Loss: 0.28019  focal_loss 0.08761  dice_loss 0.19258 
Epoch [204/300] Validation [7/16] Loss: 0.18399  focal_loss 0.07140  dice_loss 0.11259 
Epoch [204/300] Validation [8/16] Loss: 0.46514  focal_loss 0.17575  dice_loss 0.28939 
Epoch [204/300] Validation [9/16] Loss: 0.21294  focal_loss 0.08731  dice_loss 0.12563 
Epoch [204/300] Validation [10/16] Loss: 0.42285  focal_loss 0.12661  dice_loss 0.29624 
Epoch [204/300] Validation [11/16] Loss: 0.18555  focal_loss 0.07265  dice_loss 0.11290 
Epoch [204/300] Validation [12/16] Loss: 0.39819  focal_loss 0.11219  dice_loss 0.28600 
Epoch [204/300] Validation [13/16] Loss: 0.23686  focal_loss 0.07387  dice_loss 0.16299 
Epoch [204/300] Validation [14/16] Loss: 0.51321  focal_loss 0.23810  dice_loss 0.27511 
Epoch [204/300] Validation [15/16] Loss: 0.10850  focal_loss 0.03540  dice_loss 0.07309 
Epoch [204/300] Validation [16/16] Loss: 0.15990  focal_loss 0.05130  dice_loss 0.10859 
Epoch [204/300] Validation metric {'Val/mean dice_metric': 0.9264668226242065, 'Val/mean miou_metric': 0.8828715682029724, 'Val/mean f1': 0.9368774890899658, 'Val/mean precision': 0.9420706629753113, 'Val/mean recall': 0.9317413568496704, 'Val/mean hd95_metric': 18.26091766357422}
Cheakpoint...
Epoch [204/300] best acc:tensor([0.9271], device='cuda:0'), Now : mean acc: tensor([0.9265], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9264668226242065, 'Val/mean miou_metric': 0.8828715682029724, 'Val/mean f1': 0.9368774890899658, 'Val/mean precision': 0.9420706629753113, 'Val/mean recall': 0.9317413568496704, 'Val/mean hd95_metric': 18.26091766357422}
Epoch [205/300] Training [1/62] Loss: 0.05344 
Epoch [205/300] Training [2/62] Loss: 0.04486 
Epoch [205/300] Training [3/62] Loss: 0.03909 
Epoch [205/300] Training [4/62] Loss: 0.04749 
Epoch [205/300] Training [5/62] Loss: 0.03474 
Epoch [205/300] Training [6/62] Loss: 0.03404 
Epoch [205/300] Training [7/62] Loss: 0.04144 
Epoch [205/300] Training [8/62] Loss: 0.04375 
Epoch [205/300] Training [9/62] Loss: 0.03891 
Epoch [205/300] Training [10/62] Loss: 0.05004 
Epoch [205/300] Training [11/62] Loss: 0.11127 
Epoch [205/300] Training [12/62] Loss: 0.05693 
Epoch [205/300] Training [13/62] Loss: 0.07191 
Epoch [205/300] Training [14/62] Loss: 0.04597 
Epoch [205/300] Training [15/62] Loss: 0.04239 
Epoch [205/300] Training [16/62] Loss: 0.15265 
Epoch [205/300] Training [17/62] Loss: 0.05222 
Epoch [205/300] Training [18/62] Loss: 0.04196 
Epoch [205/300] Training [19/62] Loss: 0.05348 
Epoch [205/300] Training [20/62] Loss: 0.03109 
Epoch [205/300] Training [21/62] Loss: 0.03936 
Epoch [205/300] Training [22/62] Loss: 0.05565 
Epoch [205/300] Training [23/62] Loss: 0.04661 
Epoch [205/300] Training [24/62] Loss: 0.07087 
Epoch [205/300] Training [25/62] Loss: 0.03681 
Epoch [205/300] Training [26/62] Loss: 0.04019 
Epoch [205/300] Training [27/62] Loss: 0.04662 
Epoch [205/300] Training [28/62] Loss: 0.04305 
Epoch [205/300] Training [29/62] Loss: 0.06137 
Epoch [205/300] Training [30/62] Loss: 0.05263 
Epoch [205/300] Training [31/62] Loss: 0.08745 
Epoch [205/300] Training [32/62] Loss: 0.04028 
Epoch [205/300] Training [33/62] Loss: 0.05968 
Epoch [205/300] Training [34/62] Loss: 0.03333 
Epoch [205/300] Training [35/62] Loss: 0.14833 
Epoch [205/300] Training [36/62] Loss: 0.05109 
Epoch [205/300] Training [37/62] Loss: 0.08978 
Epoch [205/300] Training [38/62] Loss: 0.04277 
Epoch [205/300] Training [39/62] Loss: 0.04838 
Epoch [205/300] Training [40/62] Loss: 0.05512 
Epoch [205/300] Training [41/62] Loss: 0.12055 
Epoch [205/300] Training [42/62] Loss: 0.05110 
Epoch [205/300] Training [43/62] Loss: 0.07433 
Epoch [205/300] Training [44/62] Loss: 0.03653 
Epoch [205/300] Training [45/62] Loss: 0.03459 
Epoch [205/300] Training [46/62] Loss: 0.04187 
Epoch [205/300] Training [47/62] Loss: 0.04772 
Epoch [205/300] Training [48/62] Loss: 0.04560 
Epoch [205/300] Training [49/62] Loss: 0.04770 
Epoch [205/300] Training [50/62] Loss: 0.03286 
Epoch [205/300] Training [51/62] Loss: 0.05566 
Epoch [205/300] Training [52/62] Loss: 0.03308 
Epoch [205/300] Training [53/62] Loss: 0.11388 
Epoch [205/300] Training [54/62] Loss: 0.06955 
Epoch [205/300] Training [55/62] Loss: 0.03227 
Epoch [205/300] Training [56/62] Loss: 0.04455 
Epoch [205/300] Training [57/62] Loss: 0.04076 
Epoch [205/300] Training [58/62] Loss: 0.12910 
Epoch [205/300] Training [59/62] Loss: 0.07635 
Epoch [205/300] Training [60/62] Loss: 0.14165 
Epoch [205/300] Training [61/62] Loss: 0.05821 
Epoch [205/300] Training [62/62] Loss: 0.04060 
Epoch [205/300] Training metric {'Train/mean dice_metric': 0.960878849029541, 'Train/mean miou_metric': 0.9289206862449646, 'Train/mean f1': 0.9635336995124817, 'Train/mean precision': 0.9607928991317749, 'Train/mean recall': 0.9662901759147644, 'Train/mean hd95_metric': 9.680234909057617}
Epoch [205/300] Validation [1/16] Loss: 0.78619  focal_loss 0.51060  dice_loss 0.27559 
Epoch [205/300] Validation [2/16] Loss: 0.63605  focal_loss 0.26026  dice_loss 0.37579 
Epoch [205/300] Validation [3/16] Loss: 0.73873  focal_loss 0.38020  dice_loss 0.35853 
Epoch [205/300] Validation [4/16] Loss: 0.39886  focal_loss 0.19070  dice_loss 0.20816 
Epoch [205/300] Validation [5/16] Loss: 0.32435  focal_loss 0.11756  dice_loss 0.20679 
Epoch [205/300] Validation [6/16] Loss: 0.27938  focal_loss 0.08582  dice_loss 0.19356 
Epoch [205/300] Validation [7/16] Loss: 0.25493  focal_loss 0.10395  dice_loss 0.15098 
Epoch [205/300] Validation [8/16] Loss: 0.56043  focal_loss 0.22040  dice_loss 0.34003 
Epoch [205/300] Validation [9/16] Loss: 0.44085  focal_loss 0.22465  dice_loss 0.21620 
Epoch [205/300] Validation [10/16] Loss: 0.53692  focal_loss 0.19320  dice_loss 0.34372 
Epoch [205/300] Validation [11/16] Loss: 0.28760  focal_loss 0.11779  dice_loss 0.16981 
Epoch [205/300] Validation [12/16] Loss: 0.49286  focal_loss 0.11958  dice_loss 0.37328 
Epoch [205/300] Validation [13/16] Loss: 0.22636  focal_loss 0.07289  dice_loss 0.15347 
Epoch [205/300] Validation [14/16] Loss: 0.53722  focal_loss 0.24757  dice_loss 0.28964 
Epoch [205/300] Validation [15/16] Loss: 0.15640  focal_loss 0.05883  dice_loss 0.09757 
Epoch [205/300] Validation [16/16] Loss: 0.11752  focal_loss 0.03334  dice_loss 0.08419 
Epoch [205/300] Validation metric {'Val/mean dice_metric': 0.9200584888458252, 'Val/mean miou_metric': 0.8757304549217224, 'Val/mean f1': 0.9321563243865967, 'Val/mean precision': 0.9405845403671265, 'Val/mean recall': 0.9238777160644531, 'Val/mean hd95_metric': 19.235631942749023}
Cheakpoint...
Epoch [205/300] best acc:tensor([0.9271], device='cuda:0'), Now : mean acc: tensor([0.9201], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9200584888458252, 'Val/mean miou_metric': 0.8757304549217224, 'Val/mean f1': 0.9321563243865967, 'Val/mean precision': 0.9405845403671265, 'Val/mean recall': 0.9238777160644531, 'Val/mean hd95_metric': 19.235631942749023}
Epoch [206/300] Training [1/62] Loss: 0.03665 
Epoch [206/300] Training [2/62] Loss: 0.03592 
Epoch [206/300] Training [3/62] Loss: 0.03888 
Epoch [206/300] Training [4/62] Loss: 0.08008 
Epoch [206/300] Training [5/62] Loss: 0.04700 
Epoch [206/300] Training [6/62] Loss: 0.04027 
Epoch [206/300] Training [7/62] Loss: 0.07805 
Epoch [206/300] Training [8/62] Loss: 0.03866 
Epoch [206/300] Training [9/62] Loss: 0.09192 
Epoch [206/300] Training [10/62] Loss: 0.05362 
Epoch [206/300] Training [11/62] Loss: 0.05691 
Epoch [206/300] Training [12/62] Loss: 0.04190 
Epoch [206/300] Training [13/62] Loss: 0.09454 
Epoch [206/300] Training [14/62] Loss: 0.13190 
Epoch [206/300] Training [15/62] Loss: 0.03998 
Epoch [206/300] Training [16/62] Loss: 0.04647 
Epoch [206/300] Training [17/62] Loss: 0.02929 
Epoch [206/300] Training [18/62] Loss: 0.02980 
Epoch [206/300] Training [19/62] Loss: 0.05435 
Epoch [206/300] Training [20/62] Loss: 0.08015 
Epoch [206/300] Training [21/62] Loss: 0.04324 
Epoch [206/300] Training [22/62] Loss: 0.05329 
Epoch [206/300] Training [23/62] Loss: 0.06751 
Epoch [206/300] Training [24/62] Loss: 0.06778 
Epoch [206/300] Training [25/62] Loss: 0.03984 
Epoch [206/300] Training [26/62] Loss: 0.03437 
Epoch [206/300] Training [27/62] Loss: 0.03969 
Epoch [206/300] Training [28/62] Loss: 0.05452 
Epoch [206/300] Training [29/62] Loss: 0.06931 
Epoch [206/300] Training [30/62] Loss: 0.08031 
Epoch [206/300] Training [31/62] Loss: 0.03548 
Epoch [206/300] Training [32/62] Loss: 0.18161 
Epoch [206/300] Training [33/62] Loss: 0.04551 
Epoch [206/300] Training [34/62] Loss: 0.03605 
Epoch [206/300] Training [35/62] Loss: 0.05226 
Epoch [206/300] Training [36/62] Loss: 0.05215 
Epoch [206/300] Training [37/62] Loss: 0.04717 
Epoch [206/300] Training [38/62] Loss: 0.06428 
Epoch [206/300] Training [39/62] Loss: 0.05329 
Epoch [206/300] Training [40/62] Loss: 0.07563 
Epoch [206/300] Training [41/62] Loss: 0.19257 
Epoch [206/300] Training [42/62] Loss: 0.04881 
Epoch [206/300] Training [43/62] Loss: 0.05916 
Epoch [206/300] Training [44/62] Loss: 0.03182 
Epoch [206/300] Training [45/62] Loss: 0.04029 
Epoch [206/300] Training [46/62] Loss: 0.05112 
Epoch [206/300] Training [47/62] Loss: 0.04286 
Epoch [206/300] Training [48/62] Loss: 0.04763 
Epoch [206/300] Training [49/62] Loss: 0.05264 
Epoch [206/300] Training [50/62] Loss: 0.04404 
Epoch [206/300] Training [51/62] Loss: 0.07038 
Epoch [206/300] Training [52/62] Loss: 0.05171 
Epoch [206/300] Training [53/62] Loss: 0.05666 
Epoch [206/300] Training [54/62] Loss: 0.03757 
Epoch [206/300] Training [55/62] Loss: 0.03610 
Epoch [206/300] Training [56/62] Loss: 0.03463 
Epoch [206/300] Training [57/62] Loss: 0.04968 
Epoch [206/300] Training [58/62] Loss: 0.07148 
Epoch [206/300] Training [59/62] Loss: 0.10829 
Epoch [206/300] Training [60/62] Loss: 0.05022 
Epoch [206/300] Training [61/62] Loss: 0.06801 
Epoch [206/300] Training [62/62] Loss: 0.04716 
Epoch [206/300] Training metric {'Train/mean dice_metric': 0.9594095945358276, 'Train/mean miou_metric': 0.9279776215553284, 'Train/mean f1': 0.9654617309570312, 'Train/mean precision': 0.9625230431556702, 'Train/mean recall': 0.9684185981750488, 'Train/mean hd95_metric': 9.386838912963867}
Epoch [206/300] Validation [1/16] Loss: 0.57112  focal_loss 0.37671  dice_loss 0.19441 
Epoch [206/300] Validation [2/16] Loss: 0.51193  focal_loss 0.20432  dice_loss 0.30761 
Epoch [206/300] Validation [3/16] Loss: 0.63211  focal_loss 0.34329  dice_loss 0.28882 
Epoch [206/300] Validation [4/16] Loss: 0.31199  focal_loss 0.15593  dice_loss 0.15605 
Epoch [206/300] Validation [5/16] Loss: 0.34799  focal_loss 0.12789  dice_loss 0.22010 
Epoch [206/300] Validation [6/16] Loss: 0.28517  focal_loss 0.08509  dice_loss 0.20008 
Epoch [206/300] Validation [7/16] Loss: 0.26416  focal_loss 0.08942  dice_loss 0.17474 
Epoch [206/300] Validation [8/16] Loss: 0.42650  focal_loss 0.14975  dice_loss 0.27675 
Epoch [206/300] Validation [9/16] Loss: 0.20902  focal_loss 0.09484  dice_loss 0.11418 
Epoch [206/300] Validation [10/16] Loss: 0.56584  focal_loss 0.19814  dice_loss 0.36769 
Epoch [206/300] Validation [11/16] Loss: 0.14526  focal_loss 0.05176  dice_loss 0.09350 
Epoch [206/300] Validation [12/16] Loss: 0.40795  focal_loss 0.11854  dice_loss 0.28940 
Epoch [206/300] Validation [13/16] Loss: 0.23055  focal_loss 0.08415  dice_loss 0.14639 
Epoch [206/300] Validation [14/16] Loss: 0.51514  focal_loss 0.21067  dice_loss 0.30447 
Epoch [206/300] Validation [15/16] Loss: 0.12872  focal_loss 0.04608  dice_loss 0.08264 
Epoch [206/300] Validation [16/16] Loss: 0.13047  focal_loss 0.03693  dice_loss 0.09354 
Epoch [206/300] Validation metric {'Val/mean dice_metric': 0.9260112047195435, 'Val/mean miou_metric': 0.8834797143936157, 'Val/mean f1': 0.9393925666809082, 'Val/mean precision': 0.9453848600387573, 'Val/mean recall': 0.9334757328033447, 'Val/mean hd95_metric': 18.504186630249023}
Cheakpoint...
Epoch [206/300] best acc:tensor([0.9271], device='cuda:0'), Now : mean acc: tensor([0.9260], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9260112047195435, 'Val/mean miou_metric': 0.8834797143936157, 'Val/mean f1': 0.9393925666809082, 'Val/mean precision': 0.9453848600387573, 'Val/mean recall': 0.9334757328033447, 'Val/mean hd95_metric': 18.504186630249023}
Epoch [207/300] Training [1/62] Loss: 0.05364 
Epoch [207/300] Training [2/62] Loss: 0.03715 
Epoch [207/300] Training [3/62] Loss: 0.04213 
Epoch [207/300] Training [4/62] Loss: 0.02779 
Epoch [207/300] Training [5/62] Loss: 0.03816 
Epoch [207/300] Training [6/62] Loss: 0.15382 
Epoch [207/300] Training [7/62] Loss: 0.04406 
Epoch [207/300] Training [8/62] Loss: 0.11654 
Epoch [207/300] Training [9/62] Loss: 0.04940 
Epoch [207/300] Training [10/62] Loss: 0.04564 
Epoch [207/300] Training [11/62] Loss: 0.07477 
Epoch [207/300] Training [12/62] Loss: 0.04000 
Epoch [207/300] Training [13/62] Loss: 0.05178 
Epoch [207/300] Training [14/62] Loss: 0.10331 
Epoch [207/300] Training [15/62] Loss: 0.03308 
Epoch [207/300] Training [16/62] Loss: 0.12894 
Epoch [207/300] Training [17/62] Loss: 0.06621 
Epoch [207/300] Training [18/62] Loss: 0.03852 
Epoch [207/300] Training [19/62] Loss: 0.04165 
Epoch [207/300] Training [20/62] Loss: 0.04931 
Epoch [207/300] Training [21/62] Loss: 0.05683 
Epoch [207/300] Training [22/62] Loss: 0.05563 
Epoch [207/300] Training [23/62] Loss: 0.06067 
Epoch [207/300] Training [24/62] Loss: 0.03961 
Epoch [207/300] Training [25/62] Loss: 0.05277 
Epoch [207/300] Training [26/62] Loss: 0.03797 
Epoch [207/300] Training [27/62] Loss: 0.08369 
Epoch [207/300] Training [28/62] Loss: 0.04581 
Epoch [207/300] Training [29/62] Loss: 0.03621 
Epoch [207/300] Training [30/62] Loss: 0.04140 
Epoch [207/300] Training [31/62] Loss: 0.04964 
Epoch [207/300] Training [32/62] Loss: 0.03898 
Epoch [207/300] Training [33/62] Loss: 0.03741 
Epoch [207/300] Training [34/62] Loss: 0.04290 
Epoch [207/300] Training [35/62] Loss: 0.16939 
Epoch [207/300] Training [36/62] Loss: 0.04442 
Epoch [207/300] Training [37/62] Loss: 0.12049 
Epoch [207/300] Training [38/62] Loss: 0.02809 
Epoch [207/300] Training [39/62] Loss: 0.03468 
Epoch [207/300] Training [40/62] Loss: 0.18264 
Epoch [207/300] Training [41/62] Loss: 0.04329 
Epoch [207/300] Training [42/62] Loss: 0.15772 
Epoch [207/300] Training [43/62] Loss: 0.03384 
Epoch [207/300] Training [44/62] Loss: 0.10831 
Epoch [207/300] Training [45/62] Loss: 0.03683 
Epoch [207/300] Training [46/62] Loss: 0.04370 
Epoch [207/300] Training [47/62] Loss: 0.14481 
Epoch [207/300] Training [48/62] Loss: 0.04321 
Epoch [207/300] Training [49/62] Loss: 0.06411 
Epoch [207/300] Training [50/62] Loss: 0.04512 
Epoch [207/300] Training [51/62] Loss: 0.04476 
Epoch [207/300] Training [52/62] Loss: 0.06194 
Epoch [207/300] Training [53/62] Loss: 0.08228 
Epoch [207/300] Training [54/62] Loss: 0.03806 
Epoch [207/300] Training [55/62] Loss: 0.07483 
Epoch [207/300] Training [56/62] Loss: 0.05281 
Epoch [207/300] Training [57/62] Loss: 0.07955 
Epoch [207/300] Training [58/62] Loss: 0.10798 
Epoch [207/300] Training [59/62] Loss: 0.03111 
Epoch [207/300] Training [60/62] Loss: 0.03483 
Epoch [207/300] Training [61/62] Loss: 0.05231 
Epoch [207/300] Training [62/62] Loss: 0.14028 
Epoch [207/300] Training metric {'Train/mean dice_metric': 0.9550395607948303, 'Train/mean miou_metric': 0.9221824407577515, 'Train/mean f1': 0.9636697173118591, 'Train/mean precision': 0.9613617658615112, 'Train/mean recall': 0.96598881483078, 'Train/mean hd95_metric': 8.840007781982422}
Epoch [207/300] Validation [1/16] Loss: 0.69539  focal_loss 0.46469  dice_loss 0.23070 
Epoch [207/300] Validation [2/16] Loss: 0.46026  focal_loss 0.19112  dice_loss 0.26914 
Epoch [207/300] Validation [3/16] Loss: 0.67117  focal_loss 0.38521  dice_loss 0.28596 
Epoch [207/300] Validation [4/16] Loss: 0.34913  focal_loss 0.16019  dice_loss 0.18895 
Epoch [207/300] Validation [5/16] Loss: 0.37605  focal_loss 0.13491  dice_loss 0.24114 
Epoch [207/300] Validation [6/16] Loss: 0.35613  focal_loss 0.11126  dice_loss 0.24487 
Epoch [207/300] Validation [7/16] Loss: 0.24440  focal_loss 0.10276  dice_loss 0.14164 
Epoch [207/300] Validation [8/16] Loss: 0.52094  focal_loss 0.20102  dice_loss 0.31992 
Epoch [207/300] Validation [9/16] Loss: 0.20495  focal_loss 0.08584  dice_loss 0.11911 
Epoch [207/300] Validation [10/16] Loss: 0.45543  focal_loss 0.13238  dice_loss 0.32305 
Epoch [207/300] Validation [11/16] Loss: 0.13542  focal_loss 0.04594  dice_loss 0.08948 
Epoch [207/300] Validation [12/16] Loss: 0.39235  focal_loss 0.12506  dice_loss 0.26730 
Epoch [207/300] Validation [13/16] Loss: 0.38300  focal_loss 0.16280  dice_loss 0.22020 
Epoch [207/300] Validation [14/16] Loss: 0.60241  focal_loss 0.25819  dice_loss 0.34422 
Epoch [207/300] Validation [15/16] Loss: 0.18590  focal_loss 0.07145  dice_loss 0.11445 
Epoch [207/300] Validation [16/16] Loss: 0.16855  focal_loss 0.06017  dice_loss 0.10837 
Epoch [207/300] Validation metric {'Val/mean dice_metric': 0.9202603697776794, 'Val/mean miou_metric': 0.8756193518638611, 'Val/mean f1': 0.9348370432853699, 'Val/mean precision': 0.9477331638336182, 'Val/mean recall': 0.922287106513977, 'Val/mean hd95_metric': 17.90084457397461}
Cheakpoint...
Epoch [207/300] best acc:tensor([0.9271], device='cuda:0'), Now : mean acc: tensor([0.9203], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9202603697776794, 'Val/mean miou_metric': 0.8756193518638611, 'Val/mean f1': 0.9348370432853699, 'Val/mean precision': 0.9477331638336182, 'Val/mean recall': 0.922287106513977, 'Val/mean hd95_metric': 17.90084457397461}
Epoch [208/300] Training [1/62] Loss: 0.03570 
Epoch [208/300] Training [2/62] Loss: 0.06442 
Epoch [208/300] Training [3/62] Loss: 0.03903 
Epoch [208/300] Training [4/62] Loss: 0.05751 
Epoch [208/300] Training [5/62] Loss: 0.04125 
Epoch [208/300] Training [6/62] Loss: 0.04809 
Epoch [208/300] Training [7/62] Loss: 0.06180 
Epoch [208/300] Training [8/62] Loss: 0.03436 
Epoch [208/300] Training [9/62] Loss: 0.09050 
Epoch [208/300] Training [10/62] Loss: 0.04463 
Epoch [208/300] Training [11/62] Loss: 0.03645 
Epoch [208/300] Training [12/62] Loss: 0.09545 
Epoch [208/300] Training [13/62] Loss: 0.06947 
Epoch [208/300] Training [14/62] Loss: 0.03334 
Epoch [208/300] Training [15/62] Loss: 0.04529 
Epoch [208/300] Training [16/62] Loss: 0.03989 
Epoch [208/300] Training [17/62] Loss: 0.05610 
Epoch [208/300] Training [18/62] Loss: 0.09329 
Epoch [208/300] Training [19/62] Loss: 0.06614 
Epoch [208/300] Training [20/62] Loss: 0.03828 
Epoch [208/300] Training [21/62] Loss: 0.03804 
Epoch [208/300] Training [22/62] Loss: 0.05278 
Epoch [208/300] Training [23/62] Loss: 0.05464 
Epoch [208/300] Training [24/62] Loss: 0.03807 
Epoch [208/300] Training [25/62] Loss: 0.06676 
Epoch [208/300] Training [26/62] Loss: 0.05264 
Epoch [208/300] Training [27/62] Loss: 0.07133 
Epoch [208/300] Training [28/62] Loss: 0.05020 
Epoch [208/300] Training [29/62] Loss: 0.03245 
Epoch [208/300] Training [30/62] Loss: 0.05235 
Epoch [208/300] Training [31/62] Loss: 0.03818 
Epoch [208/300] Training [32/62] Loss: 0.03469 
Epoch [208/300] Training [33/62] Loss: 0.07124 
Epoch [208/300] Training [34/62] Loss: 0.05630 
Epoch [208/300] Training [35/62] Loss: 0.08723 
Epoch [208/300] Training [36/62] Loss: 0.05857 
Epoch [208/300] Training [37/62] Loss: 0.09650 
Epoch [208/300] Training [38/62] Loss: 0.03677 
Epoch [208/300] Training [39/62] Loss: 0.04695 
Epoch [208/300] Training [40/62] Loss: 0.04712 
Epoch [208/300] Training [41/62] Loss: 0.04138 
Epoch [208/300] Training [42/62] Loss: 0.06895 
Epoch [208/300] Training [43/62] Loss: 0.03376 
Epoch [208/300] Training [44/62] Loss: 0.12728 
Epoch [208/300] Training [45/62] Loss: 0.05107 
Epoch [208/300] Training [46/62] Loss: 0.05102 
Epoch [208/300] Training [47/62] Loss: 0.04024 
Epoch [208/300] Training [48/62] Loss: 0.03763 
Epoch [208/300] Training [49/62] Loss: 0.03592 
Epoch [208/300] Training [50/62] Loss: 0.13354 
Epoch [208/300] Training [51/62] Loss: 0.03976 
Epoch [208/300] Training [52/62] Loss: 0.03834 
Epoch [208/300] Training [53/62] Loss: 0.10928 
Epoch [208/300] Training [54/62] Loss: 0.05885 
Epoch [208/300] Training [55/62] Loss: 0.07433 
Epoch [208/300] Training [56/62] Loss: 0.05078 
Epoch [208/300] Training [57/62] Loss: 0.04518 
Epoch [208/300] Training [58/62] Loss: 0.05388 
Epoch [208/300] Training [59/62] Loss: 0.04782 
Epoch [208/300] Training [60/62] Loss: 0.04804 
Epoch [208/300] Training [61/62] Loss: 0.04806 
Epoch [208/300] Training [62/62] Loss: 0.10728 
Epoch [208/300] Training metric {'Train/mean dice_metric': 0.9625931978225708, 'Train/mean miou_metric': 0.9310795664787292, 'Train/mean f1': 0.9646185040473938, 'Train/mean precision': 0.9611552357673645, 'Train/mean recall': 0.9681068658828735, 'Train/mean hd95_metric': 9.040992736816406}
Epoch [208/300] Validation [1/16] Loss: 0.74534  focal_loss 0.50305  dice_loss 0.24229 
Epoch [208/300] Validation [2/16] Loss: 0.54068  focal_loss 0.23588  dice_loss 0.30480 
Epoch [208/300] Validation [3/16] Loss: 0.73289  focal_loss 0.42385  dice_loss 0.30904 
Epoch [208/300] Validation [4/16] Loss: 0.36561  focal_loss 0.17450  dice_loss 0.19112 
Epoch [208/300] Validation [5/16] Loss: 0.35020  focal_loss 0.14422  dice_loss 0.20597 
Epoch [208/300] Validation [6/16] Loss: 0.31165  focal_loss 0.09988  dice_loss 0.21177 
Epoch [208/300] Validation [7/16] Loss: 0.32487  focal_loss 0.13942  dice_loss 0.18545 
Epoch [208/300] Validation [8/16] Loss: 0.42233  focal_loss 0.17892  dice_loss 0.24341 
Epoch [208/300] Validation [9/16] Loss: 0.34429  focal_loss 0.16398  dice_loss 0.18031 
Epoch [208/300] Validation [10/16] Loss: 0.59474  focal_loss 0.20502  dice_loss 0.38972 
Epoch [208/300] Validation [11/16] Loss: 0.16337  focal_loss 0.05243  dice_loss 0.11094 
Epoch [208/300] Validation [12/16] Loss: 0.36528  focal_loss 0.09953  dice_loss 0.26575 
Epoch [208/300] Validation [13/16] Loss: 0.25385  focal_loss 0.08740  dice_loss 0.16645 
Epoch [208/300] Validation [14/16] Loss: 0.51891  focal_loss 0.21908  dice_loss 0.29984 
Epoch [208/300] Validation [15/16] Loss: 0.21327  focal_loss 0.09643  dice_loss 0.11684 
Epoch [208/300] Validation [16/16] Loss: 0.09413  focal_loss 0.02651  dice_loss 0.06763 
Epoch [208/300] Validation metric {'Val/mean dice_metric': 0.9262287616729736, 'Val/mean miou_metric': 0.882664680480957, 'Val/mean f1': 0.9348545074462891, 'Val/mean precision': 0.9464856386184692, 'Val/mean recall': 0.9235056638717651, 'Val/mean hd95_metric': 17.588834762573242}
Cheakpoint...
Epoch [208/300] best acc:tensor([0.9271], device='cuda:0'), Now : mean acc: tensor([0.9262], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9262287616729736, 'Val/mean miou_metric': 0.882664680480957, 'Val/mean f1': 0.9348545074462891, 'Val/mean precision': 0.9464856386184692, 'Val/mean recall': 0.9235056638717651, 'Val/mean hd95_metric': 17.588834762573242}
Epoch [209/300] Training [1/62] Loss: 0.04682 
Epoch [209/300] Training [2/62] Loss: 0.03167 
Epoch [209/300] Training [3/62] Loss: 0.04521 
Epoch [209/300] Training [4/62] Loss: 0.03516 
Epoch [209/300] Training [5/62] Loss: 0.05450 
Epoch [209/300] Training [6/62] Loss: 0.03201 
Epoch [209/300] Training [7/62] Loss: 0.16887 
Epoch [209/300] Training [8/62] Loss: 0.04393 
Epoch [209/300] Training [9/62] Loss: 0.12541 
Epoch [209/300] Training [10/62] Loss: 0.07761 
Epoch [209/300] Training [11/62] Loss: 0.05390 
Epoch [209/300] Training [12/62] Loss: 0.05907 
Epoch [209/300] Training [13/62] Loss: 0.03383 
Epoch [209/300] Training [14/62] Loss: 0.04423 
Epoch [209/300] Training [15/62] Loss: 0.04735 
Epoch [209/300] Training [16/62] Loss: 0.03295 
Epoch [209/300] Training [17/62] Loss: 0.05848 
Epoch [209/300] Training [18/62] Loss: 0.06066 
Epoch [209/300] Training [19/62] Loss: 0.05370 
Epoch [209/300] Training [20/62] Loss: 0.03168 
Epoch [209/300] Training [21/62] Loss: 0.10300 
Epoch [209/300] Training [22/62] Loss: 0.02955 
Epoch [209/300] Training [23/62] Loss: 0.06223 
Epoch [209/300] Training [24/62] Loss: 0.05028 
Epoch [209/300] Training [25/62] Loss: 0.04169 
Epoch [209/300] Training [26/62] Loss: 0.09785 
Epoch [209/300] Training [27/62] Loss: 0.06521 
Epoch [209/300] Training [28/62] Loss: 0.03759 
Epoch [209/300] Training [29/62] Loss: 0.04341 
Epoch [209/300] Training [30/62] Loss: 0.04262 
Epoch [209/300] Training [31/62] Loss: 0.03952 
Epoch [209/300] Training [32/62] Loss: 0.03659 
Epoch [209/300] Training [33/62] Loss: 0.05209 
Epoch [209/300] Training [34/62] Loss: 0.03876 
Epoch [209/300] Training [35/62] Loss: 0.06114 
Epoch [209/300] Training [36/62] Loss: 0.04224 
Epoch [209/300] Training [37/62] Loss: 0.04582 
Epoch [209/300] Training [38/62] Loss: 0.04055 
Epoch [209/300] Training [39/62] Loss: 0.03080 
Epoch [209/300] Training [40/62] Loss: 0.09466 
Epoch [209/300] Training [41/62] Loss: 0.08434 
Epoch [209/300] Training [42/62] Loss: 0.03307 
Epoch [209/300] Training [43/62] Loss: 0.03970 
Epoch [209/300] Training [44/62] Loss: 0.03816 
Epoch [209/300] Training [45/62] Loss: 0.05310 
Epoch [209/300] Training [46/62] Loss: 0.04357 
Epoch [209/300] Training [47/62] Loss: 0.12353 
Epoch [209/300] Training [48/62] Loss: 0.02997 
Epoch [209/300] Training [49/62] Loss: 0.06081 
Epoch [209/300] Training [50/62] Loss: 0.03870 
Epoch [209/300] Training [51/62] Loss: 0.03358 
Epoch [209/300] Training [52/62] Loss: 0.04379 
Epoch [209/300] Training [53/62] Loss: 0.04269 
Epoch [209/300] Training [54/62] Loss: 0.19328 
Epoch [209/300] Training [55/62] Loss: 0.07007 
Epoch [209/300] Training [56/62] Loss: 0.07370 
Epoch [209/300] Training [57/62] Loss: 0.05647 
Epoch [209/300] Training [58/62] Loss: 0.03993 
Epoch [209/300] Training [59/62] Loss: 0.03981 
Epoch [209/300] Training [60/62] Loss: 0.04240 
Epoch [209/300] Training [61/62] Loss: 0.03900 
Epoch [209/300] Training [62/62] Loss: 0.04277 
Epoch [209/300] Training metric {'Train/mean dice_metric': 0.9621829986572266, 'Train/mean miou_metric': 0.9330202341079712, 'Train/mean f1': 0.9662023782730103, 'Train/mean precision': 0.9642553925514221, 'Train/mean recall': 0.9681573510169983, 'Train/mean hd95_metric': 8.434310913085938}
Epoch [209/300] Validation [1/16] Loss: 0.70953  focal_loss 0.48376  dice_loss 0.22577 
Epoch [209/300] Validation [2/16] Loss: 0.50829  focal_loss 0.19387  dice_loss 0.31442 
Epoch [209/300] Validation [3/16] Loss: 0.55132  focal_loss 0.29889  dice_loss 0.25242 
Epoch [209/300] Validation [4/16] Loss: 0.35961  focal_loss 0.18273  dice_loss 0.17688 
Epoch [209/300] Validation [5/16] Loss: 0.32765  focal_loss 0.11372  dice_loss 0.21393 
Epoch [209/300] Validation [6/16] Loss: 0.29153  focal_loss 0.09331  dice_loss 0.19822 
Epoch [209/300] Validation [7/16] Loss: 0.21079  focal_loss 0.08094  dice_loss 0.12985 
Epoch [209/300] Validation [8/16] Loss: 0.48186  focal_loss 0.20370  dice_loss 0.27816 
Epoch [209/300] Validation [9/16] Loss: 0.20838  focal_loss 0.08386  dice_loss 0.12453 
Epoch [209/300] Validation [10/16] Loss: 0.46125  focal_loss 0.13505  dice_loss 0.32620 
Epoch [209/300] Validation [11/16] Loss: 0.16069  focal_loss 0.05744  dice_loss 0.10325 
Epoch [209/300] Validation [12/16] Loss: 0.35873  focal_loss 0.09974  dice_loss 0.25899 
Epoch [209/300] Validation [13/16] Loss: 0.29940  focal_loss 0.11553  dice_loss 0.18387 
Epoch [209/300] Validation [14/16] Loss: 0.63455  focal_loss 0.30022  dice_loss 0.33432 
Epoch [209/300] Validation [15/16] Loss: 0.17189  focal_loss 0.07064  dice_loss 0.10125 
Epoch [209/300] Validation [16/16] Loss: 0.11453  focal_loss 0.04125  dice_loss 0.07328 
Epoch [209/300] Validation metric {'Val/mean dice_metric': 0.928067147731781, 'Val/mean miou_metric': 0.8866482377052307, 'Val/mean f1': 0.9376015067100525, 'Val/mean precision': 0.9463097453117371, 'Val/mean recall': 0.9290521144866943, 'Val/mean hd95_metric': 16.457494735717773}
Cheakpoint...
Epoch [209/300] best acc:tensor([0.9281], device='cuda:0'), Now : mean acc: tensor([0.9281], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.928067147731781, 'Val/mean miou_metric': 0.8866482377052307, 'Val/mean f1': 0.9376015067100525, 'Val/mean precision': 0.9463097453117371, 'Val/mean recall': 0.9290521144866943, 'Val/mean hd95_metric': 16.457494735717773}
Epoch [210/300] Training [1/62] Loss: 0.02703 
Epoch [210/300] Training [2/62] Loss: 0.06594 
Epoch [210/300] Training [3/62] Loss: 0.04505 
Epoch [210/300] Training [4/62] Loss: 0.09479 
Epoch [210/300] Training [5/62] Loss: 0.04475 
Epoch [210/300] Training [6/62] Loss: 0.02975 
Epoch [210/300] Training [7/62] Loss: 0.04144 
Epoch [210/300] Training [8/62] Loss: 0.05074 
Epoch [210/300] Training [9/62] Loss: 0.05758 
Epoch [210/300] Training [10/62] Loss: 0.02963 
Epoch [210/300] Training [11/62] Loss: 0.03029 
Epoch [210/300] Training [12/62] Loss: 0.03767 
Epoch [210/300] Training [13/62] Loss: 0.07076 
Epoch [210/300] Training [14/62] Loss: 0.13017 
Epoch [210/300] Training [15/62] Loss: 0.03757 
Epoch [210/300] Training [16/62] Loss: 0.06060 
Epoch [210/300] Training [17/62] Loss: 0.03508 
Epoch [210/300] Training [18/62] Loss: 0.03987 
Epoch [210/300] Training [19/62] Loss: 0.05236 
Epoch [210/300] Training [20/62] Loss: 0.07561 
Epoch [210/300] Training [21/62] Loss: 0.07133 
Epoch [210/300] Training [22/62] Loss: 0.10471 
Epoch [210/300] Training [23/62] Loss: 0.03466 
Epoch [210/300] Training [24/62] Loss: 0.07281 
Epoch [210/300] Training [25/62] Loss: 0.04244 
Epoch [210/300] Training [26/62] Loss: 0.07027 
Epoch [210/300] Training [27/62] Loss: 0.05986 
Epoch [210/300] Training [28/62] Loss: 0.04302 
Epoch [210/300] Training [29/62] Loss: 0.03383 
Epoch [210/300] Training [30/62] Loss: 0.04205 
Epoch [210/300] Training [31/62] Loss: 0.09821 
Epoch [210/300] Training [32/62] Loss: 0.07377 
Epoch [210/300] Training [33/62] Loss: 0.04662 
Epoch [210/300] Training [34/62] Loss: 0.02958 
Epoch [210/300] Training [35/62] Loss: 0.03674 
Epoch [210/300] Training [36/62] Loss: 0.03809 
Epoch [210/300] Training [37/62] Loss: 0.05657 
Epoch [210/300] Training [38/62] Loss: 0.05908 
Epoch [210/300] Training [39/62] Loss: 0.06153 
Epoch [210/300] Training [40/62] Loss: 0.06858 
Epoch [210/300] Training [41/62] Loss: 0.09042 
Epoch [210/300] Training [42/62] Loss: 0.05803 
Epoch [210/300] Training [43/62] Loss: 0.05497 
Epoch [210/300] Training [44/62] Loss: 0.05465 
Epoch [210/300] Training [45/62] Loss: 0.03131 
Epoch [210/300] Training [46/62] Loss: 0.05619 
Epoch [210/300] Training [47/62] Loss: 0.03043 
Epoch [210/300] Training [48/62] Loss: 0.05072 
Epoch [210/300] Training [49/62] Loss: 0.03262 
Epoch [210/300] Training [50/62] Loss: 0.03389 
Epoch [210/300] Training [51/62] Loss: 0.05109 
Epoch [210/300] Training [52/62] Loss: 0.11084 
Epoch [210/300] Training [53/62] Loss: 0.05350 
Epoch [210/300] Training [54/62] Loss: 0.06180 
Epoch [210/300] Training [55/62] Loss: 0.04722 
Epoch [210/300] Training [56/62] Loss: 0.03063 
Epoch [210/300] Training [57/62] Loss: 0.06458 
Epoch [210/300] Training [58/62] Loss: 0.04477 
Epoch [210/300] Training [59/62] Loss: 0.03601 
Epoch [210/300] Training [60/62] Loss: 0.04635 
Epoch [210/300] Training [61/62] Loss: 0.04689 
Epoch [210/300] Training [62/62] Loss: 0.03195 
Epoch [210/300] Training metric {'Train/mean dice_metric': 0.9628987312316895, 'Train/mean miou_metric': 0.9317631721496582, 'Train/mean f1': 0.9672713875770569, 'Train/mean precision': 0.9631554484367371, 'Train/mean recall': 0.9714226126670837, 'Train/mean hd95_metric': 8.317127227783203}
Epoch [210/300] Validation [1/16] Loss: 0.59718  focal_loss 0.40524  dice_loss 0.19194 
Epoch [210/300] Validation [2/16] Loss: 0.45609  focal_loss 0.19163  dice_loss 0.26446 
Epoch [210/300] Validation [3/16] Loss: 0.68531  focal_loss 0.38316  dice_loss 0.30215 
Epoch [210/300] Validation [4/16] Loss: 0.28964  focal_loss 0.14445  dice_loss 0.14519 
Epoch [210/300] Validation [5/16] Loss: 0.39534  focal_loss 0.14409  dice_loss 0.25125 
Epoch [210/300] Validation [6/16] Loss: 0.25992  focal_loss 0.07899  dice_loss 0.18093 
Epoch [210/300] Validation [7/16] Loss: 0.19163  focal_loss 0.07707  dice_loss 0.11456 
Epoch [210/300] Validation [8/16] Loss: 0.49697  focal_loss 0.18322  dice_loss 0.31375 
Epoch [210/300] Validation [9/16] Loss: 0.20630  focal_loss 0.08745  dice_loss 0.11885 
Epoch [210/300] Validation [10/16] Loss: 0.44379  focal_loss 0.15281  dice_loss 0.29098 
Epoch [210/300] Validation [11/16] Loss: 0.12251  focal_loss 0.03945  dice_loss 0.08305 
Epoch [210/300] Validation [12/16] Loss: 0.42264  focal_loss 0.10936  dice_loss 0.31328 
Epoch [210/300] Validation [13/16] Loss: 0.23153  focal_loss 0.07473  dice_loss 0.15681 
Epoch [210/300] Validation [14/16] Loss: 0.46660  focal_loss 0.18192  dice_loss 0.28469 
Epoch [210/300] Validation [15/16] Loss: 0.10374  focal_loss 0.03405  dice_loss 0.06969 
Epoch [210/300] Validation [16/16] Loss: 0.08145  focal_loss 0.02161  dice_loss 0.05984 
Epoch [210/300] Validation metric {'Val/mean dice_metric': 0.9307510256767273, 'Val/mean miou_metric': 0.8893857598304749, 'Val/mean f1': 0.9418779015541077, 'Val/mean precision': 0.9453265070915222, 'Val/mean recall': 0.9384543299674988, 'Val/mean hd95_metric': 17.277677536010742}
Cheakpoint...
Epoch [210/300] best acc:tensor([0.9308], device='cuda:0'), Now : mean acc: tensor([0.9308], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9307510256767273, 'Val/mean miou_metric': 0.8893857598304749, 'Val/mean f1': 0.9418779015541077, 'Val/mean precision': 0.9453265070915222, 'Val/mean recall': 0.9384543299674988, 'Val/mean hd95_metric': 17.277677536010742}
Epoch [211/300] Training [1/62] Loss: 0.05138 
Epoch [211/300] Training [2/62] Loss: 0.05327 
Epoch [211/300] Training [3/62] Loss: 0.11443 
Epoch [211/300] Training [4/62] Loss: 0.04674 
Epoch [211/300] Training [5/62] Loss: 0.07502 
Epoch [211/300] Training [6/62] Loss: 0.04107 
Epoch [211/300] Training [7/62] Loss: 0.03894 
Epoch [211/300] Training [8/62] Loss: 0.02902 
Epoch [211/300] Training [9/62] Loss: 0.05071 
Epoch [211/300] Training [10/62] Loss: 0.12946 
Epoch [211/300] Training [11/62] Loss: 0.10623 
Epoch [211/300] Training [12/62] Loss: 0.02715 
Epoch [211/300] Training [13/62] Loss: 0.13767 
Epoch [211/300] Training [14/62] Loss: 0.04589 
Epoch [211/300] Training [15/62] Loss: 0.04226 
Epoch [211/300] Training [16/62] Loss: 0.04206 
Epoch [211/300] Training [17/62] Loss: 0.04929 
Epoch [211/300] Training [18/62] Loss: 0.02482 
Epoch [211/300] Training [19/62] Loss: 0.03110 
Epoch [211/300] Training [20/62] Loss: 0.03674 
Epoch [211/300] Training [21/62] Loss: 0.17671 
Epoch [211/300] Training [22/62] Loss: 0.04038 
Epoch [211/300] Training [23/62] Loss: 0.02823 
Epoch [211/300] Training [24/62] Loss: 0.03799 
Epoch [211/300] Training [25/62] Loss: 0.05380 
Epoch [211/300] Training [26/62] Loss: 0.04214 
Epoch [211/300] Training [27/62] Loss: 0.03760 
Epoch [211/300] Training [28/62] Loss: 0.05776 
Epoch [211/300] Training [29/62] Loss: 0.03866 
Epoch [211/300] Training [30/62] Loss: 0.04637 
Epoch [211/300] Training [31/62] Loss: 0.04350 
Epoch [211/300] Training [32/62] Loss: 0.04123 
Epoch [211/300] Training [33/62] Loss: 0.04806 
Epoch [211/300] Training [34/62] Loss: 0.15940 
Epoch [211/300] Training [35/62] Loss: 0.04452 
Epoch [211/300] Training [36/62] Loss: 0.16602 
Epoch [211/300] Training [37/62] Loss: 0.05209 
Epoch [211/300] Training [38/62] Loss: 0.12116 
Epoch [211/300] Training [39/62] Loss: 0.04561 
Epoch [211/300] Training [40/62] Loss: 0.04088 
Epoch [211/300] Training [41/62] Loss: 0.20804 
Epoch [211/300] Training [42/62] Loss: 0.04508 
Epoch [211/300] Training [43/62] Loss: 0.03982 
Epoch [211/300] Training [44/62] Loss: 0.05605 
Epoch [211/300] Training [45/62] Loss: 0.09295 
Epoch [211/300] Training [46/62] Loss: 0.05221 
Epoch [211/300] Training [47/62] Loss: 0.12996 
Epoch [211/300] Training [48/62] Loss: 0.05119 
Epoch [211/300] Training [49/62] Loss: 0.04393 
Epoch [211/300] Training [50/62] Loss: 0.07568 
Epoch [211/300] Training [51/62] Loss: 0.04415 
Epoch [211/300] Training [52/62] Loss: 0.07376 
Epoch [211/300] Training [53/62] Loss: 0.02953 
Epoch [211/300] Training [54/62] Loss: 0.03142 
Epoch [211/300] Training [55/62] Loss: 0.05230 
Epoch [211/300] Training [56/62] Loss: 0.04524 
Epoch [211/300] Training [57/62] Loss: 0.03417 
Epoch [211/300] Training [58/62] Loss: 0.03638 
Epoch [211/300] Training [59/62] Loss: 0.05991 
Epoch [211/300] Training [60/62] Loss: 0.04429 
Epoch [211/300] Training [61/62] Loss: 0.03262 
Epoch [211/300] Training [62/62] Loss: 0.02499 
Epoch [211/300] Training metric {'Train/mean dice_metric': 0.957319974899292, 'Train/mean miou_metric': 0.9271960258483887, 'Train/mean f1': 0.9643534421920776, 'Train/mean precision': 0.9628989696502686, 'Train/mean recall': 0.9658123254776001, 'Train/mean hd95_metric': 9.595124244689941}
Epoch [211/300] Validation [1/16] Loss: 0.59986  focal_loss 0.40828  dice_loss 0.19158 
Epoch [211/300] Validation [2/16] Loss: 0.49246  focal_loss 0.18423  dice_loss 0.30823 
Epoch [211/300] Validation [3/16] Loss: 0.71482  focal_loss 0.39502  dice_loss 0.31980 
Epoch [211/300] Validation [4/16] Loss: 0.37058  focal_loss 0.17425  dice_loss 0.19633 
Epoch [211/300] Validation [5/16] Loss: 0.34338  focal_loss 0.11693  dice_loss 0.22645 
Epoch [211/300] Validation [6/16] Loss: 0.31607  focal_loss 0.10217  dice_loss 0.21390 
Epoch [211/300] Validation [7/16] Loss: 0.19281  focal_loss 0.08034  dice_loss 0.11247 
Epoch [211/300] Validation [8/16] Loss: 0.45520  focal_loss 0.16191  dice_loss 0.29329 
Epoch [211/300] Validation [9/16] Loss: 0.21951  focal_loss 0.08707  dice_loss 0.13243 
Epoch [211/300] Validation [10/16] Loss: 0.57121  focal_loss 0.23904  dice_loss 0.33217 
Epoch [211/300] Validation [11/16] Loss: 0.14450  focal_loss 0.05261  dice_loss 0.09189 
Epoch [211/300] Validation [12/16] Loss: 0.41290  focal_loss 0.10032  dice_loss 0.31258 
Epoch [211/300] Validation [13/16] Loss: 0.23472  focal_loss 0.07590  dice_loss 0.15882 
Epoch [211/300] Validation [14/16] Loss: 0.52540  focal_loss 0.20080  dice_loss 0.32461 
Epoch [211/300] Validation [15/16] Loss: 0.13374  focal_loss 0.04162  dice_loss 0.09212 
Epoch [211/300] Validation [16/16] Loss: 0.12981  focal_loss 0.04286  dice_loss 0.08695 
Epoch [211/300] Validation metric {'Val/mean dice_metric': 0.9230570793151855, 'Val/mean miou_metric': 0.881352424621582, 'Val/mean f1': 0.9369812607765198, 'Val/mean precision': 0.9452019333839417, 'Val/mean recall': 0.9289023280143738, 'Val/mean hd95_metric': 18.189735412597656}
Cheakpoint...
Epoch [211/300] best acc:tensor([0.9308], device='cuda:0'), Now : mean acc: tensor([0.9231], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9230570793151855, 'Val/mean miou_metric': 0.881352424621582, 'Val/mean f1': 0.9369812607765198, 'Val/mean precision': 0.9452019333839417, 'Val/mean recall': 0.9289023280143738, 'Val/mean hd95_metric': 18.189735412597656}
Epoch [212/300] Training [1/62] Loss: 0.03177 
Epoch [212/300] Training [2/62] Loss: 0.04039 
Epoch [212/300] Training [3/62] Loss: 0.07921 
Epoch [212/300] Training [4/62] Loss: 0.03290 
Epoch [212/300] Training [5/62] Loss: 0.06313 
Epoch [212/300] Training [6/62] Loss: 0.03774 
Epoch [212/300] Training [7/62] Loss: 0.06615 
Epoch [212/300] Training [8/62] Loss: 0.03391 
Epoch [212/300] Training [9/62] Loss: 0.04470 
Epoch [212/300] Training [10/62] Loss: 0.03916 
Epoch [212/300] Training [11/62] Loss: 0.05391 
Epoch [212/300] Training [12/62] Loss: 0.05868 
Epoch [212/300] Training [13/62] Loss: 0.04466 
Epoch [212/300] Training [14/62] Loss: 0.03899 
Epoch [212/300] Training [15/62] Loss: 0.03168 
Epoch [212/300] Training [16/62] Loss: 0.04019 
Epoch [212/300] Training [17/62] Loss: 0.06550 
Epoch [212/300] Training [18/62] Loss: 0.05854 
Epoch [212/300] Training [19/62] Loss: 0.10121 
Epoch [212/300] Training [20/62] Loss: 0.03404 
Epoch [212/300] Training [21/62] Loss: 0.05798 
Epoch [212/300] Training [22/62] Loss: 0.04560 
Epoch [212/300] Training [23/62] Loss: 0.06272 
Epoch [212/300] Training [24/62] Loss: 0.08717 
Epoch [212/300] Training [25/62] Loss: 0.08028 
Epoch [212/300] Training [26/62] Loss: 0.03335 
Epoch [212/300] Training [27/62] Loss: 0.06041 
Epoch [212/300] Training [28/62] Loss: 0.03488 
Epoch [212/300] Training [29/62] Loss: 0.04334 
Epoch [212/300] Training [30/62] Loss: 0.04849 
Epoch [212/300] Training [31/62] Loss: 0.05762 
Epoch [212/300] Training [32/62] Loss: 0.08502 
Epoch [212/300] Training [33/62] Loss: 0.12827 
Epoch [212/300] Training [34/62] Loss: 0.04290 
Epoch [212/300] Training [35/62] Loss: 0.22136 
Epoch [212/300] Training [36/62] Loss: 0.06032 
Epoch [212/300] Training [37/62] Loss: 0.05950 
Epoch [212/300] Training [38/62] Loss: 0.07220 
Epoch [212/300] Training [39/62] Loss: 0.07425 
Epoch [212/300] Training [40/62] Loss: 0.08655 
Epoch [212/300] Training [41/62] Loss: 0.06068 
Epoch [212/300] Training [42/62] Loss: 0.15546 
Epoch [212/300] Training [43/62] Loss: 0.03329 
Epoch [212/300] Training [44/62] Loss: 0.10072 
Epoch [212/300] Training [45/62] Loss: 0.05559 
Epoch [212/300] Training [46/62] Loss: 0.04837 
Epoch [212/300] Training [47/62] Loss: 0.15080 
Epoch [212/300] Training [48/62] Loss: 0.05032 
Epoch [212/300] Training [49/62] Loss: 0.03318 
Epoch [212/300] Training [50/62] Loss: 0.05638 
Epoch [212/300] Training [51/62] Loss: 0.07368 
Epoch [212/300] Training [52/62] Loss: 0.05468 
Epoch [212/300] Training [53/62] Loss: 0.03215 
Epoch [212/300] Training [54/62] Loss: 0.03567 
Epoch [212/300] Training [55/62] Loss: 0.06707 
Epoch [212/300] Training [56/62] Loss: 0.04072 
Epoch [212/300] Training [57/62] Loss: 0.05029 
Epoch [212/300] Training [58/62] Loss: 0.04826 
Epoch [212/300] Training [59/62] Loss: 0.08621 
Epoch [212/300] Training [60/62] Loss: 0.04343 
Epoch [212/300] Training [61/62] Loss: 0.04975 
Epoch [212/300] Training [62/62] Loss: 0.11900 
Epoch [212/300] Training metric {'Train/mean dice_metric': 0.9574401378631592, 'Train/mean miou_metric': 0.9245350956916809, 'Train/mean f1': 0.9629746675491333, 'Train/mean precision': 0.9610379934310913, 'Train/mean recall': 0.9649192094802856, 'Train/mean hd95_metric': 10.671913146972656}
Epoch [212/300] Validation [1/16] Loss: 0.67743  focal_loss 0.45110  dice_loss 0.22634 
Epoch [212/300] Validation [2/16] Loss: 0.45964  focal_loss 0.18641  dice_loss 0.27323 
Epoch [212/300] Validation [3/16] Loss: 0.67545  focal_loss 0.39245  dice_loss 0.28300 
Epoch [212/300] Validation [4/16] Loss: 0.34615  focal_loss 0.15835  dice_loss 0.18780 
Epoch [212/300] Validation [5/16] Loss: 0.35864  focal_loss 0.12589  dice_loss 0.23276 
Epoch [212/300] Validation [6/16] Loss: 0.39005  focal_loss 0.14276  dice_loss 0.24729 
Epoch [212/300] Validation [7/16] Loss: 0.21362  focal_loss 0.08800  dice_loss 0.12561 
Epoch [212/300] Validation [8/16] Loss: 0.54384  focal_loss 0.18168  dice_loss 0.36216 
Epoch [212/300] Validation [9/16] Loss: 0.21872  focal_loss 0.07882  dice_loss 0.13991 
Epoch [212/300] Validation [10/16] Loss: 0.52841  focal_loss 0.16375  dice_loss 0.36466 
Epoch [212/300] Validation [11/16] Loss: 0.13835  focal_loss 0.04393  dice_loss 0.09441 
Epoch [212/300] Validation [12/16] Loss: 0.43521  focal_loss 0.11954  dice_loss 0.31567 
Epoch [212/300] Validation [13/16] Loss: 0.31982  focal_loss 0.11564  dice_loss 0.20418 
Epoch [212/300] Validation [14/16] Loss: 0.52765  focal_loss 0.21226  dice_loss 0.31539 
Epoch [212/300] Validation [15/16] Loss: 0.09070  focal_loss 0.02910  dice_loss 0.06160 
Epoch [212/300] Validation [16/16] Loss: 0.10987  focal_loss 0.03004  dice_loss 0.07983 
Epoch [212/300] Validation metric {'Val/mean dice_metric': 0.921694815158844, 'Val/mean miou_metric': 0.8773095607757568, 'Val/mean f1': 0.9345636367797852, 'Val/mean precision': 0.9442586302757263, 'Val/mean recall': 0.9250657558441162, 'Val/mean hd95_metric': 18.764572143554688}
Cheakpoint...
Epoch [212/300] best acc:tensor([0.9308], device='cuda:0'), Now : mean acc: tensor([0.9217], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.921694815158844, 'Val/mean miou_metric': 0.8773095607757568, 'Val/mean f1': 0.9345636367797852, 'Val/mean precision': 0.9442586302757263, 'Val/mean recall': 0.9250657558441162, 'Val/mean hd95_metric': 18.764572143554688}
Epoch [213/300] Training [1/62] Loss: 0.05245 
Epoch [213/300] Training [2/62] Loss: 0.04252 
Epoch [213/300] Training [3/62] Loss: 0.04672 
Epoch [213/300] Training [4/62] Loss: 0.06363 
Epoch [213/300] Training [5/62] Loss: 0.04061 
Epoch [213/300] Training [6/62] Loss: 0.04187 
Epoch [213/300] Training [7/62] Loss: 0.12507 
Epoch [213/300] Training [8/62] Loss: 0.07665 
Epoch [213/300] Training [9/62] Loss: 0.05304 
Epoch [213/300] Training [10/62] Loss: 0.03285 
Epoch [213/300] Training [11/62] Loss: 0.05045 
Epoch [213/300] Training [12/62] Loss: 0.03511 
Epoch [213/300] Training [13/62] Loss: 0.03636 
Epoch [213/300] Training [14/62] Loss: 0.06514 
Epoch [213/300] Training [15/62] Loss: 0.05428 
Epoch [213/300] Training [16/62] Loss: 0.04399 
Epoch [213/300] Training [17/62] Loss: 0.07106 
Epoch [213/300] Training [18/62] Loss: 0.03570 
Epoch [213/300] Training [19/62] Loss: 0.11927 
Epoch [213/300] Training [20/62] Loss: 0.16899 
Epoch [213/300] Training [21/62] Loss: 0.08119 
Epoch [213/300] Training [22/62] Loss: 0.05238 
Epoch [213/300] Training [23/62] Loss: 0.06147 
Epoch [213/300] Training [24/62] Loss: 0.03533 
Epoch [213/300] Training [25/62] Loss: 0.11435 
Epoch [213/300] Training [26/62] Loss: 0.05294 
Epoch [213/300] Training [27/62] Loss: 0.04159 
Epoch [213/300] Training [28/62] Loss: 0.06889 
Epoch [213/300] Training [29/62] Loss: 0.03339 
Epoch [213/300] Training [30/62] Loss: 0.03761 
Epoch [213/300] Training [31/62] Loss: 0.06402 
Epoch [213/300] Training [32/62] Loss: 0.03906 
Epoch [213/300] Training [33/62] Loss: 0.03223 
Epoch [213/300] Training [34/62] Loss: 0.03064 
Epoch [213/300] Training [35/62] Loss: 0.08113 
Epoch [213/300] Training [36/62] Loss: 0.06421 
Epoch [213/300] Training [37/62] Loss: 0.04488 
Epoch [213/300] Training [38/62] Loss: 0.03596 
Epoch [213/300] Training [39/62] Loss: 0.06023 
Epoch [213/300] Training [40/62] Loss: 0.06135 
Epoch [213/300] Training [41/62] Loss: 0.03270 
Epoch [213/300] Training [42/62] Loss: 0.03222 
Epoch [213/300] Training [43/62] Loss: 0.03467 
Epoch [213/300] Training [44/62] Loss: 0.13050 
Epoch [213/300] Training [45/62] Loss: 0.07786 
Epoch [213/300] Training [46/62] Loss: 0.03260 
Epoch [213/300] Training [47/62] Loss: 0.03315 
Epoch [213/300] Training [48/62] Loss: 0.03549 
Epoch [213/300] Training [49/62] Loss: 0.03522 
Epoch [213/300] Training [50/62] Loss: 0.03952 
Epoch [213/300] Training [51/62] Loss: 0.03449 
Epoch [213/300] Training [52/62] Loss: 0.07343 
Epoch [213/300] Training [53/62] Loss: 0.08124 
Epoch [213/300] Training [54/62] Loss: 0.03050 
Epoch [213/300] Training [55/62] Loss: 0.14865 
Epoch [213/300] Training [56/62] Loss: 0.07721 
Epoch [213/300] Training [57/62] Loss: 0.06296 
Epoch [213/300] Training [58/62] Loss: 0.04969 
Epoch [213/300] Training [59/62] Loss: 0.03905 
Epoch [213/300] Training [60/62] Loss: 0.05627 
Epoch [213/300] Training [61/62] Loss: 0.02733 
Epoch [213/300] Training [62/62] Loss: 0.07694 
Epoch [213/300] Training metric {'Train/mean dice_metric': 0.9605363607406616, 'Train/mean miou_metric': 0.9295490980148315, 'Train/mean f1': 0.9655176997184753, 'Train/mean precision': 0.961992621421814, 'Train/mean recall': 0.9690688252449036, 'Train/mean hd95_metric': 9.425894737243652}
Epoch [213/300] Validation [1/16] Loss: 0.68367  focal_loss 0.46219  dice_loss 0.22148 
Epoch [213/300] Validation [2/16] Loss: 0.46259  focal_loss 0.18855  dice_loss 0.27404 
Epoch [213/300] Validation [3/16] Loss: 0.70348  focal_loss 0.38947  dice_loss 0.31401 
Epoch [213/300] Validation [4/16] Loss: 0.31818  focal_loss 0.15848  dice_loss 0.15970 
Epoch [213/300] Validation [5/16] Loss: 0.37294  focal_loss 0.13013  dice_loss 0.24281 
Epoch [213/300] Validation [6/16] Loss: 0.32948  focal_loss 0.10041  dice_loss 0.22907 
Epoch [213/300] Validation [7/16] Loss: 0.30161  focal_loss 0.12083  dice_loss 0.18078 
Epoch [213/300] Validation [8/16] Loss: 0.48950  focal_loss 0.18579  dice_loss 0.30372 
Epoch [213/300] Validation [9/16] Loss: 0.17817  focal_loss 0.06606  dice_loss 0.11211 
Epoch [213/300] Validation [10/16] Loss: 0.55081  focal_loss 0.20825  dice_loss 0.34255 
Epoch [213/300] Validation [11/16] Loss: 0.13499  focal_loss 0.05044  dice_loss 0.08454 
Epoch [213/300] Validation [12/16] Loss: 0.38871  focal_loss 0.11906  dice_loss 0.26965 
Epoch [213/300] Validation [13/16] Loss: 0.24930  focal_loss 0.10205  dice_loss 0.14725 
Epoch [213/300] Validation [14/16] Loss: 0.65156  focal_loss 0.27258  dice_loss 0.37898 
Epoch [213/300] Validation [15/16] Loss: 0.10930  focal_loss 0.03586  dice_loss 0.07344 
Epoch [213/300] Validation [16/16] Loss: 0.11962  focal_loss 0.03612  dice_loss 0.08350 
Epoch [213/300] Validation metric {'Val/mean dice_metric': 0.9253149032592773, 'Val/mean miou_metric': 0.8829919099807739, 'Val/mean f1': 0.9376553893089294, 'Val/mean precision': 0.9434089660644531, 'Val/mean recall': 0.9319717288017273, 'Val/mean hd95_metric': 17.896310806274414}
Cheakpoint...
Epoch [213/300] best acc:tensor([0.9308], device='cuda:0'), Now : mean acc: tensor([0.9253], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9253149032592773, 'Val/mean miou_metric': 0.8829919099807739, 'Val/mean f1': 0.9376553893089294, 'Val/mean precision': 0.9434089660644531, 'Val/mean recall': 0.9319717288017273, 'Val/mean hd95_metric': 17.896310806274414}
Epoch [214/300] Training [1/62] Loss: 0.08168 
Epoch [214/300] Training [2/62] Loss: 0.03988 
Epoch [214/300] Training [3/62] Loss: 0.03517 
Epoch [214/300] Training [4/62] Loss: 0.08909 
Epoch [214/300] Training [5/62] Loss: 0.04135 
Epoch [214/300] Training [6/62] Loss: 0.03532 
Epoch [214/300] Training [7/62] Loss: 0.05694 
Epoch [214/300] Training [8/62] Loss: 0.08008 
Epoch [214/300] Training [9/62] Loss: 0.03977 
Epoch [214/300] Training [10/62] Loss: 0.03779 
Epoch [214/300] Training [11/62] Loss: 0.06820 
Epoch [214/300] Training [12/62] Loss: 0.03736 
Epoch [214/300] Training [13/62] Loss: 0.03857 
Epoch [214/300] Training [14/62] Loss: 0.05436 
Epoch [214/300] Training [15/62] Loss: 0.04149 
Epoch [214/300] Training [16/62] Loss: 0.08387 
Epoch [214/300] Training [17/62] Loss: 0.04096 
Epoch [214/300] Training [18/62] Loss: 0.04800 
Epoch [214/300] Training [19/62] Loss: 0.05134 
Epoch [214/300] Training [20/62] Loss: 0.03393 
Epoch [214/300] Training [21/62] Loss: 0.02791 
Epoch [214/300] Training [22/62] Loss: 0.08077 
Epoch [214/300] Training [23/62] Loss: 0.03263 
Epoch [214/300] Training [24/62] Loss: 0.03220 
Epoch [214/300] Training [25/62] Loss: 0.04270 
Epoch [214/300] Training [26/62] Loss: 0.07444 
Epoch [214/300] Training [27/62] Loss: 0.03710 
Epoch [214/300] Training [28/62] Loss: 0.04413 
Epoch [214/300] Training [29/62] Loss: 0.03211 
Epoch [214/300] Training [30/62] Loss: 0.09860 
Epoch [214/300] Training [31/62] Loss: 0.07326 
Epoch [214/300] Training [32/62] Loss: 0.07177 
Epoch [214/300] Training [33/62] Loss: 0.12035 
Epoch [214/300] Training [34/62] Loss: 0.03707 
Epoch [214/300] Training [35/62] Loss: 0.03241 
Epoch [214/300] Training [36/62] Loss: 0.04986 
Epoch [214/300] Training [37/62] Loss: 0.12704 
Epoch [214/300] Training [38/62] Loss: 0.04785 
Epoch [214/300] Training [39/62] Loss: 0.03824 
Epoch [214/300] Training [40/62] Loss: 0.02695 
Epoch [214/300] Training [41/62] Loss: 0.03508 
Epoch [214/300] Training [42/62] Loss: 0.08734 
Epoch [214/300] Training [43/62] Loss: 0.03449 
Epoch [214/300] Training [44/62] Loss: 0.04645 
Epoch [214/300] Training [45/62] Loss: 0.03208 
Epoch [214/300] Training [46/62] Loss: 0.11098 
Epoch [214/300] Training [47/62] Loss: 0.06251 
Epoch [214/300] Training [48/62] Loss: 0.03960 
Epoch [214/300] Training [49/62] Loss: 0.02912 
Epoch [214/300] Training [50/62] Loss: 0.03257 
Epoch [214/300] Training [51/62] Loss: 0.07022 
Epoch [214/300] Training [52/62] Loss: 0.02863 
Epoch [214/300] Training [53/62] Loss: 0.03612 
Epoch [214/300] Training [54/62] Loss: 0.05673 
Epoch [214/300] Training [55/62] Loss: 0.03134 
Epoch [214/300] Training [56/62] Loss: 0.03064 
Epoch [214/300] Training [57/62] Loss: 0.04310 
Epoch [214/300] Training [58/62] Loss: 0.04088 
Epoch [214/300] Training [59/62] Loss: 0.04114 
Epoch [214/300] Training [60/62] Loss: 0.03834 
Epoch [214/300] Training [61/62] Loss: 0.02264 
Epoch [214/300] Training [62/62] Loss: 0.04461 
Epoch [214/300] Training metric {'Train/mean dice_metric': 0.9651581048965454, 'Train/mean miou_metric': 0.9364861249923706, 'Train/mean f1': 0.9677671790122986, 'Train/mean precision': 0.9645050168037415, 'Train/mean recall': 0.9710513949394226, 'Train/mean hd95_metric': 8.109041213989258}
Epoch [214/300] Validation [1/16] Loss: 0.65038  focal_loss 0.43940  dice_loss 0.21097 
Epoch [214/300] Validation [2/16] Loss: 0.43863  focal_loss 0.18747  dice_loss 0.25117 
Epoch [214/300] Validation [3/16] Loss: 0.55699  focal_loss 0.29325  dice_loss 0.26374 
Epoch [214/300] Validation [4/16] Loss: 0.27452  focal_loss 0.13794  dice_loss 0.13658 
Epoch [214/300] Validation [5/16] Loss: 0.36920  focal_loss 0.12624  dice_loss 0.24296 
Epoch [214/300] Validation [6/16] Loss: 0.30485  focal_loss 0.09712  dice_loss 0.20773 
Epoch [214/300] Validation [7/16] Loss: 0.29715  focal_loss 0.11980  dice_loss 0.17735 
Epoch [214/300] Validation [8/16] Loss: 0.48889  focal_loss 0.17876  dice_loss 0.31013 
Epoch [214/300] Validation [9/16] Loss: 0.19317  focal_loss 0.07717  dice_loss 0.11600 
Epoch [214/300] Validation [10/16] Loss: 0.45433  focal_loss 0.14646  dice_loss 0.30788 
Epoch [214/300] Validation [11/16] Loss: 0.12156  focal_loss 0.04234  dice_loss 0.07922 
Epoch [214/300] Validation [12/16] Loss: 0.42434  focal_loss 0.12758  dice_loss 0.29676 
Epoch [214/300] Validation [13/16] Loss: 0.22446  focal_loss 0.06464  dice_loss 0.15983 
Epoch [214/300] Validation [14/16] Loss: 0.59522  focal_loss 0.26019  dice_loss 0.33503 
Epoch [214/300] Validation [15/16] Loss: 0.10629  focal_loss 0.03707  dice_loss 0.06922 
Epoch [214/300] Validation [16/16] Loss: 0.15786  focal_loss 0.05424  dice_loss 0.10363 
Epoch [214/300] Validation metric {'Val/mean dice_metric': 0.931068480014801, 'Val/mean miou_metric': 0.8906955122947693, 'Val/mean f1': 0.9407851696014404, 'Val/mean precision': 0.9456058740615845, 'Val/mean recall': 0.9360133409500122, 'Val/mean hd95_metric': 17.136686325073242}
Cheakpoint...
Epoch [214/300] best acc:tensor([0.9311], device='cuda:0'), Now : mean acc: tensor([0.9311], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.931068480014801, 'Val/mean miou_metric': 0.8906955122947693, 'Val/mean f1': 0.9407851696014404, 'Val/mean precision': 0.9456058740615845, 'Val/mean recall': 0.9360133409500122, 'Val/mean hd95_metric': 17.136686325073242}
Epoch [215/300] Training [1/62] Loss: 0.05975 
Epoch [215/300] Training [2/62] Loss: 0.02494 
Epoch [215/300] Training [3/62] Loss: 0.03835 
Epoch [215/300] Training [4/62] Loss: 0.10428 
Epoch [215/300] Training [5/62] Loss: 0.08930 
Epoch [215/300] Training [6/62] Loss: 0.02805 
Epoch [215/300] Training [7/62] Loss: 0.03573 
Epoch [215/300] Training [8/62] Loss: 0.04172 
Epoch [215/300] Training [9/62] Loss: 0.02842 
Epoch [215/300] Training [10/62] Loss: 0.09673 
Epoch [215/300] Training [11/62] Loss: 0.07761 
Epoch [215/300] Training [12/62] Loss: 0.04515 
Epoch [215/300] Training [13/62] Loss: 0.03885 
Epoch [215/300] Training [14/62] Loss: 0.03596 
Epoch [215/300] Training [15/62] Loss: 0.03859 
Epoch [215/300] Training [16/62] Loss: 0.03796 
Epoch [215/300] Training [17/62] Loss: 0.05045 
Epoch [215/300] Training [18/62] Loss: 0.03606 
Epoch [215/300] Training [19/62] Loss: 0.05067 
Epoch [215/300] Training [20/62] Loss: 0.05770 
Epoch [215/300] Training [21/62] Loss: 0.03056 
Epoch [215/300] Training [22/62] Loss: 0.05259 
Epoch [215/300] Training [23/62] Loss: 0.02925 
Epoch [215/300] Training [24/62] Loss: 0.03190 
Epoch [215/300] Training [25/62] Loss: 0.04471 
Epoch [215/300] Training [26/62] Loss: 0.03536 
Epoch [215/300] Training [27/62] Loss: 0.04054 
Epoch [215/300] Training [28/62] Loss: 0.03898 
Epoch [215/300] Training [29/62] Loss: 0.03794 
Epoch [215/300] Training [30/62] Loss: 0.03702 
Epoch [215/300] Training [31/62] Loss: 0.05046 
Epoch [215/300] Training [32/62] Loss: 0.03636 
Epoch [215/300] Training [33/62] Loss: 0.10849 
Epoch [215/300] Training [34/62] Loss: 0.08796 
Epoch [215/300] Training [35/62] Loss: 0.04544 
Epoch [215/300] Training [36/62] Loss: 0.03072 
Epoch [215/300] Training [37/62] Loss: 0.03456 
Epoch [215/300] Training [38/62] Loss: 0.02756 
Epoch [215/300] Training [39/62] Loss: 0.03524 
Epoch [215/300] Training [40/62] Loss: 0.03952 
Epoch [215/300] Training [41/62] Loss: 0.03018 
Epoch [215/300] Training [42/62] Loss: 0.04687 
Epoch [215/300] Training [43/62] Loss: 0.04145 
Epoch [215/300] Training [44/62] Loss: 0.09761 
Epoch [215/300] Training [45/62] Loss: 0.05039 
Epoch [215/300] Training [46/62] Loss: 0.03884 
Epoch [215/300] Training [47/62] Loss: 0.03357 
Epoch [215/300] Training [48/62] Loss: 0.11644 
Epoch [215/300] Training [49/62] Loss: 0.02891 
Epoch [215/300] Training [50/62] Loss: 0.04984 
Epoch [215/300] Training [51/62] Loss: 0.03497 
Epoch [215/300] Training [52/62] Loss: 0.10841 
Epoch [215/300] Training [53/62] Loss: 0.03515 
Epoch [215/300] Training [54/62] Loss: 0.05376 
Epoch [215/300] Training [55/62] Loss: 0.05776 
Epoch [215/300] Training [56/62] Loss: 0.07850 
Epoch [215/300] Training [57/62] Loss: 0.05769 
Epoch [215/300] Training [58/62] Loss: 0.03917 
Epoch [215/300] Training [59/62] Loss: 0.07012 
Epoch [215/300] Training [60/62] Loss: 0.05923 
Epoch [215/300] Training [61/62] Loss: 0.05445 
Epoch [215/300] Training [62/62] Loss: 0.04328 
Epoch [215/300] Training metric {'Train/mean dice_metric': 0.9651356935501099, 'Train/mean miou_metric': 0.937020480632782, 'Train/mean f1': 0.9685156345367432, 'Train/mean precision': 0.9634283185005188, 'Train/mean recall': 0.973656952381134, 'Train/mean hd95_metric': 6.85964298248291}
Epoch [215/300] Validation [1/16] Loss: 0.63950  focal_loss 0.44030  dice_loss 0.19920 
Epoch [215/300] Validation [2/16] Loss: 0.51360  focal_loss 0.19392  dice_loss 0.31967 
Epoch [215/300] Validation [3/16] Loss: 0.71731  focal_loss 0.42061  dice_loss 0.29669 
Epoch [215/300] Validation [4/16] Loss: 0.30767  focal_loss 0.14436  dice_loss 0.16331 
Epoch [215/300] Validation [5/16] Loss: 0.33376  focal_loss 0.11978  dice_loss 0.21398 
Epoch [215/300] Validation [6/16] Loss: 0.34620  focal_loss 0.10828  dice_loss 0.23792 
Epoch [215/300] Validation [7/16] Loss: 0.27576  focal_loss 0.10005  dice_loss 0.17572 
Epoch [215/300] Validation [8/16] Loss: 0.40078  focal_loss 0.13516  dice_loss 0.26562 
Epoch [215/300] Validation [9/16] Loss: 0.24695  focal_loss 0.10639  dice_loss 0.14056 
Epoch [215/300] Validation [10/16] Loss: 0.58691  focal_loss 0.21454  dice_loss 0.37236 
Epoch [215/300] Validation [11/16] Loss: 0.15864  focal_loss 0.05916  dice_loss 0.09948 
Epoch [215/300] Validation [12/16] Loss: 0.40945  focal_loss 0.11760  dice_loss 0.29184 
Epoch [215/300] Validation [13/16] Loss: 0.26968  focal_loss 0.09354  dice_loss 0.17615 
Epoch [215/300] Validation [14/16] Loss: 0.64360  focal_loss 0.28050  dice_loss 0.36310 
Epoch [215/300] Validation [15/16] Loss: 0.10689  focal_loss 0.03424  dice_loss 0.07265 
Epoch [215/300] Validation [16/16] Loss: 0.10988  focal_loss 0.03042  dice_loss 0.07946 
Epoch [215/300] Validation metric {'Val/mean dice_metric': 0.928290069103241, 'Val/mean miou_metric': 0.887501060962677, 'Val/mean f1': 0.9404099583625793, 'Val/mean precision': 0.9427539110183716, 'Val/mean recall': 0.9380776286125183, 'Val/mean hd95_metric': 15.942352294921875}
Cheakpoint...
Epoch [215/300] best acc:tensor([0.9311], device='cuda:0'), Now : mean acc: tensor([0.9283], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.928290069103241, 'Val/mean miou_metric': 0.887501060962677, 'Val/mean f1': 0.9404099583625793, 'Val/mean precision': 0.9427539110183716, 'Val/mean recall': 0.9380776286125183, 'Val/mean hd95_metric': 15.942352294921875}
Epoch [216/300] Training [1/62] Loss: 0.04776 
Epoch [216/300] Training [2/62] Loss: 0.04566 
Epoch [216/300] Training [3/62] Loss: 0.03208 
Epoch [216/300] Training [4/62] Loss: 0.04455 
Epoch [216/300] Training [5/62] Loss: 0.08232 
Epoch [216/300] Training [6/62] Loss: 0.04448 
Epoch [216/300] Training [7/62] Loss: 0.05076 
Epoch [216/300] Training [8/62] Loss: 0.03761 
Epoch [216/300] Training [9/62] Loss: 0.06479 
Epoch [216/300] Training [10/62] Loss: 0.03837 
Epoch [216/300] Training [11/62] Loss: 0.05714 
Epoch [216/300] Training [12/62] Loss: 0.03977 
Epoch [216/300] Training [13/62] Loss: 0.03930 
Epoch [216/300] Training [14/62] Loss: 0.05504 
Epoch [216/300] Training [15/62] Loss: 0.06939 
Epoch [216/300] Training [16/62] Loss: 0.03953 
Epoch [216/300] Training [17/62] Loss: 0.09606 
Epoch [216/300] Training [18/62] Loss: 0.03521 
Epoch [216/300] Training [19/62] Loss: 0.03239 
Epoch [216/300] Training [20/62] Loss: 0.04919 
Epoch [216/300] Training [21/62] Loss: 0.03422 
Epoch [216/300] Training [22/62] Loss: 0.04105 
Epoch [216/300] Training [23/62] Loss: 0.03507 
Epoch [216/300] Training [24/62] Loss: 0.02921 
Epoch [216/300] Training [25/62] Loss: 0.03616 
Epoch [216/300] Training [26/62] Loss: 0.03623 
Epoch [216/300] Training [27/62] Loss: 0.10317 
Epoch [216/300] Training [28/62] Loss: 0.03840 
Epoch [216/300] Training [29/62] Loss: 0.03747 
Epoch [216/300] Training [30/62] Loss: 0.06623 
Epoch [216/300] Training [31/62] Loss: 0.05194 
Epoch [216/300] Training [32/62] Loss: 0.02836 
Epoch [216/300] Training [33/62] Loss: 0.03612 
Epoch [216/300] Training [34/62] Loss: 0.07638 
Epoch [216/300] Training [35/62] Loss: 0.04422 
Epoch [216/300] Training [36/62] Loss: 0.03937 
Epoch [216/300] Training [37/62] Loss: 0.03172 
Epoch [216/300] Training [38/62] Loss: 0.03233 
Epoch [216/300] Training [39/62] Loss: 0.06163 
Epoch [216/300] Training [40/62] Loss: 0.03126 
Epoch [216/300] Training [41/62] Loss: 0.22347 
Epoch [216/300] Training [42/62] Loss: 0.06269 
Epoch [216/300] Training [43/62] Loss: 0.03829 
Epoch [216/300] Training [44/62] Loss: 0.05000 
Epoch [216/300] Training [45/62] Loss: 0.03667 
Epoch [216/300] Training [46/62] Loss: 0.03756 
Epoch [216/300] Training [47/62] Loss: 0.05410 
Epoch [216/300] Training [48/62] Loss: 0.09461 
Epoch [216/300] Training [49/62] Loss: 0.03274 
Epoch [216/300] Training [50/62] Loss: 0.04476 
Epoch [216/300] Training [51/62] Loss: 0.04123 
Epoch [216/300] Training [52/62] Loss: 0.04710 
Epoch [216/300] Training [53/62] Loss: 0.08323 
Epoch [216/300] Training [54/62] Loss: 0.08891 
Epoch [216/300] Training [55/62] Loss: 0.05839 
Epoch [216/300] Training [56/62] Loss: 0.06991 
Epoch [216/300] Training [57/62] Loss: 0.14366 
Epoch [216/300] Training [58/62] Loss: 0.03802 
Epoch [216/300] Training [59/62] Loss: 0.04081 
Epoch [216/300] Training [60/62] Loss: 0.04036 
Epoch [216/300] Training [61/62] Loss: 0.07644 
Epoch [216/300] Training [62/62] Loss: 0.08436 
Epoch [216/300] Training metric {'Train/mean dice_metric': 0.9626806974411011, 'Train/mean miou_metric': 0.9339950680732727, 'Train/mean f1': 0.9657496213912964, 'Train/mean precision': 0.9626898169517517, 'Train/mean recall': 0.9688290357589722, 'Train/mean hd95_metric': 9.426177024841309}
Epoch [216/300] Validation [1/16] Loss: 0.63082  focal_loss 0.42020  dice_loss 0.21061 
Epoch [216/300] Validation [2/16] Loss: 0.48623  focal_loss 0.20970  dice_loss 0.27653 
Epoch [216/300] Validation [3/16] Loss: 0.68722  focal_loss 0.39294  dice_loss 0.29428 
Epoch [216/300] Validation [4/16] Loss: 0.30608  focal_loss 0.15717  dice_loss 0.14891 
Epoch [216/300] Validation [5/16] Loss: 0.29914  focal_loss 0.10663  dice_loss 0.19251 
Epoch [216/300] Validation [6/16] Loss: 0.30906  focal_loss 0.09913  dice_loss 0.20993 
Epoch [216/300] Validation [7/16] Loss: 0.23190  focal_loss 0.09933  dice_loss 0.13257 
Epoch [216/300] Validation [8/16] Loss: 0.43402  focal_loss 0.17014  dice_loss 0.26388 
Epoch [216/300] Validation [9/16] Loss: 0.23259  focal_loss 0.09281  dice_loss 0.13978 
Epoch [216/300] Validation [10/16] Loss: 0.50474  focal_loss 0.15827  dice_loss 0.34646 
Epoch [216/300] Validation [11/16] Loss: 0.16496  focal_loss 0.06564  dice_loss 0.09932 
Epoch [216/300] Validation [12/16] Loss: 0.40538  focal_loss 0.12972  dice_loss 0.27566 
Epoch [216/300] Validation [13/16] Loss: 0.25375  focal_loss 0.09498  dice_loss 0.15877 
Epoch [216/300] Validation [14/16] Loss: 0.64645  focal_loss 0.27131  dice_loss 0.37513 
Epoch [216/300] Validation [15/16] Loss: 0.09785  focal_loss 0.03173  dice_loss 0.06612 
Epoch [216/300] Validation [16/16] Loss: 0.12331  focal_loss 0.04535  dice_loss 0.07796 
Epoch [216/300] Validation metric {'Val/mean dice_metric': 0.9291044473648071, 'Val/mean miou_metric': 0.8888853192329407, 'Val/mean f1': 0.938863217830658, 'Val/mean precision': 0.9446296095848083, 'Val/mean recall': 0.9331668615341187, 'Val/mean hd95_metric': 17.395977020263672}
Cheakpoint...
Epoch [216/300] best acc:tensor([0.9311], device='cuda:0'), Now : mean acc: tensor([0.9291], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9291044473648071, 'Val/mean miou_metric': 0.8888853192329407, 'Val/mean f1': 0.938863217830658, 'Val/mean precision': 0.9446296095848083, 'Val/mean recall': 0.9331668615341187, 'Val/mean hd95_metric': 17.395977020263672}
Epoch [217/300] Training [1/62] Loss: 0.03563 
Epoch [217/300] Training [2/62] Loss: 0.09294 
Epoch [217/300] Training [3/62] Loss: 0.03779 
Epoch [217/300] Training [4/62] Loss: 0.03723 
Epoch [217/300] Training [5/62] Loss: 0.03508 
Epoch [217/300] Training [6/62] Loss: 0.04929 
Epoch [217/300] Training [7/62] Loss: 0.07039 
Epoch [217/300] Training [8/62] Loss: 0.04219 
Epoch [217/300] Training [9/62] Loss: 0.03640 
Epoch [217/300] Training [10/62] Loss: 0.03766 
Epoch [217/300] Training [11/62] Loss: 0.09521 
Epoch [217/300] Training [12/62] Loss: 0.05923 
Epoch [217/300] Training [13/62] Loss: 0.03127 
Epoch [217/300] Training [14/62] Loss: 0.03375 
Epoch [217/300] Training [15/62] Loss: 0.03988 
Epoch [217/300] Training [16/62] Loss: 0.03026 
Epoch [217/300] Training [17/62] Loss: 0.09563 
Epoch [217/300] Training [18/62] Loss: 0.10237 
Epoch [217/300] Training [19/62] Loss: 0.04073 
Epoch [217/300] Training [20/62] Loss: 0.04436 
Epoch [217/300] Training [21/62] Loss: 0.03297 
Epoch [217/300] Training [22/62] Loss: 0.02844 
Epoch [217/300] Training [23/62] Loss: 0.05554 
Epoch [217/300] Training [24/62] Loss: 0.03860 
Epoch [217/300] Training [25/62] Loss: 0.06517 
Epoch [217/300] Training [26/62] Loss: 0.05836 
Epoch [217/300] Training [27/62] Loss: 0.02929 
Epoch [217/300] Training [28/62] Loss: 0.03586 
Epoch [217/300] Training [29/62] Loss: 0.04362 
Epoch [217/300] Training [30/62] Loss: 0.02702 
Epoch [217/300] Training [31/62] Loss: 0.06776 
Epoch [217/300] Training [32/62] Loss: 0.03162 
Epoch [217/300] Training [33/62] Loss: 0.04224 
Epoch [217/300] Training [34/62] Loss: 0.02998 
Epoch [217/300] Training [35/62] Loss: 0.03506 
Epoch [217/300] Training [36/62] Loss: 0.07194 
Epoch [217/300] Training [37/62] Loss: 0.04257 
Epoch [217/300] Training [38/62] Loss: 0.04612 
Epoch [217/300] Training [39/62] Loss: 0.05496 
Epoch [217/300] Training [40/62] Loss: 0.03535 
Epoch [217/300] Training [41/62] Loss: 0.05620 
Epoch [217/300] Training [42/62] Loss: 0.06389 
Epoch [217/300] Training [43/62] Loss: 0.04366 
Epoch [217/300] Training [44/62] Loss: 0.04026 
Epoch [217/300] Training [45/62] Loss: 0.04830 
Epoch [217/300] Training [46/62] Loss: 0.04515 
Epoch [217/300] Training [47/62] Loss: 0.03147 
Epoch [217/300] Training [48/62] Loss: 0.03459 
Epoch [217/300] Training [49/62] Loss: 0.12201 
Epoch [217/300] Training [50/62] Loss: 0.08726 
Epoch [217/300] Training [51/62] Loss: 0.06222 
Epoch [217/300] Training [52/62] Loss: 0.04940 
Epoch [217/300] Training [53/62] Loss: 0.06660 
Epoch [217/300] Training [54/62] Loss: 0.06026 
Epoch [217/300] Training [55/62] Loss: 0.04010 
Epoch [217/300] Training [56/62] Loss: 0.09481 
Epoch [217/300] Training [57/62] Loss: 0.05301 
Epoch [217/300] Training [58/62] Loss: 0.02859 
Epoch [217/300] Training [59/62] Loss: 0.03740 
Epoch [217/300] Training [60/62] Loss: 0.03562 
Epoch [217/300] Training [61/62] Loss: 0.04427 
Epoch [217/300] Training [62/62] Loss: 0.05600 
Epoch [217/300] Training metric {'Train/mean dice_metric': 0.9666154980659485, 'Train/mean miou_metric': 0.9382798671722412, 'Train/mean f1': 0.9675187468528748, 'Train/mean precision': 0.9637691974639893, 'Train/mean recall': 0.9712974429130554, 'Train/mean hd95_metric': 8.262675285339355}
Epoch [217/300] Validation [1/16] Loss: 0.62709  focal_loss 0.42573  dice_loss 0.20137 
Epoch [217/300] Validation [2/16] Loss: 0.47907  focal_loss 0.19482  dice_loss 0.28425 
Epoch [217/300] Validation [3/16] Loss: 0.65241  focal_loss 0.37388  dice_loss 0.27854 
Epoch [217/300] Validation [4/16] Loss: 0.32969  focal_loss 0.16809  dice_loss 0.16160 
Epoch [217/300] Validation [5/16] Loss: 0.29293  focal_loss 0.10174  dice_loss 0.19119 
Epoch [217/300] Validation [6/16] Loss: 0.30641  focal_loss 0.09842  dice_loss 0.20799 
Epoch [217/300] Validation [7/16] Loss: 0.21374  focal_loss 0.09096  dice_loss 0.12278 
Epoch [217/300] Validation [8/16] Loss: 0.41905  focal_loss 0.14949  dice_loss 0.26956 
Epoch [217/300] Validation [9/16] Loss: 0.22151  focal_loss 0.08433  dice_loss 0.13718 
Epoch [217/300] Validation [10/16] Loss: 0.51017  focal_loss 0.17488  dice_loss 0.33529 
Epoch [217/300] Validation [11/16] Loss: 0.13891  focal_loss 0.04567  dice_loss 0.09325 
Epoch [217/300] Validation [12/16] Loss: 0.36095  focal_loss 0.11207  dice_loss 0.24888 
Epoch [217/300] Validation [13/16] Loss: 0.24086  focal_loss 0.08498  dice_loss 0.15588 
Epoch [217/300] Validation [14/16] Loss: 0.54370  focal_loss 0.23395  dice_loss 0.30975 
Epoch [217/300] Validation [15/16] Loss: 0.10976  focal_loss 0.03614  dice_loss 0.07363 
Epoch [217/300] Validation [16/16] Loss: 0.09349  focal_loss 0.02064  dice_loss 0.07285 
Epoch [217/300] Validation metric {'Val/mean dice_metric': 0.9337709546089172, 'Val/mean miou_metric': 0.893470823764801, 'Val/mean f1': 0.9414841532707214, 'Val/mean precision': 0.9468233585357666, 'Val/mean recall': 0.9362047910690308, 'Val/mean hd95_metric': 17.297883987426758}
Cheakpoint...
Epoch [217/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9338], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9337709546089172, 'Val/mean miou_metric': 0.893470823764801, 'Val/mean f1': 0.9414841532707214, 'Val/mean precision': 0.9468233585357666, 'Val/mean recall': 0.9362047910690308, 'Val/mean hd95_metric': 17.297883987426758}
Epoch [218/300] Training [1/62] Loss: 0.06537 
Epoch [218/300] Training [2/62] Loss: 0.02861 
Epoch [218/300] Training [3/62] Loss: 0.03072 
Epoch [218/300] Training [4/62] Loss: 0.03844 
Epoch [218/300] Training [5/62] Loss: 0.03019 
Epoch [218/300] Training [6/62] Loss: 0.03787 
Epoch [218/300] Training [7/62] Loss: 0.06197 
Epoch [218/300] Training [8/62] Loss: 0.03569 
Epoch [218/300] Training [9/62] Loss: 0.04298 
Epoch [218/300] Training [10/62] Loss: 0.02900 
Epoch [218/300] Training [11/62] Loss: 0.03827 
Epoch [218/300] Training [12/62] Loss: 0.03957 
Epoch [218/300] Training [13/62] Loss: 0.03702 
Epoch [218/300] Training [14/62] Loss: 0.04861 
Epoch [218/300] Training [15/62] Loss: 0.02944 
Epoch [218/300] Training [16/62] Loss: 0.04697 
Epoch [218/300] Training [17/62] Loss: 0.05612 
Epoch [218/300] Training [18/62] Loss: 0.03104 
Epoch [218/300] Training [19/62] Loss: 0.03299 
Epoch [218/300] Training [20/62] Loss: 0.04295 
Epoch [218/300] Training [21/62] Loss: 0.04175 
Epoch [218/300] Training [22/62] Loss: 0.04545 
Epoch [218/300] Training [23/62] Loss: 0.05555 
Epoch [218/300] Training [24/62] Loss: 0.03344 
Epoch [218/300] Training [25/62] Loss: 0.03526 
Epoch [218/300] Training [26/62] Loss: 0.04658 
Epoch [218/300] Training [27/62] Loss: 0.06017 
Epoch [218/300] Training [28/62] Loss: 0.03374 
Epoch [218/300] Training [29/62] Loss: 0.04156 
Epoch [218/300] Training [30/62] Loss: 0.04907 
Epoch [218/300] Training [31/62] Loss: 0.03575 
Epoch [218/300] Training [32/62] Loss: 0.03266 
Epoch [218/300] Training [33/62] Loss: 0.22963 
Epoch [218/300] Training [34/62] Loss: 0.06252 
Epoch [218/300] Training [35/62] Loss: 0.07931 
Epoch [218/300] Training [36/62] Loss: 0.11197 
Epoch [218/300] Training [37/62] Loss: 0.04898 
Epoch [218/300] Training [38/62] Loss: 0.05465 
Epoch [218/300] Training [39/62] Loss: 0.03831 
Epoch [218/300] Training [40/62] Loss: 0.04570 
Epoch [218/300] Training [41/62] Loss: 0.04466 
Epoch [218/300] Training [42/62] Loss: 0.03956 
Epoch [218/300] Training [43/62] Loss: 0.04184 
Epoch [218/300] Training [44/62] Loss: 0.03061 
Epoch [218/300] Training [45/62] Loss: 0.03711 
Epoch [218/300] Training [46/62] Loss: 0.04253 
Epoch [218/300] Training [47/62] Loss: 0.03861 
Epoch [218/300] Training [48/62] Loss: 0.09919 
Epoch [218/300] Training [49/62] Loss: 0.03237 
Epoch [218/300] Training [50/62] Loss: 0.03642 
Epoch [218/300] Training [51/62] Loss: 0.07208 
Epoch [218/300] Training [52/62] Loss: 0.02513 
Epoch [218/300] Training [53/62] Loss: 0.06564 
Epoch [218/300] Training [54/62] Loss: 0.03304 
Epoch [218/300] Training [55/62] Loss: 0.04393 
Epoch [218/300] Training [56/62] Loss: 0.07484 
Epoch [218/300] Training [57/62] Loss: 0.06722 
Epoch [218/300] Training [58/62] Loss: 0.04357 
Epoch [218/300] Training [59/62] Loss: 0.03751 
Epoch [218/300] Training [60/62] Loss: 0.04752 
Epoch [218/300] Training [61/62] Loss: 0.08692 
Epoch [218/300] Training [62/62] Loss: 0.04964 
Epoch [218/300] Training metric {'Train/mean dice_metric': 0.9658829569816589, 'Train/mean miou_metric': 0.9383577108383179, 'Train/mean f1': 0.968993067741394, 'Train/mean precision': 0.9654042720794678, 'Train/mean recall': 0.9726086258888245, 'Train/mean hd95_metric': 8.712713241577148}
Epoch [218/300] Validation [1/16] Loss: 0.63527  focal_loss 0.43585  dice_loss 0.19941 
Epoch [218/300] Validation [2/16] Loss: 0.50742  focal_loss 0.20430  dice_loss 0.30313 
Epoch [218/300] Validation [3/16] Loss: 0.70568  focal_loss 0.41169  dice_loss 0.29400 
Epoch [218/300] Validation [4/16] Loss: 0.35477  focal_loss 0.17736  dice_loss 0.17741 
Epoch [218/300] Validation [5/16] Loss: 0.31096  focal_loss 0.11247  dice_loss 0.19849 
Epoch [218/300] Validation [6/16] Loss: 0.26611  focal_loss 0.07945  dice_loss 0.18666 
Epoch [218/300] Validation [7/16] Loss: 0.15871  focal_loss 0.06640  dice_loss 0.09231 
Epoch [218/300] Validation [8/16] Loss: 0.49446  focal_loss 0.17453  dice_loss 0.31993 
Epoch [218/300] Validation [9/16] Loss: 0.24913  focal_loss 0.09973  dice_loss 0.14940 
Epoch [218/300] Validation [10/16] Loss: 0.50305  focal_loss 0.15816  dice_loss 0.34489 
Epoch [218/300] Validation [11/16] Loss: 0.19601  focal_loss 0.07736  dice_loss 0.11865 
Epoch [218/300] Validation [12/16] Loss: 0.37194  focal_loss 0.10742  dice_loss 0.26453 
Epoch [218/300] Validation [13/16] Loss: 0.29841  focal_loss 0.12991  dice_loss 0.16850 
Epoch [218/300] Validation [14/16] Loss: 0.46630  focal_loss 0.20389  dice_loss 0.26241 
Epoch [218/300] Validation [15/16] Loss: 0.14089  focal_loss 0.05129  dice_loss 0.08960 
Epoch [218/300] Validation [16/16] Loss: 0.09726  focal_loss 0.03306  dice_loss 0.06419 
Epoch [218/300] Validation metric {'Val/mean dice_metric': 0.9317790269851685, 'Val/mean miou_metric': 0.8922470211982727, 'Val/mean f1': 0.9420221447944641, 'Val/mean precision': 0.9475616216659546, 'Val/mean recall': 0.9365469217300415, 'Val/mean hd95_metric': 16.219053268432617}
Cheakpoint...
Epoch [218/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9318], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9317790269851685, 'Val/mean miou_metric': 0.8922470211982727, 'Val/mean f1': 0.9420221447944641, 'Val/mean precision': 0.9475616216659546, 'Val/mean recall': 0.9365469217300415, 'Val/mean hd95_metric': 16.219053268432617}
Epoch [219/300] Training [1/62] Loss: 0.04736 
Epoch [219/300] Training [2/62] Loss: 0.06072 
Epoch [219/300] Training [3/62] Loss: 0.02988 
Epoch [219/300] Training [4/62] Loss: 0.06654 
Epoch [219/300] Training [5/62] Loss: 0.06489 
Epoch [219/300] Training [6/62] Loss: 0.02705 
Epoch [219/300] Training [7/62] Loss: 0.03836 
Epoch [219/300] Training [8/62] Loss: 0.04118 
Epoch [219/300] Training [9/62] Loss: 0.06208 
Epoch [219/300] Training [10/62] Loss: 0.06020 
Epoch [219/300] Training [11/62] Loss: 0.03581 
Epoch [219/300] Training [12/62] Loss: 0.09272 
Epoch [219/300] Training [13/62] Loss: 0.03143 
Epoch [219/300] Training [14/62] Loss: 0.15191 
Epoch [219/300] Training [15/62] Loss: 0.02825 
Epoch [219/300] Training [16/62] Loss: 0.03146 
Epoch [219/300] Training [17/62] Loss: 0.05626 
Epoch [219/300] Training [18/62] Loss: 0.06673 
Epoch [219/300] Training [19/62] Loss: 0.06549 
Epoch [219/300] Training [20/62] Loss: 0.02992 
Epoch [219/300] Training [21/62] Loss: 0.03624 
Epoch [219/300] Training [22/62] Loss: 0.05304 
Epoch [219/300] Training [23/62] Loss: 0.03976 
Epoch [219/300] Training [24/62] Loss: 0.05080 
Epoch [219/300] Training [25/62] Loss: 0.04581 
Epoch [219/300] Training [26/62] Loss: 0.03925 
Epoch [219/300] Training [27/62] Loss: 0.05361 
Epoch [219/300] Training [28/62] Loss: 0.09658 
Epoch [219/300] Training [29/62] Loss: 0.05068 
Epoch [219/300] Training [30/62] Loss: 0.08216 
Epoch [219/300] Training [31/62] Loss: 0.09305 
Epoch [219/300] Training [32/62] Loss: 0.04289 
Epoch [219/300] Training [33/62] Loss: 0.03242 
Epoch [219/300] Training [34/62] Loss: 0.03289 
Epoch [219/300] Training [35/62] Loss: 0.09019 
Epoch [219/300] Training [36/62] Loss: 0.04466 
Epoch [219/300] Training [37/62] Loss: 0.04214 
Epoch [219/300] Training [38/62] Loss: 0.05312 
Epoch [219/300] Training [39/62] Loss: 0.05780 
Epoch [219/300] Training [40/62] Loss: 0.02901 
Epoch [219/300] Training [41/62] Loss: 0.03229 
Epoch [219/300] Training [42/62] Loss: 0.03582 
Epoch [219/300] Training [43/62] Loss: 0.03785 
Epoch [219/300] Training [44/62] Loss: 0.07606 
Epoch [219/300] Training [45/62] Loss: 0.05643 
Epoch [219/300] Training [46/62] Loss: 0.04393 
Epoch [219/300] Training [47/62] Loss: 0.02437 
Epoch [219/300] Training [48/62] Loss: 0.03469 
Epoch [219/300] Training [49/62] Loss: 0.04102 
Epoch [219/300] Training [50/62] Loss: 0.04337 
Epoch [219/300] Training [51/62] Loss: 0.04877 
Epoch [219/300] Training [52/62] Loss: 0.11269 
Epoch [219/300] Training [53/62] Loss: 0.07960 
Epoch [219/300] Training [54/62] Loss: 0.03562 
Epoch [219/300] Training [55/62] Loss: 0.03472 
Epoch [219/300] Training [56/62] Loss: 0.05489 
Epoch [219/300] Training [57/62] Loss: 0.04122 
Epoch [219/300] Training [58/62] Loss: 0.03333 
Epoch [219/300] Training [59/62] Loss: 0.03879 
Epoch [219/300] Training [60/62] Loss: 0.02799 
Epoch [219/300] Training [61/62] Loss: 0.04982 
Epoch [219/300] Training [62/62] Loss: 0.03611 
Epoch [219/300] Training metric {'Train/mean dice_metric': 0.964843213558197, 'Train/mean miou_metric': 0.9354673624038696, 'Train/mean f1': 0.9682386517524719, 'Train/mean precision': 0.9640534520149231, 'Train/mean recall': 0.9724603891372681, 'Train/mean hd95_metric': 9.153772354125977}
Epoch [219/300] Validation [1/16] Loss: 0.73687  focal_loss 0.50217  dice_loss 0.23469 
Epoch [219/300] Validation [2/16] Loss: 0.53472  focal_loss 0.20803  dice_loss 0.32669 
Epoch [219/300] Validation [3/16] Loss: 0.61653  focal_loss 0.33312  dice_loss 0.28340 
Epoch [219/300] Validation [4/16] Loss: 0.32563  focal_loss 0.16632  dice_loss 0.15930 
Epoch [219/300] Validation [5/16] Loss: 0.40095  focal_loss 0.14766  dice_loss 0.25329 
Epoch [219/300] Validation [6/16] Loss: 0.30166  focal_loss 0.09473  dice_loss 0.20694 
Epoch [219/300] Validation [7/16] Loss: 0.16883  focal_loss 0.06509  dice_loss 0.10374 
Epoch [219/300] Validation [8/16] Loss: 0.50877  focal_loss 0.20350  dice_loss 0.30527 
Epoch [219/300] Validation [9/16] Loss: 0.28566  focal_loss 0.13897  dice_loss 0.14669 
Epoch [219/300] Validation [10/16] Loss: 0.54434  focal_loss 0.18113  dice_loss 0.36321 
Epoch [219/300] Validation [11/16] Loss: 0.16659  focal_loss 0.05909  dice_loss 0.10750 
Epoch [219/300] Validation [12/16] Loss: 0.48326  focal_loss 0.13068  dice_loss 0.35259 
Epoch [219/300] Validation [13/16] Loss: 0.30471  focal_loss 0.11598  dice_loss 0.18873 
Epoch [219/300] Validation [14/16] Loss: 0.58380  focal_loss 0.27219  dice_loss 0.31161 
Epoch [219/300] Validation [15/16] Loss: 0.14601  focal_loss 0.05405  dice_loss 0.09196 
Epoch [219/300] Validation [16/16] Loss: 0.11095  focal_loss 0.03156  dice_loss 0.07939 
Epoch [219/300] Validation metric {'Val/mean dice_metric': 0.9274463653564453, 'Val/mean miou_metric': 0.8858558535575867, 'Val/mean f1': 0.9385444521903992, 'Val/mean precision': 0.9423103928565979, 'Val/mean recall': 0.9348084926605225, 'Val/mean hd95_metric': 17.714033126831055}
Cheakpoint...
Epoch [219/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9274], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9274463653564453, 'Val/mean miou_metric': 0.8858558535575867, 'Val/mean f1': 0.9385444521903992, 'Val/mean precision': 0.9423103928565979, 'Val/mean recall': 0.9348084926605225, 'Val/mean hd95_metric': 17.714033126831055}
Epoch [220/300] Training [1/62] Loss: 0.03589 
Epoch [220/300] Training [2/62] Loss: 0.04910 
Epoch [220/300] Training [3/62] Loss: 0.07725 
Epoch [220/300] Training [4/62] Loss: 0.04331 
Epoch [220/300] Training [5/62] Loss: 0.04622 
Epoch [220/300] Training [6/62] Loss: 0.02571 
Epoch [220/300] Training [7/62] Loss: 0.04088 
Epoch [220/300] Training [8/62] Loss: 0.05268 
Epoch [220/300] Training [9/62] Loss: 0.03215 
Epoch [220/300] Training [10/62] Loss: 0.06804 
Epoch [220/300] Training [11/62] Loss: 0.04516 
Epoch [220/300] Training [12/62] Loss: 0.08015 
Epoch [220/300] Training [13/62] Loss: 0.15358 
Epoch [220/300] Training [14/62] Loss: 0.03818 
Epoch [220/300] Training [15/62] Loss: 0.02867 
Epoch [220/300] Training [16/62] Loss: 0.02878 
Epoch [220/300] Training [17/62] Loss: 0.03903 
Epoch [220/300] Training [18/62] Loss: 0.06633 
Epoch [220/300] Training [19/62] Loss: 0.04007 
Epoch [220/300] Training [20/62] Loss: 0.05583 
Epoch [220/300] Training [21/62] Loss: 0.15237 
Epoch [220/300] Training [22/62] Loss: 0.08544 
Epoch [220/300] Training [23/62] Loss: 0.03203 
Epoch [220/300] Training [24/62] Loss: 0.04664 
Epoch [220/300] Training [25/62] Loss: 0.02987 
Epoch [220/300] Training [26/62] Loss: 0.06141 
Epoch [220/300] Training [27/62] Loss: 0.08788 
Epoch [220/300] Training [28/62] Loss: 0.03164 
Epoch [220/300] Training [29/62] Loss: 0.08039 
Epoch [220/300] Training [30/62] Loss: 0.03767 
Epoch [220/300] Training [31/62] Loss: 0.08671 
Epoch [220/300] Training [32/62] Loss: 0.06346 
Epoch [220/300] Training [33/62] Loss: 0.03358 
Epoch [220/300] Training [34/62] Loss: 0.05993 
Epoch [220/300] Training [35/62] Loss: 0.02801 
Epoch [220/300] Training [36/62] Loss: 0.05871 
Epoch [220/300] Training [37/62] Loss: 0.05857 
Epoch [220/300] Training [38/62] Loss: 0.04020 
Epoch [220/300] Training [39/62] Loss: 0.08395 
Epoch [220/300] Training [40/62] Loss: 0.03899 
Epoch [220/300] Training [41/62] Loss: 0.03109 
Epoch [220/300] Training [42/62] Loss: 0.11472 
Epoch [220/300] Training [43/62] Loss: 0.04946 
Epoch [220/300] Training [44/62] Loss: 0.03193 
Epoch [220/300] Training [45/62] Loss: 0.02844 
Epoch [220/300] Training [46/62] Loss: 0.02896 
Epoch [220/300] Training [47/62] Loss: 0.04574 
Epoch [220/300] Training [48/62] Loss: 0.04748 
Epoch [220/300] Training [49/62] Loss: 0.05661 
Epoch [220/300] Training [50/62] Loss: 0.04694 
Epoch [220/300] Training [51/62] Loss: 0.06025 
Epoch [220/300] Training [52/62] Loss: 0.03303 
Epoch [220/300] Training [53/62] Loss: 0.04363 
Epoch [220/300] Training [54/62] Loss: 0.06134 
Epoch [220/300] Training [55/62] Loss: 0.05214 
Epoch [220/300] Training [56/62] Loss: 0.03499 
Epoch [220/300] Training [57/62] Loss: 0.03782 
Epoch [220/300] Training [58/62] Loss: 0.05589 
Epoch [220/300] Training [59/62] Loss: 0.07176 
Epoch [220/300] Training [60/62] Loss: 0.03564 
Epoch [220/300] Training [61/62] Loss: 0.03421 
Epoch [220/300] Training [62/62] Loss: 0.05624 
Epoch [220/300] Training metric {'Train/mean dice_metric': 0.9639333486557007, 'Train/mean miou_metric': 0.9345649480819702, 'Train/mean f1': 0.9668646454811096, 'Train/mean precision': 0.9640951752662659, 'Train/mean recall': 0.969650149345398, 'Train/mean hd95_metric': 8.858382225036621}
Epoch [220/300] Validation [1/16] Loss: 0.62218  focal_loss 0.41843  dice_loss 0.20375 
Epoch [220/300] Validation [2/16] Loss: 0.50102  focal_loss 0.21558  dice_loss 0.28543 
Epoch [220/300] Validation [3/16] Loss: 0.69994  focal_loss 0.41286  dice_loss 0.28708 
Epoch [220/300] Validation [4/16] Loss: 0.31998  focal_loss 0.16284  dice_loss 0.15714 
Epoch [220/300] Validation [5/16] Loss: 0.35759  focal_loss 0.12548  dice_loss 0.23211 
Epoch [220/300] Validation [6/16] Loss: 0.28545  focal_loss 0.09136  dice_loss 0.19409 
Epoch [220/300] Validation [7/16] Loss: 0.20996  focal_loss 0.08285  dice_loss 0.12711 
Epoch [220/300] Validation [8/16] Loss: 0.61699  focal_loss 0.22893  dice_loss 0.38805 
Epoch [220/300] Validation [9/16] Loss: 0.20726  focal_loss 0.08795  dice_loss 0.11931 
Epoch [220/300] Validation [10/16] Loss: 0.51089  focal_loss 0.16327  dice_loss 0.34762 
Epoch [220/300] Validation [11/16] Loss: 0.14244  focal_loss 0.04112  dice_loss 0.10132 
Epoch [220/300] Validation [12/16] Loss: 0.36952  focal_loss 0.11542  dice_loss 0.25410 
Epoch [220/300] Validation [13/16] Loss: 0.31468  focal_loss 0.12048  dice_loss 0.19420 
Epoch [220/300] Validation [14/16] Loss: 0.52298  focal_loss 0.23677  dice_loss 0.28622 
Epoch [220/300] Validation [15/16] Loss: 0.12798  focal_loss 0.04797  dice_loss 0.08001 
Epoch [220/300] Validation [16/16] Loss: 0.08349  focal_loss 0.02254  dice_loss 0.06094 
Epoch [220/300] Validation metric {'Val/mean dice_metric': 0.9293404221534729, 'Val/mean miou_metric': 0.8881438970565796, 'Val/mean f1': 0.9389559030532837, 'Val/mean precision': 0.9440116882324219, 'Val/mean recall': 0.9339540004730225, 'Val/mean hd95_metric': 17.854957580566406}
Cheakpoint...
Epoch [220/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9293], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9293404221534729, 'Val/mean miou_metric': 0.8881438970565796, 'Val/mean f1': 0.9389559030532837, 'Val/mean precision': 0.9440116882324219, 'Val/mean recall': 0.9339540004730225, 'Val/mean hd95_metric': 17.854957580566406}
Epoch [221/300] Training [1/62] Loss: 0.11031 
Epoch [221/300] Training [2/62] Loss: 0.03878 
Epoch [221/300] Training [3/62] Loss: 0.03662 
Epoch [221/300] Training [4/62] Loss: 0.04605 
Epoch [221/300] Training [5/62] Loss: 0.03798 
Epoch [221/300] Training [6/62] Loss: 0.03554 
Epoch [221/300] Training [7/62] Loss: 0.02462 
Epoch [221/300] Training [8/62] Loss: 0.05562 
Epoch [221/300] Training [9/62] Loss: 0.03406 
Epoch [221/300] Training [10/62] Loss: 0.06208 
Epoch [221/300] Training [11/62] Loss: 0.08072 
Epoch [221/300] Training [12/62] Loss: 0.04452 
Epoch [221/300] Training [13/62] Loss: 0.02494 
Epoch [221/300] Training [14/62] Loss: 0.02737 
Epoch [221/300] Training [15/62] Loss: 0.03110 
Epoch [221/300] Training [16/62] Loss: 0.04559 
Epoch [221/300] Training [17/62] Loss: 0.03659 
Epoch [221/300] Training [18/62] Loss: 0.04221 
Epoch [221/300] Training [19/62] Loss: 0.07547 
Epoch [221/300] Training [20/62] Loss: 0.03519 
Epoch [221/300] Training [21/62] Loss: 0.03478 
Epoch [221/300] Training [22/62] Loss: 0.09037 
Epoch [221/300] Training [23/62] Loss: 0.05966 
Epoch [221/300] Training [24/62] Loss: 0.03432 
Epoch [221/300] Training [25/62] Loss: 0.16006 
Epoch [221/300] Training [26/62] Loss: 0.03050 
Epoch [221/300] Training [27/62] Loss: 0.04968 
Epoch [221/300] Training [28/62] Loss: 0.08267 
Epoch [221/300] Training [29/62] Loss: 0.02469 
Epoch [221/300] Training [30/62] Loss: 0.03616 
Epoch [221/300] Training [31/62] Loss: 0.03735 
Epoch [221/300] Training [32/62] Loss: 0.03373 
Epoch [221/300] Training [33/62] Loss: 0.04071 
Epoch [221/300] Training [34/62] Loss: 0.05838 
Epoch [221/300] Training [35/62] Loss: 0.03284 
Epoch [221/300] Training [36/62] Loss: 0.03695 
Epoch [221/300] Training [37/62] Loss: 0.03629 
Epoch [221/300] Training [38/62] Loss: 0.07373 
Epoch [221/300] Training [39/62] Loss: 0.03608 
Epoch [221/300] Training [40/62] Loss: 0.03300 
Epoch [221/300] Training [41/62] Loss: 0.03248 
Epoch [221/300] Training [42/62] Loss: 0.03232 
Epoch [221/300] Training [43/62] Loss: 0.05947 
Epoch [221/300] Training [44/62] Loss: 0.02688 
Epoch [221/300] Training [45/62] Loss: 0.02650 
Epoch [221/300] Training [46/62] Loss: 0.03340 
Epoch [221/300] Training [47/62] Loss: 0.18497 
Epoch [221/300] Training [48/62] Loss: 0.05300 
Epoch [221/300] Training [49/62] Loss: 0.03251 
Epoch [221/300] Training [50/62] Loss: 0.04042 
Epoch [221/300] Training [51/62] Loss: 0.05852 
Epoch [221/300] Training [52/62] Loss: 0.03660 
Epoch [221/300] Training [53/62] Loss: 0.04910 
Epoch [221/300] Training [54/62] Loss: 0.03683 
Epoch [221/300] Training [55/62] Loss: 0.03161 
Epoch [221/300] Training [56/62] Loss: 0.03497 
Epoch [221/300] Training [57/62] Loss: 0.03199 
Epoch [221/300] Training [58/62] Loss: 0.04720 
Epoch [221/300] Training [59/62] Loss: 0.03697 
Epoch [221/300] Training [60/62] Loss: 0.07438 
Epoch [221/300] Training [61/62] Loss: 0.03693 
Epoch [221/300] Training [62/62] Loss: 0.04952 
Epoch [221/300] Training metric {'Train/mean dice_metric': 0.9666606783866882, 'Train/mean miou_metric': 0.9400917291641235, 'Train/mean f1': 0.9698014855384827, 'Train/mean precision': 0.9653155207633972, 'Train/mean recall': 0.9743293523788452, 'Train/mean hd95_metric': 7.3663105964660645}
Epoch [221/300] Validation [1/16] Loss: 0.71357  focal_loss 0.49194  dice_loss 0.22163 
Epoch [221/300] Validation [2/16] Loss: 0.55530  focal_loss 0.22111  dice_loss 0.33419 
Epoch [221/300] Validation [3/16] Loss: 0.73420  focal_loss 0.42078  dice_loss 0.31342 
Epoch [221/300] Validation [4/16] Loss: 0.31942  focal_loss 0.15900  dice_loss 0.16042 
Epoch [221/300] Validation [5/16] Loss: 0.31512  focal_loss 0.11784  dice_loss 0.19728 
Epoch [221/300] Validation [6/16] Loss: 0.28722  focal_loss 0.09649  dice_loss 0.19074 
Epoch [221/300] Validation [7/16] Loss: 0.30666  focal_loss 0.11398  dice_loss 0.19268 
Epoch [221/300] Validation [8/16] Loss: 0.46080  focal_loss 0.18110  dice_loss 0.27970 
Epoch [221/300] Validation [9/16] Loss: 0.24101  focal_loss 0.09866  dice_loss 0.14236 
Epoch [221/300] Validation [10/16] Loss: 0.53236  focal_loss 0.18690  dice_loss 0.34546 
Epoch [221/300] Validation [11/16] Loss: 0.13462  focal_loss 0.04881  dice_loss 0.08581 
Epoch [221/300] Validation [12/16] Loss: 0.51817  focal_loss 0.12153  dice_loss 0.39664 
Epoch [221/300] Validation [13/16] Loss: 0.25773  focal_loss 0.09983  dice_loss 0.15790 
Epoch [221/300] Validation [14/16] Loss: 0.58699  focal_loss 0.28314  dice_loss 0.30385 
Epoch [221/300] Validation [15/16] Loss: 0.13734  focal_loss 0.05862  dice_loss 0.07872 
Epoch [221/300] Validation [16/16] Loss: 0.16185  focal_loss 0.05436  dice_loss 0.10750 
Epoch [221/300] Validation metric {'Val/mean dice_metric': 0.9292179942131042, 'Val/mean miou_metric': 0.8909323811531067, 'Val/mean f1': 0.9414594769477844, 'Val/mean precision': 0.947373628616333, 'Val/mean recall': 0.9356186985969543, 'Val/mean hd95_metric': 16.839828491210938}
Cheakpoint...
Epoch [221/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9292], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9292179942131042, 'Val/mean miou_metric': 0.8909323811531067, 'Val/mean f1': 0.9414594769477844, 'Val/mean precision': 0.947373628616333, 'Val/mean recall': 0.9356186985969543, 'Val/mean hd95_metric': 16.839828491210938}
Epoch [222/300] Training [1/62] Loss: 0.03602 
Epoch [222/300] Training [2/62] Loss: 0.05341 
Epoch [222/300] Training [3/62] Loss: 0.08040 
Epoch [222/300] Training [4/62] Loss: 0.12627 
Epoch [222/300] Training [5/62] Loss: 0.03811 
Epoch [222/300] Training [6/62] Loss: 0.04312 
Epoch [222/300] Training [7/62] Loss: 0.04216 
Epoch [222/300] Training [8/62] Loss: 0.06435 
Epoch [222/300] Training [9/62] Loss: 0.03374 
Epoch [222/300] Training [10/62] Loss: 0.04815 
Epoch [222/300] Training [11/62] Loss: 0.19489 
Epoch [222/300] Training [12/62] Loss: 0.12047 
Epoch [222/300] Training [13/62] Loss: 0.05577 
Epoch [222/300] Training [14/62] Loss: 0.02767 
Epoch [222/300] Training [15/62] Loss: 0.06391 
Epoch [222/300] Training [16/62] Loss: 0.08815 
Epoch [222/300] Training [17/62] Loss: 0.03296 
Epoch [222/300] Training [18/62] Loss: 0.05863 
Epoch [222/300] Training [19/62] Loss: 0.02368 
Epoch [222/300] Training [20/62] Loss: 0.05526 
Epoch [222/300] Training [21/62] Loss: 0.09610 
Epoch [222/300] Training [22/62] Loss: 0.02569 
Epoch [222/300] Training [23/62] Loss: 0.05721 
Epoch [222/300] Training [24/62] Loss: 0.04608 
Epoch [222/300] Training [25/62] Loss: 0.03971 
Epoch [222/300] Training [26/62] Loss: 0.06599 
Epoch [222/300] Training [27/62] Loss: 0.03958 
Epoch [222/300] Training [28/62] Loss: 0.03006 
Epoch [222/300] Training [29/62] Loss: 0.07094 
Epoch [222/300] Training [30/62] Loss: 0.03872 
Epoch [222/300] Training [31/62] Loss: 0.07113 
Epoch [222/300] Training [32/62] Loss: 0.06241 
Epoch [222/300] Training [33/62] Loss: 0.07154 
Epoch [222/300] Training [34/62] Loss: 0.04422 
Epoch [222/300] Training [35/62] Loss: 0.04652 
Epoch [222/300] Training [36/62] Loss: 0.02758 
Epoch [222/300] Training [37/62] Loss: 0.03150 
Epoch [222/300] Training [38/62] Loss: 0.03338 
Epoch [222/300] Training [39/62] Loss: 0.05738 
Epoch [222/300] Training [40/62] Loss: 0.04236 
Epoch [222/300] Training [41/62] Loss: 0.03204 
Epoch [222/300] Training [42/62] Loss: 0.04816 
Epoch [222/300] Training [43/62] Loss: 0.04292 
Epoch [222/300] Training [44/62] Loss: 0.04895 
Epoch [222/300] Training [45/62] Loss: 0.06915 
Epoch [222/300] Training [46/62] Loss: 0.03854 
Epoch [222/300] Training [47/62] Loss: 0.04420 
Epoch [222/300] Training [48/62] Loss: 0.02961 
Epoch [222/300] Training [49/62] Loss: 0.03986 
Epoch [222/300] Training [50/62] Loss: 0.03013 
Epoch [222/300] Training [51/62] Loss: 0.11618 
Epoch [222/300] Training [52/62] Loss: 0.03934 
Epoch [222/300] Training [53/62] Loss: 0.07372 
Epoch [222/300] Training [54/62] Loss: 0.03725 
Epoch [222/300] Training [55/62] Loss: 0.03518 
Epoch [222/300] Training [56/62] Loss: 0.03346 
Epoch [222/300] Training [57/62] Loss: 0.03336 
Epoch [222/300] Training [58/62] Loss: 0.05279 
Epoch [222/300] Training [59/62] Loss: 0.04746 
Epoch [222/300] Training [60/62] Loss: 0.03297 
Epoch [222/300] Training [61/62] Loss: 0.03321 
Epoch [222/300] Training [62/62] Loss: 0.02208 
Epoch [222/300] Training metric {'Train/mean dice_metric': 0.9641826152801514, 'Train/mean miou_metric': 0.935160219669342, 'Train/mean f1': 0.9671978950500488, 'Train/mean precision': 0.9642890691757202, 'Train/mean recall': 0.9701244235038757, 'Train/mean hd95_metric': 7.819407939910889}
Epoch [222/300] Validation [1/16] Loss: 0.63890  focal_loss 0.42305  dice_loss 0.21585 
Epoch [222/300] Validation [2/16] Loss: 0.46233  focal_loss 0.19852  dice_loss 0.26381 
Epoch [222/300] Validation [3/16] Loss: 0.65688  focal_loss 0.37653  dice_loss 0.28035 
Epoch [222/300] Validation [4/16] Loss: 0.29441  focal_loss 0.15059  dice_loss 0.14383 
Epoch [222/300] Validation [5/16] Loss: 0.31330  focal_loss 0.11123  dice_loss 0.20207 
Epoch [222/300] Validation [6/16] Loss: 0.28846  focal_loss 0.09340  dice_loss 0.19506 
Epoch [222/300] Validation [7/16] Loss: 0.16402  focal_loss 0.06952  dice_loss 0.09450 
Epoch [222/300] Validation [8/16] Loss: 0.51499  focal_loss 0.19397  dice_loss 0.32102 
Epoch [222/300] Validation [9/16] Loss: 0.19862  focal_loss 0.08530  dice_loss 0.11331 
Epoch [222/300] Validation [10/16] Loss: 0.52551  focal_loss 0.17837  dice_loss 0.34714 
Epoch [222/300] Validation [11/16] Loss: 0.12865  focal_loss 0.04112  dice_loss 0.08752 
Epoch [222/300] Validation [12/16] Loss: 0.39005  focal_loss 0.11917  dice_loss 0.27088 
Epoch [222/300] Validation [13/16] Loss: 0.20496  focal_loss 0.07036  dice_loss 0.13460 
Epoch [222/300] Validation [14/16] Loss: 0.59705  focal_loss 0.25203  dice_loss 0.34502 
Epoch [222/300] Validation [15/16] Loss: 0.10854  focal_loss 0.03897  dice_loss 0.06957 
Epoch [222/300] Validation [16/16] Loss: 0.09014  focal_loss 0.02745  dice_loss 0.06269 
Epoch [222/300] Validation metric {'Val/mean dice_metric': 0.931492805480957, 'Val/mean miou_metric': 0.8920894265174866, 'Val/mean f1': 0.9410284757614136, 'Val/mean precision': 0.948777437210083, 'Val/mean recall': 0.9334049820899963, 'Val/mean hd95_metric': 15.839625358581543}
Cheakpoint...
Epoch [222/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9315], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.931492805480957, 'Val/mean miou_metric': 0.8920894265174866, 'Val/mean f1': 0.9410284757614136, 'Val/mean precision': 0.948777437210083, 'Val/mean recall': 0.9334049820899963, 'Val/mean hd95_metric': 15.839625358581543}
Epoch [223/300] Training [1/62] Loss: 0.03274 
Epoch [223/300] Training [2/62] Loss: 0.03524 
Epoch [223/300] Training [3/62] Loss: 0.02930 
Epoch [223/300] Training [4/62] Loss: 0.02755 
Epoch [223/300] Training [5/62] Loss: 0.03249 
Epoch [223/300] Training [6/62] Loss: 0.06069 
Epoch [223/300] Training [7/62] Loss: 0.05452 
Epoch [223/300] Training [8/62] Loss: 0.02089 
Epoch [223/300] Training [9/62] Loss: 0.02681 
Epoch [223/300] Training [10/62] Loss: 0.04944 
Epoch [223/300] Training [11/62] Loss: 0.15646 
Epoch [223/300] Training [12/62] Loss: 0.05796 
Epoch [223/300] Training [13/62] Loss: 0.03220 
Epoch [223/300] Training [14/62] Loss: 0.03953 
Epoch [223/300] Training [15/62] Loss: 0.03619 
Epoch [223/300] Training [16/62] Loss: 0.02617 
Epoch [223/300] Training [17/62] Loss: 0.03385 
Epoch [223/300] Training [18/62] Loss: 0.06460 
Epoch [223/300] Training [19/62] Loss: 0.03526 
Epoch [223/300] Training [20/62] Loss: 0.03152 
Epoch [223/300] Training [21/62] Loss: 0.05046 
Epoch [223/300] Training [22/62] Loss: 0.05490 
Epoch [223/300] Training [23/62] Loss: 0.04981 
Epoch [223/300] Training [24/62] Loss: 0.08144 
Epoch [223/300] Training [25/62] Loss: 0.03407 
Epoch [223/300] Training [26/62] Loss: 0.02524 
Epoch [223/300] Training [27/62] Loss: 0.02269 
Epoch [223/300] Training [28/62] Loss: 0.07739 
Epoch [223/300] Training [29/62] Loss: 0.03830 
Epoch [223/300] Training [30/62] Loss: 0.04135 
Epoch [223/300] Training [31/62] Loss: 0.03464 
Epoch [223/300] Training [32/62] Loss: 0.07543 
Epoch [223/300] Training [33/62] Loss: 0.03034 
Epoch [223/300] Training [34/62] Loss: 0.07402 
Epoch [223/300] Training [35/62] Loss: 0.04054 
Epoch [223/300] Training [36/62] Loss: 0.04164 
Epoch [223/300] Training [37/62] Loss: 0.02971 
Epoch [223/300] Training [38/62] Loss: 0.04189 
Epoch [223/300] Training [39/62] Loss: 0.02770 
Epoch [223/300] Training [40/62] Loss: 0.04792 
Epoch [223/300] Training [41/62] Loss: 0.03600 
Epoch [223/300] Training [42/62] Loss: 0.03709 
Epoch [223/300] Training [43/62] Loss: 0.03011 
Epoch [223/300] Training [44/62] Loss: 0.10785 
Epoch [223/300] Training [45/62] Loss: 0.04368 
Epoch [223/300] Training [46/62] Loss: 0.09157 
Epoch [223/300] Training [47/62] Loss: 0.02992 
Epoch [223/300] Training [48/62] Loss: 0.02986 
Epoch [223/300] Training [49/62] Loss: 0.12841 
Epoch [223/300] Training [50/62] Loss: 0.04357 
Epoch [223/300] Training [51/62] Loss: 0.05149 
Epoch [223/300] Training [52/62] Loss: 0.05070 
Epoch [223/300] Training [53/62] Loss: 0.03420 
Epoch [223/300] Training [54/62] Loss: 0.03892 
Epoch [223/300] Training [55/62] Loss: 0.04222 
Epoch [223/300] Training [56/62] Loss: 0.06397 
Epoch [223/300] Training [57/62] Loss: 0.15049 
Epoch [223/300] Training [58/62] Loss: 0.03398 
Epoch [223/300] Training [59/62] Loss: 0.02903 
Epoch [223/300] Training [60/62] Loss: 0.02502 
Epoch [223/300] Training [61/62] Loss: 0.07701 
Epoch [223/300] Training [62/62] Loss: 0.09592 
Epoch [223/300] Training metric {'Train/mean dice_metric': 0.9662812352180481, 'Train/mean miou_metric': 0.9391495585441589, 'Train/mean f1': 0.9693746566772461, 'Train/mean precision': 0.9649348258972168, 'Train/mean recall': 0.9738556146621704, 'Train/mean hd95_metric': 7.386617183685303}
Epoch [223/300] Validation [1/16] Loss: 0.77191  focal_loss 0.53400  dice_loss 0.23791 
Epoch [223/300] Validation [2/16] Loss: 0.54110  focal_loss 0.20884  dice_loss 0.33226 
Epoch [223/300] Validation [3/16] Loss: 0.66144  focal_loss 0.36617  dice_loss 0.29527 
Epoch [223/300] Validation [4/16] Loss: 0.34245  focal_loss 0.15522  dice_loss 0.18723 
Epoch [223/300] Validation [5/16] Loss: 0.43573  focal_loss 0.14402  dice_loss 0.29172 
Epoch [223/300] Validation [6/16] Loss: 0.32992  focal_loss 0.10567  dice_loss 0.22425 
Epoch [223/300] Validation [7/16] Loss: 0.30143  focal_loss 0.11500  dice_loss 0.18643 
Epoch [223/300] Validation [8/16] Loss: 0.55699  focal_loss 0.19847  dice_loss 0.35852 
Epoch [223/300] Validation [9/16] Loss: 0.16779  focal_loss 0.06584  dice_loss 0.10194 
Epoch [223/300] Validation [10/16] Loss: 0.51579  focal_loss 0.18580  dice_loss 0.32999 
Epoch [223/300] Validation [11/16] Loss: 0.13294  focal_loss 0.04637  dice_loss 0.08658 
Epoch [223/300] Validation [12/16] Loss: 0.38299  focal_loss 0.11990  dice_loss 0.26309 
Epoch [223/300] Validation [13/16] Loss: 0.26528  focal_loss 0.09844  dice_loss 0.16684 
Epoch [223/300] Validation [14/16] Loss: 0.60898  focal_loss 0.26304  dice_loss 0.34594 
Epoch [223/300] Validation [15/16] Loss: 0.14410  focal_loss 0.05468  dice_loss 0.08943 
Epoch [223/300] Validation [16/16] Loss: 0.14915  focal_loss 0.04877  dice_loss 0.10038 
Epoch [223/300] Validation metric {'Val/mean dice_metric': 0.9276574850082397, 'Val/mean miou_metric': 0.8895487189292908, 'Val/mean f1': 0.9412487745285034, 'Val/mean precision': 0.9482897520065308, 'Val/mean recall': 0.9343116283416748, 'Val/mean hd95_metric': 16.808732986450195}
Cheakpoint...
Epoch [223/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9277], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9276574850082397, 'Val/mean miou_metric': 0.8895487189292908, 'Val/mean f1': 0.9412487745285034, 'Val/mean precision': 0.9482897520065308, 'Val/mean recall': 0.9343116283416748, 'Val/mean hd95_metric': 16.808732986450195}
Epoch [224/300] Training [1/62] Loss: 0.03370 
Epoch [224/300] Training [2/62] Loss: 0.05084 
Epoch [224/300] Training [3/62] Loss: 0.07411 
Epoch [224/300] Training [4/62] Loss: 0.08874 
Epoch [224/300] Training [5/62] Loss: 0.04188 
Epoch [224/300] Training [6/62] Loss: 0.02972 
Epoch [224/300] Training [7/62] Loss: 0.02786 
Epoch [224/300] Training [8/62] Loss: 0.03319 
Epoch [224/300] Training [9/62] Loss: 0.11410 
Epoch [224/300] Training [10/62] Loss: 0.04163 
Epoch [224/300] Training [11/62] Loss: 0.02789 
Epoch [224/300] Training [12/62] Loss: 0.11948 
Epoch [224/300] Training [13/62] Loss: 0.04855 
Epoch [224/300] Training [14/62] Loss: 0.02850 
Epoch [224/300] Training [15/62] Loss: 0.05081 
Epoch [224/300] Training [16/62] Loss: 0.02933 
Epoch [224/300] Training [17/62] Loss: 0.03212 
Epoch [224/300] Training [18/62] Loss: 0.02623 
Epoch [224/300] Training [19/62] Loss: 0.04086 
Epoch [224/300] Training [20/62] Loss: 0.05153 
Epoch [224/300] Training [21/62] Loss: 0.03444 
Epoch [224/300] Training [22/62] Loss: 0.06424 
Epoch [224/300] Training [23/62] Loss: 0.03333 
Epoch [224/300] Training [24/62] Loss: 0.06825 
Epoch [224/300] Training [25/62] Loss: 0.02855 
Epoch [224/300] Training [26/62] Loss: 0.06279 
Epoch [224/300] Training [27/62] Loss: 0.07997 
Epoch [224/300] Training [28/62] Loss: 0.03716 
Epoch [224/300] Training [29/62] Loss: 0.05036 
Epoch [224/300] Training [30/62] Loss: 0.02371 
Epoch [224/300] Training [31/62] Loss: 0.04677 
Epoch [224/300] Training [32/62] Loss: 0.05350 
Epoch [224/300] Training [33/62] Loss: 0.10361 
Epoch [224/300] Training [34/62] Loss: 0.02989 
Epoch [224/300] Training [35/62] Loss: 0.02649 
Epoch [224/300] Training [36/62] Loss: 0.04262 
Epoch [224/300] Training [37/62] Loss: 0.03048 
Epoch [224/300] Training [38/62] Loss: 0.03313 
Epoch [224/300] Training [39/62] Loss: 0.03078 
Epoch [224/300] Training [40/62] Loss: 0.03220 
Epoch [224/300] Training [41/62] Loss: 0.03268 
Epoch [224/300] Training [42/62] Loss: 0.05225 
Epoch [224/300] Training [43/62] Loss: 0.03058 
Epoch [224/300] Training [44/62] Loss: 0.05065 
Epoch [224/300] Training [45/62] Loss: 0.06607 
Epoch [224/300] Training [46/62] Loss: 0.03767 
Epoch [224/300] Training [47/62] Loss: 0.10427 
Epoch [224/300] Training [48/62] Loss: 0.03402 
Epoch [224/300] Training [49/62] Loss: 0.05032 
Epoch [224/300] Training [50/62] Loss: 0.02895 
Epoch [224/300] Training [51/62] Loss: 0.03059 
Epoch [224/300] Training [52/62] Loss: 0.03627 
Epoch [224/300] Training [53/62] Loss: 0.03427 
Epoch [224/300] Training [54/62] Loss: 0.04725 
Epoch [224/300] Training [55/62] Loss: 0.16048 
Epoch [224/300] Training [56/62] Loss: 0.02849 
Epoch [224/300] Training [57/62] Loss: 0.05089 
Epoch [224/300] Training [58/62] Loss: 0.02892 
Epoch [224/300] Training [59/62] Loss: 0.03413 
Epoch [224/300] Training [60/62] Loss: 0.07323 
Epoch [224/300] Training [61/62] Loss: 0.02763 
Epoch [224/300] Training [62/62] Loss: 0.11434 
Epoch [224/300] Training metric {'Train/mean dice_metric': 0.9662521481513977, 'Train/mean miou_metric': 0.9398640990257263, 'Train/mean f1': 0.9701834321022034, 'Train/mean precision': 0.9651558995246887, 'Train/mean recall': 0.9752634167671204, 'Train/mean hd95_metric': 7.758578300476074}
Epoch [224/300] Validation [1/16] Loss: 0.61418  focal_loss 0.42490  dice_loss 0.18928 
Epoch [224/300] Validation [2/16] Loss: 0.48661  focal_loss 0.20601  dice_loss 0.28060 
Epoch [224/300] Validation [3/16] Loss: 0.66922  focal_loss 0.38549  dice_loss 0.28373 
Epoch [224/300] Validation [4/16] Loss: 0.32416  focal_loss 0.17101  dice_loss 0.15315 
Epoch [224/300] Validation [5/16] Loss: 0.34096  focal_loss 0.11949  dice_loss 0.22148 
Epoch [224/300] Validation [6/16] Loss: 0.30726  focal_loss 0.10083  dice_loss 0.20643 
Epoch [224/300] Validation [7/16] Loss: 0.15251  focal_loss 0.06717  dice_loss 0.08534 
Epoch [224/300] Validation [8/16] Loss: 0.47600  focal_loss 0.18871  dice_loss 0.28729 
Epoch [224/300] Validation [9/16] Loss: 0.21731  focal_loss 0.09615  dice_loss 0.12117 
Epoch [224/300] Validation [10/16] Loss: 0.54319  focal_loss 0.20778  dice_loss 0.33540 
Epoch [224/300] Validation [11/16] Loss: 0.15371  focal_loss 0.05317  dice_loss 0.10054 
Epoch [224/300] Validation [12/16] Loss: 0.38655  focal_loss 0.11998  dice_loss 0.26658 
Epoch [224/300] Validation [13/16] Loss: 0.24319  focal_loss 0.08756  dice_loss 0.15562 
Epoch [224/300] Validation [14/16] Loss: 0.58356  focal_loss 0.25521  dice_loss 0.32835 
Epoch [224/300] Validation [15/16] Loss: 0.11540  focal_loss 0.03954  dice_loss 0.07586 
Epoch [224/300] Validation [16/16] Loss: 0.13992  focal_loss 0.04501  dice_loss 0.09491 
Epoch [224/300] Validation metric {'Val/mean dice_metric': 0.9329004287719727, 'Val/mean miou_metric': 0.8944332003593445, 'Val/mean f1': 0.9428356885910034, 'Val/mean precision': 0.9451376795768738, 'Val/mean recall': 0.9405449032783508, 'Val/mean hd95_metric': 16.181724548339844}
Cheakpoint...
Epoch [224/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9329], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9329004287719727, 'Val/mean miou_metric': 0.8944332003593445, 'Val/mean f1': 0.9428356885910034, 'Val/mean precision': 0.9451376795768738, 'Val/mean recall': 0.9405449032783508, 'Val/mean hd95_metric': 16.181724548339844}
Epoch [225/300] Training [1/62] Loss: 0.04054 
Epoch [225/300] Training [2/62] Loss: 0.03273 
Epoch [225/300] Training [3/62] Loss: 0.05078 
Epoch [225/300] Training [4/62] Loss: 0.04305 
Epoch [225/300] Training [5/62] Loss: 0.04004 
Epoch [225/300] Training [6/62] Loss: 0.05791 
Epoch [225/300] Training [7/62] Loss: 0.03458 
Epoch [225/300] Training [8/62] Loss: 0.03794 
Epoch [225/300] Training [9/62] Loss: 0.03468 
Epoch [225/300] Training [10/62] Loss: 0.13954 
Epoch [225/300] Training [11/62] Loss: 0.03698 
Epoch [225/300] Training [12/62] Loss: 0.03289 
Epoch [225/300] Training [13/62] Loss: 0.03638 
Epoch [225/300] Training [14/62] Loss: 0.03572 
Epoch [225/300] Training [15/62] Loss: 0.04002 
Epoch [225/300] Training [16/62] Loss: 0.02288 
Epoch [225/300] Training [17/62] Loss: 0.05430 
Epoch [225/300] Training [18/62] Loss: 0.04204 
Epoch [225/300] Training [19/62] Loss: 0.03586 
Epoch [225/300] Training [20/62] Loss: 0.03325 
Epoch [225/300] Training [21/62] Loss: 0.08144 
Epoch [225/300] Training [22/62] Loss: 0.11176 
Epoch [225/300] Training [23/62] Loss: 0.03245 
Epoch [225/300] Training [24/62] Loss: 0.06395 
Epoch [225/300] Training [25/62] Loss: 0.03566 
Epoch [225/300] Training [26/62] Loss: 0.04752 
Epoch [225/300] Training [27/62] Loss: 0.05838 
Epoch [225/300] Training [28/62] Loss: 0.03918 
Epoch [225/300] Training [29/62] Loss: 0.03744 
Epoch [225/300] Training [30/62] Loss: 0.04215 
Epoch [225/300] Training [31/62] Loss: 0.05680 
Epoch [225/300] Training [32/62] Loss: 0.05342 
Epoch [225/300] Training [33/62] Loss: 0.03161 
Epoch [225/300] Training [34/62] Loss: 0.02895 
Epoch [225/300] Training [35/62] Loss: 0.06089 
Epoch [225/300] Training [36/62] Loss: 0.06255 
Epoch [225/300] Training [37/62] Loss: 0.08220 
Epoch [225/300] Training [38/62] Loss: 0.03910 
Epoch [225/300] Training [39/62] Loss: 0.03590 
Epoch [225/300] Training [40/62] Loss: 0.02479 
Epoch [225/300] Training [41/62] Loss: 0.04683 
Epoch [225/300] Training [42/62] Loss: 0.05428 
Epoch [225/300] Training [43/62] Loss: 0.11654 
Epoch [225/300] Training [44/62] Loss: 0.03527 
Epoch [225/300] Training [45/62] Loss: 0.04260 
Epoch [225/300] Training [46/62] Loss: 0.03153 
Epoch [225/300] Training [47/62] Loss: 0.04484 
Epoch [225/300] Training [48/62] Loss: 0.04116 
Epoch [225/300] Training [49/62] Loss: 0.02510 
Epoch [225/300] Training [50/62] Loss: 0.02569 
Epoch [225/300] Training [51/62] Loss: 0.03358 
Epoch [225/300] Training [52/62] Loss: 0.03811 
Epoch [225/300] Training [53/62] Loss: 0.04321 
Epoch [225/300] Training [54/62] Loss: 0.06571 
Epoch [225/300] Training [55/62] Loss: 0.04255 
Epoch [225/300] Training [56/62] Loss: 0.03834 
Epoch [225/300] Training [57/62] Loss: 0.02379 
Epoch [225/300] Training [58/62] Loss: 0.15970 
Epoch [225/300] Training [59/62] Loss: 0.06125 
Epoch [225/300] Training [60/62] Loss: 0.07170 
Epoch [225/300] Training [61/62] Loss: 0.03867 
Epoch [225/300] Training [62/62] Loss: 0.05467 
Epoch [225/300] Training metric {'Train/mean dice_metric': 0.9661806225776672, 'Train/mean miou_metric': 0.9395887851715088, 'Train/mean f1': 0.9697403907775879, 'Train/mean precision': 0.9672925472259521, 'Train/mean recall': 0.9722006916999817, 'Train/mean hd95_metric': 7.227368354797363}
Epoch [225/300] Validation [1/16] Loss: 0.65009  focal_loss 0.44366  dice_loss 0.20643 
Epoch [225/300] Validation [2/16] Loss: 0.47404  focal_loss 0.19658  dice_loss 0.27746 
Epoch [225/300] Validation [3/16] Loss: 0.64050  focal_loss 0.35491  dice_loss 0.28559 
Epoch [225/300] Validation [4/16] Loss: 0.32018  focal_loss 0.14879  dice_loss 0.17139 
Epoch [225/300] Validation [5/16] Loss: 0.35535  focal_loss 0.13457  dice_loss 0.22078 
Epoch [225/300] Validation [6/16] Loss: 0.31790  focal_loss 0.10294  dice_loss 0.21496 
Epoch [225/300] Validation [7/16] Loss: 0.24637  focal_loss 0.09208  dice_loss 0.15429 
Epoch [225/300] Validation [8/16] Loss: 0.52929  focal_loss 0.21334  dice_loss 0.31594 
Epoch [225/300] Validation [9/16] Loss: 0.22866  focal_loss 0.09414  dice_loss 0.13451 
Epoch [225/300] Validation [10/16] Loss: 0.52884  focal_loss 0.18683  dice_loss 0.34201 
Epoch [225/300] Validation [11/16] Loss: 0.15017  focal_loss 0.05120  dice_loss 0.09898 
Epoch [225/300] Validation [12/16] Loss: 0.44622  focal_loss 0.11338  dice_loss 0.33284 
Epoch [225/300] Validation [13/16] Loss: 0.21882  focal_loss 0.07613  dice_loss 0.14268 
Epoch [225/300] Validation [14/16] Loss: 0.58640  focal_loss 0.27489  dice_loss 0.31151 
Epoch [225/300] Validation [15/16] Loss: 0.09741  focal_loss 0.03347  dice_loss 0.06394 
Epoch [225/300] Validation [16/16] Loss: 0.09432  focal_loss 0.02774  dice_loss 0.06658 
Epoch [225/300] Validation metric {'Val/mean dice_metric': 0.9305757880210876, 'Val/mean miou_metric': 0.8924621343612671, 'Val/mean f1': 0.9426214694976807, 'Val/mean precision': 0.9512274265289307, 'Val/mean recall': 0.9341697692871094, 'Val/mean hd95_metric': 15.551677703857422}
Cheakpoint...
Epoch [225/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9306], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9305757880210876, 'Val/mean miou_metric': 0.8924621343612671, 'Val/mean f1': 0.9426214694976807, 'Val/mean precision': 0.9512274265289307, 'Val/mean recall': 0.9341697692871094, 'Val/mean hd95_metric': 15.551677703857422}
Epoch [226/300] Training [1/62] Loss: 0.03136 
Epoch [226/300] Training [2/62] Loss: 0.03641 
Epoch [226/300] Training [3/62] Loss: 0.02691 
Epoch [226/300] Training [4/62] Loss: 0.03368 
Epoch [226/300] Training [5/62] Loss: 0.11796 
Epoch [226/300] Training [6/62] Loss: 0.03124 
Epoch [226/300] Training [7/62] Loss: 0.05052 
Epoch [226/300] Training [8/62] Loss: 0.05530 
Epoch [226/300] Training [9/62] Loss: 0.03666 
Epoch [226/300] Training [10/62] Loss: 0.03699 
Epoch [226/300] Training [11/62] Loss: 0.07082 
Epoch [226/300] Training [12/62] Loss: 0.02778 
Epoch [226/300] Training [13/62] Loss: 0.03099 
Epoch [226/300] Training [14/62] Loss: 0.13967 
Epoch [226/300] Training [15/62] Loss: 0.04777 
Epoch [226/300] Training [16/62] Loss: 0.03810 
Epoch [226/300] Training [17/62] Loss: 0.04745 
Epoch [226/300] Training [18/62] Loss: 0.04515 
Epoch [226/300] Training [19/62] Loss: 0.05101 
Epoch [226/300] Training [20/62] Loss: 0.03737 
Epoch [226/300] Training [21/62] Loss: 0.03233 
Epoch [226/300] Training [22/62] Loss: 0.02897 
Epoch [226/300] Training [23/62] Loss: 0.02889 
Epoch [226/300] Training [24/62] Loss: 0.04065 
Epoch [226/300] Training [25/62] Loss: 0.08864 
Epoch [226/300] Training [26/62] Loss: 0.03888 
Epoch [226/300] Training [27/62] Loss: 0.05038 
Epoch [226/300] Training [28/62] Loss: 0.03776 
Epoch [226/300] Training [29/62] Loss: 0.03194 
Epoch [226/300] Training [30/62] Loss: 0.02746 
Epoch [226/300] Training [31/62] Loss: 0.05173 
Epoch [226/300] Training [32/62] Loss: 0.02622 
Epoch [226/300] Training [33/62] Loss: 0.03779 
Epoch [226/300] Training [34/62] Loss: 0.02947 
Epoch [226/300] Training [35/62] Loss: 0.11629 
Epoch [226/300] Training [36/62] Loss: 0.03169 
Epoch [226/300] Training [37/62] Loss: 0.03008 
Epoch [226/300] Training [38/62] Loss: 0.03359 
Epoch [226/300] Training [39/62] Loss: 0.03705 
Epoch [226/300] Training [40/62] Loss: 0.02868 
Epoch [226/300] Training [41/62] Loss: 0.02919 
Epoch [226/300] Training [42/62] Loss: 0.06714 
Epoch [226/300] Training [43/62] Loss: 0.03027 
Epoch [226/300] Training [44/62] Loss: 0.02813 
Epoch [226/300] Training [45/62] Loss: 0.04190 
Epoch [226/300] Training [46/62] Loss: 0.04051 
Epoch [226/300] Training [47/62] Loss: 0.03164 
Epoch [226/300] Training [48/62] Loss: 0.04073 
Epoch [226/300] Training [49/62] Loss: 0.16365 
Epoch [226/300] Training [50/62] Loss: 0.03061 
Epoch [226/300] Training [51/62] Loss: 0.08438 
Epoch [226/300] Training [52/62] Loss: 0.06825 
Epoch [226/300] Training [53/62] Loss: 0.04827 
Epoch [226/300] Training [54/62] Loss: 0.07389 
Epoch [226/300] Training [55/62] Loss: 0.03863 
Epoch [226/300] Training [56/62] Loss: 0.04213 
Epoch [226/300] Training [57/62] Loss: 0.02727 
Epoch [226/300] Training [58/62] Loss: 0.04830 
Epoch [226/300] Training [59/62] Loss: 0.06740 
Epoch [226/300] Training [60/62] Loss: 0.02421 
Epoch [226/300] Training [61/62] Loss: 0.04391 
Epoch [226/300] Training [62/62] Loss: 0.03207 
Epoch [226/300] Training metric {'Train/mean dice_metric': 0.9683083295822144, 'Train/mean miou_metric': 0.9427088499069214, 'Train/mean f1': 0.9691356420516968, 'Train/mean precision': 0.967243492603302, 'Train/mean recall': 0.9710353016853333, 'Train/mean hd95_metric': 6.357707977294922}
Epoch [226/300] Validation [1/16] Loss: 0.67352  focal_loss 0.46052  dice_loss 0.21300 
Epoch [226/300] Validation [2/16] Loss: 0.45630  focal_loss 0.19604  dice_loss 0.26026 
Epoch [226/300] Validation [3/16] Loss: 0.74020  focal_loss 0.43665  dice_loss 0.30355 
Epoch [226/300] Validation [4/16] Loss: 0.35299  focal_loss 0.17550  dice_loss 0.17749 
Epoch [226/300] Validation [5/16] Loss: 0.32982  focal_loss 0.12807  dice_loss 0.20175 
Epoch [226/300] Validation [6/16] Loss: 0.36644  focal_loss 0.10557  dice_loss 0.26087 
Epoch [226/300] Validation [7/16] Loss: 0.36356  focal_loss 0.13666  dice_loss 0.22690 
Epoch [226/300] Validation [8/16] Loss: 0.59364  focal_loss 0.23098  dice_loss 0.36266 
Epoch [226/300] Validation [9/16] Loss: 0.21084  focal_loss 0.07836  dice_loss 0.13248 
Epoch [226/300] Validation [10/16] Loss: 0.52917  focal_loss 0.18285  dice_loss 0.34631 
Epoch [226/300] Validation [11/16] Loss: 0.16898  focal_loss 0.04866  dice_loss 0.12032 
Epoch [226/300] Validation [12/16] Loss: 0.50309  focal_loss 0.13846  dice_loss 0.36464 
Epoch [226/300] Validation [13/16] Loss: 0.30695  focal_loss 0.12100  dice_loss 0.18595 
Epoch [226/300] Validation [14/16] Loss: 0.50765  focal_loss 0.21096  dice_loss 0.29669 
Epoch [226/300] Validation [15/16] Loss: 0.10778  focal_loss 0.04158  dice_loss 0.06620 
Epoch [226/300] Validation [16/16] Loss: 0.09856  focal_loss 0.03241  dice_loss 0.06615 
Epoch [226/300] Validation metric {'Val/mean dice_metric': 0.9290673732757568, 'Val/mean miou_metric': 0.8915089964866638, 'Val/mean f1': 0.9399510622024536, 'Val/mean precision': 0.9505320191383362, 'Val/mean recall': 0.929603099822998, 'Val/mean hd95_metric': 14.857198715209961}
Cheakpoint...
Epoch [226/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9291], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9290673732757568, 'Val/mean miou_metric': 0.8915089964866638, 'Val/mean f1': 0.9399510622024536, 'Val/mean precision': 0.9505320191383362, 'Val/mean recall': 0.929603099822998, 'Val/mean hd95_metric': 14.857198715209961}
Epoch [227/300] Training [1/62] Loss: 0.04378 
Epoch [227/300] Training [2/62] Loss: 0.04369 
Epoch [227/300] Training [3/62] Loss: 0.03518 
Epoch [227/300] Training [4/62] Loss: 0.11294 
Epoch [227/300] Training [5/62] Loss: 0.02168 
Epoch [227/300] Training [6/62] Loss: 0.03914 
Epoch [227/300] Training [7/62] Loss: 0.02895 
Epoch [227/300] Training [8/62] Loss: 0.04680 
Epoch [227/300] Training [9/62] Loss: 0.03848 
Epoch [227/300] Training [10/62] Loss: 0.03281 
Epoch [227/300] Training [11/62] Loss: 0.03424 
Epoch [227/300] Training [12/62] Loss: 0.10632 
Epoch [227/300] Training [13/62] Loss: 0.02618 
Epoch [227/300] Training [14/62] Loss: 0.04538 
Epoch [227/300] Training [15/62] Loss: 0.04244 
Epoch [227/300] Training [16/62] Loss: 0.02716 
Epoch [227/300] Training [17/62] Loss: 0.03537 
Epoch [227/300] Training [18/62] Loss: 0.03933 
Epoch [227/300] Training [19/62] Loss: 0.06660 
Epoch [227/300] Training [20/62] Loss: 0.07603 
Epoch [227/300] Training [21/62] Loss: 0.04144 
Epoch [227/300] Training [22/62] Loss: 0.03529 
Epoch [227/300] Training [23/62] Loss: 0.03195 
Epoch [227/300] Training [24/62] Loss: 0.07931 
Epoch [227/300] Training [25/62] Loss: 0.03682 
Epoch [227/300] Training [26/62] Loss: 0.03745 
Epoch [227/300] Training [27/62] Loss: 0.03603 
Epoch [227/300] Training [28/62] Loss: 0.05479 
Epoch [227/300] Training [29/62] Loss: 0.03263 
Epoch [227/300] Training [30/62] Loss: 0.04470 
Epoch [227/300] Training [31/62] Loss: 0.02916 
Epoch [227/300] Training [32/62] Loss: 0.08797 
Epoch [227/300] Training [33/62] Loss: 0.05217 
Epoch [227/300] Training [34/62] Loss: 0.07924 
Epoch [227/300] Training [35/62] Loss: 0.09224 
Epoch [227/300] Training [36/62] Loss: 0.04696 
Epoch [227/300] Training [37/62] Loss: 0.09386 
Epoch [227/300] Training [38/62] Loss: 0.11837 
Epoch [227/300] Training [39/62] Loss: 0.03453 
Epoch [227/300] Training [40/62] Loss: 0.03408 
Epoch [227/300] Training [41/62] Loss: 0.05971 
Epoch [227/300] Training [42/62] Loss: 0.06862 
Epoch [227/300] Training [43/62] Loss: 0.04588 
Epoch [227/300] Training [44/62] Loss: 0.08763 
Epoch [227/300] Training [45/62] Loss: 0.03046 
Epoch [227/300] Training [46/62] Loss: 0.05091 
Epoch [227/300] Training [47/62] Loss: 0.03521 
Epoch [227/300] Training [48/62] Loss: 0.02695 
Epoch [227/300] Training [49/62] Loss: 0.02961 
Epoch [227/300] Training [50/62] Loss: 0.04249 
Epoch [227/300] Training [51/62] Loss: 0.04936 
Epoch [227/300] Training [52/62] Loss: 0.03610 
Epoch [227/300] Training [53/62] Loss: 0.03616 
Epoch [227/300] Training [54/62] Loss: 0.02625 
Epoch [227/300] Training [55/62] Loss: 0.03412 
Epoch [227/300] Training [56/62] Loss: 0.02890 
Epoch [227/300] Training [57/62] Loss: 0.02747 
Epoch [227/300] Training [58/62] Loss: 0.04422 
Epoch [227/300] Training [59/62] Loss: 0.04931 
Epoch [227/300] Training [60/62] Loss: 0.06988 
Epoch [227/300] Training [61/62] Loss: 0.05400 
Epoch [227/300] Training [62/62] Loss: 0.04468 
Epoch [227/300] Training metric {'Train/mean dice_metric': 0.9666905403137207, 'Train/mean miou_metric': 0.9391760230064392, 'Train/mean f1': 0.9694388508796692, 'Train/mean precision': 0.9651141166687012, 'Train/mean recall': 0.9738026261329651, 'Train/mean hd95_metric': 8.794682502746582}
Epoch [227/300] Validation [1/16] Loss: 0.79126  focal_loss 0.53124  dice_loss 0.26002 
Epoch [227/300] Validation [2/16] Loss: 0.51794  focal_loss 0.22622  dice_loss 0.29172 
Epoch [227/300] Validation [3/16] Loss: 0.75526  focal_loss 0.44411  dice_loss 0.31115 
Epoch [227/300] Validation [4/16] Loss: 0.32248  focal_loss 0.15980  dice_loss 0.16267 
Epoch [227/300] Validation [5/16] Loss: 0.32590  focal_loss 0.12354  dice_loss 0.20236 
Epoch [227/300] Validation [6/16] Loss: 0.27875  focal_loss 0.09695  dice_loss 0.18179 
Epoch [227/300] Validation [7/16] Loss: 0.33109  focal_loss 0.13015  dice_loss 0.20094 
Epoch [227/300] Validation [8/16] Loss: 0.43264  focal_loss 0.15799  dice_loss 0.27465 
Epoch [227/300] Validation [9/16] Loss: 0.21140  focal_loss 0.09108  dice_loss 0.12032 
Epoch [227/300] Validation [10/16] Loss: 0.52999  focal_loss 0.17782  dice_loss 0.35217 
Epoch [227/300] Validation [11/16] Loss: 0.14074  focal_loss 0.05193  dice_loss 0.08881 
Epoch [227/300] Validation [12/16] Loss: 0.39426  focal_loss 0.13188  dice_loss 0.26239 
Epoch [227/300] Validation [13/16] Loss: 0.26916  focal_loss 0.09878  dice_loss 0.17038 
Epoch [227/300] Validation [14/16] Loss: 0.57687  focal_loss 0.25327  dice_loss 0.32361 
Epoch [227/300] Validation [15/16] Loss: 0.13090  focal_loss 0.05154  dice_loss 0.07936 
Epoch [227/300] Validation [16/16] Loss: 0.13337  focal_loss 0.05784  dice_loss 0.07553 
Epoch [227/300] Validation metric {'Val/mean dice_metric': 0.9307756423950195, 'Val/mean miou_metric': 0.8910707831382751, 'Val/mean f1': 0.9400526285171509, 'Val/mean precision': 0.9468899369239807, 'Val/mean recall': 0.9333134293556213, 'Val/mean hd95_metric': 16.926572799682617}
Cheakpoint...
Epoch [227/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9308], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9307756423950195, 'Val/mean miou_metric': 0.8910707831382751, 'Val/mean f1': 0.9400526285171509, 'Val/mean precision': 0.9468899369239807, 'Val/mean recall': 0.9333134293556213, 'Val/mean hd95_metric': 16.926572799682617}
Epoch [228/300] Training [1/62] Loss: 0.06983 
Epoch [228/300] Training [2/62] Loss: 0.02733 
Epoch [228/300] Training [3/62] Loss: 0.02872 
Epoch [228/300] Training [4/62] Loss: 0.05568 
Epoch [228/300] Training [5/62] Loss: 0.03950 
Epoch [228/300] Training [6/62] Loss: 0.02846 
Epoch [228/300] Training [7/62] Loss: 0.09868 
Epoch [228/300] Training [8/62] Loss: 0.05248 
Epoch [228/300] Training [9/62] Loss: 0.03377 
Epoch [228/300] Training [10/62] Loss: 0.07149 
Epoch [228/300] Training [11/62] Loss: 0.03279 
Epoch [228/300] Training [12/62] Loss: 0.03403 
Epoch [228/300] Training [13/62] Loss: 0.02726 
Epoch [228/300] Training [14/62] Loss: 0.04243 
Epoch [228/300] Training [15/62] Loss: 0.02826 
Epoch [228/300] Training [16/62] Loss: 0.03933 
Epoch [228/300] Training [17/62] Loss: 0.02713 
Epoch [228/300] Training [18/62] Loss: 0.05174 
Epoch [228/300] Training [19/62] Loss: 0.02901 
Epoch [228/300] Training [20/62] Loss: 0.04730 
Epoch [228/300] Training [21/62] Loss: 0.04014 
Epoch [228/300] Training [22/62] Loss: 0.02954 
Epoch [228/300] Training [23/62] Loss: 0.03143 
Epoch [228/300] Training [24/62] Loss: 0.07233 
Epoch [228/300] Training [25/62] Loss: 0.03018 
Epoch [228/300] Training [26/62] Loss: 0.02446 
Epoch [228/300] Training [27/62] Loss: 0.15717 
Epoch [228/300] Training [28/62] Loss: 0.03532 
Epoch [228/300] Training [29/62] Loss: 0.08252 
Epoch [228/300] Training [30/62] Loss: 0.04553 
Epoch [228/300] Training [31/62] Loss: 0.02792 
Epoch [228/300] Training [32/62] Loss: 0.08703 
Epoch [228/300] Training [33/62] Loss: 0.02932 
Epoch [228/300] Training [34/62] Loss: 0.07996 
Epoch [228/300] Training [35/62] Loss: 0.03545 
Epoch [228/300] Training [36/62] Loss: 0.04014 
Epoch [228/300] Training [37/62] Loss: 0.04756 
Epoch [228/300] Training [38/62] Loss: 0.03451 
Epoch [228/300] Training [39/62] Loss: 0.04754 
Epoch [228/300] Training [40/62] Loss: 0.05144 
Epoch [228/300] Training [41/62] Loss: 0.04757 
Epoch [228/300] Training [42/62] Loss: 0.02928 
Epoch [228/300] Training [43/62] Loss: 0.03356 
Epoch [228/300] Training [44/62] Loss: 0.03621 
Epoch [228/300] Training [45/62] Loss: 0.05243 
Epoch [228/300] Training [46/62] Loss: 0.03767 
Epoch [228/300] Training [47/62] Loss: 0.04219 
Epoch [228/300] Training [48/62] Loss: 0.05333 
Epoch [228/300] Training [49/62] Loss: 0.04107 
Epoch [228/300] Training [50/62] Loss: 0.04317 
Epoch [228/300] Training [51/62] Loss: 0.10855 
Epoch [228/300] Training [52/62] Loss: 0.07359 
Epoch [228/300] Training [53/62] Loss: 0.07621 
Epoch [228/300] Training [54/62] Loss: 0.03378 
Epoch [228/300] Training [55/62] Loss: 0.03683 
Epoch [228/300] Training [56/62] Loss: 0.05219 
Epoch [228/300] Training [57/62] Loss: 0.05701 
Epoch [228/300] Training [58/62] Loss: 0.02547 
Epoch [228/300] Training [59/62] Loss: 0.05146 
Epoch [228/300] Training [60/62] Loss: 0.06890 
Epoch [228/300] Training [61/62] Loss: 0.06697 
Epoch [228/300] Training [62/62] Loss: 0.01812 
Epoch [228/300] Training metric {'Train/mean dice_metric': 0.9679049849510193, 'Train/mean miou_metric': 0.9407005906105042, 'Train/mean f1': 0.9683708548545837, 'Train/mean precision': 0.9659191966056824, 'Train/mean recall': 0.9708350896835327, 'Train/mean hd95_metric': 6.9130048751831055}
Epoch [228/300] Validation [1/16] Loss: 0.68390  focal_loss 0.47732  dice_loss 0.20658 
Epoch [228/300] Validation [2/16] Loss: 0.45970  focal_loss 0.20105  dice_loss 0.25865 
Epoch [228/300] Validation [3/16] Loss: 0.74673  focal_loss 0.44269  dice_loss 0.30403 
Epoch [228/300] Validation [4/16] Loss: 0.35162  focal_loss 0.17246  dice_loss 0.17916 
Epoch [228/300] Validation [5/16] Loss: 0.32504  focal_loss 0.11915  dice_loss 0.20590 
Epoch [228/300] Validation [6/16] Loss: 0.26412  focal_loss 0.08409  dice_loss 0.18003 
Epoch [228/300] Validation [7/16] Loss: 0.24584  focal_loss 0.09554  dice_loss 0.15030 
Epoch [228/300] Validation [8/16] Loss: 0.50600  focal_loss 0.21008  dice_loss 0.29592 
Epoch [228/300] Validation [9/16] Loss: 0.21800  focal_loss 0.09295  dice_loss 0.12504 
Epoch [228/300] Validation [10/16] Loss: 0.49689  focal_loss 0.16335  dice_loss 0.33355 
Epoch [228/300] Validation [11/16] Loss: 0.13885  focal_loss 0.05159  dice_loss 0.08726 
Epoch [228/300] Validation [12/16] Loss: 0.40234  focal_loss 0.11203  dice_loss 0.29031 
Epoch [228/300] Validation [13/16] Loss: 0.27116  focal_loss 0.10276  dice_loss 0.16840 
Epoch [228/300] Validation [14/16] Loss: 0.52596  focal_loss 0.23386  dice_loss 0.29210 
Epoch [228/300] Validation [15/16] Loss: 0.11112  focal_loss 0.04103  dice_loss 0.07009 
Epoch [228/300] Validation [16/16] Loss: 0.11773  focal_loss 0.04783  dice_loss 0.06991 
Epoch [228/300] Validation metric {'Val/mean dice_metric': 0.9335725903511047, 'Val/mean miou_metric': 0.8951386213302612, 'Val/mean f1': 0.9411492943763733, 'Val/mean precision': 0.9493871927261353, 'Val/mean recall': 0.9330530762672424, 'Val/mean hd95_metric': 15.16646671295166}
Cheakpoint...
Epoch [228/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9336], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9335725903511047, 'Val/mean miou_metric': 0.8951386213302612, 'Val/mean f1': 0.9411492943763733, 'Val/mean precision': 0.9493871927261353, 'Val/mean recall': 0.9330530762672424, 'Val/mean hd95_metric': 15.16646671295166}
Epoch [229/300] Training [1/62] Loss: 0.03239 
Epoch [229/300] Training [2/62] Loss: 0.03737 
Epoch [229/300] Training [3/62] Loss: 0.03460 
Epoch [229/300] Training [4/62] Loss: 0.03196 
Epoch [229/300] Training [5/62] Loss: 0.07308 
Epoch [229/300] Training [6/62] Loss: 0.03257 
Epoch [229/300] Training [7/62] Loss: 0.04314 
Epoch [229/300] Training [8/62] Loss: 0.05073 
Epoch [229/300] Training [9/62] Loss: 0.06535 
Epoch [229/300] Training [10/62] Loss: 0.03542 
Epoch [229/300] Training [11/62] Loss: 0.02845 
Epoch [229/300] Training [12/62] Loss: 0.03015 
Epoch [229/300] Training [13/62] Loss: 0.03914 
Epoch [229/300] Training [14/62] Loss: 0.09222 
Epoch [229/300] Training [15/62] Loss: 0.02447 
Epoch [229/300] Training [16/62] Loss: 0.03806 
Epoch [229/300] Training [17/62] Loss: 0.03466 
Epoch [229/300] Training [18/62] Loss: 0.02242 
Epoch [229/300] Training [19/62] Loss: 0.03468 
Epoch [229/300] Training [20/62] Loss: 0.02965 
Epoch [229/300] Training [21/62] Loss: 0.02746 
Epoch [229/300] Training [22/62] Loss: 0.02980 
Epoch [229/300] Training [23/62] Loss: 0.02656 
Epoch [229/300] Training [24/62] Loss: 0.02828 
Epoch [229/300] Training [25/62] Loss: 0.05053 
Epoch [229/300] Training [26/62] Loss: 0.02786 
Epoch [229/300] Training [27/62] Loss: 0.17638 
Epoch [229/300] Training [28/62] Loss: 0.02819 
Epoch [229/300] Training [29/62] Loss: 0.06320 
Epoch [229/300] Training [30/62] Loss: 0.03480 
Epoch [229/300] Training [31/62] Loss: 0.03639 
Epoch [229/300] Training [32/62] Loss: 0.03286 
Epoch [229/300] Training [33/62] Loss: 0.04426 
Epoch [229/300] Training [34/62] Loss: 0.08763 
Epoch [229/300] Training [35/62] Loss: 0.03244 
Epoch [229/300] Training [36/62] Loss: 0.05416 
Epoch [229/300] Training [37/62] Loss: 0.09869 
Epoch [229/300] Training [38/62] Loss: 0.05819 
Epoch [229/300] Training [39/62] Loss: 0.03802 
Epoch [229/300] Training [40/62] Loss: 0.03599 
Epoch [229/300] Training [41/62] Loss: 0.03356 
Epoch [229/300] Training [42/62] Loss: 0.03073 
Epoch [229/300] Training [43/62] Loss: 0.03934 
Epoch [229/300] Training [44/62] Loss: 0.03837 
Epoch [229/300] Training [45/62] Loss: 0.03901 
Epoch [229/300] Training [46/62] Loss: 0.03177 
Epoch [229/300] Training [47/62] Loss: 0.03835 
Epoch [229/300] Training [48/62] Loss: 0.13030 
Epoch [229/300] Training [49/62] Loss: 0.05148 
Epoch [229/300] Training [50/62] Loss: 0.04819 
Epoch [229/300] Training [51/62] Loss: 0.04846 
Epoch [229/300] Training [52/62] Loss: 0.05453 
Epoch [229/300] Training [53/62] Loss: 0.02729 
Epoch [229/300] Training [54/62] Loss: 0.05052 
Epoch [229/300] Training [55/62] Loss: 0.03338 
Epoch [229/300] Training [56/62] Loss: 0.03035 
Epoch [229/300] Training [57/62] Loss: 0.05006 
Epoch [229/300] Training [58/62] Loss: 0.03123 
Epoch [229/300] Training [59/62] Loss: 0.04711 
Epoch [229/300] Training [60/62] Loss: 0.03255 
Epoch [229/300] Training [61/62] Loss: 0.02245 
Epoch [229/300] Training [62/62] Loss: 0.07541 
Epoch [229/300] Training metric {'Train/mean dice_metric': 0.9691768288612366, 'Train/mean miou_metric': 0.9442822337150574, 'Train/mean f1': 0.9712620973587036, 'Train/mean precision': 0.9669535756111145, 'Train/mean recall': 0.975609302520752, 'Train/mean hd95_metric': 6.204662799835205}
Epoch [229/300] Validation [1/16] Loss: 0.71391  focal_loss 0.49267  dice_loss 0.22124 
Epoch [229/300] Validation [2/16] Loss: 0.57376  focal_loss 0.22925  dice_loss 0.34451 
Epoch [229/300] Validation [3/16] Loss: 0.73447  focal_loss 0.44964  dice_loss 0.28483 
Epoch [229/300] Validation [4/16] Loss: 0.30419  focal_loss 0.15718  dice_loss 0.14702 
Epoch [229/300] Validation [5/16] Loss: 0.35290  focal_loss 0.14043  dice_loss 0.21247 
Epoch [229/300] Validation [6/16] Loss: 0.26762  focal_loss 0.08282  dice_loss 0.18480 
Epoch [229/300] Validation [7/16] Loss: 0.25153  focal_loss 0.09082  dice_loss 0.16071 
Epoch [229/300] Validation [8/16] Loss: 0.48634  focal_loss 0.20514  dice_loss 0.28119 
Epoch [229/300] Validation [9/16] Loss: 0.24873  focal_loss 0.11836  dice_loss 0.13037 
Epoch [229/300] Validation [10/16] Loss: 0.57786  focal_loss 0.21021  dice_loss 0.36765 
Epoch [229/300] Validation [11/16] Loss: 0.13084  focal_loss 0.04575  dice_loss 0.08508 
Epoch [229/300] Validation [12/16] Loss: 0.48745  focal_loss 0.14324  dice_loss 0.34421 
Epoch [229/300] Validation [13/16] Loss: 0.31701  focal_loss 0.12119  dice_loss 0.19582 
Epoch [229/300] Validation [14/16] Loss: 0.49083  focal_loss 0.22018  dice_loss 0.27064 
Epoch [229/300] Validation [15/16] Loss: 0.13276  focal_loss 0.05106  dice_loss 0.08171 
Epoch [229/300] Validation [16/16] Loss: 0.11642  focal_loss 0.04713  dice_loss 0.06929 
Epoch [229/300] Validation metric {'Val/mean dice_metric': 0.9324756860733032, 'Val/mean miou_metric': 0.8954228162765503, 'Val/mean f1': 0.9429904818534851, 'Val/mean precision': 0.9509404897689819, 'Val/mean recall': 0.9351722002029419, 'Val/mean hd95_metric': 15.285982131958008}
Cheakpoint...
Epoch [229/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9325], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9324756860733032, 'Val/mean miou_metric': 0.8954228162765503, 'Val/mean f1': 0.9429904818534851, 'Val/mean precision': 0.9509404897689819, 'Val/mean recall': 0.9351722002029419, 'Val/mean hd95_metric': 15.285982131958008}
Epoch [230/300] Training [1/62] Loss: 0.05771 
Epoch [230/300] Training [2/62] Loss: 0.02500 
Epoch [230/300] Training [3/62] Loss: 0.06151 
Epoch [230/300] Training [4/62] Loss: 0.06749 
Epoch [230/300] Training [5/62] Loss: 0.04820 
Epoch [230/300] Training [6/62] Loss: 0.13852 
Epoch [230/300] Training [7/62] Loss: 0.03571 
Epoch [230/300] Training [8/62] Loss: 0.07002 
Epoch [230/300] Training [9/62] Loss: 0.04341 
Epoch [230/300] Training [10/62] Loss: 0.04370 
Epoch [230/300] Training [11/62] Loss: 0.02945 
Epoch [230/300] Training [12/62] Loss: 0.03111 
Epoch [230/300] Training [13/62] Loss: 0.03161 
Epoch [230/300] Training [14/62] Loss: 0.03629 
Epoch [230/300] Training [15/62] Loss: 0.04482 
Epoch [230/300] Training [16/62] Loss: 0.05546 
Epoch [230/300] Training [17/62] Loss: 0.04221 
Epoch [230/300] Training [18/62] Loss: 0.03323 
Epoch [230/300] Training [19/62] Loss: 0.02788 
Epoch [230/300] Training [20/62] Loss: 0.03697 
Epoch [230/300] Training [21/62] Loss: 0.03246 
Epoch [230/300] Training [22/62] Loss: 0.07845 
Epoch [230/300] Training [23/62] Loss: 0.03873 
Epoch [230/300] Training [24/62] Loss: 0.03640 
Epoch [230/300] Training [25/62] Loss: 0.13212 
Epoch [230/300] Training [26/62] Loss: 0.02785 
Epoch [230/300] Training [27/62] Loss: 0.05283 
Epoch [230/300] Training [28/62] Loss: 0.03201 
Epoch [230/300] Training [29/62] Loss: 0.02736 
Epoch [230/300] Training [30/62] Loss: 0.03801 
Epoch [230/300] Training [31/62] Loss: 0.02912 
Epoch [230/300] Training [32/62] Loss: 0.02929 
Epoch [230/300] Training [33/62] Loss: 0.05552 
Epoch [230/300] Training [34/62] Loss: 0.04551 
Epoch [230/300] Training [35/62] Loss: 0.04858 
Epoch [230/300] Training [36/62] Loss: 0.03848 
Epoch [230/300] Training [37/62] Loss: 0.04321 
Epoch [230/300] Training [38/62] Loss: 0.09596 
Epoch [230/300] Training [39/62] Loss: 0.17775 
Epoch [230/300] Training [40/62] Loss: 0.02913 
Epoch [230/300] Training [41/62] Loss: 0.06635 
Epoch [230/300] Training [42/62] Loss: 0.05194 
Epoch [230/300] Training [43/62] Loss: 0.03837 
Epoch [230/300] Training [44/62] Loss: 0.03625 
Epoch [230/300] Training [45/62] Loss: 0.04866 
Epoch [230/300] Training [46/62] Loss: 0.03032 
Epoch [230/300] Training [47/62] Loss: 0.03359 
Epoch [230/300] Training [48/62] Loss: 0.03628 
Epoch [230/300] Training [49/62] Loss: 0.03208 
Epoch [230/300] Training [50/62] Loss: 0.09172 
Epoch [230/300] Training [51/62] Loss: 0.03263 
Epoch [230/300] Training [52/62] Loss: 0.03516 
Epoch [230/300] Training [53/62] Loss: 0.04696 
Epoch [230/300] Training [54/62] Loss: 0.02377 
Epoch [230/300] Training [55/62] Loss: 0.03418 
Epoch [230/300] Training [56/62] Loss: 0.03124 
Epoch [230/300] Training [57/62] Loss: 0.03294 
Epoch [230/300] Training [58/62] Loss: 0.03225 
Epoch [230/300] Training [59/62] Loss: 0.05827 
Epoch [230/300] Training [60/62] Loss: 0.02895 
Epoch [230/300] Training [61/62] Loss: 0.04744 
Epoch [230/300] Training [62/62] Loss: 0.02126 
Epoch [230/300] Training metric {'Train/mean dice_metric': 0.9669449329376221, 'Train/mean miou_metric': 0.9409483075141907, 'Train/mean f1': 0.9703370928764343, 'Train/mean precision': 0.9666857719421387, 'Train/mean recall': 0.9740161299705505, 'Train/mean hd95_metric': 6.600306510925293}
Epoch [230/300] Validation [1/16] Loss: 0.67334  focal_loss 0.45934  dice_loss 0.21400 
Epoch [230/300] Validation [2/16] Loss: 0.48715  focal_loss 0.21583  dice_loss 0.27132 
Epoch [230/300] Validation [3/16] Loss: 0.74051  focal_loss 0.42135  dice_loss 0.31916 
Epoch [230/300] Validation [4/16] Loss: 0.36481  focal_loss 0.17058  dice_loss 0.19423 
Epoch [230/300] Validation [5/16] Loss: 0.33083  focal_loss 0.11599  dice_loss 0.21484 
Epoch [230/300] Validation [6/16] Loss: 0.35624  focal_loss 0.10380  dice_loss 0.25244 
Epoch [230/300] Validation [7/16] Loss: 0.20231  focal_loss 0.08845  dice_loss 0.11385 
Epoch [230/300] Validation [8/16] Loss: 0.56770  focal_loss 0.21871  dice_loss 0.34899 
Epoch [230/300] Validation [9/16] Loss: 0.18379  focal_loss 0.07439  dice_loss 0.10940 
Epoch [230/300] Validation [10/16] Loss: 0.54145  focal_loss 0.17394  dice_loss 0.36751 
Epoch [230/300] Validation [11/16] Loss: 0.14262  focal_loss 0.04982  dice_loss 0.09280 
Epoch [230/300] Validation [12/16] Loss: 0.41122  focal_loss 0.12936  dice_loss 0.28186 
Epoch [230/300] Validation [13/16] Loss: 0.23897  focal_loss 0.07803  dice_loss 0.16093 
Epoch [230/300] Validation [14/16] Loss: 0.53234  focal_loss 0.22611  dice_loss 0.30622 
Epoch [230/300] Validation [15/16] Loss: 0.11991  focal_loss 0.04182  dice_loss 0.07809 
Epoch [230/300] Validation [16/16] Loss: 0.16682  focal_loss 0.06140  dice_loss 0.10542 
Epoch [230/300] Validation metric {'Val/mean dice_metric': 0.9303575158119202, 'Val/mean miou_metric': 0.8929247856140137, 'Val/mean f1': 0.9419729709625244, 'Val/mean precision': 0.9485982060432434, 'Val/mean recall': 0.9354396462440491, 'Val/mean hd95_metric': 16.412023544311523}
Cheakpoint...
Epoch [230/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9304], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9303575158119202, 'Val/mean miou_metric': 0.8929247856140137, 'Val/mean f1': 0.9419729709625244, 'Val/mean precision': 0.9485982060432434, 'Val/mean recall': 0.9354396462440491, 'Val/mean hd95_metric': 16.412023544311523}
Epoch [231/300] Training [1/62] Loss: 0.02817 
Epoch [231/300] Training [2/62] Loss: 0.04233 
Epoch [231/300] Training [3/62] Loss: 0.03291 
Epoch [231/300] Training [4/62] Loss: 0.03388 
Epoch [231/300] Training [5/62] Loss: 0.03086 
Epoch [231/300] Training [6/62] Loss: 0.24473 
Epoch [231/300] Training [7/62] Loss: 0.06318 
Epoch [231/300] Training [8/62] Loss: 0.06415 
Epoch [231/300] Training [9/62] Loss: 0.05679 
Epoch [231/300] Training [10/62] Loss: 0.03073 
Epoch [231/300] Training [11/62] Loss: 0.05755 
Epoch [231/300] Training [12/62] Loss: 0.04339 
Epoch [231/300] Training [13/62] Loss: 0.04903 
Epoch [231/300] Training [14/62] Loss: 0.03829 
Epoch [231/300] Training [15/62] Loss: 0.05442 
Epoch [231/300] Training [16/62] Loss: 0.08674 
Epoch [231/300] Training [17/62] Loss: 0.03365 
Epoch [231/300] Training [18/62] Loss: 0.04310 
Epoch [231/300] Training [19/62] Loss: 0.05332 
Epoch [231/300] Training [20/62] Loss: 0.03542 
Epoch [231/300] Training [21/62] Loss: 0.02889 
Epoch [231/300] Training [22/62] Loss: 0.02805 
Epoch [231/300] Training [23/62] Loss: 0.03382 
Epoch [231/300] Training [24/62] Loss: 0.03171 
Epoch [231/300] Training [25/62] Loss: 0.03727 
Epoch [231/300] Training [26/62] Loss: 0.02527 
Epoch [231/300] Training [27/62] Loss: 0.03738 
Epoch [231/300] Training [28/62] Loss: 0.03580 
Epoch [231/300] Training [29/62] Loss: 0.03957 
Epoch [231/300] Training [30/62] Loss: 0.02957 
Epoch [231/300] Training [31/62] Loss: 0.02468 
Epoch [231/300] Training [32/62] Loss: 0.04787 
Epoch [231/300] Training [33/62] Loss: 0.03851 
Epoch [231/300] Training [34/62] Loss: 0.02876 
Epoch [231/300] Training [35/62] Loss: 0.03988 
Epoch [231/300] Training [36/62] Loss: 0.04418 
Epoch [231/300] Training [37/62] Loss: 0.02937 
Epoch [231/300] Training [38/62] Loss: 0.02867 
Epoch [231/300] Training [39/62] Loss: 0.04547 
Epoch [231/300] Training [40/62] Loss: 0.03417 
Epoch [231/300] Training [41/62] Loss: 0.03069 
Epoch [231/300] Training [42/62] Loss: 0.08040 
Epoch [231/300] Training [43/62] Loss: 0.05658 
Epoch [231/300] Training [44/62] Loss: 0.10399 
Epoch [231/300] Training [45/62] Loss: 0.02998 
Epoch [231/300] Training [46/62] Loss: 0.12327 
Epoch [231/300] Training [47/62] Loss: 0.03229 
Epoch [231/300] Training [48/62] Loss: 0.03573 
Epoch [231/300] Training [49/62] Loss: 0.03169 
Epoch [231/300] Training [50/62] Loss: 0.07284 
Epoch [231/300] Training [51/62] Loss: 0.03902 
Epoch [231/300] Training [52/62] Loss: 0.03051 
Epoch [231/300] Training [53/62] Loss: 0.03933 
Epoch [231/300] Training [54/62] Loss: 0.03078 
Epoch [231/300] Training [55/62] Loss: 0.14501 
Epoch [231/300] Training [56/62] Loss: 0.03614 
Epoch [231/300] Training [57/62] Loss: 0.03014 
Epoch [231/300] Training [58/62] Loss: 0.04012 
Epoch [231/300] Training [59/62] Loss: 0.03154 
Epoch [231/300] Training [60/62] Loss: 0.03122 
Epoch [231/300] Training [61/62] Loss: 0.04360 
Epoch [231/300] Training [62/62] Loss: 0.05187 
Epoch [231/300] Training metric {'Train/mean dice_metric': 0.968834638595581, 'Train/mean miou_metric': 0.943316638469696, 'Train/mean f1': 0.9690856337547302, 'Train/mean precision': 0.9677628874778748, 'Train/mean recall': 0.9704120755195618, 'Train/mean hd95_metric': 7.023395538330078}
Epoch [231/300] Validation [1/16] Loss: 0.68174  focal_loss 0.47150  dice_loss 0.21024 
Epoch [231/300] Validation [2/16] Loss: 0.57597  focal_loss 0.22953  dice_loss 0.34645 
Epoch [231/300] Validation [3/16] Loss: 0.70923  focal_loss 0.41193  dice_loss 0.29730 
Epoch [231/300] Validation [4/16] Loss: 0.27791  focal_loss 0.14216  dice_loss 0.13575 
Epoch [231/300] Validation [5/16] Loss: 0.47130  focal_loss 0.15789  dice_loss 0.31341 
Epoch [231/300] Validation [6/16] Loss: 0.26800  focal_loss 0.09249  dice_loss 0.17551 
Epoch [231/300] Validation [7/16] Loss: 0.20553  focal_loss 0.09456  dice_loss 0.11097 
Epoch [231/300] Validation [8/16] Loss: 0.53489  focal_loss 0.23572  dice_loss 0.29917 
Epoch [231/300] Validation [9/16] Loss: 0.22069  focal_loss 0.08578  dice_loss 0.13490 
Epoch [231/300] Validation [10/16] Loss: 0.50925  focal_loss 0.16681  dice_loss 0.34244 
Epoch [231/300] Validation [11/16] Loss: 0.15189  focal_loss 0.05280  dice_loss 0.09909 
Epoch [231/300] Validation [12/16] Loss: 0.39565  focal_loss 0.12471  dice_loss 0.27095 
Epoch [231/300] Validation [13/16] Loss: 0.27667  focal_loss 0.09999  dice_loss 0.17667 
Epoch [231/300] Validation [14/16] Loss: 0.52444  focal_loss 0.22352  dice_loss 0.30093 
Epoch [231/300] Validation [15/16] Loss: 0.10404  focal_loss 0.03665  dice_loss 0.06740 
Epoch [231/300] Validation [16/16] Loss: 0.10636  focal_loss 0.03743  dice_loss 0.06893 
Epoch [231/300] Validation metric {'Val/mean dice_metric': 0.932614803314209, 'Val/mean miou_metric': 0.8954659104347229, 'Val/mean f1': 0.9416448473930359, 'Val/mean precision': 0.9504228234291077, 'Val/mean recall': 0.9330275058746338, 'Val/mean hd95_metric': 15.876358985900879}
Cheakpoint...
Epoch [231/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9326], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.932614803314209, 'Val/mean miou_metric': 0.8954659104347229, 'Val/mean f1': 0.9416448473930359, 'Val/mean precision': 0.9504228234291077, 'Val/mean recall': 0.9330275058746338, 'Val/mean hd95_metric': 15.876358985900879}
Epoch [232/300] Training [1/62] Loss: 0.09955 
Epoch [232/300] Training [2/62] Loss: 0.02678 
Epoch [232/300] Training [3/62] Loss: 0.03937 
Epoch [232/300] Training [4/62] Loss: 0.05823 
Epoch [232/300] Training [5/62] Loss: 0.07573 
Epoch [232/300] Training [6/62] Loss: 0.04130 
Epoch [232/300] Training [7/62] Loss: 0.05981 
Epoch [232/300] Training [8/62] Loss: 0.02478 
Epoch [232/300] Training [9/62] Loss: 0.06227 
Epoch [232/300] Training [10/62] Loss: 0.02455 
Epoch [232/300] Training [11/62] Loss: 0.05144 
Epoch [232/300] Training [12/62] Loss: 0.03328 
Epoch [232/300] Training [13/62] Loss: 0.07034 
Epoch [232/300] Training [14/62] Loss: 0.06383 
Epoch [232/300] Training [15/62] Loss: 0.04551 
Epoch [232/300] Training [16/62] Loss: 0.03578 
Epoch [232/300] Training [17/62] Loss: 0.03131 
Epoch [232/300] Training [18/62] Loss: 0.03368 
Epoch [232/300] Training [19/62] Loss: 0.09205 
Epoch [232/300] Training [20/62] Loss: 0.02463 
Epoch [232/300] Training [21/62] Loss: 0.03093 
Epoch [232/300] Training [22/62] Loss: 0.03241 
Epoch [232/300] Training [23/62] Loss: 0.06350 
Epoch [232/300] Training [24/62] Loss: 0.04750 
Epoch [232/300] Training [25/62] Loss: 0.03246 
Epoch [232/300] Training [26/62] Loss: 0.14342 
Epoch [232/300] Training [27/62] Loss: 0.03448 
Epoch [232/300] Training [28/62] Loss: 0.04219 
Epoch [232/300] Training [29/62] Loss: 0.12745 
Epoch [232/300] Training [30/62] Loss: 0.02787 
Epoch [232/300] Training [31/62] Loss: 0.03251 
Epoch [232/300] Training [32/62] Loss: 0.04321 
Epoch [232/300] Training [33/62] Loss: 0.08109 
Epoch [232/300] Training [34/62] Loss: 0.02413 
Epoch [232/300] Training [35/62] Loss: 0.03527 
Epoch [232/300] Training [36/62] Loss: 0.03026 
Epoch [232/300] Training [37/62] Loss: 0.02810 
Epoch [232/300] Training [38/62] Loss: 0.02919 
Epoch [232/300] Training [39/62] Loss: 0.03697 
Epoch [232/300] Training [40/62] Loss: 0.03922 
Epoch [232/300] Training [41/62] Loss: 0.03765 
Epoch [232/300] Training [42/62] Loss: 0.02648 
Epoch [232/300] Training [43/62] Loss: 0.07298 
Epoch [232/300] Training [44/62] Loss: 0.03172 
Epoch [232/300] Training [45/62] Loss: 0.02963 
Epoch [232/300] Training [46/62] Loss: 0.03641 
Epoch [232/300] Training [47/62] Loss: 0.03305 
Epoch [232/300] Training [48/62] Loss: 0.02577 
Epoch [232/300] Training [49/62] Loss: 0.03155 
Epoch [232/300] Training [50/62] Loss: 0.02006 
Epoch [232/300] Training [51/62] Loss: 0.03112 
Epoch [232/300] Training [52/62] Loss: 0.04510 
Epoch [232/300] Training [53/62] Loss: 0.05433 
Epoch [232/300] Training [54/62] Loss: 0.07586 
Epoch [232/300] Training [55/62] Loss: 0.03943 
Epoch [232/300] Training [56/62] Loss: 0.15387 
Epoch [232/300] Training [57/62] Loss: 0.02337 
Epoch [232/300] Training [58/62] Loss: 0.03354 
Epoch [232/300] Training [59/62] Loss: 0.04085 
Epoch [232/300] Training [60/62] Loss: 0.04159 
Epoch [232/300] Training [61/62] Loss: 0.05043 
Epoch [232/300] Training [62/62] Loss: 0.06321 
Epoch [232/300] Training metric {'Train/mean dice_metric': 0.9674335718154907, 'Train/mean miou_metric': 0.9416779279708862, 'Train/mean f1': 0.9703266024589539, 'Train/mean precision': 0.9666620492935181, 'Train/mean recall': 0.974018931388855, 'Train/mean hd95_metric': 7.173364162445068}
Epoch [232/300] Validation [1/16] Loss: 0.74063  focal_loss 0.50332  dice_loss 0.23730 
Epoch [232/300] Validation [2/16] Loss: 0.45122  focal_loss 0.19219  dice_loss 0.25902 
Epoch [232/300] Validation [3/16] Loss: 0.69762  focal_loss 0.40453  dice_loss 0.29309 
Epoch [232/300] Validation [4/16] Loss: 0.30131  focal_loss 0.15269  dice_loss 0.14862 
Epoch [232/300] Validation [5/16] Loss: 0.36053  focal_loss 0.14135  dice_loss 0.21918 
Epoch [232/300] Validation [6/16] Loss: 0.34770  focal_loss 0.11923  dice_loss 0.22847 
Epoch [232/300] Validation [7/16] Loss: 0.26480  focal_loss 0.09651  dice_loss 0.16829 
Epoch [232/300] Validation [8/16] Loss: 0.55167  focal_loss 0.22329  dice_loss 0.32838 
Epoch [232/300] Validation [9/16] Loss: 0.25134  focal_loss 0.11282  dice_loss 0.13852 
Epoch [232/300] Validation [10/16] Loss: 0.43857  focal_loss 0.14425  dice_loss 0.29432 
Epoch [232/300] Validation [11/16] Loss: 0.14730  focal_loss 0.05410  dice_loss 0.09320 
Epoch [232/300] Validation [12/16] Loss: 0.47353  focal_loss 0.12522  dice_loss 0.34831 
Epoch [232/300] Validation [13/16] Loss: 0.27909  focal_loss 0.11317  dice_loss 0.16592 
Epoch [232/300] Validation [14/16] Loss: 0.45246  focal_loss 0.19321  dice_loss 0.25924 
Epoch [232/300] Validation [15/16] Loss: 0.09938  focal_loss 0.03923  dice_loss 0.06015 
Epoch [232/300] Validation [16/16] Loss: 0.09449  focal_loss 0.03031  dice_loss 0.06418 
Epoch [232/300] Validation metric {'Val/mean dice_metric': 0.9319575428962708, 'Val/mean miou_metric': 0.8937016725540161, 'Val/mean f1': 0.9418970346450806, 'Val/mean precision': 0.9489197134971619, 'Val/mean recall': 0.9349774718284607, 'Val/mean hd95_metric': 16.10463523864746}
Cheakpoint...
Epoch [232/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9320], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9319575428962708, 'Val/mean miou_metric': 0.8937016725540161, 'Val/mean f1': 0.9418970346450806, 'Val/mean precision': 0.9489197134971619, 'Val/mean recall': 0.9349774718284607, 'Val/mean hd95_metric': 16.10463523864746}
Epoch [233/300] Training [1/62] Loss: 0.03955 
Epoch [233/300] Training [2/62] Loss: 0.06513 
Epoch [233/300] Training [3/62] Loss: 0.05926 
Epoch [233/300] Training [4/62] Loss: 0.13201 
Epoch [233/300] Training [5/62] Loss: 0.05739 
Epoch [233/300] Training [6/62] Loss: 0.03159 
Epoch [233/300] Training [7/62] Loss: 0.03391 
Epoch [233/300] Training [8/62] Loss: 0.03284 
Epoch [233/300] Training [9/62] Loss: 0.03068 
Epoch [233/300] Training [10/62] Loss: 0.03438 
Epoch [233/300] Training [11/62] Loss: 0.04189 
Epoch [233/300] Training [12/62] Loss: 0.03446 
Epoch [233/300] Training [13/62] Loss: 0.02958 
Epoch [233/300] Training [14/62] Loss: 0.05160 
Epoch [233/300] Training [15/62] Loss: 0.03598 
Epoch [233/300] Training [16/62] Loss: 0.03083 
Epoch [233/300] Training [17/62] Loss: 0.02701 
Epoch [233/300] Training [18/62] Loss: 0.02728 
Epoch [233/300] Training [19/62] Loss: 0.09617 
Epoch [233/300] Training [20/62] Loss: 0.02712 
Epoch [233/300] Training [21/62] Loss: 0.09134 
Epoch [233/300] Training [22/62] Loss: 0.02659 
Epoch [233/300] Training [23/62] Loss: 0.02922 
Epoch [233/300] Training [24/62] Loss: 0.07715 
Epoch [233/300] Training [25/62] Loss: 0.04999 
Epoch [233/300] Training [26/62] Loss: 0.05769 
Epoch [233/300] Training [27/62] Loss: 0.03781 
Epoch [233/300] Training [28/62] Loss: 0.05257 
Epoch [233/300] Training [29/62] Loss: 0.02461 
Epoch [233/300] Training [30/62] Loss: 0.03150 
Epoch [233/300] Training [31/62] Loss: 0.02712 
Epoch [233/300] Training [32/62] Loss: 0.02515 
Epoch [233/300] Training [33/62] Loss: 0.05843 
Epoch [233/300] Training [34/62] Loss: 0.03578 
Epoch [233/300] Training [35/62] Loss: 0.02730 
Epoch [233/300] Training [36/62] Loss: 0.04625 
Epoch [233/300] Training [37/62] Loss: 0.03354 
Epoch [233/300] Training [38/62] Loss: 0.03574 
Epoch [233/300] Training [39/62] Loss: 0.03697 
Epoch [233/300] Training [40/62] Loss: 0.02290 
Epoch [233/300] Training [41/62] Loss: 0.07610 
Epoch [233/300] Training [42/62] Loss: 0.13574 
Epoch [233/300] Training [43/62] Loss: 0.03199 
Epoch [233/300] Training [44/62] Loss: 0.07794 
Epoch [233/300] Training [45/62] Loss: 0.02864 
Epoch [233/300] Training [46/62] Loss: 0.03112 
Epoch [233/300] Training [47/62] Loss: 0.04726 
Epoch [233/300] Training [48/62] Loss: 0.02799 
Epoch [233/300] Training [49/62] Loss: 0.09526 
Epoch [233/300] Training [50/62] Loss: 0.03010 
Epoch [233/300] Training [51/62] Loss: 0.02834 
Epoch [233/300] Training [52/62] Loss: 0.03034 
Epoch [233/300] Training [53/62] Loss: 0.07851 
Epoch [233/300] Training [54/62] Loss: 0.02120 
Epoch [233/300] Training [55/62] Loss: 0.04196 
Epoch [233/300] Training [56/62] Loss: 0.05625 
Epoch [233/300] Training [57/62] Loss: 0.03347 
Epoch [233/300] Training [58/62] Loss: 0.03648 
Epoch [233/300] Training [59/62] Loss: 0.05347 
Epoch [233/300] Training [60/62] Loss: 0.03737 
Epoch [233/300] Training [61/62] Loss: 0.08480 
Epoch [233/300] Training [62/62] Loss: 0.04792 
Epoch [233/300] Training metric {'Train/mean dice_metric': 0.9685665965080261, 'Train/mean miou_metric': 0.9428725242614746, 'Train/mean f1': 0.9703171849250793, 'Train/mean precision': 0.9675426483154297, 'Train/mean recall': 0.9731076955795288, 'Train/mean hd95_metric': 7.3643059730529785}
Epoch [233/300] Validation [1/16] Loss: 0.63571  focal_loss 0.44001  dice_loss 0.19571 
Epoch [233/300] Validation [2/16] Loss: 0.46910  focal_loss 0.19748  dice_loss 0.27162 
Epoch [233/300] Validation [3/16] Loss: 0.68564  focal_loss 0.38992  dice_loss 0.29572 
Epoch [233/300] Validation [4/16] Loss: 0.35128  focal_loss 0.17694  dice_loss 0.17434 
Epoch [233/300] Validation [5/16] Loss: 0.35088  focal_loss 0.12849  dice_loss 0.22239 
Epoch [233/300] Validation [6/16] Loss: 0.29590  focal_loss 0.09763  dice_loss 0.19827 
Epoch [233/300] Validation [7/16] Loss: 0.25997  focal_loss 0.09517  dice_loss 0.16480 
Epoch [233/300] Validation [8/16] Loss: 0.54184  focal_loss 0.23034  dice_loss 0.31150 
Epoch [233/300] Validation [9/16] Loss: 0.20475  focal_loss 0.08984  dice_loss 0.11490 
Epoch [233/300] Validation [10/16] Loss: 0.48737  focal_loss 0.17266  dice_loss 0.31471 
Epoch [233/300] Validation [11/16] Loss: 0.17505  focal_loss 0.06892  dice_loss 0.10613 
Epoch [233/300] Validation [12/16] Loss: 0.38246  focal_loss 0.12513  dice_loss 0.25734 
Epoch [233/300] Validation [13/16] Loss: 0.27269  focal_loss 0.10592  dice_loss 0.16677 
Epoch [233/300] Validation [14/16] Loss: 0.57585  focal_loss 0.24303  dice_loss 0.33283 
Epoch [233/300] Validation [15/16] Loss: 0.11010  focal_loss 0.03764  dice_loss 0.07246 
Epoch [233/300] Validation [16/16] Loss: 0.09069  focal_loss 0.03310  dice_loss 0.05759 
Epoch [233/300] Validation metric {'Val/mean dice_metric': 0.9336203932762146, 'Val/mean miou_metric': 0.8960821628570557, 'Val/mean f1': 0.9428888559341431, 'Val/mean precision': 0.9501088857650757, 'Val/mean recall': 0.9357777237892151, 'Val/mean hd95_metric': 16.189056396484375}
Cheakpoint...
Epoch [233/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9336], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9336203932762146, 'Val/mean miou_metric': 0.8960821628570557, 'Val/mean f1': 0.9428888559341431, 'Val/mean precision': 0.9501088857650757, 'Val/mean recall': 0.9357777237892151, 'Val/mean hd95_metric': 16.189056396484375}
Epoch [234/300] Training [1/62] Loss: 0.03408 
Epoch [234/300] Training [2/62] Loss: 0.07499 
Epoch [234/300] Training [3/62] Loss: 0.06436 
Epoch [234/300] Training [4/62] Loss: 0.07489 
Epoch [234/300] Training [5/62] Loss: 0.04121 
Epoch [234/300] Training [6/62] Loss: 0.05211 
Epoch [234/300] Training [7/62] Loss: 0.09802 
Epoch [234/300] Training [8/62] Loss: 0.06400 
Epoch [234/300] Training [9/62] Loss: 0.05281 
Epoch [234/300] Training [10/62] Loss: 0.02930 
Epoch [234/300] Training [11/62] Loss: 0.02582 
Epoch [234/300] Training [12/62] Loss: 0.11250 
Epoch [234/300] Training [13/62] Loss: 0.02591 
Epoch [234/300] Training [14/62] Loss: 0.03466 
Epoch [234/300] Training [15/62] Loss: 0.03237 
Epoch [234/300] Training [16/62] Loss: 0.03079 
Epoch [234/300] Training [17/62] Loss: 0.03566 
Epoch [234/300] Training [18/62] Loss: 0.04083 
Epoch [234/300] Training [19/62] Loss: 0.05736 
Epoch [234/300] Training [20/62] Loss: 0.04672 
Epoch [234/300] Training [21/62] Loss: 0.03510 
Epoch [234/300] Training [22/62] Loss: 0.05344 
Epoch [234/300] Training [23/62] Loss: 0.03080 
Epoch [234/300] Training [24/62] Loss: 0.02655 
Epoch [234/300] Training [25/62] Loss: 0.06519 
Epoch [234/300] Training [26/62] Loss: 0.15995 
Epoch [234/300] Training [27/62] Loss: 0.03841 
Epoch [234/300] Training [28/62] Loss: 0.02754 
Epoch [234/300] Training [29/62] Loss: 0.02537 
Epoch [234/300] Training [30/62] Loss: 0.10559 
Epoch [234/300] Training [31/62] Loss: 0.05532 
Epoch [234/300] Training [32/62] Loss: 0.03091 
Epoch [234/300] Training [33/62] Loss: 0.04377 
Epoch [234/300] Training [34/62] Loss: 0.05672 
Epoch [234/300] Training [35/62] Loss: 0.05008 
Epoch [234/300] Training [36/62] Loss: 0.02979 
Epoch [234/300] Training [37/62] Loss: 0.02768 
Epoch [234/300] Training [38/62] Loss: 0.02641 
Epoch [234/300] Training [39/62] Loss: 0.02989 
Epoch [234/300] Training [40/62] Loss: 0.10833 
Epoch [234/300] Training [41/62] Loss: 0.04863 
Epoch [234/300] Training [42/62] Loss: 0.02666 
Epoch [234/300] Training [43/62] Loss: 0.02685 
Epoch [234/300] Training [44/62] Loss: 0.03900 
Epoch [234/300] Training [45/62] Loss: 0.02059 
Epoch [234/300] Training [46/62] Loss: 0.07048 
Epoch [234/300] Training [47/62] Loss: 0.06427 
Epoch [234/300] Training [48/62] Loss: 0.03174 
Epoch [234/300] Training [49/62] Loss: 0.08215 
Epoch [234/300] Training [50/62] Loss: 0.05443 
Epoch [234/300] Training [51/62] Loss: 0.03979 
Epoch [234/300] Training [52/62] Loss: 0.05939 
Epoch [234/300] Training [53/62] Loss: 0.02899 
Epoch [234/300] Training [54/62] Loss: 0.02550 
Epoch [234/300] Training [55/62] Loss: 0.03444 
Epoch [234/300] Training [56/62] Loss: 0.03382 
Epoch [234/300] Training [57/62] Loss: 0.03470 
Epoch [234/300] Training [58/62] Loss: 0.05251 
Epoch [234/300] Training [59/62] Loss: 0.02074 
Epoch [234/300] Training [60/62] Loss: 0.03167 
Epoch [234/300] Training [61/62] Loss: 0.06019 
Epoch [234/300] Training [62/62] Loss: 0.01691 
Epoch [234/300] Training metric {'Train/mean dice_metric': 0.9669051766395569, 'Train/mean miou_metric': 0.9409207105636597, 'Train/mean f1': 0.9701464176177979, 'Train/mean precision': 0.9674462676048279, 'Train/mean recall': 0.9728615283966064, 'Train/mean hd95_metric': 7.017752170562744}
Epoch [234/300] Validation [1/16] Loss: 0.67863  focal_loss 0.47019  dice_loss 0.20844 
Epoch [234/300] Validation [2/16] Loss: 0.59054  focal_loss 0.24074  dice_loss 0.34980 
Epoch [234/300] Validation [3/16] Loss: 0.62588  focal_loss 0.34498  dice_loss 0.28089 
Epoch [234/300] Validation [4/16] Loss: 0.39825  focal_loss 0.19043  dice_loss 0.20781 
Epoch [234/300] Validation [5/16] Loss: 0.45297  focal_loss 0.15794  dice_loss 0.29503 
Epoch [234/300] Validation [6/16] Loss: 0.26615  focal_loss 0.08225  dice_loss 0.18389 
Epoch [234/300] Validation [7/16] Loss: 0.22375  focal_loss 0.10016  dice_loss 0.12358 
Epoch [234/300] Validation [8/16] Loss: 0.61299  focal_loss 0.25221  dice_loss 0.36078 
Epoch [234/300] Validation [9/16] Loss: 0.17204  focal_loss 0.06554  dice_loss 0.10650 
Epoch [234/300] Validation [10/16] Loss: 0.52292  focal_loss 0.16672  dice_loss 0.35620 
Epoch [234/300] Validation [11/16] Loss: 0.15363  focal_loss 0.05940  dice_loss 0.09423 
Epoch [234/300] Validation [12/16] Loss: 0.40173  focal_loss 0.13122  dice_loss 0.27051 
Epoch [234/300] Validation [13/16] Loss: 0.22818  focal_loss 0.08903  dice_loss 0.13915 
Epoch [234/300] Validation [14/16] Loss: 0.56738  focal_loss 0.22707  dice_loss 0.34031 
Epoch [234/300] Validation [15/16] Loss: 0.14204  focal_loss 0.05692  dice_loss 0.08512 
Epoch [234/300] Validation [16/16] Loss: 0.11306  focal_loss 0.04262  dice_loss 0.07043 
Epoch [234/300] Validation metric {'Val/mean dice_metric': 0.9295177459716797, 'Val/mean miou_metric': 0.8918322324752808, 'Val/mean f1': 0.9424067735671997, 'Val/mean precision': 0.9523897767066956, 'Val/mean recall': 0.9326308965682983, 'Val/mean hd95_metric': 15.14448356628418}
Cheakpoint...
Epoch [234/300] best acc:tensor([0.9338], device='cuda:0'), Now : mean acc: tensor([0.9295], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9295177459716797, 'Val/mean miou_metric': 0.8918322324752808, 'Val/mean f1': 0.9424067735671997, 'Val/mean precision': 0.9523897767066956, 'Val/mean recall': 0.9326308965682983, 'Val/mean hd95_metric': 15.14448356628418}
Epoch [235/300] Training [1/62] Loss: 0.05693 
Epoch [235/300] Training [2/62] Loss: 0.03270 
Epoch [235/300] Training [3/62] Loss: 0.03199 
Epoch [235/300] Training [4/62] Loss: 0.03181 
Epoch [235/300] Training [5/62] Loss: 0.03471 
Epoch [235/300] Training [6/62] Loss: 0.03817 
Epoch [235/300] Training [7/62] Loss: 0.04525 
Epoch [235/300] Training [8/62] Loss: 0.02509 
Epoch [235/300] Training [9/62] Loss: 0.04358 
Epoch [235/300] Training [10/62] Loss: 0.04788 
Epoch [235/300] Training [11/62] Loss: 0.07179 
Epoch [235/300] Training [12/62] Loss: 0.02400 
Epoch [235/300] Training [13/62] Loss: 0.04812 
Epoch [235/300] Training [14/62] Loss: 0.02895 
Epoch [235/300] Training [15/62] Loss: 0.03948 
Epoch [235/300] Training [16/62] Loss: 0.04649 
Epoch [235/300] Training [17/62] Loss: 0.03177 
Epoch [235/300] Training [18/62] Loss: 0.02671 
Epoch [235/300] Training [19/62] Loss: 0.02995 
Epoch [235/300] Training [20/62] Loss: 0.06064 
Epoch [235/300] Training [21/62] Loss: 0.15664 
Epoch [235/300] Training [22/62] Loss: 0.03281 
Epoch [235/300] Training [23/62] Loss: 0.02249 
Epoch [235/300] Training [24/62] Loss: 0.02401 
Epoch [235/300] Training [25/62] Loss: 0.02667 
Epoch [235/300] Training [26/62] Loss: 0.02880 
Epoch [235/300] Training [27/62] Loss: 0.03930 
Epoch [235/300] Training [28/62] Loss: 0.02935 
Epoch [235/300] Training [29/62] Loss: 0.08294 
Epoch [235/300] Training [30/62] Loss: 0.03609 
Epoch [235/300] Training [31/62] Loss: 0.12106 
Epoch [235/300] Training [32/62] Loss: 0.02791 
Epoch [235/300] Training [33/62] Loss: 0.03698 
Epoch [235/300] Training [34/62] Loss: 0.03682 
Epoch [235/300] Training [35/62] Loss: 0.03346 
Epoch [235/300] Training [36/62] Loss: 0.03707 
Epoch [235/300] Training [37/62] Loss: 0.07960 
Epoch [235/300] Training [38/62] Loss: 0.03471 
Epoch [235/300] Training [39/62] Loss: 0.02350 
Epoch [235/300] Training [40/62] Loss: 0.05189 
Epoch [235/300] Training [41/62] Loss: 0.03817 
Epoch [235/300] Training [42/62] Loss: 0.02216 
Epoch [235/300] Training [43/62] Loss: 0.02754 
Epoch [235/300] Training [44/62] Loss: 0.03228 
Epoch [235/300] Training [45/62] Loss: 0.03599 
Epoch [235/300] Training [46/62] Loss: 0.03021 
Epoch [235/300] Training [47/62] Loss: 0.03364 
Epoch [235/300] Training [48/62] Loss: 0.03477 
Epoch [235/300] Training [49/62] Loss: 0.02904 
Epoch [235/300] Training [50/62] Loss: 0.03859 
Epoch [235/300] Training [51/62] Loss: 0.09637 
Epoch [235/300] Training [52/62] Loss: 0.04362 
Epoch [235/300] Training [53/62] Loss: 0.02705 
Epoch [235/300] Training [54/62] Loss: 0.05337 
Epoch [235/300] Training [55/62] Loss: 0.03450 
Epoch [235/300] Training [56/62] Loss: 0.02336 
Epoch [235/300] Training [57/62] Loss: 0.03162 
Epoch [235/300] Training [58/62] Loss: 0.07223 
Epoch [235/300] Training [59/62] Loss: 0.09073 
Epoch [235/300] Training [60/62] Loss: 0.04347 
Epoch [235/300] Training [61/62] Loss: 0.04343 
Epoch [235/300] Training [62/62] Loss: 0.02689 
Epoch [235/300] Training metric {'Train/mean dice_metric': 0.9705979824066162, 'Train/mean miou_metric': 0.9461918473243713, 'Train/mean f1': 0.9721766710281372, 'Train/mean precision': 0.9683020114898682, 'Train/mean recall': 0.9760825037956238, 'Train/mean hd95_metric': 6.332307815551758}
Epoch [235/300] Validation [1/16] Loss: 0.66385  focal_loss 0.44391  dice_loss 0.21994 
Epoch [235/300] Validation [2/16] Loss: 0.50257  focal_loss 0.22034  dice_loss 0.28222 
Epoch [235/300] Validation [3/16] Loss: 0.72100  focal_loss 0.44117  dice_loss 0.27983 
Epoch [235/300] Validation [4/16] Loss: 0.35027  focal_loss 0.18828  dice_loss 0.16199 
Epoch [235/300] Validation [5/16] Loss: 0.32237  focal_loss 0.13372  dice_loss 0.18865 
Epoch [235/300] Validation [6/16] Loss: 0.30431  focal_loss 0.10071  dice_loss 0.20360 
Epoch [235/300] Validation [7/16] Loss: 0.25169  focal_loss 0.10086  dice_loss 0.15083 
Epoch [235/300] Validation [8/16] Loss: 0.64466  focal_loss 0.26762  dice_loss 0.37704 
Epoch [235/300] Validation [9/16] Loss: 0.25716  focal_loss 0.11305  dice_loss 0.14411 
Epoch [235/300] Validation [10/16] Loss: 0.45247  focal_loss 0.14746  dice_loss 0.30501 
Epoch [235/300] Validation [11/16] Loss: 0.18359  focal_loss 0.07197  dice_loss 0.11163 
Epoch [235/300] Validation [12/16] Loss: 0.40781  focal_loss 0.13307  dice_loss 0.27474 
Epoch [235/300] Validation [13/16] Loss: 0.29296  focal_loss 0.11889  dice_loss 0.17407 
Epoch [235/300] Validation [14/16] Loss: 0.54497  focal_loss 0.21586  dice_loss 0.32911 
Epoch [235/300] Validation [15/16] Loss: 0.11811  focal_loss 0.04184  dice_loss 0.07627 
Epoch [235/300] Validation [16/16] Loss: 0.08493  focal_loss 0.02713  dice_loss 0.05781 
Epoch [235/300] Validation metric {'Val/mean dice_metric': 0.9340335726737976, 'Val/mean miou_metric': 0.8965772986412048, 'Val/mean f1': 0.942899763584137, 'Val/mean precision': 0.9524940252304077, 'Val/mean recall': 0.9334968328475952, 'Val/mean hd95_metric': 15.17164134979248}
Cheakpoint...
Epoch [235/300] best acc:tensor([0.9340], device='cuda:0'), Now : mean acc: tensor([0.9340], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9340335726737976, 'Val/mean miou_metric': 0.8965772986412048, 'Val/mean f1': 0.942899763584137, 'Val/mean precision': 0.9524940252304077, 'Val/mean recall': 0.9334968328475952, 'Val/mean hd95_metric': 15.17164134979248}
Epoch [236/300] Training [1/62] Loss: 0.03693 
Epoch [236/300] Training [2/62] Loss: 0.02922 
Epoch [236/300] Training [3/62] Loss: 0.02590 
Epoch [236/300] Training [4/62] Loss: 0.02613 
Epoch [236/300] Training [5/62] Loss: 0.05754 
Epoch [236/300] Training [6/62] Loss: 0.02872 
Epoch [236/300] Training [7/62] Loss: 0.02561 
Epoch [236/300] Training [8/62] Loss: 0.04580 
Epoch [236/300] Training [9/62] Loss: 0.02403 
Epoch [236/300] Training [10/62] Loss: 0.02787 
Epoch [236/300] Training [11/62] Loss: 0.03309 
Epoch [236/300] Training [12/62] Loss: 0.06162 
Epoch [236/300] Training [13/62] Loss: 0.03688 
Epoch [236/300] Training [14/62] Loss: 0.06520 
Epoch [236/300] Training [15/62] Loss: 0.03233 
Epoch [236/300] Training [16/62] Loss: 0.02173 
Epoch [236/300] Training [17/62] Loss: 0.03585 
Epoch [236/300] Training [18/62] Loss: 0.05219 
Epoch [236/300] Training [19/62] Loss: 0.03310 
Epoch [236/300] Training [20/62] Loss: 0.03006 
Epoch [236/300] Training [21/62] Loss: 0.15282 
Epoch [236/300] Training [22/62] Loss: 0.03211 
Epoch [236/300] Training [23/62] Loss: 0.02058 
Epoch [236/300] Training [24/62] Loss: 0.06744 
Epoch [236/300] Training [25/62] Loss: 0.02609 
Epoch [236/300] Training [26/62] Loss: 0.04450 
Epoch [236/300] Training [27/62] Loss: 0.09765 
Epoch [236/300] Training [28/62] Loss: 0.04804 
Epoch [236/300] Training [29/62] Loss: 0.02915 
Epoch [236/300] Training [30/62] Loss: 0.02457 
Epoch [236/300] Training [31/62] Loss: 0.04218 
Epoch [236/300] Training [32/62] Loss: 0.02680 
Epoch [236/300] Training [33/62] Loss: 0.05809 
Epoch [236/300] Training [34/62] Loss: 0.04582 
Epoch [236/300] Training [35/62] Loss: 0.04018 
Epoch [236/300] Training [36/62] Loss: 0.05485 
Epoch [236/300] Training [37/62] Loss: 0.05936 
Epoch [236/300] Training [38/62] Loss: 0.02749 
Epoch [236/300] Training [39/62] Loss: 0.12280 
Epoch [236/300] Training [40/62] Loss: 0.03684 
Epoch [236/300] Training [41/62] Loss: 0.13402 
Epoch [236/300] Training [42/62] Loss: 0.09347 
Epoch [236/300] Training [43/62] Loss: 0.02404 
Epoch [236/300] Training [44/62] Loss: 0.04337 
Epoch [236/300] Training [45/62] Loss: 0.05164 
Epoch [236/300] Training [46/62] Loss: 0.04404 
Epoch [236/300] Training [47/62] Loss: 0.04689 
Epoch [236/300] Training [48/62] Loss: 0.05085 
Epoch [236/300] Training [49/62] Loss: 0.05922 
Epoch [236/300] Training [50/62] Loss: 0.03650 
Epoch [236/300] Training [51/62] Loss: 0.04434 
Epoch [236/300] Training [52/62] Loss: 0.02636 
Epoch [236/300] Training [53/62] Loss: 0.05478 
Epoch [236/300] Training [54/62] Loss: 0.04113 
Epoch [236/300] Training [55/62] Loss: 0.03253 
Epoch [236/300] Training [56/62] Loss: 0.03795 
Epoch [236/300] Training [57/62] Loss: 0.03392 
Epoch [236/300] Training [58/62] Loss: 0.02775 
Epoch [236/300] Training [59/62] Loss: 0.03709 
Epoch [236/300] Training [60/62] Loss: 0.02425 
Epoch [236/300] Training [61/62] Loss: 0.02463 
Epoch [236/300] Training [62/62] Loss: 0.01931 
Epoch [236/300] Training metric {'Train/mean dice_metric': 0.9688274264335632, 'Train/mean miou_metric': 0.9439598321914673, 'Train/mean f1': 0.9717567563056946, 'Train/mean precision': 0.9681126475334167, 'Train/mean recall': 0.9754284024238586, 'Train/mean hd95_metric': 7.175881385803223}
Epoch [236/300] Validation [1/16] Loss: 0.62803  focal_loss 0.43531  dice_loss 0.19272 
Epoch [236/300] Validation [2/16] Loss: 0.51073  focal_loss 0.23135  dice_loss 0.27938 
Epoch [236/300] Validation [3/16] Loss: 0.66541  focal_loss 0.39664  dice_loss 0.26877 
Epoch [236/300] Validation [4/16] Loss: 0.29952  focal_loss 0.16046  dice_loss 0.13906 
Epoch [236/300] Validation [5/16] Loss: 0.30740  focal_loss 0.11567  dice_loss 0.19173 
Epoch [236/300] Validation [6/16] Loss: 0.29481  focal_loss 0.09670  dice_loss 0.19811 
Epoch [236/300] Validation [7/16] Loss: 0.18979  focal_loss 0.08594  dice_loss 0.10385 
Epoch [236/300] Validation [8/16] Loss: 0.53548  focal_loss 0.23249  dice_loss 0.30299 
Epoch [236/300] Validation [9/16] Loss: 0.20704  focal_loss 0.08261  dice_loss 0.12443 
Epoch [236/300] Validation [10/16] Loss: 0.48956  focal_loss 0.16204  dice_loss 0.32753 
Epoch [236/300] Validation [11/16] Loss: 0.15047  focal_loss 0.05572  dice_loss 0.09475 
Epoch [236/300] Validation [12/16] Loss: 0.36860  focal_loss 0.11226  dice_loss 0.25634 
Epoch [236/300] Validation [13/16] Loss: 0.25976  focal_loss 0.10675  dice_loss 0.15301 
Epoch [236/300] Validation [14/16] Loss: 0.53485  focal_loss 0.24713  dice_loss 0.28772 
Epoch [236/300] Validation [15/16] Loss: 0.19804  focal_loss 0.07998  dice_loss 0.11806 
Epoch [236/300] Validation [16/16] Loss: 0.09353  focal_loss 0.03192  dice_loss 0.06160 
Epoch [236/300] Validation metric {'Val/mean dice_metric': 0.9356735348701477, 'Val/mean miou_metric': 0.8985435962677002, 'Val/mean f1': 0.9445724487304688, 'Val/mean precision': 0.9513368010520935, 'Val/mean recall': 0.9379034638404846, 'Val/mean hd95_metric': 15.218185424804688}
Cheakpoint...
Epoch [236/300] best acc:tensor([0.9357], device='cuda:0'), Now : mean acc: tensor([0.9357], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9356735348701477, 'Val/mean miou_metric': 0.8985435962677002, 'Val/mean f1': 0.9445724487304688, 'Val/mean precision': 0.9513368010520935, 'Val/mean recall': 0.9379034638404846, 'Val/mean hd95_metric': 15.218185424804688}
Epoch [237/300] Training [1/62] Loss: 0.04168 
Epoch [237/300] Training [2/62] Loss: 0.03909 
Epoch [237/300] Training [3/62] Loss: 0.05171 
Epoch [237/300] Training [4/62] Loss: 0.02539 
Epoch [237/300] Training [5/62] Loss: 0.02372 
Epoch [237/300] Training [6/62] Loss: 0.02929 
Epoch [237/300] Training [7/62] Loss: 0.05484 
Epoch [237/300] Training [8/62] Loss: 0.04241 
Epoch [237/300] Training [9/62] Loss: 0.06990 
Epoch [237/300] Training [10/62] Loss: 0.03803 
Epoch [237/300] Training [11/62] Loss: 0.03268 
Epoch [237/300] Training [12/62] Loss: 0.08390 
Epoch [237/300] Training [13/62] Loss: 0.03269 
Epoch [237/300] Training [14/62] Loss: 0.02886 
Epoch [237/300] Training [15/62] Loss: 0.02565 
Epoch [237/300] Training [16/62] Loss: 0.02653 
Epoch [237/300] Training [17/62] Loss: 0.03456 
Epoch [237/300] Training [18/62] Loss: 0.02604 
Epoch [237/300] Training [19/62] Loss: 0.03059 
Epoch [237/300] Training [20/62] Loss: 0.03038 
Epoch [237/300] Training [21/62] Loss: 0.02799 
Epoch [237/300] Training [22/62] Loss: 0.02068 
Epoch [237/300] Training [23/62] Loss: 0.03481 
Epoch [237/300] Training [24/62] Loss: 0.14574 
Epoch [237/300] Training [25/62] Loss: 0.04303 
Epoch [237/300] Training [26/62] Loss: 0.02267 
Epoch [237/300] Training [27/62] Loss: 0.05693 
Epoch [237/300] Training [28/62] Loss: 0.02508 
Epoch [237/300] Training [29/62] Loss: 0.05815 
Epoch [237/300] Training [30/62] Loss: 0.02856 
Epoch [237/300] Training [31/62] Loss: 0.07384 
Epoch [237/300] Training [32/62] Loss: 0.03293 
Epoch [237/300] Training [33/62] Loss: 0.02939 
Epoch [237/300] Training [34/62] Loss: 0.03494 
Epoch [237/300] Training [35/62] Loss: 0.03603 
Epoch [237/300] Training [36/62] Loss: 0.06955 
Epoch [237/300] Training [37/62] Loss: 0.03822 
Epoch [237/300] Training [38/62] Loss: 0.04039 
Epoch [237/300] Training [39/62] Loss: 0.02562 
Epoch [237/300] Training [40/62] Loss: 0.02360 
Epoch [237/300] Training [41/62] Loss: 0.03669 
Epoch [237/300] Training [42/62] Loss: 0.02393 
Epoch [237/300] Training [43/62] Loss: 0.02664 
Epoch [237/300] Training [44/62] Loss: 0.03223 
Epoch [237/300] Training [45/62] Loss: 0.03276 
Epoch [237/300] Training [46/62] Loss: 0.06857 
Epoch [237/300] Training [47/62] Loss: 0.03399 
Epoch [237/300] Training [48/62] Loss: 0.04150 
Epoch [237/300] Training [49/62] Loss: 0.03238 
Epoch [237/300] Training [50/62] Loss: 0.04553 
Epoch [237/300] Training [51/62] Loss: 0.03273 
Epoch [237/300] Training [52/62] Loss: 0.03782 
Epoch [237/300] Training [53/62] Loss: 0.03806 
Epoch [237/300] Training [54/62] Loss: 0.12854 
Epoch [237/300] Training [55/62] Loss: 0.04445 
Epoch [237/300] Training [56/62] Loss: 0.02122 
Epoch [237/300] Training [57/62] Loss: 0.03235 
Epoch [237/300] Training [58/62] Loss: 0.03824 
Epoch [237/300] Training [59/62] Loss: 0.04525 
Epoch [237/300] Training [60/62] Loss: 0.03397 
Epoch [237/300] Training [61/62] Loss: 0.04154 
Epoch [237/300] Training [62/62] Loss: 0.07387 
Epoch [237/300] Training metric {'Train/mean dice_metric': 0.972279965877533, 'Train/mean miou_metric': 0.9485820531845093, 'Train/mean f1': 0.9725058078765869, 'Train/mean precision': 0.9682812690734863, 'Train/mean recall': 0.9767672419548035, 'Train/mean hd95_metric': 5.837515354156494}
Epoch [237/300] Validation [1/16] Loss: 0.67423  focal_loss 0.46475  dice_loss 0.20948 
Epoch [237/300] Validation [2/16] Loss: 0.45457  focal_loss 0.20636  dice_loss 0.24821 
Epoch [237/300] Validation [3/16] Loss: 0.69049  focal_loss 0.41706  dice_loss 0.27344 
Epoch [237/300] Validation [4/16] Loss: 0.31403  focal_loss 0.16857  dice_loss 0.14547 
Epoch [237/300] Validation [5/16] Loss: 0.36156  focal_loss 0.14887  dice_loss 0.21269 
Epoch [237/300] Validation [6/16] Loss: 0.27589  focal_loss 0.08902  dice_loss 0.18687 
Epoch [237/300] Validation [7/16] Loss: 0.28574  focal_loss 0.10985  dice_loss 0.17590 
Epoch [237/300] Validation [8/16] Loss: 0.54134  focal_loss 0.23362  dice_loss 0.30772 
Epoch [237/300] Validation [9/16] Loss: 0.22374  focal_loss 0.09857  dice_loss 0.12517 
Epoch [237/300] Validation [10/16] Loss: 0.56723  focal_loss 0.20840  dice_loss 0.35882 
Epoch [237/300] Validation [11/16] Loss: 0.16774  focal_loss 0.06335  dice_loss 0.10438 
Epoch [237/300] Validation [12/16] Loss: 0.36394  focal_loss 0.11055  dice_loss 0.25338 
Epoch [237/300] Validation [13/16] Loss: 0.24452  focal_loss 0.09137  dice_loss 0.15315 
Epoch [237/300] Validation [14/16] Loss: 0.69380  focal_loss 0.31834  dice_loss 0.37546 
Epoch [237/300] Validation [15/16] Loss: 0.09795  focal_loss 0.03993  dice_loss 0.05801 
Epoch [237/300] Validation [16/16] Loss: 0.13499  focal_loss 0.03914  dice_loss 0.09585 
Epoch [237/300] Validation metric {'Val/mean dice_metric': 0.9363502860069275, 'Val/mean miou_metric': 0.9009706377983093, 'Val/mean f1': 0.9447328448295593, 'Val/mean precision': 0.9502407908439636, 'Val/mean recall': 0.9392881989479065, 'Val/mean hd95_metric': 15.163081169128418}
Cheakpoint...
Epoch [237/300] best acc:tensor([0.9364], device='cuda:0'), Now : mean acc: tensor([0.9364], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9363502860069275, 'Val/mean miou_metric': 0.9009706377983093, 'Val/mean f1': 0.9447328448295593, 'Val/mean precision': 0.9502407908439636, 'Val/mean recall': 0.9392881989479065, 'Val/mean hd95_metric': 15.163081169128418}
Epoch [238/300] Training [1/62] Loss: 0.03475 
Epoch [238/300] Training [2/62] Loss: 0.04157 
Epoch [238/300] Training [3/62] Loss: 0.06179 
Epoch [238/300] Training [4/62] Loss: 0.03120 
Epoch [238/300] Training [5/62] Loss: 0.05938 
Epoch [238/300] Training [6/62] Loss: 0.03345 
Epoch [238/300] Training [7/62] Loss: 0.03102 
Epoch [238/300] Training [8/62] Loss: 0.04593 
Epoch [238/300] Training [9/62] Loss: 0.04017 
Epoch [238/300] Training [10/62] Loss: 0.03651 
Epoch [238/300] Training [11/62] Loss: 0.03599 
Epoch [238/300] Training [12/62] Loss: 0.04096 
Epoch [238/300] Training [13/62] Loss: 0.03337 
Epoch [238/300] Training [14/62] Loss: 0.04915 
Epoch [238/300] Training [15/62] Loss: 0.03351 
Epoch [238/300] Training [16/62] Loss: 0.02600 
Epoch [238/300] Training [17/62] Loss: 0.02057 
Epoch [238/300] Training [18/62] Loss: 0.03194 
Epoch [238/300] Training [19/62] Loss: 0.02425 
Epoch [238/300] Training [20/62] Loss: 0.03363 
Epoch [238/300] Training [21/62] Loss: 0.04933 
Epoch [238/300] Training [22/62] Loss: 0.07082 
Epoch [238/300] Training [23/62] Loss: 0.04379 
Epoch [238/300] Training [24/62] Loss: 0.03306 
Epoch [238/300] Training [25/62] Loss: 0.02878 
Epoch [238/300] Training [26/62] Loss: 0.02749 
Epoch [238/300] Training [27/62] Loss: 0.04046 
Epoch [238/300] Training [28/62] Loss: 0.03990 
Epoch [238/300] Training [29/62] Loss: 0.04239 
Epoch [238/300] Training [30/62] Loss: 0.02334 
Epoch [238/300] Training [31/62] Loss: 0.03158 
Epoch [238/300] Training [32/62] Loss: 0.02619 
Epoch [238/300] Training [33/62] Loss: 0.02198 
Epoch [238/300] Training [34/62] Loss: 0.08475 
Epoch [238/300] Training [35/62] Loss: 0.04310 
Epoch [238/300] Training [36/62] Loss: 0.05527 
Epoch [238/300] Training [37/62] Loss: 0.03119 
Epoch [238/300] Training [38/62] Loss: 0.08130 
Epoch [238/300] Training [39/62] Loss: 0.02476 
Epoch [238/300] Training [40/62] Loss: 0.05039 
Epoch [238/300] Training [41/62] Loss: 0.04878 
Epoch [238/300] Training [42/62] Loss: 0.03663 
Epoch [238/300] Training [43/62] Loss: 0.03668 
Epoch [238/300] Training [44/62] Loss: 0.07705 
Epoch [238/300] Training [45/62] Loss: 0.04428 
Epoch [238/300] Training [46/62] Loss: 0.02320 
Epoch [238/300] Training [47/62] Loss: 0.04201 
Epoch [238/300] Training [48/62] Loss: 0.02307 
Epoch [238/300] Training [49/62] Loss: 0.04943 
Epoch [238/300] Training [50/62] Loss: 0.03201 
Epoch [238/300] Training [51/62] Loss: 0.03331 
Epoch [238/300] Training [52/62] Loss: 0.03008 
Epoch [238/300] Training [53/62] Loss: 0.03081 
Epoch [238/300] Training [54/62] Loss: 0.02884 
Epoch [238/300] Training [55/62] Loss: 0.04740 
Epoch [238/300] Training [56/62] Loss: 0.02837 
Epoch [238/300] Training [57/62] Loss: 0.03408 
Epoch [238/300] Training [58/62] Loss: 0.03336 
Epoch [238/300] Training [59/62] Loss: 0.05207 
Epoch [238/300] Training [60/62] Loss: 0.02220 
Epoch [238/300] Training [61/62] Loss: 0.04727 
Epoch [238/300] Training [62/62] Loss: 0.07540 
Epoch [238/300] Training metric {'Train/mean dice_metric': 0.9737557768821716, 'Train/mean miou_metric': 0.9502735137939453, 'Train/mean f1': 0.9734618663787842, 'Train/mean precision': 0.9694629311561584, 'Train/mean recall': 0.9774938821792603, 'Train/mean hd95_metric': 7.311429977416992}
Epoch [238/300] Validation [1/16] Loss: 0.67592  focal_loss 0.46465  dice_loss 0.21127 
Epoch [238/300] Validation [2/16] Loss: 0.47565  focal_loss 0.20784  dice_loss 0.26781 
Epoch [238/300] Validation [3/16] Loss: 0.71690  focal_loss 0.42736  dice_loss 0.28953 
Epoch [238/300] Validation [4/16] Loss: 0.31770  focal_loss 0.15993  dice_loss 0.15776 
Epoch [238/300] Validation [5/16] Loss: 0.46167  focal_loss 0.17185  dice_loss 0.28982 
Epoch [238/300] Validation [6/16] Loss: 0.27942  focal_loss 0.09348  dice_loss 0.18595 
Epoch [238/300] Validation [7/16] Loss: 0.18095  focal_loss 0.08228  dice_loss 0.09867 
Epoch [238/300] Validation [8/16] Loss: 0.52548  focal_loss 0.21599  dice_loss 0.30949 
Epoch [238/300] Validation [9/16] Loss: 0.20115  focal_loss 0.08527  dice_loss 0.11587 
Epoch [238/300] Validation [10/16] Loss: 0.43821  focal_loss 0.13094  dice_loss 0.30726 
Epoch [238/300] Validation [11/16] Loss: 0.16479  focal_loss 0.06582  dice_loss 0.09897 
Epoch [238/300] Validation [12/16] Loss: 0.39532  focal_loss 0.12443  dice_loss 0.27089 
Epoch [238/300] Validation [13/16] Loss: 0.18349  focal_loss 0.06947  dice_loss 0.11402 
Epoch [238/300] Validation [14/16] Loss: 0.54432  focal_loss 0.22472  dice_loss 0.31960 
Epoch [238/300] Validation [15/16] Loss: 0.11347  focal_loss 0.04604  dice_loss 0.06743 
Epoch [238/300] Validation [16/16] Loss: 0.12333  focal_loss 0.04279  dice_loss 0.08054 
Epoch [238/300] Validation metric {'Val/mean dice_metric': 0.9387853145599365, 'Val/mean miou_metric': 0.9035049080848694, 'Val/mean f1': 0.9459841847419739, 'Val/mean precision': 0.9515925049781799, 'Val/mean recall': 0.9404416680335999, 'Val/mean hd95_metric': 15.907455444335938}
Cheakpoint...
Epoch [238/300] best acc:tensor([0.9388], device='cuda:0'), Now : mean acc: tensor([0.9388], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9387853145599365, 'Val/mean miou_metric': 0.9035049080848694, 'Val/mean f1': 0.9459841847419739, 'Val/mean precision': 0.9515925049781799, 'Val/mean recall': 0.9404416680335999, 'Val/mean hd95_metric': 15.907455444335938}
Epoch [239/300] Training [1/62] Loss: 0.03232 
Epoch [239/300] Training [2/62] Loss: 0.02845 
Epoch [239/300] Training [3/62] Loss: 0.02634 
Epoch [239/300] Training [4/62] Loss: 0.02644 
Epoch [239/300] Training [5/62] Loss: 0.05068 
Epoch [239/300] Training [6/62] Loss: 0.03266 
Epoch [239/300] Training [7/62] Loss: 0.03508 
Epoch [239/300] Training [8/62] Loss: 0.04003 
Epoch [239/300] Training [9/62] Loss: 0.02993 
Epoch [239/300] Training [10/62] Loss: 0.04561 
Epoch [239/300] Training [11/62] Loss: 0.02763 
Epoch [239/300] Training [12/62] Loss: 0.03017 
Epoch [239/300] Training [13/62] Loss: 0.04655 
Epoch [239/300] Training [14/62] Loss: 0.02327 
Epoch [239/300] Training [15/62] Loss: 0.03200 
Epoch [239/300] Training [16/62] Loss: 0.02644 
Epoch [239/300] Training [17/62] Loss: 0.02599 
Epoch [239/300] Training [18/62] Loss: 0.03325 
Epoch [239/300] Training [19/62] Loss: 0.05182 
Epoch [239/300] Training [20/62] Loss: 0.08659 
Epoch [239/300] Training [21/62] Loss: 0.03368 
Epoch [239/300] Training [22/62] Loss: 0.03756 
Epoch [239/300] Training [23/62] Loss: 0.03435 
Epoch [239/300] Training [24/62] Loss: 0.03468 
Epoch [239/300] Training [25/62] Loss: 0.02493 
Epoch [239/300] Training [26/62] Loss: 0.03511 
Epoch [239/300] Training [27/62] Loss: 0.02682 
Epoch [239/300] Training [28/62] Loss: 0.04372 
Epoch [239/300] Training [29/62] Loss: 0.02866 
Epoch [239/300] Training [30/62] Loss: 0.03545 
Epoch [239/300] Training [31/62] Loss: 0.04166 
Epoch [239/300] Training [32/62] Loss: 0.04680 
Epoch [239/300] Training [33/62] Loss: 0.04005 
Epoch [239/300] Training [34/62] Loss: 0.08017 
Epoch [239/300] Training [35/62] Loss: 0.03078 
Epoch [239/300] Training [36/62] Loss: 0.02673 
Epoch [239/300] Training [37/62] Loss: 0.02620 
Epoch [239/300] Training [38/62] Loss: 0.06893 
Epoch [239/300] Training [39/62] Loss: 0.04341 
Epoch [239/300] Training [40/62] Loss: 0.02817 
Epoch [239/300] Training [41/62] Loss: 0.04905 
Epoch [239/300] Training [42/62] Loss: 0.05797 
Epoch [239/300] Training [43/62] Loss: 0.02580 
Epoch [239/300] Training [44/62] Loss: 0.02664 
Epoch [239/300] Training [45/62] Loss: 0.02609 
Epoch [239/300] Training [46/62] Loss: 0.03214 
Epoch [239/300] Training [47/62] Loss: 0.04378 
Epoch [239/300] Training [48/62] Loss: 0.05307 
Epoch [239/300] Training [49/62] Loss: 0.03495 
Epoch [239/300] Training [50/62] Loss: 0.04062 
Epoch [239/300] Training [51/62] Loss: 0.04649 
Epoch [239/300] Training [52/62] Loss: 0.02140 
Epoch [239/300] Training [53/62] Loss: 0.02918 
Epoch [239/300] Training [54/62] Loss: 0.02302 
Epoch [239/300] Training [55/62] Loss: 0.06039 
Epoch [239/300] Training [56/62] Loss: 0.05021 
Epoch [239/300] Training [57/62] Loss: 0.05905 
Epoch [239/300] Training [58/62] Loss: 0.02399 
Epoch [239/300] Training [59/62] Loss: 0.03603 
Epoch [239/300] Training [60/62] Loss: 0.04244 
Epoch [239/300] Training [61/62] Loss: 0.06222 
Epoch [239/300] Training [62/62] Loss: 0.05152 
Epoch [239/300] Training metric {'Train/mean dice_metric': 0.9743910431861877, 'Train/mean miou_metric': 0.9512090682983398, 'Train/mean f1': 0.973829448223114, 'Train/mean precision': 0.9696305990219116, 'Train/mean recall': 0.978064775466919, 'Train/mean hd95_metric': 5.524813652038574}
Epoch [239/300] Validation [1/16] Loss: 0.64335  focal_loss 0.43836  dice_loss 0.20499 
Epoch [239/300] Validation [2/16] Loss: 0.50133  focal_loss 0.22275  dice_loss 0.27858 
Epoch [239/300] Validation [3/16] Loss: 0.57438  focal_loss 0.32341  dice_loss 0.25097 
Epoch [239/300] Validation [4/16] Loss: 0.38417  focal_loss 0.19715  dice_loss 0.18702 
Epoch [239/300] Validation [5/16] Loss: 0.38140  focal_loss 0.16875  dice_loss 0.21265 
Epoch [239/300] Validation [6/16] Loss: 0.31556  focal_loss 0.10702  dice_loss 0.20853 
Epoch [239/300] Validation [7/16] Loss: 0.22338  focal_loss 0.10505  dice_loss 0.11834 
Epoch [239/300] Validation [8/16] Loss: 0.46110  focal_loss 0.19452  dice_loss 0.26659 
Epoch [239/300] Validation [9/16] Loss: 0.21549  focal_loss 0.09880  dice_loss 0.11669 
Epoch [239/300] Validation [10/16] Loss: 0.46652  focal_loss 0.15477  dice_loss 0.31175 
Epoch [239/300] Validation [11/16] Loss: 0.18595  focal_loss 0.06824  dice_loss 0.11770 
Epoch [239/300] Validation [12/16] Loss: 0.39750  focal_loss 0.14126  dice_loss 0.25624 
Epoch [239/300] Validation [13/16] Loss: 0.25873  focal_loss 0.10515  dice_loss 0.15359 
Epoch [239/300] Validation [14/16] Loss: 0.57715  focal_loss 0.27640  dice_loss 0.30075 
Epoch [239/300] Validation [15/16] Loss: 0.12161  focal_loss 0.04743  dice_loss 0.07418 
Epoch [239/300] Validation [16/16] Loss: 0.16670  focal_loss 0.05797  dice_loss 0.10872 
Epoch [239/300] Validation metric {'Val/mean dice_metric': 0.9396464228630066, 'Val/mean miou_metric': 0.9035555720329285, 'Val/mean f1': 0.9457256197929382, 'Val/mean precision': 0.9517162442207336, 'Val/mean recall': 0.939810037612915, 'Val/mean hd95_metric': 14.62220287322998}
Cheakpoint...
Epoch [239/300] best acc:tensor([0.9396], device='cuda:0'), Now : mean acc: tensor([0.9396], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9396464228630066, 'Val/mean miou_metric': 0.9035555720329285, 'Val/mean f1': 0.9457256197929382, 'Val/mean precision': 0.9517162442207336, 'Val/mean recall': 0.939810037612915, 'Val/mean hd95_metric': 14.62220287322998}
Epoch [240/300] Training [1/62] Loss: 0.05801 
Epoch [240/300] Training [2/62] Loss: 0.02866 
Epoch [240/300] Training [3/62] Loss: 0.02639 
Epoch [240/300] Training [4/62] Loss: 0.06486 
Epoch [240/300] Training [5/62] Loss: 0.12659 
Epoch [240/300] Training [6/62] Loss: 0.09384 
Epoch [240/300] Training [7/62] Loss: 0.02694 
Epoch [240/300] Training [8/62] Loss: 0.03250 
Epoch [240/300] Training [9/62] Loss: 0.04127 
Epoch [240/300] Training [10/62] Loss: 0.04341 
Epoch [240/300] Training [11/62] Loss: 0.04012 
Epoch [240/300] Training [12/62] Loss: 0.02930 
Epoch [240/300] Training [13/62] Loss: 0.02605 
Epoch [240/300] Training [14/62] Loss: 0.06549 
Epoch [240/300] Training [15/62] Loss: 0.03060 
Epoch [240/300] Training [16/62] Loss: 0.09807 
Epoch [240/300] Training [17/62] Loss: 0.08341 
Epoch [240/300] Training [18/62] Loss: 0.03176 
Epoch [240/300] Training [19/62] Loss: 0.03659 
Epoch [240/300] Training [20/62] Loss: 0.08680 
Epoch [240/300] Training [21/62] Loss: 0.02349 
Epoch [240/300] Training [22/62] Loss: 0.06309 
Epoch [240/300] Training [23/62] Loss: 0.07058 
Epoch [240/300] Training [24/62] Loss: 0.03247 
Epoch [240/300] Training [25/62] Loss: 0.03526 
Epoch [240/300] Training [26/62] Loss: 0.04002 
Epoch [240/300] Training [27/62] Loss: 0.03243 
Epoch [240/300] Training [28/62] Loss: 0.02378 
Epoch [240/300] Training [29/62] Loss: 0.02404 
Epoch [240/300] Training [30/62] Loss: 0.03991 
Epoch [240/300] Training [31/62] Loss: 0.02534 
Epoch [240/300] Training [32/62] Loss: 0.03355 
Epoch [240/300] Training [33/62] Loss: 0.03383 
Epoch [240/300] Training [34/62] Loss: 0.04317 
Epoch [240/300] Training [35/62] Loss: 0.03003 
Epoch [240/300] Training [36/62] Loss: 0.02706 
Epoch [240/300] Training [37/62] Loss: 0.04158 
Epoch [240/300] Training [38/62] Loss: 0.05700 
Epoch [240/300] Training [39/62] Loss: 0.06527 
Epoch [240/300] Training [40/62] Loss: 0.03530 
Epoch [240/300] Training [41/62] Loss: 0.02793 
Epoch [240/300] Training [42/62] Loss: 0.06717 
Epoch [240/300] Training [43/62] Loss: 0.02431 
Epoch [240/300] Training [44/62] Loss: 0.02532 
Epoch [240/300] Training [45/62] Loss: 0.07275 
Epoch [240/300] Training [46/62] Loss: 0.05039 
Epoch [240/300] Training [47/62] Loss: 0.04079 
Epoch [240/300] Training [48/62] Loss: 0.02696 
Epoch [240/300] Training [49/62] Loss: 0.02728 
Epoch [240/300] Training [50/62] Loss: 0.04280 
Epoch [240/300] Training [51/62] Loss: 0.08644 
Epoch [240/300] Training [52/62] Loss: 0.03050 
Epoch [240/300] Training [53/62] Loss: 0.06370 
Epoch [240/300] Training [54/62] Loss: 0.02853 
Epoch [240/300] Training [55/62] Loss: 0.05027 
Epoch [240/300] Training [56/62] Loss: 0.03258 
Epoch [240/300] Training [57/62] Loss: 0.02674 
Epoch [240/300] Training [58/62] Loss: 0.02204 
Epoch [240/300] Training [59/62] Loss: 0.03676 
Epoch [240/300] Training [60/62] Loss: 0.02937 
Epoch [240/300] Training [61/62] Loss: 0.03364 
Epoch [240/300] Training [62/62] Loss: 0.14608 
Epoch [240/300] Training metric {'Train/mean dice_metric': 0.9693800806999207, 'Train/mean miou_metric': 0.943695068359375, 'Train/mean f1': 0.9724708795547485, 'Train/mean precision': 0.9685769081115723, 'Train/mean recall': 0.976396381855011, 'Train/mean hd95_metric': 7.729634761810303}
Epoch [240/300] Validation [1/16] Loss: 0.64464  focal_loss 0.45434  dice_loss 0.19030 
Epoch [240/300] Validation [2/16] Loss: 0.57169  focal_loss 0.24149  dice_loss 0.33021 
Epoch [240/300] Validation [3/16] Loss: 0.75654  focal_loss 0.46375  dice_loss 0.29279 
Epoch [240/300] Validation [4/16] Loss: 0.30716  focal_loss 0.16219  dice_loss 0.14497 
Epoch [240/300] Validation [5/16] Loss: 0.45814  focal_loss 0.15695  dice_loss 0.30119 
Epoch [240/300] Validation [6/16] Loss: 0.33358  focal_loss 0.11257  dice_loss 0.22101 
Epoch [240/300] Validation [7/16] Loss: 0.33215  focal_loss 0.12893  dice_loss 0.20322 
Epoch [240/300] Validation [8/16] Loss: 0.49411  focal_loss 0.21043  dice_loss 0.28369 
Epoch [240/300] Validation [9/16] Loss: 0.20257  focal_loss 0.08926  dice_loss 0.11331 
Epoch [240/300] Validation [10/16] Loss: 0.52769  focal_loss 0.19595  dice_loss 0.33174 
Epoch [240/300] Validation [11/16] Loss: 0.19493  focal_loss 0.08143  dice_loss 0.11349 
Epoch [240/300] Validation [12/16] Loss: 0.38108  focal_loss 0.13136  dice_loss 0.24972 
Epoch [240/300] Validation [13/16] Loss: 0.21747  focal_loss 0.07296  dice_loss 0.14451 
Epoch [240/300] Validation [14/16] Loss: 0.60661  focal_loss 0.28076  dice_loss 0.32585 
Epoch [240/300] Validation [15/16] Loss: 0.09938  focal_loss 0.03831  dice_loss 0.06107 
Epoch [240/300] Validation [16/16] Loss: 0.20211  focal_loss 0.08006  dice_loss 0.12205 
Epoch [240/300] Validation metric {'Val/mean dice_metric': 0.9323667883872986, 'Val/mean miou_metric': 0.8948220610618591, 'Val/mean f1': 0.9443444609642029, 'Val/mean precision': 0.951655924320221, 'Val/mean recall': 0.9371443390846252, 'Val/mean hd95_metric': 16.49217414855957}
Cheakpoint...
Epoch [240/300] best acc:tensor([0.9396], device='cuda:0'), Now : mean acc: tensor([0.9324], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9323667883872986, 'Val/mean miou_metric': 0.8948220610618591, 'Val/mean f1': 0.9443444609642029, 'Val/mean precision': 0.951655924320221, 'Val/mean recall': 0.9371443390846252, 'Val/mean hd95_metric': 16.49217414855957}
Epoch [241/300] Training [1/62] Loss: 0.04152 
Epoch [241/300] Training [2/62] Loss: 0.02726 
Epoch [241/300] Training [3/62] Loss: 0.03864 
Epoch [241/300] Training [4/62] Loss: 0.02575 
Epoch [241/300] Training [5/62] Loss: 0.03148 
Epoch [241/300] Training [6/62] Loss: 0.02395 
Epoch [241/300] Training [7/62] Loss: 0.02741 
Epoch [241/300] Training [8/62] Loss: 0.08709 
Epoch [241/300] Training [9/62] Loss: 0.03418 
Epoch [241/300] Training [10/62] Loss: 0.02625 
Epoch [241/300] Training [11/62] Loss: 0.03850 
Epoch [241/300] Training [12/62] Loss: 0.03217 
Epoch [241/300] Training [13/62] Loss: 0.02120 
Epoch [241/300] Training [14/62] Loss: 0.08484 
Epoch [241/300] Training [15/62] Loss: 0.02541 
Epoch [241/300] Training [16/62] Loss: 0.09814 
Epoch [241/300] Training [17/62] Loss: 0.02795 
Epoch [241/300] Training [18/62] Loss: 0.03103 
Epoch [241/300] Training [19/62] Loss: 0.02775 
Epoch [241/300] Training [20/62] Loss: 0.02766 
Epoch [241/300] Training [21/62] Loss: 0.02410 
Epoch [241/300] Training [22/62] Loss: 0.02983 
Epoch [241/300] Training [23/62] Loss: 0.02825 
Epoch [241/300] Training [24/62] Loss: 0.02866 
Epoch [241/300] Training [25/62] Loss: 0.03391 
Epoch [241/300] Training [26/62] Loss: 0.04162 
Epoch [241/300] Training [27/62] Loss: 0.03611 
Epoch [241/300] Training [28/62] Loss: 0.05515 
Epoch [241/300] Training [29/62] Loss: 0.04017 
Epoch [241/300] Training [30/62] Loss: 0.14301 
Epoch [241/300] Training [31/62] Loss: 0.02604 
Epoch [241/300] Training [32/62] Loss: 0.03208 
Epoch [241/300] Training [33/62] Loss: 0.04297 
Epoch [241/300] Training [34/62] Loss: 0.06841 
Epoch [241/300] Training [35/62] Loss: 0.03880 
Epoch [241/300] Training [36/62] Loss: 0.15128 
Epoch [241/300] Training [37/62] Loss: 0.03383 
Epoch [241/300] Training [38/62] Loss: 0.05108 
Epoch [241/300] Training [39/62] Loss: 0.03069 
Epoch [241/300] Training [40/62] Loss: 0.04175 
Epoch [241/300] Training [41/62] Loss: 0.03112 
Epoch [241/300] Training [42/62] Loss: 0.02349 
Epoch [241/300] Training [43/62] Loss: 0.05192 
Epoch [241/300] Training [44/62] Loss: 0.04223 
Epoch [241/300] Training [45/62] Loss: 0.01969 
Epoch [241/300] Training [46/62] Loss: 0.02389 
Epoch [241/300] Training [47/62] Loss: 0.02718 
Epoch [241/300] Training [48/62] Loss: 0.03332 
Epoch [241/300] Training [49/62] Loss: 0.02128 
Epoch [241/300] Training [50/62] Loss: 0.02474 
Epoch [241/300] Training [51/62] Loss: 0.03308 
Epoch [241/300] Training [52/62] Loss: 0.02908 
Epoch [241/300] Training [53/62] Loss: 0.03156 
Epoch [241/300] Training [54/62] Loss: 0.03351 
Epoch [241/300] Training [55/62] Loss: 0.02961 
Epoch [241/300] Training [56/62] Loss: 0.03449 
Epoch [241/300] Training [57/62] Loss: 0.04669 
Epoch [241/300] Training [58/62] Loss: 0.05316 
Epoch [241/300] Training [59/62] Loss: 0.03715 
Epoch [241/300] Training [60/62] Loss: 0.02607 
Epoch [241/300] Training [61/62] Loss: 0.06316 
Epoch [241/300] Training [62/62] Loss: 0.05711 
Epoch [241/300] Training metric {'Train/mean dice_metric': 0.9719380736351013, 'Train/mean miou_metric': 0.9489828944206238, 'Train/mean f1': 0.9735020399093628, 'Train/mean precision': 0.9683492183685303, 'Train/mean recall': 0.9787098169326782, 'Train/mean hd95_metric': 7.315295696258545}
Epoch [241/300] Validation [1/16] Loss: 0.66903  focal_loss 0.46006  dice_loss 0.20897 
Epoch [241/300] Validation [2/16] Loss: 0.49708  focal_loss 0.20914  dice_loss 0.28795 
Epoch [241/300] Validation [3/16] Loss: 0.71515  focal_loss 0.43355  dice_loss 0.28160 
Epoch [241/300] Validation [4/16] Loss: 0.32355  focal_loss 0.16879  dice_loss 0.15477 
Epoch [241/300] Validation [5/16] Loss: 0.38636  focal_loss 0.16900  dice_loss 0.21737 
Epoch [241/300] Validation [6/16] Loss: 0.28356  focal_loss 0.08957  dice_loss 0.19399 
Epoch [241/300] Validation [7/16] Loss: 0.26100  focal_loss 0.10030  dice_loss 0.16070 
Epoch [241/300] Validation [8/16] Loss: 0.51773  focal_loss 0.21251  dice_loss 0.30522 
Epoch [241/300] Validation [9/16] Loss: 0.20409  focal_loss 0.09040  dice_loss 0.11370 
Epoch [241/300] Validation [10/16] Loss: 0.58529  focal_loss 0.21265  dice_loss 0.37264 
Epoch [241/300] Validation [11/16] Loss: 0.15593  focal_loss 0.05813  dice_loss 0.09780 
Epoch [241/300] Validation [12/16] Loss: 0.41867  focal_loss 0.13474  dice_loss 0.28394 
Epoch [241/300] Validation [13/16] Loss: 0.29608  focal_loss 0.11983  dice_loss 0.17625 
Epoch [241/300] Validation [14/16] Loss: 0.61829  focal_loss 0.25967  dice_loss 0.35862 
Epoch [241/300] Validation [15/16] Loss: 0.09984  focal_loss 0.03729  dice_loss 0.06255 
Epoch [241/300] Validation [16/16] Loss: 0.09314  focal_loss 0.02722  dice_loss 0.06593 
Epoch [241/300] Validation metric {'Val/mean dice_metric': 0.9352138042449951, 'Val/mean miou_metric': 0.8999699354171753, 'Val/mean f1': 0.9449329376220703, 'Val/mean precision': 0.9512161016464233, 'Val/mean recall': 0.9387322068214417, 'Val/mean hd95_metric': 15.64321517944336}
Cheakpoint...
Epoch [241/300] best acc:tensor([0.9396], device='cuda:0'), Now : mean acc: tensor([0.9352], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9352138042449951, 'Val/mean miou_metric': 0.8999699354171753, 'Val/mean f1': 0.9449329376220703, 'Val/mean precision': 0.9512161016464233, 'Val/mean recall': 0.9387322068214417, 'Val/mean hd95_metric': 15.64321517944336}
Epoch [242/300] Training [1/62] Loss: 0.04731 
Epoch [242/300] Training [2/62] Loss: 0.02720 
Epoch [242/300] Training [3/62] Loss: 0.02966 
Epoch [242/300] Training [4/62] Loss: 0.02266 
Epoch [242/300] Training [5/62] Loss: 0.02953 
Epoch [242/300] Training [6/62] Loss: 0.02625 
Epoch [242/300] Training [7/62] Loss: 0.06372 
Epoch [242/300] Training [8/62] Loss: 0.08573 
Epoch [242/300] Training [9/62] Loss: 0.02057 
Epoch [242/300] Training [10/62] Loss: 0.03420 
Epoch [242/300] Training [11/62] Loss: 0.03931 
Epoch [242/300] Training [12/62] Loss: 0.02665 
Epoch [242/300] Training [13/62] Loss: 0.03734 
Epoch [242/300] Training [14/62] Loss: 0.03277 
Epoch [242/300] Training [15/62] Loss: 0.05035 
Epoch [242/300] Training [16/62] Loss: 0.06267 
Epoch [242/300] Training [17/62] Loss: 0.03770 
Epoch [242/300] Training [18/62] Loss: 0.01887 
Epoch [242/300] Training [19/62] Loss: 0.04120 
Epoch [242/300] Training [20/62] Loss: 0.02741 
Epoch [242/300] Training [21/62] Loss: 0.02575 
Epoch [242/300] Training [22/62] Loss: 0.02826 
Epoch [242/300] Training [23/62] Loss: 0.02951 
Epoch [242/300] Training [24/62] Loss: 0.03241 
Epoch [242/300] Training [25/62] Loss: 0.05950 
Epoch [242/300] Training [26/62] Loss: 0.02707 
Epoch [242/300] Training [27/62] Loss: 0.03784 
Epoch [242/300] Training [28/62] Loss: 0.02639 
Epoch [242/300] Training [29/62] Loss: 0.02257 
Epoch [242/300] Training [30/62] Loss: 0.02606 
Epoch [242/300] Training [31/62] Loss: 0.02657 
Epoch [242/300] Training [32/62] Loss: 0.02673 
Epoch [242/300] Training [33/62] Loss: 0.07081 
Epoch [242/300] Training [34/62] Loss: 0.02397 
Epoch [242/300] Training [35/62] Loss: 0.02206 
Epoch [242/300] Training [36/62] Loss: 0.03946 
Epoch [242/300] Training [37/62] Loss: 0.04825 
Epoch [242/300] Training [38/62] Loss: 0.03988 
Epoch [242/300] Training [39/62] Loss: 0.03177 
Epoch [242/300] Training [40/62] Loss: 0.02450 
Epoch [242/300] Training [41/62] Loss: 0.12096 
Epoch [242/300] Training [42/62] Loss: 0.03718 
Epoch [242/300] Training [43/62] Loss: 0.07972 
Epoch [242/300] Training [44/62] Loss: 0.03797 
Epoch [242/300] Training [45/62] Loss: 0.03994 
Epoch [242/300] Training [46/62] Loss: 0.05235 
Epoch [242/300] Training [47/62] Loss: 0.02286 
Epoch [242/300] Training [48/62] Loss: 0.03987 
Epoch [242/300] Training [49/62] Loss: 0.03654 
Epoch [242/300] Training [50/62] Loss: 0.02234 
Epoch [242/300] Training [51/62] Loss: 0.02931 
Epoch [242/300] Training [52/62] Loss: 0.03080 
Epoch [242/300] Training [53/62] Loss: 0.04754 
Epoch [242/300] Training [54/62] Loss: 0.02539 
Epoch [242/300] Training [55/62] Loss: 0.13409 
Epoch [242/300] Training [56/62] Loss: 0.05043 
Epoch [242/300] Training [57/62] Loss: 0.03023 
Epoch [242/300] Training [58/62] Loss: 0.02632 
Epoch [242/300] Training [59/62] Loss: 0.02387 
Epoch [242/300] Training [60/62] Loss: 0.04808 
Epoch [242/300] Training [61/62] Loss: 0.02967 
Epoch [242/300] Training [62/62] Loss: 0.44035 
Epoch [242/300] Training metric {'Train/mean dice_metric': 0.97282874584198, 'Train/mean miou_metric': 0.94993656873703, 'Train/mean f1': 0.9737978577613831, 'Train/mean precision': 0.9698157906532288, 'Train/mean recall': 0.9778128266334534, 'Train/mean hd95_metric': 6.005756378173828}
Epoch [242/300] Validation [1/16] Loss: 0.68035  focal_loss 0.46827  dice_loss 0.21208 
Epoch [242/300] Validation [2/16] Loss: 0.52795  focal_loss 0.21376  dice_loss 0.31419 
Epoch [242/300] Validation [3/16] Loss: 0.75935  focal_loss 0.45674  dice_loss 0.30261 
Epoch [242/300] Validation [4/16] Loss: 0.32663  focal_loss 0.17584  dice_loss 0.15079 
Epoch [242/300] Validation [5/16] Loss: 0.36015  focal_loss 0.15636  dice_loss 0.20379 
Epoch [242/300] Validation [6/16] Loss: 0.28796  focal_loss 0.09280  dice_loss 0.19516 
Epoch [242/300] Validation [7/16] Loss: 0.19444  focal_loss 0.08794  dice_loss 0.10649 
Epoch [242/300] Validation [8/16] Loss: 0.50642  focal_loss 0.21634  dice_loss 0.29008 
Epoch [242/300] Validation [9/16] Loss: 0.22048  focal_loss 0.09292  dice_loss 0.12756 
Epoch [242/300] Validation [10/16] Loss: 0.55554  focal_loss 0.19783  dice_loss 0.35771 
Epoch [242/300] Validation [11/16] Loss: 0.18007  focal_loss 0.07440  dice_loss 0.10567 
Epoch [242/300] Validation [12/16] Loss: 0.39457  focal_loss 0.13120  dice_loss 0.26337 
Epoch [242/300] Validation [13/16] Loss: 0.23263  focal_loss 0.08809  dice_loss 0.14454 
Epoch [242/300] Validation [14/16] Loss: 0.57823  focal_loss 0.27560  dice_loss 0.30264 
Epoch [242/300] Validation [15/16] Loss: 0.10013  focal_loss 0.03648  dice_loss 0.06365 
Epoch [242/300] Validation [16/16] Loss: 0.20073  focal_loss 0.07897  dice_loss 0.12176 
Epoch [242/300] Validation metric {'Val/mean dice_metric': 0.9370964169502258, 'Val/mean miou_metric': 0.901482880115509, 'Val/mean f1': 0.9446844458580017, 'Val/mean precision': 0.9493245482444763, 'Val/mean recall': 0.9400893449783325, 'Val/mean hd95_metric': 15.401911735534668}
Cheakpoint...
Epoch [242/300] best acc:tensor([0.9396], device='cuda:0'), Now : mean acc: tensor([0.9371], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9370964169502258, 'Val/mean miou_metric': 0.901482880115509, 'Val/mean f1': 0.9446844458580017, 'Val/mean precision': 0.9493245482444763, 'Val/mean recall': 0.9400893449783325, 'Val/mean hd95_metric': 15.401911735534668}
Epoch [243/300] Training [1/62] Loss: 0.02593 
Epoch [243/300] Training [2/62] Loss: 0.03156 
Epoch [243/300] Training [3/62] Loss: 0.03046 
Epoch [243/300] Training [4/62] Loss: 0.06552 
Epoch [243/300] Training [5/62] Loss: 0.03248 
Epoch [243/300] Training [6/62] Loss: 0.02851 
Epoch [243/300] Training [7/62] Loss: 0.02924 
Epoch [243/300] Training [8/62] Loss: 0.03245 
Epoch [243/300] Training [9/62] Loss: 0.08150 
Epoch [243/300] Training [10/62] Loss: 0.02046 
Epoch [243/300] Training [11/62] Loss: 0.06337 
Epoch [243/300] Training [12/62] Loss: 0.05180 
Epoch [243/300] Training [13/62] Loss: 0.03740 
Epoch [243/300] Training [14/62] Loss: 0.02613 
Epoch [243/300] Training [15/62] Loss: 0.05033 
Epoch [243/300] Training [16/62] Loss: 0.03727 
Epoch [243/300] Training [17/62] Loss: 0.03018 
Epoch [243/300] Training [18/62] Loss: 0.02553 
Epoch [243/300] Training [19/62] Loss: 0.03223 
Epoch [243/300] Training [20/62] Loss: 0.02821 
Epoch [243/300] Training [21/62] Loss: 0.02371 
Epoch [243/300] Training [22/62] Loss: 0.03808 
Epoch [243/300] Training [23/62] Loss: 0.06001 
Epoch [243/300] Training [24/62] Loss: 0.03481 
Epoch [243/300] Training [25/62] Loss: 0.03087 
Epoch [243/300] Training [26/62] Loss: 0.04807 
Epoch [243/300] Training [27/62] Loss: 0.03996 
Epoch [243/300] Training [28/62] Loss: 0.07686 
Epoch [243/300] Training [29/62] Loss: 0.03411 
Epoch [243/300] Training [30/62] Loss: 0.03736 
Epoch [243/300] Training [31/62] Loss: 0.02877 
Epoch [243/300] Training [32/62] Loss: 0.03896 
Epoch [243/300] Training [33/62] Loss: 0.03994 
Epoch [243/300] Training [34/62] Loss: 0.03185 
Epoch [243/300] Training [35/62] Loss: 0.02179 
Epoch [243/300] Training [36/62] Loss: 0.02553 
Epoch [243/300] Training [37/62] Loss: 0.05056 
Epoch [243/300] Training [38/62] Loss: 0.02559 
Epoch [243/300] Training [39/62] Loss: 0.07733 
Epoch [243/300] Training [40/62] Loss: 0.02642 
Epoch [243/300] Training [41/62] Loss: 0.06489 
Epoch [243/300] Training [42/62] Loss: 0.02261 
Epoch [243/300] Training [43/62] Loss: 0.03880 
Epoch [243/300] Training [44/62] Loss: 0.02674 
Epoch [243/300] Training [45/62] Loss: 0.02492 
Epoch [243/300] Training [46/62] Loss: 0.03874 
Epoch [243/300] Training [47/62] Loss: 0.03146 
Epoch [243/300] Training [48/62] Loss: 0.02659 
Epoch [243/300] Training [49/62] Loss: 0.03725 
Epoch [243/300] Training [50/62] Loss: 0.07471 
Epoch [243/300] Training [51/62] Loss: 0.02153 
Epoch [243/300] Training [52/62] Loss: 0.10286 
Epoch [243/300] Training [53/62] Loss: 0.02638 
Epoch [243/300] Training [54/62] Loss: 0.02478 
Epoch [243/300] Training [55/62] Loss: 0.05325 
Epoch [243/300] Training [56/62] Loss: 0.03821 
Epoch [243/300] Training [57/62] Loss: 0.04261 
Epoch [243/300] Training [58/62] Loss: 0.02980 
Epoch [243/300] Training [59/62] Loss: 0.02654 
Epoch [243/300] Training [60/62] Loss: 0.03324 
Epoch [243/300] Training [61/62] Loss: 0.02665 
Epoch [243/300] Training [62/62] Loss: 0.05606 
Epoch [243/300] Training metric {'Train/mean dice_metric': 0.973641037940979, 'Train/mean miou_metric': 0.9504112601280212, 'Train/mean f1': 0.9742056131362915, 'Train/mean precision': 0.9713900089263916, 'Train/mean recall': 0.9770375490188599, 'Train/mean hd95_metric': 5.861538887023926}
Epoch [243/300] Validation [1/16] Loss: 0.64720  focal_loss 0.44575  dice_loss 0.20144 
Epoch [243/300] Validation [2/16] Loss: 0.48161  focal_loss 0.20540  dice_loss 0.27621 
Epoch [243/300] Validation [3/16] Loss: 0.61664  focal_loss 0.35012  dice_loss 0.26652 
Epoch [243/300] Validation [4/16] Loss: 0.29040  focal_loss 0.15972  dice_loss 0.13068 
Epoch [243/300] Validation [5/16] Loss: 0.33858  focal_loss 0.13783  dice_loss 0.20076 
Epoch [243/300] Validation [6/16] Loss: 0.32209  focal_loss 0.10818  dice_loss 0.21391 
Epoch [243/300] Validation [7/16] Loss: 0.18740  focal_loss 0.08623  dice_loss 0.10118 
Epoch [243/300] Validation [8/16] Loss: 0.52581  focal_loss 0.21436  dice_loss 0.31145 
Epoch [243/300] Validation [9/16] Loss: 0.19864  focal_loss 0.09115  dice_loss 0.10749 
Epoch [243/300] Validation [10/16] Loss: 0.51612  focal_loss 0.18640  dice_loss 0.32973 
Epoch [243/300] Validation [11/16] Loss: 0.13903  focal_loss 0.05000  dice_loss 0.08902 
Epoch [243/300] Validation [12/16] Loss: 0.50140  focal_loss 0.13676  dice_loss 0.36464 
Epoch [243/300] Validation [13/16] Loss: 0.28171  focal_loss 0.11069  dice_loss 0.17102 
Epoch [243/300] Validation [14/16] Loss: 0.55692  focal_loss 0.26184  dice_loss 0.29509 
Epoch [243/300] Validation [15/16] Loss: 0.11970  focal_loss 0.04432  dice_loss 0.07539 
Epoch [243/300] Validation [16/16] Loss: 0.11225  focal_loss 0.03645  dice_loss 0.07580 
Epoch [243/300] Validation metric {'Val/mean dice_metric': 0.9382334351539612, 'Val/mean miou_metric': 0.9020088315010071, 'Val/mean f1': 0.9461565613746643, 'Val/mean precision': 0.9521879553794861, 'Val/mean recall': 0.9402010440826416, 'Val/mean hd95_metric': 15.825075149536133}
Cheakpoint...
Epoch [243/300] best acc:tensor([0.9396], device='cuda:0'), Now : mean acc: tensor([0.9382], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9382334351539612, 'Val/mean miou_metric': 0.9020088315010071, 'Val/mean f1': 0.9461565613746643, 'Val/mean precision': 0.9521879553794861, 'Val/mean recall': 0.9402010440826416, 'Val/mean hd95_metric': 15.825075149536133}
Epoch [244/300] Training [1/62] Loss: 0.06126 
Epoch [244/300] Training [2/62] Loss: 0.03118 
Epoch [244/300] Training [3/62] Loss: 0.03879 
Epoch [244/300] Training [4/62] Loss: 0.04034 
Epoch [244/300] Training [5/62] Loss: 0.03335 
Epoch [244/300] Training [6/62] Loss: 0.02991 
Epoch [244/300] Training [7/62] Loss: 0.02417 
Epoch [244/300] Training [8/62] Loss: 0.01901 
Epoch [244/300] Training [9/62] Loss: 0.03216 
Epoch [244/300] Training [10/62] Loss: 0.03505 
Epoch [244/300] Training [11/62] Loss: 0.03592 
Epoch [244/300] Training [12/62] Loss: 0.02908 
Epoch [244/300] Training [13/62] Loss: 0.02512 
Epoch [244/300] Training [14/62] Loss: 0.02620 
Epoch [244/300] Training [15/62] Loss: 0.03064 
Epoch [244/300] Training [16/62] Loss: 0.04259 
Epoch [244/300] Training [17/62] Loss: 0.02144 
Epoch [244/300] Training [18/62] Loss: 0.02622 
Epoch [244/300] Training [19/62] Loss: 0.03184 
Epoch [244/300] Training [20/62] Loss: 0.02020 
Epoch [244/300] Training [21/62] Loss: 0.07267 
Epoch [244/300] Training [22/62] Loss: 0.19090 
Epoch [244/300] Training [23/62] Loss: 0.04351 
Epoch [244/300] Training [24/62] Loss: 0.03483 
Epoch [244/300] Training [25/62] Loss: 0.03304 
Epoch [244/300] Training [26/62] Loss: 0.02827 
Epoch [244/300] Training [27/62] Loss: 0.06347 
Epoch [244/300] Training [28/62] Loss: 0.03802 
Epoch [244/300] Training [29/62] Loss: 0.02845 
Epoch [244/300] Training [30/62] Loss: 0.03912 
Epoch [244/300] Training [31/62] Loss: 0.02907 
Epoch [244/300] Training [32/62] Loss: 0.08076 
Epoch [244/300] Training [33/62] Loss: 0.02618 
Epoch [244/300] Training [34/62] Loss: 0.03224 
Epoch [244/300] Training [35/62] Loss: 0.04370 
Epoch [244/300] Training [36/62] Loss: 0.05490 
Epoch [244/300] Training [37/62] Loss: 0.02871 
Epoch [244/300] Training [38/62] Loss: 0.02631 
Epoch [244/300] Training [39/62] Loss: 0.06011 
Epoch [244/300] Training [40/62] Loss: 0.04021 
Epoch [244/300] Training [41/62] Loss: 0.02448 
Epoch [244/300] Training [42/62] Loss: 0.02561 
Epoch [244/300] Training [43/62] Loss: 0.02565 
Epoch [244/300] Training [44/62] Loss: 0.04381 
Epoch [244/300] Training [45/62] Loss: 0.03237 
Epoch [244/300] Training [46/62] Loss: 0.02894 
Epoch [244/300] Training [47/62] Loss: 0.02899 
Epoch [244/300] Training [48/62] Loss: 0.03461 
Epoch [244/300] Training [49/62] Loss: 0.03979 
Epoch [244/300] Training [50/62] Loss: 0.03009 
Epoch [244/300] Training [51/62] Loss: 0.10543 
Epoch [244/300] Training [52/62] Loss: 0.04336 
Epoch [244/300] Training [53/62] Loss: 0.07490 
Epoch [244/300] Training [54/62] Loss: 0.04714 
Epoch [244/300] Training [55/62] Loss: 0.05067 
Epoch [244/300] Training [56/62] Loss: 0.04971 
Epoch [244/300] Training [57/62] Loss: 0.02326 
Epoch [244/300] Training [58/62] Loss: 0.03488 
Epoch [244/300] Training [59/62] Loss: 0.02794 
Epoch [244/300] Training [60/62] Loss: 0.04187 
Epoch [244/300] Training [61/62] Loss: 0.06143 
Epoch [244/300] Training [62/62] Loss: 0.04972 
Epoch [244/300] Training metric {'Train/mean dice_metric': 0.9736664891242981, 'Train/mean miou_metric': 0.9506955742835999, 'Train/mean f1': 0.9721658825874329, 'Train/mean precision': 0.9699162244796753, 'Train/mean recall': 0.9744259715080261, 'Train/mean hd95_metric': 6.568359375}
Epoch [244/300] Validation [1/16] Loss: 0.67229  focal_loss 0.46749  dice_loss 0.20480 
Epoch [244/300] Validation [2/16] Loss: 0.49009  focal_loss 0.20369  dice_loss 0.28640 
Epoch [244/300] Validation [3/16] Loss: 0.63508  focal_loss 0.37894  dice_loss 0.25615 
Epoch [244/300] Validation [4/16] Loss: 0.31547  focal_loss 0.16471  dice_loss 0.15077 
Epoch [244/300] Validation [5/16] Loss: 0.46734  focal_loss 0.17484  dice_loss 0.29250 
Epoch [244/300] Validation [6/16] Loss: 0.35946  focal_loss 0.11894  dice_loss 0.24052 
Epoch [244/300] Validation [7/16] Loss: 0.22370  focal_loss 0.09984  dice_loss 0.12386 
Epoch [244/300] Validation [8/16] Loss: 0.56705  focal_loss 0.22433  dice_loss 0.34272 
Epoch [244/300] Validation [9/16] Loss: 0.26521  focal_loss 0.12493  dice_loss 0.14028 
Epoch [244/300] Validation [10/16] Loss: 0.58603  focal_loss 0.20481  dice_loss 0.38122 
Epoch [244/300] Validation [11/16] Loss: 0.15048  focal_loss 0.05562  dice_loss 0.09486 
Epoch [244/300] Validation [12/16] Loss: 0.39613  focal_loss 0.12575  dice_loss 0.27038 
Epoch [244/300] Validation [13/16] Loss: 0.24981  focal_loss 0.09483  dice_loss 0.15498 
Epoch [244/300] Validation [14/16] Loss: 0.52252  focal_loss 0.23473  dice_loss 0.28779 
Epoch [244/300] Validation [15/16] Loss: 0.11785  focal_loss 0.04373  dice_loss 0.07413 
Epoch [244/300] Validation [16/16] Loss: 0.15361  focal_loss 0.05396  dice_loss 0.09965 
Epoch [244/300] Validation metric {'Val/mean dice_metric': 0.9359192848205566, 'Val/mean miou_metric': 0.9001937508583069, 'Val/mean f1': 0.943149745464325, 'Val/mean precision': 0.9498352408409119, 'Val/mean recall': 0.9365578293800354, 'Val/mean hd95_metric': 15.726460456848145}
Cheakpoint...
Epoch [244/300] best acc:tensor([0.9396], device='cuda:0'), Now : mean acc: tensor([0.9359], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9359192848205566, 'Val/mean miou_metric': 0.9001937508583069, 'Val/mean f1': 0.943149745464325, 'Val/mean precision': 0.9498352408409119, 'Val/mean recall': 0.9365578293800354, 'Val/mean hd95_metric': 15.726460456848145}
Epoch [245/300] Training [1/62] Loss: 0.03267 
Epoch [245/300] Training [2/62] Loss: 0.04841 
Epoch [245/300] Training [3/62] Loss: 0.04514 
Epoch [245/300] Training [4/62] Loss: 0.07351 
Epoch [245/300] Training [5/62] Loss: 0.02867 
Epoch [245/300] Training [6/62] Loss: 0.02658 
Epoch [245/300] Training [7/62] Loss: 0.03291 
Epoch [245/300] Training [8/62] Loss: 0.02615 
Epoch [245/300] Training [9/62] Loss: 0.02722 
Epoch [245/300] Training [10/62] Loss: 0.05711 
Epoch [245/300] Training [11/62] Loss: 0.03380 
Epoch [245/300] Training [12/62] Loss: 0.02498 
Epoch [245/300] Training [13/62] Loss: 0.05450 
Epoch [245/300] Training [14/62] Loss: 0.05323 
Epoch [245/300] Training [15/62] Loss: 0.09027 
Epoch [245/300] Training [16/62] Loss: 0.04540 
Epoch [245/300] Training [17/62] Loss: 0.03441 
Epoch [245/300] Training [18/62] Loss: 0.04609 
Epoch [245/300] Training [19/62] Loss: 0.02719 
Epoch [245/300] Training [20/62] Loss: 0.04549 
Epoch [245/300] Training [21/62] Loss: 0.03147 
Epoch [245/300] Training [22/62] Loss: 0.02594 
Epoch [245/300] Training [23/62] Loss: 0.10377 
Epoch [245/300] Training [24/62] Loss: 0.06739 
Epoch [245/300] Training [25/62] Loss: 0.02487 
Epoch [245/300] Training [26/62] Loss: 0.04550 
Epoch [245/300] Training [27/62] Loss: 0.06834 
Epoch [245/300] Training [28/62] Loss: 0.04708 
Epoch [245/300] Training [29/62] Loss: 0.02193 
Epoch [245/300] Training [30/62] Loss: 0.03357 
Epoch [245/300] Training [31/62] Loss: 0.02689 
Epoch [245/300] Training [32/62] Loss: 0.02824 
Epoch [245/300] Training [33/62] Loss: 0.03174 
Epoch [245/300] Training [34/62] Loss: 0.03599 
Epoch [245/300] Training [35/62] Loss: 0.03426 
Epoch [245/300] Training [36/62] Loss: 0.03723 
Epoch [245/300] Training [37/62] Loss: 0.02221 
Epoch [245/300] Training [38/62] Loss: 0.02988 
Epoch [245/300] Training [39/62] Loss: 0.03889 
Epoch [245/300] Training [40/62] Loss: 0.02489 
Epoch [245/300] Training [41/62] Loss: 0.04127 
Epoch [245/300] Training [42/62] Loss: 0.04137 
Epoch [245/300] Training [43/62] Loss: 0.12285 
Epoch [245/300] Training [44/62] Loss: 0.06025 
Epoch [245/300] Training [45/62] Loss: 0.03000 
Epoch [245/300] Training [46/62] Loss: 0.02487 
Epoch [245/300] Training [47/62] Loss: 0.03666 
Epoch [245/300] Training [48/62] Loss: 0.02683 
Epoch [245/300] Training [49/62] Loss: 0.05630 
Epoch [245/300] Training [50/62] Loss: 0.05421 
Epoch [245/300] Training [51/62] Loss: 0.02564 
Epoch [245/300] Training [52/62] Loss: 0.03689 
Epoch [245/300] Training [53/62] Loss: 0.04372 
Epoch [245/300] Training [54/62] Loss: 0.04436 
Epoch [245/300] Training [55/62] Loss: 0.02427 
Epoch [245/300] Training [56/62] Loss: 0.04768 
Epoch [245/300] Training [57/62] Loss: 0.02802 
Epoch [245/300] Training [58/62] Loss: 0.03159 
Epoch [245/300] Training [59/62] Loss: 0.02739 
Epoch [245/300] Training [60/62] Loss: 0.03038 
Epoch [245/300] Training [61/62] Loss: 0.02394 
Epoch [245/300] Training [62/62] Loss: 0.03832 
Epoch [245/300] Training metric {'Train/mean dice_metric': 0.9732000827789307, 'Train/mean miou_metric': 0.9494895935058594, 'Train/mean f1': 0.9722222089767456, 'Train/mean precision': 0.9689539074897766, 'Train/mean recall': 0.975512683391571, 'Train/mean hd95_metric': 6.424414157867432}
Epoch [245/300] Validation [1/16] Loss: 0.64571  focal_loss 0.44360  dice_loss 0.20211 
Epoch [245/300] Validation [2/16] Loss: 0.49286  focal_loss 0.21573  dice_loss 0.27714 
Epoch [245/300] Validation [3/16] Loss: 0.67964  focal_loss 0.38937  dice_loss 0.29027 
Epoch [245/300] Validation [4/16] Loss: 0.29648  focal_loss 0.15771  dice_loss 0.13878 
Epoch [245/300] Validation [5/16] Loss: 0.46416  focal_loss 0.16479  dice_loss 0.29937 
Epoch [245/300] Validation [6/16] Loss: 0.26232  focal_loss 0.08247  dice_loss 0.17986 
Epoch [245/300] Validation [7/16] Loss: 0.26110  focal_loss 0.10115  dice_loss 0.15995 
Epoch [245/300] Validation [8/16] Loss: 0.51949  focal_loss 0.21504  dice_loss 0.30445 
Epoch [245/300] Validation [9/16] Loss: 0.20840  focal_loss 0.09668  dice_loss 0.11173 
Epoch [245/300] Validation [10/16] Loss: 0.56264  focal_loss 0.20948  dice_loss 0.35316 
Epoch [245/300] Validation [11/16] Loss: 0.14349  focal_loss 0.05489  dice_loss 0.08860 
Epoch [245/300] Validation [12/16] Loss: 0.40374  focal_loss 0.12359  dice_loss 0.28015 
Epoch [245/300] Validation [13/16] Loss: 0.26458  focal_loss 0.10726  dice_loss 0.15732 
Epoch [245/300] Validation [14/16] Loss: 0.53641  focal_loss 0.24274  dice_loss 0.29367 
Epoch [245/300] Validation [15/16] Loss: 0.14460  focal_loss 0.05659  dice_loss 0.08801 
Epoch [245/300] Validation [16/16] Loss: 0.09775  focal_loss 0.03771  dice_loss 0.06003 
Epoch [245/300] Validation metric {'Val/mean dice_metric': 0.936661958694458, 'Val/mean miou_metric': 0.9011824131011963, 'Val/mean f1': 0.9443644881248474, 'Val/mean precision': 0.9517711997032166, 'Val/mean recall': 0.9370721578598022, 'Val/mean hd95_metric': 15.507184028625488}
Cheakpoint...
Epoch [245/300] best acc:tensor([0.9396], device='cuda:0'), Now : mean acc: tensor([0.9367], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.936661958694458, 'Val/mean miou_metric': 0.9011824131011963, 'Val/mean f1': 0.9443644881248474, 'Val/mean precision': 0.9517711997032166, 'Val/mean recall': 0.9370721578598022, 'Val/mean hd95_metric': 15.507184028625488}
Epoch [246/300] Training [1/62] Loss: 0.02898 
Epoch [246/300] Training [2/62] Loss: 0.03115 
Epoch [246/300] Training [3/62] Loss: 0.02580 
Epoch [246/300] Training [4/62] Loss: 0.06187 
Epoch [246/300] Training [5/62] Loss: 0.03330 
Epoch [246/300] Training [6/62] Loss: 0.02767 
Epoch [246/300] Training [7/62] Loss: 0.04251 
Epoch [246/300] Training [8/62] Loss: 0.04188 
Epoch [246/300] Training [9/62] Loss: 0.02057 
Epoch [246/300] Training [10/62] Loss: 0.03739 
Epoch [246/300] Training [11/62] Loss: 0.07047 
Epoch [246/300] Training [12/62] Loss: 0.04526 
Epoch [246/300] Training [13/62] Loss: 0.02527 
Epoch [246/300] Training [14/62] Loss: 0.05229 
Epoch [246/300] Training [15/62] Loss: 0.04055 
Epoch [246/300] Training [16/62] Loss: 0.07554 
Epoch [246/300] Training [17/62] Loss: 0.02635 
Epoch [246/300] Training [18/62] Loss: 0.02868 
Epoch [246/300] Training [19/62] Loss: 0.09564 
Epoch [246/300] Training [20/62] Loss: 0.02612 
Epoch [246/300] Training [21/62] Loss: 0.10126 
Epoch [246/300] Training [22/62] Loss: 0.04557 
Epoch [246/300] Training [23/62] Loss: 0.06055 
Epoch [246/300] Training [24/62] Loss: 0.02617 
Epoch [246/300] Training [25/62] Loss: 0.03027 
Epoch [246/300] Training [26/62] Loss: 0.04743 
Epoch [246/300] Training [27/62] Loss: 0.02053 
Epoch [246/300] Training [28/62] Loss: 0.03136 
Epoch [246/300] Training [29/62] Loss: 0.02039 
Epoch [246/300] Training [30/62] Loss: 0.02930 
Epoch [246/300] Training [31/62] Loss: 0.07175 
Epoch [246/300] Training [32/62] Loss: 0.02273 
Epoch [246/300] Training [33/62] Loss: 0.03030 
Epoch [246/300] Training [34/62] Loss: 0.02182 
Epoch [246/300] Training [35/62] Loss: 0.02957 
Epoch [246/300] Training [36/62] Loss: 0.02714 
Epoch [246/300] Training [37/62] Loss: 0.02359 
Epoch [246/300] Training [38/62] Loss: 0.05080 
Epoch [246/300] Training [39/62] Loss: 0.02929 
Epoch [246/300] Training [40/62] Loss: 0.04779 
Epoch [246/300] Training [41/62] Loss: 0.02422 
Epoch [246/300] Training [42/62] Loss: 0.03336 
Epoch [246/300] Training [43/62] Loss: 0.04475 
Epoch [246/300] Training [44/62] Loss: 0.03230 
Epoch [246/300] Training [45/62] Loss: 0.04074 
Epoch [246/300] Training [46/62] Loss: 0.04373 
Epoch [246/300] Training [47/62] Loss: 0.02811 
Epoch [246/300] Training [48/62] Loss: 0.04291 
Epoch [246/300] Training [49/62] Loss: 0.02212 
Epoch [246/300] Training [50/62] Loss: 0.04286 
Epoch [246/300] Training [51/62] Loss: 0.02955 
Epoch [246/300] Training [52/62] Loss: 0.03354 
Epoch [246/300] Training [53/62] Loss: 0.02156 
Epoch [246/300] Training [54/62] Loss: 0.02588 
Epoch [246/300] Training [55/62] Loss: 0.02281 
Epoch [246/300] Training [56/62] Loss: 0.13014 
Epoch [246/300] Training [57/62] Loss: 0.02320 
Epoch [246/300] Training [58/62] Loss: 0.04281 
Epoch [246/300] Training [59/62] Loss: 0.02959 
Epoch [246/300] Training [60/62] Loss: 0.02413 
Epoch [246/300] Training [61/62] Loss: 0.02597 
Epoch [246/300] Training [62/62] Loss: 0.01641 
Epoch [246/300] Training metric {'Train/mean dice_metric': 0.9748438000679016, 'Train/mean miou_metric': 0.9522952437400818, 'Train/mean f1': 0.9730337858200073, 'Train/mean precision': 0.9707452654838562, 'Train/mean recall': 0.9753331542015076, 'Train/mean hd95_metric': 5.169253826141357}
Epoch [246/300] Validation [1/16] Loss: 0.67435  focal_loss 0.47793  dice_loss 0.19642 
Epoch [246/300] Validation [2/16] Loss: 0.58541  focal_loss 0.23892  dice_loss 0.34649 
Epoch [246/300] Validation [3/16] Loss: 0.71857  focal_loss 0.44757  dice_loss 0.27099 
Epoch [246/300] Validation [4/16] Loss: 0.29305  focal_loss 0.15914  dice_loss 0.13392 
Epoch [246/300] Validation [5/16] Loss: 0.32324  focal_loss 0.13153  dice_loss 0.19171 
Epoch [246/300] Validation [6/16] Loss: 0.31114  focal_loss 0.10802  dice_loss 0.20312 
Epoch [246/300] Validation [7/16] Loss: 0.32446  focal_loss 0.11576  dice_loss 0.20870 
Epoch [246/300] Validation [8/16] Loss: 0.46757  focal_loss 0.17785  dice_loss 0.28972 
Epoch [246/300] Validation [9/16] Loss: 0.21227  focal_loss 0.09315  dice_loss 0.11912 
Epoch [246/300] Validation [10/16] Loss: 0.48055  focal_loss 0.15420  dice_loss 0.32635 
Epoch [246/300] Validation [11/16] Loss: 0.14491  focal_loss 0.05326  dice_loss 0.09165 
Epoch [246/300] Validation [12/16] Loss: 0.43006  focal_loss 0.14256  dice_loss 0.28750 
Epoch [246/300] Validation [13/16] Loss: 0.23444  focal_loss 0.08867  dice_loss 0.14577 
Epoch [246/300] Validation [14/16] Loss: 0.57059  focal_loss 0.24989  dice_loss 0.32070 
Epoch [246/300] Validation [15/16] Loss: 0.16733  focal_loss 0.06222  dice_loss 0.10511 
Epoch [246/300] Validation [16/16] Loss: 0.14784  focal_loss 0.06198  dice_loss 0.08586 
Epoch [246/300] Validation metric {'Val/mean dice_metric': 0.9378696084022522, 'Val/mean miou_metric': 0.9031982421875, 'Val/mean f1': 0.9451860189437866, 'Val/mean precision': 0.9529856443405151, 'Val/mean recall': 0.9375131130218506, 'Val/mean hd95_metric': 13.71688175201416}
Cheakpoint...
Epoch [246/300] best acc:tensor([0.9396], device='cuda:0'), Now : mean acc: tensor([0.9379], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9378696084022522, 'Val/mean miou_metric': 0.9031982421875, 'Val/mean f1': 0.9451860189437866, 'Val/mean precision': 0.9529856443405151, 'Val/mean recall': 0.9375131130218506, 'Val/mean hd95_metric': 13.71688175201416}
Epoch [247/300] Training [1/62] Loss: 0.05014 
Epoch [247/300] Training [2/62] Loss: 0.03566 
Epoch [247/300] Training [3/62] Loss: 0.02901 
Epoch [247/300] Training [4/62] Loss: 0.04369 
Epoch [247/300] Training [5/62] Loss: 0.03035 
Epoch [247/300] Training [6/62] Loss: 0.03118 
Epoch [247/300] Training [7/62] Loss: 0.05459 
Epoch [247/300] Training [8/62] Loss: 0.02451 
Epoch [247/300] Training [9/62] Loss: 0.04035 
Epoch [247/300] Training [10/62] Loss: 0.03289 
Epoch [247/300] Training [11/62] Loss: 0.03634 
Epoch [247/300] Training [12/62] Loss: 0.03286 
Epoch [247/300] Training [13/62] Loss: 0.02564 
Epoch [247/300] Training [14/62] Loss: 0.02765 
Epoch [247/300] Training [15/62] Loss: 0.03660 
Epoch [247/300] Training [16/62] Loss: 0.04270 
Epoch [247/300] Training [17/62] Loss: 0.04869 
Epoch [247/300] Training [18/62] Loss: 0.05707 
Epoch [247/300] Training [19/62] Loss: 0.04268 
Epoch [247/300] Training [20/62] Loss: 0.03009 
Epoch [247/300] Training [21/62] Loss: 0.06983 
Epoch [247/300] Training [22/62] Loss: 0.02749 
Epoch [247/300] Training [23/62] Loss: 0.05182 
Epoch [247/300] Training [24/62] Loss: 0.02737 
Epoch [247/300] Training [25/62] Loss: 0.03914 
Epoch [247/300] Training [26/62] Loss: 0.03220 
Epoch [247/300] Training [27/62] Loss: 0.03982 
Epoch [247/300] Training [28/62] Loss: 0.04890 
Epoch [247/300] Training [29/62] Loss: 0.02342 
Epoch [247/300] Training [30/62] Loss: 0.03974 
Epoch [247/300] Training [31/62] Loss: 0.03517 
Epoch [247/300] Training [32/62] Loss: 0.02486 
Epoch [247/300] Training [33/62] Loss: 0.03845 
Epoch [247/300] Training [34/62] Loss: 0.08035 
Epoch [247/300] Training [35/62] Loss: 0.02377 
Epoch [247/300] Training [36/62] Loss: 0.02928 
Epoch [247/300] Training [37/62] Loss: 0.03467 
Epoch [247/300] Training [38/62] Loss: 0.01954 
Epoch [247/300] Training [39/62] Loss: 0.03236 
Epoch [247/300] Training [40/62] Loss: 0.05564 
Epoch [247/300] Training [41/62] Loss: 0.02424 
Epoch [247/300] Training [42/62] Loss: 0.04344 
Epoch [247/300] Training [43/62] Loss: 0.05847 
Epoch [247/300] Training [44/62] Loss: 0.02757 
Epoch [247/300] Training [45/62] Loss: 0.03189 
Epoch [247/300] Training [46/62] Loss: 0.04744 
Epoch [247/300] Training [47/62] Loss: 0.02656 
Epoch [247/300] Training [48/62] Loss: 0.02571 
Epoch [247/300] Training [49/62] Loss: 0.07686 
Epoch [247/300] Training [50/62] Loss: 0.11370 
Epoch [247/300] Training [51/62] Loss: 0.02945 
Epoch [247/300] Training [52/62] Loss: 0.01963 
Epoch [247/300] Training [53/62] Loss: 0.04885 
Epoch [247/300] Training [54/62] Loss: 0.02842 
Epoch [247/300] Training [55/62] Loss: 0.07567 
Epoch [247/300] Training [56/62] Loss: 0.03892 
Epoch [247/300] Training [57/62] Loss: 0.04148 
Epoch [247/300] Training [58/62] Loss: 0.03381 
Epoch [247/300] Training [59/62] Loss: 0.02872 
Epoch [247/300] Training [60/62] Loss: 0.02926 
Epoch [247/300] Training [61/62] Loss: 0.02500 
Epoch [247/300] Training [62/62] Loss: 0.02738 
Epoch [247/300] Training metric {'Train/mean dice_metric': 0.9736005663871765, 'Train/mean miou_metric': 0.9507219195365906, 'Train/mean f1': 0.9740502834320068, 'Train/mean precision': 0.9700509309768677, 'Train/mean recall': 0.9780828952789307, 'Train/mean hd95_metric': 5.387836933135986}
Epoch [247/300] Validation [1/16] Loss: 0.64172  focal_loss 0.44151  dice_loss 0.20021 
Epoch [247/300] Validation [2/16] Loss: 0.45089  focal_loss 0.19720  dice_loss 0.25369 
Epoch [247/300] Validation [3/16] Loss: 0.62119  focal_loss 0.33603  dice_loss 0.28516 
Epoch [247/300] Validation [4/16] Loss: 0.30444  focal_loss 0.16284  dice_loss 0.14160 
Epoch [247/300] Validation [5/16] Loss: 0.36530  focal_loss 0.15610  dice_loss 0.20920 
Epoch [247/300] Validation [6/16] Loss: 0.29650  focal_loss 0.09742  dice_loss 0.19908 
Epoch [247/300] Validation [7/16] Loss: 0.19792  focal_loss 0.07679  dice_loss 0.12113 
Epoch [247/300] Validation [8/16] Loss: 0.51117  focal_loss 0.21791  dice_loss 0.29326 
Epoch [247/300] Validation [9/16] Loss: 0.21603  focal_loss 0.09757  dice_loss 0.11846 
Epoch [247/300] Validation [10/16] Loss: 0.44530  focal_loss 0.14896  dice_loss 0.29634 
Epoch [247/300] Validation [11/16] Loss: 0.15902  focal_loss 0.05986  dice_loss 0.09916 
Epoch [247/300] Validation [12/16] Loss: 0.40842  focal_loss 0.13900  dice_loss 0.26942 
Epoch [247/300] Validation [13/16] Loss: 0.27071  focal_loss 0.10815  dice_loss 0.16255 
Epoch [247/300] Validation [14/16] Loss: 0.53813  focal_loss 0.26342  dice_loss 0.27470 
Epoch [247/300] Validation [15/16] Loss: 0.13601  focal_loss 0.05480  dice_loss 0.08121 
Epoch [247/300] Validation [16/16] Loss: 0.09710  focal_loss 0.03555  dice_loss 0.06155 
Epoch [247/300] Validation metric {'Val/mean dice_metric': 0.9398679137229919, 'Val/mean miou_metric': 0.9048359990119934, 'Val/mean f1': 0.9471895098686218, 'Val/mean precision': 0.9525241255760193, 'Val/mean recall': 0.9419142603874207, 'Val/mean hd95_metric': 14.37214183807373}
Cheakpoint...
Epoch [247/300] best acc:tensor([0.9399], device='cuda:0'), Now : mean acc: tensor([0.9399], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9398679137229919, 'Val/mean miou_metric': 0.9048359990119934, 'Val/mean f1': 0.9471895098686218, 'Val/mean precision': 0.9525241255760193, 'Val/mean recall': 0.9419142603874207, 'Val/mean hd95_metric': 14.37214183807373}
Epoch [248/300] Training [1/62] Loss: 0.03415 
Epoch [248/300] Training [2/62] Loss: 0.05111 
Epoch [248/300] Training [3/62] Loss: 0.04954 
Epoch [248/300] Training [4/62] Loss: 0.06716 
Epoch [248/300] Training [5/62] Loss: 0.03004 
Epoch [248/300] Training [6/62] Loss: 0.03407 
Epoch [248/300] Training [7/62] Loss: 0.02738 
Epoch [248/300] Training [8/62] Loss: 0.04395 
Epoch [248/300] Training [9/62] Loss: 0.02244 
Epoch [248/300] Training [10/62] Loss: 0.04802 
Epoch [248/300] Training [11/62] Loss: 0.05899 
Epoch [248/300] Training [12/62] Loss: 0.02502 
Epoch [248/300] Training [13/62] Loss: 0.02169 
Epoch [248/300] Training [14/62] Loss: 0.02797 
Epoch [248/300] Training [15/62] Loss: 0.06565 
Epoch [248/300] Training [16/62] Loss: 0.04299 
Epoch [248/300] Training [17/62] Loss: 0.03037 
Epoch [248/300] Training [18/62] Loss: 0.02914 
Epoch [248/300] Training [19/62] Loss: 0.04437 
Epoch [248/300] Training [20/62] Loss: 0.04491 
Epoch [248/300] Training [21/62] Loss: 0.06987 
Epoch [248/300] Training [22/62] Loss: 0.02761 
Epoch [248/300] Training [23/62] Loss: 0.03747 
Epoch [248/300] Training [24/62] Loss: 0.02618 
Epoch [248/300] Training [25/62] Loss: 0.02675 
Epoch [248/300] Training [26/62] Loss: 0.10128 
Epoch [248/300] Training [27/62] Loss: 0.02195 
Epoch [248/300] Training [28/62] Loss: 0.17418 
Epoch [248/300] Training [29/62] Loss: 0.04773 
Epoch [248/300] Training [30/62] Loss: 0.03003 
Epoch [248/300] Training [31/62] Loss: 0.02772 
Epoch [248/300] Training [32/62] Loss: 0.02823 
Epoch [248/300] Training [33/62] Loss: 0.08146 
Epoch [248/300] Training [34/62] Loss: 0.02402 
Epoch [248/300] Training [35/62] Loss: 0.03191 
Epoch [248/300] Training [36/62] Loss: 0.02713 
Epoch [248/300] Training [37/62] Loss: 0.03112 
Epoch [248/300] Training [38/62] Loss: 0.02936 
Epoch [248/300] Training [39/62] Loss: 0.09571 
Epoch [248/300] Training [40/62] Loss: 0.03298 
Epoch [248/300] Training [41/62] Loss: 0.05208 
Epoch [248/300] Training [42/62] Loss: 0.01998 
Epoch [248/300] Training [43/62] Loss: 0.02880 
Epoch [248/300] Training [44/62] Loss: 0.03452 
Epoch [248/300] Training [45/62] Loss: 0.05091 
Epoch [248/300] Training [46/62] Loss: 0.02652 
Epoch [248/300] Training [47/62] Loss: 0.05718 
Epoch [248/300] Training [48/62] Loss: 0.02583 
Epoch [248/300] Training [49/62] Loss: 0.04037 
Epoch [248/300] Training [50/62] Loss: 0.02973 
Epoch [248/300] Training [51/62] Loss: 0.02689 
Epoch [248/300] Training [52/62] Loss: 0.03498 
Epoch [248/300] Training [53/62] Loss: 0.04022 
Epoch [248/300] Training [54/62] Loss: 0.02631 
Epoch [248/300] Training [55/62] Loss: 0.04075 
Epoch [248/300] Training [56/62] Loss: 0.11123 
Epoch [248/300] Training [57/62] Loss: 0.02428 
Epoch [248/300] Training [58/62] Loss: 0.02623 
Epoch [248/300] Training [59/62] Loss: 0.02829 
Epoch [248/300] Training [60/62] Loss: 0.03388 
Epoch [248/300] Training [61/62] Loss: 0.04152 
Epoch [248/300] Training [62/62] Loss: 0.13559 
Epoch [248/300] Training metric {'Train/mean dice_metric': 0.9711931347846985, 'Train/mean miou_metric': 0.9483721256256104, 'Train/mean f1': 0.973183810710907, 'Train/mean precision': 0.9694882035255432, 'Train/mean recall': 0.9769077897071838, 'Train/mean hd95_metric': 6.2713541984558105}
Epoch [248/300] Validation [1/16] Loss: 0.62014  focal_loss 0.42474  dice_loss 0.19540 
Epoch [248/300] Validation [2/16] Loss: 0.49685  focal_loss 0.21093  dice_loss 0.28591 
Epoch [248/300] Validation [3/16] Loss: 0.75520  focal_loss 0.45305  dice_loss 0.30214 
Epoch [248/300] Validation [4/16] Loss: 0.30720  focal_loss 0.16094  dice_loss 0.14626 
Epoch [248/300] Validation [5/16] Loss: 0.32551  focal_loss 0.12170  dice_loss 0.20381 
Epoch [248/300] Validation [6/16] Loss: 0.28399  focal_loss 0.09244  dice_loss 0.19155 
Epoch [248/300] Validation [7/16] Loss: 0.18048  focal_loss 0.08531  dice_loss 0.09517 
Epoch [248/300] Validation [8/16] Loss: 0.43821  focal_loss 0.16286  dice_loss 0.27535 
Epoch [248/300] Validation [9/16] Loss: 0.19520  focal_loss 0.08556  dice_loss 0.10965 
Epoch [248/300] Validation [10/16] Loss: 0.50232  focal_loss 0.18212  dice_loss 0.32020 
Epoch [248/300] Validation [11/16] Loss: 0.16961  focal_loss 0.06995  dice_loss 0.09966 
Epoch [248/300] Validation [12/16] Loss: 0.39367  focal_loss 0.13035  dice_loss 0.26332 
Epoch [248/300] Validation [13/16] Loss: 0.21572  focal_loss 0.08322  dice_loss 0.13250 
Epoch [248/300] Validation [14/16] Loss: 0.62115  focal_loss 0.29417  dice_loss 0.32698 
Epoch [248/300] Validation [15/16] Loss: 0.14494  focal_loss 0.05683  dice_loss 0.08811 
Epoch [248/300] Validation [16/16] Loss: 0.11399  focal_loss 0.03612  dice_loss 0.07788 
Epoch [248/300] Validation metric {'Val/mean dice_metric': 0.9375475645065308, 'Val/mean miou_metric': 0.9026257991790771, 'Val/mean f1': 0.9460631608963013, 'Val/mean precision': 0.9505074620246887, 'Val/mean recall': 0.9416602849960327, 'Val/mean hd95_metric': 15.199803352355957}
Cheakpoint...
Epoch [248/300] best acc:tensor([0.9399], device='cuda:0'), Now : mean acc: tensor([0.9375], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9375475645065308, 'Val/mean miou_metric': 0.9026257991790771, 'Val/mean f1': 0.9460631608963013, 'Val/mean precision': 0.9505074620246887, 'Val/mean recall': 0.9416602849960327, 'Val/mean hd95_metric': 15.199803352355957}
Epoch [249/300] Training [1/62] Loss: 0.02879 
Epoch [249/300] Training [2/62] Loss: 0.02616 
Epoch [249/300] Training [3/62] Loss: 0.02361 
Epoch [249/300] Training [4/62] Loss: 0.03086 
Epoch [249/300] Training [5/62] Loss: 0.02990 
Epoch [249/300] Training [6/62] Loss: 0.03436 
Epoch [249/300] Training [7/62] Loss: 0.02495 
Epoch [249/300] Training [8/62] Loss: 0.02730 
Epoch [249/300] Training [9/62] Loss: 0.04797 
Epoch [249/300] Training [10/62] Loss: 0.02688 
Epoch [249/300] Training [11/62] Loss: 0.01941 
Epoch [249/300] Training [12/62] Loss: 0.03278 
Epoch [249/300] Training [13/62] Loss: 0.02322 
Epoch [249/300] Training [14/62] Loss: 0.04282 
Epoch [249/300] Training [15/62] Loss: 0.04140 
Epoch [249/300] Training [16/62] Loss: 0.04525 
Epoch [249/300] Training [17/62] Loss: 0.02984 
Epoch [249/300] Training [18/62] Loss: 0.03846 
Epoch [249/300] Training [19/62] Loss: 0.01733 
Epoch [249/300] Training [20/62] Loss: 0.03458 
Epoch [249/300] Training [21/62] Loss: 0.03355 
Epoch [249/300] Training [22/62] Loss: 0.03398 
Epoch [249/300] Training [23/62] Loss: 0.02896 
Epoch [249/300] Training [24/62] Loss: 0.03505 
Epoch [249/300] Training [25/62] Loss: 0.07173 
Epoch [249/300] Training [26/62] Loss: 0.03202 
Epoch [249/300] Training [27/62] Loss: 0.04052 
Epoch [249/300] Training [28/62] Loss: 0.04426 
Epoch [249/300] Training [29/62] Loss: 0.04273 
Epoch [249/300] Training [30/62] Loss: 0.03243 
Epoch [249/300] Training [31/62] Loss: 0.06937 
Epoch [249/300] Training [32/62] Loss: 0.04511 
Epoch [249/300] Training [33/62] Loss: 0.02909 
Epoch [249/300] Training [34/62] Loss: 0.03595 
Epoch [249/300] Training [35/62] Loss: 0.02625 
Epoch [249/300] Training [36/62] Loss: 0.03552 
Epoch [249/300] Training [37/62] Loss: 0.02417 
Epoch [249/300] Training [38/62] Loss: 0.02960 
Epoch [249/300] Training [39/62] Loss: 0.03383 
Epoch [249/300] Training [40/62] Loss: 0.09516 
Epoch [249/300] Training [41/62] Loss: 0.02519 
Epoch [249/300] Training [42/62] Loss: 0.02588 
Epoch [249/300] Training [43/62] Loss: 0.02018 
Epoch [249/300] Training [44/62] Loss: 0.04242 
Epoch [249/300] Training [45/62] Loss: 0.04503 
Epoch [249/300] Training [46/62] Loss: 0.02545 
Epoch [249/300] Training [47/62] Loss: 0.04263 
Epoch [249/300] Training [48/62] Loss: 0.05306 
Epoch [249/300] Training [49/62] Loss: 0.06570 
Epoch [249/300] Training [50/62] Loss: 0.08099 
Epoch [249/300] Training [51/62] Loss: 0.08066 
Epoch [249/300] Training [52/62] Loss: 0.06087 
Epoch [249/300] Training [53/62] Loss: 0.02985 
Epoch [249/300] Training [54/62] Loss: 0.02863 
Epoch [249/300] Training [55/62] Loss: 0.05087 
Epoch [249/300] Training [56/62] Loss: 0.04935 
Epoch [249/300] Training [57/62] Loss: 0.02055 
Epoch [249/300] Training [58/62] Loss: 0.05619 
Epoch [249/300] Training [59/62] Loss: 0.06448 
Epoch [249/300] Training [60/62] Loss: 0.03113 
Epoch [249/300] Training [61/62] Loss: 0.03029 
Epoch [249/300] Training [62/62] Loss: 0.02458 
Epoch [249/300] Training metric {'Train/mean dice_metric': 0.9740689396858215, 'Train/mean miou_metric': 0.9513965249061584, 'Train/mean f1': 0.9734999537467957, 'Train/mean precision': 0.9703854322433472, 'Train/mean recall': 0.9766346216201782, 'Train/mean hd95_metric': 6.416894435882568}
Epoch [249/300] Validation [1/16] Loss: 0.66154  focal_loss 0.45100  dice_loss 0.21054 
Epoch [249/300] Validation [2/16] Loss: 0.46883  focal_loss 0.19523  dice_loss 0.27360 
Epoch [249/300] Validation [3/16] Loss: 0.66116  focal_loss 0.38872  dice_loss 0.27244 
Epoch [249/300] Validation [4/16] Loss: 0.30127  focal_loss 0.16136  dice_loss 0.13991 
Epoch [249/300] Validation [5/16] Loss: 0.36425  focal_loss 0.13950  dice_loss 0.22475 
Epoch [249/300] Validation [6/16] Loss: 0.28988  focal_loss 0.09179  dice_loss 0.19809 
Epoch [249/300] Validation [7/16] Loss: 0.22092  focal_loss 0.10475  dice_loss 0.11618 
Epoch [249/300] Validation [8/16] Loss: 0.48859  focal_loss 0.19936  dice_loss 0.28923 
Epoch [249/300] Validation [9/16] Loss: 0.20521  focal_loss 0.09210  dice_loss 0.11312 
Epoch [249/300] Validation [10/16] Loss: 0.53546  focal_loss 0.19868  dice_loss 0.33679 
Epoch [249/300] Validation [11/16] Loss: 0.16763  focal_loss 0.06113  dice_loss 0.10650 
Epoch [249/300] Validation [12/16] Loss: 0.38470  focal_loss 0.11633  dice_loss 0.26837 
Epoch [249/300] Validation [13/16] Loss: 0.25579  focal_loss 0.09781  dice_loss 0.15797 
Epoch [249/300] Validation [14/16] Loss: 0.59765  focal_loss 0.26088  dice_loss 0.33677 
Epoch [249/300] Validation [15/16] Loss: 0.12676  focal_loss 0.05354  dice_loss 0.07322 
Epoch [249/300] Validation [16/16] Loss: 0.14224  focal_loss 0.04863  dice_loss 0.09360 
Epoch [249/300] Validation metric {'Val/mean dice_metric': 0.9386907815933228, 'Val/mean miou_metric': 0.9031625390052795, 'Val/mean f1': 0.9459843039512634, 'Val/mean precision': 0.9519497156143188, 'Val/mean recall': 0.9400931596755981, 'Val/mean hd95_metric': 15.77489948272705}
Cheakpoint...
Epoch [249/300] best acc:tensor([0.9399], device='cuda:0'), Now : mean acc: tensor([0.9387], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9386907815933228, 'Val/mean miou_metric': 0.9031625390052795, 'Val/mean f1': 0.9459843039512634, 'Val/mean precision': 0.9519497156143188, 'Val/mean recall': 0.9400931596755981, 'Val/mean hd95_metric': 15.77489948272705}
Epoch [250/300] Training [1/62] Loss: 0.03113 
Epoch [250/300] Training [2/62] Loss: 0.04154 
Epoch [250/300] Training [3/62] Loss: 0.04938 
Epoch [250/300] Training [4/62] Loss: 0.02332 
Epoch [250/300] Training [5/62] Loss: 0.05735 
Epoch [250/300] Training [6/62] Loss: 0.03063 
Epoch [250/300] Training [7/62] Loss: 0.04563 
Epoch [250/300] Training [8/62] Loss: 0.03388 
Epoch [250/300] Training [9/62] Loss: 0.04896 
Epoch [250/300] Training [10/62] Loss: 0.03390 
Epoch [250/300] Training [11/62] Loss: 0.03181 
Epoch [250/300] Training [12/62] Loss: 0.04624 
Epoch [250/300] Training [13/62] Loss: 0.03124 
Epoch [250/300] Training [14/62] Loss: 0.07218 
Epoch [250/300] Training [15/62] Loss: 0.07173 
Epoch [250/300] Training [16/62] Loss: 0.02763 
Epoch [250/300] Training [17/62] Loss: 0.03136 
Epoch [250/300] Training [18/62] Loss: 0.02419 
Epoch [250/300] Training [19/62] Loss: 0.03759 
Epoch [250/300] Training [20/62] Loss: 0.03010 
Epoch [250/300] Training [21/62] Loss: 0.02291 
Epoch [250/300] Training [22/62] Loss: 0.05082 
Epoch [250/300] Training [23/62] Loss: 0.02718 
Epoch [250/300] Training [24/62] Loss: 0.10155 
Epoch [250/300] Training [25/62] Loss: 0.02039 
Epoch [250/300] Training [26/62] Loss: 0.03514 
Epoch [250/300] Training [27/62] Loss: 0.02097 
Epoch [250/300] Training [28/62] Loss: 0.02691 
Epoch [250/300] Training [29/62] Loss: 0.02074 
Epoch [250/300] Training [30/62] Loss: 0.03648 
Epoch [250/300] Training [31/62] Loss: 0.02203 
Epoch [250/300] Training [32/62] Loss: 0.02261 
Epoch [250/300] Training [33/62] Loss: 0.06585 
Epoch [250/300] Training [34/62] Loss: 0.02720 
Epoch [250/300] Training [35/62] Loss: 0.03691 
Epoch [250/300] Training [36/62] Loss: 0.02597 
Epoch [250/300] Training [37/62] Loss: 0.04125 
Epoch [250/300] Training [38/62] Loss: 0.04506 
Epoch [250/300] Training [39/62] Loss: 0.02355 
Epoch [250/300] Training [40/62] Loss: 0.03022 
Epoch [250/300] Training [41/62] Loss: 0.02272 
Epoch [250/300] Training [42/62] Loss: 0.04759 
Epoch [250/300] Training [43/62] Loss: 0.02610 
Epoch [250/300] Training [44/62] Loss: 0.02096 
Epoch [250/300] Training [45/62] Loss: 0.08642 
Epoch [250/300] Training [46/62] Loss: 0.03780 
Epoch [250/300] Training [47/62] Loss: 0.04636 
Epoch [250/300] Training [48/62] Loss: 0.02719 
Epoch [250/300] Training [49/62] Loss: 0.02755 
Epoch [250/300] Training [50/62] Loss: 0.03445 
Epoch [250/300] Training [51/62] Loss: 0.04839 
Epoch [250/300] Training [52/62] Loss: 0.02716 
Epoch [250/300] Training [53/62] Loss: 0.03002 
Epoch [250/300] Training [54/62] Loss: 0.04329 
Epoch [250/300] Training [55/62] Loss: 0.03068 
Epoch [250/300] Training [56/62] Loss: 0.02351 
Epoch [250/300] Training [57/62] Loss: 0.01958 
Epoch [250/300] Training [58/62] Loss: 0.03161 
Epoch [250/300] Training [59/62] Loss: 0.02169 
Epoch [250/300] Training [60/62] Loss: 0.04416 
Epoch [250/300] Training [61/62] Loss: 0.02121 
Epoch [250/300] Training [62/62] Loss: 0.04441 
Epoch [250/300] Training metric {'Train/mean dice_metric': 0.97645503282547, 'Train/mean miou_metric': 0.9550694227218628, 'Train/mean f1': 0.9741671085357666, 'Train/mean precision': 0.971362292766571, 'Train/mean recall': 0.9769882559776306, 'Train/mean hd95_metric': 6.059372901916504}
Epoch [250/300] Validation [1/16] Loss: 0.67620  focal_loss 0.46937  dice_loss 0.20682 
Epoch [250/300] Validation [2/16] Loss: 0.54354  focal_loss 0.23445  dice_loss 0.30909 
Epoch [250/300] Validation [3/16] Loss: 0.76179  focal_loss 0.46729  dice_loss 0.29449 
Epoch [250/300] Validation [4/16] Loss: 0.30212  focal_loss 0.16371  dice_loss 0.13842 
Epoch [250/300] Validation [5/16] Loss: 0.32214  focal_loss 0.12294  dice_loss 0.19920 
Epoch [250/300] Validation [6/16] Loss: 0.28037  focal_loss 0.08539  dice_loss 0.19498 
Epoch [250/300] Validation [7/16] Loss: 0.27527  focal_loss 0.11310  dice_loss 0.16217 
Epoch [250/300] Validation [8/16] Loss: 0.52562  focal_loss 0.19103  dice_loss 0.33459 
Epoch [250/300] Validation [9/16] Loss: 0.21410  focal_loss 0.09785  dice_loss 0.11625 
Epoch [250/300] Validation [10/16] Loss: 0.62176  focal_loss 0.23503  dice_loss 0.38673 
Epoch [250/300] Validation [11/16] Loss: 0.14268  focal_loss 0.05065  dice_loss 0.09203 
Epoch [250/300] Validation [12/16] Loss: 0.41788  focal_loss 0.13613  dice_loss 0.28175 
Epoch [250/300] Validation [13/16] Loss: 0.27632  focal_loss 0.11077  dice_loss 0.16555 
Epoch [250/300] Validation [14/16] Loss: 0.59270  focal_loss 0.26603  dice_loss 0.32667 
Epoch [250/300] Validation [15/16] Loss: 0.13319  focal_loss 0.05530  dice_loss 0.07788 
Epoch [250/300] Validation [16/16] Loss: 0.10835  focal_loss 0.04282  dice_loss 0.06552 
Epoch [250/300] Validation metric {'Val/mean dice_metric': 0.9384171366691589, 'Val/mean miou_metric': 0.9042601585388184, 'Val/mean f1': 0.9453049302101135, 'Val/mean precision': 0.9545661807060242, 'Val/mean recall': 0.9362218379974365, 'Val/mean hd95_metric': 14.372505187988281}
Cheakpoint...
Epoch [250/300] best acc:tensor([0.9399], device='cuda:0'), Now : mean acc: tensor([0.9384], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9384171366691589, 'Val/mean miou_metric': 0.9042601585388184, 'Val/mean f1': 0.9453049302101135, 'Val/mean precision': 0.9545661807060242, 'Val/mean recall': 0.9362218379974365, 'Val/mean hd95_metric': 14.372505187988281}
Epoch [251/300] Training [1/62] Loss: 0.04169 
Epoch [251/300] Training [2/62] Loss: 0.03392 
Epoch [251/300] Training [3/62] Loss: 0.01929 
Epoch [251/300] Training [4/62] Loss: 0.03329 
Epoch [251/300] Training [5/62] Loss: 0.02429 
Epoch [251/300] Training [6/62] Loss: 0.03056 
Epoch [251/300] Training [7/62] Loss: 0.12567 
Epoch [251/300] Training [8/62] Loss: 0.02707 
Epoch [251/300] Training [9/62] Loss: 0.03169 
Epoch [251/300] Training [10/62] Loss: 0.02777 
Epoch [251/300] Training [11/62] Loss: 0.02554 
Epoch [251/300] Training [12/62] Loss: 0.03722 
Epoch [251/300] Training [13/62] Loss: 0.02107 
Epoch [251/300] Training [14/62] Loss: 0.02662 
Epoch [251/300] Training [15/62] Loss: 0.06194 
Epoch [251/300] Training [16/62] Loss: 0.02979 
Epoch [251/300] Training [17/62] Loss: 0.02833 
Epoch [251/300] Training [18/62] Loss: 0.02649 
Epoch [251/300] Training [19/62] Loss: 0.17195 
Epoch [251/300] Training [20/62] Loss: 0.04727 
Epoch [251/300] Training [21/62] Loss: 0.02249 
Epoch [251/300] Training [22/62] Loss: 0.02770 
Epoch [251/300] Training [23/62] Loss: 0.02518 
Epoch [251/300] Training [24/62] Loss: 0.04290 
Epoch [251/300] Training [25/62] Loss: 0.03312 
Epoch [251/300] Training [26/62] Loss: 0.06556 
Epoch [251/300] Training [27/62] Loss: 0.03150 
Epoch [251/300] Training [28/62] Loss: 0.03752 
Epoch [251/300] Training [29/62] Loss: 0.04062 
Epoch [251/300] Training [30/62] Loss: 0.02732 
Epoch [251/300] Training [31/62] Loss: 0.02651 
Epoch [251/300] Training [32/62] Loss: 0.03400 
Epoch [251/300] Training [33/62] Loss: 0.03030 
Epoch [251/300] Training [34/62] Loss: 0.02352 
Epoch [251/300] Training [35/62] Loss: 0.15080 
Epoch [251/300] Training [36/62] Loss: 0.02322 
Epoch [251/300] Training [37/62] Loss: 0.02497 
Epoch [251/300] Training [38/62] Loss: 0.02581 
Epoch [251/300] Training [39/62] Loss: 0.05764 
Epoch [251/300] Training [40/62] Loss: 0.04119 
Epoch [251/300] Training [41/62] Loss: 0.05477 
Epoch [251/300] Training [42/62] Loss: 0.04562 
Epoch [251/300] Training [43/62] Loss: 0.06873 
Epoch [251/300] Training [44/62] Loss: 0.05652 
Epoch [251/300] Training [45/62] Loss: 0.04082 
Epoch [251/300] Training [46/62] Loss: 0.04757 
Epoch [251/300] Training [47/62] Loss: 0.02884 
Epoch [251/300] Training [48/62] Loss: 0.02945 
Epoch [251/300] Training [49/62] Loss: 0.04671 
Epoch [251/300] Training [50/62] Loss: 0.03543 
Epoch [251/300] Training [51/62] Loss: 0.02562 
Epoch [251/300] Training [52/62] Loss: 0.02972 
Epoch [251/300] Training [53/62] Loss: 0.02223 
Epoch [251/300] Training [54/62] Loss: 0.05463 
Epoch [251/300] Training [55/62] Loss: 0.02806 
Epoch [251/300] Training [56/62] Loss: 0.08483 
Epoch [251/300] Training [57/62] Loss: 0.03174 
Epoch [251/300] Training [58/62] Loss: 0.02695 
Epoch [251/300] Training [59/62] Loss: 0.03361 
Epoch [251/300] Training [60/62] Loss: 0.04539 
Epoch [251/300] Training [61/62] Loss: 0.02232 
Epoch [251/300] Training [62/62] Loss: 0.03714 
Epoch [251/300] Training metric {'Train/mean dice_metric': 0.9712139964103699, 'Train/mean miou_metric': 0.9494228363037109, 'Train/mean f1': 0.9743786454200745, 'Train/mean precision': 0.9708980917930603, 'Train/mean recall': 0.9778842329978943, 'Train/mean hd95_metric': 6.3017258644104}
Epoch [251/300] Validation [1/16] Loss: 0.70496  focal_loss 0.47676  dice_loss 0.22820 
Epoch [251/300] Validation [2/16] Loss: 0.46566  focal_loss 0.19499  dice_loss 0.27067 
Epoch [251/300] Validation [3/16] Loss: 0.75707  focal_loss 0.46135  dice_loss 0.29572 
Epoch [251/300] Validation [4/16] Loss: 0.34129  focal_loss 0.16613  dice_loss 0.17517 
Epoch [251/300] Validation [5/16] Loss: 0.32224  focal_loss 0.13107  dice_loss 0.19117 
Epoch [251/300] Validation [6/16] Loss: 0.26288  focal_loss 0.08616  dice_loss 0.17672 
Epoch [251/300] Validation [7/16] Loss: 0.21919  focal_loss 0.10487  dice_loss 0.11432 
Epoch [251/300] Validation [8/16] Loss: 0.50592  focal_loss 0.20076  dice_loss 0.30516 
Epoch [251/300] Validation [9/16] Loss: 0.22756  focal_loss 0.10662  dice_loss 0.12093 
Epoch [251/300] Validation [10/16] Loss: 0.58929  focal_loss 0.20874  dice_loss 0.38055 
Epoch [251/300] Validation [11/16] Loss: 0.13618  focal_loss 0.05344  dice_loss 0.08274 
Epoch [251/300] Validation [12/16] Loss: 0.38432  focal_loss 0.12052  dice_loss 0.26380 
Epoch [251/300] Validation [13/16] Loss: 0.26171  focal_loss 0.11171  dice_loss 0.15001 
Epoch [251/300] Validation [14/16] Loss: 0.58632  focal_loss 0.29186  dice_loss 0.29446 
Epoch [251/300] Validation [15/16] Loss: 0.16176  focal_loss 0.06190  dice_loss 0.09987 
Epoch [251/300] Validation [16/16] Loss: 0.09668  focal_loss 0.03483  dice_loss 0.06185 
Epoch [251/300] Validation metric {'Val/mean dice_metric': 0.9360610842704773, 'Val/mean miou_metric': 0.9019535779953003, 'Val/mean f1': 0.9456998109817505, 'Val/mean precision': 0.9517335295677185, 'Val/mean recall': 0.9397420883178711, 'Val/mean hd95_metric': 14.970219612121582}
Cheakpoint...
Epoch [251/300] best acc:tensor([0.9399], device='cuda:0'), Now : mean acc: tensor([0.9361], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9360610842704773, 'Val/mean miou_metric': 0.9019535779953003, 'Val/mean f1': 0.9456998109817505, 'Val/mean precision': 0.9517335295677185, 'Val/mean recall': 0.9397420883178711, 'Val/mean hd95_metric': 14.970219612121582}
Epoch [252/300] Training [1/62] Loss: 0.02862 
Epoch [252/300] Training [2/62] Loss: 0.03038 
Epoch [252/300] Training [3/62] Loss: 0.03017 
Epoch [252/300] Training [4/62] Loss: 0.05948 
Epoch [252/300] Training [5/62] Loss: 0.02919 
Epoch [252/300] Training [6/62] Loss: 0.16145 
Epoch [252/300] Training [7/62] Loss: 0.02392 
Epoch [252/300] Training [8/62] Loss: 0.02451 
Epoch [252/300] Training [9/62] Loss: 0.03626 
Epoch [252/300] Training [10/62] Loss: 0.02489 
Epoch [252/300] Training [11/62] Loss: 0.03638 
Epoch [252/300] Training [12/62] Loss: 0.03175 
Epoch [252/300] Training [13/62] Loss: 0.04367 
Epoch [252/300] Training [14/62] Loss: 0.05756 
Epoch [252/300] Training [15/62] Loss: 0.04046 
Epoch [252/300] Training [16/62] Loss: 0.04280 
Epoch [252/300] Training [17/62] Loss: 0.02626 
Epoch [252/300] Training [18/62] Loss: 0.02818 
Epoch [252/300] Training [19/62] Loss: 0.02109 
Epoch [252/300] Training [20/62] Loss: 0.02816 
Epoch [252/300] Training [21/62] Loss: 0.05757 
Epoch [252/300] Training [22/62] Loss: 0.03918 
Epoch [252/300] Training [23/62] Loss: 0.02532 
Epoch [252/300] Training [24/62] Loss: 0.02584 
Epoch [252/300] Training [25/62] Loss: 0.03744 
Epoch [252/300] Training [26/62] Loss: 0.04877 
Epoch [252/300] Training [27/62] Loss: 0.03467 
Epoch [252/300] Training [28/62] Loss: 0.04478 
Epoch [252/300] Training [29/62] Loss: 0.02644 
Epoch [252/300] Training [30/62] Loss: 0.02451 
Epoch [252/300] Training [31/62] Loss: 0.03386 
Epoch [252/300] Training [32/62] Loss: 0.02087 
Epoch [252/300] Training [33/62] Loss: 0.02404 
Epoch [252/300] Training [34/62] Loss: 0.03144 
Epoch [252/300] Training [35/62] Loss: 0.03454 
Epoch [252/300] Training [36/62] Loss: 0.10306 
Epoch [252/300] Training [37/62] Loss: 0.02379 
Epoch [252/300] Training [38/62] Loss: 0.03723 
Epoch [252/300] Training [39/62] Loss: 0.02202 
Epoch [252/300] Training [40/62] Loss: 0.02614 
Epoch [252/300] Training [41/62] Loss: 0.04169 
Epoch [252/300] Training [42/62] Loss: 0.06053 
Epoch [252/300] Training [43/62] Loss: 0.02796 
Epoch [252/300] Training [44/62] Loss: 0.04925 
Epoch [252/300] Training [45/62] Loss: 0.03151 
Epoch [252/300] Training [46/62] Loss: 0.05195 
Epoch [252/300] Training [47/62] Loss: 0.04387 
Epoch [252/300] Training [48/62] Loss: 0.05574 
Epoch [252/300] Training [49/62] Loss: 0.07143 
Epoch [252/300] Training [50/62] Loss: 0.03084 
Epoch [252/300] Training [51/62] Loss: 0.06683 
Epoch [252/300] Training [52/62] Loss: 0.02361 
Epoch [252/300] Training [53/62] Loss: 0.05136 
Epoch [252/300] Training [54/62] Loss: 0.02039 
Epoch [252/300] Training [55/62] Loss: 0.07246 
Epoch [252/300] Training [56/62] Loss: 0.03696 
Epoch [252/300] Training [57/62] Loss: 0.01865 
Epoch [252/300] Training [58/62] Loss: 0.03445 
Epoch [252/300] Training [59/62] Loss: 0.05550 
Epoch [252/300] Training [60/62] Loss: 0.02675 
Epoch [252/300] Training [61/62] Loss: 0.05092 
Epoch [252/300] Training [62/62] Loss: 0.03188 
Epoch [252/300] Training metric {'Train/mean dice_metric': 0.9728794693946838, 'Train/mean miou_metric': 0.9505913257598877, 'Train/mean f1': 0.9742398858070374, 'Train/mean precision': 0.9706391096115112, 'Train/mean recall': 0.9778674244880676, 'Train/mean hd95_metric': 6.2027740478515625}
Epoch [252/300] Validation [1/16] Loss: 0.69542  focal_loss 0.48521  dice_loss 0.21021 
Epoch [252/300] Validation [2/16] Loss: 0.49884  focal_loss 0.21645  dice_loss 0.28239 
Epoch [252/300] Validation [3/16] Loss: 0.74503  focal_loss 0.45320  dice_loss 0.29183 
Epoch [252/300] Validation [4/16] Loss: 0.35425  focal_loss 0.18328  dice_loss 0.17098 
Epoch [252/300] Validation [5/16] Loss: 0.36707  focal_loss 0.14736  dice_loss 0.21972 
Epoch [252/300] Validation [6/16] Loss: 0.27785  focal_loss 0.09486  dice_loss 0.18300 
Epoch [252/300] Validation [7/16] Loss: 0.20306  focal_loss 0.08074  dice_loss 0.12232 
Epoch [252/300] Validation [8/16] Loss: 0.56500  focal_loss 0.23665  dice_loss 0.32835 
Epoch [252/300] Validation [9/16] Loss: 0.21353  focal_loss 0.09767  dice_loss 0.11586 
Epoch [252/300] Validation [10/16] Loss: 0.52295  focal_loss 0.19955  dice_loss 0.32340 
Epoch [252/300] Validation [11/16] Loss: 0.14582  focal_loss 0.05573  dice_loss 0.09009 
Epoch [252/300] Validation [12/16] Loss: 0.38544  focal_loss 0.11865  dice_loss 0.26679 
Epoch [252/300] Validation [13/16] Loss: 0.27190  focal_loss 0.10876  dice_loss 0.16314 
Epoch [252/300] Validation [14/16] Loss: 0.53077  focal_loss 0.24428  dice_loss 0.28649 
Epoch [252/300] Validation [15/16] Loss: 0.11178  focal_loss 0.04577  dice_loss 0.06601 
Epoch [252/300] Validation [16/16] Loss: 0.09418  focal_loss 0.03634  dice_loss 0.05784 
Epoch [252/300] Validation metric {'Val/mean dice_metric': 0.9378355145454407, 'Val/mean miou_metric': 0.9030071496963501, 'Val/mean f1': 0.9460780024528503, 'Val/mean precision': 0.9527395367622375, 'Val/mean recall': 0.9395092129707336, 'Val/mean hd95_metric': 14.37979507446289}
Cheakpoint...
Epoch [252/300] best acc:tensor([0.9399], device='cuda:0'), Now : mean acc: tensor([0.9378], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9378355145454407, 'Val/mean miou_metric': 0.9030071496963501, 'Val/mean f1': 0.9460780024528503, 'Val/mean precision': 0.9527395367622375, 'Val/mean recall': 0.9395092129707336, 'Val/mean hd95_metric': 14.37979507446289}
Epoch [253/300] Training [1/62] Loss: 0.02228 
Epoch [253/300] Training [2/62] Loss: 0.02513 
Epoch [253/300] Training [3/62] Loss: 0.02492 
Epoch [253/300] Training [4/62] Loss: 0.03574 
Epoch [253/300] Training [5/62] Loss: 0.04471 
Epoch [253/300] Training [6/62] Loss: 0.05726 
Epoch [253/300] Training [7/62] Loss: 0.02407 
Epoch [253/300] Training [8/62] Loss: 0.03202 
Epoch [253/300] Training [9/62] Loss: 0.02343 
Epoch [253/300] Training [10/62] Loss: 0.03213 
Epoch [253/300] Training [11/62] Loss: 0.03112 
Epoch [253/300] Training [12/62] Loss: 0.06575 
Epoch [253/300] Training [13/62] Loss: 0.05849 
Epoch [253/300] Training [14/62] Loss: 0.04408 
Epoch [253/300] Training [15/62] Loss: 0.02945 
Epoch [253/300] Training [16/62] Loss: 0.03233 
Epoch [253/300] Training [17/62] Loss: 0.07109 
Epoch [253/300] Training [18/62] Loss: 0.04611 
Epoch [253/300] Training [19/62] Loss: 0.02667 
Epoch [253/300] Training [20/62] Loss: 0.02824 
Epoch [253/300] Training [21/62] Loss: 0.02696 
Epoch [253/300] Training [22/62] Loss: 0.03122 
Epoch [253/300] Training [23/62] Loss: 0.03416 
Epoch [253/300] Training [24/62] Loss: 0.03300 
Epoch [253/300] Training [25/62] Loss: 0.06688 
Epoch [253/300] Training [26/62] Loss: 0.02705 
Epoch [253/300] Training [27/62] Loss: 0.02446 
Epoch [253/300] Training [28/62] Loss: 0.04308 
Epoch [253/300] Training [29/62] Loss: 0.02687 
Epoch [253/300] Training [30/62] Loss: 0.02646 
Epoch [253/300] Training [31/62] Loss: 0.03907 
Epoch [253/300] Training [32/62] Loss: 0.03515 
Epoch [253/300] Training [33/62] Loss: 0.03509 
Epoch [253/300] Training [34/62] Loss: 0.02731 
Epoch [253/300] Training [35/62] Loss: 0.03412 
Epoch [253/300] Training [36/62] Loss: 0.02918 
Epoch [253/300] Training [37/62] Loss: 0.02695 
Epoch [253/300] Training [38/62] Loss: 0.03762 
Epoch [253/300] Training [39/62] Loss: 0.05225 
Epoch [253/300] Training [40/62] Loss: 0.02368 
Epoch [253/300] Training [41/62] Loss: 0.02885 
Epoch [253/300] Training [42/62] Loss: 0.02590 
Epoch [253/300] Training [43/62] Loss: 0.03263 
Epoch [253/300] Training [44/62] Loss: 0.03315 
Epoch [253/300] Training [45/62] Loss: 0.08847 
Epoch [253/300] Training [46/62] Loss: 0.03350 
Epoch [253/300] Training [47/62] Loss: 0.01879 
Epoch [253/300] Training [48/62] Loss: 0.03431 
Epoch [253/300] Training [49/62] Loss: 0.02876 
Epoch [253/300] Training [50/62] Loss: 0.03396 
Epoch [253/300] Training [51/62] Loss: 0.02319 
Epoch [253/300] Training [52/62] Loss: 0.03402 
Epoch [253/300] Training [53/62] Loss: 0.03383 
Epoch [253/300] Training [54/62] Loss: 0.02625 
Epoch [253/300] Training [55/62] Loss: 0.04045 
Epoch [253/300] Training [56/62] Loss: 0.05023 
Epoch [253/300] Training [57/62] Loss: 0.03974 
Epoch [253/300] Training [58/62] Loss: 0.03158 
Epoch [253/300] Training [59/62] Loss: 0.02480 
Epoch [253/300] Training [60/62] Loss: 0.07843 
Epoch [253/300] Training [61/62] Loss: 0.03390 
Epoch [253/300] Training [62/62] Loss: 0.02408 
Epoch [253/300] Training metric {'Train/mean dice_metric': 0.9756391048431396, 'Train/mean miou_metric': 0.953680157661438, 'Train/mean f1': 0.9752105474472046, 'Train/mean precision': 0.971825897693634, 'Train/mean recall': 0.978618860244751, 'Train/mean hd95_metric': 5.084067344665527}
Epoch [253/300] Validation [1/16] Loss: 0.66319  focal_loss 0.45645  dice_loss 0.20674 
Epoch [253/300] Validation [2/16] Loss: 0.51178  focal_loss 0.22081  dice_loss 0.29097 
Epoch [253/300] Validation [3/16] Loss: 0.73915  focal_loss 0.45948  dice_loss 0.27967 
Epoch [253/300] Validation [4/16] Loss: 0.34740  focal_loss 0.16708  dice_loss 0.18033 
Epoch [253/300] Validation [5/16] Loss: 0.31324  focal_loss 0.12790  dice_loss 0.18534 
Epoch [253/300] Validation [6/16] Loss: 0.30360  focal_loss 0.10280  dice_loss 0.20080 
Epoch [253/300] Validation [7/16] Loss: 0.16749  focal_loss 0.07548  dice_loss 0.09201 
Epoch [253/300] Validation [8/16] Loss: 0.41395  focal_loss 0.16669  dice_loss 0.24726 
Epoch [253/300] Validation [9/16] Loss: 0.20728  focal_loss 0.08777  dice_loss 0.11951 
Epoch [253/300] Validation [10/16] Loss: 0.51840  focal_loss 0.19182  dice_loss 0.32658 
Epoch [253/300] Validation [11/16] Loss: 0.16030  focal_loss 0.05816  dice_loss 0.10213 
Epoch [253/300] Validation [12/16] Loss: 0.39168  focal_loss 0.12742  dice_loss 0.26426 
Epoch [253/300] Validation [13/16] Loss: 0.23078  focal_loss 0.08427  dice_loss 0.14651 
Epoch [253/300] Validation [14/16] Loss: 0.58613  focal_loss 0.26934  dice_loss 0.31679 
Epoch [253/300] Validation [15/16] Loss: 0.15846  focal_loss 0.06321  dice_loss 0.09524 
Epoch [253/300] Validation [16/16] Loss: 0.11822  focal_loss 0.03964  dice_loss 0.07858 
Epoch [253/300] Validation metric {'Val/mean dice_metric': 0.9410173892974854, 'Val/mean miou_metric': 0.9066622853279114, 'Val/mean f1': 0.9475134015083313, 'Val/mean precision': 0.9522622227668762, 'Val/mean recall': 0.9428118467330933, 'Val/mean hd95_metric': 14.367369651794434}
Cheakpoint...
Epoch [253/300] best acc:tensor([0.9410], device='cuda:0'), Now : mean acc: tensor([0.9410], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9410173892974854, 'Val/mean miou_metric': 0.9066622853279114, 'Val/mean f1': 0.9475134015083313, 'Val/mean precision': 0.9522622227668762, 'Val/mean recall': 0.9428118467330933, 'Val/mean hd95_metric': 14.367369651794434}
Epoch [254/300] Training [1/62] Loss: 0.02586 
Epoch [254/300] Training [2/62] Loss: 0.02966 
Epoch [254/300] Training [3/62] Loss: 0.04606 
Epoch [254/300] Training [4/62] Loss: 0.05943 
Epoch [254/300] Training [5/62] Loss: 0.02244 
Epoch [254/300] Training [6/62] Loss: 0.02835 
Epoch [254/300] Training [7/62] Loss: 0.02430 
Epoch [254/300] Training [8/62] Loss: 0.03638 
Epoch [254/300] Training [9/62] Loss: 0.09825 
Epoch [254/300] Training [10/62] Loss: 0.02953 
Epoch [254/300] Training [11/62] Loss: 0.03985 
Epoch [254/300] Training [12/62] Loss: 0.02246 
Epoch [254/300] Training [13/62] Loss: 0.03074 
Epoch [254/300] Training [14/62] Loss: 0.04893 
Epoch [254/300] Training [15/62] Loss: 0.05821 
Epoch [254/300] Training [16/62] Loss: 0.02394 
Epoch [254/300] Training [17/62] Loss: 0.04372 
Epoch [254/300] Training [18/62] Loss: 0.03533 
Epoch [254/300] Training [19/62] Loss: 0.03651 
Epoch [254/300] Training [20/62] Loss: 0.02397 
Epoch [254/300] Training [21/62] Loss: 0.02547 
Epoch [254/300] Training [22/62] Loss: 0.03459 
Epoch [254/300] Training [23/62] Loss: 0.02106 
Epoch [254/300] Training [24/62] Loss: 0.02299 
Epoch [254/300] Training [25/62] Loss: 0.02913 
Epoch [254/300] Training [26/62] Loss: 0.02692 
Epoch [254/300] Training [27/62] Loss: 0.02081 
Epoch [254/300] Training [28/62] Loss: 0.02424 
Epoch [254/300] Training [29/62] Loss: 0.02931 
Epoch [254/300] Training [30/62] Loss: 0.08196 
Epoch [254/300] Training [31/62] Loss: 0.02385 
Epoch [254/300] Training [32/62] Loss: 0.02177 
Epoch [254/300] Training [33/62] Loss: 0.02067 
Epoch [254/300] Training [34/62] Loss: 0.03363 
Epoch [254/300] Training [35/62] Loss: 0.02010 
Epoch [254/300] Training [36/62] Loss: 0.02574 
Epoch [254/300] Training [37/62] Loss: 0.02400 
Epoch [254/300] Training [38/62] Loss: 0.02790 
Epoch [254/300] Training [39/62] Loss: 0.04219 
Epoch [254/300] Training [40/62] Loss: 0.02657 
Epoch [254/300] Training [41/62] Loss: 0.03201 
Epoch [254/300] Training [42/62] Loss: 0.03752 
Epoch [254/300] Training [43/62] Loss: 0.05334 
Epoch [254/300] Training [44/62] Loss: 0.04327 
Epoch [254/300] Training [45/62] Loss: 0.02184 
Epoch [254/300] Training [46/62] Loss: 0.02669 
Epoch [254/300] Training [47/62] Loss: 0.04215 
Epoch [254/300] Training [48/62] Loss: 0.05716 
Epoch [254/300] Training [49/62] Loss: 0.02135 
Epoch [254/300] Training [50/62] Loss: 0.05205 
Epoch [254/300] Training [51/62] Loss: 0.03072 
Epoch [254/300] Training [52/62] Loss: 0.02303 
Epoch [254/300] Training [53/62] Loss: 0.05247 
Epoch [254/300] Training [54/62] Loss: 0.03571 
Epoch [254/300] Training [55/62] Loss: 0.03124 
Epoch [254/300] Training [56/62] Loss: 0.03907 
Epoch [254/300] Training [57/62] Loss: 0.03869 
Epoch [254/300] Training [58/62] Loss: 0.03126 
Epoch [254/300] Training [59/62] Loss: 0.02424 
Epoch [254/300] Training [60/62] Loss: 0.03670 
Epoch [254/300] Training [61/62] Loss: 0.05530 
Epoch [254/300] Training [62/62] Loss: 0.03290 
Epoch [254/300] Training metric {'Train/mean dice_metric': 0.9764151573181152, 'Train/mean miou_metric': 0.9554989337921143, 'Train/mean f1': 0.9762563109397888, 'Train/mean precision': 0.9716380834579468, 'Train/mean recall': 0.9809186458587646, 'Train/mean hd95_metric': 5.178493976593018}
Epoch [254/300] Validation [1/16] Loss: 0.65598  focal_loss 0.47016  dice_loss 0.18582 
Epoch [254/300] Validation [2/16] Loss: 0.49914  focal_loss 0.22506  dice_loss 0.27408 
Epoch [254/300] Validation [3/16] Loss: 0.73811  focal_loss 0.46392  dice_loss 0.27419 
Epoch [254/300] Validation [4/16] Loss: 0.37087  focal_loss 0.17875  dice_loss 0.19212 
Epoch [254/300] Validation [5/16] Loss: 0.34366  focal_loss 0.14673  dice_loss 0.19693 
Epoch [254/300] Validation [6/16] Loss: 0.26459  focal_loss 0.08795  dice_loss 0.17664 
Epoch [254/300] Validation [7/16] Loss: 0.20718  focal_loss 0.09477  dice_loss 0.11241 
Epoch [254/300] Validation [8/16] Loss: 0.55624  focal_loss 0.22556  dice_loss 0.33068 
Epoch [254/300] Validation [9/16] Loss: 0.21794  focal_loss 0.09981  dice_loss 0.11813 
Epoch [254/300] Validation [10/16] Loss: 0.50261  focal_loss 0.18154  dice_loss 0.32107 
Epoch [254/300] Validation [11/16] Loss: 0.20403  focal_loss 0.07490  dice_loss 0.12914 
Epoch [254/300] Validation [12/16] Loss: 0.39052  focal_loss 0.12414  dice_loss 0.26639 
Epoch [254/300] Validation [13/16] Loss: 0.28251  focal_loss 0.12852  dice_loss 0.15399 
Epoch [254/300] Validation [14/16] Loss: 0.59054  focal_loss 0.25880  dice_loss 0.33174 
Epoch [254/300] Validation [15/16] Loss: 0.13144  focal_loss 0.05091  dice_loss 0.08053 
Epoch [254/300] Validation [16/16] Loss: 0.10551  focal_loss 0.03763  dice_loss 0.06788 
Epoch [254/300] Validation metric {'Val/mean dice_metric': 0.9401665925979614, 'Val/mean miou_metric': 0.9066233038902283, 'Val/mean f1': 0.9475160837173462, 'Val/mean precision': 0.9547457098960876, 'Val/mean recall': 0.940394937992096, 'Val/mean hd95_metric': 13.053304672241211}
Cheakpoint...
Epoch [254/300] best acc:tensor([0.9410], device='cuda:0'), Now : mean acc: tensor([0.9402], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9401665925979614, 'Val/mean miou_metric': 0.9066233038902283, 'Val/mean f1': 0.9475160837173462, 'Val/mean precision': 0.9547457098960876, 'Val/mean recall': 0.940394937992096, 'Val/mean hd95_metric': 13.053304672241211}
Epoch [255/300] Training [1/62] Loss: 0.02418 
Epoch [255/300] Training [2/62] Loss: 0.02731 
Epoch [255/300] Training [3/62] Loss: 0.02642 
Epoch [255/300] Training [4/62] Loss: 0.06939 
Epoch [255/300] Training [5/62] Loss: 0.02794 
Epoch [255/300] Training [6/62] Loss: 0.02457 
Epoch [255/300] Training [7/62] Loss: 0.02801 
Epoch [255/300] Training [8/62] Loss: 0.03002 
Epoch [255/300] Training [9/62] Loss: 0.08206 
Epoch [255/300] Training [10/62] Loss: 0.03638 
Epoch [255/300] Training [11/62] Loss: 0.05976 
Epoch [255/300] Training [12/62] Loss: 0.04475 
Epoch [255/300] Training [13/62] Loss: 0.05521 
Epoch [255/300] Training [14/62] Loss: 0.02046 
Epoch [255/300] Training [15/62] Loss: 0.02418 
Epoch [255/300] Training [16/62] Loss: 0.02608 
Epoch [255/300] Training [17/62] Loss: 0.03314 
Epoch [255/300] Training [18/62] Loss: 0.02799 
Epoch [255/300] Training [19/62] Loss: 0.02484 
Epoch [255/300] Training [20/62] Loss: 0.02129 
Epoch [255/300] Training [21/62] Loss: 0.03784 
Epoch [255/300] Training [22/62] Loss: 0.03286 
Epoch [255/300] Training [23/62] Loss: 0.02566 
Epoch [255/300] Training [24/62] Loss: 0.01998 
Epoch [255/300] Training [25/62] Loss: 0.06959 
Epoch [255/300] Training [26/62] Loss: 0.02788 
Epoch [255/300] Training [27/62] Loss: 0.03043 
Epoch [255/300] Training [28/62] Loss: 0.04110 
Epoch [255/300] Training [29/62] Loss: 0.02662 
Epoch [255/300] Training [30/62] Loss: 0.05790 
Epoch [255/300] Training [31/62] Loss: 0.09169 
Epoch [255/300] Training [32/62] Loss: 0.04050 
Epoch [255/300] Training [33/62] Loss: 0.03603 
Epoch [255/300] Training [34/62] Loss: 0.01894 
Epoch [255/300] Training [35/62] Loss: 0.02404 
Epoch [255/300] Training [36/62] Loss: 0.03450 
Epoch [255/300] Training [37/62] Loss: 0.02714 
Epoch [255/300] Training [38/62] Loss: 0.03118 
Epoch [255/300] Training [39/62] Loss: 0.02123 
Epoch [255/300] Training [40/62] Loss: 0.14487 
Epoch [255/300] Training [41/62] Loss: 0.02401 
Epoch [255/300] Training [42/62] Loss: 0.04309 
Epoch [255/300] Training [43/62] Loss: 0.03252 
Epoch [255/300] Training [44/62] Loss: 0.03010 
Epoch [255/300] Training [45/62] Loss: 0.03162 
Epoch [255/300] Training [46/62] Loss: 0.03529 
Epoch [255/300] Training [47/62] Loss: 0.05287 
Epoch [255/300] Training [48/62] Loss: 0.03056 
Epoch [255/300] Training [49/62] Loss: 0.02631 
Epoch [255/300] Training [50/62] Loss: 0.02465 
Epoch [255/300] Training [51/62] Loss: 0.02953 
Epoch [255/300] Training [52/62] Loss: 0.06470 
Epoch [255/300] Training [53/62] Loss: 0.05653 
Epoch [255/300] Training [54/62] Loss: 0.07323 
Epoch [255/300] Training [55/62] Loss: 0.02221 
Epoch [255/300] Training [56/62] Loss: 0.01959 
Epoch [255/300] Training [57/62] Loss: 0.06372 
Epoch [255/300] Training [58/62] Loss: 0.04727 
Epoch [255/300] Training [59/62] Loss: 0.02828 
Epoch [255/300] Training [60/62] Loss: 0.02042 
Epoch [255/300] Training [61/62] Loss: 0.05688 
Epoch [255/300] Training [62/62] Loss: 0.02602 
Epoch [255/300] Training metric {'Train/mean dice_metric': 0.973365306854248, 'Train/mean miou_metric': 0.9516651034355164, 'Train/mean f1': 0.9749455451965332, 'Train/mean precision': 0.9711525440216064, 'Train/mean recall': 0.9787683486938477, 'Train/mean hd95_metric': 5.5534844398498535}
Epoch [255/300] Validation [1/16] Loss: 0.72005  focal_loss 0.49699  dice_loss 0.22306 
Epoch [255/300] Validation [2/16] Loss: 0.59139  focal_loss 0.26036  dice_loss 0.33102 
Epoch [255/300] Validation [3/16] Loss: 0.66167  focal_loss 0.39197  dice_loss 0.26970 
Epoch [255/300] Validation [4/16] Loss: 0.29806  focal_loss 0.15489  dice_loss 0.14317 
Epoch [255/300] Validation [5/16] Loss: 0.39697  focal_loss 0.16221  dice_loss 0.23476 
Epoch [255/300] Validation [6/16] Loss: 0.27863  focal_loss 0.09085  dice_loss 0.18778 
Epoch [255/300] Validation [7/16] Loss: 0.31755  focal_loss 0.12533  dice_loss 0.19222 
Epoch [255/300] Validation [8/16] Loss: 0.48205  focal_loss 0.19624  dice_loss 0.28581 
Epoch [255/300] Validation [9/16] Loss: 0.21965  focal_loss 0.10160  dice_loss 0.11805 
Epoch [255/300] Validation [10/16] Loss: 0.57295  focal_loss 0.22296  dice_loss 0.34999 
Epoch [255/300] Validation [11/16] Loss: 0.16543  focal_loss 0.06428  dice_loss 0.10115 
Epoch [255/300] Validation [12/16] Loss: 0.51433  focal_loss 0.13908  dice_loss 0.37525 
Epoch [255/300] Validation [13/16] Loss: 0.28035  focal_loss 0.12175  dice_loss 0.15860 
Epoch [255/300] Validation [14/16] Loss: 0.58099  focal_loss 0.25579  dice_loss 0.32520 
Epoch [255/300] Validation [15/16] Loss: 0.10566  focal_loss 0.04070  dice_loss 0.06496 
Epoch [255/300] Validation [16/16] Loss: 0.09458  focal_loss 0.03347  dice_loss 0.06110 
Epoch [255/300] Validation metric {'Val/mean dice_metric': 0.9350507855415344, 'Val/mean miou_metric': 0.9010136127471924, 'Val/mean f1': 0.9464072585105896, 'Val/mean precision': 0.9542898535728455, 'Val/mean recall': 0.9386537671089172, 'Val/mean hd95_metric': 14.104609489440918}
Cheakpoint...
Epoch [255/300] best acc:tensor([0.9410], device='cuda:0'), Now : mean acc: tensor([0.9351], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9350507855415344, 'Val/mean miou_metric': 0.9010136127471924, 'Val/mean f1': 0.9464072585105896, 'Val/mean precision': 0.9542898535728455, 'Val/mean recall': 0.9386537671089172, 'Val/mean hd95_metric': 14.104609489440918}
Epoch [256/300] Training [1/62] Loss: 0.02335 
Epoch [256/300] Training [2/62] Loss: 0.02664 
Epoch [256/300] Training [3/62] Loss: 0.04773 
Epoch [256/300] Training [4/62] Loss: 0.02259 
Epoch [256/300] Training [5/62] Loss: 0.06827 
Epoch [256/300] Training [6/62] Loss: 0.03233 
Epoch [256/300] Training [7/62] Loss: 0.02578 
Epoch [256/300] Training [8/62] Loss: 0.03840 
Epoch [256/300] Training [9/62] Loss: 0.03529 
Epoch [256/300] Training [10/62] Loss: 0.03190 
Epoch [256/300] Training [11/62] Loss: 0.02059 
Epoch [256/300] Training [12/62] Loss: 0.01937 
Epoch [256/300] Training [13/62] Loss: 0.04020 
Epoch [256/300] Training [14/62] Loss: 0.02698 
Epoch [256/300] Training [15/62] Loss: 0.18031 
Epoch [256/300] Training [16/62] Loss: 0.03133 
Epoch [256/300] Training [17/62] Loss: 0.03125 
Epoch [256/300] Training [18/62] Loss: 0.02000 
Epoch [256/300] Training [19/62] Loss: 0.03385 
Epoch [256/300] Training [20/62] Loss: 0.03543 
Epoch [256/300] Training [21/62] Loss: 0.01949 
Epoch [256/300] Training [22/62] Loss: 0.02541 
Epoch [256/300] Training [23/62] Loss: 0.02458 
Epoch [256/300] Training [24/62] Loss: 0.04342 
Epoch [256/300] Training [25/62] Loss: 0.03346 
Epoch [256/300] Training [26/62] Loss: 0.02370 
Epoch [256/300] Training [27/62] Loss: 0.02881 
Epoch [256/300] Training [28/62] Loss: 0.04043 
Epoch [256/300] Training [29/62] Loss: 0.03686 
Epoch [256/300] Training [30/62] Loss: 0.02920 
Epoch [256/300] Training [31/62] Loss: 0.05834 
Epoch [256/300] Training [32/62] Loss: 0.03503 
Epoch [256/300] Training [33/62] Loss: 0.03585 
Epoch [256/300] Training [34/62] Loss: 0.16583 
Epoch [256/300] Training [35/62] Loss: 0.02880 
Epoch [256/300] Training [36/62] Loss: 0.02225 
Epoch [256/300] Training [37/62] Loss: 0.04110 
Epoch [256/300] Training [38/62] Loss: 0.04917 
Epoch [256/300] Training [39/62] Loss: 0.02633 
Epoch [256/300] Training [40/62] Loss: 0.03791 
Epoch [256/300] Training [41/62] Loss: 0.09904 
Epoch [256/300] Training [42/62] Loss: 0.08546 
Epoch [256/300] Training [43/62] Loss: 0.02978 
Epoch [256/300] Training [44/62] Loss: 0.03176 
Epoch [256/300] Training [45/62] Loss: 0.02338 
Epoch [256/300] Training [46/62] Loss: 0.02166 
Epoch [256/300] Training [47/62] Loss: 0.04611 
Epoch [256/300] Training [48/62] Loss: 0.06335 
Epoch [256/300] Training [49/62] Loss: 0.02970 
Epoch [256/300] Training [50/62] Loss: 0.02977 
Epoch [256/300] Training [51/62] Loss: 0.05235 
Epoch [256/300] Training [52/62] Loss: 0.02412 
Epoch [256/300] Training [53/62] Loss: 0.02983 
Epoch [256/300] Training [54/62] Loss: 0.02318 
Epoch [256/300] Training [55/62] Loss: 0.03321 
Epoch [256/300] Training [56/62] Loss: 0.02300 
Epoch [256/300] Training [57/62] Loss: 0.02285 
Epoch [256/300] Training [58/62] Loss: 0.05311 
Epoch [256/300] Training [59/62] Loss: 0.05296 
Epoch [256/300] Training [60/62] Loss: 0.02846 
Epoch [256/300] Training [61/62] Loss: 0.03403 
Epoch [256/300] Training [62/62] Loss: 0.44747 
Epoch [256/300] Training metric {'Train/mean dice_metric': 0.9720050692558289, 'Train/mean miou_metric': 0.9509820342063904, 'Train/mean f1': 0.9748697280883789, 'Train/mean precision': 0.9722282886505127, 'Train/mean recall': 0.9775254726409912, 'Train/mean hd95_metric': 4.994412422180176}
Epoch [256/300] Validation [1/16] Loss: 0.67184  focal_loss 0.47005  dice_loss 0.20179 
Epoch [256/300] Validation [2/16] Loss: 0.52616  focal_loss 0.24366  dice_loss 0.28250 
Epoch [256/300] Validation [3/16] Loss: 0.69236  focal_loss 0.40413  dice_loss 0.28823 
Epoch [256/300] Validation [4/16] Loss: 0.35285  focal_loss 0.17450  dice_loss 0.17835 
Epoch [256/300] Validation [5/16] Loss: 0.33569  focal_loss 0.13708  dice_loss 0.19860 
Epoch [256/300] Validation [6/16] Loss: 0.28747  focal_loss 0.09056  dice_loss 0.19691 
Epoch [256/300] Validation [7/16] Loss: 0.23370  focal_loss 0.11306  dice_loss 0.12063 
Epoch [256/300] Validation [8/16] Loss: 0.48097  focal_loss 0.18465  dice_loss 0.29632 
Epoch [256/300] Validation [9/16] Loss: 0.21225  focal_loss 0.09518  dice_loss 0.11706 
Epoch [256/300] Validation [10/16] Loss: 0.49699  focal_loss 0.18137  dice_loss 0.31562 
Epoch [256/300] Validation [11/16] Loss: 0.19090  focal_loss 0.08190  dice_loss 0.10900 
Epoch [256/300] Validation [12/16] Loss: 0.38884  focal_loss 0.11996  dice_loss 0.26888 
Epoch [256/300] Validation [13/16] Loss: 0.26156  focal_loss 0.10369  dice_loss 0.15786 
Epoch [256/300] Validation [14/16] Loss: 0.61137  focal_loss 0.24939  dice_loss 0.36198 
Epoch [256/300] Validation [15/16] Loss: 0.13885  focal_loss 0.06130  dice_loss 0.07755 
Epoch [256/300] Validation [16/16] Loss: 0.11024  focal_loss 0.04380  dice_loss 0.06645 
Epoch [256/300] Validation metric {'Val/mean dice_metric': 0.9363502860069275, 'Val/mean miou_metric': 0.9025413393974304, 'Val/mean f1': 0.9468848705291748, 'Val/mean precision': 0.9557543992996216, 'Val/mean recall': 0.9381784796714783, 'Val/mean hd95_metric': 14.313191413879395}
Cheakpoint...
Epoch [256/300] best acc:tensor([0.9410], device='cuda:0'), Now : mean acc: tensor([0.9364], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9363502860069275, 'Val/mean miou_metric': 0.9025413393974304, 'Val/mean f1': 0.9468848705291748, 'Val/mean precision': 0.9557543992996216, 'Val/mean recall': 0.9381784796714783, 'Val/mean hd95_metric': 14.313191413879395}
Epoch [257/300] Training [1/62] Loss: 0.02879 
Epoch [257/300] Training [2/62] Loss: 0.04268 
Epoch [257/300] Training [3/62] Loss: 0.05670 
Epoch [257/300] Training [4/62] Loss: 0.03376 
Epoch [257/300] Training [5/62] Loss: 0.04260 
Epoch [257/300] Training [6/62] Loss: 0.08621 
Epoch [257/300] Training [7/62] Loss: 0.03464 
Epoch [257/300] Training [8/62] Loss: 0.02742 
Epoch [257/300] Training [9/62] Loss: 0.02841 
Epoch [257/300] Training [10/62] Loss: 0.04899 
Epoch [257/300] Training [11/62] Loss: 0.03375 
Epoch [257/300] Training [12/62] Loss: 0.02809 
Epoch [257/300] Training [13/62] Loss: 0.06058 
Epoch [257/300] Training [14/62] Loss: 0.03408 
Epoch [257/300] Training [15/62] Loss: 0.03091 
Epoch [257/300] Training [16/62] Loss: 0.03005 
Epoch [257/300] Training [17/62] Loss: 0.03177 
Epoch [257/300] Training [18/62] Loss: 0.03090 
Epoch [257/300] Training [19/62] Loss: 0.03131 
Epoch [257/300] Training [20/62] Loss: 0.03727 
Epoch [257/300] Training [21/62] Loss: 0.04876 
Epoch [257/300] Training [22/62] Loss: 0.03473 
Epoch [257/300] Training [23/62] Loss: 0.04437 
Epoch [257/300] Training [24/62] Loss: 0.04885 
Epoch [257/300] Training [25/62] Loss: 0.03048 
Epoch [257/300] Training [26/62] Loss: 0.02639 
Epoch [257/300] Training [27/62] Loss: 0.02113 
Epoch [257/300] Training [28/62] Loss: 0.06659 
Epoch [257/300] Training [29/62] Loss: 0.14099 
Epoch [257/300] Training [30/62] Loss: 0.02721 
Epoch [257/300] Training [31/62] Loss: 0.03928 
Epoch [257/300] Training [32/62] Loss: 0.02621 
Epoch [257/300] Training [33/62] Loss: 0.02977 
Epoch [257/300] Training [34/62] Loss: 0.02535 
Epoch [257/300] Training [35/62] Loss: 0.02473 
Epoch [257/300] Training [36/62] Loss: 0.03344 
Epoch [257/300] Training [37/62] Loss: 0.04552 
Epoch [257/300] Training [38/62] Loss: 0.06196 
Epoch [257/300] Training [39/62] Loss: 0.03489 
Epoch [257/300] Training [40/62] Loss: 0.04903 
Epoch [257/300] Training [41/62] Loss: 0.02559 
Epoch [257/300] Training [42/62] Loss: 0.06905 
Epoch [257/300] Training [43/62] Loss: 0.05477 
Epoch [257/300] Training [44/62] Loss: 0.02276 
Epoch [257/300] Training [45/62] Loss: 0.04462 
Epoch [257/300] Training [46/62] Loss: 0.02927 
Epoch [257/300] Training [47/62] Loss: 0.01822 
Epoch [257/300] Training [48/62] Loss: 0.04734 
Epoch [257/300] Training [49/62] Loss: 0.02582 
Epoch [257/300] Training [50/62] Loss: 0.02133 
Epoch [257/300] Training [51/62] Loss: 0.03567 
Epoch [257/300] Training [52/62] Loss: 0.04020 
Epoch [257/300] Training [53/62] Loss: 0.02372 
Epoch [257/300] Training [54/62] Loss: 0.02151 
Epoch [257/300] Training [55/62] Loss: 0.04738 
Epoch [257/300] Training [56/62] Loss: 0.02518 
Epoch [257/300] Training [57/62] Loss: 0.02456 
Epoch [257/300] Training [58/62] Loss: 0.04105 
Epoch [257/300] Training [59/62] Loss: 0.02459 
Epoch [257/300] Training [60/62] Loss: 0.02132 
Epoch [257/300] Training [61/62] Loss: 0.03580 
Epoch [257/300] Training [62/62] Loss: 0.09268 
Epoch [257/300] Training metric {'Train/mean dice_metric': 0.9741818904876709, 'Train/mean miou_metric': 0.9520614743232727, 'Train/mean f1': 0.9743872284889221, 'Train/mean precision': 0.9693130850791931, 'Train/mean recall': 0.9795148372650146, 'Train/mean hd95_metric': 7.4633965492248535}
Epoch [257/300] Validation [1/16] Loss: 0.69283  focal_loss 0.48304  dice_loss 0.20978 
Epoch [257/300] Validation [2/16] Loss: 0.48470  focal_loss 0.21171  dice_loss 0.27299 
Epoch [257/300] Validation [3/16] Loss: 0.56149  focal_loss 0.31316  dice_loss 0.24832 
Epoch [257/300] Validation [4/16] Loss: 0.35602  focal_loss 0.17705  dice_loss 0.17897 
Epoch [257/300] Validation [5/16] Loss: 0.48729  focal_loss 0.16859  dice_loss 0.31870 
Epoch [257/300] Validation [6/16] Loss: 0.29185  focal_loss 0.09561  dice_loss 0.19625 
Epoch [257/300] Validation [7/16] Loss: 0.26498  focal_loss 0.10227  dice_loss 0.16272 
Epoch [257/300] Validation [8/16] Loss: 0.50658  focal_loss 0.20511  dice_loss 0.30147 
Epoch [257/300] Validation [9/16] Loss: 0.20557  focal_loss 0.09281  dice_loss 0.11276 
Epoch [257/300] Validation [10/16] Loss: 0.47067  focal_loss 0.15510  dice_loss 0.31556 
Epoch [257/300] Validation [11/16] Loss: 0.16779  focal_loss 0.06098  dice_loss 0.10681 
Epoch [257/300] Validation [12/16] Loss: 0.35750  focal_loss 0.10856  dice_loss 0.24894 
Epoch [257/300] Validation [13/16] Loss: 0.26439  focal_loss 0.10912  dice_loss 0.15527 
Epoch [257/300] Validation [14/16] Loss: 0.58860  focal_loss 0.28563  dice_loss 0.30297 
Epoch [257/300] Validation [15/16] Loss: 0.10606  focal_loss 0.04029  dice_loss 0.06577 
Epoch [257/300] Validation [16/16] Loss: 0.13443  focal_loss 0.06055  dice_loss 0.07388 
Epoch [257/300] Validation metric {'Val/mean dice_metric': 0.9376953840255737, 'Val/mean miou_metric': 0.9033384919166565, 'Val/mean f1': 0.9471328854560852, 'Val/mean precision': 0.9529132843017578, 'Val/mean recall': 0.9414222240447998, 'Val/mean hd95_metric': 16.64317512512207}
Cheakpoint...
Epoch [257/300] best acc:tensor([0.9410], device='cuda:0'), Now : mean acc: tensor([0.9377], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9376953840255737, 'Val/mean miou_metric': 0.9033384919166565, 'Val/mean f1': 0.9471328854560852, 'Val/mean precision': 0.9529132843017578, 'Val/mean recall': 0.9414222240447998, 'Val/mean hd95_metric': 16.64317512512207}
Epoch [258/300] Training [1/62] Loss: 0.02505 
Epoch [258/300] Training [2/62] Loss: 0.02154 
Epoch [258/300] Training [3/62] Loss: 0.05086 
Epoch [258/300] Training [4/62] Loss: 0.02860 
Epoch [258/300] Training [5/62] Loss: 0.02124 
Epoch [258/300] Training [6/62] Loss: 0.03934 
Epoch [258/300] Training [7/62] Loss: 0.02337 
Epoch [258/300] Training [8/62] Loss: 0.03111 
Epoch [258/300] Training [9/62] Loss: 0.03280 
Epoch [258/300] Training [10/62] Loss: 0.02618 
Epoch [258/300] Training [11/62] Loss: 0.02884 
Epoch [258/300] Training [12/62] Loss: 0.03385 
Epoch [258/300] Training [13/62] Loss: 0.03167 
Epoch [258/300] Training [14/62] Loss: 0.04962 
Epoch [258/300] Training [15/62] Loss: 0.03521 
Epoch [258/300] Training [16/62] Loss: 0.03013 
Epoch [258/300] Training [17/62] Loss: 0.04061 
Epoch [258/300] Training [18/62] Loss: 0.12131 
Epoch [258/300] Training [19/62] Loss: 0.07748 
Epoch [258/300] Training [20/62] Loss: 0.04026 
Epoch [258/300] Training [21/62] Loss: 0.03236 
Epoch [258/300] Training [22/62] Loss: 0.03498 
Epoch [258/300] Training [23/62] Loss: 0.02193 
Epoch [258/300] Training [24/62] Loss: 0.03136 
Epoch [258/300] Training [25/62] Loss: 0.06646 
Epoch [258/300] Training [26/62] Loss: 0.02750 
Epoch [258/300] Training [27/62] Loss: 0.01834 
Epoch [258/300] Training [28/62] Loss: 0.02625 
Epoch [258/300] Training [29/62] Loss: 0.04508 
Epoch [258/300] Training [30/62] Loss: 0.05505 
Epoch [258/300] Training [31/62] Loss: 0.04371 
Epoch [258/300] Training [32/62] Loss: 0.03383 
Epoch [258/300] Training [33/62] Loss: 0.02953 
Epoch [258/300] Training [34/62] Loss: 0.02765 
Epoch [258/300] Training [35/62] Loss: 0.02666 
Epoch [258/300] Training [36/62] Loss: 0.06103 
Epoch [258/300] Training [37/62] Loss: 0.03165 
Epoch [258/300] Training [38/62] Loss: 0.03506 
Epoch [258/300] Training [39/62] Loss: 0.03210 
Epoch [258/300] Training [40/62] Loss: 0.04117 
Epoch [258/300] Training [41/62] Loss: 0.04194 
Epoch [258/300] Training [42/62] Loss: 0.02585 
Epoch [258/300] Training [43/62] Loss: 0.03963 
Epoch [258/300] Training [44/62] Loss: 0.02920 
Epoch [258/300] Training [45/62] Loss: 0.02278 
Epoch [258/300] Training [46/62] Loss: 0.04520 
Epoch [258/300] Training [47/62] Loss: 0.04790 
Epoch [258/300] Training [48/62] Loss: 0.02025 
Epoch [258/300] Training [49/62] Loss: 0.06332 
Epoch [258/300] Training [50/62] Loss: 0.03046 
Epoch [258/300] Training [51/62] Loss: 0.02753 
Epoch [258/300] Training [52/62] Loss: 0.02937 
Epoch [258/300] Training [53/62] Loss: 0.02048 
Epoch [258/300] Training [54/62] Loss: 0.03182 
Epoch [258/300] Training [55/62] Loss: 0.02899 
Epoch [258/300] Training [56/62] Loss: 0.04223 
Epoch [258/300] Training [57/62] Loss: 0.02212 
Epoch [258/300] Training [58/62] Loss: 0.02834 
Epoch [258/300] Training [59/62] Loss: 0.02587 
Epoch [258/300] Training [60/62] Loss: 0.02711 
Epoch [258/300] Training [61/62] Loss: 0.03353 
Epoch [258/300] Training [62/62] Loss: 0.02340 
Epoch [258/300] Training metric {'Train/mean dice_metric': 0.976236879825592, 'Train/mean miou_metric': 0.9551705121994019, 'Train/mean f1': 0.975701630115509, 'Train/mean precision': 0.9720601439476013, 'Train/mean recall': 0.9793705344200134, 'Train/mean hd95_metric': 5.274967193603516}
Epoch [258/300] Validation [1/16] Loss: 0.67352  focal_loss 0.45815  dice_loss 0.21537 
Epoch [258/300] Validation [2/16] Loss: 0.55363  focal_loss 0.24595  dice_loss 0.30768 
Epoch [258/300] Validation [3/16] Loss: 0.74117  focal_loss 0.46738  dice_loss 0.27379 
Epoch [258/300] Validation [4/16] Loss: 0.28524  focal_loss 0.15508  dice_loss 0.13016 
Epoch [258/300] Validation [5/16] Loss: 0.34678  focal_loss 0.15616  dice_loss 0.19063 
Epoch [258/300] Validation [6/16] Loss: 0.30586  focal_loss 0.09995  dice_loss 0.20591 
Epoch [258/300] Validation [7/16] Loss: 0.31678  focal_loss 0.13240  dice_loss 0.18438 
Epoch [258/300] Validation [8/16] Loss: 0.50762  focal_loss 0.19857  dice_loss 0.30905 
Epoch [258/300] Validation [9/16] Loss: 0.28919  focal_loss 0.14736  dice_loss 0.14184 
Epoch [258/300] Validation [10/16] Loss: 0.51875  focal_loss 0.18379  dice_loss 0.33496 
Epoch [258/300] Validation [11/16] Loss: 0.17753  focal_loss 0.07133  dice_loss 0.10621 
Epoch [258/300] Validation [12/16] Loss: 0.41436  focal_loss 0.14475  dice_loss 0.26961 
Epoch [258/300] Validation [13/16] Loss: 0.24543  focal_loss 0.09322  dice_loss 0.15220 
Epoch [258/300] Validation [14/16] Loss: 0.53485  focal_loss 0.22912  dice_loss 0.30573 
Epoch [258/300] Validation [15/16] Loss: 0.18152  focal_loss 0.08183  dice_loss 0.09968 
Epoch [258/300] Validation [16/16] Loss: 0.12430  focal_loss 0.04229  dice_loss 0.08201 
Epoch [258/300] Validation metric {'Val/mean dice_metric': 0.9389491677284241, 'Val/mean miou_metric': 0.9044633507728577, 'Val/mean f1': 0.9461895823478699, 'Val/mean precision': 0.951241672039032, 'Val/mean recall': 0.9411909580230713, 'Val/mean hd95_metric': 14.328230857849121}
Cheakpoint...
Epoch [258/300] best acc:tensor([0.9410], device='cuda:0'), Now : mean acc: tensor([0.9389], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9389491677284241, 'Val/mean miou_metric': 0.9044633507728577, 'Val/mean f1': 0.9461895823478699, 'Val/mean precision': 0.951241672039032, 'Val/mean recall': 0.9411909580230713, 'Val/mean hd95_metric': 14.328230857849121}
Epoch [259/300] Training [1/62] Loss: 0.02291 
Epoch [259/300] Training [2/62] Loss: 0.02456 
Epoch [259/300] Training [3/62] Loss: 0.01916 
Epoch [259/300] Training [4/62] Loss: 0.03941 
Epoch [259/300] Training [5/62] Loss: 0.02875 
Epoch [259/300] Training [6/62] Loss: 0.02440 
Epoch [259/300] Training [7/62] Loss: 0.03305 
Epoch [259/300] Training [8/62] Loss: 0.03112 
Epoch [259/300] Training [9/62] Loss: 0.03825 
Epoch [259/300] Training [10/62] Loss: 0.04999 
Epoch [259/300] Training [11/62] Loss: 0.05309 
Epoch [259/300] Training [12/62] Loss: 0.02564 
Epoch [259/300] Training [13/62] Loss: 0.02396 
Epoch [259/300] Training [14/62] Loss: 0.04401 
Epoch [259/300] Training [15/62] Loss: 0.03412 
Epoch [259/300] Training [16/62] Loss: 0.08674 
Epoch [259/300] Training [17/62] Loss: 0.02097 
Epoch [259/300] Training [18/62] Loss: 0.03052 
Epoch [259/300] Training [19/62] Loss: 0.02788 
Epoch [259/300] Training [20/62] Loss: 0.03222 
Epoch [259/300] Training [21/62] Loss: 0.02268 
Epoch [259/300] Training [22/62] Loss: 0.04211 
Epoch [259/300] Training [23/62] Loss: 0.03901 
Epoch [259/300] Training [24/62] Loss: 0.02595 
Epoch [259/300] Training [25/62] Loss: 0.02372 
Epoch [259/300] Training [26/62] Loss: 0.02398 
Epoch [259/300] Training [27/62] Loss: 0.06562 
Epoch [259/300] Training [28/62] Loss: 0.02724 
Epoch [259/300] Training [29/62] Loss: 0.06117 
Epoch [259/300] Training [30/62] Loss: 0.15578 
Epoch [259/300] Training [31/62] Loss: 0.03038 
Epoch [259/300] Training [32/62] Loss: 0.04042 
Epoch [259/300] Training [33/62] Loss: 0.02888 
Epoch [259/300] Training [34/62] Loss: 0.04079 
Epoch [259/300] Training [35/62] Loss: 0.02673 
Epoch [259/300] Training [36/62] Loss: 0.01875 
Epoch [259/300] Training [37/62] Loss: 0.02849 
Epoch [259/300] Training [38/62] Loss: 0.03887 
Epoch [259/300] Training [39/62] Loss: 0.04099 
Epoch [259/300] Training [40/62] Loss: 0.02900 
Epoch [259/300] Training [41/62] Loss: 0.01742 
Epoch [259/300] Training [42/62] Loss: 0.02217 
Epoch [259/300] Training [43/62] Loss: 0.04798 
Epoch [259/300] Training [44/62] Loss: 0.02393 
Epoch [259/300] Training [45/62] Loss: 0.03970 
Epoch [259/300] Training [46/62] Loss: 0.02746 
Epoch [259/300] Training [47/62] Loss: 0.03213 
Epoch [259/300] Training [48/62] Loss: 0.03315 
Epoch [259/300] Training [49/62] Loss: 0.02483 
Epoch [259/300] Training [50/62] Loss: 0.02544 
Epoch [259/300] Training [51/62] Loss: 0.02699 
Epoch [259/300] Training [52/62] Loss: 0.03969 
Epoch [259/300] Training [53/62] Loss: 0.03783 
Epoch [259/300] Training [54/62] Loss: 0.05288 
Epoch [259/300] Training [55/62] Loss: 0.02363 
Epoch [259/300] Training [56/62] Loss: 0.04113 
Epoch [259/300] Training [57/62] Loss: 0.02211 
Epoch [259/300] Training [58/62] Loss: 0.02325 
Epoch [259/300] Training [59/62] Loss: 0.03197 
Epoch [259/300] Training [60/62] Loss: 0.02699 
Epoch [259/300] Training [61/62] Loss: 0.02462 
Epoch [259/300] Training [62/62] Loss: 0.07544 
Epoch [259/300] Training metric {'Train/mean dice_metric': 0.9769224524497986, 'Train/mean miou_metric': 0.9566270709037781, 'Train/mean f1': 0.9758350849151611, 'Train/mean precision': 0.9722872376441956, 'Train/mean recall': 0.9794089794158936, 'Train/mean hd95_metric': 4.706632137298584}
Epoch [259/300] Validation [1/16] Loss: 0.64291  focal_loss 0.44571  dice_loss 0.19720 
Epoch [259/300] Validation [2/16] Loss: 0.46506  focal_loss 0.20234  dice_loss 0.26272 
Epoch [259/300] Validation [3/16] Loss: 0.73690  focal_loss 0.46496  dice_loss 0.27194 
Epoch [259/300] Validation [4/16] Loss: 0.36266  focal_loss 0.19267  dice_loss 0.16998 
Epoch [259/300] Validation [5/16] Loss: 0.34056  focal_loss 0.14061  dice_loss 0.19995 
Epoch [259/300] Validation [6/16] Loss: 0.27996  focal_loss 0.09145  dice_loss 0.18852 
Epoch [259/300] Validation [7/16] Loss: 0.20328  focal_loss 0.09687  dice_loss 0.10641 
Epoch [259/300] Validation [8/16] Loss: 0.55149  focal_loss 0.23120  dice_loss 0.32029 
Epoch [259/300] Validation [9/16] Loss: 0.20276  focal_loss 0.09419  dice_loss 0.10857 
Epoch [259/300] Validation [10/16] Loss: 0.57183  focal_loss 0.20083  dice_loss 0.37100 
Epoch [259/300] Validation [11/16] Loss: 0.17016  focal_loss 0.06812  dice_loss 0.10204 
Epoch [259/300] Validation [12/16] Loss: 0.40282  focal_loss 0.13730  dice_loss 0.26553 
Epoch [259/300] Validation [13/16] Loss: 0.22824  focal_loss 0.08479  dice_loss 0.14345 
Epoch [259/300] Validation [14/16] Loss: 0.61660  focal_loss 0.26092  dice_loss 0.35568 
Epoch [259/300] Validation [15/16] Loss: 0.12711  focal_loss 0.05089  dice_loss 0.07622 
Epoch [259/300] Validation [16/16] Loss: 0.10823  focal_loss 0.03918  dice_loss 0.06905 
Epoch [259/300] Validation metric {'Val/mean dice_metric': 0.9407484531402588, 'Val/mean miou_metric': 0.9082130789756775, 'Val/mean f1': 0.9482077360153198, 'Val/mean precision': 0.955238401889801, 'Val/mean recall': 0.9412797689437866, 'Val/mean hd95_metric': 13.370798110961914}
Cheakpoint...
Epoch [259/300] best acc:tensor([0.9410], device='cuda:0'), Now : mean acc: tensor([0.9407], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9407484531402588, 'Val/mean miou_metric': 0.9082130789756775, 'Val/mean f1': 0.9482077360153198, 'Val/mean precision': 0.955238401889801, 'Val/mean recall': 0.9412797689437866, 'Val/mean hd95_metric': 13.370798110961914}
Epoch [260/300] Training [1/62] Loss: 0.03645 
Epoch [260/300] Training [2/62] Loss: 0.02187 
Epoch [260/300] Training [3/62] Loss: 0.07762 
Epoch [260/300] Training [4/62] Loss: 0.02913 
Epoch [260/300] Training [5/62] Loss: 0.03917 
Epoch [260/300] Training [6/62] Loss: 0.03473 
Epoch [260/300] Training [7/62] Loss: 0.02991 
Epoch [260/300] Training [8/62] Loss: 0.02185 
Epoch [260/300] Training [9/62] Loss: 0.02739 
Epoch [260/300] Training [10/62] Loss: 0.04267 
Epoch [260/300] Training [11/62] Loss: 0.04851 
Epoch [260/300] Training [12/62] Loss: 0.02101 
Epoch [260/300] Training [13/62] Loss: 0.03360 
Epoch [260/300] Training [14/62] Loss: 0.02981 
Epoch [260/300] Training [15/62] Loss: 0.02590 
Epoch [260/300] Training [16/62] Loss: 0.03133 
Epoch [260/300] Training [17/62] Loss: 0.05785 
Epoch [260/300] Training [18/62] Loss: 0.02158 
Epoch [260/300] Training [19/62] Loss: 0.04763 
Epoch [260/300] Training [20/62] Loss: 0.02489 
Epoch [260/300] Training [21/62] Loss: 0.04739 
Epoch [260/300] Training [22/62] Loss: 0.02352 
Epoch [260/300] Training [23/62] Loss: 0.02555 
Epoch [260/300] Training [24/62] Loss: 0.02783 
Epoch [260/300] Training [25/62] Loss: 0.02630 
Epoch [260/300] Training [26/62] Loss: 0.02907 
Epoch [260/300] Training [27/62] Loss: 0.02789 
Epoch [260/300] Training [28/62] Loss: 0.03728 
Epoch [260/300] Training [29/62] Loss: 0.04416 
Epoch [260/300] Training [30/62] Loss: 0.02249 
Epoch [260/300] Training [31/62] Loss: 0.05279 
Epoch [260/300] Training [32/62] Loss: 0.02920 
Epoch [260/300] Training [33/62] Loss: 0.02904 
Epoch [260/300] Training [34/62] Loss: 0.01958 
Epoch [260/300] Training [35/62] Loss: 0.04844 
Epoch [260/300] Training [36/62] Loss: 0.03519 
Epoch [260/300] Training [37/62] Loss: 0.02797 
Epoch [260/300] Training [38/62] Loss: 0.02332 
Epoch [260/300] Training [39/62] Loss: 0.03986 
Epoch [260/300] Training [40/62] Loss: 0.02663 
Epoch [260/300] Training [41/62] Loss: 0.02529 
Epoch [260/300] Training [42/62] Loss: 0.03529 
Epoch [260/300] Training [43/62] Loss: 0.03245 
Epoch [260/300] Training [44/62] Loss: 0.02620 
Epoch [260/300] Training [45/62] Loss: 0.05231 
Epoch [260/300] Training [46/62] Loss: 0.03539 
Epoch [260/300] Training [47/62] Loss: 0.03111 
Epoch [260/300] Training [48/62] Loss: 0.02649 
Epoch [260/300] Training [49/62] Loss: 0.02471 
Epoch [260/300] Training [50/62] Loss: 0.02432 
Epoch [260/300] Training [51/62] Loss: 0.02125 
Epoch [260/300] Training [52/62] Loss: 0.06564 
Epoch [260/300] Training [53/62] Loss: 0.02503 
Epoch [260/300] Training [54/62] Loss: 0.02388 
Epoch [260/300] Training [55/62] Loss: 0.03457 
Epoch [260/300] Training [56/62] Loss: 0.06101 
Epoch [260/300] Training [57/62] Loss: 0.01991 
Epoch [260/300] Training [58/62] Loss: 0.02381 
Epoch [260/300] Training [59/62] Loss: 0.04141 
Epoch [260/300] Training [60/62] Loss: 0.04222 
Epoch [260/300] Training [61/62] Loss: 0.02574 
Epoch [260/300] Training [62/62] Loss: 0.02360 
Epoch [260/300] Training metric {'Train/mean dice_metric': 0.9779722094535828, 'Train/mean miou_metric': 0.9578284621238708, 'Train/mean f1': 0.9760131239891052, 'Train/mean precision': 0.9720697999000549, 'Train/mean recall': 0.9799884557723999, 'Train/mean hd95_metric': 5.107010364532471}
Epoch [260/300] Validation [1/16] Loss: 0.70826  focal_loss 0.48367  dice_loss 0.22459 
Epoch [260/300] Validation [2/16] Loss: 0.48248  focal_loss 0.21343  dice_loss 0.26906 
Epoch [260/300] Validation [3/16] Loss: 0.75220  focal_loss 0.45340  dice_loss 0.29880 
Epoch [260/300] Validation [4/16] Loss: 0.32025  focal_loss 0.16923  dice_loss 0.15102 
Epoch [260/300] Validation [5/16] Loss: 0.43226  focal_loss 0.14703  dice_loss 0.28523 
Epoch [260/300] Validation [6/16] Loss: 0.27442  focal_loss 0.09096  dice_loss 0.18345 
Epoch [260/300] Validation [7/16] Loss: 0.18201  focal_loss 0.08431  dice_loss 0.09770 
Epoch [260/300] Validation [8/16] Loss: 0.47027  focal_loss 0.19840  dice_loss 0.27187 
Epoch [260/300] Validation [9/16] Loss: 0.19342  focal_loss 0.08632  dice_loss 0.10710 
Epoch [260/300] Validation [10/16] Loss: 0.53379  focal_loss 0.20397  dice_loss 0.32982 
Epoch [260/300] Validation [11/16] Loss: 0.14757  focal_loss 0.05679  dice_loss 0.09079 
Epoch [260/300] Validation [12/16] Loss: 0.37390  focal_loss 0.11254  dice_loss 0.26136 
Epoch [260/300] Validation [13/16] Loss: 0.24305  focal_loss 0.09178  dice_loss 0.15127 
Epoch [260/300] Validation [14/16] Loss: 0.46891  focal_loss 0.19279  dice_loss 0.27612 
Epoch [260/300] Validation [15/16] Loss: 0.10696  focal_loss 0.03962  dice_loss 0.06734 
Epoch [260/300] Validation [16/16] Loss: 0.08604  focal_loss 0.02932  dice_loss 0.05672 
Epoch [260/300] Validation metric {'Val/mean dice_metric': 0.9426029920578003, 'Val/mean miou_metric': 0.9098414182662964, 'Val/mean f1': 0.9485563039779663, 'Val/mean precision': 0.9535772204399109, 'Val/mean recall': 0.9435880780220032, 'Val/mean hd95_metric': 14.152426719665527}
Cheakpoint...
Epoch [260/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9426], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9426029920578003, 'Val/mean miou_metric': 0.9098414182662964, 'Val/mean f1': 0.9485563039779663, 'Val/mean precision': 0.9535772204399109, 'Val/mean recall': 0.9435880780220032, 'Val/mean hd95_metric': 14.152426719665527}
Epoch [261/300] Training [1/62] Loss: 0.02893 
Epoch [261/300] Training [2/62] Loss: 0.04961 
Epoch [261/300] Training [3/62] Loss: 0.03706 
Epoch [261/300] Training [4/62] Loss: 0.03209 
Epoch [261/300] Training [5/62] Loss: 0.03225 
Epoch [261/300] Training [6/62] Loss: 0.02996 
Epoch [261/300] Training [7/62] Loss: 0.02399 
Epoch [261/300] Training [8/62] Loss: 0.02999 
Epoch [261/300] Training [9/62] Loss: 0.04384 
Epoch [261/300] Training [10/62] Loss: 0.16595 
Epoch [261/300] Training [11/62] Loss: 0.02741 
Epoch [261/300] Training [12/62] Loss: 0.06718 
Epoch [261/300] Training [13/62] Loss: 0.02746 
Epoch [261/300] Training [14/62] Loss: 0.02890 
Epoch [261/300] Training [15/62] Loss: 0.02840 
Epoch [261/300] Training [16/62] Loss: 0.02699 
Epoch [261/300] Training [17/62] Loss: 0.02822 
Epoch [261/300] Training [18/62] Loss: 0.02875 
Epoch [261/300] Training [19/62] Loss: 0.02135 
Epoch [261/300] Training [20/62] Loss: 0.02762 
Epoch [261/300] Training [21/62] Loss: 0.03052 
Epoch [261/300] Training [22/62] Loss: 0.05380 
Epoch [261/300] Training [23/62] Loss: 0.02416 
Epoch [261/300] Training [24/62] Loss: 0.01911 
Epoch [261/300] Training [25/62] Loss: 0.02593 
Epoch [261/300] Training [26/62] Loss: 0.03478 
Epoch [261/300] Training [27/62] Loss: 0.02138 
Epoch [261/300] Training [28/62] Loss: 0.03103 
Epoch [261/300] Training [29/62] Loss: 0.02578 
Epoch [261/300] Training [30/62] Loss: 0.02186 
Epoch [261/300] Training [31/62] Loss: 0.04859 
Epoch [261/300] Training [32/62] Loss: 0.02750 
Epoch [261/300] Training [33/62] Loss: 0.02715 
Epoch [261/300] Training [34/62] Loss: 0.03280 
Epoch [261/300] Training [35/62] Loss: 0.03894 
Epoch [261/300] Training [36/62] Loss: 0.02774 
Epoch [261/300] Training [37/62] Loss: 0.03554 
Epoch [261/300] Training [38/62] Loss: 0.07624 
Epoch [261/300] Training [39/62] Loss: 0.02759 
Epoch [261/300] Training [40/62] Loss: 0.02410 
Epoch [261/300] Training [41/62] Loss: 0.02522 
Epoch [261/300] Training [42/62] Loss: 0.04103 
Epoch [261/300] Training [43/62] Loss: 0.02715 
Epoch [261/300] Training [44/62] Loss: 0.03698 
Epoch [261/300] Training [45/62] Loss: 0.02572 
Epoch [261/300] Training [46/62] Loss: 0.02581 
Epoch [261/300] Training [47/62] Loss: 0.02062 
Epoch [261/300] Training [48/62] Loss: 0.02418 
Epoch [261/300] Training [49/62] Loss: 0.04101 
Epoch [261/300] Training [50/62] Loss: 0.03177 
Epoch [261/300] Training [51/62] Loss: 0.07962 
Epoch [261/300] Training [52/62] Loss: 0.04224 
Epoch [261/300] Training [53/62] Loss: 0.02636 
Epoch [261/300] Training [54/62] Loss: 0.02833 
Epoch [261/300] Training [55/62] Loss: 0.11160 
Epoch [261/300] Training [56/62] Loss: 0.02445 
Epoch [261/300] Training [57/62] Loss: 0.02142 
Epoch [261/300] Training [58/62] Loss: 0.04309 
Epoch [261/300] Training [59/62] Loss: 0.06037 
Epoch [261/300] Training [60/62] Loss: 0.03120 
Epoch [261/300] Training [61/62] Loss: 0.02401 
Epoch [261/300] Training [62/62] Loss: 0.03401 
Epoch [261/300] Training metric {'Train/mean dice_metric': 0.9758004546165466, 'Train/mean miou_metric': 0.9556844830513, 'Train/mean f1': 0.9752194285392761, 'Train/mean precision': 0.9724761843681335, 'Train/mean recall': 0.9779780507087708, 'Train/mean hd95_metric': 5.2037200927734375}
Epoch [261/300] Validation [1/16] Loss: 0.75474  focal_loss 0.51387  dice_loss 0.24086 
Epoch [261/300] Validation [2/16] Loss: 0.48416  focal_loss 0.21318  dice_loss 0.27098 
Epoch [261/300] Validation [3/16] Loss: 0.64548  focal_loss 0.39072  dice_loss 0.25476 
Epoch [261/300] Validation [4/16] Loss: 0.31402  focal_loss 0.16697  dice_loss 0.14704 
Epoch [261/300] Validation [5/16] Loss: 0.33455  focal_loss 0.13440  dice_loss 0.20014 
Epoch [261/300] Validation [6/16] Loss: 0.31504  focal_loss 0.11128  dice_loss 0.20376 
Epoch [261/300] Validation [7/16] Loss: 0.27308  focal_loss 0.11543  dice_loss 0.15765 
Epoch [261/300] Validation [8/16] Loss: 0.52950  focal_loss 0.21167  dice_loss 0.31783 
Epoch [261/300] Validation [9/16] Loss: 0.27107  focal_loss 0.13255  dice_loss 0.13852 
Epoch [261/300] Validation [10/16] Loss: 0.56810  focal_loss 0.20202  dice_loss 0.36608 
Epoch [261/300] Validation [11/16] Loss: 0.16716  focal_loss 0.06184  dice_loss 0.10532 
Epoch [261/300] Validation [12/16] Loss: 0.48973  focal_loss 0.12787  dice_loss 0.36186 
Epoch [261/300] Validation [13/16] Loss: 0.22057  focal_loss 0.08092  dice_loss 0.13965 
Epoch [261/300] Validation [14/16] Loss: 0.59939  focal_loss 0.28773  dice_loss 0.31165 
Epoch [261/300] Validation [15/16] Loss: 0.11677  focal_loss 0.04903  dice_loss 0.06774 
Epoch [261/300] Validation [16/16] Loss: 0.10755  focal_loss 0.03819  dice_loss 0.06936 
Epoch [261/300] Validation metric {'Val/mean dice_metric': 0.9378367066383362, 'Val/mean miou_metric': 0.9046757221221924, 'Val/mean f1': 0.946670651435852, 'Val/mean precision': 0.9543167948722839, 'Val/mean recall': 0.939146101474762, 'Val/mean hd95_metric': 13.75622272491455}
Cheakpoint...
Epoch [261/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9378], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9378367066383362, 'Val/mean miou_metric': 0.9046757221221924, 'Val/mean f1': 0.946670651435852, 'Val/mean precision': 0.9543167948722839, 'Val/mean recall': 0.939146101474762, 'Val/mean hd95_metric': 13.75622272491455}
Epoch [262/300] Training [1/62] Loss: 0.01795 
Epoch [262/300] Training [2/62] Loss: 0.01981 
Epoch [262/300] Training [3/62] Loss: 0.03989 
Epoch [262/300] Training [4/62] Loss: 0.02052 
Epoch [262/300] Training [5/62] Loss: 0.03750 
Epoch [262/300] Training [6/62] Loss: 0.02366 
Epoch [262/300] Training [7/62] Loss: 0.03337 
Epoch [262/300] Training [8/62] Loss: 0.03596 
Epoch [262/300] Training [9/62] Loss: 0.02627 
Epoch [262/300] Training [10/62] Loss: 0.04799 
Epoch [262/300] Training [11/62] Loss: 0.02689 
Epoch [262/300] Training [12/62] Loss: 0.02796 
Epoch [262/300] Training [13/62] Loss: 0.02378 
Epoch [262/300] Training [14/62] Loss: 0.02936 
Epoch [262/300] Training [15/62] Loss: 0.02689 
Epoch [262/300] Training [16/62] Loss: 0.03115 
Epoch [262/300] Training [17/62] Loss: 0.02946 
Epoch [262/300] Training [18/62] Loss: 0.02966 
Epoch [262/300] Training [19/62] Loss: 0.02893 
Epoch [262/300] Training [20/62] Loss: 0.02495 
Epoch [262/300] Training [21/62] Loss: 0.03998 
Epoch [262/300] Training [22/62] Loss: 0.02021 
Epoch [262/300] Training [23/62] Loss: 0.07053 
Epoch [262/300] Training [24/62] Loss: 0.04099 
Epoch [262/300] Training [25/62] Loss: 0.03119 
Epoch [262/300] Training [26/62] Loss: 0.02938 
Epoch [262/300] Training [27/62] Loss: 0.05521 
Epoch [262/300] Training [28/62] Loss: 0.02055 
Epoch [262/300] Training [29/62] Loss: 0.04089 
Epoch [262/300] Training [30/62] Loss: 0.03596 
Epoch [262/300] Training [31/62] Loss: 0.02410 
Epoch [262/300] Training [32/62] Loss: 0.02773 
Epoch [262/300] Training [33/62] Loss: 0.02209 
Epoch [262/300] Training [34/62] Loss: 0.02998 
Epoch [262/300] Training [35/62] Loss: 0.02114 
Epoch [262/300] Training [36/62] Loss: 0.05485 
Epoch [262/300] Training [37/62] Loss: 0.02506 
Epoch [262/300] Training [38/62] Loss: 0.04618 
Epoch [262/300] Training [39/62] Loss: 0.03544 
Epoch [262/300] Training [40/62] Loss: 0.02506 
Epoch [262/300] Training [41/62] Loss: 0.02665 
Epoch [262/300] Training [42/62] Loss: 0.02096 
Epoch [262/300] Training [43/62] Loss: 0.02401 
Epoch [262/300] Training [44/62] Loss: 0.02784 
Epoch [262/300] Training [45/62] Loss: 0.02263 
Epoch [262/300] Training [46/62] Loss: 0.07134 
Epoch [262/300] Training [47/62] Loss: 0.03926 
Epoch [262/300] Training [48/62] Loss: 0.02683 
Epoch [262/300] Training [49/62] Loss: 0.02320 
Epoch [262/300] Training [50/62] Loss: 0.02479 
Epoch [262/300] Training [51/62] Loss: 0.06008 
Epoch [262/300] Training [52/62] Loss: 0.04295 
Epoch [262/300] Training [53/62] Loss: 0.18243 
Epoch [262/300] Training [54/62] Loss: 0.02496 
Epoch [262/300] Training [55/62] Loss: 0.05348 
Epoch [262/300] Training [56/62] Loss: 0.02438 
Epoch [262/300] Training [57/62] Loss: 0.06638 
Epoch [262/300] Training [58/62] Loss: 0.02985 
Epoch [262/300] Training [59/62] Loss: 0.02879 
Epoch [262/300] Training [60/62] Loss: 0.02436 
Epoch [262/300] Training [61/62] Loss: 0.03024 
Epoch [262/300] Training [62/62] Loss: 0.11511 
Epoch [262/300] Training metric {'Train/mean dice_metric': 0.9761844277381897, 'Train/mean miou_metric': 0.956157386302948, 'Train/mean f1': 0.976299524307251, 'Train/mean precision': 0.9727903008460999, 'Train/mean recall': 0.9798341393470764, 'Train/mean hd95_metric': 5.306983947753906}
Epoch [262/300] Validation [1/16] Loss: 0.79075  focal_loss 0.54411  dice_loss 0.24665 
Epoch [262/300] Validation [2/16] Loss: 0.50635  focal_loss 0.22336  dice_loss 0.28299 
Epoch [262/300] Validation [3/16] Loss: 0.67615  focal_loss 0.39485  dice_loss 0.28130 
Epoch [262/300] Validation [4/16] Loss: 0.35410  focal_loss 0.18688  dice_loss 0.16722 
Epoch [262/300] Validation [5/16] Loss: 0.45377  focal_loss 0.15777  dice_loss 0.29601 
Epoch [262/300] Validation [6/16] Loss: 0.34140  focal_loss 0.12399  dice_loss 0.21741 
Epoch [262/300] Validation [7/16] Loss: 0.27997  focal_loss 0.12025  dice_loss 0.15971 
Epoch [262/300] Validation [8/16] Loss: 0.54922  focal_loss 0.23021  dice_loss 0.31900 
Epoch [262/300] Validation [9/16] Loss: 0.26931  focal_loss 0.12373  dice_loss 0.14557 
Epoch [262/300] Validation [10/16] Loss: 0.52720  focal_loss 0.18035  dice_loss 0.34686 
Epoch [262/300] Validation [11/16] Loss: 0.22222  focal_loss 0.09496  dice_loss 0.12726 
Epoch [262/300] Validation [12/16] Loss: 0.51421  focal_loss 0.13799  dice_loss 0.37622 
Epoch [262/300] Validation [13/16] Loss: 0.29430  focal_loss 0.11591  dice_loss 0.17839 
Epoch [262/300] Validation [14/16] Loss: 0.55264  focal_loss 0.25661  dice_loss 0.29603 
Epoch [262/300] Validation [15/16] Loss: 0.13074  focal_loss 0.05932  dice_loss 0.07142 
Epoch [262/300] Validation [16/16] Loss: 0.10973  focal_loss 0.04167  dice_loss 0.06806 
Epoch [262/300] Validation metric {'Val/mean dice_metric': 0.935154139995575, 'Val/mean miou_metric': 0.9017646908760071, 'Val/mean f1': 0.9454517364501953, 'Val/mean precision': 0.9534921050071716, 'Val/mean recall': 0.9375458359718323, 'Val/mean hd95_metric': 14.84873104095459}
Cheakpoint...
Epoch [262/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9352], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.935154139995575, 'Val/mean miou_metric': 0.9017646908760071, 'Val/mean f1': 0.9454517364501953, 'Val/mean precision': 0.9534921050071716, 'Val/mean recall': 0.9375458359718323, 'Val/mean hd95_metric': 14.84873104095459}
Epoch [263/300] Training [1/62] Loss: 0.05922 
Epoch [263/300] Training [2/62] Loss: 0.01987 
Epoch [263/300] Training [3/62] Loss: 0.06711 
Epoch [263/300] Training [4/62] Loss: 0.03106 
Epoch [263/300] Training [5/62] Loss: 0.16925 
Epoch [263/300] Training [6/62] Loss: 0.02210 
Epoch [263/300] Training [7/62] Loss: 0.01953 
Epoch [263/300] Training [8/62] Loss: 0.03827 
Epoch [263/300] Training [9/62] Loss: 0.02342 
Epoch [263/300] Training [10/62] Loss: 0.02515 
Epoch [263/300] Training [11/62] Loss: 0.02660 
Epoch [263/300] Training [12/62] Loss: 0.10347 
Epoch [263/300] Training [13/62] Loss: 0.04859 
Epoch [263/300] Training [14/62] Loss: 0.01996 
Epoch [263/300] Training [15/62] Loss: 0.03950 
Epoch [263/300] Training [16/62] Loss: 0.03939 
Epoch [263/300] Training [17/62] Loss: 0.02989 
Epoch [263/300] Training [18/62] Loss: 0.04083 
Epoch [263/300] Training [19/62] Loss: 0.05044 
Epoch [263/300] Training [20/62] Loss: 0.02854 
Epoch [263/300] Training [21/62] Loss: 0.07790 
Epoch [263/300] Training [22/62] Loss: 0.03448 
Epoch [263/300] Training [23/62] Loss: 0.02572 
Epoch [263/300] Training [24/62] Loss: 0.02682 
Epoch [263/300] Training [25/62] Loss: 0.03587 
Epoch [263/300] Training [26/62] Loss: 0.02387 
Epoch [263/300] Training [27/62] Loss: 0.03106 
Epoch [263/300] Training [28/62] Loss: 0.02733 
Epoch [263/300] Training [29/62] Loss: 0.03050 
Epoch [263/300] Training [30/62] Loss: 0.03312 
Epoch [263/300] Training [31/62] Loss: 0.04069 
Epoch [263/300] Training [32/62] Loss: 0.03032 
Epoch [263/300] Training [33/62] Loss: 0.02568 
Epoch [263/300] Training [34/62] Loss: 0.03949 
Epoch [263/300] Training [35/62] Loss: 0.02552 
Epoch [263/300] Training [36/62] Loss: 0.02881 
Epoch [263/300] Training [37/62] Loss: 0.10222 
Epoch [263/300] Training [38/62] Loss: 0.06817 
Epoch [263/300] Training [39/62] Loss: 0.02862 
Epoch [263/300] Training [40/62] Loss: 0.02618 
Epoch [263/300] Training [41/62] Loss: 0.06515 
Epoch [263/300] Training [42/62] Loss: 0.02446 
Epoch [263/300] Training [43/62] Loss: 0.03047 
Epoch [263/300] Training [44/62] Loss: 0.05158 
Epoch [263/300] Training [45/62] Loss: 0.04099 
Epoch [263/300] Training [46/62] Loss: 0.02774 
Epoch [263/300] Training [47/62] Loss: 0.02347 
Epoch [263/300] Training [48/62] Loss: 0.02937 
Epoch [263/300] Training [49/62] Loss: 0.03620 
Epoch [263/300] Training [50/62] Loss: 0.01787 
Epoch [263/300] Training [51/62] Loss: 0.02873 
Epoch [263/300] Training [52/62] Loss: 0.02838 
Epoch [263/300] Training [53/62] Loss: 0.02715 
Epoch [263/300] Training [54/62] Loss: 0.04388 
Epoch [263/300] Training [55/62] Loss: 0.02339 
Epoch [263/300] Training [56/62] Loss: 0.03000 
Epoch [263/300] Training [57/62] Loss: 0.04076 
Epoch [263/300] Training [58/62] Loss: 0.04599 
Epoch [263/300] Training [59/62] Loss: 0.03255 
Epoch [263/300] Training [60/62] Loss: 0.02048 
Epoch [263/300] Training [61/62] Loss: 0.08726 
Epoch [263/300] Training [62/62] Loss: 0.01854 
Epoch [263/300] Training metric {'Train/mean dice_metric': 0.9730959534645081, 'Train/mean miou_metric': 0.9511972069740295, 'Train/mean f1': 0.9750605225563049, 'Train/mean precision': 0.9711270332336426, 'Train/mean recall': 0.9790259003639221, 'Train/mean hd95_metric': 6.511103630065918}
Epoch [263/300] Validation [1/16] Loss: 0.68804  focal_loss 0.46573  dice_loss 0.22231 
Epoch [263/300] Validation [2/16] Loss: 0.46479  focal_loss 0.20687  dice_loss 0.25792 
Epoch [263/300] Validation [3/16] Loss: 0.71885  focal_loss 0.43462  dice_loss 0.28423 
Epoch [263/300] Validation [4/16] Loss: 0.37656  focal_loss 0.18626  dice_loss 0.19030 
Epoch [263/300] Validation [5/16] Loss: 0.33026  focal_loss 0.13584  dice_loss 0.19442 
Epoch [263/300] Validation [6/16] Loss: 0.35829  focal_loss 0.12587  dice_loss 0.23242 
Epoch [263/300] Validation [7/16] Loss: 0.27232  focal_loss 0.11207  dice_loss 0.16026 
Epoch [263/300] Validation [8/16] Loss: 0.53687  focal_loss 0.21282  dice_loss 0.32404 
Epoch [263/300] Validation [9/16] Loss: 0.25769  focal_loss 0.12471  dice_loss 0.13298 
Epoch [263/300] Validation [10/16] Loss: 0.52670  focal_loss 0.18948  dice_loss 0.33722 
Epoch [263/300] Validation [11/16] Loss: 0.16593  focal_loss 0.06398  dice_loss 0.10194 
Epoch [263/300] Validation [12/16] Loss: 0.39401  focal_loss 0.13181  dice_loss 0.26219 
Epoch [263/300] Validation [13/16] Loss: 0.20047  focal_loss 0.07784  dice_loss 0.12264 
Epoch [263/300] Validation [14/16] Loss: 0.57016  focal_loss 0.26658  dice_loss 0.30359 
Epoch [263/300] Validation [15/16] Loss: 0.11845  focal_loss 0.04775  dice_loss 0.07070 
Epoch [263/300] Validation [16/16] Loss: 0.14662  focal_loss 0.05644  dice_loss 0.09019 
Epoch [263/300] Validation metric {'Val/mean dice_metric': 0.9367544054985046, 'Val/mean miou_metric': 0.902296781539917, 'Val/mean f1': 0.9463004469871521, 'Val/mean precision': 0.9510471820831299, 'Val/mean recall': 0.9416009187698364, 'Val/mean hd95_metric': 15.803427696228027}
Cheakpoint...
Epoch [263/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9368], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9367544054985046, 'Val/mean miou_metric': 0.902296781539917, 'Val/mean f1': 0.9463004469871521, 'Val/mean precision': 0.9510471820831299, 'Val/mean recall': 0.9416009187698364, 'Val/mean hd95_metric': 15.803427696228027}
Epoch [264/300] Training [1/62] Loss: 0.02521 
Epoch [264/300] Training [2/62] Loss: 0.01909 
Epoch [264/300] Training [3/62] Loss: 0.03962 
Epoch [264/300] Training [4/62] Loss: 0.03269 
Epoch [264/300] Training [5/62] Loss: 0.04453 
Epoch [264/300] Training [6/62] Loss: 0.02855 
Epoch [264/300] Training [7/62] Loss: 0.02850 
Epoch [264/300] Training [8/62] Loss: 0.02387 
Epoch [264/300] Training [9/62] Loss: 0.02376 
Epoch [264/300] Training [10/62] Loss: 0.04599 
Epoch [264/300] Training [11/62] Loss: 0.03317 
Epoch [264/300] Training [12/62] Loss: 0.02799 
Epoch [264/300] Training [13/62] Loss: 0.02640 
Epoch [264/300] Training [14/62] Loss: 0.02537 
Epoch [264/300] Training [15/62] Loss: 0.02717 
Epoch [264/300] Training [16/62] Loss: 0.03715 
Epoch [264/300] Training [17/62] Loss: 0.02089 
Epoch [264/300] Training [18/62] Loss: 0.14135 
Epoch [264/300] Training [19/62] Loss: 0.02391 
Epoch [264/300] Training [20/62] Loss: 0.02737 
Epoch [264/300] Training [21/62] Loss: 0.04272 
Epoch [264/300] Training [22/62] Loss: 0.02539 
Epoch [264/300] Training [23/62] Loss: 0.03253 
Epoch [264/300] Training [24/62] Loss: 0.02549 
Epoch [264/300] Training [25/62] Loss: 0.01740 
Epoch [264/300] Training [26/62] Loss: 0.04326 
Epoch [264/300] Training [27/62] Loss: 0.03231 
Epoch [264/300] Training [28/62] Loss: 0.02078 
Epoch [264/300] Training [29/62] Loss: 0.02205 
Epoch [264/300] Training [30/62] Loss: 0.05760 
Epoch [264/300] Training [31/62] Loss: 0.05136 
Epoch [264/300] Training [32/62] Loss: 0.03322 
Epoch [264/300] Training [33/62] Loss: 0.01893 
Epoch [264/300] Training [34/62] Loss: 0.02077 
Epoch [264/300] Training [35/62] Loss: 0.02497 
Epoch [264/300] Training [36/62] Loss: 0.04605 
Epoch [264/300] Training [37/62] Loss: 0.04470 
Epoch [264/300] Training [38/62] Loss: 0.03809 
Epoch [264/300] Training [39/62] Loss: 0.02037 
Epoch [264/300] Training [40/62] Loss: 0.06032 
Epoch [264/300] Training [41/62] Loss: 0.02003 
Epoch [264/300] Training [42/62] Loss: 0.02302 
Epoch [264/300] Training [43/62] Loss: 0.02806 
Epoch [264/300] Training [44/62] Loss: 0.05048 
Epoch [264/300] Training [45/62] Loss: 0.04277 
Epoch [264/300] Training [46/62] Loss: 0.04162 
Epoch [264/300] Training [47/62] Loss: 0.03139 
Epoch [264/300] Training [48/62] Loss: 0.06242 
Epoch [264/300] Training [49/62] Loss: 0.03446 
Epoch [264/300] Training [50/62] Loss: 0.02584 
Epoch [264/300] Training [51/62] Loss: 0.18139 
Epoch [264/300] Training [52/62] Loss: 0.03336 
Epoch [264/300] Training [53/62] Loss: 0.02190 
Epoch [264/300] Training [54/62] Loss: 0.06416 
Epoch [264/300] Training [55/62] Loss: 0.02540 
Epoch [264/300] Training [56/62] Loss: 0.02775 
Epoch [264/300] Training [57/62] Loss: 0.02536 
Epoch [264/300] Training [58/62] Loss: 0.02579 
Epoch [264/300] Training [59/62] Loss: 0.02081 
Epoch [264/300] Training [60/62] Loss: 0.03072 
Epoch [264/300] Training [61/62] Loss: 0.03868 
Epoch [264/300] Training [62/62] Loss: 0.04019 
Epoch [264/300] Training metric {'Train/mean dice_metric': 0.9746112823486328, 'Train/mean miou_metric': 0.954059362411499, 'Train/mean f1': 0.9763217568397522, 'Train/mean precision': 0.971968948841095, 'Train/mean recall': 0.9807137846946716, 'Train/mean hd95_metric': 4.359760761260986}
Epoch [264/300] Validation [1/16] Loss: 0.73638  focal_loss 0.51281  dice_loss 0.22357 
Epoch [264/300] Validation [2/16] Loss: 0.52486  focal_loss 0.24298  dice_loss 0.28188 
Epoch [264/300] Validation [3/16] Loss: 0.68066  focal_loss 0.41525  dice_loss 0.26540 
Epoch [264/300] Validation [4/16] Loss: 0.35677  focal_loss 0.17217  dice_loss 0.18460 
Epoch [264/300] Validation [5/16] Loss: 0.46342  focal_loss 0.16797  dice_loss 0.29545 
Epoch [264/300] Validation [6/16] Loss: 0.32388  focal_loss 0.11515  dice_loss 0.20873 
Epoch [264/300] Validation [7/16] Loss: 0.18658  focal_loss 0.08411  dice_loss 0.10247 
Epoch [264/300] Validation [8/16] Loss: 0.50683  focal_loss 0.22195  dice_loss 0.28488 
Epoch [264/300] Validation [9/16] Loss: 0.19654  focal_loss 0.08787  dice_loss 0.10867 
Epoch [264/300] Validation [10/16] Loss: 0.53303  focal_loss 0.19042  dice_loss 0.34261 
Epoch [264/300] Validation [11/16] Loss: 0.15854  focal_loss 0.06269  dice_loss 0.09586 
Epoch [264/300] Validation [12/16] Loss: 0.38443  focal_loss 0.11930  dice_loss 0.26513 
Epoch [264/300] Validation [13/16] Loss: 0.32088  focal_loss 0.13922  dice_loss 0.18166 
Epoch [264/300] Validation [14/16] Loss: 0.54444  focal_loss 0.24394  dice_loss 0.30050 
Epoch [264/300] Validation [15/16] Loss: 0.13760  focal_loss 0.05816  dice_loss 0.07944 
Epoch [264/300] Validation [16/16] Loss: 0.10690  focal_loss 0.04166  dice_loss 0.06523 
Epoch [264/300] Validation metric {'Val/mean dice_metric': 0.9378646016120911, 'Val/mean miou_metric': 0.904508113861084, 'Val/mean f1': 0.9472225308418274, 'Val/mean precision': 0.9537531733512878, 'Val/mean recall': 0.940780758857727, 'Val/mean hd95_metric': 14.38090705871582}
Cheakpoint...
Epoch [264/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9379], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9378646016120911, 'Val/mean miou_metric': 0.904508113861084, 'Val/mean f1': 0.9472225308418274, 'Val/mean precision': 0.9537531733512878, 'Val/mean recall': 0.940780758857727, 'Val/mean hd95_metric': 14.38090705871582}
Epoch [265/300] Training [1/62] Loss: 0.02040 
Epoch [265/300] Training [2/62] Loss: 0.02772 
Epoch [265/300] Training [3/62] Loss: 0.04096 
Epoch [265/300] Training [4/62] Loss: 0.02769 
Epoch [265/300] Training [5/62] Loss: 0.02888 
Epoch [265/300] Training [6/62] Loss: 0.02234 
Epoch [265/300] Training [7/62] Loss: 0.05345 
Epoch [265/300] Training [8/62] Loss: 0.02959 
Epoch [265/300] Training [9/62] Loss: 0.03158 
Epoch [265/300] Training [10/62] Loss: 0.03821 
Epoch [265/300] Training [11/62] Loss: 0.07339 
Epoch [265/300] Training [12/62] Loss: 0.01672 
Epoch [265/300] Training [13/62] Loss: 0.02461 
Epoch [265/300] Training [14/62] Loss: 0.02266 
Epoch [265/300] Training [15/62] Loss: 0.02189 
Epoch [265/300] Training [16/62] Loss: 0.02134 
Epoch [265/300] Training [17/62] Loss: 0.02714 
Epoch [265/300] Training [18/62] Loss: 0.02438 
Epoch [265/300] Training [19/62] Loss: 0.02677 
Epoch [265/300] Training [20/62] Loss: 0.02044 
Epoch [265/300] Training [21/62] Loss: 0.12749 
Epoch [265/300] Training [22/62] Loss: 0.03936 
Epoch [265/300] Training [23/62] Loss: 0.03994 
Epoch [265/300] Training [24/62] Loss: 0.03580 
Epoch [265/300] Training [25/62] Loss: 0.02929 
Epoch [265/300] Training [26/62] Loss: 0.02338 
Epoch [265/300] Training [27/62] Loss: 0.03013 
Epoch [265/300] Training [28/62] Loss: 0.02927 
Epoch [265/300] Training [29/62] Loss: 0.02756 
Epoch [265/300] Training [30/62] Loss: 0.02846 
Epoch [265/300] Training [31/62] Loss: 0.03397 
Epoch [265/300] Training [32/62] Loss: 0.02881 
Epoch [265/300] Training [33/62] Loss: 0.05767 
Epoch [265/300] Training [34/62] Loss: 0.02924 
Epoch [265/300] Training [35/62] Loss: 0.02840 
Epoch [265/300] Training [36/62] Loss: 0.03536 
Epoch [265/300] Training [37/62] Loss: 0.09683 
Epoch [265/300] Training [38/62] Loss: 0.05173 
Epoch [265/300] Training [39/62] Loss: 0.03113 
Epoch [265/300] Training [40/62] Loss: 0.02524 
Epoch [265/300] Training [41/62] Loss: 0.04003 
Epoch [265/300] Training [42/62] Loss: 0.09715 
Epoch [265/300] Training [43/62] Loss: 0.02201 
Epoch [265/300] Training [44/62] Loss: 0.02897 
Epoch [265/300] Training [45/62] Loss: 0.02198 
Epoch [265/300] Training [46/62] Loss: 0.03532 
Epoch [265/300] Training [47/62] Loss: 0.01971 
Epoch [265/300] Training [48/62] Loss: 0.03330 
Epoch [265/300] Training [49/62] Loss: 0.03386 
Epoch [265/300] Training [50/62] Loss: 0.02445 
Epoch [265/300] Training [51/62] Loss: 0.03007 
Epoch [265/300] Training [52/62] Loss: 0.07865 
Epoch [265/300] Training [53/62] Loss: 0.02902 
Epoch [265/300] Training [54/62] Loss: 0.03551 
Epoch [265/300] Training [55/62] Loss: 0.01953 
Epoch [265/300] Training [56/62] Loss: 0.03101 
Epoch [265/300] Training [57/62] Loss: 0.06460 
Epoch [265/300] Training [58/62] Loss: 0.02307 
Epoch [265/300] Training [59/62] Loss: 0.05085 
Epoch [265/300] Training [60/62] Loss: 0.03727 
Epoch [265/300] Training [61/62] Loss: 0.04704 
Epoch [265/300] Training [62/62] Loss: 0.01438 
Epoch [265/300] Training metric {'Train/mean dice_metric': 0.975501537322998, 'Train/mean miou_metric': 0.9548529982566833, 'Train/mean f1': 0.975695788860321, 'Train/mean precision': 0.9719468355178833, 'Train/mean recall': 0.9794739484786987, 'Train/mean hd95_metric': 5.556637287139893}
Epoch [265/300] Validation [1/16] Loss: 0.69371  focal_loss 0.48803  dice_loss 0.20568 
Epoch [265/300] Validation [2/16] Loss: 0.52691  focal_loss 0.22843  dice_loss 0.29848 
Epoch [265/300] Validation [3/16] Loss: 0.76450  focal_loss 0.47034  dice_loss 0.29416 
Epoch [265/300] Validation [4/16] Loss: 0.31066  focal_loss 0.17091  dice_loss 0.13974 
Epoch [265/300] Validation [5/16] Loss: 0.35205  focal_loss 0.14642  dice_loss 0.20563 
Epoch [265/300] Validation [6/16] Loss: 0.27959  focal_loss 0.09623  dice_loss 0.18336 
Epoch [265/300] Validation [7/16] Loss: 0.15848  focal_loss 0.07298  dice_loss 0.08550 
Epoch [265/300] Validation [8/16] Loss: 0.51593  focal_loss 0.21747  dice_loss 0.29846 
Epoch [265/300] Validation [9/16] Loss: 0.24629  focal_loss 0.11231  dice_loss 0.13398 
Epoch [265/300] Validation [10/16] Loss: 0.57183  focal_loss 0.22458  dice_loss 0.34725 
Epoch [265/300] Validation [11/16] Loss: 0.16096  focal_loss 0.05986  dice_loss 0.10110 
Epoch [265/300] Validation [12/16] Loss: 0.41122  focal_loss 0.14420  dice_loss 0.26701 
Epoch [265/300] Validation [13/16] Loss: 0.25432  focal_loss 0.09631  dice_loss 0.15801 
Epoch [265/300] Validation [14/16] Loss: 0.56615  focal_loss 0.25677  dice_loss 0.30938 
Epoch [265/300] Validation [15/16] Loss: 0.11240  focal_loss 0.04285  dice_loss 0.06955 
Epoch [265/300] Validation [16/16] Loss: 0.09831  focal_loss 0.03817  dice_loss 0.06014 
Epoch [265/300] Validation metric {'Val/mean dice_metric': 0.9401624202728271, 'Val/mean miou_metric': 0.9067918658256531, 'Val/mean f1': 0.9477128386497498, 'Val/mean precision': 0.95540851354599, 'Val/mean recall': 0.9401402473449707, 'Val/mean hd95_metric': 14.35517692565918}
Cheakpoint...
Epoch [265/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9402], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9401624202728271, 'Val/mean miou_metric': 0.9067918658256531, 'Val/mean f1': 0.9477128386497498, 'Val/mean precision': 0.95540851354599, 'Val/mean recall': 0.9401402473449707, 'Val/mean hd95_metric': 14.35517692565918}
Epoch [266/300] Training [1/62] Loss: 0.03751 
Epoch [266/300] Training [2/62] Loss: 0.02593 
Epoch [266/300] Training [3/62] Loss: 0.08778 
Epoch [266/300] Training [4/62] Loss: 0.02176 
Epoch [266/300] Training [5/62] Loss: 0.02466 
Epoch [266/300] Training [6/62] Loss: 0.04297 
Epoch [266/300] Training [7/62] Loss: 0.02607 
Epoch [266/300] Training [8/62] Loss: 0.01875 
Epoch [266/300] Training [9/62] Loss: 0.02682 
Epoch [266/300] Training [10/62] Loss: 0.02637 
Epoch [266/300] Training [11/62] Loss: 0.02361 
Epoch [266/300] Training [12/62] Loss: 0.07693 
Epoch [266/300] Training [13/62] Loss: 0.02494 
Epoch [266/300] Training [14/62] Loss: 0.04365 
Epoch [266/300] Training [15/62] Loss: 0.09259 
Epoch [266/300] Training [16/62] Loss: 0.06558 
Epoch [266/300] Training [17/62] Loss: 0.04507 
Epoch [266/300] Training [18/62] Loss: 0.02569 
Epoch [266/300] Training [19/62] Loss: 0.08790 
Epoch [266/300] Training [20/62] Loss: 0.03916 
Epoch [266/300] Training [21/62] Loss: 0.03748 
Epoch [266/300] Training [22/62] Loss: 0.03880 
Epoch [266/300] Training [23/62] Loss: 0.02412 
Epoch [266/300] Training [24/62] Loss: 0.01988 
Epoch [266/300] Training [25/62] Loss: 0.11466 
Epoch [266/300] Training [26/62] Loss: 0.05287 
Epoch [266/300] Training [27/62] Loss: 0.03416 
Epoch [266/300] Training [28/62] Loss: 0.02249 
Epoch [266/300] Training [29/62] Loss: 0.04742 
Epoch [266/300] Training [30/62] Loss: 0.04249 
Epoch [266/300] Training [31/62] Loss: 0.02644 
Epoch [266/300] Training [32/62] Loss: 0.03604 
Epoch [266/300] Training [33/62] Loss: 0.02372 
Epoch [266/300] Training [34/62] Loss: 0.03854 
Epoch [266/300] Training [35/62] Loss: 0.02482 
Epoch [266/300] Training [36/62] Loss: 0.02241 
Epoch [266/300] Training [37/62] Loss: 0.02526 
Epoch [266/300] Training [38/62] Loss: 0.02346 
Epoch [266/300] Training [39/62] Loss: 0.05003 
Epoch [266/300] Training [40/62] Loss: 0.02857 
Epoch [266/300] Training [41/62] Loss: 0.02506 
Epoch [266/300] Training [42/62] Loss: 0.03188 
Epoch [266/300] Training [43/62] Loss: 0.04186 
Epoch [266/300] Training [44/62] Loss: 0.02145 
Epoch [266/300] Training [45/62] Loss: 0.04318 
Epoch [266/300] Training [46/62] Loss: 0.02881 
Epoch [266/300] Training [47/62] Loss: 0.04256 
Epoch [266/300] Training [48/62] Loss: 0.02524 
Epoch [266/300] Training [49/62] Loss: 0.03051 
Epoch [266/300] Training [50/62] Loss: 0.02559 
Epoch [266/300] Training [51/62] Loss: 0.06294 
Epoch [266/300] Training [52/62] Loss: 0.02952 
Epoch [266/300] Training [53/62] Loss: 0.02382 
Epoch [266/300] Training [54/62] Loss: 0.03610 
Epoch [266/300] Training [55/62] Loss: 0.03521 
Epoch [266/300] Training [56/62] Loss: 0.03657 
Epoch [266/300] Training [57/62] Loss: 0.08883 
Epoch [266/300] Training [58/62] Loss: 0.02805 
Epoch [266/300] Training [59/62] Loss: 0.03080 
Epoch [266/300] Training [60/62] Loss: 0.02693 
Epoch [266/300] Training [61/62] Loss: 0.01967 
Epoch [266/300] Training [62/62] Loss: 0.01703 
Epoch [266/300] Training metric {'Train/mean dice_metric': 0.9753094911575317, 'Train/mean miou_metric': 0.954161524772644, 'Train/mean f1': 0.974795401096344, 'Train/mean precision': 0.9717490673065186, 'Train/mean recall': 0.9778608083724976, 'Train/mean hd95_metric': 5.159709453582764}
Epoch [266/300] Validation [1/16] Loss: 0.67735  focal_loss 0.45972  dice_loss 0.21763 
Epoch [266/300] Validation [2/16] Loss: 0.51104  focal_loss 0.21523  dice_loss 0.29581 
Epoch [266/300] Validation [3/16] Loss: 0.75756  focal_loss 0.45417  dice_loss 0.30339 
Epoch [266/300] Validation [4/16] Loss: 0.31898  focal_loss 0.17095  dice_loss 0.14803 
Epoch [266/300] Validation [5/16] Loss: 0.36633  focal_loss 0.14844  dice_loss 0.21788 
Epoch [266/300] Validation [6/16] Loss: 0.34794  focal_loss 0.12923  dice_loss 0.21871 
Epoch [266/300] Validation [7/16] Loss: 0.20802  focal_loss 0.09605  dice_loss 0.11196 
Epoch [266/300] Validation [8/16] Loss: 0.51088  focal_loss 0.20851  dice_loss 0.30237 
Epoch [266/300] Validation [9/16] Loss: 0.22003  focal_loss 0.10381  dice_loss 0.11622 
Epoch [266/300] Validation [10/16] Loss: 0.56675  focal_loss 0.22083  dice_loss 0.34592 
Epoch [266/300] Validation [11/16] Loss: 0.18913  focal_loss 0.07894  dice_loss 0.11018 
Epoch [266/300] Validation [12/16] Loss: 0.50952  focal_loss 0.13589  dice_loss 0.37363 
Epoch [266/300] Validation [13/16] Loss: 0.29026  focal_loss 0.12529  dice_loss 0.16498 
Epoch [266/300] Validation [14/16] Loss: 0.61113  focal_loss 0.27516  dice_loss 0.33597 
Epoch [266/300] Validation [15/16] Loss: 0.13252  focal_loss 0.05832  dice_loss 0.07420 
Epoch [266/300] Validation [16/16] Loss: 0.08980  focal_loss 0.02851  dice_loss 0.06129 
Epoch [266/300] Validation metric {'Val/mean dice_metric': 0.9368817806243896, 'Val/mean miou_metric': 0.902430534362793, 'Val/mean f1': 0.945025622844696, 'Val/mean precision': 0.9515577554702759, 'Val/mean recall': 0.9385824203491211, 'Val/mean hd95_metric': 14.445798873901367}
Cheakpoint...
Epoch [266/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9369], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9368817806243896, 'Val/mean miou_metric': 0.902430534362793, 'Val/mean f1': 0.945025622844696, 'Val/mean precision': 0.9515577554702759, 'Val/mean recall': 0.9385824203491211, 'Val/mean hd95_metric': 14.445798873901367}
Epoch [267/300] Training [1/62] Loss: 0.13737 
Epoch [267/300] Training [2/62] Loss: 0.03387 
Epoch [267/300] Training [3/62] Loss: 0.02441 
Epoch [267/300] Training [4/62] Loss: 0.02539 
Epoch [267/300] Training [5/62] Loss: 0.14021 
Epoch [267/300] Training [6/62] Loss: 0.02206 
Epoch [267/300] Training [7/62] Loss: 0.02980 
Epoch [267/300] Training [8/62] Loss: 0.03554 
Epoch [267/300] Training [9/62] Loss: 0.02564 
Epoch [267/300] Training [10/62] Loss: 0.02387 
Epoch [267/300] Training [11/62] Loss: 0.02162 
Epoch [267/300] Training [12/62] Loss: 0.04833 
Epoch [267/300] Training [13/62] Loss: 0.02623 
Epoch [267/300] Training [14/62] Loss: 0.03819 
Epoch [267/300] Training [15/62] Loss: 0.03558 
Epoch [267/300] Training [16/62] Loss: 0.02099 
Epoch [267/300] Training [17/62] Loss: 0.03157 
Epoch [267/300] Training [18/62] Loss: 0.04071 
Epoch [267/300] Training [19/62] Loss: 0.03687 
Epoch [267/300] Training [20/62] Loss: 0.03960 
Epoch [267/300] Training [21/62] Loss: 0.02550 
Epoch [267/300] Training [22/62] Loss: 0.02123 
Epoch [267/300] Training [23/62] Loss: 0.02317 
Epoch [267/300] Training [24/62] Loss: 0.02687 
Epoch [267/300] Training [25/62] Loss: 0.03840 
Epoch [267/300] Training [26/62] Loss: 0.01843 
Epoch [267/300] Training [27/62] Loss: 0.04833 
Epoch [267/300] Training [28/62] Loss: 0.02521 
Epoch [267/300] Training [29/62] Loss: 0.04399 
Epoch [267/300] Training [30/62] Loss: 0.02992 
Epoch [267/300] Training [31/62] Loss: 0.03351 
Epoch [267/300] Training [32/62] Loss: 0.02579 
Epoch [267/300] Training [33/62] Loss: 0.02987 
Epoch [267/300] Training [34/62] Loss: 0.03126 
Epoch [267/300] Training [35/62] Loss: 0.02041 
Epoch [267/300] Training [36/62] Loss: 0.02510 
Epoch [267/300] Training [37/62] Loss: 0.02912 
Epoch [267/300] Training [38/62] Loss: 0.05833 
Epoch [267/300] Training [39/62] Loss: 0.02392 
Epoch [267/300] Training [40/62] Loss: 0.03132 
Epoch [267/300] Training [41/62] Loss: 0.02053 
Epoch [267/300] Training [42/62] Loss: 0.02839 
Epoch [267/300] Training [43/62] Loss: 0.02680 
Epoch [267/300] Training [44/62] Loss: 0.02760 
Epoch [267/300] Training [45/62] Loss: 0.04534 
Epoch [267/300] Training [46/62] Loss: 0.03343 
Epoch [267/300] Training [47/62] Loss: 0.04240 
Epoch [267/300] Training [48/62] Loss: 0.05616 
Epoch [267/300] Training [49/62] Loss: 0.02253 
Epoch [267/300] Training [50/62] Loss: 0.03645 
Epoch [267/300] Training [51/62] Loss: 0.10593 
Epoch [267/300] Training [52/62] Loss: 0.02365 
Epoch [267/300] Training [53/62] Loss: 0.02488 
Epoch [267/300] Training [54/62] Loss: 0.02384 
Epoch [267/300] Training [55/62] Loss: 0.02429 
Epoch [267/300] Training [56/62] Loss: 0.03449 
Epoch [267/300] Training [57/62] Loss: 0.01750 
Epoch [267/300] Training [58/62] Loss: 0.02354 
Epoch [267/300] Training [59/62] Loss: 0.03248 
Epoch [267/300] Training [60/62] Loss: 0.03157 
Epoch [267/300] Training [61/62] Loss: 0.02831 
Epoch [267/300] Training [62/62] Loss: 0.03516 
Epoch [267/300] Training metric {'Train/mean dice_metric': 0.9756270051002502, 'Train/mean miou_metric': 0.955989420413971, 'Train/mean f1': 0.9764062762260437, 'Train/mean precision': 0.9721465706825256, 'Train/mean recall': 0.9807037115097046, 'Train/mean hd95_metric': 5.390446186065674}
Epoch [267/300] Validation [1/16] Loss: 0.67629  focal_loss 0.46566  dice_loss 0.21063 
Epoch [267/300] Validation [2/16] Loss: 0.57748  focal_loss 0.24246  dice_loss 0.33502 
Epoch [267/300] Validation [3/16] Loss: 0.65931  focal_loss 0.39329  dice_loss 0.26603 
Epoch [267/300] Validation [4/16] Loss: 0.32395  focal_loss 0.17488  dice_loss 0.14907 
Epoch [267/300] Validation [5/16] Loss: 0.40571  focal_loss 0.17748  dice_loss 0.22823 
Epoch [267/300] Validation [6/16] Loss: 0.34654  focal_loss 0.12973  dice_loss 0.21681 
Epoch [267/300] Validation [7/16] Loss: 0.20267  focal_loss 0.09550  dice_loss 0.10717 
Epoch [267/300] Validation [8/16] Loss: 0.55825  focal_loss 0.23258  dice_loss 0.32567 
Epoch [267/300] Validation [9/16] Loss: 0.21350  focal_loss 0.09725  dice_loss 0.11625 
Epoch [267/300] Validation [10/16] Loss: 0.59014  focal_loss 0.21731  dice_loss 0.37283 
Epoch [267/300] Validation [11/16] Loss: 0.15240  focal_loss 0.06008  dice_loss 0.09232 
Epoch [267/300] Validation [12/16] Loss: 0.35542  focal_loss 0.10057  dice_loss 0.25485 
Epoch [267/300] Validation [13/16] Loss: 0.29227  focal_loss 0.12585  dice_loss 0.16642 
Epoch [267/300] Validation [14/16] Loss: 0.49102  focal_loss 0.22056  dice_loss 0.27046 
Epoch [267/300] Validation [15/16] Loss: 0.10194  focal_loss 0.03950  dice_loss 0.06244 
Epoch [267/300] Validation [16/16] Loss: 0.10102  focal_loss 0.03625  dice_loss 0.06477 
Epoch [267/300] Validation metric {'Val/mean dice_metric': 0.9392752051353455, 'Val/mean miou_metric': 0.9065733551979065, 'Val/mean f1': 0.9478082060813904, 'Val/mean precision': 0.9524242281913757, 'Val/mean recall': 0.9432365894317627, 'Val/mean hd95_metric': 14.479840278625488}
Cheakpoint...
Epoch [267/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9393], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9392752051353455, 'Val/mean miou_metric': 0.9065733551979065, 'Val/mean f1': 0.9478082060813904, 'Val/mean precision': 0.9524242281913757, 'Val/mean recall': 0.9432365894317627, 'Val/mean hd95_metric': 14.479840278625488}
Epoch [268/300] Training [1/62] Loss: 0.02558 
Epoch [268/300] Training [2/62] Loss: 0.03717 
Epoch [268/300] Training [3/62] Loss: 0.03245 
Epoch [268/300] Training [4/62] Loss: 0.04109 
Epoch [268/300] Training [5/62] Loss: 0.03783 
Epoch [268/300] Training [6/62] Loss: 0.03546 
Epoch [268/300] Training [7/62] Loss: 0.02092 
Epoch [268/300] Training [8/62] Loss: 0.02338 
Epoch [268/300] Training [9/62] Loss: 0.05443 
Epoch [268/300] Training [10/62] Loss: 0.04332 
Epoch [268/300] Training [11/62] Loss: 0.04511 
Epoch [268/300] Training [12/62] Loss: 0.02148 
Epoch [268/300] Training [13/62] Loss: 0.02581 
Epoch [268/300] Training [14/62] Loss: 0.04155 
Epoch [268/300] Training [15/62] Loss: 0.02265 
Epoch [268/300] Training [16/62] Loss: 0.02675 
Epoch [268/300] Training [17/62] Loss: 0.02407 
Epoch [268/300] Training [18/62] Loss: 0.02596 
Epoch [268/300] Training [19/62] Loss: 0.02426 
Epoch [268/300] Training [20/62] Loss: 0.02304 
Epoch [268/300] Training [21/62] Loss: 0.02412 
Epoch [268/300] Training [22/62] Loss: 0.02415 
Epoch [268/300] Training [23/62] Loss: 0.03861 
Epoch [268/300] Training [24/62] Loss: 0.03648 
Epoch [268/300] Training [25/62] Loss: 0.03159 
Epoch [268/300] Training [26/62] Loss: 0.03638 
Epoch [268/300] Training [27/62] Loss: 0.02298 
Epoch [268/300] Training [28/62] Loss: 0.02800 
Epoch [268/300] Training [29/62] Loss: 0.02804 
Epoch [268/300] Training [30/62] Loss: 0.03474 
Epoch [268/300] Training [31/62] Loss: 0.02858 
Epoch [268/300] Training [32/62] Loss: 0.02065 
Epoch [268/300] Training [33/62] Loss: 0.02485 
Epoch [268/300] Training [34/62] Loss: 0.02636 
Epoch [268/300] Training [35/62] Loss: 0.07725 
Epoch [268/300] Training [36/62] Loss: 0.02918 
Epoch [268/300] Training [37/62] Loss: 0.02670 
Epoch [268/300] Training [38/62] Loss: 0.02415 
Epoch [268/300] Training [39/62] Loss: 0.07262 
Epoch [268/300] Training [40/62] Loss: 0.03709 
Epoch [268/300] Training [41/62] Loss: 0.01985 
Epoch [268/300] Training [42/62] Loss: 0.03931 
Epoch [268/300] Training [43/62] Loss: 0.03744 
Epoch [268/300] Training [44/62] Loss: 0.02643 
Epoch [268/300] Training [45/62] Loss: 0.02454 
Epoch [268/300] Training [46/62] Loss: 0.05579 
Epoch [268/300] Training [47/62] Loss: 0.03174 
Epoch [268/300] Training [48/62] Loss: 0.03365 
Epoch [268/300] Training [49/62] Loss: 0.03061 
Epoch [268/300] Training [50/62] Loss: 0.03134 
Epoch [268/300] Training [51/62] Loss: 0.04069 
Epoch [268/300] Training [52/62] Loss: 0.02255 
Epoch [268/300] Training [53/62] Loss: 0.03734 
Epoch [268/300] Training [54/62] Loss: 0.04267 
Epoch [268/300] Training [55/62] Loss: 0.03432 
Epoch [268/300] Training [56/62] Loss: 0.02560 
Epoch [268/300] Training [57/62] Loss: 0.13719 
Epoch [268/300] Training [58/62] Loss: 0.04118 
Epoch [268/300] Training [59/62] Loss: 0.05003 
Epoch [268/300] Training [60/62] Loss: 0.03372 
Epoch [268/300] Training [61/62] Loss: 0.02793 
Epoch [268/300] Training [62/62] Loss: 0.04600 
Epoch [268/300] Training metric {'Train/mean dice_metric': 0.9765225648880005, 'Train/mean miou_metric': 0.9558913111686707, 'Train/mean f1': 0.9765408635139465, 'Train/mean precision': 0.971483051776886, 'Train/mean recall': 0.9816516637802124, 'Train/mean hd95_metric': 5.693577289581299}
Epoch [268/300] Validation [1/16] Loss: 0.65593  focal_loss 0.45150  dice_loss 0.20443 
Epoch [268/300] Validation [2/16] Loss: 0.49369  focal_loss 0.21510  dice_loss 0.27859 
Epoch [268/300] Validation [3/16] Loss: 0.74718  focal_loss 0.45538  dice_loss 0.29180 
Epoch [268/300] Validation [4/16] Loss: 0.29587  focal_loss 0.16037  dice_loss 0.13550 
Epoch [268/300] Validation [5/16] Loss: 0.33955  focal_loss 0.13862  dice_loss 0.20093 
Epoch [268/300] Validation [6/16] Loss: 0.34381  focal_loss 0.12349  dice_loss 0.22031 
Epoch [268/300] Validation [7/16] Loss: 0.31183  focal_loss 0.12565  dice_loss 0.18618 
Epoch [268/300] Validation [8/16] Loss: 0.51654  focal_loss 0.21663  dice_loss 0.29992 
Epoch [268/300] Validation [9/16] Loss: 0.20043  focal_loss 0.08833  dice_loss 0.11210 
Epoch [268/300] Validation [10/16] Loss: 0.56548  focal_loss 0.20521  dice_loss 0.36027 
Epoch [268/300] Validation [11/16] Loss: 0.15140  focal_loss 0.06163  dice_loss 0.08977 
Epoch [268/300] Validation [12/16] Loss: 0.40446  focal_loss 0.13743  dice_loss 0.26703 
Epoch [268/300] Validation [13/16] Loss: 0.27608  focal_loss 0.11436  dice_loss 0.16172 
Epoch [268/300] Validation [14/16] Loss: 0.51406  focal_loss 0.23568  dice_loss 0.27838 
Epoch [268/300] Validation [15/16] Loss: 0.10092  focal_loss 0.03932  dice_loss 0.06160 
Epoch [268/300] Validation [16/16] Loss: 0.09525  focal_loss 0.03076  dice_loss 0.06448 
Epoch [268/300] Validation metric {'Val/mean dice_metric': 0.9402274489402771, 'Val/mean miou_metric': 0.9068896770477295, 'Val/mean f1': 0.9484241008758545, 'Val/mean precision': 0.9527190923690796, 'Val/mean recall': 0.9441676735877991, 'Val/mean hd95_metric': 14.586581230163574}
Cheakpoint...
Epoch [268/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9402], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9402274489402771, 'Val/mean miou_metric': 0.9068896770477295, 'Val/mean f1': 0.9484241008758545, 'Val/mean precision': 0.9527190923690796, 'Val/mean recall': 0.9441676735877991, 'Val/mean hd95_metric': 14.586581230163574}
Epoch [269/300] Training [1/62] Loss: 0.18341 
Epoch [269/300] Training [2/62] Loss: 0.01704 
Epoch [269/300] Training [3/62] Loss: 0.02370 
Epoch [269/300] Training [4/62] Loss: 0.01812 
Epoch [269/300] Training [5/62] Loss: 0.02528 
Epoch [269/300] Training [6/62] Loss: 0.02260 
Epoch [269/300] Training [7/62] Loss: 0.02793 
Epoch [269/300] Training [8/62] Loss: 0.01857 
Epoch [269/300] Training [9/62] Loss: 0.03382 
Epoch [269/300] Training [10/62] Loss: 0.05193 
Epoch [269/300] Training [11/62] Loss: 0.02670 
Epoch [269/300] Training [12/62] Loss: 0.02714 
Epoch [269/300] Training [13/62] Loss: 0.02380 
Epoch [269/300] Training [14/62] Loss: 0.02337 
Epoch [269/300] Training [15/62] Loss: 0.02149 
Epoch [269/300] Training [16/62] Loss: 0.03951 
Epoch [269/300] Training [17/62] Loss: 0.02869 
Epoch [269/300] Training [18/62] Loss: 0.02512 
Epoch [269/300] Training [19/62] Loss: 0.02148 
Epoch [269/300] Training [20/62] Loss: 0.03638 
Epoch [269/300] Training [21/62] Loss: 0.05249 
Epoch [269/300] Training [22/62] Loss: 0.04810 
Epoch [269/300] Training [23/62] Loss: 0.01933 
Epoch [269/300] Training [24/62] Loss: 0.02723 
Epoch [269/300] Training [25/62] Loss: 0.02712 
Epoch [269/300] Training [26/62] Loss: 0.02169 
Epoch [269/300] Training [27/62] Loss: 0.03824 
Epoch [269/300] Training [28/62] Loss: 0.02538 
Epoch [269/300] Training [29/62] Loss: 0.02138 
Epoch [269/300] Training [30/62] Loss: 0.03519 
Epoch [269/300] Training [31/62] Loss: 0.04450 
Epoch [269/300] Training [32/62] Loss: 0.02302 
Epoch [269/300] Training [33/62] Loss: 0.03903 
Epoch [269/300] Training [34/62] Loss: 0.02357 
Epoch [269/300] Training [35/62] Loss: 0.02192 
Epoch [269/300] Training [36/62] Loss: 0.02821 
Epoch [269/300] Training [37/62] Loss: 0.04665 
Epoch [269/300] Training [38/62] Loss: 0.02207 
Epoch [269/300] Training [39/62] Loss: 0.02799 
Epoch [269/300] Training [40/62] Loss: 0.03934 
Epoch [269/300] Training [41/62] Loss: 0.02106 
Epoch [269/300] Training [42/62] Loss: 0.04483 
Epoch [269/300] Training [43/62] Loss: 0.02388 
Epoch [269/300] Training [44/62] Loss: 0.03270 
Epoch [269/300] Training [45/62] Loss: 0.05981 
Epoch [269/300] Training [46/62] Loss: 0.02914 
Epoch [269/300] Training [47/62] Loss: 0.04314 
Epoch [269/300] Training [48/62] Loss: 0.03825 
Epoch [269/300] Training [49/62] Loss: 0.04213 
Epoch [269/300] Training [50/62] Loss: 0.03344 
Epoch [269/300] Training [51/62] Loss: 0.02402 
Epoch [269/300] Training [52/62] Loss: 0.03753 
Epoch [269/300] Training [53/62] Loss: 0.02515 
Epoch [269/300] Training [54/62] Loss: 0.02011 
Epoch [269/300] Training [55/62] Loss: 0.02356 
Epoch [269/300] Training [56/62] Loss: 0.02850 
Epoch [269/300] Training [57/62] Loss: 0.02877 
Epoch [269/300] Training [58/62] Loss: 0.02519 
Epoch [269/300] Training [59/62] Loss: 0.03188 
Epoch [269/300] Training [60/62] Loss: 0.02690 
Epoch [269/300] Training [61/62] Loss: 0.05327 
Epoch [269/300] Training [62/62] Loss: 0.14104 
Epoch [269/300] Training metric {'Train/mean dice_metric': 0.9776282906532288, 'Train/mean miou_metric': 0.9585316181182861, 'Train/mean f1': 0.9774538278579712, 'Train/mean precision': 0.973991870880127, 'Train/mean recall': 0.9809404015541077, 'Train/mean hd95_metric': 5.383967876434326}
Epoch [269/300] Validation [1/16] Loss: 0.69914  focal_loss 0.48038  dice_loss 0.21876 
Epoch [269/300] Validation [2/16] Loss: 0.56778  focal_loss 0.26192  dice_loss 0.30586 
Epoch [269/300] Validation [3/16] Loss: 0.74178  focal_loss 0.45559  dice_loss 0.28619 
Epoch [269/300] Validation [4/16] Loss: 0.32002  focal_loss 0.17800  dice_loss 0.14202 
Epoch [269/300] Validation [5/16] Loss: 0.36763  focal_loss 0.14993  dice_loss 0.21770 
Epoch [269/300] Validation [6/16] Loss: 0.36808  focal_loss 0.13636  dice_loss 0.23172 
Epoch [269/300] Validation [7/16] Loss: 0.22125  focal_loss 0.10405  dice_loss 0.11721 
Epoch [269/300] Validation [8/16] Loss: 0.48801  focal_loss 0.19168  dice_loss 0.29633 
Epoch [269/300] Validation [9/16] Loss: 0.24383  focal_loss 0.11020  dice_loss 0.13363 
Epoch [269/300] Validation [10/16] Loss: 0.51154  focal_loss 0.18250  dice_loss 0.32905 
Epoch [269/300] Validation [11/16] Loss: 0.15062  focal_loss 0.05806  dice_loss 0.09256 
Epoch [269/300] Validation [12/16] Loss: 0.40483  focal_loss 0.13883  dice_loss 0.26601 
Epoch [269/300] Validation [13/16] Loss: 0.30776  focal_loss 0.13414  dice_loss 0.17363 
Epoch [269/300] Validation [14/16] Loss: 0.50586  focal_loss 0.22832  dice_loss 0.27754 
Epoch [269/300] Validation [15/16] Loss: 0.15336  focal_loss 0.07161  dice_loss 0.08175 
Epoch [269/300] Validation [16/16] Loss: 0.09837  focal_loss 0.03795  dice_loss 0.06043 
Epoch [269/300] Validation metric {'Val/mean dice_metric': 0.9409784078598022, 'Val/mean miou_metric': 0.9082154631614685, 'Val/mean f1': 0.9485887885093689, 'Val/mean precision': 0.9573343396186829, 'Val/mean recall': 0.9400015473365784, 'Val/mean hd95_metric': 14.06423282623291}
Cheakpoint...
Epoch [269/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9410], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9409784078598022, 'Val/mean miou_metric': 0.9082154631614685, 'Val/mean f1': 0.9485887885093689, 'Val/mean precision': 0.9573343396186829, 'Val/mean recall': 0.9400015473365784, 'Val/mean hd95_metric': 14.06423282623291}
Epoch [270/300] Training [1/62] Loss: 0.03120 
Epoch [270/300] Training [2/62] Loss: 0.11264 
Epoch [270/300] Training [3/62] Loss: 0.04222 
Epoch [270/300] Training [4/62] Loss: 0.03074 
Epoch [270/300] Training [5/62] Loss: 0.02486 
Epoch [270/300] Training [6/62] Loss: 0.02768 
Epoch [270/300] Training [7/62] Loss: 0.07579 
Epoch [270/300] Training [8/62] Loss: 0.02373 
Epoch [270/300] Training [9/62] Loss: 0.03524 
Epoch [270/300] Training [10/62] Loss: 0.03807 
Epoch [270/300] Training [11/62] Loss: 0.03499 
Epoch [270/300] Training [12/62] Loss: 0.02623 
Epoch [270/300] Training [13/62] Loss: 0.02673 
Epoch [270/300] Training [14/62] Loss: 0.02992 
Epoch [270/300] Training [15/62] Loss: 0.01890 
Epoch [270/300] Training [16/62] Loss: 0.02863 
Epoch [270/300] Training [17/62] Loss: 0.03331 
Epoch [270/300] Training [18/62] Loss: 0.02751 
Epoch [270/300] Training [19/62] Loss: 0.09416 
Epoch [270/300] Training [20/62] Loss: 0.02627 
Epoch [270/300] Training [21/62] Loss: 0.03089 
Epoch [270/300] Training [22/62] Loss: 0.03736 
Epoch [270/300] Training [23/62] Loss: 0.02503 
Epoch [270/300] Training [24/62] Loss: 0.02483 
Epoch [270/300] Training [25/62] Loss: 0.02253 
Epoch [270/300] Training [26/62] Loss: 0.02557 
Epoch [270/300] Training [27/62] Loss: 0.01936 
Epoch [270/300] Training [28/62] Loss: 0.03601 
Epoch [270/300] Training [29/62] Loss: 0.02588 
Epoch [270/300] Training [30/62] Loss: 0.03414 
Epoch [270/300] Training [31/62] Loss: 0.03677 
Epoch [270/300] Training [32/62] Loss: 0.02896 
Epoch [270/300] Training [33/62] Loss: 0.03064 
Epoch [270/300] Training [34/62] Loss: 0.02180 
Epoch [270/300] Training [35/62] Loss: 0.03520 
Epoch [270/300] Training [36/62] Loss: 0.04641 
Epoch [270/300] Training [37/62] Loss: 0.03803 
Epoch [270/300] Training [38/62] Loss: 0.02611 
Epoch [270/300] Training [39/62] Loss: 0.02102 
Epoch [270/300] Training [40/62] Loss: 0.03751 
Epoch [270/300] Training [41/62] Loss: 0.02504 
Epoch [270/300] Training [42/62] Loss: 0.02530 
Epoch [270/300] Training [43/62] Loss: 0.04236 
Epoch [270/300] Training [44/62] Loss: 0.03420 
Epoch [270/300] Training [45/62] Loss: 0.05548 
Epoch [270/300] Training [46/62] Loss: 0.15499 
Epoch [270/300] Training [47/62] Loss: 0.04389 
Epoch [270/300] Training [48/62] Loss: 0.04358 
Epoch [270/300] Training [49/62] Loss: 0.02213 
Epoch [270/300] Training [50/62] Loss: 0.02375 
Epoch [270/300] Training [51/62] Loss: 0.01626 
Epoch [270/300] Training [52/62] Loss: 0.04061 
Epoch [270/300] Training [53/62] Loss: 0.02453 
Epoch [270/300] Training [54/62] Loss: 0.02429 
Epoch [270/300] Training [55/62] Loss: 0.03886 
Epoch [270/300] Training [56/62] Loss: 0.06338 
Epoch [270/300] Training [57/62] Loss: 0.02745 
Epoch [270/300] Training [58/62] Loss: 0.05738 
Epoch [270/300] Training [59/62] Loss: 0.02663 
Epoch [270/300] Training [60/62] Loss: 0.02284 
Epoch [270/300] Training [61/62] Loss: 0.02218 
Epoch [270/300] Training [62/62] Loss: 0.02246 
Epoch [270/300] Training metric {'Train/mean dice_metric': 0.9749259352684021, 'Train/mean miou_metric': 0.9545808434486389, 'Train/mean f1': 0.9759736061096191, 'Train/mean precision': 0.9719399809837341, 'Train/mean recall': 0.9800406694412231, 'Train/mean hd95_metric': 6.51398229598999}
Epoch [270/300] Validation [1/16] Loss: 0.67903  focal_loss 0.46817  dice_loss 0.21086 
Epoch [270/300] Validation [2/16] Loss: 0.48121  focal_loss 0.20983  dice_loss 0.27138 
Epoch [270/300] Validation [3/16] Loss: 0.67613  focal_loss 0.39856  dice_loss 0.27756 
Epoch [270/300] Validation [4/16] Loss: 0.35264  focal_loss 0.17657  dice_loss 0.17607 
Epoch [270/300] Validation [5/16] Loss: 0.31948  focal_loss 0.13000  dice_loss 0.18949 
Epoch [270/300] Validation [6/16] Loss: 0.27434  focal_loss 0.08727  dice_loss 0.18707 
Epoch [270/300] Validation [7/16] Loss: 0.34403  focal_loss 0.13582  dice_loss 0.20820 
Epoch [270/300] Validation [8/16] Loss: 0.46904  focal_loss 0.20752  dice_loss 0.26152 
Epoch [270/300] Validation [9/16] Loss: 0.19644  focal_loss 0.08801  dice_loss 0.10843 
Epoch [270/300] Validation [10/16] Loss: 0.50192  focal_loss 0.18102  dice_loss 0.32091 
Epoch [270/300] Validation [11/16] Loss: 0.13455  focal_loss 0.04448  dice_loss 0.09006 
Epoch [270/300] Validation [12/16] Loss: 0.40619  focal_loss 0.13908  dice_loss 0.26711 
Epoch [270/300] Validation [13/16] Loss: 0.28244  focal_loss 0.12034  dice_loss 0.16210 
Epoch [270/300] Validation [14/16] Loss: 0.47926  focal_loss 0.21543  dice_loss 0.26383 
Epoch [270/300] Validation [15/16] Loss: 0.10095  focal_loss 0.03904  dice_loss 0.06190 
Epoch [270/300] Validation [16/16] Loss: 0.09154  focal_loss 0.03021  dice_loss 0.06133 
Epoch [270/300] Validation metric {'Val/mean dice_metric': 0.9402557611465454, 'Val/mean miou_metric': 0.9075410962104797, 'Val/mean f1': 0.9489960074424744, 'Val/mean precision': 0.9546524882316589, 'Val/mean recall': 0.9434061050415039, 'Val/mean hd95_metric': 14.240218162536621}
Cheakpoint...
Epoch [270/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9403], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9402557611465454, 'Val/mean miou_metric': 0.9075410962104797, 'Val/mean f1': 0.9489960074424744, 'Val/mean precision': 0.9546524882316589, 'Val/mean recall': 0.9434061050415039, 'Val/mean hd95_metric': 14.240218162536621}
Epoch [271/300] Training [1/62] Loss: 0.02048 
Epoch [271/300] Training [2/62] Loss: 0.02138 
Epoch [271/300] Training [3/62] Loss: 0.01959 
Epoch [271/300] Training [4/62] Loss: 0.02264 
Epoch [271/300] Training [5/62] Loss: 0.06969 
Epoch [271/300] Training [6/62] Loss: 0.02711 
Epoch [271/300] Training [7/62] Loss: 0.02201 
Epoch [271/300] Training [8/62] Loss: 0.04149 
Epoch [271/300] Training [9/62] Loss: 0.02217 
Epoch [271/300] Training [10/62] Loss: 0.05372 
Epoch [271/300] Training [11/62] Loss: 0.02027 
Epoch [271/300] Training [12/62] Loss: 0.02857 
Epoch [271/300] Training [13/62] Loss: 0.02926 
Epoch [271/300] Training [14/62] Loss: 0.03565 
Epoch [271/300] Training [15/62] Loss: 0.02093 
Epoch [271/300] Training [16/62] Loss: 0.01771 
Epoch [271/300] Training [17/62] Loss: 0.04332 
Epoch [271/300] Training [18/62] Loss: 0.03408 
Epoch [271/300] Training [19/62] Loss: 0.02409 
Epoch [271/300] Training [20/62] Loss: 0.02162 
Epoch [271/300] Training [21/62] Loss: 0.04192 
Epoch [271/300] Training [22/62] Loss: 0.07719 
Epoch [271/300] Training [23/62] Loss: 0.05709 
Epoch [271/300] Training [24/62] Loss: 0.02463 
Epoch [271/300] Training [25/62] Loss: 0.03427 
Epoch [271/300] Training [26/62] Loss: 0.02820 
Epoch [271/300] Training [27/62] Loss: 0.02766 
Epoch [271/300] Training [28/62] Loss: 0.02061 
Epoch [271/300] Training [29/62] Loss: 0.03618 
Epoch [271/300] Training [30/62] Loss: 0.02098 
Epoch [271/300] Training [31/62] Loss: 0.02829 
Epoch [271/300] Training [32/62] Loss: 0.02006 
Epoch [271/300] Training [33/62] Loss: 0.07084 
Epoch [271/300] Training [34/62] Loss: 0.04604 
Epoch [271/300] Training [35/62] Loss: 0.03219 
Epoch [271/300] Training [36/62] Loss: 0.02429 
Epoch [271/300] Training [37/62] Loss: 0.04470 
Epoch [271/300] Training [38/62] Loss: 0.05190 
Epoch [271/300] Training [39/62] Loss: 0.02852 
Epoch [271/300] Training [40/62] Loss: 0.03082 
Epoch [271/300] Training [41/62] Loss: 0.02294 
Epoch [271/300] Training [42/62] Loss: 0.03397 
Epoch [271/300] Training [43/62] Loss: 0.03600 
Epoch [271/300] Training [44/62] Loss: 0.02120 
Epoch [271/300] Training [45/62] Loss: 0.02421 
Epoch [271/300] Training [46/62] Loss: 0.02239 
Epoch [271/300] Training [47/62] Loss: 0.02532 
Epoch [271/300] Training [48/62] Loss: 0.03525 
Epoch [271/300] Training [49/62] Loss: 0.05841 
Epoch [271/300] Training [50/62] Loss: 0.02180 
Epoch [271/300] Training [51/62] Loss: 0.04167 
Epoch [271/300] Training [52/62] Loss: 0.03365 
Epoch [271/300] Training [53/62] Loss: 0.03960 
Epoch [271/300] Training [54/62] Loss: 0.03104 
Epoch [271/300] Training [55/62] Loss: 0.04636 
Epoch [271/300] Training [56/62] Loss: 0.06235 
Epoch [271/300] Training [57/62] Loss: 0.02310 
Epoch [271/300] Training [58/62] Loss: 0.02066 
Epoch [271/300] Training [59/62] Loss: 0.02787 
Epoch [271/300] Training [60/62] Loss: 0.01810 
Epoch [271/300] Training [61/62] Loss: 0.03315 
Epoch [271/300] Training [62/62] Loss: 0.05780 
Epoch [271/300] Training metric {'Train/mean dice_metric': 0.9775699377059937, 'Train/mean miou_metric': 0.9576630592346191, 'Train/mean f1': 0.9777613878250122, 'Train/mean precision': 0.9727354645729065, 'Train/mean recall': 0.9828395843505859, 'Train/mean hd95_metric': 5.3451385498046875}
Epoch [271/300] Validation [1/16] Loss: 0.65974  focal_loss 0.45115  dice_loss 0.20858 
Epoch [271/300] Validation [2/16] Loss: 0.47776  focal_loss 0.20972  dice_loss 0.26804 
Epoch [271/300] Validation [3/16] Loss: 0.76560  focal_loss 0.46689  dice_loss 0.29871 
Epoch [271/300] Validation [4/16] Loss: 0.30440  focal_loss 0.16790  dice_loss 0.13650 
Epoch [271/300] Validation [5/16] Loss: 0.47547  focal_loss 0.17215  dice_loss 0.30331 
Epoch [271/300] Validation [6/16] Loss: 0.29594  focal_loss 0.10361  dice_loss 0.19234 
Epoch [271/300] Validation [7/16] Loss: 0.25312  focal_loss 0.10836  dice_loss 0.14476 
Epoch [271/300] Validation [8/16] Loss: 0.51889  focal_loss 0.21460  dice_loss 0.30429 
Epoch [271/300] Validation [9/16] Loss: 0.21222  focal_loss 0.10247  dice_loss 0.10975 
Epoch [271/300] Validation [10/16] Loss: 0.60938  focal_loss 0.23437  dice_loss 0.37501 
Epoch [271/300] Validation [11/16] Loss: 0.15459  focal_loss 0.06098  dice_loss 0.09361 
Epoch [271/300] Validation [12/16] Loss: 0.41626  focal_loss 0.14598  dice_loss 0.27028 
Epoch [271/300] Validation [13/16] Loss: 0.22505  focal_loss 0.08039  dice_loss 0.14466 
Epoch [271/300] Validation [14/16] Loss: 0.59117  focal_loss 0.26598  dice_loss 0.32518 
Epoch [271/300] Validation [15/16] Loss: 0.10654  focal_loss 0.04208  dice_loss 0.06445 
Epoch [271/300] Validation [16/16] Loss: 0.10056  focal_loss 0.03881  dice_loss 0.06175 
Epoch [271/300] Validation metric {'Val/mean dice_metric': 0.939854621887207, 'Val/mean miou_metric': 0.9075831770896912, 'Val/mean f1': 0.9496671557426453, 'Val/mean precision': 0.956214427947998, 'Val/mean recall': 0.9432090520858765, 'Val/mean hd95_metric': 14.20543098449707}
Cheakpoint...
Epoch [271/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9399], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.939854621887207, 'Val/mean miou_metric': 0.9075831770896912, 'Val/mean f1': 0.9496671557426453, 'Val/mean precision': 0.956214427947998, 'Val/mean recall': 0.9432090520858765, 'Val/mean hd95_metric': 14.20543098449707}
Epoch [272/300] Training [1/62] Loss: 0.04221 
Epoch [272/300] Training [2/62] Loss: 0.02835 
Epoch [272/300] Training [3/62] Loss: 0.12144 
Epoch [272/300] Training [4/62] Loss: 0.01958 
Epoch [272/300] Training [5/62] Loss: 0.02966 
Epoch [272/300] Training [6/62] Loss: 0.05193 
Epoch [272/300] Training [7/62] Loss: 0.04935 
Epoch [272/300] Training [8/62] Loss: 0.02495 
Epoch [272/300] Training [9/62] Loss: 0.04203 
Epoch [272/300] Training [10/62] Loss: 0.02704 
Epoch [272/300] Training [11/62] Loss: 0.02132 
Epoch [272/300] Training [12/62] Loss: 0.02266 
Epoch [272/300] Training [13/62] Loss: 0.05015 
Epoch [272/300] Training [14/62] Loss: 0.03221 
Epoch [272/300] Training [15/62] Loss: 0.02416 
Epoch [272/300] Training [16/62] Loss: 0.09409 
Epoch [272/300] Training [17/62] Loss: 0.03011 
Epoch [272/300] Training [18/62] Loss: 0.03507 
Epoch [272/300] Training [19/62] Loss: 0.07316 
Epoch [272/300] Training [20/62] Loss: 0.02728 
Epoch [272/300] Training [21/62] Loss: 0.02959 
Epoch [272/300] Training [22/62] Loss: 0.02057 
Epoch [272/300] Training [23/62] Loss: 0.02368 
Epoch [272/300] Training [24/62] Loss: 0.02134 
Epoch [272/300] Training [25/62] Loss: 0.05576 
Epoch [272/300] Training [26/62] Loss: 0.03196 
Epoch [272/300] Training [27/62] Loss: 0.04565 
Epoch [272/300] Training [28/62] Loss: 0.02876 
Epoch [272/300] Training [29/62] Loss: 0.03762 
Epoch [272/300] Training [30/62] Loss: 0.02019 
Epoch [272/300] Training [31/62] Loss: 0.02663 
Epoch [272/300] Training [32/62] Loss: 0.03857 
Epoch [272/300] Training [33/62] Loss: 0.03671 
Epoch [272/300] Training [34/62] Loss: 0.02438 
Epoch [272/300] Training [35/62] Loss: 0.05298 
Epoch [272/300] Training [36/62] Loss: 0.02598 
Epoch [272/300] Training [37/62] Loss: 0.02343 
Epoch [272/300] Training [38/62] Loss: 0.02267 
Epoch [272/300] Training [39/62] Loss: 0.03581 
Epoch [272/300] Training [40/62] Loss: 0.02013 
Epoch [272/300] Training [41/62] Loss: 0.02578 
Epoch [272/300] Training [42/62] Loss: 0.03955 
Epoch [272/300] Training [43/62] Loss: 0.04567 
Epoch [272/300] Training [44/62] Loss: 0.05183 
Epoch [272/300] Training [45/62] Loss: 0.02545 
Epoch [272/300] Training [46/62] Loss: 0.03481 
Epoch [272/300] Training [47/62] Loss: 0.03821 
Epoch [272/300] Training [48/62] Loss: 0.01984 
Epoch [272/300] Training [49/62] Loss: 0.04478 
Epoch [272/300] Training [50/62] Loss: 0.04707 
Epoch [272/300] Training [51/62] Loss: 0.02060 
Epoch [272/300] Training [52/62] Loss: 0.04066 
Epoch [272/300] Training [53/62] Loss: 0.03654 
Epoch [272/300] Training [54/62] Loss: 0.04758 
Epoch [272/300] Training [55/62] Loss: 0.05294 
Epoch [272/300] Training [56/62] Loss: 0.04841 
Epoch [272/300] Training [57/62] Loss: 0.02568 
Epoch [272/300] Training [58/62] Loss: 0.05687 
Epoch [272/300] Training [59/62] Loss: 0.02454 
Epoch [272/300] Training [60/62] Loss: 0.02601 
Epoch [272/300] Training [61/62] Loss: 0.06397 
Epoch [272/300] Training [62/62] Loss: 0.08011 
Epoch [272/300] Training metric {'Train/mean dice_metric': 0.9755785465240479, 'Train/mean miou_metric': 0.9538065195083618, 'Train/mean f1': 0.974102795124054, 'Train/mean precision': 0.9713425636291504, 'Train/mean recall': 0.976878821849823, 'Train/mean hd95_metric': 5.052667140960693}
Epoch [272/300] Validation [1/16] Loss: 0.66049  focal_loss 0.45865  dice_loss 0.20185 
Epoch [272/300] Validation [2/16] Loss: 0.57466  focal_loss 0.25928  dice_loss 0.31538 
Epoch [272/300] Validation [3/16] Loss: 0.75824  focal_loss 0.47869  dice_loss 0.27955 
Epoch [272/300] Validation [4/16] Loss: 0.35352  focal_loss 0.17272  dice_loss 0.18080 
Epoch [272/300] Validation [5/16] Loss: 0.33473  focal_loss 0.12789  dice_loss 0.20683 
Epoch [272/300] Validation [6/16] Loss: 0.27532  focal_loss 0.08931  dice_loss 0.18601 
Epoch [272/300] Validation [7/16] Loss: 0.31853  focal_loss 0.12110  dice_loss 0.19743 
Epoch [272/300] Validation [8/16] Loss: 0.56362  focal_loss 0.23714  dice_loss 0.32648 
Epoch [272/300] Validation [9/16] Loss: 0.19377  focal_loss 0.08674  dice_loss 0.10703 
Epoch [272/300] Validation [10/16] Loss: 0.53580  focal_loss 0.18619  dice_loss 0.34961 
Epoch [272/300] Validation [11/16] Loss: 0.15598  focal_loss 0.05981  dice_loss 0.09616 
Epoch [272/300] Validation [12/16] Loss: 0.40076  focal_loss 0.12497  dice_loss 0.27579 
Epoch [272/300] Validation [13/16] Loss: 0.25433  focal_loss 0.11366  dice_loss 0.14066 
Epoch [272/300] Validation [14/16] Loss: 0.55533  focal_loss 0.26311  dice_loss 0.29222 
Epoch [272/300] Validation [15/16] Loss: 0.10540  focal_loss 0.03862  dice_loss 0.06677 
Epoch [272/300] Validation [16/16] Loss: 0.10086  focal_loss 0.03787  dice_loss 0.06300 
Epoch [272/300] Validation metric {'Val/mean dice_metric': 0.938511848449707, 'Val/mean miou_metric': 0.9045034050941467, 'Val/mean f1': 0.9460809230804443, 'Val/mean precision': 0.9535071849822998, 'Val/mean recall': 0.9387694597244263, 'Val/mean hd95_metric': 13.55705451965332}
Cheakpoint...
Epoch [272/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9385], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.938511848449707, 'Val/mean miou_metric': 0.9045034050941467, 'Val/mean f1': 0.9460809230804443, 'Val/mean precision': 0.9535071849822998, 'Val/mean recall': 0.9387694597244263, 'Val/mean hd95_metric': 13.55705451965332}
Epoch [273/300] Training [1/62] Loss: 0.02196 
Epoch [273/300] Training [2/62] Loss: 0.08848 
Epoch [273/300] Training [3/62] Loss: 0.03335 
Epoch [273/300] Training [4/62] Loss: 0.01814 
Epoch [273/300] Training [5/62] Loss: 0.02241 
Epoch [273/300] Training [6/62] Loss: 0.02172 
Epoch [273/300] Training [7/62] Loss: 0.02518 
Epoch [273/300] Training [8/62] Loss: 0.03457 
Epoch [273/300] Training [9/62] Loss: 0.05213 
Epoch [273/300] Training [10/62] Loss: 0.03690 
Epoch [273/300] Training [11/62] Loss: 0.04816 
Epoch [273/300] Training [12/62] Loss: 0.03721 
Epoch [273/300] Training [13/62] Loss: 0.03184 
Epoch [273/300] Training [14/62] Loss: 0.07981 
Epoch [273/300] Training [15/62] Loss: 0.05216 
Epoch [273/300] Training [16/62] Loss: 0.02232 
Epoch [273/300] Training [17/62] Loss: 0.02862 
Epoch [273/300] Training [18/62] Loss: 0.02865 
Epoch [273/300] Training [19/62] Loss: 0.02555 
Epoch [273/300] Training [20/62] Loss: 0.02663 
Epoch [273/300] Training [21/62] Loss: 0.02069 
Epoch [273/300] Training [22/62] Loss: 0.02964 
Epoch [273/300] Training [23/62] Loss: 0.03641 
Epoch [273/300] Training [24/62] Loss: 0.02092 
Epoch [273/300] Training [25/62] Loss: 0.01981 
Epoch [273/300] Training [26/62] Loss: 0.02000 
Epoch [273/300] Training [27/62] Loss: 0.08357 
Epoch [273/300] Training [28/62] Loss: 0.03071 
Epoch [273/300] Training [29/62] Loss: 0.02602 
Epoch [273/300] Training [30/62] Loss: 0.04482 
Epoch [273/300] Training [31/62] Loss: 0.01684 
Epoch [273/300] Training [32/62] Loss: 0.01706 
Epoch [273/300] Training [33/62] Loss: 0.03886 
Epoch [273/300] Training [34/62] Loss: 0.02154 
Epoch [273/300] Training [35/62] Loss: 0.02208 
Epoch [273/300] Training [36/62] Loss: 0.02268 
Epoch [273/300] Training [37/62] Loss: 0.01780 
Epoch [273/300] Training [38/62] Loss: 0.02844 
Epoch [273/300] Training [39/62] Loss: 0.03132 
Epoch [273/300] Training [40/62] Loss: 0.05827 
Epoch [273/300] Training [41/62] Loss: 0.02528 
Epoch [273/300] Training [42/62] Loss: 0.02839 
Epoch [273/300] Training [43/62] Loss: 0.02344 
Epoch [273/300] Training [44/62] Loss: 0.02672 
Epoch [273/300] Training [45/62] Loss: 0.03596 
Epoch [273/300] Training [46/62] Loss: 0.02530 
Epoch [273/300] Training [47/62] Loss: 0.03718 
Epoch [273/300] Training [48/62] Loss: 0.02876 
Epoch [273/300] Training [49/62] Loss: 0.02924 
Epoch [273/300] Training [50/62] Loss: 0.02364 
Epoch [273/300] Training [51/62] Loss: 0.02103 
Epoch [273/300] Training [52/62] Loss: 0.02477 
Epoch [273/300] Training [53/62] Loss: 0.03087 
Epoch [273/300] Training [54/62] Loss: 0.01852 
Epoch [273/300] Training [55/62] Loss: 0.02816 
Epoch [273/300] Training [56/62] Loss: 0.03513 
Epoch [273/300] Training [57/62] Loss: 0.02975 
Epoch [273/300] Training [58/62] Loss: 0.04631 
Epoch [273/300] Training [59/62] Loss: 0.02562 
Epoch [273/300] Training [60/62] Loss: 0.02552 
Epoch [273/300] Training [61/62] Loss: 0.08642 
Epoch [273/300] Training [62/62] Loss: 0.02195 
Epoch [273/300] Training metric {'Train/mean dice_metric': 0.978291928768158, 'Train/mean miou_metric': 0.9585281610488892, 'Train/mean f1': 0.9771814942359924, 'Train/mean precision': 0.973124086856842, 'Train/mean recall': 0.9812729954719543, 'Train/mean hd95_metric': 4.167200565338135}
Epoch [273/300] Validation [1/16] Loss: 0.65365  focal_loss 0.45261  dice_loss 0.20104 
Epoch [273/300] Validation [2/16] Loss: 0.48280  focal_loss 0.21447  dice_loss 0.26834 
Epoch [273/300] Validation [3/16] Loss: 0.77270  focal_loss 0.47628  dice_loss 0.29642 
Epoch [273/300] Validation [4/16] Loss: 0.35198  focal_loss 0.17382  dice_loss 0.17816 
Epoch [273/300] Validation [5/16] Loss: 0.35088  focal_loss 0.13318  dice_loss 0.21770 
Epoch [273/300] Validation [6/16] Loss: 0.27753  focal_loss 0.09414  dice_loss 0.18340 
Epoch [273/300] Validation [7/16] Loss: 0.37507  focal_loss 0.15152  dice_loss 0.22354 
Epoch [273/300] Validation [8/16] Loss: 0.54749  focal_loss 0.22423  dice_loss 0.32326 
Epoch [273/300] Validation [9/16] Loss: 0.22894  focal_loss 0.10688  dice_loss 0.12207 
Epoch [273/300] Validation [10/16] Loss: 0.53673  focal_loss 0.18834  dice_loss 0.34840 
Epoch [273/300] Validation [11/16] Loss: 0.18349  focal_loss 0.07805  dice_loss 0.10544 
Epoch [273/300] Validation [12/16] Loss: 0.48663  focal_loss 0.12318  dice_loss 0.36345 
Epoch [273/300] Validation [13/16] Loss: 0.26691  focal_loss 0.11633  dice_loss 0.15057 
Epoch [273/300] Validation [14/16] Loss: 0.58749  focal_loss 0.28928  dice_loss 0.29821 
Epoch [273/300] Validation [15/16] Loss: 0.10503  focal_loss 0.03868  dice_loss 0.06634 
Epoch [273/300] Validation [16/16] Loss: 0.10381  focal_loss 0.03984  dice_loss 0.06398 
Epoch [273/300] Validation metric {'Val/mean dice_metric': 0.938977837562561, 'Val/mean miou_metric': 0.9067233204841614, 'Val/mean f1': 0.9484611749649048, 'Val/mean precision': 0.9561747908592224, 'Val/mean recall': 0.9408708810806274, 'Val/mean hd95_metric': 12.87209415435791}
Cheakpoint...
Epoch [273/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9390], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.938977837562561, 'Val/mean miou_metric': 0.9067233204841614, 'Val/mean f1': 0.9484611749649048, 'Val/mean precision': 0.9561747908592224, 'Val/mean recall': 0.9408708810806274, 'Val/mean hd95_metric': 12.87209415435791}
Epoch [274/300] Training [1/62] Loss: 0.04262 
Epoch [274/300] Training [2/62] Loss: 0.03175 
Epoch [274/300] Training [3/62] Loss: 0.03715 
Epoch [274/300] Training [4/62] Loss: 0.02466 
Epoch [274/300] Training [5/62] Loss: 0.06565 
Epoch [274/300] Training [6/62] Loss: 0.03006 
Epoch [274/300] Training [7/62] Loss: 0.02385 
Epoch [274/300] Training [8/62] Loss: 0.02386 
Epoch [274/300] Training [9/62] Loss: 0.01966 
Epoch [274/300] Training [10/62] Loss: 0.02712 
Epoch [274/300] Training [11/62] Loss: 0.02710 
Epoch [274/300] Training [12/62] Loss: 0.03098 
Epoch [274/300] Training [13/62] Loss: 0.02797 
Epoch [274/300] Training [14/62] Loss: 0.04468 
Epoch [274/300] Training [15/62] Loss: 0.02971 
Epoch [274/300] Training [16/62] Loss: 0.08483 
Epoch [274/300] Training [17/62] Loss: 0.03209 
Epoch [274/300] Training [18/62] Loss: 0.02754 
Epoch [274/300] Training [19/62] Loss: 0.02903 
Epoch [274/300] Training [20/62] Loss: 0.04064 
Epoch [274/300] Training [21/62] Loss: 0.04342 
Epoch [274/300] Training [22/62] Loss: 0.02680 
Epoch [274/300] Training [23/62] Loss: 0.02101 
Epoch [274/300] Training [24/62] Loss: 0.02550 
Epoch [274/300] Training [25/62] Loss: 0.02981 
Epoch [274/300] Training [26/62] Loss: 0.02491 
Epoch [274/300] Training [27/62] Loss: 0.03769 
Epoch [274/300] Training [28/62] Loss: 0.01747 
Epoch [274/300] Training [29/62] Loss: 0.03172 
Epoch [274/300] Training [30/62] Loss: 0.03157 
Epoch [274/300] Training [31/62] Loss: 0.03178 
Epoch [274/300] Training [32/62] Loss: 0.03085 
Epoch [274/300] Training [33/62] Loss: 0.02545 
Epoch [274/300] Training [34/62] Loss: 0.02414 
Epoch [274/300] Training [35/62] Loss: 0.03775 
Epoch [274/300] Training [36/62] Loss: 0.03583 
Epoch [274/300] Training [37/62] Loss: 0.02047 
Epoch [274/300] Training [38/62] Loss: 0.02404 
Epoch [274/300] Training [39/62] Loss: 0.03634 
Epoch [274/300] Training [40/62] Loss: 0.02452 
Epoch [274/300] Training [41/62] Loss: 0.03559 
Epoch [274/300] Training [42/62] Loss: 0.02467 
Epoch [274/300] Training [43/62] Loss: 0.03630 
Epoch [274/300] Training [44/62] Loss: 0.03663 
Epoch [274/300] Training [45/62] Loss: 0.02120 
Epoch [274/300] Training [46/62] Loss: 0.03727 
Epoch [274/300] Training [47/62] Loss: 0.09344 
Epoch [274/300] Training [48/62] Loss: 0.03173 
Epoch [274/300] Training [49/62] Loss: 0.02395 
Epoch [274/300] Training [50/62] Loss: 0.05818 
Epoch [274/300] Training [51/62] Loss: 0.02377 
Epoch [274/300] Training [52/62] Loss: 0.02277 
Epoch [274/300] Training [53/62] Loss: 0.04531 
Epoch [274/300] Training [54/62] Loss: 0.07293 
Epoch [274/300] Training [55/62] Loss: 0.03005 
Epoch [274/300] Training [56/62] Loss: 0.01800 
Epoch [274/300] Training [57/62] Loss: 0.03238 
Epoch [274/300] Training [58/62] Loss: 0.03601 
Epoch [274/300] Training [59/62] Loss: 0.02389 
Epoch [274/300] Training [60/62] Loss: 0.03201 
Epoch [274/300] Training [61/62] Loss: 0.02899 
Epoch [274/300] Training [62/62] Loss: 0.03081 
Epoch [274/300] Training metric {'Train/mean dice_metric': 0.9777324199676514, 'Train/mean miou_metric': 0.9579136967658997, 'Train/mean f1': 0.9769022464752197, 'Train/mean precision': 0.973660409450531, 'Train/mean recall': 0.9801657795906067, 'Train/mean hd95_metric': 4.464156627655029}
Epoch [274/300] Validation [1/16] Loss: 0.67988  focal_loss 0.47901  dice_loss 0.20087 
Epoch [274/300] Validation [2/16] Loss: 0.48317  focal_loss 0.21337  dice_loss 0.26981 
Epoch [274/300] Validation [3/16] Loss: 0.69193  focal_loss 0.41089  dice_loss 0.28104 
Epoch [274/300] Validation [4/16] Loss: 0.34120  focal_loss 0.18605  dice_loss 0.15514 
Epoch [274/300] Validation [5/16] Loss: 0.36190  focal_loss 0.14459  dice_loss 0.21731 
Epoch [274/300] Validation [6/16] Loss: 0.28084  focal_loss 0.09684  dice_loss 0.18400 
Epoch [274/300] Validation [7/16] Loss: 0.26056  focal_loss 0.10373  dice_loss 0.15683 
Epoch [274/300] Validation [8/16] Loss: 0.46894  focal_loss 0.17780  dice_loss 0.29114 
Epoch [274/300] Validation [9/16] Loss: 0.20659  focal_loss 0.09624  dice_loss 0.11035 
Epoch [274/300] Validation [10/16] Loss: 0.57191  focal_loss 0.22852  dice_loss 0.34339 
Epoch [274/300] Validation [11/16] Loss: 0.16369  focal_loss 0.07017  dice_loss 0.09352 
Epoch [274/300] Validation [12/16] Loss: 0.38103  focal_loss 0.11760  dice_loss 0.26344 
Epoch [274/300] Validation [13/16] Loss: 0.28701  focal_loss 0.12412  dice_loss 0.16289 
Epoch [274/300] Validation [14/16] Loss: 0.62364  focal_loss 0.28687  dice_loss 0.33678 
Epoch [274/300] Validation [15/16] Loss: 0.12977  focal_loss 0.05401  dice_loss 0.07576 
Epoch [274/300] Validation [16/16] Loss: 0.19127  focal_loss 0.07522  dice_loss 0.11605 
Epoch [274/300] Validation metric {'Val/mean dice_metric': 0.9410704374313354, 'Val/mean miou_metric': 0.9080477356910706, 'Val/mean f1': 0.9480774402618408, 'Val/mean precision': 0.9551060199737549, 'Val/mean recall': 0.9411516785621643, 'Val/mean hd95_metric': 13.794590950012207}
Cheakpoint...
Epoch [274/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9411], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9410704374313354, 'Val/mean miou_metric': 0.9080477356910706, 'Val/mean f1': 0.9480774402618408, 'Val/mean precision': 0.9551060199737549, 'Val/mean recall': 0.9411516785621643, 'Val/mean hd95_metric': 13.794590950012207}
Epoch [275/300] Training [1/62] Loss: 0.03657 
Epoch [275/300] Training [2/62] Loss: 0.03519 
Epoch [275/300] Training [3/62] Loss: 0.02180 
Epoch [275/300] Training [4/62] Loss: 0.03425 
Epoch [275/300] Training [5/62] Loss: 0.02715 
Epoch [275/300] Training [6/62] Loss: 0.03945 
Epoch [275/300] Training [7/62] Loss: 0.03406 
Epoch [275/300] Training [8/62] Loss: 0.07290 
Epoch [275/300] Training [9/62] Loss: 0.03871 
Epoch [275/300] Training [10/62] Loss: 0.02916 
Epoch [275/300] Training [11/62] Loss: 0.02589 
Epoch [275/300] Training [12/62] Loss: 0.02113 
Epoch [275/300] Training [13/62] Loss: 0.02733 
Epoch [275/300] Training [14/62] Loss: 0.02369 
Epoch [275/300] Training [15/62] Loss: 0.05920 
Epoch [275/300] Training [16/62] Loss: 0.02820 
Epoch [275/300] Training [17/62] Loss: 0.03186 
Epoch [275/300] Training [18/62] Loss: 0.04921 
Epoch [275/300] Training [19/62] Loss: 0.03887 
Epoch [275/300] Training [20/62] Loss: 0.04176 
Epoch [275/300] Training [21/62] Loss: 0.02855 
Epoch [275/300] Training [22/62] Loss: 0.02740 
Epoch [275/300] Training [23/62] Loss: 0.03044 
Epoch [275/300] Training [24/62] Loss: 0.05332 
Epoch [275/300] Training [25/62] Loss: 0.07102 
Epoch [275/300] Training [26/62] Loss: 0.02634 
Epoch [275/300] Training [27/62] Loss: 0.04105 
Epoch [275/300] Training [28/62] Loss: 0.02660 
Epoch [275/300] Training [29/62] Loss: 0.01938 
Epoch [275/300] Training [30/62] Loss: 0.02416 
Epoch [275/300] Training [31/62] Loss: 0.03734 
Epoch [275/300] Training [32/62] Loss: 0.05546 
Epoch [275/300] Training [33/62] Loss: 0.02670 
Epoch [275/300] Training [34/62] Loss: 0.02238 
Epoch [275/300] Training [35/62] Loss: 0.03664 
Epoch [275/300] Training [36/62] Loss: 0.02408 
Epoch [275/300] Training [37/62] Loss: 0.02310 
Epoch [275/300] Training [38/62] Loss: 0.12697 
Epoch [275/300] Training [39/62] Loss: 0.02472 
Epoch [275/300] Training [40/62] Loss: 0.04281 
Epoch [275/300] Training [41/62] Loss: 0.02184 
Epoch [275/300] Training [42/62] Loss: 0.02344 
Epoch [275/300] Training [43/62] Loss: 0.02176 
Epoch [275/300] Training [44/62] Loss: 0.03004 
Epoch [275/300] Training [45/62] Loss: 0.06287 
Epoch [275/300] Training [46/62] Loss: 0.02891 
Epoch [275/300] Training [47/62] Loss: 0.02228 
Epoch [275/300] Training [48/62] Loss: 0.02433 
Epoch [275/300] Training [49/62] Loss: 0.02856 
Epoch [275/300] Training [50/62] Loss: 0.04772 
Epoch [275/300] Training [51/62] Loss: 0.04129 
Epoch [275/300] Training [52/62] Loss: 0.02126 
Epoch [275/300] Training [53/62] Loss: 0.03401 
Epoch [275/300] Training [54/62] Loss: 0.02855 
Epoch [275/300] Training [55/62] Loss: 0.07212 
Epoch [275/300] Training [56/62] Loss: 0.02423 
Epoch [275/300] Training [57/62] Loss: 0.03631 
Epoch [275/300] Training [58/62] Loss: 0.02473 
Epoch [275/300] Training [59/62] Loss: 0.02099 
Epoch [275/300] Training [60/62] Loss: 0.02107 
Epoch [275/300] Training [61/62] Loss: 0.02542 
Epoch [275/300] Training [62/62] Loss: 0.03380 
Epoch [275/300] Training metric {'Train/mean dice_metric': 0.976507306098938, 'Train/mean miou_metric': 0.9567252993583679, 'Train/mean f1': 0.976442813873291, 'Train/mean precision': 0.9721377491950989, 'Train/mean recall': 0.9807863235473633, 'Train/mean hd95_metric': 4.402181625366211}
Epoch [275/300] Validation [1/16] Loss: 0.68675  focal_loss 0.47207  dice_loss 0.21469 
Epoch [275/300] Validation [2/16] Loss: 0.52898  focal_loss 0.24546  dice_loss 0.28351 
Epoch [275/300] Validation [3/16] Loss: 0.66572  focal_loss 0.38299  dice_loss 0.28273 
Epoch [275/300] Validation [4/16] Loss: 0.35470  focal_loss 0.18492  dice_loss 0.16978 
Epoch [275/300] Validation [5/16] Loss: 0.35572  focal_loss 0.14331  dice_loss 0.21240 
Epoch [275/300] Validation [6/16] Loss: 0.29472  focal_loss 0.09845  dice_loss 0.19627 
Epoch [275/300] Validation [7/16] Loss: 0.34959  focal_loss 0.14481  dice_loss 0.20478 
Epoch [275/300] Validation [8/16] Loss: 0.51816  focal_loss 0.21032  dice_loss 0.30784 
Epoch [275/300] Validation [9/16] Loss: 0.20492  focal_loss 0.09039  dice_loss 0.11453 
Epoch [275/300] Validation [10/16] Loss: 0.51128  focal_loss 0.19431  dice_loss 0.31697 
Epoch [275/300] Validation [11/16] Loss: 0.17448  focal_loss 0.07532  dice_loss 0.09916 
Epoch [275/300] Validation [12/16] Loss: 0.49686  focal_loss 0.13267  dice_loss 0.36419 
Epoch [275/300] Validation [13/16] Loss: 0.27210  focal_loss 0.11127  dice_loss 0.16083 
Epoch [275/300] Validation [14/16] Loss: 0.58448  focal_loss 0.28008  dice_loss 0.30440 
Epoch [275/300] Validation [15/16] Loss: 0.16240  focal_loss 0.06431  dice_loss 0.09810 
Epoch [275/300] Validation [16/16] Loss: 0.11156  focal_loss 0.03992  dice_loss 0.07164 
Epoch [275/300] Validation metric {'Val/mean dice_metric': 0.9377896189689636, 'Val/mean miou_metric': 0.9048241376876831, 'Val/mean f1': 0.947348952293396, 'Val/mean precision': 0.9529425501823425, 'Val/mean recall': 0.9418206810951233, 'Val/mean hd95_metric': 13.903363227844238}
Cheakpoint...
Epoch [275/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9378], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9377896189689636, 'Val/mean miou_metric': 0.9048241376876831, 'Val/mean f1': 0.947348952293396, 'Val/mean precision': 0.9529425501823425, 'Val/mean recall': 0.9418206810951233, 'Val/mean hd95_metric': 13.903363227844238}
Epoch [276/300] Training [1/62] Loss: 0.18232 
Epoch [276/300] Training [2/62] Loss: 0.02625 
Epoch [276/300] Training [3/62] Loss: 0.04272 
Epoch [276/300] Training [4/62] Loss: 0.03465 
Epoch [276/300] Training [5/62] Loss: 0.02595 
Epoch [276/300] Training [6/62] Loss: 0.02678 
Epoch [276/300] Training [7/62] Loss: 0.02257 
Epoch [276/300] Training [8/62] Loss: 0.02837 
Epoch [276/300] Training [9/62] Loss: 0.04789 
Epoch [276/300] Training [10/62] Loss: 0.02551 
Epoch [276/300] Training [11/62] Loss: 0.02262 
Epoch [276/300] Training [12/62] Loss: 0.03771 
Epoch [276/300] Training [13/62] Loss: 0.01944 
Epoch [276/300] Training [14/62] Loss: 0.02326 
Epoch [276/300] Training [15/62] Loss: 0.04540 
Epoch [276/300] Training [16/62] Loss: 0.04003 
Epoch [276/300] Training [17/62] Loss: 0.02697 
Epoch [276/300] Training [18/62] Loss: 0.04913 
Epoch [276/300] Training [19/62] Loss: 0.02717 
Epoch [276/300] Training [20/62] Loss: 0.05053 
Epoch [276/300] Training [21/62] Loss: 0.05564 
Epoch [276/300] Training [22/62] Loss: 0.03215 
Epoch [276/300] Training [23/62] Loss: 0.02487 
Epoch [276/300] Training [24/62] Loss: 0.04509 
Epoch [276/300] Training [25/62] Loss: 0.02237 
Epoch [276/300] Training [26/62] Loss: 0.03260 
Epoch [276/300] Training [27/62] Loss: 0.03412 
Epoch [276/300] Training [28/62] Loss: 0.03741 
Epoch [276/300] Training [29/62] Loss: 0.03743 
Epoch [276/300] Training [30/62] Loss: 0.03086 
Epoch [276/300] Training [31/62] Loss: 0.02832 
Epoch [276/300] Training [32/62] Loss: 0.03217 
Epoch [276/300] Training [33/62] Loss: 0.03813 
Epoch [276/300] Training [34/62] Loss: 0.01895 
Epoch [276/300] Training [35/62] Loss: 0.03393 
Epoch [276/300] Training [36/62] Loss: 0.02509 
Epoch [276/300] Training [37/62] Loss: 0.03967 
Epoch [276/300] Training [38/62] Loss: 0.03089 
Epoch [276/300] Training [39/62] Loss: 0.02402 
Epoch [276/300] Training [40/62] Loss: 0.02986 
Epoch [276/300] Training [41/62] Loss: 0.03354 
Epoch [276/300] Training [42/62] Loss: 0.02456 
Epoch [276/300] Training [43/62] Loss: 0.04205 
Epoch [276/300] Training [44/62] Loss: 0.02270 
Epoch [276/300] Training [45/62] Loss: 0.02432 
Epoch [276/300] Training [46/62] Loss: 0.02401 
Epoch [276/300] Training [47/62] Loss: 0.05704 
Epoch [276/300] Training [48/62] Loss: 0.02823 
Epoch [276/300] Training [49/62] Loss: 0.04262 
Epoch [276/300] Training [50/62] Loss: 0.04431 
Epoch [276/300] Training [51/62] Loss: 0.06726 
Epoch [276/300] Training [52/62] Loss: 0.03030 
Epoch [276/300] Training [53/62] Loss: 0.05028 
Epoch [276/300] Training [54/62] Loss: 0.02275 
Epoch [276/300] Training [55/62] Loss: 0.03940 
Epoch [276/300] Training [56/62] Loss: 0.02839 
Epoch [276/300] Training [57/62] Loss: 0.02958 
Epoch [276/300] Training [58/62] Loss: 0.02753 
Epoch [276/300] Training [59/62] Loss: 0.04390 
Epoch [276/300] Training [60/62] Loss: 0.03492 
Epoch [276/300] Training [61/62] Loss: 0.02355 
Epoch [276/300] Training [62/62] Loss: 0.03269 
Epoch [276/300] Training metric {'Train/mean dice_metric': 0.9762367010116577, 'Train/mean miou_metric': 0.9558525085449219, 'Train/mean f1': 0.9759350419044495, 'Train/mean precision': 0.9709473848342896, 'Train/mean recall': 0.9809742569923401, 'Train/mean hd95_metric': 4.672388076782227}
Epoch [276/300] Validation [1/16] Loss: 0.73667  focal_loss 0.50792  dice_loss 0.22874 
Epoch [276/300] Validation [2/16] Loss: 0.63057  focal_loss 0.27565  dice_loss 0.35491 
Epoch [276/300] Validation [3/16] Loss: 0.65850  focal_loss 0.38157  dice_loss 0.27693 
Epoch [276/300] Validation [4/16] Loss: 0.30521  focal_loss 0.16405  dice_loss 0.14116 
Epoch [276/300] Validation [5/16] Loss: 0.35052  focal_loss 0.15811  dice_loss 0.19241 
Epoch [276/300] Validation [6/16] Loss: 0.28507  focal_loss 0.09270  dice_loss 0.19237 
Epoch [276/300] Validation [7/16] Loss: 0.22159  focal_loss 0.10977  dice_loss 0.11182 
Epoch [276/300] Validation [8/16] Loss: 0.53053  focal_loss 0.22188  dice_loss 0.30866 
Epoch [276/300] Validation [9/16] Loss: 0.24265  focal_loss 0.11495  dice_loss 0.12770 
Epoch [276/300] Validation [10/16] Loss: 0.54618  focal_loss 0.20637  dice_loss 0.33981 
Epoch [276/300] Validation [11/16] Loss: 0.15233  focal_loss 0.05772  dice_loss 0.09461 
Epoch [276/300] Validation [12/16] Loss: 0.50889  focal_loss 0.13573  dice_loss 0.37316 
Epoch [276/300] Validation [13/16] Loss: 0.31211  focal_loss 0.13306  dice_loss 0.17905 
Epoch [276/300] Validation [14/16] Loss: 0.65190  focal_loss 0.30125  dice_loss 0.35065 
Epoch [276/300] Validation [15/16] Loss: 0.12160  focal_loss 0.05139  dice_loss 0.07021 
Epoch [276/300] Validation [16/16] Loss: 0.12286  focal_loss 0.04697  dice_loss 0.07590 
Epoch [276/300] Validation metric {'Val/mean dice_metric': 0.9374114274978638, 'Val/mean miou_metric': 0.9042530059814453, 'Val/mean f1': 0.946269690990448, 'Val/mean precision': 0.9522849917411804, 'Val/mean recall': 0.9403300285339355, 'Val/mean hd95_metric': 13.778763771057129}
Cheakpoint...
Epoch [276/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9374], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9374114274978638, 'Val/mean miou_metric': 0.9042530059814453, 'Val/mean f1': 0.946269690990448, 'Val/mean precision': 0.9522849917411804, 'Val/mean recall': 0.9403300285339355, 'Val/mean hd95_metric': 13.778763771057129}
Epoch [277/300] Training [1/62] Loss: 0.03361 
Epoch [277/300] Training [2/62] Loss: 0.02223 
Epoch [277/300] Training [3/62] Loss: 0.03184 
Epoch [277/300] Training [4/62] Loss: 0.02508 
Epoch [277/300] Training [5/62] Loss: 0.02331 
Epoch [277/300] Training [6/62] Loss: 0.02720 
Epoch [277/300] Training [7/62] Loss: 0.02594 
Epoch [277/300] Training [8/62] Loss: 0.01776 
Epoch [277/300] Training [9/62] Loss: 0.03170 
Epoch [277/300] Training [10/62] Loss: 0.01865 
Epoch [277/300] Training [11/62] Loss: 0.01728 
Epoch [277/300] Training [12/62] Loss: 0.02404 
Epoch [277/300] Training [13/62] Loss: 0.04526 
Epoch [277/300] Training [14/62] Loss: 0.01779 
Epoch [277/300] Training [15/62] Loss: 0.06412 
Epoch [277/300] Training [16/62] Loss: 0.03612 
Epoch [277/300] Training [17/62] Loss: 0.02887 
Epoch [277/300] Training [18/62] Loss: 0.06294 
Epoch [277/300] Training [19/62] Loss: 0.03090 
Epoch [277/300] Training [20/62] Loss: 0.06439 
Epoch [277/300] Training [21/62] Loss: 0.03497 
Epoch [277/300] Training [22/62] Loss: 0.02079 
Epoch [277/300] Training [23/62] Loss: 0.03645 
Epoch [277/300] Training [24/62] Loss: 0.02817 
Epoch [277/300] Training [25/62] Loss: 0.01959 
Epoch [277/300] Training [26/62] Loss: 0.02566 
Epoch [277/300] Training [27/62] Loss: 0.07122 
Epoch [277/300] Training [28/62] Loss: 0.08662 
Epoch [277/300] Training [29/62] Loss: 0.02100 
Epoch [277/300] Training [30/62] Loss: 0.02369 
Epoch [277/300] Training [31/62] Loss: 0.03310 
Epoch [277/300] Training [32/62] Loss: 0.01791 
Epoch [277/300] Training [33/62] Loss: 0.04875 
Epoch [277/300] Training [34/62] Loss: 0.02841 
Epoch [277/300] Training [35/62] Loss: 0.05326 
Epoch [277/300] Training [36/62] Loss: 0.02982 
Epoch [277/300] Training [37/62] Loss: 0.02709 
Epoch [277/300] Training [38/62] Loss: 0.02937 
Epoch [277/300] Training [39/62] Loss: 0.03575 
Epoch [277/300] Training [40/62] Loss: 0.02428 
Epoch [277/300] Training [41/62] Loss: 0.04272 
Epoch [277/300] Training [42/62] Loss: 0.03799 
Epoch [277/300] Training [43/62] Loss: 0.04938 
Epoch [277/300] Training [44/62] Loss: 0.03238 
Epoch [277/300] Training [45/62] Loss: 0.06334 
Epoch [277/300] Training [46/62] Loss: 0.02220 
Epoch [277/300] Training [47/62] Loss: 0.02523 
Epoch [277/300] Training [48/62] Loss: 0.02197 
Epoch [277/300] Training [49/62] Loss: 0.01903 
Epoch [277/300] Training [50/62] Loss: 0.05622 
Epoch [277/300] Training [51/62] Loss: 0.01916 
Epoch [277/300] Training [52/62] Loss: 0.02166 
Epoch [277/300] Training [53/62] Loss: 0.03542 
Epoch [277/300] Training [54/62] Loss: 0.02321 
Epoch [277/300] Training [55/62] Loss: 0.02660 
Epoch [277/300] Training [56/62] Loss: 0.04666 
Epoch [277/300] Training [57/62] Loss: 0.02591 
Epoch [277/300] Training [58/62] Loss: 0.02326 
Epoch [277/300] Training [59/62] Loss: 0.01799 
Epoch [277/300] Training [60/62] Loss: 0.02424 
Epoch [277/300] Training [61/62] Loss: 0.02445 
Epoch [277/300] Training [62/62] Loss: 0.01832 
Epoch [277/300] Training metric {'Train/mean dice_metric': 0.9779587984085083, 'Train/mean miou_metric': 0.9585773348808289, 'Train/mean f1': 0.9781113266944885, 'Train/mean precision': 0.9741401076316833, 'Train/mean recall': 0.9821150898933411, 'Train/mean hd95_metric': 5.137354850769043}
Epoch [277/300] Validation [1/16] Loss: 0.74725  focal_loss 0.50918  dice_loss 0.23807 
Epoch [277/300] Validation [2/16] Loss: 0.50015  focal_loss 0.22872  dice_loss 0.27142 
Epoch [277/300] Validation [3/16] Loss: 0.73208  focal_loss 0.44647  dice_loss 0.28561 
Epoch [277/300] Validation [4/16] Loss: 0.31548  focal_loss 0.17528  dice_loss 0.14020 
Epoch [277/300] Validation [5/16] Loss: 0.31944  focal_loss 0.13658  dice_loss 0.18286 
Epoch [277/300] Validation [6/16] Loss: 0.29112  focal_loss 0.10063  dice_loss 0.19049 
Epoch [277/300] Validation [7/16] Loss: 0.34894  focal_loss 0.13983  dice_loss 0.20910 
Epoch [277/300] Validation [8/16] Loss: 0.54931  focal_loss 0.22945  dice_loss 0.31986 
Epoch [277/300] Validation [9/16] Loss: 0.21513  focal_loss 0.09677  dice_loss 0.11836 
Epoch [277/300] Validation [10/16] Loss: 0.51386  focal_loss 0.18699  dice_loss 0.32687 
Epoch [277/300] Validation [11/16] Loss: 0.16851  focal_loss 0.07013  dice_loss 0.09839 
Epoch [277/300] Validation [12/16] Loss: 0.41743  focal_loss 0.14408  dice_loss 0.27335 
Epoch [277/300] Validation [13/16] Loss: 0.26120  focal_loss 0.10386  dice_loss 0.15734 
Epoch [277/300] Validation [14/16] Loss: 0.57728  focal_loss 0.28316  dice_loss 0.29412 
Epoch [277/300] Validation [15/16] Loss: 0.14296  focal_loss 0.06179  dice_loss 0.08117 
Epoch [277/300] Validation [16/16] Loss: 0.10356  focal_loss 0.03974  dice_loss 0.06382 
Epoch [277/300] Validation metric {'Val/mean dice_metric': 0.9409273266792297, 'Val/mean miou_metric': 0.9086238145828247, 'Val/mean f1': 0.9488743543624878, 'Val/mean precision': 0.9569130539894104, 'Val/mean recall': 0.940969705581665, 'Val/mean hd95_metric': 13.894901275634766}
Cheakpoint...
Epoch [277/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9409], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9409273266792297, 'Val/mean miou_metric': 0.9086238145828247, 'Val/mean f1': 0.9488743543624878, 'Val/mean precision': 0.9569130539894104, 'Val/mean recall': 0.940969705581665, 'Val/mean hd95_metric': 13.894901275634766}
Epoch [278/300] Training [1/62] Loss: 0.03968 
Epoch [278/300] Training [2/62] Loss: 0.03747 
Epoch [278/300] Training [3/62] Loss: 0.04763 
Epoch [278/300] Training [4/62] Loss: 0.16216 
Epoch [278/300] Training [5/62] Loss: 0.03460 
Epoch [278/300] Training [6/62] Loss: 0.04925 
Epoch [278/300] Training [7/62] Loss: 0.02919 
Epoch [278/300] Training [8/62] Loss: 0.04456 
Epoch [278/300] Training [9/62] Loss: 0.02757 
Epoch [278/300] Training [10/62] Loss: 0.03441 
Epoch [278/300] Training [11/62] Loss: 0.02012 
Epoch [278/300] Training [12/62] Loss: 0.01964 
Epoch [278/300] Training [13/62] Loss: 0.02076 
Epoch [278/300] Training [14/62] Loss: 0.02493 
Epoch [278/300] Training [15/62] Loss: 0.04139 
Epoch [278/300] Training [16/62] Loss: 0.03329 
Epoch [278/300] Training [17/62] Loss: 0.03962 
Epoch [278/300] Training [18/62] Loss: 0.04322 
Epoch [278/300] Training [19/62] Loss: 0.02804 
Epoch [278/300] Training [20/62] Loss: 0.02474 
Epoch [278/300] Training [21/62] Loss: 0.02829 
Epoch [278/300] Training [22/62] Loss: 0.04836 
Epoch [278/300] Training [23/62] Loss: 0.04625 
Epoch [278/300] Training [24/62] Loss: 0.03544 
Epoch [278/300] Training [25/62] Loss: 0.02116 
Epoch [278/300] Training [26/62] Loss: 0.02438 
Epoch [278/300] Training [27/62] Loss: 0.03775 
Epoch [278/300] Training [28/62] Loss: 0.02170 
Epoch [278/300] Training [29/62] Loss: 0.02245 
Epoch [278/300] Training [30/62] Loss: 0.03536 
Epoch [278/300] Training [31/62] Loss: 0.03692 
Epoch [278/300] Training [32/62] Loss: 0.03121 
Epoch [278/300] Training [33/62] Loss: 0.02855 
Epoch [278/300] Training [34/62] Loss: 0.01819 
Epoch [278/300] Training [35/62] Loss: 0.08434 
Epoch [278/300] Training [36/62] Loss: 0.02708 
Epoch [278/300] Training [37/62] Loss: 0.02409 
Epoch [278/300] Training [38/62] Loss: 0.02233 
Epoch [278/300] Training [39/62] Loss: 0.06481 
Epoch [278/300] Training [40/62] Loss: 0.02438 
Epoch [278/300] Training [41/62] Loss: 0.02290 
Epoch [278/300] Training [42/62] Loss: 0.04392 
Epoch [278/300] Training [43/62] Loss: 0.04150 
Epoch [278/300] Training [44/62] Loss: 0.02165 
Epoch [278/300] Training [45/62] Loss: 0.02932 
Epoch [278/300] Training [46/62] Loss: 0.02775 
Epoch [278/300] Training [47/62] Loss: 0.01985 
Epoch [278/300] Training [48/62] Loss: 0.03009 
Epoch [278/300] Training [49/62] Loss: 0.02412 
Epoch [278/300] Training [50/62] Loss: 0.04915 
Epoch [278/300] Training [51/62] Loss: 0.02148 
Epoch [278/300] Training [52/62] Loss: 0.02831 
Epoch [278/300] Training [53/62] Loss: 0.03400 
Epoch [278/300] Training [54/62] Loss: 0.03703 
Epoch [278/300] Training [55/62] Loss: 0.03018 
Epoch [278/300] Training [56/62] Loss: 0.02375 
Epoch [278/300] Training [57/62] Loss: 0.03512 
Epoch [278/300] Training [58/62] Loss: 0.03497 
Epoch [278/300] Training [59/62] Loss: 0.02487 
Epoch [278/300] Training [60/62] Loss: 0.04840 
Epoch [278/300] Training [61/62] Loss: 0.06381 
Epoch [278/300] Training [62/62] Loss: 0.06159 
Epoch [278/300] Training metric {'Train/mean dice_metric': 0.9758518934249878, 'Train/mean miou_metric': 0.9553846716880798, 'Train/mean f1': 0.9763092994689941, 'Train/mean precision': 0.9729316830635071, 'Train/mean recall': 0.9797102808952332, 'Train/mean hd95_metric': 4.41888427734375}
Epoch [278/300] Validation [1/16] Loss: 0.73993  focal_loss 0.51341  dice_loss 0.22652 
Epoch [278/300] Validation [2/16] Loss: 0.53490  focal_loss 0.23651  dice_loss 0.29839 
Epoch [278/300] Validation [3/16] Loss: 0.74428  focal_loss 0.46293  dice_loss 0.28135 
Epoch [278/300] Validation [4/16] Loss: 0.30755  focal_loss 0.17049  dice_loss 0.13705 
Epoch [278/300] Validation [5/16] Loss: 0.32670  focal_loss 0.13475  dice_loss 0.19195 
Epoch [278/300] Validation [6/16] Loss: 0.34650  focal_loss 0.13156  dice_loss 0.21494 
Epoch [278/300] Validation [7/16] Loss: 0.21015  focal_loss 0.10209  dice_loss 0.10806 
Epoch [278/300] Validation [8/16] Loss: 0.44353  focal_loss 0.17971  dice_loss 0.26382 
Epoch [278/300] Validation [9/16] Loss: 0.27347  focal_loss 0.13156  dice_loss 0.14191 
Epoch [278/300] Validation [10/16] Loss: 0.55895  focal_loss 0.21702  dice_loss 0.34193 
Epoch [278/300] Validation [11/16] Loss: 0.16084  focal_loss 0.06326  dice_loss 0.09758 
Epoch [278/300] Validation [12/16] Loss: 0.41089  focal_loss 0.14244  dice_loss 0.26845 
Epoch [278/300] Validation [13/16] Loss: 0.26160  focal_loss 0.09932  dice_loss 0.16227 
Epoch [278/300] Validation [14/16] Loss: 0.54472  focal_loss 0.23224  dice_loss 0.31248 
Epoch [278/300] Validation [15/16] Loss: 0.11137  focal_loss 0.04460  dice_loss 0.06677 
Epoch [278/300] Validation [16/16] Loss: 0.10410  focal_loss 0.03876  dice_loss 0.06534 
Epoch [278/300] Validation metric {'Val/mean dice_metric': 0.9402443170547485, 'Val/mean miou_metric': 0.9066630601882935, 'Val/mean f1': 0.9471270442008972, 'Val/mean precision': 0.9526625275611877, 'Val/mean recall': 0.9416555762290955, 'Val/mean hd95_metric': 14.183531761169434}
Cheakpoint...
Epoch [278/300] best acc:tensor([0.9426], device='cuda:0'), Now : mean acc: tensor([0.9402], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9402443170547485, 'Val/mean miou_metric': 0.9066630601882935, 'Val/mean f1': 0.9471270442008972, 'Val/mean precision': 0.9526625275611877, 'Val/mean recall': 0.9416555762290955, 'Val/mean hd95_metric': 14.183531761169434}
Epoch [279/300] Training [1/62] Loss: 0.02137 
Epoch [279/300] Training [2/62] Loss: 0.04548 
Epoch [279/300] Training [3/62] Loss: 0.02106 
Epoch [279/300] Training [4/62] Loss: 0.06815 
Epoch [279/300] Training [5/62] Loss: 0.02468 
Epoch [279/300] Training [6/62] Loss: 0.02717 
Epoch [279/300] Training [7/62] Loss: 0.03019 
Epoch [279/300] Training [8/62] Loss: 0.02315 
Epoch [279/300] Training [9/62] Loss: 0.05299 
Epoch [279/300] Training [10/62] Loss: 0.02073 
Epoch [279/300] Training [11/62] Loss: 0.05035 
Epoch [279/300] Training [12/62] Loss: 0.05261 
Epoch [279/300] Training [13/62] Loss: 0.04087 
Epoch [279/300] Training [14/62] Loss: 0.04872 
Epoch [279/300] Training [15/62] Loss: 0.02735 
Epoch [279/300] Training [16/62] Loss: 0.01995 
Epoch [279/300] Training [17/62] Loss: 0.02290 
Epoch [279/300] Training [18/62] Loss: 0.02686 
Epoch [279/300] Training [19/62] Loss: 0.02177 
Epoch [279/300] Training [20/62] Loss: 0.04095 
Epoch [279/300] Training [21/62] Loss: 0.02544 
Epoch [279/300] Training [22/62] Loss: 0.08202 
Epoch [279/300] Training [23/62] Loss: 0.04386 
Epoch [279/300] Training [24/62] Loss: 0.02052 
Epoch [279/300] Training [25/62] Loss: 0.02113 
Epoch [279/300] Training [26/62] Loss: 0.02663 
Epoch [279/300] Training [27/62] Loss: 0.02431 
Epoch [279/300] Training [28/62] Loss: 0.02287 
Epoch [279/300] Training [29/62] Loss: 0.02253 
Epoch [279/300] Training [30/62] Loss: 0.03520 
Epoch [279/300] Training [31/62] Loss: 0.02966 
Epoch [279/300] Training [32/62] Loss: 0.02653 
Epoch [279/300] Training [33/62] Loss: 0.04911 
Epoch [279/300] Training [34/62] Loss: 0.02230 
Epoch [279/300] Training [35/62] Loss: 0.02073 
Epoch [279/300] Training [36/62] Loss: 0.03153 
Epoch [279/300] Training [37/62] Loss: 0.03468 
Epoch [279/300] Training [38/62] Loss: 0.02037 
Epoch [279/300] Training [39/62] Loss: 0.02379 
Epoch [279/300] Training [40/62] Loss: 0.02075 
Epoch [279/300] Training [41/62] Loss: 0.02238 
Epoch [279/300] Training [42/62] Loss: 0.02985 
Epoch [279/300] Training [43/62] Loss: 0.02236 
Epoch [279/300] Training [44/62] Loss: 0.02569 
Epoch [279/300] Training [45/62] Loss: 0.03237 
Epoch [279/300] Training [46/62] Loss: 0.02585 
Epoch [279/300] Training [47/62] Loss: 0.03091 
Epoch [279/300] Training [48/62] Loss: 0.01829 
Epoch [279/300] Training [49/62] Loss: 0.02124 
Epoch [279/300] Training [50/62] Loss: 0.09260 
Epoch [279/300] Training [51/62] Loss: 0.03665 
Epoch [279/300] Training [52/62] Loss: 0.07206 
Epoch [279/300] Training [53/62] Loss: 0.02404 
Epoch [279/300] Training [54/62] Loss: 0.05440 
Epoch [279/300] Training [55/62] Loss: 0.02351 
Epoch [279/300] Training [56/62] Loss: 0.02579 
Epoch [279/300] Training [57/62] Loss: 0.02713 
Epoch [279/300] Training [58/62] Loss: 0.02372 
Epoch [279/300] Training [59/62] Loss: 0.02297 
Epoch [279/300] Training [60/62] Loss: 0.02466 
Epoch [279/300] Training [61/62] Loss: 0.05707 
Epoch [279/300] Training [62/62] Loss: 0.09840 
Epoch [279/300] Training metric {'Train/mean dice_metric': 0.977800190448761, 'Train/mean miou_metric': 0.9581397175788879, 'Train/mean f1': 0.9777432084083557, 'Train/mean precision': 0.9730915427207947, 'Train/mean recall': 0.9824396371841431, 'Train/mean hd95_metric': 4.944757461547852}
Epoch [279/300] Validation [1/16] Loss: 0.66310  focal_loss 0.46456  dice_loss 0.19854 
Epoch [279/300] Validation [2/16] Loss: 0.47907  focal_loss 0.21798  dice_loss 0.26108 
Epoch [279/300] Validation [3/16] Loss: 0.76624  focal_loss 0.46627  dice_loss 0.29997 
Epoch [279/300] Validation [4/16] Loss: 0.31216  focal_loss 0.17348  dice_loss 0.13869 
Epoch [279/300] Validation [5/16] Loss: 0.36174  focal_loss 0.14463  dice_loss 0.21712 
Epoch [279/300] Validation [6/16] Loss: 0.30415  focal_loss 0.10401  dice_loss 0.20014 
Epoch [279/300] Validation [7/16] Loss: 0.21965  focal_loss 0.10791  dice_loss 0.11174 
Epoch [279/300] Validation [8/16] Loss: 0.42537  focal_loss 0.16789  dice_loss 0.25747 
Epoch [279/300] Validation [9/16] Loss: 0.27824  focal_loss 0.14029  dice_loss 0.13796 
Epoch [279/300] Validation [10/16] Loss: 0.54720  focal_loss 0.21120  dice_loss 0.33600 
Epoch [279/300] Validation [11/16] Loss: 0.17229  focal_loss 0.07563  dice_loss 0.09665 
Epoch [279/300] Validation [12/16] Loss: 0.42716  focal_loss 0.14729  dice_loss 0.27987 
Epoch [279/300] Validation [13/16] Loss: 0.25118  focal_loss 0.10199  dice_loss 0.14918 
Epoch [279/300] Validation [14/16] Loss: 0.56044  focal_loss 0.26898  dice_loss 0.29146 
Epoch [279/300] Validation [15/16] Loss: 0.10829  focal_loss 0.04378  dice_loss 0.06451 
Epoch [279/300] Validation [16/16] Loss: 0.12147  focal_loss 0.04250  dice_loss 0.07897 
Epoch [279/300] Validation metric {'Val/mean dice_metric': 0.9427424669265747, 'Val/mean miou_metric': 0.9100593328475952, 'Val/mean f1': 0.9496439695358276, 'Val/mean precision': 0.9541620016098022, 'Val/mean recall': 0.9451686143875122, 'Val/mean hd95_metric': 14.514311790466309}
Cheakpoint...
Epoch [279/300] best acc:tensor([0.9427], device='cuda:0'), Now : mean acc: tensor([0.9427], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9427424669265747, 'Val/mean miou_metric': 0.9100593328475952, 'Val/mean f1': 0.9496439695358276, 'Val/mean precision': 0.9541620016098022, 'Val/mean recall': 0.9451686143875122, 'Val/mean hd95_metric': 14.514311790466309}
Epoch [280/300] Training [1/62] Loss: 0.01886 
Epoch [280/300] Training [2/62] Loss: 0.02691 
Epoch [280/300] Training [3/62] Loss: 0.03409 
Epoch [280/300] Training [4/62] Loss: 0.02199 
Epoch [280/300] Training [5/62] Loss: 0.02960 
Epoch [280/300] Training [6/62] Loss: 0.05932 
Epoch [280/300] Training [7/62] Loss: 0.03172 
Epoch [280/300] Training [8/62] Loss: 0.02130 
Epoch [280/300] Training [9/62] Loss: 0.02377 
Epoch [280/300] Training [10/62] Loss: 0.04806 
Epoch [280/300] Training [11/62] Loss: 0.01928 
Epoch [280/300] Training [12/62] Loss: 0.02257 
Epoch [280/300] Training [13/62] Loss: 0.03342 
Epoch [280/300] Training [14/62] Loss: 0.02632 
Epoch [280/300] Training [15/62] Loss: 0.07563 
Epoch [280/300] Training [16/62] Loss: 0.03304 
Epoch [280/300] Training [17/62] Loss: 0.05167 
Epoch [280/300] Training [18/62] Loss: 0.01812 
Epoch [280/300] Training [19/62] Loss: 0.01922 
Epoch [280/300] Training [20/62] Loss: 0.02579 
Epoch [280/300] Training [21/62] Loss: 0.01811 
Epoch [280/300] Training [22/62] Loss: 0.02678 
Epoch [280/300] Training [23/62] Loss: 0.06004 
Epoch [280/300] Training [24/62] Loss: 0.02078 
Epoch [280/300] Training [25/62] Loss: 0.06834 
Epoch [280/300] Training [26/62] Loss: 0.02219 
Epoch [280/300] Training [27/62] Loss: 0.04021 
Epoch [280/300] Training [28/62] Loss: 0.02150 
Epoch [280/300] Training [29/62] Loss: 0.05213 
Epoch [280/300] Training [30/62] Loss: 0.03359 
Epoch [280/300] Training [31/62] Loss: 0.04786 
Epoch [280/300] Training [32/62] Loss: 0.03028 
Epoch [280/300] Training [33/62] Loss: 0.03194 
Epoch [280/300] Training [34/62] Loss: 0.02055 
Epoch [280/300] Training [35/62] Loss: 0.02994 
Epoch [280/300] Training [36/62] Loss: 0.02903 
Epoch [280/300] Training [37/62] Loss: 0.02379 
Epoch [280/300] Training [38/62] Loss: 0.03153 
Epoch [280/300] Training [39/62] Loss: 0.05235 
Epoch [280/300] Training [40/62] Loss: 0.02492 
Epoch [280/300] Training [41/62] Loss: 0.03228 
Epoch [280/300] Training [42/62] Loss: 0.02066 
Epoch [280/300] Training [43/62] Loss: 0.03559 
Epoch [280/300] Training [44/62] Loss: 0.03647 
Epoch [280/300] Training [45/62] Loss: 0.02439 
Epoch [280/300] Training [46/62] Loss: 0.02568 
Epoch [280/300] Training [47/62] Loss: 0.02102 
Epoch [280/300] Training [48/62] Loss: 0.02311 
Epoch [280/300] Training [49/62] Loss: 0.03600 
Epoch [280/300] Training [50/62] Loss: 0.05721 
Epoch [280/300] Training [51/62] Loss: 0.04231 
Epoch [280/300] Training [52/62] Loss: 0.02000 
Epoch [280/300] Training [53/62] Loss: 0.02736 
Epoch [280/300] Training [54/62] Loss: 0.02389 
Epoch [280/300] Training [55/62] Loss: 0.03037 
Epoch [280/300] Training [56/62] Loss: 0.03191 
Epoch [280/300] Training [57/62] Loss: 0.04146 
Epoch [280/300] Training [58/62] Loss: 0.02186 
Epoch [280/300] Training [59/62] Loss: 0.05075 
Epoch [280/300] Training [60/62] Loss: 0.02366 
Epoch [280/300] Training [61/62] Loss: 0.03199 
Epoch [280/300] Training [62/62] Loss: 0.04991 
Epoch [280/300] Training metric {'Train/mean dice_metric': 0.9788045287132263, 'Train/mean miou_metric': 0.9592754244804382, 'Train/mean f1': 0.9767167568206787, 'Train/mean precision': 0.973243236541748, 'Train/mean recall': 0.9802152514457703, 'Train/mean hd95_metric': 4.682832717895508}
Epoch [280/300] Validation [1/16] Loss: 0.64835  focal_loss 0.45597  dice_loss 0.19238 
Epoch [280/300] Validation [2/16] Loss: 0.59423  focal_loss 0.25202  dice_loss 0.34221 
Epoch [280/300] Validation [3/16] Loss: 0.67463  focal_loss 0.39711  dice_loss 0.27753 
Epoch [280/300] Validation [4/16] Loss: 0.30842  focal_loss 0.16846  dice_loss 0.13995 
Epoch [280/300] Validation [5/16] Loss: 0.35561  focal_loss 0.15013  dice_loss 0.20548 
Epoch [280/300] Validation [6/16] Loss: 0.30755  focal_loss 0.09819  dice_loss 0.20936 
Epoch [280/300] Validation [7/16] Loss: 0.33087  focal_loss 0.13276  dice_loss 0.19811 
Epoch [280/300] Validation [8/16] Loss: 0.56550  focal_loss 0.23079  dice_loss 0.33471 
Epoch [280/300] Validation [9/16] Loss: 0.21671  focal_loss 0.09675  dice_loss 0.11995 
Epoch [280/300] Validation [10/16] Loss: 0.56138  focal_loss 0.20504  dice_loss 0.35633 
Epoch [280/300] Validation [11/16] Loss: 0.16634  focal_loss 0.06689  dice_loss 0.09945 
Epoch [280/300] Validation [12/16] Loss: 0.38772  focal_loss 0.12280  dice_loss 0.26492 
Epoch [280/300] Validation [13/16] Loss: 0.24096  focal_loss 0.09970  dice_loss 0.14126 
Epoch [280/300] Validation [14/16] Loss: 0.55425  focal_loss 0.25482  dice_loss 0.29943 
Epoch [280/300] Validation [15/16] Loss: 0.13033  focal_loss 0.05562  dice_loss 0.07471 
Epoch [280/300] Validation [16/16] Loss: 0.12800  focal_loss 0.04864  dice_loss 0.07936 
Epoch [280/300] Validation metric {'Val/mean dice_metric': 0.9405956268310547, 'Val/mean miou_metric': 0.9081616401672363, 'Val/mean f1': 0.9489304423332214, 'Val/mean precision': 0.9566386342048645, 'Val/mean recall': 0.9413455724716187, 'Val/mean hd95_metric': 14.40556812286377}
Cheakpoint...
Epoch [280/300] best acc:tensor([0.9427], device='cuda:0'), Now : mean acc: tensor([0.9406], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9405956268310547, 'Val/mean miou_metric': 0.9081616401672363, 'Val/mean f1': 0.9489304423332214, 'Val/mean precision': 0.9566386342048645, 'Val/mean recall': 0.9413455724716187, 'Val/mean hd95_metric': 14.40556812286377}
Epoch [281/300] Training [1/62] Loss: 0.02651 
Epoch [281/300] Training [2/62] Loss: 0.01770 
Epoch [281/300] Training [3/62] Loss: 0.06622 
Epoch [281/300] Training [4/62] Loss: 0.03779 
Epoch [281/300] Training [5/62] Loss: 0.04587 
Epoch [281/300] Training [6/62] Loss: 0.02199 
Epoch [281/300] Training [7/62] Loss: 0.06455 
Epoch [281/300] Training [8/62] Loss: 0.02364 
Epoch [281/300] Training [9/62] Loss: 0.02152 
Epoch [281/300] Training [10/62] Loss: 0.05141 
Epoch [281/300] Training [11/62] Loss: 0.02861 
Epoch [281/300] Training [12/62] Loss: 0.03625 
Epoch [281/300] Training [13/62] Loss: 0.04393 
Epoch [281/300] Training [14/62] Loss: 0.02253 
Epoch [281/300] Training [15/62] Loss: 0.03582 
Epoch [281/300] Training [16/62] Loss: 0.03235 
Epoch [281/300] Training [17/62] Loss: 0.02773 
Epoch [281/300] Training [18/62] Loss: 0.02796 
Epoch [281/300] Training [19/62] Loss: 0.01983 
Epoch [281/300] Training [20/62] Loss: 0.02895 
Epoch [281/300] Training [21/62] Loss: 0.02100 
Epoch [281/300] Training [22/62] Loss: 0.06390 
Epoch [281/300] Training [23/62] Loss: 0.03668 
Epoch [281/300] Training [24/62] Loss: 0.05693 
Epoch [281/300] Training [25/62] Loss: 0.06964 
Epoch [281/300] Training [26/62] Loss: 0.02732 
Epoch [281/300] Training [27/62] Loss: 0.03676 
Epoch [281/300] Training [28/62] Loss: 0.02795 
Epoch [281/300] Training [29/62] Loss: 0.08070 
Epoch [281/300] Training [30/62] Loss: 0.02875 
Epoch [281/300] Training [31/62] Loss: 0.04471 
Epoch [281/300] Training [32/62] Loss: 0.02264 
Epoch [281/300] Training [33/62] Loss: 0.02162 
Epoch [281/300] Training [34/62] Loss: 0.01947 
Epoch [281/300] Training [35/62] Loss: 0.02939 
Epoch [281/300] Training [36/62] Loss: 0.02167 
Epoch [281/300] Training [37/62] Loss: 0.02808 
Epoch [281/300] Training [38/62] Loss: 0.02343 
Epoch [281/300] Training [39/62] Loss: 0.02779 
Epoch [281/300] Training [40/62] Loss: 0.02859 
Epoch [281/300] Training [41/62] Loss: 0.07699 
Epoch [281/300] Training [42/62] Loss: 0.02331 
Epoch [281/300] Training [43/62] Loss: 0.03576 
Epoch [281/300] Training [44/62] Loss: 0.05702 
Epoch [281/300] Training [45/62] Loss: 0.03480 
Epoch [281/300] Training [46/62] Loss: 0.01678 
Epoch [281/300] Training [47/62] Loss: 0.02718 
Epoch [281/300] Training [48/62] Loss: 0.02104 
Epoch [281/300] Training [49/62] Loss: 0.03392 
Epoch [281/300] Training [50/62] Loss: 0.01956 
Epoch [281/300] Training [51/62] Loss: 0.07286 
Epoch [281/300] Training [52/62] Loss: 0.03137 
Epoch [281/300] Training [53/62] Loss: 0.03440 
Epoch [281/300] Training [54/62] Loss: 0.04370 
Epoch [281/300] Training [55/62] Loss: 0.04497 
Epoch [281/300] Training [56/62] Loss: 0.03705 
Epoch [281/300] Training [57/62] Loss: 0.02681 
Epoch [281/300] Training [58/62] Loss: 0.03660 
Epoch [281/300] Training [59/62] Loss: 0.02707 
Epoch [281/300] Training [60/62] Loss: 0.02280 
Epoch [281/300] Training [61/62] Loss: 0.04677 
Epoch [281/300] Training [62/62] Loss: 0.06236 
Epoch [281/300] Training metric {'Train/mean dice_metric': 0.9763917922973633, 'Train/mean miou_metric': 0.9555904269218445, 'Train/mean f1': 0.9754900336265564, 'Train/mean precision': 0.97110515832901, 'Train/mean recall': 0.9799146056175232, 'Train/mean hd95_metric': 5.081284999847412}
Epoch [281/300] Validation [1/16] Loss: 0.63954  focal_loss 0.44322  dice_loss 0.19632 
Epoch [281/300] Validation [2/16] Loss: 0.49938  focal_loss 0.21469  dice_loss 0.28469 
Epoch [281/300] Validation [3/16] Loss: 0.74228  focal_loss 0.47102  dice_loss 0.27127 
Epoch [281/300] Validation [4/16] Loss: 0.31460  focal_loss 0.17448  dice_loss 0.14012 
Epoch [281/300] Validation [5/16] Loss: 0.37950  focal_loss 0.16781  dice_loss 0.21170 
Epoch [281/300] Validation [6/16] Loss: 0.28791  focal_loss 0.09895  dice_loss 0.18897 
Epoch [281/300] Validation [7/16] Loss: 0.22868  focal_loss 0.11234  dice_loss 0.11634 
Epoch [281/300] Validation [8/16] Loss: 0.52622  focal_loss 0.21317  dice_loss 0.31305 
Epoch [281/300] Validation [9/16] Loss: 0.23330  focal_loss 0.11513  dice_loss 0.11817 
Epoch [281/300] Validation [10/16] Loss: 0.56704  focal_loss 0.22453  dice_loss 0.34251 
Epoch [281/300] Validation [11/16] Loss: 0.16002  focal_loss 0.06676  dice_loss 0.09326 
Epoch [281/300] Validation [12/16] Loss: 0.52670  focal_loss 0.15162  dice_loss 0.37507 
Epoch [281/300] Validation [13/16] Loss: 0.26768  focal_loss 0.10841  dice_loss 0.15927 
Epoch [281/300] Validation [14/16] Loss: 0.59884  focal_loss 0.28342  dice_loss 0.31543 
Epoch [281/300] Validation [15/16] Loss: 0.16261  focal_loss 0.07665  dice_loss 0.08595 
Epoch [281/300] Validation [16/16] Loss: 0.14880  focal_loss 0.05739  dice_loss 0.09141 
Epoch [281/300] Validation metric {'Val/mean dice_metric': 0.9392412900924683, 'Val/mean miou_metric': 0.9054710865020752, 'Val/mean f1': 0.9470845460891724, 'Val/mean precision': 0.9524169564247131, 'Val/mean recall': 0.9418115019798279, 'Val/mean hd95_metric': 14.440587997436523}
Cheakpoint...
Epoch [281/300] best acc:tensor([0.9427], device='cuda:0'), Now : mean acc: tensor([0.9392], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9392412900924683, 'Val/mean miou_metric': 0.9054710865020752, 'Val/mean f1': 0.9470845460891724, 'Val/mean precision': 0.9524169564247131, 'Val/mean recall': 0.9418115019798279, 'Val/mean hd95_metric': 14.440587997436523}
Epoch [282/300] Training [1/62] Loss: 0.03451 
Epoch [282/300] Training [2/62] Loss: 0.03036 
Epoch [282/300] Training [3/62] Loss: 0.05835 
Epoch [282/300] Training [4/62] Loss: 0.01906 
Epoch [282/300] Training [5/62] Loss: 0.02693 
Epoch [282/300] Training [6/62] Loss: 0.02446 
Epoch [282/300] Training [7/62] Loss: 0.01953 
Epoch [282/300] Training [8/62] Loss: 0.02737 
Epoch [282/300] Training [9/62] Loss: 0.02603 
Epoch [282/300] Training [10/62] Loss: 0.03959 
Epoch [282/300] Training [11/62] Loss: 0.02205 
Epoch [282/300] Training [12/62] Loss: 0.02546 
Epoch [282/300] Training [13/62] Loss: 0.06162 
Epoch [282/300] Training [14/62] Loss: 0.03186 
Epoch [282/300] Training [15/62] Loss: 0.05463 
Epoch [282/300] Training [16/62] Loss: 0.02590 
Epoch [282/300] Training [17/62] Loss: 0.02601 
Epoch [282/300] Training [18/62] Loss: 0.03334 
Epoch [282/300] Training [19/62] Loss: 0.02158 
Epoch [282/300] Training [20/62] Loss: 0.01713 
Epoch [282/300] Training [21/62] Loss: 0.04749 
Epoch [282/300] Training [22/62] Loss: 0.02289 
Epoch [282/300] Training [23/62] Loss: 0.02594 
Epoch [282/300] Training [24/62] Loss: 0.01841 
Epoch [282/300] Training [25/62] Loss: 0.02021 
Epoch [282/300] Training [26/62] Loss: 0.02154 
Epoch [282/300] Training [27/62] Loss: 0.02753 
Epoch [282/300] Training [28/62] Loss: 0.04177 
Epoch [282/300] Training [29/62] Loss: 0.02985 
Epoch [282/300] Training [30/62] Loss: 0.06248 
Epoch [282/300] Training [31/62] Loss: 0.03797 
Epoch [282/300] Training [32/62] Loss: 0.01764 
Epoch [282/300] Training [33/62] Loss: 0.02966 
Epoch [282/300] Training [34/62] Loss: 0.02433 
Epoch [282/300] Training [35/62] Loss: 0.01920 
Epoch [282/300] Training [36/62] Loss: 0.03333 
Epoch [282/300] Training [37/62] Loss: 0.03566 
Epoch [282/300] Training [38/62] Loss: 0.03616 
Epoch [282/300] Training [39/62] Loss: 0.02254 
Epoch [282/300] Training [40/62] Loss: 0.02778 
Epoch [282/300] Training [41/62] Loss: 0.02223 
Epoch [282/300] Training [42/62] Loss: 0.04590 
Epoch [282/300] Training [43/62] Loss: 0.02331 
Epoch [282/300] Training [44/62] Loss: 0.03579 
Epoch [282/300] Training [45/62] Loss: 0.03129 
Epoch [282/300] Training [46/62] Loss: 0.01996 
Epoch [282/300] Training [47/62] Loss: 0.02058 
Epoch [282/300] Training [48/62] Loss: 0.02492 
Epoch [282/300] Training [49/62] Loss: 0.03681 
Epoch [282/300] Training [50/62] Loss: 0.01869 
Epoch [282/300] Training [51/62] Loss: 0.04410 
Epoch [282/300] Training [52/62] Loss: 0.03679 
Epoch [282/300] Training [53/62] Loss: 0.02787 
Epoch [282/300] Training [54/62] Loss: 0.03648 
Epoch [282/300] Training [55/62] Loss: 0.02106 
Epoch [282/300] Training [56/62] Loss: 0.03916 
Epoch [282/300] Training [57/62] Loss: 0.01840 
Epoch [282/300] Training [58/62] Loss: 0.05099 
Epoch [282/300] Training [59/62] Loss: 0.03943 
Epoch [282/300] Training [60/62] Loss: 0.09576 
Epoch [282/300] Training [61/62] Loss: 0.03788 
Epoch [282/300] Training [62/62] Loss: 0.04723 
Epoch [282/300] Training metric {'Train/mean dice_metric': 0.9789477586746216, 'Train/mean miou_metric': 0.9596796035766602, 'Train/mean f1': 0.9775564074516296, 'Train/mean precision': 0.9737325310707092, 'Train/mean recall': 0.9814104437828064, 'Train/mean hd95_metric': 4.990089416503906}
Epoch [282/300] Validation [1/16] Loss: 0.65990  focal_loss 0.45912  dice_loss 0.20078 
Epoch [282/300] Validation [2/16] Loss: 0.62853  focal_loss 0.27672  dice_loss 0.35182 
Epoch [282/300] Validation [3/16] Loss: 0.64597  focal_loss 0.35531  dice_loss 0.29066 
Epoch [282/300] Validation [4/16] Loss: 0.30592  focal_loss 0.16828  dice_loss 0.13764 
Epoch [282/300] Validation [5/16] Loss: 0.33014  focal_loss 0.13589  dice_loss 0.19425 
Epoch [282/300] Validation [6/16] Loss: 0.30129  focal_loss 0.10370  dice_loss 0.19759 
Epoch [282/300] Validation [7/16] Loss: 0.27504  focal_loss 0.11701  dice_loss 0.15803 
Epoch [282/300] Validation [8/16] Loss: 0.54778  focal_loss 0.22793  dice_loss 0.31986 
Epoch [282/300] Validation [9/16] Loss: 0.22303  focal_loss 0.09983  dice_loss 0.12320 
Epoch [282/300] Validation [10/16] Loss: 0.54217  focal_loss 0.20864  dice_loss 0.33353 
Epoch [282/300] Validation [11/16] Loss: 0.16848  focal_loss 0.06585  dice_loss 0.10263 
Epoch [282/300] Validation [12/16] Loss: 0.42153  focal_loss 0.14497  dice_loss 0.27656 
Epoch [282/300] Validation [13/16] Loss: 0.26864  focal_loss 0.10416  dice_loss 0.16448 
Epoch [282/300] Validation [14/16] Loss: 0.53600  focal_loss 0.25955  dice_loss 0.27645 
Epoch [282/300] Validation [15/16] Loss: 0.12348  focal_loss 0.05314  dice_loss 0.07034 
Epoch [282/300] Validation [16/16] Loss: 0.12100  focal_loss 0.04251  dice_loss 0.07849 
Epoch [282/300] Validation metric {'Val/mean dice_metric': 0.9414870142936707, 'Val/mean miou_metric': 0.9087336659431458, 'Val/mean f1': 0.9485611915588379, 'Val/mean precision': 0.954428493976593, 'Val/mean recall': 0.9427657127380371, 'Val/mean hd95_metric': 15.320487976074219}
Cheakpoint...
Epoch [282/300] best acc:tensor([0.9427], device='cuda:0'), Now : mean acc: tensor([0.9415], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9414870142936707, 'Val/mean miou_metric': 0.9087336659431458, 'Val/mean f1': 0.9485611915588379, 'Val/mean precision': 0.954428493976593, 'Val/mean recall': 0.9427657127380371, 'Val/mean hd95_metric': 15.320487976074219}
Epoch [283/300] Training [1/62] Loss: 0.01670 
Epoch [283/300] Training [2/62] Loss: 0.04061 
Epoch [283/300] Training [3/62] Loss: 0.03066 
Epoch [283/300] Training [4/62] Loss: 0.05446 
Epoch [283/300] Training [5/62] Loss: 0.02871 
Epoch [283/300] Training [6/62] Loss: 0.02855 
Epoch [283/300] Training [7/62] Loss: 0.02329 
Epoch [283/300] Training [8/62] Loss: 0.02435 
Epoch [283/300] Training [9/62] Loss: 0.02273 
Epoch [283/300] Training [10/62] Loss: 0.03483 
Epoch [283/300] Training [11/62] Loss: 0.02834 
Epoch [283/300] Training [12/62] Loss: 0.02280 
Epoch [283/300] Training [13/62] Loss: 0.01907 
Epoch [283/300] Training [14/62] Loss: 0.07649 
Epoch [283/300] Training [15/62] Loss: 0.02580 
Epoch [283/300] Training [16/62] Loss: 0.02516 
Epoch [283/300] Training [17/62] Loss: 0.02037 
Epoch [283/300] Training [18/62] Loss: 0.03615 
Epoch [283/300] Training [19/62] Loss: 0.03305 
Epoch [283/300] Training [20/62] Loss: 0.03951 
Epoch [283/300] Training [21/62] Loss: 0.01977 
Epoch [283/300] Training [22/62] Loss: 0.02264 
Epoch [283/300] Training [23/62] Loss: 0.02196 
Epoch [283/300] Training [24/62] Loss: 0.02640 
Epoch [283/300] Training [25/62] Loss: 0.04577 
Epoch [283/300] Training [26/62] Loss: 0.06400 
Epoch [283/300] Training [27/62] Loss: 0.01905 
Epoch [283/300] Training [28/62] Loss: 0.04271 
Epoch [283/300] Training [29/62] Loss: 0.02887 
Epoch [283/300] Training [30/62] Loss: 0.02296 
Epoch [283/300] Training [31/62] Loss: 0.02789 
Epoch [283/300] Training [32/62] Loss: 0.02784 
Epoch [283/300] Training [33/62] Loss: 0.03490 
Epoch [283/300] Training [34/62] Loss: 0.04601 
Epoch [283/300] Training [35/62] Loss: 0.02322 
Epoch [283/300] Training [36/62] Loss: 0.03872 
Epoch [283/300] Training [37/62] Loss: 0.03113 
Epoch [283/300] Training [38/62] Loss: 0.03632 
Epoch [283/300] Training [39/62] Loss: 0.02834 
Epoch [283/300] Training [40/62] Loss: 0.06055 
Epoch [283/300] Training [41/62] Loss: 0.02216 
Epoch [283/300] Training [42/62] Loss: 0.02451 
Epoch [283/300] Training [43/62] Loss: 0.02684 
Epoch [283/300] Training [44/62] Loss: 0.03498 
Epoch [283/300] Training [45/62] Loss: 0.02269 
Epoch [283/300] Training [46/62] Loss: 0.02239 
Epoch [283/300] Training [47/62] Loss: 0.02377 
Epoch [283/300] Training [48/62] Loss: 0.02440 
Epoch [283/300] Training [49/62] Loss: 0.02904 
Epoch [283/300] Training [50/62] Loss: 0.02763 
Epoch [283/300] Training [51/62] Loss: 0.02780 
Epoch [283/300] Training [52/62] Loss: 0.02331 
Epoch [283/300] Training [53/62] Loss: 0.02794 
Epoch [283/300] Training [54/62] Loss: 0.02547 
Epoch [283/300] Training [55/62] Loss: 0.02624 
Epoch [283/300] Training [56/62] Loss: 0.03387 
Epoch [283/300] Training [57/62] Loss: 0.02097 
Epoch [283/300] Training [58/62] Loss: 0.02747 
Epoch [283/300] Training [59/62] Loss: 0.03155 
Epoch [283/300] Training [60/62] Loss: 0.03423 
Epoch [283/300] Training [61/62] Loss: 0.03508 
Epoch [283/300] Training [62/62] Loss: 0.01400 
Epoch [283/300] Training metric {'Train/mean dice_metric': 0.979721188545227, 'Train/mean miou_metric': 0.9612492918968201, 'Train/mean f1': 0.9785049557685852, 'Train/mean precision': 0.9742475152015686, 'Train/mean recall': 0.9827997088432312, 'Train/mean hd95_metric': 4.415498733520508}
Epoch [283/300] Validation [1/16] Loss: 0.70630  focal_loss 0.48875  dice_loss 0.21755 
Epoch [283/300] Validation [2/16] Loss: 0.59977  focal_loss 0.25628  dice_loss 0.34349 
Epoch [283/300] Validation [3/16] Loss: 0.77362  focal_loss 0.47547  dice_loss 0.29815 
Epoch [283/300] Validation [4/16] Loss: 0.30715  focal_loss 0.16542  dice_loss 0.14172 
Epoch [283/300] Validation [5/16] Loss: 0.34828  focal_loss 0.14443  dice_loss 0.20385 
Epoch [283/300] Validation [6/16] Loss: 0.28219  focal_loss 0.09666  dice_loss 0.18553 
Epoch [283/300] Validation [7/16] Loss: 0.27277  focal_loss 0.11677  dice_loss 0.15600 
Epoch [283/300] Validation [8/16] Loss: 0.51817  focal_loss 0.21957  dice_loss 0.29859 
Epoch [283/300] Validation [9/16] Loss: 0.21106  focal_loss 0.09717  dice_loss 0.11389 
Epoch [283/300] Validation [10/16] Loss: 0.49195  focal_loss 0.17671  dice_loss 0.31524 
Epoch [283/300] Validation [11/16] Loss: 0.15961  focal_loss 0.06287  dice_loss 0.09674 
Epoch [283/300] Validation [12/16] Loss: 0.40812  focal_loss 0.14090  dice_loss 0.26723 
Epoch [283/300] Validation [13/16] Loss: 0.26315  focal_loss 0.10545  dice_loss 0.15770 
Epoch [283/300] Validation [14/16] Loss: 0.61811  focal_loss 0.28919  dice_loss 0.32892 
Epoch [283/300] Validation [15/16] Loss: 0.11284  focal_loss 0.04900  dice_loss 0.06384 
Epoch [283/300] Validation [16/16] Loss: 0.13678  focal_loss 0.05437  dice_loss 0.08241 
Epoch [283/300] Validation metric {'Val/mean dice_metric': 0.94217848777771, 'Val/mean miou_metric': 0.9103463292121887, 'Val/mean f1': 0.9498781561851501, 'Val/mean precision': 0.9564685821533203, 'Val/mean recall': 0.9433779120445251, 'Val/mean hd95_metric': 13.850814819335938}
Cheakpoint...
Epoch [283/300] best acc:tensor([0.9427], device='cuda:0'), Now : mean acc: tensor([0.9422], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.94217848777771, 'Val/mean miou_metric': 0.9103463292121887, 'Val/mean f1': 0.9498781561851501, 'Val/mean precision': 0.9564685821533203, 'Val/mean recall': 0.9433779120445251, 'Val/mean hd95_metric': 13.850814819335938}
Epoch [284/300] Training [1/62] Loss: 0.03067 
Epoch [284/300] Training [2/62] Loss: 0.01968 
Epoch [284/300] Training [3/62] Loss: 0.03494 
Epoch [284/300] Training [4/62] Loss: 0.02343 
Epoch [284/300] Training [5/62] Loss: 0.02948 
Epoch [284/300] Training [6/62] Loss: 0.04404 
Epoch [284/300] Training [7/62] Loss: 0.01881 
Epoch [284/300] Training [8/62] Loss: 0.03139 
Epoch [284/300] Training [9/62] Loss: 0.02860 
Epoch [284/300] Training [10/62] Loss: 0.02542 
Epoch [284/300] Training [11/62] Loss: 0.02172 
Epoch [284/300] Training [12/62] Loss: 0.02249 
Epoch [284/300] Training [13/62] Loss: 0.02666 
Epoch [284/300] Training [14/62] Loss: 0.02868 
Epoch [284/300] Training [15/62] Loss: 0.02394 
Epoch [284/300] Training [16/62] Loss: 0.02107 
Epoch [284/300] Training [17/62] Loss: 0.02696 
Epoch [284/300] Training [18/62] Loss: 0.02550 
Epoch [284/300] Training [19/62] Loss: 0.02846 
Epoch [284/300] Training [20/62] Loss: 0.02889 
Epoch [284/300] Training [21/62] Loss: 0.02090 
Epoch [284/300] Training [22/62] Loss: 0.02499 
Epoch [284/300] Training [23/62] Loss: 0.02683 
Epoch [284/300] Training [24/62] Loss: 0.06198 
Epoch [284/300] Training [25/62] Loss: 0.03187 
Epoch [284/300] Training [26/62] Loss: 0.02595 
Epoch [284/300] Training [27/62] Loss: 0.02932 
Epoch [284/300] Training [28/62] Loss: 0.02420 
Epoch [284/300] Training [29/62] Loss: 0.02959 
Epoch [284/300] Training [30/62] Loss: 0.01830 
Epoch [284/300] Training [31/62] Loss: 0.02341 
Epoch [284/300] Training [32/62] Loss: 0.04114 
Epoch [284/300] Training [33/62] Loss: 0.02788 
Epoch [284/300] Training [34/62] Loss: 0.02031 
Epoch [284/300] Training [35/62] Loss: 0.02135 
Epoch [284/300] Training [36/62] Loss: 0.02510 
Epoch [284/300] Training [37/62] Loss: 0.02600 
Epoch [284/300] Training [38/62] Loss: 0.02373 
Epoch [284/300] Training [39/62] Loss: 0.04212 
Epoch [284/300] Training [40/62] Loss: 0.02273 
Epoch [284/300] Training [41/62] Loss: 0.02755 
Epoch [284/300] Training [42/62] Loss: 0.02894 
Epoch [284/300] Training [43/62] Loss: 0.06643 
Epoch [284/300] Training [44/62] Loss: 0.07889 
Epoch [284/300] Training [45/62] Loss: 0.03984 
Epoch [284/300] Training [46/62] Loss: 0.02880 
Epoch [284/300] Training [47/62] Loss: 0.03032 
Epoch [284/300] Training [48/62] Loss: 0.02428 
Epoch [284/300] Training [49/62] Loss: 0.02741 
Epoch [284/300] Training [50/62] Loss: 0.06136 
Epoch [284/300] Training [51/62] Loss: 0.05364 
Epoch [284/300] Training [52/62] Loss: 0.02998 
Epoch [284/300] Training [53/62] Loss: 0.02479 
Epoch [284/300] Training [54/62] Loss: 0.01803 
Epoch [284/300] Training [55/62] Loss: 0.02748 
Epoch [284/300] Training [56/62] Loss: 0.03500 
Epoch [284/300] Training [57/62] Loss: 0.02901 
Epoch [284/300] Training [58/62] Loss: 0.03036 
Epoch [284/300] Training [59/62] Loss: 0.02179 
Epoch [284/300] Training [60/62] Loss: 0.02433 
Epoch [284/300] Training [61/62] Loss: 0.04732 
Epoch [284/300] Training [62/62] Loss: 0.14990 
Epoch [284/300] Training metric {'Train/mean dice_metric': 0.9800822138786316, 'Train/mean miou_metric': 0.9616517424583435, 'Train/mean f1': 0.9779608845710754, 'Train/mean precision': 0.9743924140930176, 'Train/mean recall': 0.981555700302124, 'Train/mean hd95_metric': 3.873326063156128}
Epoch [284/300] Validation [1/16] Loss: 0.68217  focal_loss 0.47420  dice_loss 0.20798 
Epoch [284/300] Validation [2/16] Loss: 0.52679  focal_loss 0.23349  dice_loss 0.29331 
Epoch [284/300] Validation [3/16] Loss: 0.71876  focal_loss 0.44500  dice_loss 0.27376 
Epoch [284/300] Validation [4/16] Loss: 0.31541  focal_loss 0.17508  dice_loss 0.14033 
Epoch [284/300] Validation [5/16] Loss: 0.36246  focal_loss 0.16475  dice_loss 0.19772 
Epoch [284/300] Validation [6/16] Loss: 0.30315  focal_loss 0.10417  dice_loss 0.19898 
Epoch [284/300] Validation [7/16] Loss: 0.19635  focal_loss 0.08968  dice_loss 0.10668 
Epoch [284/300] Validation [8/16] Loss: 0.52896  focal_loss 0.22204  dice_loss 0.30692 
Epoch [284/300] Validation [9/16] Loss: 0.20061  focal_loss 0.09176  dice_loss 0.10885 
Epoch [284/300] Validation [10/16] Loss: 0.60151  focal_loss 0.23742  dice_loss 0.36409 
Epoch [284/300] Validation [11/16] Loss: 0.15114  focal_loss 0.06207  dice_loss 0.08907 
Epoch [284/300] Validation [12/16] Loss: 0.38304  focal_loss 0.12299  dice_loss 0.26005 
Epoch [284/300] Validation [13/16] Loss: 0.29175  focal_loss 0.12024  dice_loss 0.17151 
Epoch [284/300] Validation [14/16] Loss: 0.52688  focal_loss 0.24120  dice_loss 0.28568 
Epoch [284/300] Validation [15/16] Loss: 0.10077  focal_loss 0.04010  dice_loss 0.06067 
Epoch [284/300] Validation [16/16] Loss: 0.09821  focal_loss 0.03710  dice_loss 0.06111 
Epoch [284/300] Validation metric {'Val/mean dice_metric': 0.9442289471626282, 'Val/mean miou_metric': 0.9133356809616089, 'Val/mean f1': 0.9501060843467712, 'Val/mean precision': 0.9557749629020691, 'Val/mean recall': 0.9445040822029114, 'Val/mean hd95_metric': 12.401506423950195}
Cheakpoint...
Epoch [284/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9442], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9442289471626282, 'Val/mean miou_metric': 0.9133356809616089, 'Val/mean f1': 0.9501060843467712, 'Val/mean precision': 0.9557749629020691, 'Val/mean recall': 0.9445040822029114, 'Val/mean hd95_metric': 12.401506423950195}
Epoch [285/300] Training [1/62] Loss: 0.02635 
Epoch [285/300] Training [2/62] Loss: 0.03442 
Epoch [285/300] Training [3/62] Loss: 0.03802 
Epoch [285/300] Training [4/62] Loss: 0.02767 
Epoch [285/300] Training [5/62] Loss: 0.02926 
Epoch [285/300] Training [6/62] Loss: 0.04361 
Epoch [285/300] Training [7/62] Loss: 0.02675 
Epoch [285/300] Training [8/62] Loss: 0.03020 
Epoch [285/300] Training [9/62] Loss: 0.02311 
Epoch [285/300] Training [10/62] Loss: 0.02014 
Epoch [285/300] Training [11/62] Loss: 0.01929 
Epoch [285/300] Training [12/62] Loss: 0.01974 
Epoch [285/300] Training [13/62] Loss: 0.05110 
Epoch [285/300] Training [14/62] Loss: 0.02083 
Epoch [285/300] Training [15/62] Loss: 0.06073 
Epoch [285/300] Training [16/62] Loss: 0.11836 
Epoch [285/300] Training [17/62] Loss: 0.05824 
Epoch [285/300] Training [18/62] Loss: 0.02203 
Epoch [285/300] Training [19/62] Loss: 0.02233 
Epoch [285/300] Training [20/62] Loss: 0.01932 
Epoch [285/300] Training [21/62] Loss: 0.04017 
Epoch [285/300] Training [22/62] Loss: 0.02256 
Epoch [285/300] Training [23/62] Loss: 0.05379 
Epoch [285/300] Training [24/62] Loss: 0.02063 
Epoch [285/300] Training [25/62] Loss: 0.02430 
Epoch [285/300] Training [26/62] Loss: 0.02515 
Epoch [285/300] Training [27/62] Loss: 0.03440 
Epoch [285/300] Training [28/62] Loss: 0.02982 
Epoch [285/300] Training [29/62] Loss: 0.03431 
Epoch [285/300] Training [30/62] Loss: 0.03305 
Epoch [285/300] Training [31/62] Loss: 0.06484 
Epoch [285/300] Training [32/62] Loss: 0.02461 
Epoch [285/300] Training [33/62] Loss: 0.02457 
Epoch [285/300] Training [34/62] Loss: 0.07526 
Epoch [285/300] Training [35/62] Loss: 0.02426 
Epoch [285/300] Training [36/62] Loss: 0.02922 
Epoch [285/300] Training [37/62] Loss: 0.07733 
Epoch [285/300] Training [38/62] Loss: 0.03705 
Epoch [285/300] Training [39/62] Loss: 0.02260 
Epoch [285/300] Training [40/62] Loss: 0.03977 
Epoch [285/300] Training [41/62] Loss: 0.02918 
Epoch [285/300] Training [42/62] Loss: 0.02403 
Epoch [285/300] Training [43/62] Loss: 0.02947 
Epoch [285/300] Training [44/62] Loss: 0.04942 
Epoch [285/300] Training [45/62] Loss: 0.02561 
Epoch [285/300] Training [46/62] Loss: 0.02118 
Epoch [285/300] Training [47/62] Loss: 0.03567 
Epoch [285/300] Training [48/62] Loss: 0.15567 
Epoch [285/300] Training [49/62] Loss: 0.03063 
Epoch [285/300] Training [50/62] Loss: 0.03685 
Epoch [285/300] Training [51/62] Loss: 0.04495 
Epoch [285/300] Training [52/62] Loss: 0.05018 
Epoch [285/300] Training [53/62] Loss: 0.02248 
Epoch [285/300] Training [54/62] Loss: 0.02514 
Epoch [285/300] Training [55/62] Loss: 0.02364 
Epoch [285/300] Training [56/62] Loss: 0.02365 
Epoch [285/300] Training [57/62] Loss: 0.01897 
Epoch [285/300] Training [58/62] Loss: 0.02278 
Epoch [285/300] Training [59/62] Loss: 0.02506 
Epoch [285/300] Training [60/62] Loss: 0.03910 
Epoch [285/300] Training [61/62] Loss: 0.03016 
Epoch [285/300] Training [62/62] Loss: 0.04639 
Epoch [285/300] Training metric {'Train/mean dice_metric': 0.9751833081245422, 'Train/mean miou_metric': 0.955069899559021, 'Train/mean f1': 0.9766552448272705, 'Train/mean precision': 0.9721211791038513, 'Train/mean recall': 0.9812318086624146, 'Train/mean hd95_metric': 5.982222557067871}
Epoch [285/300] Validation [1/16] Loss: 0.62230  focal_loss 0.43819  dice_loss 0.18410 
Epoch [285/300] Validation [2/16] Loss: 0.47116  focal_loss 0.20910  dice_loss 0.26206 
Epoch [285/300] Validation [3/16] Loss: 0.69125  focal_loss 0.40827  dice_loss 0.28298 
Epoch [285/300] Validation [4/16] Loss: 0.35304  focal_loss 0.18711  dice_loss 0.16593 
Epoch [285/300] Validation [5/16] Loss: 0.32213  focal_loss 0.13779  dice_loss 0.18435 
Epoch [285/300] Validation [6/16] Loss: 0.29608  focal_loss 0.10101  dice_loss 0.19507 
Epoch [285/300] Validation [7/16] Loss: 0.33967  focal_loss 0.14736  dice_loss 0.19231 
Epoch [285/300] Validation [8/16] Loss: 0.57576  focal_loss 0.22866  dice_loss 0.34710 
Epoch [285/300] Validation [9/16] Loss: 0.26989  focal_loss 0.13143  dice_loss 0.13845 
Epoch [285/300] Validation [10/16] Loss: 0.57544  focal_loss 0.20895  dice_loss 0.36650 
Epoch [285/300] Validation [11/16] Loss: 0.16485  focal_loss 0.06241  dice_loss 0.10243 
Epoch [285/300] Validation [12/16] Loss: 0.49735  focal_loss 0.11646  dice_loss 0.38089 
Epoch [285/300] Validation [13/16] Loss: 0.29259  focal_loss 0.11312  dice_loss 0.17946 
Epoch [285/300] Validation [14/16] Loss: 0.49572  focal_loss 0.23086  dice_loss 0.26486 
Epoch [285/300] Validation [15/16] Loss: 0.10460  focal_loss 0.04194  dice_loss 0.06266 
Epoch [285/300] Validation [16/16] Loss: 0.10466  focal_loss 0.03864  dice_loss 0.06602 
Epoch [285/300] Validation metric {'Val/mean dice_metric': 0.9370730519294739, 'Val/mean miou_metric': 0.9037814736366272, 'Val/mean f1': 0.9482859373092651, 'Val/mean precision': 0.952971875667572, 'Val/mean recall': 0.943645715713501, 'Val/mean hd95_metric': 15.365500450134277}
Cheakpoint...
Epoch [285/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9371], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9370730519294739, 'Val/mean miou_metric': 0.9037814736366272, 'Val/mean f1': 0.9482859373092651, 'Val/mean precision': 0.952971875667572, 'Val/mean recall': 0.943645715713501, 'Val/mean hd95_metric': 15.365500450134277}
Epoch [286/300] Training [1/62] Loss: 0.02658 
Epoch [286/300] Training [2/62] Loss: 0.02511 
Epoch [286/300] Training [3/62] Loss: 0.02570 
Epoch [286/300] Training [4/62] Loss: 0.02275 
Epoch [286/300] Training [5/62] Loss: 0.04019 
Epoch [286/300] Training [6/62] Loss: 0.03525 
Epoch [286/300] Training [7/62] Loss: 0.04343 
Epoch [286/300] Training [8/62] Loss: 0.02192 
Epoch [286/300] Training [9/62] Loss: 0.03660 
Epoch [286/300] Training [10/62] Loss: 0.02468 
Epoch [286/300] Training [11/62] Loss: 0.03342 
Epoch [286/300] Training [12/62] Loss: 0.02477 
Epoch [286/300] Training [13/62] Loss: 0.02758 
Epoch [286/300] Training [14/62] Loss: 0.02221 
Epoch [286/300] Training [15/62] Loss: 0.03017 
Epoch [286/300] Training [16/62] Loss: 0.02256 
Epoch [286/300] Training [17/62] Loss: 0.02982 
Epoch [286/300] Training [18/62] Loss: 0.02305 
Epoch [286/300] Training [19/62] Loss: 0.01703 
Epoch [286/300] Training [20/62] Loss: 0.03630 
Epoch [286/300] Training [21/62] Loss: 0.02918 
Epoch [286/300] Training [22/62] Loss: 0.02317 
Epoch [286/300] Training [23/62] Loss: 0.02036 
Epoch [286/300] Training [24/62] Loss: 0.04734 
Epoch [286/300] Training [25/62] Loss: 0.10764 
Epoch [286/300] Training [26/62] Loss: 0.02149 
Epoch [286/300] Training [27/62] Loss: 0.11578 
Epoch [286/300] Training [28/62] Loss: 0.03652 
Epoch [286/300] Training [29/62] Loss: 0.02570 
Epoch [286/300] Training [30/62] Loss: 0.06063 
Epoch [286/300] Training [31/62] Loss: 0.02761 
Epoch [286/300] Training [32/62] Loss: 0.04465 
Epoch [286/300] Training [33/62] Loss: 0.02152 
Epoch [286/300] Training [34/62] Loss: 0.05712 
Epoch [286/300] Training [35/62] Loss: 0.02593 
Epoch [286/300] Training [36/62] Loss: 0.03103 
Epoch [286/300] Training [37/62] Loss: 0.03587 
Epoch [286/300] Training [38/62] Loss: 0.03004 
Epoch [286/300] Training [39/62] Loss: 0.02221 
Epoch [286/300] Training [40/62] Loss: 0.02181 
Epoch [286/300] Training [41/62] Loss: 0.05631 
Epoch [286/300] Training [42/62] Loss: 0.04613 
Epoch [286/300] Training [43/62] Loss: 0.02898 
Epoch [286/300] Training [44/62] Loss: 0.03212 
Epoch [286/300] Training [45/62] Loss: 0.04311 
Epoch [286/300] Training [46/62] Loss: 0.02499 
Epoch [286/300] Training [47/62] Loss: 0.03020 
Epoch [286/300] Training [48/62] Loss: 0.02409 
Epoch [286/300] Training [49/62] Loss: 0.01988 
Epoch [286/300] Training [50/62] Loss: 0.04262 
Epoch [286/300] Training [51/62] Loss: 0.04768 
Epoch [286/300] Training [52/62] Loss: 0.02636 
Epoch [286/300] Training [53/62] Loss: 0.01835 
Epoch [286/300] Training [54/62] Loss: 0.03365 
Epoch [286/300] Training [55/62] Loss: 0.02771 
Epoch [286/300] Training [56/62] Loss: 0.04661 
Epoch [286/300] Training [57/62] Loss: 0.01849 
Epoch [286/300] Training [58/62] Loss: 0.01825 
Epoch [286/300] Training [59/62] Loss: 0.02941 
Epoch [286/300] Training [60/62] Loss: 0.02741 
Epoch [286/300] Training [61/62] Loss: 0.02295 
Epoch [286/300] Training [62/62] Loss: 0.04565 
Epoch [286/300] Training metric {'Train/mean dice_metric': 0.9778803586959839, 'Train/mean miou_metric': 0.9580817222595215, 'Train/mean f1': 0.9771620035171509, 'Train/mean precision': 0.9735541939735413, 'Train/mean recall': 0.9807965755462646, 'Train/mean hd95_metric': 4.799997329711914}
Epoch [286/300] Validation [1/16] Loss: 0.68971  focal_loss 0.47672  dice_loss 0.21299 
Epoch [286/300] Validation [2/16] Loss: 0.52261  focal_loss 0.24090  dice_loss 0.28172 
Epoch [286/300] Validation [3/16] Loss: 0.77914  focal_loss 0.48014  dice_loss 0.29900 
Epoch [286/300] Validation [4/16] Loss: 0.32308  focal_loss 0.17710  dice_loss 0.14598 
Epoch [286/300] Validation [5/16] Loss: 0.40797  focal_loss 0.16772  dice_loss 0.24025 
Epoch [286/300] Validation [6/16] Loss: 0.30374  focal_loss 0.10485  dice_loss 0.19890 
Epoch [286/300] Validation [7/16] Loss: 0.28369  focal_loss 0.11710  dice_loss 0.16659 
Epoch [286/300] Validation [8/16] Loss: 0.49642  focal_loss 0.21317  dice_loss 0.28325 
Epoch [286/300] Validation [9/16] Loss: 0.20596  focal_loss 0.09272  dice_loss 0.11324 
Epoch [286/300] Validation [10/16] Loss: 0.54087  focal_loss 0.20208  dice_loss 0.33879 
Epoch [286/300] Validation [11/16] Loss: 0.17953  focal_loss 0.07533  dice_loss 0.10419 
Epoch [286/300] Validation [12/16] Loss: 0.38287  focal_loss 0.12070  dice_loss 0.26217 
Epoch [286/300] Validation [13/16] Loss: 0.33307  focal_loss 0.14486  dice_loss 0.18821 
Epoch [286/300] Validation [14/16] Loss: 0.63064  focal_loss 0.31172  dice_loss 0.31892 
Epoch [286/300] Validation [15/16] Loss: 0.09970  focal_loss 0.03783  dice_loss 0.06187 
Epoch [286/300] Validation [16/16] Loss: 0.11974  focal_loss 0.04427  dice_loss 0.07546 
Epoch [286/300] Validation metric {'Val/mean dice_metric': 0.9404286742210388, 'Val/mean miou_metric': 0.9074833393096924, 'Val/mean f1': 0.9479358196258545, 'Val/mean precision': 0.9549353122711182, 'Val/mean recall': 0.9410382509231567, 'Val/mean hd95_metric': 14.235162734985352}
Cheakpoint...
Epoch [286/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9404], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9404286742210388, 'Val/mean miou_metric': 0.9074833393096924, 'Val/mean f1': 0.9479358196258545, 'Val/mean precision': 0.9549353122711182, 'Val/mean recall': 0.9410382509231567, 'Val/mean hd95_metric': 14.235162734985352}
Epoch [287/300] Training [1/62] Loss: 0.02483 
Epoch [287/300] Training [2/62] Loss: 0.04265 
Epoch [287/300] Training [3/62] Loss: 0.02508 
Epoch [287/300] Training [4/62] Loss: 0.02245 
Epoch [287/300] Training [5/62] Loss: 0.03051 
Epoch [287/300] Training [6/62] Loss: 0.02285 
Epoch [287/300] Training [7/62] Loss: 0.13189 
Epoch [287/300] Training [8/62] Loss: 0.01956 
Epoch [287/300] Training [9/62] Loss: 0.02356 
Epoch [287/300] Training [10/62] Loss: 0.06093 
Epoch [287/300] Training [11/62] Loss: 0.04439 
Epoch [287/300] Training [12/62] Loss: 0.02428 
Epoch [287/300] Training [13/62] Loss: 0.01932 
Epoch [287/300] Training [14/62] Loss: 0.02008 
Epoch [287/300] Training [15/62] Loss: 0.04941 
Epoch [287/300] Training [16/62] Loss: 0.04784 
Epoch [287/300] Training [17/62] Loss: 0.04580 
Epoch [287/300] Training [18/62] Loss: 0.03568 
Epoch [287/300] Training [19/62] Loss: 0.03224 
Epoch [287/300] Training [20/62] Loss: 0.02634 
Epoch [287/300] Training [21/62] Loss: 0.02563 
Epoch [287/300] Training [22/62] Loss: 0.05099 
Epoch [287/300] Training [23/62] Loss: 0.02566 
Epoch [287/300] Training [24/62] Loss: 0.02516 
Epoch [287/300] Training [25/62] Loss: 0.02525 
Epoch [287/300] Training [26/62] Loss: 0.02528 
Epoch [287/300] Training [27/62] Loss: 0.04690 
Epoch [287/300] Training [28/62] Loss: 0.03040 
Epoch [287/300] Training [29/62] Loss: 0.02502 
Epoch [287/300] Training [30/62] Loss: 0.02467 
Epoch [287/300] Training [31/62] Loss: 0.03034 
Epoch [287/300] Training [32/62] Loss: 0.02450 
Epoch [287/300] Training [33/62] Loss: 0.03438 
Epoch [287/300] Training [34/62] Loss: 0.02343 
Epoch [287/300] Training [35/62] Loss: 0.04739 
Epoch [287/300] Training [36/62] Loss: 0.02730 
Epoch [287/300] Training [37/62] Loss: 0.03665 
Epoch [287/300] Training [38/62] Loss: 0.03966 
Epoch [287/300] Training [39/62] Loss: 0.02046 
Epoch [287/300] Training [40/62] Loss: 0.03324 
Epoch [287/300] Training [41/62] Loss: 0.02278 
Epoch [287/300] Training [42/62] Loss: 0.05250 
Epoch [287/300] Training [43/62] Loss: 0.03402 
Epoch [287/300] Training [44/62] Loss: 0.02726 
Epoch [287/300] Training [45/62] Loss: 0.02935 
Epoch [287/300] Training [46/62] Loss: 0.11424 
Epoch [287/300] Training [47/62] Loss: 0.06901 
Epoch [287/300] Training [48/62] Loss: 0.02137 
Epoch [287/300] Training [49/62] Loss: 0.03232 
Epoch [287/300] Training [50/62] Loss: 0.03131 
Epoch [287/300] Training [51/62] Loss: 0.02370 
Epoch [287/300] Training [52/62] Loss: 0.03053 
Epoch [287/300] Training [53/62] Loss: 0.03250 
Epoch [287/300] Training [54/62] Loss: 0.01691 
Epoch [287/300] Training [55/62] Loss: 0.02645 
Epoch [287/300] Training [56/62] Loss: 0.02721 
Epoch [287/300] Training [57/62] Loss: 0.02088 
Epoch [287/300] Training [58/62] Loss: 0.01773 
Epoch [287/300] Training [59/62] Loss: 0.04250 
Epoch [287/300] Training [60/62] Loss: 0.04265 
Epoch [287/300] Training [61/62] Loss: 0.02292 
Epoch [287/300] Training [62/62] Loss: 0.05653 
Epoch [287/300] Training metric {'Train/mean dice_metric': 0.9769792556762695, 'Train/mean miou_metric': 0.957286536693573, 'Train/mean f1': 0.9766014814376831, 'Train/mean precision': 0.972831130027771, 'Train/mean recall': 0.9804012179374695, 'Train/mean hd95_metric': 4.934545040130615}
Epoch [287/300] Validation [1/16] Loss: 0.71925  focal_loss 0.49595  dice_loss 0.22331 
Epoch [287/300] Validation [2/16] Loss: 0.47980  focal_loss 0.21134  dice_loss 0.26846 
Epoch [287/300] Validation [3/16] Loss: 0.63727  focal_loss 0.38162  dice_loss 0.25565 
Epoch [287/300] Validation [4/16] Loss: 0.29914  focal_loss 0.15949  dice_loss 0.13964 
Epoch [287/300] Validation [5/16] Loss: 0.47676  focal_loss 0.16844  dice_loss 0.30831 
Epoch [287/300] Validation [6/16] Loss: 0.26505  focal_loss 0.09280  dice_loss 0.17225 
Epoch [287/300] Validation [7/16] Loss: 0.20656  focal_loss 0.09642  dice_loss 0.11013 
Epoch [287/300] Validation [8/16] Loss: 0.47301  focal_loss 0.18639  dice_loss 0.28662 
Epoch [287/300] Validation [9/16] Loss: 0.23029  focal_loss 0.10078  dice_loss 0.12951 
Epoch [287/300] Validation [10/16] Loss: 0.55334  focal_loss 0.22152  dice_loss 0.33182 
Epoch [287/300] Validation [11/16] Loss: 0.17024  focal_loss 0.06404  dice_loss 0.10620 
Epoch [287/300] Validation [12/16] Loss: 0.36313  focal_loss 0.11274  dice_loss 0.25039 
Epoch [287/300] Validation [13/16] Loss: 0.28525  focal_loss 0.11064  dice_loss 0.17461 
Epoch [287/300] Validation [14/16] Loss: 0.57015  focal_loss 0.27687  dice_loss 0.29328 
Epoch [287/300] Validation [15/16] Loss: 0.09639  focal_loss 0.03831  dice_loss 0.05808 
Epoch [287/300] Validation [16/16] Loss: 0.09857  focal_loss 0.03411  dice_loss 0.06446 
Epoch [287/300] Validation metric {'Val/mean dice_metric': 0.9411798715591431, 'Val/mean miou_metric': 0.9086557030677795, 'Val/mean f1': 0.9484081268310547, 'Val/mean precision': 0.9544656872749329, 'Val/mean recall': 0.9424270391464233, 'Val/mean hd95_metric': 13.835511207580566}
Cheakpoint...
Epoch [287/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9412], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9411798715591431, 'Val/mean miou_metric': 0.9086557030677795, 'Val/mean f1': 0.9484081268310547, 'Val/mean precision': 0.9544656872749329, 'Val/mean recall': 0.9424270391464233, 'Val/mean hd95_metric': 13.835511207580566}
Epoch [288/300] Training [1/62] Loss: 0.03949 
Epoch [288/300] Training [2/62] Loss: 0.03758 
Epoch [288/300] Training [3/62] Loss: 0.03137 
Epoch [288/300] Training [4/62] Loss: 0.03341 
Epoch [288/300] Training [5/62] Loss: 0.01858 
Epoch [288/300] Training [6/62] Loss: 0.02534 
Epoch [288/300] Training [7/62] Loss: 0.03124 
Epoch [288/300] Training [8/62] Loss: 0.01983 
Epoch [288/300] Training [9/62] Loss: 0.02669 
Epoch [288/300] Training [10/62] Loss: 0.03432 
Epoch [288/300] Training [11/62] Loss: 0.04017 
Epoch [288/300] Training [12/62] Loss: 0.02611 
Epoch [288/300] Training [13/62] Loss: 0.04168 
Epoch [288/300] Training [14/62] Loss: 0.02913 
Epoch [288/300] Training [15/62] Loss: 0.02088 
Epoch [288/300] Training [16/62] Loss: 0.04256 
Epoch [288/300] Training [17/62] Loss: 0.02119 
Epoch [288/300] Training [18/62] Loss: 0.02168 
Epoch [288/300] Training [19/62] Loss: 0.03015 
Epoch [288/300] Training [20/62] Loss: 0.02946 
Epoch [288/300] Training [21/62] Loss: 0.02714 
Epoch [288/300] Training [22/62] Loss: 0.02722 
Epoch [288/300] Training [23/62] Loss: 0.02170 
Epoch [288/300] Training [24/62] Loss: 0.02218 
Epoch [288/300] Training [25/62] Loss: 0.04165 
Epoch [288/300] Training [26/62] Loss: 0.02531 
Epoch [288/300] Training [27/62] Loss: 0.04355 
Epoch [288/300] Training [28/62] Loss: 0.01967 
Epoch [288/300] Training [29/62] Loss: 0.03868 
Epoch [288/300] Training [30/62] Loss: 0.02684 
Epoch [288/300] Training [31/62] Loss: 0.02088 
Epoch [288/300] Training [32/62] Loss: 0.04562 
Epoch [288/300] Training [33/62] Loss: 0.02454 
Epoch [288/300] Training [34/62] Loss: 0.02158 
Epoch [288/300] Training [35/62] Loss: 0.02138 
Epoch [288/300] Training [36/62] Loss: 0.03941 
Epoch [288/300] Training [37/62] Loss: 0.03255 
Epoch [288/300] Training [38/62] Loss: 0.02279 
Epoch [288/300] Training [39/62] Loss: 0.02738 
Epoch [288/300] Training [40/62] Loss: 0.02639 
Epoch [288/300] Training [41/62] Loss: 0.03196 
Epoch [288/300] Training [42/62] Loss: 0.04583 
Epoch [288/300] Training [43/62] Loss: 0.12713 
Epoch [288/300] Training [44/62] Loss: 0.05317 
Epoch [288/300] Training [45/62] Loss: 0.03474 
Epoch [288/300] Training [46/62] Loss: 0.02847 
Epoch [288/300] Training [47/62] Loss: 0.02264 
Epoch [288/300] Training [48/62] Loss: 0.04574 
Epoch [288/300] Training [49/62] Loss: 0.03248 
Epoch [288/300] Training [50/62] Loss: 0.01940 
Epoch [288/300] Training [51/62] Loss: 0.02626 
Epoch [288/300] Training [52/62] Loss: 0.02331 
Epoch [288/300] Training [53/62] Loss: 0.04669 
Epoch [288/300] Training [54/62] Loss: 0.04046 
Epoch [288/300] Training [55/62] Loss: 0.02572 
Epoch [288/300] Training [56/62] Loss: 0.02484 
Epoch [288/300] Training [57/62] Loss: 0.06193 
Epoch [288/300] Training [58/62] Loss: 0.02599 
Epoch [288/300] Training [59/62] Loss: 0.02304 
Epoch [288/300] Training [60/62] Loss: 0.03008 
Epoch [288/300] Training [61/62] Loss: 0.03004 
Epoch [288/300] Training [62/62] Loss: 0.02068 
Epoch [288/300] Training metric {'Train/mean dice_metric': 0.978043794631958, 'Train/mean miou_metric': 0.9589858651161194, 'Train/mean f1': 0.9782052040100098, 'Train/mean precision': 0.9740850329399109, 'Train/mean recall': 0.9823603630065918, 'Train/mean hd95_metric': 4.081335544586182}
Epoch [288/300] Validation [1/16] Loss: 0.68392  focal_loss 0.47295  dice_loss 0.21097 
Epoch [288/300] Validation [2/16] Loss: 0.47671  focal_loss 0.21246  dice_loss 0.26425 
Epoch [288/300] Validation [3/16] Loss: 0.75232  focal_loss 0.46023  dice_loss 0.29209 
Epoch [288/300] Validation [4/16] Loss: 0.34233  focal_loss 0.18483  dice_loss 0.15749 
Epoch [288/300] Validation [5/16] Loss: 0.39977  focal_loss 0.16511  dice_loss 0.23466 
Epoch [288/300] Validation [6/16] Loss: 0.34624  focal_loss 0.12610  dice_loss 0.22013 
Epoch [288/300] Validation [7/16] Loss: 0.32297  focal_loss 0.12544  dice_loss 0.19753 
Epoch [288/300] Validation [8/16] Loss: 0.48339  focal_loss 0.18766  dice_loss 0.29573 
Epoch [288/300] Validation [9/16] Loss: 0.21153  focal_loss 0.09754  dice_loss 0.11399 
Epoch [288/300] Validation [10/16] Loss: 0.52578  focal_loss 0.19901  dice_loss 0.32677 
Epoch [288/300] Validation [11/16] Loss: 0.15036  focal_loss 0.06238  dice_loss 0.08799 
Epoch [288/300] Validation [12/16] Loss: 0.36951  focal_loss 0.12071  dice_loss 0.24880 
Epoch [288/300] Validation [13/16] Loss: 0.29709  focal_loss 0.12547  dice_loss 0.17162 
Epoch [288/300] Validation [14/16] Loss: 0.60036  focal_loss 0.29218  dice_loss 0.30818 
Epoch [288/300] Validation [15/16] Loss: 0.12375  focal_loss 0.04932  dice_loss 0.07443 
Epoch [288/300] Validation [16/16] Loss: 0.21246  focal_loss 0.09224  dice_loss 0.12022 
Epoch [288/300] Validation metric {'Val/mean dice_metric': 0.9403647780418396, 'Val/mean miou_metric': 0.9078477621078491, 'Val/mean f1': 0.9488542079925537, 'Val/mean precision': 0.9547012448310852, 'Val/mean recall': 0.943078339099884, 'Val/mean hd95_metric': 13.487699508666992}
Cheakpoint...
Epoch [288/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9404], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9403647780418396, 'Val/mean miou_metric': 0.9078477621078491, 'Val/mean f1': 0.9488542079925537, 'Val/mean precision': 0.9547012448310852, 'Val/mean recall': 0.943078339099884, 'Val/mean hd95_metric': 13.487699508666992}
Epoch [289/300] Training [1/62] Loss: 0.03524 
Epoch [289/300] Training [2/62] Loss: 0.03060 
Epoch [289/300] Training [3/62] Loss: 0.02185 
Epoch [289/300] Training [4/62] Loss: 0.02130 
Epoch [289/300] Training [5/62] Loss: 0.03041 
Epoch [289/300] Training [6/62] Loss: 0.04223 
Epoch [289/300] Training [7/62] Loss: 0.02167 
Epoch [289/300] Training [8/62] Loss: 0.04227 
Epoch [289/300] Training [9/62] Loss: 0.02083 
Epoch [289/300] Training [10/62] Loss: 0.02978 
Epoch [289/300] Training [11/62] Loss: 0.01816 
Epoch [289/300] Training [12/62] Loss: 0.02208 
Epoch [289/300] Training [13/62] Loss: 0.02657 
Epoch [289/300] Training [14/62] Loss: 0.03081 
Epoch [289/300] Training [15/62] Loss: 0.03065 
Epoch [289/300] Training [16/62] Loss: 0.04445 
Epoch [289/300] Training [17/62] Loss: 0.03451 
Epoch [289/300] Training [18/62] Loss: 0.02295 
Epoch [289/300] Training [19/62] Loss: 0.01884 
Epoch [289/300] Training [20/62] Loss: 0.02320 
Epoch [289/300] Training [21/62] Loss: 0.02024 
Epoch [289/300] Training [22/62] Loss: 0.01926 
Epoch [289/300] Training [23/62] Loss: 0.04263 
Epoch [289/300] Training [24/62] Loss: 0.02415 
Epoch [289/300] Training [25/62] Loss: 0.04167 
Epoch [289/300] Training [26/62] Loss: 0.02898 
Epoch [289/300] Training [27/62] Loss: 0.02261 
Epoch [289/300] Training [28/62] Loss: 0.02556 
Epoch [289/300] Training [29/62] Loss: 0.02903 
Epoch [289/300] Training [30/62] Loss: 0.03445 
Epoch [289/300] Training [31/62] Loss: 0.02215 
Epoch [289/300] Training [32/62] Loss: 0.02432 
Epoch [289/300] Training [33/62] Loss: 0.03614 
Epoch [289/300] Training [34/62] Loss: 0.03354 
Epoch [289/300] Training [35/62] Loss: 0.02665 
Epoch [289/300] Training [36/62] Loss: 0.04532 
Epoch [289/300] Training [37/62] Loss: 0.01973 
Epoch [289/300] Training [38/62] Loss: 0.05277 
Epoch [289/300] Training [39/62] Loss: 0.02686 
Epoch [289/300] Training [40/62] Loss: 0.02689 
Epoch [289/300] Training [41/62] Loss: 0.04159 
Epoch [289/300] Training [42/62] Loss: 0.03638 
Epoch [289/300] Training [43/62] Loss: 0.07349 
Epoch [289/300] Training [44/62] Loss: 0.03661 
Epoch [289/300] Training [45/62] Loss: 0.02237 
Epoch [289/300] Training [46/62] Loss: 0.01793 
Epoch [289/300] Training [47/62] Loss: 0.06103 
Epoch [289/300] Training [48/62] Loss: 0.04749 
Epoch [289/300] Training [49/62] Loss: 0.01893 
Epoch [289/300] Training [50/62] Loss: 0.01874 
Epoch [289/300] Training [51/62] Loss: 0.05469 
Epoch [289/300] Training [52/62] Loss: 0.02744 
Epoch [289/300] Training [53/62] Loss: 0.03276 
Epoch [289/300] Training [54/62] Loss: 0.04012 
Epoch [289/300] Training [55/62] Loss: 0.01688 
Epoch [289/300] Training [56/62] Loss: 0.02247 
Epoch [289/300] Training [57/62] Loss: 0.03404 
Epoch [289/300] Training [58/62] Loss: 0.03063 
Epoch [289/300] Training [59/62] Loss: 0.02500 
Epoch [289/300] Training [60/62] Loss: 0.02044 
Epoch [289/300] Training [61/62] Loss: 0.02452 
Epoch [289/300] Training [62/62] Loss: 0.02962 
Epoch [289/300] Training metric {'Train/mean dice_metric': 0.9800879955291748, 'Train/mean miou_metric': 0.96150141954422, 'Train/mean f1': 0.9777989983558655, 'Train/mean precision': 0.9741016030311584, 'Train/mean recall': 0.9815244674682617, 'Train/mean hd95_metric': 4.34420919418335}
Epoch [289/300] Validation [1/16] Loss: 0.66591  focal_loss 0.46242  dice_loss 0.20348 
Epoch [289/300] Validation [2/16] Loss: 0.45598  focal_loss 0.19591  dice_loss 0.26007 
Epoch [289/300] Validation [3/16] Loss: 0.77378  focal_loss 0.46389  dice_loss 0.30989 
Epoch [289/300] Validation [4/16] Loss: 0.33282  focal_loss 0.18308  dice_loss 0.14974 
Epoch [289/300] Validation [5/16] Loss: 0.32778  focal_loss 0.14028  dice_loss 0.18750 
Epoch [289/300] Validation [6/16] Loss: 0.30743  focal_loss 0.11109  dice_loss 0.19634 
Epoch [289/300] Validation [7/16] Loss: 0.20377  focal_loss 0.09865  dice_loss 0.10513 
Epoch [289/300] Validation [8/16] Loss: 0.53998  focal_loss 0.22023  dice_loss 0.31975 
Epoch [289/300] Validation [9/16] Loss: 0.20459  focal_loss 0.09587  dice_loss 0.10872 
Epoch [289/300] Validation [10/16] Loss: 0.60636  focal_loss 0.24105  dice_loss 0.36531 
Epoch [289/300] Validation [11/16] Loss: 0.15289  focal_loss 0.06289  dice_loss 0.09000 
Epoch [289/300] Validation [12/16] Loss: 0.40848  focal_loss 0.14199  dice_loss 0.26650 
Epoch [289/300] Validation [13/16] Loss: 0.25977  focal_loss 0.10345  dice_loss 0.15632 
Epoch [289/300] Validation [14/16] Loss: 0.64085  focal_loss 0.31086  dice_loss 0.32999 
Epoch [289/300] Validation [15/16] Loss: 0.11086  focal_loss 0.04253  dice_loss 0.06833 
Epoch [289/300] Validation [16/16] Loss: 0.10231  focal_loss 0.03878  dice_loss 0.06353 
Epoch [289/300] Validation metric {'Val/mean dice_metric': 0.9435208439826965, 'Val/mean miou_metric': 0.9120222330093384, 'Val/mean f1': 0.9497612714767456, 'Val/mean precision': 0.9562558531761169, 'Val/mean recall': 0.9433543086051941, 'Val/mean hd95_metric': 13.65803050994873}
Cheakpoint...
Epoch [289/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9435], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9435208439826965, 'Val/mean miou_metric': 0.9120222330093384, 'Val/mean f1': 0.9497612714767456, 'Val/mean precision': 0.9562558531761169, 'Val/mean recall': 0.9433543086051941, 'Val/mean hd95_metric': 13.65803050994873}
Epoch [290/300] Training [1/62] Loss: 0.05022 
Epoch [290/300] Training [2/62] Loss: 0.03566 
Epoch [290/300] Training [3/62] Loss: 0.03823 
Epoch [290/300] Training [4/62] Loss: 0.02080 
Epoch [290/300] Training [5/62] Loss: 0.02325 
Epoch [290/300] Training [6/62] Loss: 0.01928 
Epoch [290/300] Training [7/62] Loss: 0.02166 
Epoch [290/300] Training [8/62] Loss: 0.02137 
Epoch [290/300] Training [9/62] Loss: 0.04999 
Epoch [290/300] Training [10/62] Loss: 0.02149 
Epoch [290/300] Training [11/62] Loss: 0.02928 
Epoch [290/300] Training [12/62] Loss: 0.02310 
Epoch [290/300] Training [13/62] Loss: 0.01833 
Epoch [290/300] Training [14/62] Loss: 0.02794 
Epoch [290/300] Training [15/62] Loss: 0.01873 
Epoch [290/300] Training [16/62] Loss: 0.06158 
Epoch [290/300] Training [17/62] Loss: 0.01683 
Epoch [290/300] Training [18/62] Loss: 0.01919 
Epoch [290/300] Training [19/62] Loss: 0.03569 
Epoch [290/300] Training [20/62] Loss: 0.03920 
Epoch [290/300] Training [21/62] Loss: 0.01787 
Epoch [290/300] Training [22/62] Loss: 0.02561 
Epoch [290/300] Training [23/62] Loss: 0.03823 
Epoch [290/300] Training [24/62] Loss: 0.01962 
Epoch [290/300] Training [25/62] Loss: 0.03176 
Epoch [290/300] Training [26/62] Loss: 0.03647 
Epoch [290/300] Training [27/62] Loss: 0.03879 
Epoch [290/300] Training [28/62] Loss: 0.01948 
Epoch [290/300] Training [29/62] Loss: 0.04123 
Epoch [290/300] Training [30/62] Loss: 0.02602 
Epoch [290/300] Training [31/62] Loss: 0.02917 
Epoch [290/300] Training [32/62] Loss: 0.02113 
Epoch [290/300] Training [33/62] Loss: 0.03695 
Epoch [290/300] Training [34/62] Loss: 0.01548 
Epoch [290/300] Training [35/62] Loss: 0.02344 
Epoch [290/300] Training [36/62] Loss: 0.02049 
Epoch [290/300] Training [37/62] Loss: 0.02859 
Epoch [290/300] Training [38/62] Loss: 0.02529 
Epoch [290/300] Training [39/62] Loss: 0.03354 
Epoch [290/300] Training [40/62] Loss: 0.02724 
Epoch [290/300] Training [41/62] Loss: 0.04444 
Epoch [290/300] Training [42/62] Loss: 0.01999 
Epoch [290/300] Training [43/62] Loss: 0.02148 
Epoch [290/300] Training [44/62] Loss: 0.06889 
Epoch [290/300] Training [45/62] Loss: 0.02688 
Epoch [290/300] Training [46/62] Loss: 0.01907 
Epoch [290/300] Training [47/62] Loss: 0.04048 
Epoch [290/300] Training [48/62] Loss: 0.02346 
Epoch [290/300] Training [49/62] Loss: 0.04351 
Epoch [290/300] Training [50/62] Loss: 0.06158 
Epoch [290/300] Training [51/62] Loss: 0.02892 
Epoch [290/300] Training [52/62] Loss: 0.02138 
Epoch [290/300] Training [53/62] Loss: 0.02129 
Epoch [290/300] Training [54/62] Loss: 0.01923 
Epoch [290/300] Training [55/62] Loss: 0.02834 
Epoch [290/300] Training [56/62] Loss: 0.03229 
Epoch [290/300] Training [57/62] Loss: 0.01842 
Epoch [290/300] Training [58/62] Loss: 0.02097 
Epoch [290/300] Training [59/62] Loss: 0.04273 
Epoch [290/300] Training [60/62] Loss: 0.02377 
Epoch [290/300] Training [61/62] Loss: 0.03258 
Epoch [290/300] Training [62/62] Loss: 0.02963 
Epoch [290/300] Training metric {'Train/mean dice_metric': 0.9806487560272217, 'Train/mean miou_metric': 0.9625284075737, 'Train/mean f1': 0.9787423610687256, 'Train/mean precision': 0.9749382138252258, 'Train/mean recall': 0.9825761914253235, 'Train/mean hd95_metric': 4.469836235046387}
Epoch [290/300] Validation [1/16] Loss: 0.71719  focal_loss 0.49531  dice_loss 0.22188 
Epoch [290/300] Validation [2/16] Loss: 0.55849  focal_loss 0.22725  dice_loss 0.33124 
Epoch [290/300] Validation [3/16] Loss: 0.69041  focal_loss 0.40936  dice_loss 0.28104 
Epoch [290/300] Validation [4/16] Loss: 0.32306  focal_loss 0.17190  dice_loss 0.15116 
Epoch [290/300] Validation [5/16] Loss: 0.48823  focal_loss 0.19089  dice_loss 0.29734 
Epoch [290/300] Validation [6/16] Loss: 0.30030  focal_loss 0.10163  dice_loss 0.19867 
Epoch [290/300] Validation [7/16] Loss: 0.20994  focal_loss 0.10180  dice_loss 0.10814 
Epoch [290/300] Validation [8/16] Loss: 0.54688  focal_loss 0.22765  dice_loss 0.31923 
Epoch [290/300] Validation [9/16] Loss: 0.20103  focal_loss 0.09254  dice_loss 0.10848 
Epoch [290/300] Validation [10/16] Loss: 0.53926  focal_loss 0.20744  dice_loss 0.33182 
Epoch [290/300] Validation [11/16] Loss: 0.17326  focal_loss 0.06820  dice_loss 0.10506 
Epoch [290/300] Validation [12/16] Loss: 0.38751  focal_loss 0.12653  dice_loss 0.26098 
Epoch [290/300] Validation [13/16] Loss: 0.25335  focal_loss 0.09406  dice_loss 0.15928 
Epoch [290/300] Validation [14/16] Loss: 0.61671  focal_loss 0.30697  dice_loss 0.30973 
Epoch [290/300] Validation [15/16] Loss: 0.18741  focal_loss 0.08293  dice_loss 0.10448 
Epoch [290/300] Validation [16/16] Loss: 0.09551  focal_loss 0.03543  dice_loss 0.06008 
Epoch [290/300] Validation metric {'Val/mean dice_metric': 0.9418340921401978, 'Val/mean miou_metric': 0.9103473424911499, 'Val/mean f1': 0.9494681358337402, 'Val/mean precision': 0.9560340046882629, 'Val/mean recall': 0.9429918527603149, 'Val/mean hd95_metric': 13.844745635986328}
Cheakpoint...
Epoch [290/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9418], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9418340921401978, 'Val/mean miou_metric': 0.9103473424911499, 'Val/mean f1': 0.9494681358337402, 'Val/mean precision': 0.9560340046882629, 'Val/mean recall': 0.9429918527603149, 'Val/mean hd95_metric': 13.844745635986328}
Epoch [291/300] Training [1/62] Loss: 0.03251 
Epoch [291/300] Training [2/62] Loss: 0.02378 
Epoch [291/300] Training [3/62] Loss: 0.02176 
Epoch [291/300] Training [4/62] Loss: 0.02225 
Epoch [291/300] Training [5/62] Loss: 0.01842 
Epoch [291/300] Training [6/62] Loss: 0.05262 
Epoch [291/300] Training [7/62] Loss: 0.03662 
Epoch [291/300] Training [8/62] Loss: 0.15092 
Epoch [291/300] Training [9/62] Loss: 0.02932 
Epoch [291/300] Training [10/62] Loss: 0.05993 
Epoch [291/300] Training [11/62] Loss: 0.06520 
Epoch [291/300] Training [12/62] Loss: 0.03437 
Epoch [291/300] Training [13/62] Loss: 0.02462 
Epoch [291/300] Training [14/62] Loss: 0.03994 
Epoch [291/300] Training [15/62] Loss: 0.03382 
Epoch [291/300] Training [16/62] Loss: 0.02308 
Epoch [291/300] Training [17/62] Loss: 0.02342 
Epoch [291/300] Training [18/62] Loss: 0.01960 
Epoch [291/300] Training [19/62] Loss: 0.06965 
Epoch [291/300] Training [20/62] Loss: 0.03148 
Epoch [291/300] Training [21/62] Loss: 0.03157 
Epoch [291/300] Training [22/62] Loss: 0.03344 
Epoch [291/300] Training [23/62] Loss: 0.02909 
Epoch [291/300] Training [24/62] Loss: 0.03383 
Epoch [291/300] Training [25/62] Loss: 0.02084 
Epoch [291/300] Training [26/62] Loss: 0.02873 
Epoch [291/300] Training [27/62] Loss: 0.03197 
Epoch [291/300] Training [28/62] Loss: 0.04259 
Epoch [291/300] Training [29/62] Loss: 0.03295 
Epoch [291/300] Training [30/62] Loss: 0.02555 
Epoch [291/300] Training [31/62] Loss: 0.02283 
Epoch [291/300] Training [32/62] Loss: 0.03774 
Epoch [291/300] Training [33/62] Loss: 0.02922 
Epoch [291/300] Training [34/62] Loss: 0.03621 
Epoch [291/300] Training [35/62] Loss: 0.02861 
Epoch [291/300] Training [36/62] Loss: 0.01782 
Epoch [291/300] Training [37/62] Loss: 0.03551 
Epoch [291/300] Training [38/62] Loss: 0.03372 
Epoch [291/300] Training [39/62] Loss: 0.05307 
Epoch [291/300] Training [40/62] Loss: 0.02167 
Epoch [291/300] Training [41/62] Loss: 0.03084 
Epoch [291/300] Training [42/62] Loss: 0.02648 
Epoch [291/300] Training [43/62] Loss: 0.04349 
Epoch [291/300] Training [44/62] Loss: 0.02039 
Epoch [291/300] Training [45/62] Loss: 0.04703 
Epoch [291/300] Training [46/62] Loss: 0.02291 
Epoch [291/300] Training [47/62] Loss: 0.02055 
Epoch [291/300] Training [48/62] Loss: 0.03106 
Epoch [291/300] Training [49/62] Loss: 0.04545 
Epoch [291/300] Training [50/62] Loss: 0.02862 
Epoch [291/300] Training [51/62] Loss: 0.02177 
Epoch [291/300] Training [52/62] Loss: 0.03209 
Epoch [291/300] Training [53/62] Loss: 0.03192 
Epoch [291/300] Training [54/62] Loss: 0.02642 
Epoch [291/300] Training [55/62] Loss: 0.02940 
Epoch [291/300] Training [56/62] Loss: 0.02496 
Epoch [291/300] Training [57/62] Loss: 0.02029 
Epoch [291/300] Training [58/62] Loss: 0.02630 
Epoch [291/300] Training [59/62] Loss: 0.02890 
Epoch [291/300] Training [60/62] Loss: 0.02635 
Epoch [291/300] Training [61/62] Loss: 0.05771 
Epoch [291/300] Training [62/62] Loss: 0.05754 
Epoch [291/300] Training metric {'Train/mean dice_metric': 0.9770675301551819, 'Train/mean miou_metric': 0.9577465653419495, 'Train/mean f1': 0.9775214195251465, 'Train/mean precision': 0.973513126373291, 'Train/mean recall': 0.9815627932548523, 'Train/mean hd95_metric': 4.597420692443848}
Epoch [291/300] Validation [1/16] Loss: 0.65968  focal_loss 0.45737  dice_loss 0.20231 
Epoch [291/300] Validation [2/16] Loss: 0.48100  focal_loss 0.21380  dice_loss 0.26720 
Epoch [291/300] Validation [3/16] Loss: 0.75162  focal_loss 0.45598  dice_loss 0.29564 
Epoch [291/300] Validation [4/16] Loss: 0.32637  focal_loss 0.17678  dice_loss 0.14960 
Epoch [291/300] Validation [5/16] Loss: 0.37431  focal_loss 0.15841  dice_loss 0.21589 
Epoch [291/300] Validation [6/16] Loss: 0.29360  focal_loss 0.10060  dice_loss 0.19300 
Epoch [291/300] Validation [7/16] Loss: 0.19936  focal_loss 0.09848  dice_loss 0.10089 
Epoch [291/300] Validation [8/16] Loss: 0.51730  focal_loss 0.21641  dice_loss 0.30089 
Epoch [291/300] Validation [9/16] Loss: 0.21293  focal_loss 0.09693  dice_loss 0.11600 
Epoch [291/300] Validation [10/16] Loss: 0.54739  focal_loss 0.20460  dice_loss 0.34279 
Epoch [291/300] Validation [11/16] Loss: 0.18218  focal_loss 0.07749  dice_loss 0.10470 
Epoch [291/300] Validation [12/16] Loss: 0.53875  focal_loss 0.15921  dice_loss 0.37955 
Epoch [291/300] Validation [13/16] Loss: 0.33786  focal_loss 0.15047  dice_loss 0.18739 
Epoch [291/300] Validation [14/16] Loss: 0.48485  focal_loss 0.20564  dice_loss 0.27921 
Epoch [291/300] Validation [15/16] Loss: 0.17613  focal_loss 0.07641  dice_loss 0.09972 
Epoch [291/300] Validation [16/16] Loss: 0.13574  focal_loss 0.05260  dice_loss 0.08314 
Epoch [291/300] Validation metric {'Val/mean dice_metric': 0.9394116401672363, 'Val/mean miou_metric': 0.906618595123291, 'Val/mean f1': 0.948961615562439, 'Val/mean precision': 0.954348623752594, 'Val/mean recall': 0.9436349868774414, 'Val/mean hd95_metric': 14.782316207885742}
Cheakpoint...
Epoch [291/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9394], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9394116401672363, 'Val/mean miou_metric': 0.906618595123291, 'Val/mean f1': 0.948961615562439, 'Val/mean precision': 0.954348623752594, 'Val/mean recall': 0.9436349868774414, 'Val/mean hd95_metric': 14.782316207885742}
Epoch [292/300] Training [1/62] Loss: 0.02690 
Epoch [292/300] Training [2/62] Loss: 0.04065 
Epoch [292/300] Training [3/62] Loss: 0.02347 
Epoch [292/300] Training [4/62] Loss: 0.01906 
Epoch [292/300] Training [5/62] Loss: 0.02654 
Epoch [292/300] Training [6/62] Loss: 0.02860 
Epoch [292/300] Training [7/62] Loss: 0.02822 
Epoch [292/300] Training [8/62] Loss: 0.02660 
Epoch [292/300] Training [9/62] Loss: 0.02332 
Epoch [292/300] Training [10/62] Loss: 0.11761 
Epoch [292/300] Training [11/62] Loss: 0.02822 
Epoch [292/300] Training [12/62] Loss: 0.04806 
Epoch [292/300] Training [13/62] Loss: 0.02474 
Epoch [292/300] Training [14/62] Loss: 0.03595 
Epoch [292/300] Training [15/62] Loss: 0.02277 
Epoch [292/300] Training [16/62] Loss: 0.05508 
Epoch [292/300] Training [17/62] Loss: 0.03404 
Epoch [292/300] Training [18/62] Loss: 0.01947 
Epoch [292/300] Training [19/62] Loss: 0.02285 
Epoch [292/300] Training [20/62] Loss: 0.02631 
Epoch [292/300] Training [21/62] Loss: 0.03454 
Epoch [292/300] Training [22/62] Loss: 0.02764 
Epoch [292/300] Training [23/62] Loss: 0.03197 
Epoch [292/300] Training [24/62] Loss: 0.03248 
Epoch [292/300] Training [25/62] Loss: 0.03533 
Epoch [292/300] Training [26/62] Loss: 0.02920 
Epoch [292/300] Training [27/62] Loss: 0.03212 
Epoch [292/300] Training [28/62] Loss: 0.03122 
Epoch [292/300] Training [29/62] Loss: 0.01824 
Epoch [292/300] Training [30/62] Loss: 0.04668 
Epoch [292/300] Training [31/62] Loss: 0.02477 
Epoch [292/300] Training [32/62] Loss: 0.04705 
Epoch [292/300] Training [33/62] Loss: 0.04188 
Epoch [292/300] Training [34/62] Loss: 0.02000 
Epoch [292/300] Training [35/62] Loss: 0.03037 
Epoch [292/300] Training [36/62] Loss: 0.15029 
Epoch [292/300] Training [37/62] Loss: 0.02547 
Epoch [292/300] Training [38/62] Loss: 0.01897 
Epoch [292/300] Training [39/62] Loss: 0.05067 
Epoch [292/300] Training [40/62] Loss: 0.04970 
Epoch [292/300] Training [41/62] Loss: 0.03408 
Epoch [292/300] Training [42/62] Loss: 0.05431 
Epoch [292/300] Training [43/62] Loss: 0.09661 
Epoch [292/300] Training [44/62] Loss: 0.02694 
Epoch [292/300] Training [45/62] Loss: 0.05190 
Epoch [292/300] Training [46/62] Loss: 0.03058 
Epoch [292/300] Training [47/62] Loss: 0.02313 
Epoch [292/300] Training [48/62] Loss: 0.03267 
Epoch [292/300] Training [49/62] Loss: 0.02799 
Epoch [292/300] Training [50/62] Loss: 0.02922 
Epoch [292/300] Training [51/62] Loss: 0.03032 
Epoch [292/300] Training [52/62] Loss: 0.02536 
Epoch [292/300] Training [53/62] Loss: 0.02215 
Epoch [292/300] Training [54/62] Loss: 0.02347 
Epoch [292/300] Training [55/62] Loss: 0.02908 
Epoch [292/300] Training [56/62] Loss: 0.05642 
Epoch [292/300] Training [57/62] Loss: 0.06039 
Epoch [292/300] Training [58/62] Loss: 0.02740 
Epoch [292/300] Training [59/62] Loss: 0.02755 
Epoch [292/300] Training [60/62] Loss: 0.02713 
Epoch [292/300] Training [61/62] Loss: 0.02699 
Epoch [292/300] Training [62/62] Loss: 0.03711 
Epoch [292/300] Training metric {'Train/mean dice_metric': 0.975541889667511, 'Train/mean miou_metric': 0.9554440975189209, 'Train/mean f1': 0.9754771590232849, 'Train/mean precision': 0.9718794226646423, 'Train/mean recall': 0.9791015982627869, 'Train/mean hd95_metric': 5.51545524597168}
Epoch [292/300] Validation [1/16] Loss: 0.73715  focal_loss 0.51550  dice_loss 0.22166 
Epoch [292/300] Validation [2/16] Loss: 0.47543  focal_loss 0.21293  dice_loss 0.26250 
Epoch [292/300] Validation [3/16] Loss: 0.68331  focal_loss 0.41415  dice_loss 0.26916 
Epoch [292/300] Validation [4/16] Loss: 0.35881  focal_loss 0.17980  dice_loss 0.17901 
Epoch [292/300] Validation [5/16] Loss: 0.40784  focal_loss 0.16728  dice_loss 0.24056 
Epoch [292/300] Validation [6/16] Loss: 0.30991  focal_loss 0.10563  dice_loss 0.20428 
Epoch [292/300] Validation [7/16] Loss: 0.19073  focal_loss 0.09132  dice_loss 0.09941 
Epoch [292/300] Validation [8/16] Loss: 0.52856  focal_loss 0.22705  dice_loss 0.30152 
Epoch [292/300] Validation [9/16] Loss: 0.24956  focal_loss 0.12455  dice_loss 0.12501 
Epoch [292/300] Validation [10/16] Loss: 0.61367  focal_loss 0.24036  dice_loss 0.37331 
Epoch [292/300] Validation [11/16] Loss: 0.17516  focal_loss 0.07001  dice_loss 0.10515 
Epoch [292/300] Validation [12/16] Loss: 0.37766  focal_loss 0.11893  dice_loss 0.25873 
Epoch [292/300] Validation [13/16] Loss: 0.24511  focal_loss 0.09558  dice_loss 0.14953 
Epoch [292/300] Validation [14/16] Loss: 0.56558  focal_loss 0.27435  dice_loss 0.29123 
Epoch [292/300] Validation [15/16] Loss: 0.10193  focal_loss 0.04014  dice_loss 0.06179 
Epoch [292/300] Validation [16/16] Loss: 0.10346  focal_loss 0.04044  dice_loss 0.06303 
Epoch [292/300] Validation metric {'Val/mean dice_metric': 0.9395080804824829, 'Val/mean miou_metric': 0.9069584012031555, 'Val/mean f1': 0.9470300674438477, 'Val/mean precision': 0.9535832405090332, 'Val/mean recall': 0.94056636095047, 'Val/mean hd95_metric': 14.793852806091309}
Cheakpoint...
Epoch [292/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9395], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9395080804824829, 'Val/mean miou_metric': 0.9069584012031555, 'Val/mean f1': 0.9470300674438477, 'Val/mean precision': 0.9535832405090332, 'Val/mean recall': 0.94056636095047, 'Val/mean hd95_metric': 14.793852806091309}
Epoch [293/300] Training [1/62] Loss: 0.02423 
Epoch [293/300] Training [2/62] Loss: 0.07088 
Epoch [293/300] Training [3/62] Loss: 0.04650 
Epoch [293/300] Training [4/62] Loss: 0.02890 
Epoch [293/300] Training [5/62] Loss: 0.03201 
Epoch [293/300] Training [6/62] Loss: 0.02504 
Epoch [293/300] Training [7/62] Loss: 0.01567 
Epoch [293/300] Training [8/62] Loss: 0.02193 
Epoch [293/300] Training [9/62] Loss: 0.03246 
Epoch [293/300] Training [10/62] Loss: 0.02036 
Epoch [293/300] Training [11/62] Loss: 0.03592 
Epoch [293/300] Training [12/62] Loss: 0.02715 
Epoch [293/300] Training [13/62] Loss: 0.02226 
Epoch [293/300] Training [14/62] Loss: 0.02449 
Epoch [293/300] Training [15/62] Loss: 0.03300 
Epoch [293/300] Training [16/62] Loss: 0.02546 
Epoch [293/300] Training [17/62] Loss: 0.02297 
Epoch [293/300] Training [18/62] Loss: 0.08112 
Epoch [293/300] Training [19/62] Loss: 0.02195 
Epoch [293/300] Training [20/62] Loss: 0.08152 
Epoch [293/300] Training [21/62] Loss: 0.02155 
Epoch [293/300] Training [22/62] Loss: 0.03013 
Epoch [293/300] Training [23/62] Loss: 0.02381 
Epoch [293/300] Training [24/62] Loss: 0.02891 
Epoch [293/300] Training [25/62] Loss: 0.04927 
Epoch [293/300] Training [26/62] Loss: 0.04581 
Epoch [293/300] Training [27/62] Loss: 0.03980 
Epoch [293/300] Training [28/62] Loss: 0.02365 
Epoch [293/300] Training [29/62] Loss: 0.02252 
Epoch [293/300] Training [30/62] Loss: 0.02022 
Epoch [293/300] Training [31/62] Loss: 0.01823 
Epoch [293/300] Training [32/62] Loss: 0.02024 
Epoch [293/300] Training [33/62] Loss: 0.02731 
Epoch [293/300] Training [34/62] Loss: 0.02840 
Epoch [293/300] Training [35/62] Loss: 0.04651 
Epoch [293/300] Training [36/62] Loss: 0.02430 
Epoch [293/300] Training [37/62] Loss: 0.01874 
Epoch [293/300] Training [38/62] Loss: 0.02066 
Epoch [293/300] Training [39/62] Loss: 0.02427 
Epoch [293/300] Training [40/62] Loss: 0.06093 
Epoch [293/300] Training [41/62] Loss: 0.04329 
Epoch [293/300] Training [42/62] Loss: 0.03072 
Epoch [293/300] Training [43/62] Loss: 0.03077 
Epoch [293/300] Training [44/62] Loss: 0.04787 
Epoch [293/300] Training [45/62] Loss: 0.03144 
Epoch [293/300] Training [46/62] Loss: 0.05067 
Epoch [293/300] Training [47/62] Loss: 0.01649 
Epoch [293/300] Training [48/62] Loss: 0.01949 
Epoch [293/300] Training [49/62] Loss: 0.04298 
Epoch [293/300] Training [50/62] Loss: 0.02064 
Epoch [293/300] Training [51/62] Loss: 0.02584 
Epoch [293/300] Training [52/62] Loss: 0.02380 
Epoch [293/300] Training [53/62] Loss: 0.02688 
Epoch [293/300] Training [54/62] Loss: 0.03376 
Epoch [293/300] Training [55/62] Loss: 0.07972 
Epoch [293/300] Training [56/62] Loss: 0.02984 
Epoch [293/300] Training [57/62] Loss: 0.04225 
Epoch [293/300] Training [58/62] Loss: 0.02088 
Epoch [293/300] Training [59/62] Loss: 0.02833 
Epoch [293/300] Training [60/62] Loss: 0.02678 
Epoch [293/300] Training [61/62] Loss: 0.03093 
Epoch [293/300] Training [62/62] Loss: 0.02771 
Epoch [293/300] Training metric {'Train/mean dice_metric': 0.9784514904022217, 'Train/mean miou_metric': 0.9588630795478821, 'Train/mean f1': 0.9772069454193115, 'Train/mean precision': 0.9726941585540771, 'Train/mean recall': 0.9817617535591125, 'Train/mean hd95_metric': 5.00525426864624}
Epoch [293/300] Validation [1/16] Loss: 0.67818  focal_loss 0.47194  dice_loss 0.20624 
Epoch [293/300] Validation [2/16] Loss: 0.49118  focal_loss 0.22468  dice_loss 0.26650 
Epoch [293/300] Validation [3/16] Loss: 0.73927  focal_loss 0.46834  dice_loss 0.27094 
Epoch [293/300] Validation [4/16] Loss: 0.35295  focal_loss 0.18016  dice_loss 0.17279 
Epoch [293/300] Validation [5/16] Loss: 0.46256  focal_loss 0.17064  dice_loss 0.29192 
Epoch [293/300] Validation [6/16] Loss: 0.35742  focal_loss 0.13734  dice_loss 0.22009 
Epoch [293/300] Validation [7/16] Loss: 0.21846  focal_loss 0.10670  dice_loss 0.11176 
Epoch [293/300] Validation [8/16] Loss: 0.45876  focal_loss 0.18471  dice_loss 0.27404 
Epoch [293/300] Validation [9/16] Loss: 0.26252  focal_loss 0.13170  dice_loss 0.13082 
Epoch [293/300] Validation [10/16] Loss: 0.48226  focal_loss 0.16155  dice_loss 0.32071 
Epoch [293/300] Validation [11/16] Loss: 0.16130  focal_loss 0.06565  dice_loss 0.09565 
Epoch [293/300] Validation [12/16] Loss: 0.37325  focal_loss 0.11835  dice_loss 0.25490 
Epoch [293/300] Validation [13/16] Loss: 0.30738  focal_loss 0.14489  dice_loss 0.16248 
Epoch [293/300] Validation [14/16] Loss: 0.59391  focal_loss 0.28769  dice_loss 0.30622 
Epoch [293/300] Validation [15/16] Loss: 0.15906  focal_loss 0.06208  dice_loss 0.09698 
Epoch [293/300] Validation [16/16] Loss: 0.08043  focal_loss 0.02833  dice_loss 0.05210 
Epoch [293/300] Validation metric {'Val/mean dice_metric': 0.9413776397705078, 'Val/mean miou_metric': 0.9087087512016296, 'Val/mean f1': 0.9480584263801575, 'Val/mean precision': 0.9529421925544739, 'Val/mean recall': 0.9432245492935181, 'Val/mean hd95_metric': 14.45971965789795}
Cheakpoint...
Epoch [293/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9414], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9413776397705078, 'Val/mean miou_metric': 0.9087087512016296, 'Val/mean f1': 0.9480584263801575, 'Val/mean precision': 0.9529421925544739, 'Val/mean recall': 0.9432245492935181, 'Val/mean hd95_metric': 14.45971965789795}
Epoch [294/300] Training [1/62] Loss: 0.05105 
Epoch [294/300] Training [2/62] Loss: 0.03866 
Epoch [294/300] Training [3/62] Loss: 0.01993 
Epoch [294/300] Training [4/62] Loss: 0.02828 
Epoch [294/300] Training [5/62] Loss: 0.06666 
Epoch [294/300] Training [6/62] Loss: 0.05209 
Epoch [294/300] Training [7/62] Loss: 0.02545 
Epoch [294/300] Training [8/62] Loss: 0.01885 
Epoch [294/300] Training [9/62] Loss: 0.06899 
Epoch [294/300] Training [10/62] Loss: 0.01859 
Epoch [294/300] Training [11/62] Loss: 0.02975 
Epoch [294/300] Training [12/62] Loss: 0.02614 
Epoch [294/300] Training [13/62] Loss: 0.02610 
Epoch [294/300] Training [14/62] Loss: 0.04124 
Epoch [294/300] Training [15/62] Loss: 0.02422 
Epoch [294/300] Training [16/62] Loss: 0.04241 
Epoch [294/300] Training [17/62] Loss: 0.02584 
Epoch [294/300] Training [18/62] Loss: 0.02661 
Epoch [294/300] Training [19/62] Loss: 0.02555 
Epoch [294/300] Training [20/62] Loss: 0.05898 
Epoch [294/300] Training [21/62] Loss: 0.03745 
Epoch [294/300] Training [22/62] Loss: 0.02327 
Epoch [294/300] Training [23/62] Loss: 0.02615 
Epoch [294/300] Training [24/62] Loss: 0.01936 
Epoch [294/300] Training [25/62] Loss: 0.03479 
Epoch [294/300] Training [26/62] Loss: 0.04223 
Epoch [294/300] Training [27/62] Loss: 0.02092 
Epoch [294/300] Training [28/62] Loss: 0.06279 
Epoch [294/300] Training [29/62] Loss: 0.04052 
Epoch [294/300] Training [30/62] Loss: 0.02371 
Epoch [294/300] Training [31/62] Loss: 0.11623 
Epoch [294/300] Training [32/62] Loss: 0.02071 
Epoch [294/300] Training [33/62] Loss: 0.02213 
Epoch [294/300] Training [34/62] Loss: 0.04605 
Epoch [294/300] Training [35/62] Loss: 0.01906 
Epoch [294/300] Training [36/62] Loss: 0.02797 
Epoch [294/300] Training [37/62] Loss: 0.02237 
Epoch [294/300] Training [38/62] Loss: 0.02769 
Epoch [294/300] Training [39/62] Loss: 0.02702 
Epoch [294/300] Training [40/62] Loss: 0.02896 
Epoch [294/300] Training [41/62] Loss: 0.03228 
Epoch [294/300] Training [42/62] Loss: 0.02435 
Epoch [294/300] Training [43/62] Loss: 0.02406 
Epoch [294/300] Training [44/62] Loss: 0.02892 
Epoch [294/300] Training [45/62] Loss: 0.03683 
Epoch [294/300] Training [46/62] Loss: 0.02601 
Epoch [294/300] Training [47/62] Loss: 0.02288 
Epoch [294/300] Training [48/62] Loss: 0.03115 
Epoch [294/300] Training [49/62] Loss: 0.02465 
Epoch [294/300] Training [50/62] Loss: 0.03376 
Epoch [294/300] Training [51/62] Loss: 0.02789 
Epoch [294/300] Training [52/62] Loss: 0.03199 
Epoch [294/300] Training [53/62] Loss: 0.03327 
Epoch [294/300] Training [54/62] Loss: 0.03749 
Epoch [294/300] Training [55/62] Loss: 0.02242 
Epoch [294/300] Training [56/62] Loss: 0.02892 
Epoch [294/300] Training [57/62] Loss: 0.02314 
Epoch [294/300] Training [58/62] Loss: 0.03444 
Epoch [294/300] Training [59/62] Loss: 0.02528 
Epoch [294/300] Training [60/62] Loss: 0.02913 
Epoch [294/300] Training [61/62] Loss: 0.02604 
Epoch [294/300] Training [62/62] Loss: 0.05868 
Epoch [294/300] Training metric {'Train/mean dice_metric': 0.978007972240448, 'Train/mean miou_metric': 0.9587157964706421, 'Train/mean f1': 0.9773564338684082, 'Train/mean precision': 0.9728751182556152, 'Train/mean recall': 0.9818791747093201, 'Train/mean hd95_metric': 5.479600429534912}
Epoch [294/300] Validation [1/16] Loss: 0.66230  focal_loss 0.45658  dice_loss 0.20571 
Epoch [294/300] Validation [2/16] Loss: 0.49852  focal_loss 0.22434  dice_loss 0.27418 
Epoch [294/300] Validation [3/16] Loss: 0.77299  focal_loss 0.47056  dice_loss 0.30243 
Epoch [294/300] Validation [4/16] Loss: 0.30946  focal_loss 0.17153  dice_loss 0.13793 
Epoch [294/300] Validation [5/16] Loss: 0.33898  focal_loss 0.13547  dice_loss 0.20351 
Epoch [294/300] Validation [6/16] Loss: 0.38249  focal_loss 0.14389  dice_loss 0.23860 
Epoch [294/300] Validation [7/16] Loss: 0.23115  focal_loss 0.11627  dice_loss 0.11489 
Epoch [294/300] Validation [8/16] Loss: 0.46200  focal_loss 0.19044  dice_loss 0.27156 
Epoch [294/300] Validation [9/16] Loss: 0.25196  focal_loss 0.12003  dice_loss 0.13193 
Epoch [294/300] Validation [10/16] Loss: 0.45950  focal_loss 0.15657  dice_loss 0.30293 
Epoch [294/300] Validation [11/16] Loss: 0.18199  focal_loss 0.07711  dice_loss 0.10489 
Epoch [294/300] Validation [12/16] Loss: 0.43207  focal_loss 0.15201  dice_loss 0.28006 
Epoch [294/300] Validation [13/16] Loss: 0.27191  focal_loss 0.10866  dice_loss 0.16326 
Epoch [294/300] Validation [14/16] Loss: 0.51143  focal_loss 0.21935  dice_loss 0.29208 
Epoch [294/300] Validation [15/16] Loss: 0.10340  focal_loss 0.04094  dice_loss 0.06246 
Epoch [294/300] Validation [16/16] Loss: 0.10945  focal_loss 0.03964  dice_loss 0.06981 
Epoch [294/300] Validation metric {'Val/mean dice_metric': 0.9422224164009094, 'Val/mean miou_metric': 0.9092042446136475, 'Val/mean f1': 0.9492388963699341, 'Val/mean precision': 0.9532326459884644, 'Val/mean recall': 0.9452784061431885, 'Val/mean hd95_metric': 15.49983024597168}
Cheakpoint...
Epoch [294/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9422], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9422224164009094, 'Val/mean miou_metric': 0.9092042446136475, 'Val/mean f1': 0.9492388963699341, 'Val/mean precision': 0.9532326459884644, 'Val/mean recall': 0.9452784061431885, 'Val/mean hd95_metric': 15.49983024597168}
Epoch [295/300] Training [1/62] Loss: 0.03755 
Epoch [295/300] Training [2/62] Loss: 0.03550 
Epoch [295/300] Training [3/62] Loss: 0.03819 
Epoch [295/300] Training [4/62] Loss: 0.03080 
Epoch [295/300] Training [5/62] Loss: 0.02171 
Epoch [295/300] Training [6/62] Loss: 0.02601 
Epoch [295/300] Training [7/62] Loss: 0.02231 
Epoch [295/300] Training [8/62] Loss: 0.02871 
Epoch [295/300] Training [9/62] Loss: 0.01944 
Epoch [295/300] Training [10/62] Loss: 0.04341 
Epoch [295/300] Training [11/62] Loss: 0.02847 
Epoch [295/300] Training [12/62] Loss: 0.02612 
Epoch [295/300] Training [13/62] Loss: 0.01803 
Epoch [295/300] Training [14/62] Loss: 0.02304 
Epoch [295/300] Training [15/62] Loss: 0.03007 
Epoch [295/300] Training [16/62] Loss: 0.01954 
Epoch [295/300] Training [17/62] Loss: 0.02848 
Epoch [295/300] Training [18/62] Loss: 0.03618 
Epoch [295/300] Training [19/62] Loss: 0.03656 
Epoch [295/300] Training [20/62] Loss: 0.01839 
Epoch [295/300] Training [21/62] Loss: 0.03407 
Epoch [295/300] Training [22/62] Loss: 0.03363 
Epoch [295/300] Training [23/62] Loss: 0.11098 
Epoch [295/300] Training [24/62] Loss: 0.04991 
Epoch [295/300] Training [25/62] Loss: 0.03133 
Epoch [295/300] Training [26/62] Loss: 0.03993 
Epoch [295/300] Training [27/62] Loss: 0.02877 
Epoch [295/300] Training [28/62] Loss: 0.02086 
Epoch [295/300] Training [29/62] Loss: 0.02572 
Epoch [295/300] Training [30/62] Loss: 0.03175 
Epoch [295/300] Training [31/62] Loss: 0.03132 
Epoch [295/300] Training [32/62] Loss: 0.02718 
Epoch [295/300] Training [33/62] Loss: 0.03267 
Epoch [295/300] Training [34/62] Loss: 0.03831 
Epoch [295/300] Training [35/62] Loss: 0.02364 
Epoch [295/300] Training [36/62] Loss: 0.03098 
Epoch [295/300] Training [37/62] Loss: 0.02332 
Epoch [295/300] Training [38/62] Loss: 0.02366 
Epoch [295/300] Training [39/62] Loss: 0.06258 
Epoch [295/300] Training [40/62] Loss: 0.02616 
Epoch [295/300] Training [41/62] Loss: 0.02767 
Epoch [295/300] Training [42/62] Loss: 0.01775 
Epoch [295/300] Training [43/62] Loss: 0.02248 
Epoch [295/300] Training [44/62] Loss: 0.02076 
Epoch [295/300] Training [45/62] Loss: 0.02443 
Epoch [295/300] Training [46/62] Loss: 0.02176 
Epoch [295/300] Training [47/62] Loss: 0.02168 
Epoch [295/300] Training [48/62] Loss: 0.03435 
Epoch [295/300] Training [49/62] Loss: 0.06164 
Epoch [295/300] Training [50/62] Loss: 0.03307 
Epoch [295/300] Training [51/62] Loss: 0.07860 
Epoch [295/300] Training [52/62] Loss: 0.04271 
Epoch [295/300] Training [53/62] Loss: 0.03131 
Epoch [295/300] Training [54/62] Loss: 0.02764 
Epoch [295/300] Training [55/62] Loss: 0.02563 
Epoch [295/300] Training [56/62] Loss: 0.03812 
Epoch [295/300] Training [57/62] Loss: 0.03100 
Epoch [295/300] Training [58/62] Loss: 0.01871 
Epoch [295/300] Training [59/62] Loss: 0.02304 
Epoch [295/300] Training [60/62] Loss: 0.02698 
Epoch [295/300] Training [61/62] Loss: 0.03504 
Epoch [295/300] Training [62/62] Loss: 0.02673 
Epoch [295/300] Training metric {'Train/mean dice_metric': 0.97889643907547, 'Train/mean miou_metric': 0.9599897861480713, 'Train/mean f1': 0.9773079752922058, 'Train/mean precision': 0.9728764295578003, 'Train/mean recall': 0.9817800521850586, 'Train/mean hd95_metric': 4.166844367980957}
Epoch [295/300] Validation [1/16] Loss: 0.68576  focal_loss 0.47933  dice_loss 0.20643 
Epoch [295/300] Validation [2/16] Loss: 0.53804  focal_loss 0.23587  dice_loss 0.30218 
Epoch [295/300] Validation [3/16] Loss: 0.73802  focal_loss 0.45091  dice_loss 0.28711 
Epoch [295/300] Validation [4/16] Loss: 0.32384  focal_loss 0.17328  dice_loss 0.15056 
Epoch [295/300] Validation [5/16] Loss: 0.34681  focal_loss 0.14769  dice_loss 0.19912 
Epoch [295/300] Validation [6/16] Loss: 0.30554  focal_loss 0.10623  dice_loss 0.19932 
Epoch [295/300] Validation [7/16] Loss: 0.19243  focal_loss 0.09464  dice_loss 0.09779 
Epoch [295/300] Validation [8/16] Loss: 0.50307  focal_loss 0.22175  dice_loss 0.28132 
Epoch [295/300] Validation [9/16] Loss: 0.20911  focal_loss 0.09637  dice_loss 0.11274 
Epoch [295/300] Validation [10/16] Loss: 0.54562  focal_loss 0.20084  dice_loss 0.34478 
Epoch [295/300] Validation [11/16] Loss: 0.20333  focal_loss 0.08648  dice_loss 0.11685 
Epoch [295/300] Validation [12/16] Loss: 0.48733  focal_loss 0.15102  dice_loss 0.33631 
Epoch [295/300] Validation [13/16] Loss: 0.28386  focal_loss 0.12622  dice_loss 0.15764 
Epoch [295/300] Validation [14/16] Loss: 0.59306  focal_loss 0.26270  dice_loss 0.33036 
Epoch [295/300] Validation [15/16] Loss: 0.18187  focal_loss 0.08055  dice_loss 0.10131 
Epoch [295/300] Validation [16/16] Loss: 0.08961  focal_loss 0.03202  dice_loss 0.05759 
Epoch [295/300] Validation metric {'Val/mean dice_metric': 0.9410820007324219, 'Val/mean miou_metric': 0.9085484147071838, 'Val/mean f1': 0.9484188556671143, 'Val/mean precision': 0.9556037783622742, 'Val/mean recall': 0.9413411021232605, 'Val/mean hd95_metric': 13.94002914428711}
Cheakpoint...
Epoch [295/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9411], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9410820007324219, 'Val/mean miou_metric': 0.9085484147071838, 'Val/mean f1': 0.9484188556671143, 'Val/mean precision': 0.9556037783622742, 'Val/mean recall': 0.9413411021232605, 'Val/mean hd95_metric': 13.94002914428711}
Epoch [296/300] Training [1/62] Loss: 0.02887 
Epoch [296/300] Training [2/62] Loss: 0.01875 
Epoch [296/300] Training [3/62] Loss: 0.01864 
Epoch [296/300] Training [4/62] Loss: 0.01428 
Epoch [296/300] Training [5/62] Loss: 0.03390 
Epoch [296/300] Training [6/62] Loss: 0.03329 
Epoch [296/300] Training [7/62] Loss: 0.02532 
Epoch [296/300] Training [8/62] Loss: 0.02635 
Epoch [296/300] Training [9/62] Loss: 0.02252 
Epoch [296/300] Training [10/62] Loss: 0.03620 
Epoch [296/300] Training [11/62] Loss: 0.02633 
Epoch [296/300] Training [12/62] Loss: 0.01927 
Epoch [296/300] Training [13/62] Loss: 0.03003 
Epoch [296/300] Training [14/62] Loss: 0.05423 
Epoch [296/300] Training [15/62] Loss: 0.02606 
Epoch [296/300] Training [16/62] Loss: 0.03539 
Epoch [296/300] Training [17/62] Loss: 0.01861 
Epoch [296/300] Training [18/62] Loss: 0.01765 
Epoch [296/300] Training [19/62] Loss: 0.02739 
Epoch [296/300] Training [20/62] Loss: 0.02840 
Epoch [296/300] Training [21/62] Loss: 0.02160 
Epoch [296/300] Training [22/62] Loss: 0.02046 
Epoch [296/300] Training [23/62] Loss: 0.03980 
Epoch [296/300] Training [24/62] Loss: 0.02705 
Epoch [296/300] Training [25/62] Loss: 0.02144 
Epoch [296/300] Training [26/62] Loss: 0.02858 
Epoch [296/300] Training [27/62] Loss: 0.02284 
Epoch [296/300] Training [28/62] Loss: 0.04766 
Epoch [296/300] Training [29/62] Loss: 0.03571 
Epoch [296/300] Training [30/62] Loss: 0.04130 
Epoch [296/300] Training [31/62] Loss: 0.02476 
Epoch [296/300] Training [32/62] Loss: 0.02552 
Epoch [296/300] Training [33/62] Loss: 0.02105 
Epoch [296/300] Training [34/62] Loss: 0.02398 
Epoch [296/300] Training [35/62] Loss: 0.04067 
Epoch [296/300] Training [36/62] Loss: 0.02370 
Epoch [296/300] Training [37/62] Loss: 0.03897 
Epoch [296/300] Training [38/62] Loss: 0.02792 
Epoch [296/300] Training [39/62] Loss: 0.02267 
Epoch [296/300] Training [40/62] Loss: 0.02563 
Epoch [296/300] Training [41/62] Loss: 0.04187 
Epoch [296/300] Training [42/62] Loss: 0.02589 
Epoch [296/300] Training [43/62] Loss: 0.04828 
Epoch [296/300] Training [44/62] Loss: 0.03238 
Epoch [296/300] Training [45/62] Loss: 0.01771 
Epoch [296/300] Training [46/62] Loss: 0.09483 
Epoch [296/300] Training [47/62] Loss: 0.01963 
Epoch [296/300] Training [48/62] Loss: 0.03303 
Epoch [296/300] Training [49/62] Loss: 0.02373 
Epoch [296/300] Training [50/62] Loss: 0.02390 
Epoch [296/300] Training [51/62] Loss: 0.02357 
Epoch [296/300] Training [52/62] Loss: 0.03872 
Epoch [296/300] Training [53/62] Loss: 0.03980 
Epoch [296/300] Training [54/62] Loss: 0.03536 
Epoch [296/300] Training [55/62] Loss: 0.07386 
Epoch [296/300] Training [56/62] Loss: 0.03780 
Epoch [296/300] Training [57/62] Loss: 0.02383 
Epoch [296/300] Training [58/62] Loss: 0.02368 
Epoch [296/300] Training [59/62] Loss: 0.03404 
Epoch [296/300] Training [60/62] Loss: 0.04999 
Epoch [296/300] Training [61/62] Loss: 0.05315 
Epoch [296/300] Training [62/62] Loss: 0.06592 
Epoch [296/300] Training metric {'Train/mean dice_metric': 0.9795308709144592, 'Train/mean miou_metric': 0.9604916572570801, 'Train/mean f1': 0.977932870388031, 'Train/mean precision': 0.9736930727958679, 'Train/mean recall': 0.9822096228599548, 'Train/mean hd95_metric': 4.6315813064575195}
Epoch [296/300] Validation [1/16] Loss: 0.68095  focal_loss 0.47674  dice_loss 0.20421 
Epoch [296/300] Validation [2/16] Loss: 0.52754  focal_loss 0.24885  dice_loss 0.27869 
Epoch [296/300] Validation [3/16] Loss: 0.69412  focal_loss 0.40989  dice_loss 0.28423 
Epoch [296/300] Validation [4/16] Loss: 0.31114  focal_loss 0.16689  dice_loss 0.14425 
Epoch [296/300] Validation [5/16] Loss: 0.37207  focal_loss 0.16739  dice_loss 0.20469 
Epoch [296/300] Validation [6/16] Loss: 0.30283  focal_loss 0.10872  dice_loss 0.19411 
Epoch [296/300] Validation [7/16] Loss: 0.22949  focal_loss 0.10850  dice_loss 0.12098 
Epoch [296/300] Validation [8/16] Loss: 0.48244  focal_loss 0.18903  dice_loss 0.29341 
Epoch [296/300] Validation [9/16] Loss: 0.22310  focal_loss 0.10560  dice_loss 0.11750 
Epoch [296/300] Validation [10/16] Loss: 0.60034  focal_loss 0.24781  dice_loss 0.35253 
Epoch [296/300] Validation [11/16] Loss: 0.18190  focal_loss 0.07575  dice_loss 0.10614 
Epoch [296/300] Validation [12/16] Loss: 0.36558  focal_loss 0.11539  dice_loss 0.25019 
Epoch [296/300] Validation [13/16] Loss: 0.23378  focal_loss 0.09316  dice_loss 0.14062 
Epoch [296/300] Validation [14/16] Loss: 0.54439  focal_loss 0.25922  dice_loss 0.28517 
Epoch [296/300] Validation [15/16] Loss: 0.11641  focal_loss 0.04430  dice_loss 0.07211 
Epoch [296/300] Validation [16/16] Loss: 0.10636  focal_loss 0.03975  dice_loss 0.06661 
Epoch [296/300] Validation metric {'Val/mean dice_metric': 0.9439823031425476, 'Val/mean miou_metric': 0.9114863872528076, 'Val/mean f1': 0.9492018222808838, 'Val/mean precision': 0.9543402791023254, 'Val/mean recall': 0.9441184401512146, 'Val/mean hd95_metric': 13.941182136535645}
Cheakpoint...
Epoch [296/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9440], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9439823031425476, 'Val/mean miou_metric': 0.9114863872528076, 'Val/mean f1': 0.9492018222808838, 'Val/mean precision': 0.9543402791023254, 'Val/mean recall': 0.9441184401512146, 'Val/mean hd95_metric': 13.941182136535645}
Epoch [297/300] Training [1/62] Loss: 0.03254 
Epoch [297/300] Training [2/62] Loss: 0.12442 
Epoch [297/300] Training [3/62] Loss: 0.01754 
Epoch [297/300] Training [4/62] Loss: 0.01976 
Epoch [297/300] Training [5/62] Loss: 0.05088 
Epoch [297/300] Training [6/62] Loss: 0.03998 
Epoch [297/300] Training [7/62] Loss: 0.02076 
Epoch [297/300] Training [8/62] Loss: 0.03133 
Epoch [297/300] Training [9/62] Loss: 0.02155 
Epoch [297/300] Training [10/62] Loss: 0.03612 
Epoch [297/300] Training [11/62] Loss: 0.01748 
Epoch [297/300] Training [12/62] Loss: 0.05935 
Epoch [297/300] Training [13/62] Loss: 0.02412 
Epoch [297/300] Training [14/62] Loss: 0.02600 
Epoch [297/300] Training [15/62] Loss: 0.03162 
Epoch [297/300] Training [16/62] Loss: 0.04671 
Epoch [297/300] Training [17/62] Loss: 0.02611 
Epoch [297/300] Training [18/62] Loss: 0.04963 
Epoch [297/300] Training [19/62] Loss: 0.04252 
Epoch [297/300] Training [20/62] Loss: 0.06103 
Epoch [297/300] Training [21/62] Loss: 0.02632 
Epoch [297/300] Training [22/62] Loss: 0.02695 
Epoch [297/300] Training [23/62] Loss: 0.04466 
Epoch [297/300] Training [24/62] Loss: 0.02733 
Epoch [297/300] Training [25/62] Loss: 0.06044 
Epoch [297/300] Training [26/62] Loss: 0.02929 
Epoch [297/300] Training [27/62] Loss: 0.03427 
Epoch [297/300] Training [28/62] Loss: 0.06024 
Epoch [297/300] Training [29/62] Loss: 0.02041 
Epoch [297/300] Training [30/62] Loss: 0.02339 
Epoch [297/300] Training [31/62] Loss: 0.02430 
Epoch [297/300] Training [32/62] Loss: 0.01828 
Epoch [297/300] Training [33/62] Loss: 0.02182 
Epoch [297/300] Training [34/62] Loss: 0.02421 
Epoch [297/300] Training [35/62] Loss: 0.13109 
Epoch [297/300] Training [36/62] Loss: 0.03134 
Epoch [297/300] Training [37/62] Loss: 0.01757 
Epoch [297/300] Training [38/62] Loss: 0.01849 
Epoch [297/300] Training [39/62] Loss: 0.18605 
Epoch [297/300] Training [40/62] Loss: 0.02575 
Epoch [297/300] Training [41/62] Loss: 0.02812 
Epoch [297/300] Training [42/62] Loss: 0.03508 
Epoch [297/300] Training [43/62] Loss: 0.02816 
Epoch [297/300] Training [44/62] Loss: 0.01804 
Epoch [297/300] Training [45/62] Loss: 0.03006 
Epoch [297/300] Training [46/62] Loss: 0.03236 
Epoch [297/300] Training [47/62] Loss: 0.02501 
Epoch [297/300] Training [48/62] Loss: 0.03168 
Epoch [297/300] Training [49/62] Loss: 0.02175 
Epoch [297/300] Training [50/62] Loss: 0.02624 
Epoch [297/300] Training [51/62] Loss: 0.01998 
Epoch [297/300] Training [52/62] Loss: 0.02557 
Epoch [297/300] Training [53/62] Loss: 0.01651 
Epoch [297/300] Training [54/62] Loss: 0.03146 
Epoch [297/300] Training [55/62] Loss: 0.03003 
Epoch [297/300] Training [56/62] Loss: 0.02860 
Epoch [297/300] Training [57/62] Loss: 0.03619 
Epoch [297/300] Training [58/62] Loss: 0.03528 
Epoch [297/300] Training [59/62] Loss: 0.02622 
Epoch [297/300] Training [60/62] Loss: 0.02197 
Epoch [297/300] Training [61/62] Loss: 0.09635 
Epoch [297/300] Training [62/62] Loss: 0.10866 
Epoch [297/300] Training metric {'Train/mean dice_metric': 0.9743790626525879, 'Train/mean miou_metric': 0.955115556716919, 'Train/mean f1': 0.9761359095573425, 'Train/mean precision': 0.9723629951477051, 'Train/mean recall': 0.9799382090568542, 'Train/mean hd95_metric': 5.3186211585998535}
Epoch [297/300] Validation [1/16] Loss: 0.69539  focal_loss 0.48851  dice_loss 0.20688 
Epoch [297/300] Validation [2/16] Loss: 0.51561  focal_loss 0.22139  dice_loss 0.29422 
Epoch [297/300] Validation [3/16] Loss: 0.66302  focal_loss 0.40177  dice_loss 0.26125 
Epoch [297/300] Validation [4/16] Loss: 0.35950  focal_loss 0.18832  dice_loss 0.17118 
Epoch [297/300] Validation [5/16] Loss: 0.41164  focal_loss 0.16858  dice_loss 0.24306 
Epoch [297/300] Validation [6/16] Loss: 0.26852  focal_loss 0.08941  dice_loss 0.17911 
Epoch [297/300] Validation [7/16] Loss: 0.21025  focal_loss 0.10016  dice_loss 0.11009 
Epoch [297/300] Validation [8/16] Loss: 0.59486  focal_loss 0.24582  dice_loss 0.34904 
Epoch [297/300] Validation [9/16] Loss: 0.20813  focal_loss 0.09618  dice_loss 0.11195 
Epoch [297/300] Validation [10/16] Loss: 0.55210  focal_loss 0.21292  dice_loss 0.33918 
Epoch [297/300] Validation [11/16] Loss: 0.16440  focal_loss 0.06390  dice_loss 0.10050 
Epoch [297/300] Validation [12/16] Loss: 0.41374  focal_loss 0.14305  dice_loss 0.27069 
Epoch [297/300] Validation [13/16] Loss: 0.28642  focal_loss 0.13084  dice_loss 0.15558 
Epoch [297/300] Validation [14/16] Loss: 0.58577  focal_loss 0.29817  dice_loss 0.28760 
Epoch [297/300] Validation [15/16] Loss: 0.15516  focal_loss 0.06272  dice_loss 0.09243 
Epoch [297/300] Validation [16/16] Loss: 0.12497  focal_loss 0.04578  dice_loss 0.07919 
Epoch [297/300] Validation metric {'Val/mean dice_metric': 0.9380947947502136, 'Val/mean miou_metric': 0.9056723713874817, 'Val/mean f1': 0.947046160697937, 'Val/mean precision': 0.9539429545402527, 'Val/mean recall': 0.9402483701705933, 'Val/mean hd95_metric': 14.45474910736084}
Cheakpoint...
Epoch [297/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9381], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9380947947502136, 'Val/mean miou_metric': 0.9056723713874817, 'Val/mean f1': 0.947046160697937, 'Val/mean precision': 0.9539429545402527, 'Val/mean recall': 0.9402483701705933, 'Val/mean hd95_metric': 14.45474910736084}
Epoch [298/300] Training [1/62] Loss: 0.01969 
Epoch [298/300] Training [2/62] Loss: 0.02330 
Epoch [298/300] Training [3/62] Loss: 0.04523 
Epoch [298/300] Training [4/62] Loss: 0.02301 
Epoch [298/300] Training [5/62] Loss: 0.15574 
Epoch [298/300] Training [6/62] Loss: 0.03382 
Epoch [298/300] Training [7/62] Loss: 0.05318 
Epoch [298/300] Training [8/62] Loss: 0.06309 
Epoch [298/300] Training [9/62] Loss: 0.02712 
Epoch [298/300] Training [10/62] Loss: 0.02117 
Epoch [298/300] Training [11/62] Loss: 0.03051 
Epoch [298/300] Training [12/62] Loss: 0.02036 
Epoch [298/300] Training [13/62] Loss: 0.04692 
Epoch [298/300] Training [14/62] Loss: 0.03042 
Epoch [298/300] Training [15/62] Loss: 0.02500 
Epoch [298/300] Training [16/62] Loss: 0.02113 
Epoch [298/300] Training [17/62] Loss: 0.06772 
Epoch [298/300] Training [18/62] Loss: 0.02158 
Epoch [298/300] Training [19/62] Loss: 0.03228 
Epoch [298/300] Training [20/62] Loss: 0.04451 
Epoch [298/300] Training [21/62] Loss: 0.04540 
Epoch [298/300] Training [22/62] Loss: 0.01958 
Epoch [298/300] Training [23/62] Loss: 0.04632 
Epoch [298/300] Training [24/62] Loss: 0.03188 
Epoch [298/300] Training [25/62] Loss: 0.02678 
Epoch [298/300] Training [26/62] Loss: 0.02614 
Epoch [298/300] Training [27/62] Loss: 0.04493 
Epoch [298/300] Training [28/62] Loss: 0.06826 
Epoch [298/300] Training [29/62] Loss: 0.03477 
Epoch [298/300] Training [30/62] Loss: 0.02735 
Epoch [298/300] Training [31/62] Loss: 0.03221 
Epoch [298/300] Training [32/62] Loss: 0.02574 
Epoch [298/300] Training [33/62] Loss: 0.03338 
Epoch [298/300] Training [34/62] Loss: 0.03334 
Epoch [298/300] Training [35/62] Loss: 0.06662 
Epoch [298/300] Training [36/62] Loss: 0.02370 
Epoch [298/300] Training [37/62] Loss: 0.02630 
Epoch [298/300] Training [38/62] Loss: 0.01982 
Epoch [298/300] Training [39/62] Loss: 0.02344 
Epoch [298/300] Training [40/62] Loss: 0.01818 
Epoch [298/300] Training [41/62] Loss: 0.02352 
Epoch [298/300] Training [42/62] Loss: 0.02279 
Epoch [298/300] Training [43/62] Loss: 0.02505 
Epoch [298/300] Training [44/62] Loss: 0.02771 
Epoch [298/300] Training [45/62] Loss: 0.02997 
Epoch [298/300] Training [46/62] Loss: 0.02996 
Epoch [298/300] Training [47/62] Loss: 0.02423 
Epoch [298/300] Training [48/62] Loss: 0.02228 
Epoch [298/300] Training [49/62] Loss: 0.02814 
Epoch [298/300] Training [50/62] Loss: 0.01871 
Epoch [298/300] Training [51/62] Loss: 0.03639 
Epoch [298/300] Training [52/62] Loss: 0.02163 
Epoch [298/300] Training [53/62] Loss: 0.03490 
Epoch [298/300] Training [54/62] Loss: 0.04128 
Epoch [298/300] Training [55/62] Loss: 0.01980 
Epoch [298/300] Training [56/62] Loss: 0.04874 
Epoch [298/300] Training [57/62] Loss: 0.03164 
Epoch [298/300] Training [58/62] Loss: 0.05315 
Epoch [298/300] Training [59/62] Loss: 0.02569 
Epoch [298/300] Training [60/62] Loss: 0.02065 
Epoch [298/300] Training [61/62] Loss: 0.04831 
Epoch [298/300] Training [62/62] Loss: 0.03180 
Epoch [298/300] Training metric {'Train/mean dice_metric': 0.9766184687614441, 'Train/mean miou_metric': 0.9568144679069519, 'Train/mean f1': 0.9763551354408264, 'Train/mean precision': 0.9723328948020935, 'Train/mean recall': 0.980410635471344, 'Train/mean hd95_metric': 4.730277061462402}
Epoch [298/300] Validation [1/16] Loss: 0.67280  focal_loss 0.47769  dice_loss 0.19511 
Epoch [298/300] Validation [2/16] Loss: 0.59107  focal_loss 0.24884  dice_loss 0.34223 
Epoch [298/300] Validation [3/16] Loss: 0.65454  focal_loss 0.39640  dice_loss 0.25814 
Epoch [298/300] Validation [4/16] Loss: 0.33470  focal_loss 0.17839  dice_loss 0.15631 
Epoch [298/300] Validation [5/16] Loss: 0.40207  focal_loss 0.16084  dice_loss 0.24123 
Epoch [298/300] Validation [6/16] Loss: 0.32808  focal_loss 0.11493  dice_loss 0.21316 
Epoch [298/300] Validation [7/16] Loss: 0.20994  focal_loss 0.10272  dice_loss 0.10722 
Epoch [298/300] Validation [8/16] Loss: 0.56351  focal_loss 0.23377  dice_loss 0.32974 
Epoch [298/300] Validation [9/16] Loss: 0.23414  focal_loss 0.10457  dice_loss 0.12957 
Epoch [298/300] Validation [10/16] Loss: 0.56901  focal_loss 0.21338  dice_loss 0.35564 
Epoch [298/300] Validation [11/16] Loss: 0.16043  focal_loss 0.05800  dice_loss 0.10243 
Epoch [298/300] Validation [12/16] Loss: 0.53049  focal_loss 0.15439  dice_loss 0.37610 
Epoch [298/300] Validation [13/16] Loss: 0.29437  focal_loss 0.12014  dice_loss 0.17423 
Epoch [298/300] Validation [14/16] Loss: 0.49460  focal_loss 0.22006  dice_loss 0.27454 
Epoch [298/300] Validation [15/16] Loss: 0.11171  focal_loss 0.04335  dice_loss 0.06836 
Epoch [298/300] Validation [16/16] Loss: 0.09949  focal_loss 0.03585  dice_loss 0.06364 
Epoch [298/300] Validation metric {'Val/mean dice_metric': 0.938160240650177, 'Val/mean miou_metric': 0.9048823714256287, 'Val/mean f1': 0.9472386240959167, 'Val/mean precision': 0.9520496726036072, 'Val/mean recall': 0.9424760341644287, 'Val/mean hd95_metric': 14.693215370178223}
Cheakpoint...
Epoch [298/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9382], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.938160240650177, 'Val/mean miou_metric': 0.9048823714256287, 'Val/mean f1': 0.9472386240959167, 'Val/mean precision': 0.9520496726036072, 'Val/mean recall': 0.9424760341644287, 'Val/mean hd95_metric': 14.693215370178223}
Epoch [299/300] Training [1/62] Loss: 0.02448 
Epoch [299/300] Training [2/62] Loss: 0.02243 
Epoch [299/300] Training [3/62] Loss: 0.02454 
Epoch [299/300] Training [4/62] Loss: 0.03896 
Epoch [299/300] Training [5/62] Loss: 0.02101 
Epoch [299/300] Training [6/62] Loss: 0.03150 
Epoch [299/300] Training [7/62] Loss: 0.03888 
Epoch [299/300] Training [8/62] Loss: 0.05314 
Epoch [299/300] Training [9/62] Loss: 0.02850 
Epoch [299/300] Training [10/62] Loss: 0.05402 
Epoch [299/300] Training [11/62] Loss: 0.02946 
Epoch [299/300] Training [12/62] Loss: 0.04138 
Epoch [299/300] Training [13/62] Loss: 0.02196 
Epoch [299/300] Training [14/62] Loss: 0.02606 
Epoch [299/300] Training [15/62] Loss: 0.02358 
Epoch [299/300] Training [16/62] Loss: 0.02738 
Epoch [299/300] Training [17/62] Loss: 0.02192 
Epoch [299/300] Training [18/62] Loss: 0.02690 
Epoch [299/300] Training [19/62] Loss: 0.02478 
Epoch [299/300] Training [20/62] Loss: 0.02928 
Epoch [299/300] Training [21/62] Loss: 0.02826 
Epoch [299/300] Training [22/62] Loss: 0.03156 
Epoch [299/300] Training [23/62] Loss: 0.03452 
Epoch [299/300] Training [24/62] Loss: 0.02207 
Epoch [299/300] Training [25/62] Loss: 0.01944 
Epoch [299/300] Training [26/62] Loss: 0.02790 
Epoch [299/300] Training [27/62] Loss: 0.02378 
Epoch [299/300] Training [28/62] Loss: 0.03915 
Epoch [299/300] Training [29/62] Loss: 0.03625 
Epoch [299/300] Training [30/62] Loss: 0.02874 
Epoch [299/300] Training [31/62] Loss: 0.02707 
Epoch [299/300] Training [32/62] Loss: 0.01799 
Epoch [299/300] Training [33/62] Loss: 0.06755 
Epoch [299/300] Training [34/62] Loss: 0.02409 
Epoch [299/300] Training [35/62] Loss: 0.02675 
Epoch [299/300] Training [36/62] Loss: 0.04378 
Epoch [299/300] Training [37/62] Loss: 0.02629 
Epoch [299/300] Training [38/62] Loss: 0.02504 
Epoch [299/300] Training [39/62] Loss: 0.02692 
Epoch [299/300] Training [40/62] Loss: 0.05489 
Epoch [299/300] Training [41/62] Loss: 0.01963 
Epoch [299/300] Training [42/62] Loss: 0.01997 
Epoch [299/300] Training [43/62] Loss: 0.02068 
Epoch [299/300] Training [44/62] Loss: 0.12495 
Epoch [299/300] Training [45/62] Loss: 0.02233 
Epoch [299/300] Training [46/62] Loss: 0.02209 
Epoch [299/300] Training [47/62] Loss: 0.02282 
Epoch [299/300] Training [48/62] Loss: 0.02591 
Epoch [299/300] Training [49/62] Loss: 0.02657 
Epoch [299/300] Training [50/62] Loss: 0.03615 
Epoch [299/300] Training [51/62] Loss: 0.03506 
Epoch [299/300] Training [52/62] Loss: 0.02160 
Epoch [299/300] Training [53/62] Loss: 0.03380 
Epoch [299/300] Training [54/62] Loss: 0.02897 
Epoch [299/300] Training [55/62] Loss: 0.02086 
Epoch [299/300] Training [56/62] Loss: 0.02630 
Epoch [299/300] Training [57/62] Loss: 0.04063 
Epoch [299/300] Training [58/62] Loss: 0.02226 
Epoch [299/300] Training [59/62] Loss: 0.02219 
Epoch [299/300] Training [60/62] Loss: 0.02972 
Epoch [299/300] Training [61/62] Loss: 0.05360 
Epoch [299/300] Training [62/62] Loss: 0.03723 
Epoch [299/300] Training metric {'Train/mean dice_metric': 0.9787691235542297, 'Train/mean miou_metric': 0.9603385925292969, 'Train/mean f1': 0.97804194688797, 'Train/mean precision': 0.9739058613777161, 'Train/mean recall': 0.9822133779525757, 'Train/mean hd95_metric': 4.129222393035889}
Epoch [299/300] Validation [1/16] Loss: 0.68736  focal_loss 0.47823  dice_loss 0.20913 
Epoch [299/300] Validation [2/16] Loss: 0.59512  focal_loss 0.25590  dice_loss 0.33922 
Epoch [299/300] Validation [3/16] Loss: 0.68349  focal_loss 0.39370  dice_loss 0.28979 
Epoch [299/300] Validation [4/16] Loss: 0.30640  focal_loss 0.16398  dice_loss 0.14242 
Epoch [299/300] Validation [5/16] Loss: 0.36259  focal_loss 0.14602  dice_loss 0.21656 
Epoch [299/300] Validation [6/16] Loss: 0.32220  focal_loss 0.11720  dice_loss 0.20500 
Epoch [299/300] Validation [7/16] Loss: 0.18430  focal_loss 0.09036  dice_loss 0.09394 
Epoch [299/300] Validation [8/16] Loss: 0.52951  focal_loss 0.21752  dice_loss 0.31199 
Epoch [299/300] Validation [9/16] Loss: 0.20983  focal_loss 0.09056  dice_loss 0.11927 
Epoch [299/300] Validation [10/16] Loss: 0.56792  focal_loss 0.22393  dice_loss 0.34399 
Epoch [299/300] Validation [11/16] Loss: 0.15141  focal_loss 0.06006  dice_loss 0.09135 
Epoch [299/300] Validation [12/16] Loss: 0.49770  focal_loss 0.13505  dice_loss 0.36265 
Epoch [299/300] Validation [13/16] Loss: 0.26898  focal_loss 0.12717  dice_loss 0.14181 
Epoch [299/300] Validation [14/16] Loss: 0.55666  focal_loss 0.26931  dice_loss 0.28734 
Epoch [299/300] Validation [15/16] Loss: 0.14726  focal_loss 0.05828  dice_loss 0.08898 
Epoch [299/300] Validation [16/16] Loss: 0.14057  focal_loss 0.05424  dice_loss 0.08633 
Epoch [299/300] Validation metric {'Val/mean dice_metric': 0.9406846165657043, 'Val/mean miou_metric': 0.9086644649505615, 'Val/mean f1': 0.9487375617027283, 'Val/mean precision': 0.9536914229393005, 'Val/mean recall': 0.9438350796699524, 'Val/mean hd95_metric': 14.585332870483398}
Cheakpoint...
Epoch [299/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9407], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9406846165657043, 'Val/mean miou_metric': 0.9086644649505615, 'Val/mean f1': 0.9487375617027283, 'Val/mean precision': 0.9536914229393005, 'Val/mean recall': 0.9438350796699524, 'Val/mean hd95_metric': 14.585332870483398}
Epoch [300/300] Training [1/62] Loss: 0.02731 
Epoch [300/300] Training [2/62] Loss: 0.06012 
Epoch [300/300] Training [3/62] Loss: 0.02030 
Epoch [300/300] Training [4/62] Loss: 0.04027 
Epoch [300/300] Training [5/62] Loss: 0.01972 
Epoch [300/300] Training [6/62] Loss: 0.01877 
Epoch [300/300] Training [7/62] Loss: 0.02933 
Epoch [300/300] Training [8/62] Loss: 0.02829 
Epoch [300/300] Training [9/62] Loss: 0.03437 
Epoch [300/300] Training [10/62] Loss: 0.02097 
Epoch [300/300] Training [11/62] Loss: 0.01759 
Epoch [300/300] Training [12/62] Loss: 0.04013 
Epoch [300/300] Training [13/62] Loss: 0.03462 
Epoch [300/300] Training [14/62] Loss: 0.02379 
Epoch [300/300] Training [15/62] Loss: 0.02292 
Epoch [300/300] Training [16/62] Loss: 0.02395 
Epoch [300/300] Training [17/62] Loss: 0.02641 
Epoch [300/300] Training [18/62] Loss: 0.02647 
Epoch [300/300] Training [19/62] Loss: 0.03611 
Epoch [300/300] Training [20/62] Loss: 0.03081 
Epoch [300/300] Training [21/62] Loss: 0.03689 
Epoch [300/300] Training [22/62] Loss: 0.02744 
Epoch [300/300] Training [23/62] Loss: 0.05408 
Epoch [300/300] Training [24/62] Loss: 0.02058 
Epoch [300/300] Training [25/62] Loss: 0.03322 
Epoch [300/300] Training [26/62] Loss: 0.02611 
Epoch [300/300] Training [27/62] Loss: 0.03248 
Epoch [300/300] Training [28/62] Loss: 0.05351 
Epoch [300/300] Training [29/62] Loss: 0.02234 
Epoch [300/300] Training [30/62] Loss: 0.04817 
Epoch [300/300] Training [31/62] Loss: 0.02347 
Epoch [300/300] Training [32/62] Loss: 0.03671 
Epoch [300/300] Training [33/62] Loss: 0.03598 
Epoch [300/300] Training [34/62] Loss: 0.02289 
Epoch [300/300] Training [35/62] Loss: 0.01881 
Epoch [300/300] Training [36/62] Loss: 0.03612 
Epoch [300/300] Training [37/62] Loss: 0.04073 
Epoch [300/300] Training [38/62] Loss: 0.03262 
Epoch [300/300] Training [39/62] Loss: 0.02127 
Epoch [300/300] Training [40/62] Loss: 0.02273 
Epoch [300/300] Training [41/62] Loss: 0.03185 
Epoch [300/300] Training [42/62] Loss: 0.02586 
Epoch [300/300] Training [43/62] Loss: 0.02891 
Epoch [300/300] Training [44/62] Loss: 0.04299 
Epoch [300/300] Training [45/62] Loss: 0.02249 
Epoch [300/300] Training [46/62] Loss: 0.02057 
Epoch [300/300] Training [47/62] Loss: 0.02634 
Epoch [300/300] Training [48/62] Loss: 0.02181 
Epoch [300/300] Training [49/62] Loss: 0.02305 
Epoch [300/300] Training [50/62] Loss: 0.02894 
Epoch [300/300] Training [51/62] Loss: 0.02124 
Epoch [300/300] Training [52/62] Loss: 0.03410 
Epoch [300/300] Training [53/62] Loss: 0.02749 
Epoch [300/300] Training [54/62] Loss: 0.02009 
Epoch [300/300] Training [55/62] Loss: 0.02122 
Epoch [300/300] Training [56/62] Loss: 0.09263 
Epoch [300/300] Training [57/62] Loss: 0.05714 
Epoch [300/300] Training [58/62] Loss: 0.03046 
Epoch [300/300] Training [59/62] Loss: 0.05872 
Epoch [300/300] Training [60/62] Loss: 0.02244 
Epoch [300/300] Training [61/62] Loss: 0.15261 
Epoch [300/300] Training [62/62] Loss: 0.15162 
Epoch [300/300] Training metric {'Train/mean dice_metric': 0.9769875407218933, 'Train/mean miou_metric': 0.9578467011451721, 'Train/mean f1': 0.9775931239128113, 'Train/mean precision': 0.973205029964447, 'Train/mean recall': 0.982020914554596, 'Train/mean hd95_metric': 5.047483921051025}
Epoch [300/300] Validation [1/16] Loss: 0.67936  focal_loss 0.47814  dice_loss 0.20122 
Epoch [300/300] Validation [2/16] Loss: 0.52414  focal_loss 0.23072  dice_loss 0.29342 
Epoch [300/300] Validation [3/16] Loss: 0.68619  focal_loss 0.40736  dice_loss 0.27883 
Epoch [300/300] Validation [4/16] Loss: 0.34554  focal_loss 0.18693  dice_loss 0.15860 
Epoch [300/300] Validation [5/16] Loss: 0.36139  focal_loss 0.14641  dice_loss 0.21498 
Epoch [300/300] Validation [6/16] Loss: 0.33076  focal_loss 0.11925  dice_loss 0.21151 
Epoch [300/300] Validation [7/16] Loss: 0.20003  focal_loss 0.09981  dice_loss 0.10022 
Epoch [300/300] Validation [8/16] Loss: 0.52581  focal_loss 0.21420  dice_loss 0.31162 
Epoch [300/300] Validation [9/16] Loss: 0.20324  focal_loss 0.09312  dice_loss 0.11012 
Epoch [300/300] Validation [10/16] Loss: 0.60965  focal_loss 0.24108  dice_loss 0.36858 
Epoch [300/300] Validation [11/16] Loss: 0.15606  focal_loss 0.06441  dice_loss 0.09165 
Epoch [300/300] Validation [12/16] Loss: 0.38398  focal_loss 0.12593  dice_loss 0.25805 
Epoch [300/300] Validation [13/16] Loss: 0.25467  focal_loss 0.10116  dice_loss 0.15351 
Epoch [300/300] Validation [14/16] Loss: 0.62106  focal_loss 0.28961  dice_loss 0.33145 
Epoch [300/300] Validation [15/16] Loss: 0.13000  focal_loss 0.05706  dice_loss 0.07295 
Epoch [300/300] Validation [16/16] Loss: 0.09827  focal_loss 0.03705  dice_loss 0.06122 
Epoch [300/300] Validation metric {'Val/mean dice_metric': 0.9405573606491089, 'Val/mean miou_metric': 0.9086335897445679, 'Val/mean f1': 0.9494867920875549, 'Val/mean precision': 0.9545724391937256, 'Val/mean recall': 0.9444552063941956, 'Val/mean hd95_metric': 14.199026107788086}
Cheakpoint...
Epoch [300/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9406], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9405573606491089, 'Val/mean miou_metric': 0.9086335897445679, 'Val/mean f1': 0.9494867920875549, 'Val/mean precision': 0.9545724391937256, 'Val/mean recall': 0.9444552063941956, 'Val/mean hd95_metric': 14.199026107788086}
最高acc: tensor([0.9442], device='cuda:0')
最高class : {'Val/mean dice_metric': 0.9442289471626282, 'Val/mean miou_metric': 0.9133356809616089, 'Val/mean f1': 0.9501060843467712, 'Val/mean precision': 0.9557749629020691, 'Val/mean recall': 0.9445040822029114, 'Val/mean hd95_metric': 12.401506423950195}
最优保存轮数: 283
