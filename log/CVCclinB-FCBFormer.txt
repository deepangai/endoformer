<EasyDict 0x7f21b0f67e70
  'Unet': <EasyDict 0x7f205482dbc0
    'bilinear': False,
    'n_channels': 3,
    'n_classes': 1
  >,
  'cfp_net': <EasyDict 0x7f205482dc10
    'block_1': 2,
    'block_2': 6,
    'classes': 1
  >,
  'cvc_unetr': <EasyDict 0x7f205482db20
    'dims': [64, 128, 320, 512],
    'kernel_size': 3,
    'mlp_ratio': 4,
    'model_dir': '/workspace/Encvis/Code/src/DuAT/pvt_v2_b2.pth',
    'out_dim': 32
  >,
  'dataset': <EasyDict 0x7f205482d9e0
    'CVC_ClinicDB': <EasyDict 0x7f205482db70
      'batch_size': 8,
      'data_root': '/dataset/cv/seg/CVC-ClinicDB/',
      'image_size': 352,
      'num_workers': 4,
      'train_ratio': 0.8
    >
  >,
  'duat': <EasyDict 0x7f205482da30
    'dim': 32,
    'dims': [64, 128, 320, 512],
    'model_dir': '/workspace/Encvis/Code/src/DuAT/pvt_v2_b2.pth'
  >,
  'finetune': <EasyDict 0x7f205482dad0
    'checkpoint': 'CVC'
  >,
  'swin_unetr': <EasyDict 0x7f205482dcb0
    'img_size': [352, 352],
    'in_channels': 3,
    'out_channels': 1,
    'spatial_dims': 2,
    'use_checkpoint': True
  >,
  'trainer': <EasyDict 0x7f205b5b49a0
    'lr': 0.001,
    'min_lr': 1e-07,
    'num_epochs': 300,
    'optimizer': 'adamw',
    'pred_ratio_var': 0,
    'resume': True,
    'train_ratio': 0.8,
    'warmup': 2,
    'weight_decay': 0.05,
    'weight_decay_end': 0.04
  >,
  'trans_unet': <EasyDict 0x7f205482dd00
    'block_num': 8,
    'class_num': 1,
    'head_num': 4,
    'img_dim': 352,
    'in_channels': 3,
    'mlp_dim': 512,
    'out_channels': 128,
    'patch_dim': 16
  >,
  'u_netr': <EasyDict 0x7f205482dda0
    'feature_size': 64,
    'img_size': 352,
    'in_channels': 3,
    'out_channels': 1,
    'spatial_dims': 2
  >,
  'unet': <EasyDict 0x7f205482d940
    'channels': [4, 8, 16, 32, 64],
    'in_channels': 3,
    'out_channels': 1,
    'spatial_dims': 2,
    'strides': [2, 2, 2, 2]
  >,
  'unet2': <EasyDict 0x7f205482dc60
    'in_channels': 3,
    'out_channels': 1
  >
>
Load Model...
Load Dataloader...
[Errno 2] No such file or directory: '/workspace/Unitest/model_store/CVC/checkpoint/pytorch_model.bin'
Failed to load the training model！
loaded state dict contains a parameter group that doesn't match the size of optimizer's group
Failed to load training state！
Start Training！
Epoch [1/300] Training [1/62] Loss: 1.13795 
Epoch [1/300] Training [2/62] Loss: 1.07808 
Epoch [1/300] Training [3/62] Loss: 1.09918 
Epoch [1/300] Training [4/62] Loss: 1.11596 
Epoch [1/300] Training [5/62] Loss: 1.14677 
Epoch [1/300] Training [6/62] Loss: 1.11198 
Epoch [1/300] Training [7/62] Loss: 1.10441 
Epoch [1/300] Training [8/62] Loss: 1.06333 
Epoch [1/300] Training [9/62] Loss: 1.13226 
Epoch [1/300] Training [10/62] Loss: 1.06709 
Epoch [1/300] Training [11/62] Loss: 1.04141 
Epoch [1/300] Training [12/62] Loss: 1.16329 
Epoch [1/300] Training [13/62] Loss: 1.15293 
Epoch [1/300] Training [14/62] Loss: 1.08775 
Epoch [1/300] Training [15/62] Loss: 1.13520 
Epoch [1/300] Training [16/62] Loss: 1.07784 
Epoch [1/300] Training [17/62] Loss: 1.10672 
Epoch [1/300] Training [18/62] Loss: 1.14991 
Epoch [1/300] Training [19/62] Loss: 1.11688 
Epoch [1/300] Training [20/62] Loss: 1.06030 
Epoch [1/300] Training [21/62] Loss: 1.04602 
Epoch [1/300] Training [22/62] Loss: 1.10543 
Epoch [1/300] Training [23/62] Loss: 1.10523 
Epoch [1/300] Training [24/62] Loss: 1.07090 
Epoch [1/300] Training [25/62] Loss: 1.13297 
Epoch [1/300] Training [26/62] Loss: 1.09114 
Epoch [1/300] Training [27/62] Loss: 1.09387 
Epoch [1/300] Training [28/62] Loss: 1.06469 
Epoch [1/300] Training [29/62] Loss: 1.16368 
Epoch [1/300] Training [30/62] Loss: 1.06217 
Epoch [1/300] Training [31/62] Loss: 1.08459 
Epoch [1/300] Training [32/62] Loss: 1.09631 
Epoch [1/300] Training [33/62] Loss: 1.10635 
Epoch [1/300] Training [34/62] Loss: 1.10445 
Epoch [1/300] Training [35/62] Loss: 1.07146 
Epoch [1/300] Training [36/62] Loss: 1.14000 
Epoch [1/300] Training [37/62] Loss: 1.06041 
Epoch [1/300] Training [38/62] Loss: 1.12112 
Epoch [1/300] Training [39/62] Loss: 1.01991 
Epoch [1/300] Training [40/62] Loss: 1.09569 
Epoch [1/300] Training [41/62] Loss: 1.02701 
Epoch [1/300] Training [42/62] Loss: 1.09171 
Epoch [1/300] Training [43/62] Loss: 1.09818 
Epoch [1/300] Training [44/62] Loss: 1.07042 
Epoch [1/300] Training [45/62] Loss: 1.12804 
Epoch [1/300] Training [46/62] Loss: 1.12353 
Epoch [1/300] Training [47/62] Loss: 1.17184 
Epoch [1/300] Training [48/62] Loss: 1.09579 
Epoch [1/300] Training [49/62] Loss: 1.07232 
Epoch [1/300] Training [50/62] Loss: 1.11906 
Epoch [1/300] Training [51/62] Loss: 1.14153 
Epoch [1/300] Training [52/62] Loss: 1.05001 
Epoch [1/300] Training [53/62] Loss: 1.14114 
Epoch [1/300] Training [54/62] Loss: 1.14364 
Epoch [1/300] Training [55/62] Loss: 1.09975 
Epoch [1/300] Training [56/62] Loss: 1.07332 
Epoch [1/300] Training [57/62] Loss: 0.98233 
Epoch [1/300] Training [58/62] Loss: 1.11049 
Epoch [1/300] Training [59/62] Loss: 1.14061 
Epoch [1/300] Training [60/62] Loss: 1.14971 
Epoch [1/300] Training [61/62] Loss: 1.10875 
Epoch [1/300] Training [62/62] Loss: 1.09899 
Epoch [1/300] Training metric {'Train/mean dice_metric': 0.15299585461616516, 'Train/mean miou_metric': 0.08779919892549515, 'Train/mean f1': 0.16356991231441498, 'Train/mean precision': 0.0923004075884819, 'Train/mean recall': 0.7178757190704346, 'Train/mean hd95_metric': 202.97219848632812}
Epoch [1/300] Validation [1/16] Loss: 1.05878  focal_loss 0.24321  dice_loss 0.81557 
Epoch [1/300] Validation [2/16] Loss: 1.10995  focal_loss 0.24771  dice_loss 0.86224 
Epoch [1/300] Validation [3/16] Loss: 1.11771  focal_loss 0.24749  dice_loss 0.87022 
Epoch [1/300] Validation [4/16] Loss: 1.10221  focal_loss 0.24798  dice_loss 0.85423 
Epoch [1/300] Validation [5/16] Loss: 1.12065  focal_loss 0.24596  dice_loss 0.87469 
Epoch [1/300] Validation [6/16] Loss: 1.11438  focal_loss 0.24668  dice_loss 0.86770 
Epoch [1/300] Validation [7/16] Loss: 1.09288  focal_loss 0.24651  dice_loss 0.84637 
Epoch [1/300] Validation [8/16] Loss: 1.14751  focal_loss 0.24779  dice_loss 0.89971 
Epoch [1/300] Validation [9/16] Loss: 1.09999  focal_loss 0.24774  dice_loss 0.85225 
Epoch [1/300] Validation [10/16] Loss: 1.08606  focal_loss 0.24818  dice_loss 0.83788 
Epoch [1/300] Validation [11/16] Loss: 1.11452  focal_loss 0.24877  dice_loss 0.86575 
Epoch [1/300] Validation [12/16] Loss: 1.15678  focal_loss 0.25088  dice_loss 0.90590 
Epoch [1/300] Validation [13/16] Loss: 1.12766  focal_loss 0.25227  dice_loss 0.87539 
Epoch [1/300] Validation [14/16] Loss: 1.12206  focal_loss 0.24703  dice_loss 0.87503 
Epoch [1/300] Validation [15/16] Loss: 1.07943  focal_loss 0.24893  dice_loss 0.83050 
Epoch [1/300] Validation [16/16] Loss: 1.06680  focal_loss 0.24602  dice_loss 0.82077 
Epoch [1/300] Validation metric {'Val/mean dice_metric': 0.15099304914474487, 'Val/mean miou_metric': 0.08641505241394043, 'Val/mean f1': 0.16107876598834991, 'Val/mean precision': 0.09075105935335159, 'Val/mean recall': 0.7157526016235352, 'Val/mean hd95_metric': 204.02957153320312}
Cheakpoint...
Epoch [1/300] best acc:tensor([0.1510], device='cuda:0'), Now : mean acc: tensor([0.1510], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.15099304914474487, 'Val/mean miou_metric': 0.08641505241394043, 'Val/mean f1': 0.16107876598834991, 'Val/mean precision': 0.09075105935335159, 'Val/mean recall': 0.7157526016235352, 'Val/mean hd95_metric': 204.02957153320312}
Epoch [2/300] Training [1/62] Loss: 1.08067 
Epoch [2/300] Training [2/62] Loss: 1.12939 
Epoch [2/300] Training [3/62] Loss: 1.07767 
Epoch [2/300] Training [4/62] Loss: 1.08109 
Epoch [2/300] Training [5/62] Loss: 1.06837 
Epoch [2/300] Training [6/62] Loss: 1.08465 
Epoch [2/300] Training [7/62] Loss: 1.10282 
Epoch [2/300] Training [8/62] Loss: 1.11794 
Epoch [2/300] Training [9/62] Loss: 1.05744 
Epoch [2/300] Training [10/62] Loss: 1.07733 
Epoch [2/300] Training [11/62] Loss: 1.14617 
Epoch [2/300] Training [12/62] Loss: 1.11406 
Epoch [2/300] Training [13/62] Loss: 1.10825 
Epoch [2/300] Training [14/62] Loss: 1.11331 
Epoch [2/300] Training [15/62] Loss: 1.10596 
Epoch [2/300] Training [16/62] Loss: 1.09682 
Epoch [2/300] Training [17/62] Loss: 1.11467 
Epoch [2/300] Training [18/62] Loss: 1.12290 
Epoch [2/300] Training [19/62] Loss: 1.13544 
Epoch [2/300] Training [20/62] Loss: 1.04021 
Epoch [2/300] Training [21/62] Loss: 1.08274 
Epoch [2/300] Training [22/62] Loss: 1.11745 
Epoch [2/300] Training [23/62] Loss: 1.02259 
Epoch [2/300] Training [24/62] Loss: 1.13069 
Epoch [2/300] Training [25/62] Loss: 1.13858 
Epoch [2/300] Training [26/62] Loss: 1.10453 
Epoch [2/300] Training [27/62] Loss: 1.16610 
Epoch [2/300] Training [28/62] Loss: 1.11703 
Epoch [2/300] Training [29/62] Loss: 1.10538 
Epoch [2/300] Training [30/62] Loss: 1.14163 
Epoch [2/300] Training [31/62] Loss: 1.11970 
Epoch [2/300] Training [32/62] Loss: 1.10386 
Epoch [2/300] Training [33/62] Loss: 1.10246 
Epoch [2/300] Training [34/62] Loss: 1.14228 
Epoch [2/300] Training [35/62] Loss: 1.08587 
Epoch [2/300] Training [36/62] Loss: 1.09950 
Epoch [2/300] Training [37/62] Loss: 1.13025 
Epoch [2/300] Training [38/62] Loss: 1.05415 
Epoch [2/300] Training [39/62] Loss: 1.10830 
Epoch [2/300] Training [40/62] Loss: 1.05497 
Epoch [2/300] Training [41/62] Loss: 1.13837 
Epoch [2/300] Training [42/62] Loss: 1.09269 
Epoch [2/300] Training [43/62] Loss: 1.07901 
Epoch [2/300] Training [44/62] Loss: 1.09664 
Epoch [2/300] Training [45/62] Loss: 1.07136 
Epoch [2/300] Training [46/62] Loss: 1.10017 
Epoch [2/300] Training [47/62] Loss: 1.08965 
Epoch [2/300] Training [48/62] Loss: 1.05436 
Epoch [2/300] Training [49/62] Loss: 1.20557 
Epoch [2/300] Training [50/62] Loss: 1.07040 
Epoch [2/300] Training [51/62] Loss: 1.09578 
Epoch [2/300] Training [52/62] Loss: 1.09392 
Epoch [2/300] Training [53/62] Loss: 1.07000 
Epoch [2/300] Training [54/62] Loss: 1.11661 
Epoch [2/300] Training [55/62] Loss: 1.13993 
Epoch [2/300] Training [56/62] Loss: 1.07964 
Epoch [2/300] Training [57/62] Loss: 1.09068 
Epoch [2/300] Training [58/62] Loss: 1.09581 
Epoch [2/300] Training [59/62] Loss: 1.03882 
Epoch [2/300] Training [60/62] Loss: 1.11502 
Epoch [2/300] Training [61/62] Loss: 1.07447 
Epoch [2/300] Training [62/62] Loss: 1.12314 
Epoch [2/300] Training metric {'Train/mean dice_metric': 0.15293022990226746, 'Train/mean miou_metric': 0.08768054842948914, 'Train/mean f1': 0.16334833204746246, 'Train/mean precision': 0.09218163788318634, 'Train/mean recall': 0.7165244221687317, 'Train/mean hd95_metric': 203.2284698486328}
Epoch [2/300] Validation [1/16] Loss: 1.05420  focal_loss 0.24092  dice_loss 0.81328 
Epoch [2/300] Validation [2/16] Loss: 1.11338  focal_loss 0.25009  dice_loss 0.86329 
Epoch [2/300] Validation [3/16] Loss: 1.12085  focal_loss 0.24888  dice_loss 0.87197 
Epoch [2/300] Validation [4/16] Loss: 1.10541  focal_loss 0.24905  dice_loss 0.85636 
Epoch [2/300] Validation [5/16] Loss: 1.12452  focal_loss 0.24751  dice_loss 0.87700 
Epoch [2/300] Validation [6/16] Loss: 1.10967  focal_loss 0.24423  dice_loss 0.86545 
Epoch [2/300] Validation [7/16] Loss: 1.09523  focal_loss 0.24766  dice_loss 0.84757 
Epoch [2/300] Validation [8/16] Loss: 1.14877  focal_loss 0.24943  dice_loss 0.89934 
Epoch [2/300] Validation [9/16] Loss: 1.10165  focal_loss 0.24868  dice_loss 0.85297 
Epoch [2/300] Validation [10/16] Loss: 1.09027  focal_loss 0.24973  dice_loss 0.84054 
Epoch [2/300] Validation [11/16] Loss: 1.11220  focal_loss 0.24767  dice_loss 0.86453 
Epoch [2/300] Validation [12/16] Loss: 1.16012  focal_loss 0.25246  dice_loss 0.90765 
Epoch [2/300] Validation [13/16] Loss: 1.12749  focal_loss 0.25284  dice_loss 0.87465 
Epoch [2/300] Validation [14/16] Loss: 1.11956  focal_loss 0.24596  dice_loss 0.87360 
Epoch [2/300] Validation [15/16] Loss: 1.07956  focal_loss 0.24884  dice_loss 0.83072 
Epoch [2/300] Validation [16/16] Loss: 1.06179  focal_loss 0.24331  dice_loss 0.81849 
Epoch [2/300] Validation metric {'Val/mean dice_metric': 0.15075862407684326, 'Val/mean miou_metric': 0.08618656545877457, 'Val/mean f1': 0.16065554320812225, 'Val/mean precision': 0.0905139297246933, 'Val/mean recall': 0.7137904167175293, 'Val/mean hd95_metric': 204.31729125976562}
Cheakpoint...
Epoch [2/300] best acc:tensor([0.1510], device='cuda:0'), Now : mean acc: tensor([0.1508], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.15075862407684326, 'Val/mean miou_metric': 0.08618656545877457, 'Val/mean f1': 0.16065554320812225, 'Val/mean precision': 0.0905139297246933, 'Val/mean recall': 0.7137904167175293, 'Val/mean hd95_metric': 204.31729125976562}
Epoch [3/300] Training [1/62] Loss: 1.08647 
Epoch [3/300] Training [2/62] Loss: 1.17699 
Epoch [3/300] Training [3/62] Loss: 0.95145 
Epoch [3/300] Training [4/62] Loss: 0.84056 
Epoch [3/300] Training [5/62] Loss: 0.83689 
Epoch [3/300] Training [6/62] Loss: 0.86919 
Epoch [3/300] Training [7/62] Loss: 0.87511 
Epoch [3/300] Training [8/62] Loss: 0.77798 
Epoch [3/300] Training [9/62] Loss: 1.03400 
Epoch [3/300] Training [10/62] Loss: 0.83560 
Epoch [3/300] Training [11/62] Loss: 0.92957 
Epoch [3/300] Training [12/62] Loss: 0.93636 
Epoch [3/300] Training [13/62] Loss: 0.97418 
Epoch [3/300] Training [14/62] Loss: 0.86753 
Epoch [3/300] Training [15/62] Loss: 0.87701 
Epoch [3/300] Training [16/62] Loss: 0.89405 
Epoch [3/300] Training [17/62] Loss: 0.91980 
Epoch [3/300] Training [18/62] Loss: 0.84992 
Epoch [3/300] Training [19/62] Loss: 0.82713 
Epoch [3/300] Training [20/62] Loss: 0.90796 
Epoch [3/300] Training [21/62] Loss: 0.93891 
Epoch [3/300] Training [22/62] Loss: 0.88216 
Epoch [3/300] Training [23/62] Loss: 0.84738 
Epoch [3/300] Training [24/62] Loss: 0.84010 
Epoch [3/300] Training [25/62] Loss: 0.85750 
Epoch [3/300] Training [26/62] Loss: 0.88912 
Epoch [3/300] Training [27/62] Loss: 0.95608 
Epoch [3/300] Training [28/62] Loss: 0.87628 
Epoch [3/300] Training [29/62] Loss: 0.90370 
Epoch [3/300] Training [30/62] Loss: 0.82557 
Epoch [3/300] Training [31/62] Loss: 0.95925 
Epoch [3/300] Training [32/62] Loss: 0.80942 
Epoch [3/300] Training [33/62] Loss: 0.75527 
Epoch [3/300] Training [34/62] Loss: 0.84243 
Epoch [3/300] Training [35/62] Loss: 0.81665 
Epoch [3/300] Training [36/62] Loss: 0.83310 
Epoch [3/300] Training [37/62] Loss: 0.89803 
Epoch [3/300] Training [38/62] Loss: 0.78003 
Epoch [3/300] Training [39/62] Loss: 0.90690 
Epoch [3/300] Training [40/62] Loss: 0.76909 
Epoch [3/300] Training [41/62] Loss: 0.86655 
Epoch [3/300] Training [42/62] Loss: 0.79573 
Epoch [3/300] Training [43/62] Loss: 0.90174 
Epoch [3/300] Training [44/62] Loss: 0.72028 
Epoch [3/300] Training [45/62] Loss: 0.72563 
Epoch [3/300] Training [46/62] Loss: 0.83827 
Epoch [3/300] Training [47/62] Loss: 0.89298 
Epoch [3/300] Training [48/62] Loss: 0.92906 
Epoch [3/300] Training [49/62] Loss: 0.81233 
Epoch [3/300] Training [50/62] Loss: 0.71973 
Epoch [3/300] Training [51/62] Loss: 0.81456 
Epoch [3/300] Training [52/62] Loss: 0.76165 
Epoch [3/300] Training [53/62] Loss: 0.93331 
Epoch [3/300] Training [54/62] Loss: 0.67297 
Epoch [3/300] Training [55/62] Loss: 0.78019 
Epoch [3/300] Training [56/62] Loss: 0.86461 
Epoch [3/300] Training [57/62] Loss: 0.78827 
Epoch [3/300] Training [58/62] Loss: 0.83786 
Epoch [3/300] Training [59/62] Loss: 0.84316 
Epoch [3/300] Training [60/62] Loss: 0.88138 
Epoch [3/300] Training [61/62] Loss: 0.99276 
Epoch [3/300] Training [62/62] Loss: 0.91963 
Epoch [3/300] Training metric {'Train/mean dice_metric': 0.26369601488113403, 'Train/mean miou_metric': 0.177962988615036, 'Train/mean f1': 0.3376685678958893, 'Train/mean precision': 0.2835574448108673, 'Train/mean recall': 0.41730213165283203, 'Train/mean hd95_metric': 113.69857025146484}
Epoch [3/300] Validation [1/16] Loss: 0.93821  focal_loss 0.17444  dice_loss 0.76377 
Epoch [3/300] Validation [2/16] Loss: 0.95769  focal_loss 0.10974  dice_loss 0.84796 
Epoch [3/300] Validation [3/16] Loss: 0.93150  focal_loss 0.12239  dice_loss 0.80912 
Epoch [3/300] Validation [4/16] Loss: 0.94072  focal_loss 0.14760  dice_loss 0.79312 
Epoch [3/300] Validation [5/16] Loss: 0.80928  focal_loss 0.05371  dice_loss 0.75556 
Epoch [3/300] Validation [6/16] Loss: 0.84408  focal_loss 0.07770  dice_loss 0.76639 
Epoch [3/300] Validation [7/16] Loss: 0.84912  focal_loss 0.10449  dice_loss 0.74463 
Epoch [3/300] Validation [8/16] Loss: 0.90502  focal_loss 0.07653  dice_loss 0.82849 
Epoch [3/300] Validation [9/16] Loss: 0.85077  focal_loss 0.08771  dice_loss 0.76305 
Epoch [3/300] Validation [10/16] Loss: 0.97146  focal_loss 0.15165  dice_loss 0.81981 
Epoch [3/300] Validation [11/16] Loss: 0.83645  focal_loss 0.08236  dice_loss 0.75409 
Epoch [3/300] Validation [12/16] Loss: 0.89724  focal_loss 0.05651  dice_loss 0.84073 
Epoch [3/300] Validation [13/16] Loss: 0.86448  focal_loss 0.09397  dice_loss 0.77051 
Epoch [3/300] Validation [14/16] Loss: 0.95707  focal_loss 0.12568  dice_loss 0.83139 
Epoch [3/300] Validation [15/16] Loss: 0.88178  focal_loss 0.12251  dice_loss 0.75927 
Epoch [3/300] Validation [16/16] Loss: 0.76607  focal_loss 0.08042  dice_loss 0.68565 
Epoch [3/300] Validation metric {'Val/mean dice_metric': 0.2212849110364914, 'Val/mean miou_metric': 0.14874394237995148, 'Val/mean f1': 0.31111109256744385, 'Val/mean precision': 0.28400683403015137, 'Val/mean recall': 0.343934565782547, 'Val/mean hd95_metric': 111.17887115478516}
Cheakpoint...
Epoch [3/300] best acc:tensor([0.2213], device='cuda:0'), Now : mean acc: tensor([0.2213], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.2212849110364914, 'Val/mean miou_metric': 0.14874394237995148, 'Val/mean f1': 0.31111109256744385, 'Val/mean precision': 0.28400683403015137, 'Val/mean recall': 0.343934565782547, 'Val/mean hd95_metric': 111.17887115478516}
Epoch [4/300] Training [1/62] Loss: 0.86370 
Epoch [4/300] Training [2/62] Loss: 0.91843 
Epoch [4/300] Training [3/62] Loss: 1.01240 
Epoch [4/300] Training [4/62] Loss: 0.80943 
Epoch [4/300] Training [5/62] Loss: 0.92645 
Epoch [4/300] Training [6/62] Loss: 0.83139 
Epoch [4/300] Training [7/62] Loss: 0.86389 
Epoch [4/300] Training [8/62] Loss: 0.91215 
Epoch [4/300] Training [9/62] Loss: 0.91569 
Epoch [4/300] Training [10/62] Loss: 0.87659 
Epoch [4/300] Training [11/62] Loss: 0.81459 
Epoch [4/300] Training [12/62] Loss: 0.83828 
Epoch [4/300] Training [13/62] Loss: 0.90388 
Epoch [4/300] Training [14/62] Loss: 0.82455 
Epoch [4/300] Training [15/62] Loss: 0.94480 
Epoch [4/300] Training [16/62] Loss: 0.84468 
Epoch [4/300] Training [17/62] Loss: 0.82427 
Epoch [4/300] Training [18/62] Loss: 0.83975 
Epoch [4/300] Training [19/62] Loss: 0.84288 
Epoch [4/300] Training [20/62] Loss: 0.78626 
Epoch [4/300] Training [21/62] Loss: 0.86256 
Epoch [4/300] Training [22/62] Loss: 0.85072 
Epoch [4/300] Training [23/62] Loss: 0.82868 
Epoch [4/300] Training [24/62] Loss: 0.80912 
Epoch [4/300] Training [25/62] Loss: 0.83750 
Epoch [4/300] Training [26/62] Loss: 0.76578 
Epoch [4/300] Training [27/62] Loss: 0.95479 
Epoch [4/300] Training [28/62] Loss: 0.98915 
Epoch [4/300] Training [29/62] Loss: 1.14360 
Epoch [4/300] Training [30/62] Loss: 0.82032 
Epoch [4/300] Training [31/62] Loss: 0.88216 
Epoch [4/300] Training [32/62] Loss: 0.83922 
Epoch [4/300] Training [33/62] Loss: 0.77907 
Epoch [4/300] Training [34/62] Loss: 0.82182 
Epoch [4/300] Training [35/62] Loss: 0.82927 
Epoch [4/300] Training [36/62] Loss: 0.82529 
Epoch [4/300] Training [37/62] Loss: 0.85519 
Epoch [4/300] Training [38/62] Loss: 0.69685 
Epoch [4/300] Training [39/62] Loss: 0.88613 
Epoch [4/300] Training [40/62] Loss: 0.75915 
Epoch [4/300] Training [41/62] Loss: 0.88838 
Epoch [4/300] Training [42/62] Loss: 0.80183 
Epoch [4/300] Training [43/62] Loss: 0.83856 
Epoch [4/300] Training [44/62] Loss: 0.84328 
Epoch [4/300] Training [45/62] Loss: 0.85975 
Epoch [4/300] Training [46/62] Loss: 0.85792 
Epoch [4/300] Training [47/62] Loss: 0.90531 
Epoch [4/300] Training [48/62] Loss: 0.89429 
Epoch [4/300] Training [49/62] Loss: 0.81177 
Epoch [4/300] Training [50/62] Loss: 0.74127 
Epoch [4/300] Training [51/62] Loss: 0.77751 
Epoch [4/300] Training [52/62] Loss: 0.75789 
Epoch [4/300] Training [53/62] Loss: 0.81933 
Epoch [4/300] Training [54/62] Loss: 0.79105 
Epoch [4/300] Training [55/62] Loss: 0.80543 
Epoch [4/300] Training [56/62] Loss: 0.83289 
Epoch [4/300] Training [57/62] Loss: 0.83074 
Epoch [4/300] Training [58/62] Loss: 0.78172 
Epoch [4/300] Training [59/62] Loss: 0.69400 
Epoch [4/300] Training [60/62] Loss: 0.75837 
Epoch [4/300] Training [61/62] Loss: 0.77534 
Epoch [4/300] Training [62/62] Loss: 0.81014 
Epoch [4/300] Training metric {'Train/mean dice_metric': 0.30727505683898926, 'Train/mean miou_metric': 0.21055278182029724, 'Train/mean f1': 0.373930960893631, 'Train/mean precision': 0.32421499490737915, 'Train/mean recall': 0.44165560603141785, 'Train/mean hd95_metric': 109.1844711303711}
Epoch [4/300] Validation [1/16] Loss: 0.79670  focal_loss 0.16258  dice_loss 0.63413 
Epoch [4/300] Validation [2/16] Loss: 0.85466  focal_loss 0.11709  dice_loss 0.73757 
Epoch [4/300] Validation [3/16] Loss: 0.98228  focal_loss 0.20958  dice_loss 0.77270 
Epoch [4/300] Validation [4/16] Loss: 0.94037  focal_loss 0.20279  dice_loss 0.73758 
Epoch [4/300] Validation [5/16] Loss: 0.84987  focal_loss 0.13975  dice_loss 0.71012 
Epoch [4/300] Validation [6/16] Loss: 0.80159  focal_loss 0.12250  dice_loss 0.67908 
Epoch [4/300] Validation [7/16] Loss: 0.80609  focal_loss 0.14949  dice_loss 0.65660 
Epoch [4/300] Validation [8/16] Loss: 0.93294  focal_loss 0.15419  dice_loss 0.77875 
Epoch [4/300] Validation [9/16] Loss: 0.84739  focal_loss 0.15264  dice_loss 0.69475 
Epoch [4/300] Validation [10/16] Loss: 0.91606  focal_loss 0.18322  dice_loss 0.73284 
Epoch [4/300] Validation [11/16] Loss: 0.83637  focal_loss 0.14167  dice_loss 0.69470 
Epoch [4/300] Validation [12/16] Loss: 0.90610  focal_loss 0.13008  dice_loss 0.77602 
Epoch [4/300] Validation [13/16] Loss: 0.86373  focal_loss 0.16258  dice_loss 0.70115 
Epoch [4/300] Validation [14/16] Loss: 0.95296  focal_loss 0.18342  dice_loss 0.76954 
Epoch [4/300] Validation [15/16] Loss: 0.84142  focal_loss 0.14475  dice_loss 0.69667 
Epoch [4/300] Validation [16/16] Loss: 0.66187  focal_loss 0.11745  dice_loss 0.54443 
Epoch [4/300] Validation metric {'Val/mean dice_metric': 0.31535807251930237, 'Val/mean miou_metric': 0.215036079287529, 'Val/mean f1': 0.3739193379878998, 'Val/mean precision': 0.3017841875553131, 'Val/mean recall': 0.491371214389801, 'Val/mean hd95_metric': 114.84862518310547}
Cheakpoint...
Epoch [4/300] best acc:tensor([0.3154], device='cuda:0'), Now : mean acc: tensor([0.3154], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.31535807251930237, 'Val/mean miou_metric': 0.215036079287529, 'Val/mean f1': 0.3739193379878998, 'Val/mean precision': 0.3017841875553131, 'Val/mean recall': 0.491371214389801, 'Val/mean hd95_metric': 114.84862518310547}
Epoch [5/300] Training [1/62] Loss: 0.85175 
Epoch [5/300] Training [2/62] Loss: 0.86142 
Epoch [5/300] Training [3/62] Loss: 0.84739 
Epoch [5/300] Training [4/62] Loss: 0.82501 
Epoch [5/300] Training [5/62] Loss: 0.83027 
Epoch [5/300] Training [6/62] Loss: 0.88063 
Epoch [5/300] Training [7/62] Loss: 0.78295 
Epoch [5/300] Training [8/62] Loss: 0.88419 
Epoch [5/300] Training [9/62] Loss: 0.84535 
Epoch [5/300] Training [10/62] Loss: 0.92467 
Epoch [5/300] Training [11/62] Loss: 0.91155 
Epoch [5/300] Training [12/62] Loss: 0.85874 
Epoch [5/300] Training [13/62] Loss: 0.85902 
Epoch [5/300] Training [14/62] Loss: 0.88410 
Epoch [5/300] Training [15/62] Loss: 0.86674 
Epoch [5/300] Training [16/62] Loss: 0.88259 
Epoch [5/300] Training [17/62] Loss: 0.84325 
Epoch [5/300] Training [18/62] Loss: 0.91671 
Epoch [5/300] Training [19/62] Loss: 0.92744 
Epoch [5/300] Training [20/62] Loss: 0.71094 
Epoch [5/300] Training [21/62] Loss: 0.83313 
Epoch [5/300] Training [22/62] Loss: 0.72683 
Epoch [5/300] Training [23/62] Loss: 0.86159 
Epoch [5/300] Training [24/62] Loss: 0.96918 
Epoch [5/300] Training [25/62] Loss: 0.88738 
Epoch [5/300] Training [26/62] Loss: 0.91824 
Epoch [5/300] Training [27/62] Loss: 0.92760 
Epoch [5/300] Training [28/62] Loss: 0.91140 
Epoch [5/300] Training [29/62] Loss: 0.89672 
Epoch [5/300] Training [30/62] Loss: 0.87128 
Epoch [5/300] Training [31/62] Loss: 0.74769 
Epoch [5/300] Training [32/62] Loss: 0.84416 
Epoch [5/300] Training [33/62] Loss: 0.86804 
Epoch [5/300] Training [34/62] Loss: 0.83396 
Epoch [5/300] Training [35/62] Loss: 0.81365 
Epoch [5/300] Training [36/62] Loss: 0.78250 
Epoch [5/300] Training [37/62] Loss: 0.78029 
Epoch [5/300] Training [38/62] Loss: 0.90686 
Epoch [5/300] Training [39/62] Loss: 0.74457 
Epoch [5/300] Training [40/62] Loss: 0.72786 
Epoch [5/300] Training [41/62] Loss: 0.85566 
Epoch [5/300] Training [42/62] Loss: 0.71606 
Epoch [5/300] Training [43/62] Loss: 0.82164 
Epoch [5/300] Training [44/62] Loss: 0.60686 
Epoch [5/300] Training [45/62] Loss: 0.83636 
Epoch [5/300] Training [46/62] Loss: 0.98699 
Epoch [5/300] Training [47/62] Loss: 0.70777 
Epoch [5/300] Training [48/62] Loss: 0.90988 
Epoch [5/300] Training [49/62] Loss: 0.94978 
Epoch [5/300] Training [50/62] Loss: 0.83675 
Epoch [5/300] Training [51/62] Loss: 0.78508 
Epoch [5/300] Training [52/62] Loss: 0.81658 
Epoch [5/300] Training [53/62] Loss: 0.75346 
Epoch [5/300] Training [54/62] Loss: 0.87419 
Epoch [5/300] Training [55/62] Loss: 0.79497 
Epoch [5/300] Training [56/62] Loss: 0.86640 
Epoch [5/300] Training [57/62] Loss: 0.78328 
Epoch [5/300] Training [58/62] Loss: 0.73745 
Epoch [5/300] Training [59/62] Loss: 0.82406 
Epoch [5/300] Training [60/62] Loss: 0.79632 
Epoch [5/300] Training [61/62] Loss: 0.79888 
Epoch [5/300] Training [62/62] Loss: 0.41428 
Epoch [5/300] Training metric {'Train/mean dice_metric': 0.3135237395763397, 'Train/mean miou_metric': 0.21730823814868927, 'Train/mean f1': 0.3776399493217468, 'Train/mean precision': 0.33127832412719727, 'Train/mean recall': 0.4390896260738373, 'Train/mean hd95_metric': 109.38372039794922}
Epoch [5/300] Validation [1/16] Loss: 0.76725  focal_loss 0.13624  dice_loss 0.63101 
Epoch [5/300] Validation [2/16] Loss: 0.86050  focal_loss 0.11312  dice_loss 0.74738 
Epoch [5/300] Validation [3/16] Loss: 0.92434  focal_loss 0.16468  dice_loss 0.75966 
Epoch [5/300] Validation [4/16] Loss: 0.87907  focal_loss 0.15729  dice_loss 0.72178 
Epoch [5/300] Validation [5/16] Loss: 0.83323  focal_loss 0.11764  dice_loss 0.71560 
Epoch [5/300] Validation [6/16] Loss: 0.78428  focal_loss 0.10074  dice_loss 0.68354 
Epoch [5/300] Validation [7/16] Loss: 0.78045  focal_loss 0.12628  dice_loss 0.65417 
Epoch [5/300] Validation [8/16] Loss: 0.92555  focal_loss 0.14000  dice_loss 0.78555 
Epoch [5/300] Validation [9/16] Loss: 0.82061  focal_loss 0.12931  dice_loss 0.69130 
Epoch [5/300] Validation [10/16] Loss: 0.89901  focal_loss 0.15888  dice_loss 0.74013 
Epoch [5/300] Validation [11/16] Loss: 0.82113  focal_loss 0.12232  dice_loss 0.69881 
Epoch [5/300] Validation [12/16] Loss: 0.88567  focal_loss 0.11733  dice_loss 0.76834 
Epoch [5/300] Validation [13/16] Loss: 0.82759  focal_loss 0.12972  dice_loss 0.69787 
Epoch [5/300] Validation [14/16] Loss: 0.92330  focal_loss 0.15395  dice_loss 0.76934 
Epoch [5/300] Validation [15/16] Loss: 0.81160  focal_loss 0.11990  dice_loss 0.69170 
Epoch [5/300] Validation [16/16] Loss: 0.66370  focal_loss 0.10637  dice_loss 0.55733 
Epoch [5/300] Validation metric {'Val/mean dice_metric': 0.323223739862442, 'Val/mean miou_metric': 0.2227046936750412, 'Val/mean f1': 0.38109639286994934, 'Val/mean precision': 0.31388795375823975, 'Val/mean recall': 0.48492705821990967, 'Val/mean hd95_metric': 113.34463500976562}
Cheakpoint...
Epoch [5/300] best acc:tensor([0.3232], device='cuda:0'), Now : mean acc: tensor([0.3232], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.323223739862442, 'Val/mean miou_metric': 0.2227046936750412, 'Val/mean f1': 0.38109639286994934, 'Val/mean precision': 0.31388795375823975, 'Val/mean recall': 0.48492705821990967, 'Val/mean hd95_metric': 113.34463500976562}
Epoch [6/300] Training [1/62] Loss: 0.82704 
Epoch [6/300] Training [2/62] Loss: 0.79850 
Epoch [6/300] Training [3/62] Loss: 0.88001 
Epoch [6/300] Training [4/62] Loss: 0.86583 
Epoch [6/300] Training [5/62] Loss: 0.77451 
Epoch [6/300] Training [6/62] Loss: 0.89698 
Epoch [6/300] Training [7/62] Loss: 0.75943 
Epoch [6/300] Training [8/62] Loss: 0.80408 
Epoch [6/300] Training [9/62] Loss: 0.87644 
Epoch [6/300] Training [10/62] Loss: 0.85910 
Epoch [6/300] Training [11/62] Loss: 0.86107 
Epoch [6/300] Training [12/62] Loss: 0.84256 
Epoch [6/300] Training [13/62] Loss: 0.86083 
Epoch [6/300] Training [14/62] Loss: 0.83560 
Epoch [6/300] Training [15/62] Loss: 0.86877 
Epoch [6/300] Training [16/62] Loss: 0.80635 
Epoch [6/300] Training [17/62] Loss: 0.75677 
Epoch [6/300] Training [18/62] Loss: 0.85034 
Epoch [6/300] Training [19/62] Loss: 1.00196 
Epoch [6/300] Training [20/62] Loss: 0.79309 
Epoch [6/300] Training [21/62] Loss: 0.83759 
Epoch [6/300] Training [22/62] Loss: 0.84743 
Epoch [6/300] Training [23/62] Loss: 0.78447 
Epoch [6/300] Training [24/62] Loss: 0.73456 
Epoch [6/300] Training [25/62] Loss: 0.86111 
Epoch [6/300] Training [26/62] Loss: 0.88491 
Epoch [6/300] Training [27/62] Loss: 0.78021 
Epoch [6/300] Training [28/62] Loss: 0.76776 
Epoch [6/300] Training [29/62] Loss: 0.80615 
Epoch [6/300] Training [30/62] Loss: 0.95464 
Epoch [6/300] Training [31/62] Loss: 0.83250 
Epoch [6/300] Training [32/62] Loss: 0.87639 
Epoch [6/300] Training [33/62] Loss: 0.81644 
Epoch [6/300] Training [34/62] Loss: 0.85227 
Epoch [6/300] Training [35/62] Loss: 0.74390 
Epoch [6/300] Training [36/62] Loss: 0.79959 
Epoch [6/300] Training [37/62] Loss: 0.88435 
Epoch [6/300] Training [38/62] Loss: 0.83396 
Epoch [6/300] Training [39/62] Loss: 0.72561 
Epoch [6/300] Training [40/62] Loss: 0.83284 
Epoch [6/300] Training [41/62] Loss: 0.71731 
Epoch [6/300] Training [42/62] Loss: 0.86156 
Epoch [6/300] Training [43/62] Loss: 0.66118 
Epoch [6/300] Training [44/62] Loss: 0.70710 
Epoch [6/300] Training [45/62] Loss: 1.00000 
Epoch [6/300] Training [46/62] Loss: 0.77691 
Epoch [6/300] Training [47/62] Loss: 0.80224 
Epoch [6/300] Training [48/62] Loss: 0.72887 
Epoch [6/300] Training [49/62] Loss: 0.81609 
Epoch [6/300] Training [50/62] Loss: 0.85723 
Epoch [6/300] Training [51/62] Loss: 0.79401 
Epoch [6/300] Training [52/62] Loss: 0.80737 
Epoch [6/300] Training [53/62] Loss: 0.79081 
Epoch [6/300] Training [54/62] Loss: 0.80193 
Epoch [6/300] Training [55/62] Loss: 0.77120 
Epoch [6/300] Training [56/62] Loss: 0.85952 
Epoch [6/300] Training [57/62] Loss: 0.71144 
Epoch [6/300] Training [58/62] Loss: 0.89014 
Epoch [6/300] Training [59/62] Loss: 0.88781 
Epoch [6/300] Training [60/62] Loss: 0.92533 
Epoch [6/300] Training [61/62] Loss: 0.77732 
Epoch [6/300] Training [62/62] Loss: 0.96051 
Epoch [6/300] Training metric {'Train/mean dice_metric': 0.34076330065727234, 'Train/mean miou_metric': 0.2342655062675476, 'Train/mean f1': 0.39500534534454346, 'Train/mean precision': 0.34309864044189453, 'Train/mean recall': 0.4654175043106079, 'Train/mean hd95_metric': 104.43937683105469}
Epoch [6/300] Validation [1/16] Loss: 0.82432  focal_loss 0.12621  dice_loss 0.69811 
Epoch [6/300] Validation [2/16] Loss: 0.85170  focal_loss 0.06640  dice_loss 0.78529 
Epoch [6/300] Validation [3/16] Loss: 0.90558  focal_loss 0.10902  dice_loss 0.79655 
Epoch [6/300] Validation [4/16] Loss: 0.87355  focal_loss 0.10875  dice_loss 0.76480 
Epoch [6/300] Validation [5/16] Loss: 0.77858  focal_loss 0.04257  dice_loss 0.73601 
Epoch [6/300] Validation [6/16] Loss: 0.76316  focal_loss 0.04635  dice_loss 0.71681 
Epoch [6/300] Validation [7/16] Loss: 0.79398  focal_loss 0.08111  dice_loss 0.71287 
Epoch [6/300] Validation [8/16] Loss: 0.84865  focal_loss 0.05821  dice_loss 0.79044 
Epoch [6/300] Validation [9/16] Loss: 0.83154  focal_loss 0.07856  dice_loss 0.75299 
Epoch [6/300] Validation [10/16] Loss: 0.90710  focal_loss 0.12624  dice_loss 0.78086 
Epoch [6/300] Validation [11/16] Loss: 0.77901  focal_loss 0.06105  dice_loss 0.71797 
Epoch [6/300] Validation [12/16] Loss: 0.83148  focal_loss 0.03894  dice_loss 0.79254 
Epoch [6/300] Validation [13/16] Loss: 0.80223  focal_loss 0.06983  dice_loss 0.73240 
Epoch [6/300] Validation [14/16] Loss: 0.89574  focal_loss 0.09414  dice_loss 0.80160 
Epoch [6/300] Validation [15/16] Loss: 0.84273  focal_loss 0.10333  dice_loss 0.73940 
Epoch [6/300] Validation [16/16] Loss: 0.68436  focal_loss 0.05221  dice_loss 0.63215 
Epoch [6/300] Validation metric {'Val/mean dice_metric': 0.32225796580314636, 'Val/mean miou_metric': 0.2213306874036789, 'Val/mean f1': 0.38322731852531433, 'Val/mean precision': 0.3508239984512329, 'Val/mean recall': 0.4222255051136017, 'Val/mean hd95_metric': 103.5615463256836}
Cheakpoint...
Epoch [6/300] best acc:tensor([0.3232], device='cuda:0'), Now : mean acc: tensor([0.3223], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.32225796580314636, 'Val/mean miou_metric': 0.2213306874036789, 'Val/mean f1': 0.38322731852531433, 'Val/mean precision': 0.3508239984512329, 'Val/mean recall': 0.4222255051136017, 'Val/mean hd95_metric': 103.5615463256836}
Epoch [7/300] Training [1/62] Loss: 0.85771 
Epoch [7/300] Training [2/62] Loss: 0.80234 
Epoch [7/300] Training [3/62] Loss: 0.91455 
Epoch [7/300] Training [4/62] Loss: 0.74380 
Epoch [7/300] Training [5/62] Loss: 0.78352 
Epoch [7/300] Training [6/62] Loss: 0.91979 
Epoch [7/300] Training [7/62] Loss: 0.81391 
Epoch [7/300] Training [8/62] Loss: 0.77504 
Epoch [7/300] Training [9/62] Loss: 0.83366 
Epoch [7/300] Training [10/62] Loss: 0.86732 
Epoch [7/300] Training [11/62] Loss: 0.68665 
Epoch [7/300] Training [12/62] Loss: 0.87970 
Epoch [7/300] Training [13/62] Loss: 0.82664 
Epoch [7/300] Training [14/62] Loss: 0.91383 
Epoch [7/300] Training [15/62] Loss: 0.81814 
Epoch [7/300] Training [16/62] Loss: 0.91490 
Epoch [7/300] Training [17/62] Loss: 0.89503 
Epoch [7/300] Training [18/62] Loss: 0.90056 
Epoch [7/300] Training [19/62] Loss: 0.89515 
Epoch [7/300] Training [20/62] Loss: 0.87418 
Epoch [7/300] Training [21/62] Loss: 0.78784 
Epoch [7/300] Training [22/62] Loss: 0.86260 
Epoch [7/300] Training [23/62] Loss: 0.70598 
Epoch [7/300] Training [24/62] Loss: 0.87105 
Epoch [7/300] Training [25/62] Loss: 0.91579 
Epoch [7/300] Training [26/62] Loss: 0.79663 
Epoch [7/300] Training [27/62] Loss: 0.80420 
Epoch [7/300] Training [28/62] Loss: 0.86981 
Epoch [7/300] Training [29/62] Loss: 0.82870 
Epoch [7/300] Training [30/62] Loss: 0.79532 
Epoch [7/300] Training [31/62] Loss: 0.81152 
Epoch [7/300] Training [32/62] Loss: 0.69818 
Epoch [7/300] Training [33/62] Loss: 0.80487 
Epoch [7/300] Training [34/62] Loss: 0.81832 
Epoch [7/300] Training [35/62] Loss: 0.85398 
Epoch [7/300] Training [36/62] Loss: 0.80339 
Epoch [7/300] Training [37/62] Loss: 0.80151 
Epoch [7/300] Training [38/62] Loss: 0.88195 
Epoch [7/300] Training [39/62] Loss: 0.74954 
Epoch [7/300] Training [40/62] Loss: 0.75201 
Epoch [7/300] Training [41/62] Loss: 0.70046 
Epoch [7/300] Training [42/62] Loss: 0.76520 
Epoch [7/300] Training [43/62] Loss: 0.81451 
Epoch [7/300] Training [44/62] Loss: 0.79578 
Epoch [7/300] Training [45/62] Loss: 0.94657 
Epoch [7/300] Training [46/62] Loss: 0.79634 
Epoch [7/300] Training [47/62] Loss: 0.79372 
Epoch [7/300] Training [48/62] Loss: 0.81096 
Epoch [7/300] Training [49/62] Loss: 0.76099 
Epoch [7/300] Training [50/62] Loss: 0.86055 
Epoch [7/300] Training [51/62] Loss: 0.82811 
Epoch [7/300] Training [52/62] Loss: 0.67668 
Epoch [7/300] Training [53/62] Loss: 0.70791 
Epoch [7/300] Training [54/62] Loss: 0.80779 
Epoch [7/300] Training [55/62] Loss: 0.83829 
Epoch [7/300] Training [56/62] Loss: 0.84222 
Epoch [7/300] Training [57/62] Loss: 0.74509 
Epoch [7/300] Training [58/62] Loss: 0.73643 
Epoch [7/300] Training [59/62] Loss: 0.72048 
Epoch [7/300] Training [60/62] Loss: 0.75263 
Epoch [7/300] Training [61/62] Loss: 0.94551 
Epoch [7/300] Training [62/62] Loss: 1.41862 
Epoch [7/300] Training metric {'Train/mean dice_metric': 0.34765756130218506, 'Train/mean miou_metric': 0.24140256643295288, 'Train/mean f1': 0.40916818380355835, 'Train/mean precision': 0.3611162602901459, 'Train/mean recall': 0.47197097539901733, 'Train/mean hd95_metric': 109.69303894042969}
Epoch [7/300] Validation [1/16] Loss: 0.80509  focal_loss 0.15900  dice_loss 0.64609 
Epoch [7/300] Validation [2/16] Loss: 0.84219  focal_loss 0.08943  dice_loss 0.75275 
Epoch [7/300] Validation [3/16] Loss: 0.90929  focal_loss 0.15226  dice_loss 0.75704 
Epoch [7/300] Validation [4/16] Loss: 0.88658  focal_loss 0.16170  dice_loss 0.72488 
Epoch [7/300] Validation [5/16] Loss: 0.78007  focal_loss 0.08625  dice_loss 0.69382 
Epoch [7/300] Validation [6/16] Loss: 0.71317  focal_loss 0.06829  dice_loss 0.64487 
Epoch [7/300] Validation [7/16] Loss: 0.74232  focal_loss 0.09758  dice_loss 0.64474 
Epoch [7/300] Validation [8/16] Loss: 0.83664  focal_loss 0.09039  dice_loss 0.74624 
Epoch [7/300] Validation [9/16] Loss: 0.78600  focal_loss 0.09481  dice_loss 0.69119 
Epoch [7/300] Validation [10/16] Loss: 0.83542  focal_loss 0.13001  dice_loss 0.70541 
Epoch [7/300] Validation [11/16] Loss: 0.73104  focal_loss 0.08764  dice_loss 0.64340 
Epoch [7/300] Validation [12/16] Loss: 0.83060  focal_loss 0.07123  dice_loss 0.75936 
Epoch [7/300] Validation [13/16] Loss: 0.76034  focal_loss 0.08924  dice_loss 0.67109 
Epoch [7/300] Validation [14/16] Loss: 0.89875  focal_loss 0.12230  dice_loss 0.77646 
Epoch [7/300] Validation [15/16] Loss: 0.77002  focal_loss 0.09645  dice_loss 0.67357 
Epoch [7/300] Validation [16/16] Loss: 0.58136  focal_loss 0.06518  dice_loss 0.51618 
Epoch [7/300] Validation metric {'Val/mean dice_metric': 0.3525959551334381, 'Val/mean miou_metric': 0.24499660730361938, 'Val/mean f1': 0.4115539491176605, 'Val/mean precision': 0.3529587686061859, 'Val/mean recall': 0.4934767186641693, 'Val/mean hd95_metric': 111.4883041381836}
Cheakpoint...
Epoch [7/300] best acc:tensor([0.3526], device='cuda:0'), Now : mean acc: tensor([0.3526], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3525959551334381, 'Val/mean miou_metric': 0.24499660730361938, 'Val/mean f1': 0.4115539491176605, 'Val/mean precision': 0.3529587686061859, 'Val/mean recall': 0.4934767186641693, 'Val/mean hd95_metric': 111.4883041381836}
Epoch [8/300] Training [1/62] Loss: 0.83529 
Epoch [8/300] Training [2/62] Loss: 0.71760 
Epoch [8/300] Training [3/62] Loss: 0.77498 
Epoch [8/300] Training [4/62] Loss: 0.73035 
Epoch [8/300] Training [5/62] Loss: 0.86836 
Epoch [8/300] Training [6/62] Loss: 0.76816 
Epoch [8/300] Training [7/62] Loss: 0.82232 
Epoch [8/300] Training [8/62] Loss: 0.83790 
Epoch [8/300] Training [9/62] Loss: 0.87951 
Epoch [8/300] Training [10/62] Loss: 0.86106 
Epoch [8/300] Training [11/62] Loss: 0.85690 
Epoch [8/300] Training [12/62] Loss: 0.84170 
Epoch [8/300] Training [13/62] Loss: 0.70037 
Epoch [8/300] Training [14/62] Loss: 0.82811 
Epoch [8/300] Training [15/62] Loss: 0.78833 
Epoch [8/300] Training [16/62] Loss: 0.83232 
Epoch [8/300] Training [17/62] Loss: 0.74670 
Epoch [8/300] Training [18/62] Loss: 0.73791 
Epoch [8/300] Training [19/62] Loss: 0.80985 
Epoch [8/300] Training [20/62] Loss: 0.85896 
Epoch [8/300] Training [21/62] Loss: 0.75841 
Epoch [8/300] Training [22/62] Loss: 0.85837 
Epoch [8/300] Training [23/62] Loss: 0.84016 
Epoch [8/300] Training [24/62] Loss: 0.83364 
Epoch [8/300] Training [25/62] Loss: 0.80626 
Epoch [8/300] Training [26/62] Loss: 0.85031 
Epoch [8/300] Training [27/62] Loss: 0.79114 
Epoch [8/300] Training [28/62] Loss: 0.71321 
Epoch [8/300] Training [29/62] Loss: 0.72141 
Epoch [8/300] Training [30/62] Loss: 0.88731 
Epoch [8/300] Training [31/62] Loss: 0.83711 
Epoch [8/300] Training [32/62] Loss: 0.80332 
Epoch [8/300] Training [33/62] Loss: 0.80139 
Epoch [8/300] Training [34/62] Loss: 0.84475 
Epoch [8/300] Training [35/62] Loss: 0.84491 
Epoch [8/300] Training [36/62] Loss: 0.79112 
Epoch [8/300] Training [37/62] Loss: 0.79982 
Epoch [8/300] Training [38/62] Loss: 0.75428 
Epoch [8/300] Training [39/62] Loss: 0.79212 
Epoch [8/300] Training [40/62] Loss: 0.81871 
Epoch [8/300] Training [41/62] Loss: 0.76781 
Epoch [8/300] Training [42/62] Loss: 0.77529 
Epoch [8/300] Training [43/62] Loss: 0.86132 
Epoch [8/300] Training [44/62] Loss: 0.77547 
Epoch [8/300] Training [45/62] Loss: 0.84810 
Epoch [8/300] Training [46/62] Loss: 0.80638 
Epoch [8/300] Training [47/62] Loss: 0.80441 
Epoch [8/300] Training [48/62] Loss: 0.82562 
Epoch [8/300] Training [49/62] Loss: 0.68207 
Epoch [8/300] Training [50/62] Loss: 0.73951 
Epoch [8/300] Training [51/62] Loss: 0.81160 
Epoch [8/300] Training [52/62] Loss: 0.87381 
Epoch [8/300] Training [53/62] Loss: 0.73482 
Epoch [8/300] Training [54/62] Loss: 0.76416 
Epoch [8/300] Training [55/62] Loss: 0.72554 
Epoch [8/300] Training [56/62] Loss: 0.74869 
Epoch [8/300] Training [57/62] Loss: 0.77253 
Epoch [8/300] Training [58/62] Loss: 0.81764 
Epoch [8/300] Training [59/62] Loss: 0.71736 
Epoch [8/300] Training [60/62] Loss: 0.74248 
Epoch [8/300] Training [61/62] Loss: 0.76487 
Epoch [8/300] Training [62/62] Loss: 1.00055 
Epoch [8/300] Training metric {'Train/mean dice_metric': 0.37557703256607056, 'Train/mean miou_metric': 0.2632080912590027, 'Train/mean f1': 0.4369736313819885, 'Train/mean precision': 0.3885693848133087, 'Train/mean recall': 0.49915340542793274, 'Train/mean hd95_metric': 105.0135726928711}
Epoch [8/300] Validation [1/16] Loss: 0.75416  focal_loss 0.15937  dice_loss 0.59480 
Epoch [8/300] Validation [2/16] Loss: 0.83265  focal_loss 0.11737  dice_loss 0.71529 
Epoch [8/300] Validation [3/16] Loss: 0.94774  focal_loss 0.21396  dice_loss 0.73378 
Epoch [8/300] Validation [4/16] Loss: 0.85250  focal_loss 0.18078  dice_loss 0.67172 
Epoch [8/300] Validation [5/16] Loss: 0.75799  focal_loss 0.10324  dice_loss 0.65475 
Epoch [8/300] Validation [6/16] Loss: 0.68746  focal_loss 0.09389  dice_loss 0.59357 
Epoch [8/300] Validation [7/16] Loss: 0.70065  focal_loss 0.11245  dice_loss 0.58820 
Epoch [8/300] Validation [8/16] Loss: 0.84112  focal_loss 0.11180  dice_loss 0.72932 
Epoch [8/300] Validation [9/16] Loss: 0.72486  focal_loss 0.09958  dice_loss 0.62528 
Epoch [8/300] Validation [10/16] Loss: 0.79349  focal_loss 0.14280  dice_loss 0.65069 
Epoch [8/300] Validation [11/16] Loss: 0.69745  focal_loss 0.10011  dice_loss 0.59734 
Epoch [8/300] Validation [12/16] Loss: 0.84260  focal_loss 0.10018  dice_loss 0.74242 
Epoch [8/300] Validation [13/16] Loss: 0.78947  focal_loss 0.13302  dice_loss 0.65646 
Epoch [8/300] Validation [14/16] Loss: 0.90704  focal_loss 0.16279  dice_loss 0.74425 
Epoch [8/300] Validation [15/16] Loss: 0.77899  focal_loss 0.13304  dice_loss 0.64595 
Epoch [8/300] Validation [16/16] Loss: 0.53737  focal_loss 0.06190  dice_loss 0.47547 
Epoch [8/300] Validation metric {'Val/mean dice_metric': 0.38262152671813965, 'Val/mean miou_metric': 0.2675180435180664, 'Val/mean f1': 0.44062167406082153, 'Val/mean precision': 0.38316893577575684, 'Val/mean recall': 0.5183424949645996, 'Val/mean hd95_metric': 107.8337173461914}
Cheakpoint...
Epoch [8/300] best acc:tensor([0.3826], device='cuda:0'), Now : mean acc: tensor([0.3826], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.38262152671813965, 'Val/mean miou_metric': 0.2675180435180664, 'Val/mean f1': 0.44062167406082153, 'Val/mean precision': 0.38316893577575684, 'Val/mean recall': 0.5183424949645996, 'Val/mean hd95_metric': 107.8337173461914}
Epoch [9/300] Training [1/62] Loss: 0.78323 
Epoch [9/300] Training [2/62] Loss: 0.76985 
Epoch [9/300] Training [3/62] Loss: 0.71710 
Epoch [9/300] Training [4/62] Loss: 0.82333 
Epoch [9/300] Training [5/62] Loss: 0.84705 
Epoch [9/300] Training [6/62] Loss: 0.77705 
Epoch [9/300] Training [7/62] Loss: 0.76085 
Epoch [9/300] Training [8/62] Loss: 0.89977 
Epoch [9/300] Training [9/62] Loss: 0.82961 
Epoch [9/300] Training [10/62] Loss: 0.75937 
Epoch [9/300] Training [11/62] Loss: 0.61227 
Epoch [9/300] Training [12/62] Loss: 0.87324 
Epoch [9/300] Training [13/62] Loss: 0.72213 
Epoch [9/300] Training [14/62] Loss: 0.87274 
Epoch [9/300] Training [15/62] Loss: 0.91857 
Epoch [9/300] Training [16/62] Loss: 0.74576 
Epoch [9/300] Training [17/62] Loss: 0.70722 
Epoch [9/300] Training [18/62] Loss: 0.66469 
Epoch [9/300] Training [19/62] Loss: 0.76171 
Epoch [9/300] Training [20/62] Loss: 0.78753 
Epoch [9/300] Training [21/62] Loss: 0.92599 
Epoch [9/300] Training [22/62] Loss: 0.73838 
Epoch [9/300] Training [23/62] Loss: 0.77293 
Epoch [9/300] Training [24/62] Loss: 0.77353 
Epoch [9/300] Training [25/62] Loss: 0.78776 
Epoch [9/300] Training [26/62] Loss: 0.89604 
Epoch [9/300] Training [27/62] Loss: 0.94834 
Epoch [9/300] Training [28/62] Loss: 0.90975 
Epoch [9/300] Training [29/62] Loss: 0.73309 
Epoch [9/300] Training [30/62] Loss: 0.75138 
Epoch [9/300] Training [31/62] Loss: 0.80206 
Epoch [9/300] Training [32/62] Loss: 0.69786 
Epoch [9/300] Training [33/62] Loss: 0.87612 
Epoch [9/300] Training [34/62] Loss: 0.75290 
Epoch [9/300] Training [35/62] Loss: 0.83069 
Epoch [9/300] Training [36/62] Loss: 0.73243 
Epoch [9/300] Training [37/62] Loss: 0.74758 
Epoch [9/300] Training [38/62] Loss: 0.67867 
Epoch [9/300] Training [39/62] Loss: 0.80136 
Epoch [9/300] Training [40/62] Loss: 0.82368 
Epoch [9/300] Training [41/62] Loss: 0.64878 
Epoch [9/300] Training [42/62] Loss: 0.92401 
Epoch [9/300] Training [43/62] Loss: 0.74264 
Epoch [9/300] Training [44/62] Loss: 0.69775 
Epoch [9/300] Training [45/62] Loss: 0.71177 
Epoch [9/300] Training [46/62] Loss: 0.84117 
Epoch [9/300] Training [47/62] Loss: 0.90158 
Epoch [9/300] Training [48/62] Loss: 0.71205 
Epoch [9/300] Training [49/62] Loss: 0.84101 
Epoch [9/300] Training [50/62] Loss: 0.91406 
Epoch [9/300] Training [51/62] Loss: 0.87725 
Epoch [9/300] Training [52/62] Loss: 0.67768 
Epoch [9/300] Training [53/62] Loss: 0.69926 
Epoch [9/300] Training [54/62] Loss: 0.84604 
Epoch [9/300] Training [55/62] Loss: 0.83252 
Epoch [9/300] Training [56/62] Loss: 0.84316 
Epoch [9/300] Training [57/62] Loss: 0.87280 
Epoch [9/300] Training [58/62] Loss: 0.77680 
Epoch [9/300] Training [59/62] Loss: 0.82726 
Epoch [9/300] Training [60/62] Loss: 0.66458 
Epoch [9/300] Training [61/62] Loss: 0.88213 
Epoch [9/300] Training [62/62] Loss: 0.99991 
Epoch [9/300] Training metric {'Train/mean dice_metric': 0.3874628245830536, 'Train/mean miou_metric': 0.2740393877029419, 'Train/mean f1': 0.4482963979244232, 'Train/mean precision': 0.4004582166671753, 'Train/mean recall': 0.5091145634651184, 'Train/mean hd95_metric': 104.5723876953125}
Epoch [9/300] Validation [1/16] Loss: 0.75288  focal_loss 0.13882  dice_loss 0.61406 
Epoch [9/300] Validation [2/16] Loss: 0.78796  focal_loss 0.08743  dice_loss 0.70053 
Epoch [9/300] Validation [3/16] Loss: 0.88484  focal_loss 0.15176  dice_loss 0.73308 
Epoch [9/300] Validation [4/16] Loss: 0.81644  focal_loss 0.14048  dice_loss 0.67597 
Epoch [9/300] Validation [5/16] Loss: 0.71173  focal_loss 0.06703  dice_loss 0.64470 
Epoch [9/300] Validation [6/16] Loss: 0.67127  focal_loss 0.06087  dice_loss 0.61039 
Epoch [9/300] Validation [7/16] Loss: 0.69756  focal_loss 0.09421  dice_loss 0.60335 
Epoch [9/300] Validation [8/16] Loss: 0.80151  focal_loss 0.08779  dice_loss 0.71372 
Epoch [9/300] Validation [9/16] Loss: 0.76971  focal_loss 0.11068  dice_loss 0.65903 
Epoch [9/300] Validation [10/16] Loss: 0.88901  focal_loss 0.16701  dice_loss 0.72200 
Epoch [9/300] Validation [11/16] Loss: 0.67756  focal_loss 0.07994  dice_loss 0.59762 
Epoch [9/300] Validation [12/16] Loss: 0.78665  focal_loss 0.06431  dice_loss 0.72234 
Epoch [9/300] Validation [13/16] Loss: 0.69222  focal_loss 0.06844  dice_loss 0.62377 
Epoch [9/300] Validation [14/16] Loss: 0.91991  focal_loss 0.13939  dice_loss 0.78051 
Epoch [9/300] Validation [15/16] Loss: 0.76057  focal_loss 0.10834  dice_loss 0.65223 
Epoch [9/300] Validation [16/16] Loss: 0.50987  focal_loss 0.05330  dice_loss 0.45658 
Epoch [9/300] Validation metric {'Val/mean dice_metric': 0.39278993010520935, 'Val/mean miou_metric': 0.27842947840690613, 'Val/mean f1': 0.4500742256641388, 'Val/mean precision': 0.3973991274833679, 'Val/mean recall': 0.5188472867012024, 'Val/mean hd95_metric': 105.41339874267578}
Cheakpoint...
Epoch [9/300] best acc:tensor([0.3928], device='cuda:0'), Now : mean acc: tensor([0.3928], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.39278993010520935, 'Val/mean miou_metric': 0.27842947840690613, 'Val/mean f1': 0.4500742256641388, 'Val/mean precision': 0.3973991274833679, 'Val/mean recall': 0.5188472867012024, 'Val/mean hd95_metric': 105.41339874267578}
Epoch [10/300] Training [1/62] Loss: 0.68047 
Epoch [10/300] Training [2/62] Loss: 0.76252 
Epoch [10/300] Training [3/62] Loss: 0.81703 
Epoch [10/300] Training [4/62] Loss: 0.88492 
Epoch [10/300] Training [5/62] Loss: 0.85397 
Epoch [10/300] Training [6/62] Loss: 0.81906 
Epoch [10/300] Training [7/62] Loss: 0.82701 
Epoch [10/300] Training [8/62] Loss: 0.77108 
Epoch [10/300] Training [9/62] Loss: 0.73419 
Epoch [10/300] Training [10/62] Loss: 0.94878 
Epoch [10/300] Training [11/62] Loss: 0.74950 
Epoch [10/300] Training [12/62] Loss: 0.76128 
Epoch [10/300] Training [13/62] Loss: 0.82733 
Epoch [10/300] Training [14/62] Loss: 0.85578 
Epoch [10/300] Training [15/62] Loss: 0.74039 
Epoch [10/300] Training [16/62] Loss: 0.78078 
Epoch [10/300] Training [17/62] Loss: 0.76918 
Epoch [10/300] Training [18/62] Loss: 0.67356 
Epoch [10/300] Training [19/62] Loss: 0.74026 
Epoch [10/300] Training [20/62] Loss: 0.83723 
Epoch [10/300] Training [21/62] Loss: 0.79841 
Epoch [10/300] Training [22/62] Loss: 0.83947 
Epoch [10/300] Training [23/62] Loss: 0.67152 
Epoch [10/300] Training [24/62] Loss: 0.74460 
Epoch [10/300] Training [25/62] Loss: 0.81026 
Epoch [10/300] Training [26/62] Loss: 0.80740 
Epoch [10/300] Training [27/62] Loss: 0.82371 
Epoch [10/300] Training [28/62] Loss: 0.79858 
Epoch [10/300] Training [29/62] Loss: 0.75504 
Epoch [10/300] Training [30/62] Loss: 0.86628 
Epoch [10/300] Training [31/62] Loss: 0.92179 
Epoch [10/300] Training [32/62] Loss: 0.82459 
Epoch [10/300] Training [33/62] Loss: 0.82220 
Epoch [10/300] Training [34/62] Loss: 0.61716 
Epoch [10/300] Training [35/62] Loss: 0.72413 
Epoch [10/300] Training [36/62] Loss: 0.87188 
Epoch [10/300] Training [37/62] Loss: 0.86267 
Epoch [10/300] Training [38/62] Loss: 0.80275 
Epoch [10/300] Training [39/62] Loss: 0.79848 
Epoch [10/300] Training [40/62] Loss: 0.85179 
Epoch [10/300] Training [41/62] Loss: 0.71186 
Epoch [10/300] Training [42/62] Loss: 0.74211 
Epoch [10/300] Training [43/62] Loss: 0.78843 
Epoch [10/300] Training [44/62] Loss: 0.78572 
Epoch [10/300] Training [45/62] Loss: 0.80975 
Epoch [10/300] Training [46/62] Loss: 0.91974 
Epoch [10/300] Training [47/62] Loss: 0.75846 
Epoch [10/300] Training [48/62] Loss: 0.82960 
Epoch [10/300] Training [49/62] Loss: 0.72097 
Epoch [10/300] Training [50/62] Loss: 0.72682 
Epoch [10/300] Training [51/62] Loss: 0.95419 
Epoch [10/300] Training [52/62] Loss: 0.75181 
Epoch [10/300] Training [53/62] Loss: 0.87336 
Epoch [10/300] Training [54/62] Loss: 0.84236 
Epoch [10/300] Training [55/62] Loss: 0.71406 
Epoch [10/300] Training [56/62] Loss: 0.67375 
Epoch [10/300] Training [57/62] Loss: 0.75839 
Epoch [10/300] Training [58/62] Loss: 0.72133 
Epoch [10/300] Training [59/62] Loss: 0.77630 
Epoch [10/300] Training [60/62] Loss: 0.77973 
Epoch [10/300] Training [61/62] Loss: 0.96224 
Epoch [10/300] Training [62/62] Loss: 0.36965 
Epoch [10/300] Training metric {'Train/mean dice_metric': 0.3825799226760864, 'Train/mean miou_metric': 0.27010276913642883, 'Train/mean f1': 0.4373326897621155, 'Train/mean precision': 0.3856240510940552, 'Train/mean recall': 0.5050560235977173, 'Train/mean hd95_metric': 105.85911560058594}
Epoch [10/300] Validation [1/16] Loss: 0.68478  focal_loss 0.10368  dice_loss 0.58110 
Epoch [10/300] Validation [2/16] Loss: 0.83009  focal_loss 0.09959  dice_loss 0.73051 
Epoch [10/300] Validation [3/16] Loss: 0.86976  focal_loss 0.13631  dice_loss 0.73346 
Epoch [10/300] Validation [4/16] Loss: 0.86524  focal_loss 0.15025  dice_loss 0.71499 
Epoch [10/300] Validation [5/16] Loss: 0.75924  focal_loss 0.08596  dice_loss 0.67328 
Epoch [10/300] Validation [6/16] Loss: 0.73421  focal_loss 0.08439  dice_loss 0.64981 
Epoch [10/300] Validation [7/16] Loss: 0.66590  focal_loss 0.07583  dice_loss 0.59007 
Epoch [10/300] Validation [8/16] Loss: 0.83598  focal_loss 0.09235  dice_loss 0.74363 
Epoch [10/300] Validation [9/16] Loss: 0.73477  focal_loss 0.08874  dice_loss 0.64603 
Epoch [10/300] Validation [10/16] Loss: 0.77189  focal_loss 0.10631  dice_loss 0.66558 
Epoch [10/300] Validation [11/16] Loss: 0.65488  focal_loss 0.06494  dice_loss 0.58994 
Epoch [10/300] Validation [12/16] Loss: 0.83080  focal_loss 0.07255  dice_loss 0.75825 
Epoch [10/300] Validation [13/16] Loss: 0.78088  focal_loss 0.09053  dice_loss 0.69035 
Epoch [10/300] Validation [14/16] Loss: 0.90083  focal_loss 0.12819  dice_loss 0.77264 
Epoch [10/300] Validation [15/16] Loss: 0.68601  focal_loss 0.06755  dice_loss 0.61845 
Epoch [10/300] Validation [16/16] Loss: 0.70110  focal_loss 0.09335  dice_loss 0.60774 
Epoch [10/300] Validation metric {'Val/mean dice_metric': 0.3921739161014557, 'Val/mean miou_metric': 0.27701205015182495, 'Val/mean f1': 0.4431764781475067, 'Val/mean precision': 0.3834303021430969, 'Val/mean recall': 0.524978756904602, 'Val/mean hd95_metric': 105.74185180664062}
Cheakpoint...
Epoch [10/300] best acc:tensor([0.3928], device='cuda:0'), Now : mean acc: tensor([0.3922], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3921739161014557, 'Val/mean miou_metric': 0.27701205015182495, 'Val/mean f1': 0.4431764781475067, 'Val/mean precision': 0.3834303021430969, 'Val/mean recall': 0.524978756904602, 'Val/mean hd95_metric': 105.74185180664062}
Epoch [11/300] Training [1/62] Loss: 0.78529 
Epoch [11/300] Training [2/62] Loss: 0.88635 
Epoch [11/300] Training [3/62] Loss: 0.81365 
Epoch [11/300] Training [4/62] Loss: 0.75498 
Epoch [11/300] Training [5/62] Loss: 0.78846 
Epoch [11/300] Training [6/62] Loss: 0.76941 
Epoch [11/300] Training [7/62] Loss: 0.81033 
Epoch [11/300] Training [8/62] Loss: 0.80121 
Epoch [11/300] Training [9/62] Loss: 0.84348 
Epoch [11/300] Training [10/62] Loss: 0.86714 
Epoch [11/300] Training [11/62] Loss: 0.88066 
Epoch [11/300] Training [12/62] Loss: 0.84582 
Epoch [11/300] Training [13/62] Loss: 0.81630 
Epoch [11/300] Training [14/62] Loss: 0.83628 
Epoch [11/300] Training [15/62] Loss: 0.69868 
Epoch [11/300] Training [16/62] Loss: 0.80944 
Epoch [11/300] Training [17/62] Loss: 0.62741 
Epoch [11/300] Training [18/62] Loss: 0.74088 
Epoch [11/300] Training [19/62] Loss: 0.71680 
Epoch [11/300] Training [20/62] Loss: 0.73156 
Epoch [11/300] Training [21/62] Loss: 0.64007 
Epoch [11/300] Training [22/62] Loss: 0.77631 
Epoch [11/300] Training [23/62] Loss: 0.81459 
Epoch [11/300] Training [24/62] Loss: 0.70980 
Epoch [11/300] Training [25/62] Loss: 0.72248 
Epoch [11/300] Training [26/62] Loss: 0.69944 
Epoch [11/300] Training [27/62] Loss: 0.75332 
Epoch [11/300] Training [28/62] Loss: 0.74358 
Epoch [11/300] Training [29/62] Loss: 0.80226 
Epoch [11/300] Training [30/62] Loss: 0.78780 
Epoch [11/300] Training [31/62] Loss: 0.80399 
Epoch [11/300] Training [32/62] Loss: 0.64950 
Epoch [11/300] Training [33/62] Loss: 0.69849 
Epoch [11/300] Training [34/62] Loss: 0.89739 
Epoch [11/300] Training [35/62] Loss: 0.80868 
Epoch [11/300] Training [36/62] Loss: 0.79656 
Epoch [11/300] Training [37/62] Loss: 0.78162 
Epoch [11/300] Training [38/62] Loss: 0.80828 
Epoch [11/300] Training [39/62] Loss: 0.77337 
Epoch [11/300] Training [40/62] Loss: 0.83539 
Epoch [11/300] Training [41/62] Loss: 0.89161 
Epoch [11/300] Training [42/62] Loss: 0.90168 
Epoch [11/300] Training [43/62] Loss: 0.78206 
Epoch [11/300] Training [44/62] Loss: 0.80358 
Epoch [11/300] Training [45/62] Loss: 0.86890 
Epoch [11/300] Training [46/62] Loss: 0.79803 
Epoch [11/300] Training [47/62] Loss: 0.81565 
Epoch [11/300] Training [48/62] Loss: 0.85376 
Epoch [11/300] Training [49/62] Loss: 0.75962 
Epoch [11/300] Training [50/62] Loss: 0.74282 
Epoch [11/300] Training [51/62] Loss: 0.78543 
Epoch [11/300] Training [52/62] Loss: 0.80527 
Epoch [11/300] Training [53/62] Loss: 0.61257 
Epoch [11/300] Training [54/62] Loss: 0.75051 
Epoch [11/300] Training [55/62] Loss: 0.82864 
Epoch [11/300] Training [56/62] Loss: 0.79450 
Epoch [11/300] Training [57/62] Loss: 0.84510 
Epoch [11/300] Training [58/62] Loss: 0.93918 
Epoch [11/300] Training [59/62] Loss: 0.76033 
Epoch [11/300] Training [60/62] Loss: 0.79240 
Epoch [11/300] Training [61/62] Loss: 0.86238 
Epoch [11/300] Training [62/62] Loss: 0.93838 
Epoch [11/300] Training metric {'Train/mean dice_metric': 0.3900400698184967, 'Train/mean miou_metric': 0.27642902731895447, 'Train/mean f1': 0.45070210099220276, 'Train/mean precision': 0.3994724452495575, 'Train/mean recall': 0.5170044302940369, 'Train/mean hd95_metric': 104.83460235595703}
Epoch [11/300] Validation [1/16] Loss: 0.74353  focal_loss 0.11135  dice_loss 0.63218 
Epoch [11/300] Validation [2/16] Loss: 0.82321  focal_loss 0.08041  dice_loss 0.74280 
Epoch [11/300] Validation [3/16] Loss: 0.87186  focal_loss 0.11807  dice_loss 0.75378 
Epoch [11/300] Validation [4/16] Loss: 0.80968  focal_loss 0.09925  dice_loss 0.71043 
Epoch [11/300] Validation [5/16] Loss: 0.73310  focal_loss 0.05298  dice_loss 0.68012 
Epoch [11/300] Validation [6/16] Loss: 0.68583  focal_loss 0.05661  dice_loss 0.62923 
Epoch [11/300] Validation [7/16] Loss: 0.68531  focal_loss 0.06670  dice_loss 0.61862 
Epoch [11/300] Validation [8/16] Loss: 0.83179  focal_loss 0.07539  dice_loss 0.75640 
Epoch [11/300] Validation [9/16] Loss: 0.76018  focal_loss 0.07440  dice_loss 0.68578 
Epoch [11/300] Validation [10/16] Loss: 0.76331  focal_loss 0.09145  dice_loss 0.67185 
Epoch [11/300] Validation [11/16] Loss: 0.73256  focal_loss 0.06442  dice_loss 0.66814 
Epoch [11/300] Validation [12/16] Loss: 0.79292  focal_loss 0.04317  dice_loss 0.74975 
Epoch [11/300] Validation [13/16] Loss: 0.76988  focal_loss 0.08583  dice_loss 0.68405 
Epoch [11/300] Validation [14/16] Loss: 0.87736  focal_loss 0.10499  dice_loss 0.77237 
Epoch [11/300] Validation [15/16] Loss: 0.81678  focal_loss 0.10792  dice_loss 0.70886 
Epoch [11/300] Validation [16/16] Loss: 0.56554  focal_loss 0.04838  dice_loss 0.51717 
Epoch [11/300] Validation metric {'Val/mean dice_metric': 0.3875899612903595, 'Val/mean miou_metric': 0.273651659488678, 'Val/mean f1': 0.44665321707725525, 'Val/mean precision': 0.4062896966934204, 'Val/mean recall': 0.4959213435649872, 'Val/mean hd95_metric': 105.45259857177734}
Cheakpoint...
Epoch [11/300] best acc:tensor([0.3928], device='cuda:0'), Now : mean acc: tensor([0.3876], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3875899612903595, 'Val/mean miou_metric': 0.273651659488678, 'Val/mean f1': 0.44665321707725525, 'Val/mean precision': 0.4062896966934204, 'Val/mean recall': 0.4959213435649872, 'Val/mean hd95_metric': 105.45259857177734}
Epoch [12/300] Training [1/62] Loss: 0.71101 
Epoch [12/300] Training [2/62] Loss: 0.78468 
Epoch [12/300] Training [3/62] Loss: 0.81363 
Epoch [12/300] Training [4/62] Loss: 0.81633 
Epoch [12/300] Training [5/62] Loss: 0.67435 
Epoch [12/300] Training [6/62] Loss: 0.78095 
Epoch [12/300] Training [7/62] Loss: 0.77654 
Epoch [12/300] Training [8/62] Loss: 0.72326 
Epoch [12/300] Training [9/62] Loss: 0.75305 
Epoch [12/300] Training [10/62] Loss: 0.73797 
Epoch [12/300] Training [11/62] Loss: 0.94714 
Epoch [12/300] Training [12/62] Loss: 0.79551 
Epoch [12/300] Training [13/62] Loss: 0.71705 
Epoch [12/300] Training [14/62] Loss: 0.87587 
Epoch [12/300] Training [15/62] Loss: 0.83516 
Epoch [12/300] Training [16/62] Loss: 0.79406 
Epoch [12/300] Training [17/62] Loss: 0.79629 
Epoch [12/300] Training [18/62] Loss: 0.63306 
Epoch [12/300] Training [19/62] Loss: 0.76257 
Epoch [12/300] Training [20/62] Loss: 0.72853 
Epoch [12/300] Training [21/62] Loss: 0.74600 
Epoch [12/300] Training [22/62] Loss: 0.90097 
Epoch [12/300] Training [23/62] Loss: 0.83440 
Epoch [12/300] Training [24/62] Loss: 0.69090 
Epoch [12/300] Training [25/62] Loss: 0.79895 
Epoch [12/300] Training [26/62] Loss: 0.78733 
Epoch [12/300] Training [27/62] Loss: 0.78457 
Epoch [12/300] Training [28/62] Loss: 0.77237 
Epoch [12/300] Training [29/62] Loss: 0.82168 
Epoch [12/300] Training [30/62] Loss: 0.71554 
Epoch [12/300] Training [31/62] Loss: 0.88014 
Epoch [12/300] Training [32/62] Loss: 0.78247 
Epoch [12/300] Training [33/62] Loss: 0.71643 
Epoch [12/300] Training [34/62] Loss: 0.82538 
Epoch [12/300] Training [35/62] Loss: 0.79366 
Epoch [12/300] Training [36/62] Loss: 0.84013 
Epoch [12/300] Training [37/62] Loss: 0.76716 
Epoch [12/300] Training [38/62] Loss: 0.79364 
Epoch [12/300] Training [39/62] Loss: 0.70104 
Epoch [12/300] Training [40/62] Loss: 0.79349 
Epoch [12/300] Training [41/62] Loss: 0.82784 
Epoch [12/300] Training [42/62] Loss: 0.85383 
Epoch [12/300] Training [43/62] Loss: 0.82085 
Epoch [12/300] Training [44/62] Loss: 0.81083 
Epoch [12/300] Training [45/62] Loss: 0.77409 
Epoch [12/300] Training [46/62] Loss: 0.87188 
Epoch [12/300] Training [47/62] Loss: 0.75631 
Epoch [12/300] Training [48/62] Loss: 0.77200 
Epoch [12/300] Training [49/62] Loss: 0.75029 
Epoch [12/300] Training [50/62] Loss: 0.89694 
Epoch [12/300] Training [51/62] Loss: 0.67109 
Epoch [12/300] Training [52/62] Loss: 0.79243 
Epoch [12/300] Training [53/62] Loss: 0.86788 
Epoch [12/300] Training [54/62] Loss: 0.72985 
Epoch [12/300] Training [55/62] Loss: 0.77912 
Epoch [12/300] Training [56/62] Loss: 0.70321 
Epoch [12/300] Training [57/62] Loss: 0.75966 
Epoch [12/300] Training [58/62] Loss: 0.76269 
Epoch [12/300] Training [59/62] Loss: 0.83550 
Epoch [12/300] Training [60/62] Loss: 0.71619 
Epoch [12/300] Training [61/62] Loss: 0.89386 
Epoch [12/300] Training [62/62] Loss: 0.86632 
Epoch [12/300] Training metric {'Train/mean dice_metric': 0.39153122901916504, 'Train/mean miou_metric': 0.2774919271469116, 'Train/mean f1': 0.4519210159778595, 'Train/mean precision': 0.4012398421764374, 'Train/mean recall': 0.5172564387321472, 'Train/mean hd95_metric': 103.94129180908203}
Epoch [12/300] Validation [1/16] Loss: 0.74770  focal_loss 0.11926  dice_loss 0.62844 
Epoch [12/300] Validation [2/16] Loss: 0.86543  focal_loss 0.08410  dice_loss 0.78132 
Epoch [12/300] Validation [3/16] Loss: 0.86575  focal_loss 0.11714  dice_loss 0.74861 
Epoch [12/300] Validation [4/16] Loss: 0.81540  focal_loss 0.10715  dice_loss 0.70825 
Epoch [12/300] Validation [5/16] Loss: 0.71282  focal_loss 0.05330  dice_loss 0.65952 
Epoch [12/300] Validation [6/16] Loss: 0.71976  focal_loss 0.05600  dice_loss 0.66376 
Epoch [12/300] Validation [7/16] Loss: 0.70519  focal_loss 0.07179  dice_loss 0.63341 
Epoch [12/300] Validation [8/16] Loss: 0.79006  focal_loss 0.06117  dice_loss 0.72889 
Epoch [12/300] Validation [9/16] Loss: 0.77912  focal_loss 0.08749  dice_loss 0.69162 
Epoch [12/300] Validation [10/16] Loss: 0.82635  focal_loss 0.11531  dice_loss 0.71104 
Epoch [12/300] Validation [11/16] Loss: 0.70911  focal_loss 0.05848  dice_loss 0.65063 
Epoch [12/300] Validation [12/16] Loss: 0.79166  focal_loss 0.04596  dice_loss 0.74570 
Epoch [12/300] Validation [13/16] Loss: 0.74483  focal_loss 0.07098  dice_loss 0.67385 
Epoch [12/300] Validation [14/16] Loss: 0.86811  focal_loss 0.09764  dice_loss 0.77047 
Epoch [12/300] Validation [15/16] Loss: 0.74259  focal_loss 0.08482  dice_loss 0.65777 
Epoch [12/300] Validation [16/16] Loss: 0.60276  focal_loss 0.05550  dice_loss 0.54726 
Epoch [12/300] Validation metric {'Val/mean dice_metric': 0.3931092321872711, 'Val/mean miou_metric': 0.277519166469574, 'Val/mean f1': 0.4481375217437744, 'Val/mean precision': 0.40305987000465393, 'Val/mean recall': 0.5045677423477173, 'Val/mean hd95_metric': 102.9094009399414}
Cheakpoint...
Epoch [12/300] best acc:tensor([0.3931], device='cuda:0'), Now : mean acc: tensor([0.3931], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3931092321872711, 'Val/mean miou_metric': 0.277519166469574, 'Val/mean f1': 0.4481375217437744, 'Val/mean precision': 0.40305987000465393, 'Val/mean recall': 0.5045677423477173, 'Val/mean hd95_metric': 102.9094009399414}
Epoch [13/300] Training [1/62] Loss: 0.70344 
Epoch [13/300] Training [2/62] Loss: 0.77780 
Epoch [13/300] Training [3/62] Loss: 0.63181 
Epoch [13/300] Training [4/62] Loss: 0.71404 
Epoch [13/300] Training [5/62] Loss: 0.71974 
Epoch [13/300] Training [6/62] Loss: 0.78528 
Epoch [13/300] Training [7/62] Loss: 0.78754 
Epoch [13/300] Training [8/62] Loss: 0.78242 
Epoch [13/300] Training [9/62] Loss: 0.70110 
Epoch [13/300] Training [10/62] Loss: 0.76199 
Epoch [13/300] Training [11/62] Loss: 0.72695 
Epoch [13/300] Training [12/62] Loss: 0.73462 
Epoch [13/300] Training [13/62] Loss: 0.88423 
Epoch [13/300] Training [14/62] Loss: 0.77546 
Epoch [13/300] Training [15/62] Loss: 0.73627 
Epoch [13/300] Training [16/62] Loss: 0.96834 
Epoch [13/300] Training [17/62] Loss: 0.96641 
Epoch [13/300] Training [18/62] Loss: 0.65798 
Epoch [13/300] Training [19/62] Loss: 0.71063 
Epoch [13/300] Training [20/62] Loss: 0.74881 
Epoch [13/300] Training [21/62] Loss: 0.82933 
Epoch [13/300] Training [22/62] Loss: 0.85818 
Epoch [13/300] Training [23/62] Loss: 0.90470 
Epoch [13/300] Training [24/62] Loss: 0.77317 
Epoch [13/300] Training [25/62] Loss: 0.76206 
Epoch [13/300] Training [26/62] Loss: 0.78174 
Epoch [13/300] Training [27/62] Loss: 0.82417 
Epoch [13/300] Training [28/62] Loss: 0.78785 
Epoch [13/300] Training [29/62] Loss: 0.74614 
Epoch [13/300] Training [30/62] Loss: 0.74820 
Epoch [13/300] Training [31/62] Loss: 0.75579 
Epoch [13/300] Training [32/62] Loss: 0.91566 
Epoch [13/300] Training [33/62] Loss: 0.75567 
Epoch [13/300] Training [34/62] Loss: 0.75674 
Epoch [13/300] Training [35/62] Loss: 0.75384 
Epoch [13/300] Training [36/62] Loss: 0.74209 
Epoch [13/300] Training [37/62] Loss: 0.86158 
Epoch [13/300] Training [38/62] Loss: 0.72934 
Epoch [13/300] Training [39/62] Loss: 0.87078 
Epoch [13/300] Training [40/62] Loss: 0.93136 
Epoch [13/300] Training [41/62] Loss: 0.86979 
Epoch [13/300] Training [42/62] Loss: 0.70829 
Epoch [13/300] Training [43/62] Loss: 0.74060 
Epoch [13/300] Training [44/62] Loss: 0.87622 
Epoch [13/300] Training [45/62] Loss: 0.81831 
Epoch [13/300] Training [46/62] Loss: 0.71024 
Epoch [13/300] Training [47/62] Loss: 0.70673 
Epoch [13/300] Training [48/62] Loss: 0.76724 
Epoch [13/300] Training [49/62] Loss: 0.92156 
Epoch [13/300] Training [50/62] Loss: 0.80974 
Epoch [13/300] Training [51/62] Loss: 0.79227 
Epoch [13/300] Training [52/62] Loss: 0.93214 
Epoch [13/300] Training [53/62] Loss: 0.70451 
Epoch [13/300] Training [54/62] Loss: 0.77482 
Epoch [13/300] Training [55/62] Loss: 0.77097 
Epoch [13/300] Training [56/62] Loss: 0.73741 
Epoch [13/300] Training [57/62] Loss: 0.87112 
Epoch [13/300] Training [58/62] Loss: 0.74357 
Epoch [13/300] Training [59/62] Loss: 0.82817 
Epoch [13/300] Training [60/62] Loss: 0.84593 
Epoch [13/300] Training [61/62] Loss: 0.68902 
Epoch [13/300] Training [62/62] Loss: 0.64442 
Epoch [13/300] Training metric {'Train/mean dice_metric': 0.3901698589324951, 'Train/mean miou_metric': 0.27555322647094727, 'Train/mean f1': 0.44787362217903137, 'Train/mean precision': 0.40374666452407837, 'Train/mean recall': 0.5028297901153564, 'Train/mean hd95_metric': 106.63786315917969}
Epoch [13/300] Validation [1/16] Loss: 0.75651  focal_loss 0.12193  dice_loss 0.63457 
Epoch [13/300] Validation [2/16] Loss: 0.81463  focal_loss 0.07239  dice_loss 0.74224 
Epoch [13/300] Validation [3/16] Loss: 0.86809  focal_loss 0.12836  dice_loss 0.73973 
Epoch [13/300] Validation [4/16] Loss: 0.81513  focal_loss 0.11193  dice_loss 0.70320 
Epoch [13/300] Validation [5/16] Loss: 0.71384  focal_loss 0.05669  dice_loss 0.65715 
Epoch [13/300] Validation [6/16] Loss: 0.66035  focal_loss 0.05361  dice_loss 0.60674 
Epoch [13/300] Validation [7/16] Loss: 0.66090  focal_loss 0.06560  dice_loss 0.59530 
Epoch [13/300] Validation [8/16] Loss: 0.79610  focal_loss 0.07017  dice_loss 0.72593 
Epoch [13/300] Validation [9/16] Loss: 0.74875  focal_loss 0.07635  dice_loss 0.67240 
Epoch [13/300] Validation [10/16] Loss: 0.87354  focal_loss 0.14351  dice_loss 0.73003 
Epoch [13/300] Validation [11/16] Loss: 0.68246  focal_loss 0.05672  dice_loss 0.62574 
Epoch [13/300] Validation [12/16] Loss: 0.75667  focal_loss 0.04065  dice_loss 0.71602 
Epoch [13/300] Validation [13/16] Loss: 0.73988  focal_loss 0.07362  dice_loss 0.66626 
Epoch [13/300] Validation [14/16] Loss: 0.88044  focal_loss 0.10899  dice_loss 0.77145 
Epoch [13/300] Validation [15/16] Loss: 0.76135  focal_loss 0.09289  dice_loss 0.66846 
Epoch [13/300] Validation [16/16] Loss: 0.53312  focal_loss 0.03991  dice_loss 0.49322 
Epoch [13/300] Validation metric {'Val/mean dice_metric': 0.3953445851802826, 'Val/mean miou_metric': 0.27952176332473755, 'Val/mean f1': 0.45090726017951965, 'Val/mean precision': 0.4112700819969177, 'Val/mean recall': 0.49899959564208984, 'Val/mean hd95_metric': 105.96654510498047}
Cheakpoint...
Epoch [13/300] best acc:tensor([0.3953], device='cuda:0'), Now : mean acc: tensor([0.3953], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.3953445851802826, 'Val/mean miou_metric': 0.27952176332473755, 'Val/mean f1': 0.45090726017951965, 'Val/mean precision': 0.4112700819969177, 'Val/mean recall': 0.49899959564208984, 'Val/mean hd95_metric': 105.96654510498047}
Epoch [14/300] Training [1/62] Loss: 0.90624 
Epoch [14/300] Training [2/62] Loss: 0.67344 
Epoch [14/300] Training [3/62] Loss: 0.85988 
Epoch [14/300] Training [4/62] Loss: 0.63280 
Epoch [14/300] Training [5/62] Loss: 0.82759 
Epoch [14/300] Training [6/62] Loss: 0.82328 
Epoch [14/300] Training [7/62] Loss: 0.78750 
Epoch [14/300] Training [8/62] Loss: 0.84023 
Epoch [14/300] Training [9/62] Loss: 0.81912 
Epoch [14/300] Training [10/62] Loss: 0.86549 
Epoch [14/300] Training [11/62] Loss: 0.84236 
Epoch [14/300] Training [12/62] Loss: 0.76236 
Epoch [14/300] Training [13/62] Loss: 0.74832 
Epoch [14/300] Training [14/62] Loss: 0.72016 
Epoch [14/300] Training [15/62] Loss: 0.83120 
Epoch [14/300] Training [16/62] Loss: 0.78798 
Epoch [14/300] Training [17/62] Loss: 0.76681 
Epoch [14/300] Training [18/62] Loss: 0.86010 
Epoch [14/300] Training [19/62] Loss: 0.77089 
Epoch [14/300] Training [20/62] Loss: 0.70840 
Epoch [14/300] Training [21/62] Loss: 0.76138 
Epoch [14/300] Training [22/62] Loss: 0.80748 
Epoch [14/300] Training [23/62] Loss: 0.80123 
Epoch [14/300] Training [24/62] Loss: 0.75273 
Epoch [14/300] Training [25/62] Loss: 0.73689 
Epoch [14/300] Training [26/62] Loss: 0.81542 
Epoch [14/300] Training [27/62] Loss: 0.85313 
Epoch [14/300] Training [28/62] Loss: 0.70958 
Epoch [14/300] Training [29/62] Loss: 0.64769 
Epoch [14/300] Training [30/62] Loss: 0.62670 
Epoch [14/300] Training [31/62] Loss: 0.60184 
Epoch [14/300] Training [32/62] Loss: 0.79610 
Epoch [14/300] Training [33/62] Loss: 0.78377 
Epoch [14/300] Training [34/62] Loss: 0.87892 
Epoch [14/300] Training [35/62] Loss: 0.71478 
Epoch [14/300] Training [36/62] Loss: 0.72797 
Epoch [14/300] Training [37/62] Loss: 0.72651 
Epoch [14/300] Training [38/62] Loss: 0.72910 
Epoch [14/300] Training [39/62] Loss: 0.91407 
Epoch [14/300] Training [40/62] Loss: 0.70283 
Epoch [14/300] Training [41/62] Loss: 0.76575 
Epoch [14/300] Training [42/62] Loss: 0.71247 
Epoch [14/300] Training [43/62] Loss: 0.74333 
Epoch [14/300] Training [44/62] Loss: 0.81314 
Epoch [14/300] Training [45/62] Loss: 0.78462 
Epoch [14/300] Training [46/62] Loss: 0.86553 
Epoch [14/300] Training [47/62] Loss: 0.65787 
Epoch [14/300] Training [48/62] Loss: 0.75939 
Epoch [14/300] Training [49/62] Loss: 0.82519 
Epoch [14/300] Training [50/62] Loss: 0.79388 
Epoch [14/300] Training [51/62] Loss: 0.71498 
Epoch [14/300] Training [52/62] Loss: 0.87840 
Epoch [14/300] Training [53/62] Loss: 0.83520 
Epoch [14/300] Training [54/62] Loss: 0.73478 
Epoch [14/300] Training [55/62] Loss: 0.77386 
Epoch [14/300] Training [56/62] Loss: 0.90707 
Epoch [14/300] Training [57/62] Loss: 0.80678 
Epoch [14/300] Training [58/62] Loss: 0.82607 
Epoch [14/300] Training [59/62] Loss: 0.70084 
Epoch [14/300] Training [60/62] Loss: 0.77114 
Epoch [14/300] Training [61/62] Loss: 0.83582 
Epoch [14/300] Training [62/62] Loss: 0.71912 
Epoch [14/300] Training metric {'Train/mean dice_metric': 0.40881872177124023, 'Train/mean miou_metric': 0.29160067439079285, 'Train/mean f1': 0.459757924079895, 'Train/mean precision': 0.41327589750289917, 'Train/mean recall': 0.5180208683013916, 'Train/mean hd95_metric': 105.80673217773438}
Epoch [14/300] Validation [1/16] Loss: 0.68017  focal_loss 0.10519  dice_loss 0.57498 
Epoch [14/300] Validation [2/16] Loss: 0.78390  focal_loss 0.06264  dice_loss 0.72125 
Epoch [14/300] Validation [3/16] Loss: 0.85225  focal_loss 0.10865  dice_loss 0.74360 
Epoch [14/300] Validation [4/16] Loss: 0.77107  focal_loss 0.08762  dice_loss 0.68345 
Epoch [14/300] Validation [5/16] Loss: 0.72117  focal_loss 0.04922  dice_loss 0.67196 
Epoch [14/300] Validation [6/16] Loss: 0.67503  focal_loss 0.04978  dice_loss 0.62525 
Epoch [14/300] Validation [7/16] Loss: 0.69540  focal_loss 0.06842  dice_loss 0.62698 
Epoch [14/300] Validation [8/16] Loss: 0.78650  focal_loss 0.06264  dice_loss 0.72386 
Epoch [14/300] Validation [9/16] Loss: 0.74011  focal_loss 0.06587  dice_loss 0.67424 
Epoch [14/300] Validation [10/16] Loss: 0.81162  focal_loss 0.10902  dice_loss 0.70260 
Epoch [14/300] Validation [11/16] Loss: 0.72012  focal_loss 0.06864  dice_loss 0.65148 
Epoch [14/300] Validation [12/16] Loss: 0.78121  focal_loss 0.04695  dice_loss 0.73426 
Epoch [14/300] Validation [13/16] Loss: 0.73029  focal_loss 0.06608  dice_loss 0.66420 
Epoch [14/300] Validation [14/16] Loss: 0.86830  focal_loss 0.09579  dice_loss 0.77252 
Epoch [14/300] Validation [15/16] Loss: 0.75300  focal_loss 0.08373  dice_loss 0.66927 
Epoch [14/300] Validation [16/16] Loss: 0.57763  focal_loss 0.04798  dice_loss 0.52964 
Epoch [14/300] Validation metric {'Val/mean dice_metric': 0.4100048243999481, 'Val/mean miou_metric': 0.29242774844169617, 'Val/mean f1': 0.46198803186416626, 'Val/mean precision': 0.41633179783821106, 'Val/mean recall': 0.5188912749290466, 'Val/mean hd95_metric': 105.75562286376953}
Cheakpoint...
Epoch [14/300] best acc:tensor([0.4100], device='cuda:0'), Now : mean acc: tensor([0.4100], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.4100048243999481, 'Val/mean miou_metric': 0.29242774844169617, 'Val/mean f1': 0.46198803186416626, 'Val/mean precision': 0.41633179783821106, 'Val/mean recall': 0.5188912749290466, 'Val/mean hd95_metric': 105.75562286376953}
Epoch [15/300] Training [1/62] Loss: 0.85973 
Epoch [15/300] Training [2/62] Loss: 0.78674 
Epoch [15/300] Training [3/62] Loss: 0.80048 
Epoch [15/300] Training [4/62] Loss: 0.73298 
Epoch [15/300] Training [5/62] Loss: 0.75302 
Epoch [15/300] Training [6/62] Loss: 0.80049 
Epoch [15/300] Training [7/62] Loss: 0.74973 
Epoch [15/300] Training [8/62] Loss: 0.67711 
Epoch [15/300] Training [9/62] Loss: 0.70159 
Epoch [15/300] Training [10/62] Loss: 0.65220 
Epoch [15/300] Training [11/62] Loss: 0.78427 
Epoch [15/300] Training [12/62] Loss: 0.72581 
Epoch [15/300] Training [13/62] Loss: 0.72021 
Epoch [15/300] Training [14/62] Loss: 0.83290 
Epoch [15/300] Training [15/62] Loss: 0.84436 
Epoch [15/300] Training [16/62] Loss: 0.58231 
Epoch [15/300] Training [17/62] Loss: 0.84755 
Epoch [15/300] Training [18/62] Loss: 0.68875 
Epoch [15/300] Training [19/62] Loss: 0.74528 
Epoch [15/300] Training [20/62] Loss: 0.74491 
Epoch [15/300] Training [21/62] Loss: 0.63987 
Epoch [15/300] Training [22/62] Loss: 0.75479 
Epoch [15/300] Training [23/62] Loss: 0.64999 
Epoch [15/300] Training [24/62] Loss: 0.71817 
Epoch [15/300] Training [25/62] Loss: 0.73824 
Epoch [15/300] Training [26/62] Loss: 0.76669 
Epoch [15/300] Training [27/62] Loss: 0.77792 
Epoch [15/300] Training [28/62] Loss: 0.75421 
Epoch [15/300] Training [29/62] Loss: 0.79509 
Epoch [15/300] Training [30/62] Loss: 0.93516 
Epoch [15/300] Training [31/62] Loss: 0.85686 
Epoch [15/300] Training [32/62] Loss: 0.66993 
Epoch [15/300] Training [33/62] Loss: 0.80069 
Epoch [15/300] Training [34/62] Loss: 0.86039 
Epoch [15/300] Training [35/62] Loss: 0.77435 
Epoch [15/300] Training [36/62] Loss: 0.65351 
Epoch [15/300] Training [37/62] Loss: 0.87848 
Epoch [15/300] Training [38/62] Loss: 0.67268 
Epoch [15/300] Training [39/62] Loss: 0.76457 
Epoch [15/300] Training [40/62] Loss: 0.85413 
Epoch [15/300] Training [41/62] Loss: 0.75586 
Epoch [15/300] Training [42/62] Loss: 0.74554 
Epoch [15/300] Training [43/62] Loss: 0.85290 
Epoch [15/300] Training [44/62] Loss: 0.78810 
Epoch [15/300] Training [45/62] Loss: 0.83555 
Epoch [15/300] Training [46/62] Loss: 0.74297 
Epoch [15/300] Training [47/62] Loss: 0.72864 
Epoch [15/300] Training [48/62] Loss: 0.73982 
Epoch [15/300] Training [49/62] Loss: 0.77368 
Epoch [15/300] Training [50/62] Loss: 0.72306 
Epoch [15/300] Training [51/62] Loss: 0.86982 
Epoch [15/300] Training [52/62] Loss: 0.74684 
Epoch [15/300] Training [53/62] Loss: 0.79058 
Epoch [15/300] Training [54/62] Loss: 0.71895 
Epoch [15/300] Training [55/62] Loss: 0.80439 
Epoch [15/300] Training [56/62] Loss: 0.70387 
Epoch [15/300] Training [57/62] Loss: 0.79986 
Epoch [15/300] Training [58/62] Loss: 0.76777 
Epoch [15/300] Training [59/62] Loss: 0.84290 
Epoch [15/300] Training [60/62] Loss: 0.79035 
Epoch [15/300] Training [61/62] Loss: 0.66964 
Epoch [15/300] Training [62/62] Loss: 0.96942 
Epoch [15/300] Training metric {'Train/mean dice_metric': 0.4129335880279541, 'Train/mean miou_metric': 0.2965141534805298, 'Train/mean f1': 0.4700377583503723, 'Train/mean precision': 0.42750290036201477, 'Train/mean recall': 0.5219720005989075, 'Train/mean hd95_metric': 105.00020599365234}
Epoch [15/300] Validation [1/16] Loss: 0.74365  focal_loss 0.11473  dice_loss 0.62892 
Epoch [15/300] Validation [2/16] Loss: 0.81661  focal_loss 0.06623  dice_loss 0.75037 
Epoch [15/300] Validation [3/16] Loss: 0.83920  focal_loss 0.08740  dice_loss 0.75180 
Epoch [15/300] Validation [4/16] Loss: 0.83650  focal_loss 0.10711  dice_loss 0.72939 
Epoch [15/300] Validation [5/16] Loss: 0.73314  focal_loss 0.04781  dice_loss 0.68533 
Epoch [15/300] Validation [6/16] Loss: 0.67931  focal_loss 0.04545  dice_loss 0.63386 
Epoch [15/300] Validation [7/16] Loss: 0.68209  focal_loss 0.05814  dice_loss 0.62396 
Epoch [15/300] Validation [8/16] Loss: 0.81021  focal_loss 0.06088  dice_loss 0.74933 
Epoch [15/300] Validation [9/16] Loss: 0.76714  focal_loss 0.07387  dice_loss 0.69327 
Epoch [15/300] Validation [10/16] Loss: 0.78184  focal_loss 0.08706  dice_loss 0.69478 
Epoch [15/300] Validation [11/16] Loss: 0.70233  focal_loss 0.05514  dice_loss 0.64719 
Epoch [15/300] Validation [12/16] Loss: 0.79638  focal_loss 0.03953  dice_loss 0.75685 
Epoch [15/300] Validation [13/16] Loss: 0.74023  focal_loss 0.06088  dice_loss 0.67935 
Epoch [15/300] Validation [14/16] Loss: 0.83809  focal_loss 0.07231  dice_loss 0.76579 
Epoch [15/300] Validation [15/16] Loss: 0.73784  focal_loss 0.06785  dice_loss 0.66999 
Epoch [15/300] Validation [16/16] Loss: 0.54564  focal_loss 0.03716  dice_loss 0.50848 
Epoch [15/300] Validation metric {'Val/mean dice_metric': 0.41551992297172546, 'Val/mean miou_metric': 0.2984587550163269, 'Val/mean f1': 0.4699726104736328, 'Val/mean precision': 0.43456992506980896, 'Val/mean recall': 0.5116551518440247, 'Val/mean hd95_metric': 104.61853790283203}
Cheakpoint...
Epoch [15/300] best acc:tensor([0.4155], device='cuda:0'), Now : mean acc: tensor([0.4155], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.41551992297172546, 'Val/mean miou_metric': 0.2984587550163269, 'Val/mean f1': 0.4699726104736328, 'Val/mean precision': 0.43456992506980896, 'Val/mean recall': 0.5116551518440247, 'Val/mean hd95_metric': 104.61853790283203}
Epoch [16/300] Training [1/62] Loss: 0.71960 
Epoch [16/300] Training [2/62] Loss: 0.70901 
Epoch [16/300] Training [3/62] Loss: 0.85633 
Epoch [16/300] Training [4/62] Loss: 0.77976 
Epoch [16/300] Training [5/62] Loss: 0.80176 
Epoch [16/300] Training [6/62] Loss: 0.69137 
Epoch [16/300] Training [7/62] Loss: 0.76334 
Epoch [16/300] Training [8/62] Loss: 0.79451 
Epoch [16/300] Training [9/62] Loss: 0.77785 
Epoch [16/300] Training [10/62] Loss: 0.83651 
Epoch [16/300] Training [11/62] Loss: 0.65958 
Epoch [16/300] Training [12/62] Loss: 0.64877 
Epoch [16/300] Training [13/62] Loss: 0.85144 
Epoch [16/300] Training [14/62] Loss: 0.66819 
Epoch [16/300] Training [15/62] Loss: 0.76294 
Epoch [16/300] Training [16/62] Loss: 0.78522 
Epoch [16/300] Training [17/62] Loss: 0.68147 
Epoch [16/300] Training [18/62] Loss: 0.70878 
Epoch [16/300] Training [19/62] Loss: 0.84544 
Epoch [16/300] Training [20/62] Loss: 0.84435 
Epoch [16/300] Training [21/62] Loss: 0.76190 
Epoch [16/300] Training [22/62] Loss: 0.76458 
Epoch [16/300] Training [23/62] Loss: 0.92395 
Epoch [16/300] Training [24/62] Loss: 0.65808 
Epoch [16/300] Training [25/62] Loss: 0.55887 
Epoch [16/300] Training [26/62] Loss: 0.76234 
Epoch [16/300] Training [27/62] Loss: 0.76255 
Epoch [16/300] Training [28/62] Loss: 0.85192 
Epoch [16/300] Training [29/62] Loss: 0.86013 
Epoch [16/300] Training [30/62] Loss: 0.66800 
Epoch [16/300] Training [31/62] Loss: 0.87257 
Epoch [16/300] Training [32/62] Loss: 0.58299 
Epoch [16/300] Training [33/62] Loss: 0.68246 
Epoch [16/300] Training [34/62] Loss: 0.70270 
Epoch [16/300] Training [35/62] Loss: 0.83139 
Epoch [16/300] Training [36/62] Loss: 0.92222 
Epoch [16/300] Training [37/62] Loss: 0.71713 
Epoch [16/300] Training [38/62] Loss: 0.69478 
Epoch [16/300] Training [39/62] Loss: 0.63261 
Epoch [16/300] Training [40/62] Loss: 0.83888 
Epoch [16/300] Training [41/62] Loss: 0.59820 
Epoch [16/300] Training [42/62] Loss: 0.58613 
Epoch [16/300] Training [43/62] Loss: 0.64243 
Epoch [16/300] Training [44/62] Loss: 0.80744 
Epoch [16/300] Training [45/62] Loss: 0.64874 
Epoch [16/300] Training [46/62] Loss: 0.69078 
Epoch [16/300] Training [47/62] Loss: 0.61780 
Epoch [16/300] Training [48/62] Loss: 0.77526 
Epoch [16/300] Training [49/62] Loss: 0.67197 
Epoch [16/300] Training [50/62] Loss: 0.72719 
Epoch [16/300] Training [51/62] Loss: 0.63641 
Epoch [16/300] Training [52/62] Loss: 0.80800 
Epoch [16/300] Training [53/62] Loss: 0.70003 
Epoch [16/300] Training [54/62] Loss: 0.78514 
Epoch [16/300] Training [55/62] Loss: 0.88092 
Epoch [16/300] Training [56/62] Loss: 0.69496 
Epoch [16/300] Training [57/62] Loss: 0.80846 
Epoch [16/300] Training [58/62] Loss: 0.81962 
Epoch [16/300] Training [59/62] Loss: 0.80424 
Epoch [16/300] Training [60/62] Loss: 0.77511 
Epoch [16/300] Training [61/62] Loss: 0.69581 
Epoch [16/300] Training [62/62] Loss: 0.70039 
Epoch [16/300] Training metric {'Train/mean dice_metric': 0.4296164810657501, 'Train/mean miou_metric': 0.31374573707580566, 'Train/mean f1': 0.49054571986198425, 'Train/mean precision': 0.4596216082572937, 'Train/mean recall': 0.5259312391281128, 'Train/mean hd95_metric': 100.03768157958984}
Epoch [16/300] Validation [1/16] Loss: 0.68676  focal_loss 0.10170  dice_loss 0.58507 
Epoch [16/300] Validation [2/16] Loss: 0.81619  focal_loss 0.10085  dice_loss 0.71534 
Epoch [16/300] Validation [3/16] Loss: 0.85003  focal_loss 0.14952  dice_loss 0.70051 
Epoch [16/300] Validation [4/16] Loss: 0.93218  focal_loss 0.20205  dice_loss 0.73013 
Epoch [16/300] Validation [5/16] Loss: 0.73372  focal_loss 0.09486  dice_loss 0.63885 
Epoch [16/300] Validation [6/16] Loss: 0.68619  focal_loss 0.08777  dice_loss 0.59842 
Epoch [16/300] Validation [7/16] Loss: 0.66623  focal_loss 0.09365  dice_loss 0.57258 
Epoch [16/300] Validation [8/16] Loss: 0.83956  focal_loss 0.11029  dice_loss 0.72927 
Epoch [16/300] Validation [9/16] Loss: 0.73432  focal_loss 0.10473  dice_loss 0.62959 
Epoch [16/300] Validation [10/16] Loss: 0.71879  focal_loss 0.09446  dice_loss 0.62433 
Epoch [16/300] Validation [11/16] Loss: 0.67118  focal_loss 0.07235  dice_loss 0.59883 
Epoch [16/300] Validation [12/16] Loss: 0.81616  focal_loss 0.08362  dice_loss 0.73254 
Epoch [16/300] Validation [13/16] Loss: 0.73752  focal_loss 0.10028  dice_loss 0.63724 
Epoch [16/300] Validation [14/16] Loss: 0.95329  focal_loss 0.16171  dice_loss 0.79158 
Epoch [16/300] Validation [15/16] Loss: 0.67129  focal_loss 0.07795  dice_loss 0.59334 
Epoch [16/300] Validation [16/16] Loss: 0.55672  focal_loss 0.06249  dice_loss 0.49422 
Epoch [16/300] Validation metric {'Val/mean dice_metric': 0.4300333559513092, 'Val/mean miou_metric': 0.3132767379283905, 'Val/mean f1': 0.4861363172531128, 'Val/mean precision': 0.43112313747406006, 'Val/mean recall': 0.5572429299354553, 'Val/mean hd95_metric': 104.25883483886719}
Cheakpoint...
Epoch [16/300] best acc:tensor([0.4300], device='cuda:0'), Now : mean acc: tensor([0.4300], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.4300333559513092, 'Val/mean miou_metric': 0.3132767379283905, 'Val/mean f1': 0.4861363172531128, 'Val/mean precision': 0.43112313747406006, 'Val/mean recall': 0.5572429299354553, 'Val/mean hd95_metric': 104.25883483886719}
Epoch [17/300] Training [1/62] Loss: 0.59512 
Epoch [17/300] Training [2/62] Loss: 0.65593 
Epoch [17/300] Training [3/62] Loss: 0.59222 
Epoch [17/300] Training [4/62] Loss: 0.82633 
Epoch [17/300] Training [5/62] Loss: 0.84661 
Epoch [17/300] Training [6/62] Loss: 0.70386 
Epoch [17/300] Training [7/62] Loss: 0.69636 
Epoch [17/300] Training [8/62] Loss: 0.72341 
Epoch [17/300] Training [9/62] Loss: 0.73275 
Epoch [17/300] Training [10/62] Loss: 0.81815 
Epoch [17/300] Training [11/62] Loss: 0.90064 
Epoch [17/300] Training [12/62] Loss: 0.86544 
Epoch [17/300] Training [13/62] Loss: 0.72099 
Epoch [17/300] Training [14/62] Loss: 0.68277 
Epoch [17/300] Training [15/62] Loss: 0.68468 
Epoch [17/300] Training [16/62] Loss: 0.70498 
Epoch [17/300] Training [17/62] Loss: 0.78437 
Epoch [17/300] Training [18/62] Loss: 0.81011 
Epoch [17/300] Training [19/62] Loss: 0.88403 
Epoch [17/300] Training [20/62] Loss: 0.77374 
Epoch [17/300] Training [21/62] Loss: 0.84838 
Epoch [17/300] Training [22/62] Loss: 0.81968 
Epoch [17/300] Training [23/62] Loss: 0.83663 
Epoch [17/300] Training [24/62] Loss: 0.92289 
Epoch [17/300] Training [25/62] Loss: 0.71431 
Epoch [17/300] Training [26/62] Loss: 0.71954 
Epoch [17/300] Training [27/62] Loss: 0.78890 
Epoch [17/300] Training [28/62] Loss: 0.77397 
Epoch [17/300] Training [29/62] Loss: 0.74479 
Epoch [17/300] Training [30/62] Loss: 0.73630 
Epoch [17/300] Training [31/62] Loss: 0.74633 
Epoch [17/300] Training [32/62] Loss: 0.76110 
Epoch [17/300] Training [33/62] Loss: 0.82178 
Epoch [17/300] Training [34/62] Loss: 0.64672 
Epoch [17/300] Training [35/62] Loss: 0.70051 
Epoch [17/300] Training [36/62] Loss: 0.57112 
Epoch [17/300] Training [37/62] Loss: 0.64879 
Epoch [17/300] Training [38/62] Loss: 0.74033 
Epoch [17/300] Training [39/62] Loss: 0.75940 
Epoch [17/300] Training [40/62] Loss: 0.82257 
Epoch [17/300] Training [41/62] Loss: 0.63166 
Epoch [17/300] Training [42/62] Loss: 0.71992 
Epoch [17/300] Training [43/62] Loss: 0.81818 
Epoch [17/300] Training [44/62] Loss: 0.65364 
Epoch [17/300] Training [45/62] Loss: 0.74642 
Epoch [17/300] Training [46/62] Loss: 0.73042 
Epoch [17/300] Training [47/62] Loss: 0.90520 
Epoch [17/300] Training [48/62] Loss: 0.60437 
Epoch [17/300] Training [49/62] Loss: 0.68802 
Epoch [17/300] Training [50/62] Loss: 0.83551 
Epoch [17/300] Training [51/62] Loss: 0.71661 
Epoch [17/300] Training [52/62] Loss: 0.92917 
Epoch [17/300] Training [53/62] Loss: 0.67098 
Epoch [17/300] Training [54/62] Loss: 0.72227 
Epoch [17/300] Training [55/62] Loss: 0.72202 
Epoch [17/300] Training [56/62] Loss: 0.70191 
Epoch [17/300] Training [57/62] Loss: 0.80362 
Epoch [17/300] Training [58/62] Loss: 0.88217 
Epoch [17/300] Training [59/62] Loss: 0.82172 
Epoch [17/300] Training [60/62] Loss: 0.83503 
Epoch [17/300] Training [61/62] Loss: 0.79016 
Epoch [17/300] Training [62/62] Loss: 0.52733 
Epoch [17/300] Training metric {'Train/mean dice_metric': 0.42643553018569946, 'Train/mean miou_metric': 0.309207022190094, 'Train/mean f1': 0.4808198809623718, 'Train/mean precision': 0.43611276149749756, 'Train/mean recall': 0.535740077495575, 'Train/mean hd95_metric': 104.13031005859375}
Epoch [17/300] Validation [1/16] Loss: 0.75798  focal_loss 0.12843  dice_loss 0.62955 
Epoch [17/300] Validation [2/16] Loss: 0.85630  focal_loss 0.09068  dice_loss 0.76562 
Epoch [17/300] Validation [3/16] Loss: 0.86689  focal_loss 0.10630  dice_loss 0.76059 
Epoch [17/300] Validation [4/16] Loss: 0.78021  focal_loss 0.08796  dice_loss 0.69224 
Epoch [17/300] Validation [5/16] Loss: 0.76351  focal_loss 0.05999  dice_loss 0.70352 
Epoch [17/300] Validation [6/16] Loss: 0.67834  focal_loss 0.05030  dice_loss 0.62804 
Epoch [17/300] Validation [7/16] Loss: 0.67833  focal_loss 0.07152  dice_loss 0.60681 
Epoch [17/300] Validation [8/16] Loss: 0.79514  focal_loss 0.06345  dice_loss 0.73169 
Epoch [17/300] Validation [9/16] Loss: 0.81458  focal_loss 0.10503  dice_loss 0.70955 
Epoch [17/300] Validation [10/16] Loss: 0.76096  focal_loss 0.09576  dice_loss 0.66520 
Epoch [17/300] Validation [11/16] Loss: 0.72922  focal_loss 0.06687  dice_loss 0.66235 
Epoch [17/300] Validation [12/16] Loss: 0.80617  focal_loss 0.04075  dice_loss 0.76542 
Epoch [17/300] Validation [13/16] Loss: 0.72524  focal_loss 0.05995  dice_loss 0.66529 
Epoch [17/300] Validation [14/16] Loss: 0.96301  focal_loss 0.12418  dice_loss 0.83883 
Epoch [17/300] Validation [15/16] Loss: 0.78741  focal_loss 0.08523  dice_loss 0.70219 
Epoch [17/300] Validation [16/16] Loss: 0.56922  focal_loss 0.07583  dice_loss 0.49339 
Epoch [17/300] Validation metric {'Val/mean dice_metric': 0.40847593545913696, 'Val/mean miou_metric': 0.29611119627952576, 'Val/mean f1': 0.4696190357208252, 'Val/mean precision': 0.44645291566848755, 'Val/mean recall': 0.4953208863735199, 'Val/mean hd95_metric': 103.24211883544922}
Cheakpoint...
Epoch [17/300] best acc:tensor([0.4300], device='cuda:0'), Now : mean acc: tensor([0.4085], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.40847593545913696, 'Val/mean miou_metric': 0.29611119627952576, 'Val/mean f1': 0.4696190357208252, 'Val/mean precision': 0.44645291566848755, 'Val/mean recall': 0.4953208863735199, 'Val/mean hd95_metric': 103.24211883544922}
Epoch [18/300] Training [1/62] Loss: 0.73709 
Epoch [18/300] Training [2/62] Loss: 0.78768 
Epoch [18/300] Training [3/62] Loss: 0.81300 
Epoch [18/300] Training [4/62] Loss: 0.72493 
Epoch [18/300] Training [5/62] Loss: 0.77877 
Epoch [18/300] Training [6/62] Loss: 0.70369 
Epoch [18/300] Training [7/62] Loss: 1.00407 
Epoch [18/300] Training [8/62] Loss: 0.86934 
Epoch [18/300] Training [9/62] Loss: 0.69978 
Epoch [18/300] Training [10/62] Loss: 0.65663 
Epoch [18/300] Training [11/62] Loss: 0.79002 
Epoch [18/300] Training [12/62] Loss: 0.65018 
Epoch [18/300] Training [13/62] Loss: 0.76375 
Epoch [18/300] Training [14/62] Loss: 0.74973 
Epoch [18/300] Training [15/62] Loss: 0.76220 
Epoch [18/300] Training [16/62] Loss: 0.74828 
Epoch [18/300] Training [17/62] Loss: 0.84465 
Epoch [18/300] Training [18/62] Loss: 0.80830 
Epoch [18/300] Training [19/62] Loss: 0.79090 
Epoch [18/300] Training [20/62] Loss: 0.63339 
Epoch [18/300] Training [21/62] Loss: 0.67912 
Epoch [18/300] Training [22/62] Loss: 0.71332 
Epoch [18/300] Training [23/62] Loss: 0.73212 
Epoch [18/300] Training [24/62] Loss: 0.87080 
Epoch [18/300] Training [25/62] Loss: 0.75637 
Epoch [18/300] Training [26/62] Loss: 0.70092 
Epoch [18/300] Training [27/62] Loss: 0.76022 
Epoch [18/300] Training [28/62] Loss: 0.77239 
Epoch [18/300] Training [29/62] Loss: 1.00458 
Epoch [18/300] Training [30/62] Loss: 0.77712 
Epoch [18/300] Training [31/62] Loss: 0.58198 
Epoch [18/300] Training [32/62] Loss: 0.69628 
Epoch [18/300] Training [33/62] Loss: 0.88315 
Epoch [18/300] Training [34/62] Loss: 0.59593 
Epoch [18/300] Training [35/62] Loss: 0.61614 
Epoch [18/300] Training [36/62] Loss: 0.78988 
Epoch [18/300] Training [37/62] Loss: 0.85182 
Epoch [18/300] Training [38/62] Loss: 0.81807 
Epoch [18/300] Training [39/62] Loss: 0.64601 
Epoch [18/300] Training [40/62] Loss: 0.68620 
Epoch [18/300] Training [41/62] Loss: 0.73566 
Epoch [18/300] Training [42/62] Loss: 0.68945 
Epoch [18/300] Training [43/62] Loss: 0.75564 
Epoch [18/300] Training [44/62] Loss: 0.71420 
Epoch [18/300] Training [45/62] Loss: 0.83397 
Epoch [18/300] Training [46/62] Loss: 0.54333 
Epoch [18/300] Training [47/62] Loss: 0.94784 
Epoch [18/300] Training [48/62] Loss: 0.76611 
Epoch [18/300] Training [49/62] Loss: 0.70891 
Epoch [18/300] Training [50/62] Loss: 0.79557 
Epoch [18/300] Training [51/62] Loss: 0.68266 
Epoch [18/300] Training [52/62] Loss: 0.66575 
Epoch [18/300] Training [53/62] Loss: 0.76373 
Epoch [18/300] Training [54/62] Loss: 0.75963 
Epoch [18/300] Training [55/62] Loss: 0.71443 
Epoch [18/300] Training [56/62] Loss: 0.76654 
Epoch [18/300] Training [57/62] Loss: 0.68142 
Epoch [18/300] Training [58/62] Loss: 0.92054 
Epoch [18/300] Training [59/62] Loss: 0.82118 
Epoch [18/300] Training [60/62] Loss: 0.84012 
Epoch [18/300] Training [61/62] Loss: 0.71532 
Epoch [18/300] Training [62/62] Loss: 0.50503 
Epoch [18/300] Training metric {'Train/mean dice_metric': 0.43198999762535095, 'Train/mean miou_metric': 0.3155200481414795, 'Train/mean f1': 0.48654904961586, 'Train/mean precision': 0.4491676688194275, 'Train/mean recall': 0.5307173728942871, 'Train/mean hd95_metric': 101.82313537597656}
Epoch [18/300] Validation [1/16] Loss: 0.68094  focal_loss 0.10208  dice_loss 0.57886 
Epoch [18/300] Validation [2/16] Loss: 0.79334  focal_loss 0.07855  dice_loss 0.71479 
Epoch [18/300] Validation [3/16] Loss: 0.82699  focal_loss 0.11470  dice_loss 0.71229 
Epoch [18/300] Validation [4/16] Loss: 0.75779  focal_loss 0.09047  dice_loss 0.66732 
Epoch [18/300] Validation [5/16] Loss: 0.70639  focal_loss 0.05605  dice_loss 0.65034 
Epoch [18/300] Validation [6/16] Loss: 0.65227  focal_loss 0.05552  dice_loss 0.59675 
Epoch [18/300] Validation [7/16] Loss: 0.61489  focal_loss 0.05858  dice_loss 0.55631 
Epoch [18/300] Validation [8/16] Loss: 0.75301  focal_loss 0.06671  dice_loss 0.68630 
Epoch [18/300] Validation [9/16] Loss: 0.75887  focal_loss 0.07831  dice_loss 0.68057 
Epoch [18/300] Validation [10/16] Loss: 0.76060  focal_loss 0.10928  dice_loss 0.65132 
Epoch [18/300] Validation [11/16] Loss: 0.62006  focal_loss 0.05326  dice_loss 0.56679 
Epoch [18/300] Validation [12/16] Loss: 0.77973  focal_loss 0.05222  dice_loss 0.72751 
Epoch [18/300] Validation [13/16] Loss: 0.71582  focal_loss 0.06622  dice_loss 0.64959 
Epoch [18/300] Validation [14/16] Loss: 0.86579  focal_loss 0.10102  dice_loss 0.76477 
Epoch [18/300] Validation [15/16] Loss: 0.77000  focal_loss 0.11367  dice_loss 0.65633 
Epoch [18/300] Validation [16/16] Loss: 0.59804  focal_loss 0.05447  dice_loss 0.54356 
Epoch [18/300] Validation metric {'Val/mean dice_metric': 0.4383656084537506, 'Val/mean miou_metric': 0.3204200267791748, 'Val/mean f1': 0.4906408488750458, 'Val/mean precision': 0.4471812844276428, 'Val/mean recall': 0.54345703125, 'Val/mean hd95_metric': 100.7788314819336}
Cheakpoint...
Epoch [18/300] best acc:tensor([0.4384], device='cuda:0'), Now : mean acc: tensor([0.4384], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.4383656084537506, 'Val/mean miou_metric': 0.3204200267791748, 'Val/mean f1': 0.4906408488750458, 'Val/mean precision': 0.4471812844276428, 'Val/mean recall': 0.54345703125, 'Val/mean hd95_metric': 100.7788314819336}
Epoch [19/300] Training [1/62] Loss: 0.77171 
Epoch [19/300] Training [2/62] Loss: 0.79155 
Epoch [19/300] Training [3/62] Loss: 0.52554 
Epoch [19/300] Training [4/62] Loss: 0.71370 
Epoch [19/300] Training [5/62] Loss: 0.80624 
Epoch [19/300] Training [6/62] Loss: 0.75121 
Epoch [19/300] Training [7/62] Loss: 0.71398 
Epoch [19/300] Training [8/62] Loss: 0.77154 
Epoch [19/300] Training [9/62] Loss: 0.77980 
Epoch [19/300] Training [10/62] Loss: 0.84979 
Epoch [19/300] Training [11/62] Loss: 0.65529 
Epoch [19/300] Training [12/62] Loss: 0.77431 
Epoch [19/300] Training [13/62] Loss: 0.82139 
Epoch [19/300] Training [14/62] Loss: 0.75213 
Epoch [19/300] Training [15/62] Loss: 0.76195 
Epoch [19/300] Training [16/62] Loss: 0.75355 
Epoch [19/300] Training [17/62] Loss: 0.67395 
Epoch [19/300] Training [18/62] Loss: 0.78684 
Epoch [19/300] Training [19/62] Loss: 0.82192 
Epoch [19/300] Training [20/62] Loss: 0.87982 
Epoch [19/300] Training [21/62] Loss: 0.70859 
Epoch [19/300] Training [22/62] Loss: 0.69405 
Epoch [19/300] Training [23/62] Loss: 0.76938 
Epoch [19/300] Training [24/62] Loss: 0.71580 
Epoch [19/300] Training [25/62] Loss: 0.69012 
Epoch [19/300] Training [26/62] Loss: 0.69858 
Epoch [19/300] Training [27/62] Loss: 0.76275 
Epoch [19/300] Training [28/62] Loss: 0.61965 
Epoch [19/300] Training [29/62] Loss: 0.72526 
Epoch [19/300] Training [30/62] Loss: 0.82898 
Epoch [19/300] Training [31/62] Loss: 0.63110 
Epoch [19/300] Training [32/62] Loss: 0.83844 
Epoch [19/300] Training [33/62] Loss: 0.82479 
Epoch [19/300] Training [34/62] Loss: 0.66600 
Epoch [19/300] Training [35/62] Loss: 0.68671 
Epoch [19/300] Training [36/62] Loss: 0.73164 
Epoch [19/300] Training [37/62] Loss: 0.69369 
Epoch [19/300] Training [38/62] Loss: 0.68276 
Epoch [19/300] Training [39/62] Loss: 0.67813 
Epoch [19/300] Training [40/62] Loss: 0.65395 
Epoch [19/300] Training [41/62] Loss: 0.81643 
Epoch [19/300] Training [42/62] Loss: 0.62505 
Epoch [19/300] Training [43/62] Loss: 0.72854 
Epoch [19/300] Training [44/62] Loss: 0.84660 
Epoch [19/300] Training [45/62] Loss: 0.64475 
Epoch [19/300] Training [46/62] Loss: 0.67842 
Epoch [19/300] Training [47/62] Loss: 0.76394 
Epoch [19/300] Training [48/62] Loss: 0.83238 
Epoch [19/300] Training [49/62] Loss: 0.76284 
Epoch [19/300] Training [50/62] Loss: 0.71927 
Epoch [19/300] Training [51/62] Loss: 0.70364 
Epoch [19/300] Training [52/62] Loss: 0.88418 
Epoch [19/300] Training [53/62] Loss: 0.74904 
Epoch [19/300] Training [54/62] Loss: 0.80401 
Epoch [19/300] Training [55/62] Loss: 0.69125 
Epoch [19/300] Training [56/62] Loss: 0.72509 
Epoch [19/300] Training [57/62] Loss: 0.85026 
Epoch [19/300] Training [58/62] Loss: 0.77125 
Epoch [19/300] Training [59/62] Loss: 0.88462 
Epoch [19/300] Training [60/62] Loss: 0.68334 
Epoch [19/300] Training [61/62] Loss: 0.65241 
Epoch [19/300] Training [62/62] Loss: 0.91162 
Epoch [19/300] Training metric {'Train/mean dice_metric': 0.43511325120925903, 'Train/mean miou_metric': 0.31764480471611023, 'Train/mean f1': 0.4944325089454651, 'Train/mean precision': 0.4550812244415283, 'Train/mean recall': 0.541233479976654, 'Train/mean hd95_metric': 100.9893798828125}
Epoch [19/300] Validation [1/16] Loss: 0.63341  focal_loss 0.08687  dice_loss 0.54654 
Epoch [19/300] Validation [2/16] Loss: 0.77240  focal_loss 0.07009  dice_loss 0.70231 
Epoch [19/300] Validation [3/16] Loss: 0.80029  focal_loss 0.10733  dice_loss 0.69295 
Epoch [19/300] Validation [4/16] Loss: 0.71259  focal_loss 0.07946  dice_loss 0.63313 
Epoch [19/300] Validation [5/16] Loss: 0.69765  focal_loss 0.05492  dice_loss 0.64273 
Epoch [19/300] Validation [6/16] Loss: 0.63643  focal_loss 0.05732  dice_loss 0.57912 
Epoch [19/300] Validation [7/16] Loss: 0.64126  focal_loss 0.07010  dice_loss 0.57116 
Epoch [19/300] Validation [8/16] Loss: 0.74667  focal_loss 0.06433  dice_loss 0.68235 
Epoch [19/300] Validation [9/16] Loss: 0.80337  focal_loss 0.09500  dice_loss 0.70837 
Epoch [19/300] Validation [10/16] Loss: 0.71388  focal_loss 0.08673  dice_loss 0.62715 
Epoch [19/300] Validation [11/16] Loss: 0.62674  focal_loss 0.05537  dice_loss 0.57137 
Epoch [19/300] Validation [12/16] Loss: 0.76251  focal_loss 0.05456  dice_loss 0.70795 
Epoch [19/300] Validation [13/16] Loss: 0.68816  focal_loss 0.06208  dice_loss 0.62608 
Epoch [19/300] Validation [14/16] Loss: 0.80434  focal_loss 0.08815  dice_loss 0.71620 
Epoch [19/300] Validation [15/16] Loss: 0.63109  focal_loss 0.06408  dice_loss 0.56702 
Epoch [19/300] Validation [16/16] Loss: 0.48067  focal_loss 0.03889  dice_loss 0.44178 
Epoch [19/300] Validation metric {'Val/mean dice_metric': 0.4440416693687439, 'Val/mean miou_metric': 0.32463064789772034, 'Val/mean f1': 0.49885791540145874, 'Val/mean precision': 0.45941710472106934, 'Val/mean recall': 0.5457066893577576, 'Val/mean hd95_metric': 100.14399719238281}
Cheakpoint...
Epoch [19/300] best acc:tensor([0.4440], device='cuda:0'), Now : mean acc: tensor([0.4440], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.4440416693687439, 'Val/mean miou_metric': 0.32463064789772034, 'Val/mean f1': 0.49885791540145874, 'Val/mean precision': 0.45941710472106934, 'Val/mean recall': 0.5457066893577576, 'Val/mean hd95_metric': 100.14399719238281}
Epoch [20/300] Training [1/62] Loss: 0.84483 
Epoch [20/300] Training [2/62] Loss: 0.70148 
Epoch [20/300] Training [3/62] Loss: 0.65102 
Epoch [20/300] Training [4/62] Loss: 0.69907 
Epoch [20/300] Training [5/62] Loss: 0.75564 
Epoch [20/300] Training [6/62] Loss: 0.80244 
Epoch [20/300] Training [7/62] Loss: 0.69682 
Epoch [20/300] Training [8/62] Loss: 0.78517 
Epoch [20/300] Training [9/62] Loss: 0.67886 
Epoch [20/300] Training [10/62] Loss: 0.67964 
Epoch [20/300] Training [11/62] Loss: 0.76135 
Epoch [20/300] Training [12/62] Loss: 0.71034 
Epoch [20/300] Training [13/62] Loss: 0.76197 
Epoch [20/300] Training [14/62] Loss: 0.72110 
Epoch [20/300] Training [15/62] Loss: 0.64126 
Epoch [20/300] Training [16/62] Loss: 0.65175 
Epoch [20/300] Training [17/62] Loss: 0.89622 
Epoch [20/300] Training [18/62] Loss: 0.87285 
Epoch [20/300] Training [19/62] Loss: 0.76396 
Epoch [20/300] Training [20/62] Loss: 0.74816 
Epoch [20/300] Training [21/62] Loss: 0.64337 
Epoch [20/300] Training [22/62] Loss: 0.79571 
Epoch [20/300] Training [23/62] Loss: 0.56658 
Epoch [20/300] Training [24/62] Loss: 0.83345 
Epoch [20/300] Training [25/62] Loss: 0.92195 
Epoch [20/300] Training [26/62] Loss: 0.76788 
Epoch [20/300] Training [27/62] Loss: 0.74598 
Epoch [20/300] Training [28/62] Loss: 0.72999 
Epoch [20/300] Training [29/62] Loss: 0.69976 
Epoch [20/300] Training [30/62] Loss: 0.84205 
Epoch [20/300] Training [31/62] Loss: 0.69139 
Epoch [20/300] Training [32/62] Loss: 0.80003 
Epoch [20/300] Training [33/62] Loss: 0.75458 
Epoch [20/300] Training [34/62] Loss: 0.56681 
Epoch [20/300] Training [35/62] Loss: 0.90406 
Epoch [20/300] Training [36/62] Loss: 0.77677 
Epoch [20/300] Training [37/62] Loss: 0.75125 
Epoch [20/300] Training [38/62] Loss: 0.71343 
Epoch [20/300] Training [39/62] Loss: 0.72515 
Epoch [20/300] Training [40/62] Loss: 0.57917 
Epoch [20/300] Training [41/62] Loss: 0.70772 
Epoch [20/300] Training [42/62] Loss: 0.61833 
Epoch [20/300] Training [43/62] Loss: 0.79070 
Epoch [20/300] Training [44/62] Loss: 0.66996 
Epoch [20/300] Training [45/62] Loss: 0.58663 
Epoch [20/300] Training [46/62] Loss: 0.68512 
Epoch [20/300] Training [47/62] Loss: 0.94594 
Epoch [20/300] Training [48/62] Loss: 0.72279 
Epoch [20/300] Training [49/62] Loss: 0.72988 
Epoch [20/300] Training [50/62] Loss: 0.73604 
Epoch [20/300] Training [51/62] Loss: 0.85901 
Epoch [20/300] Training [52/62] Loss: 0.70902 
Epoch [20/300] Training [53/62] Loss: 0.73253 
Epoch [20/300] Training [54/62] Loss: 0.73230 
Epoch [20/300] Training [55/62] Loss: 0.70079 
Epoch [20/300] Training [56/62] Loss: 0.73237 
Epoch [20/300] Training [57/62] Loss: 0.66451 
Epoch [20/300] Training [58/62] Loss: 0.77463 
Epoch [20/300] Training [59/62] Loss: 0.68164 
Epoch [20/300] Training [60/62] Loss: 0.85507 
Epoch [20/300] Training [61/62] Loss: 0.69220 
Epoch [20/300] Training [62/62] Loss: 0.57180 
Epoch [20/300] Training metric {'Train/mean dice_metric': 0.4391220510005951, 'Train/mean miou_metric': 0.32169973850250244, 'Train/mean f1': 0.5001175999641418, 'Train/mean precision': 0.4650428593158722, 'Train/mean recall': 0.5409148335456848, 'Train/mean hd95_metric': 102.7634048461914}
Epoch [20/300] Validation [1/16] Loss: 0.80107  focal_loss 0.21050  dice_loss 0.59056 
Epoch [20/300] Validation [2/16] Loss: 0.76627  focal_loss 0.09337  dice_loss 0.67290 
Epoch [20/300] Validation [3/16] Loss: 0.86704  focal_loss 0.16508  dice_loss 0.70196 
Epoch [20/300] Validation [4/16] Loss: 0.76694  focal_loss 0.12152  dice_loss 0.64542 
Epoch [20/300] Validation [5/16] Loss: 0.75450  focal_loss 0.09825  dice_loss 0.65625 
Epoch [20/300] Validation [6/16] Loss: 0.62924  focal_loss 0.07269  dice_loss 0.55655 
Epoch [20/300] Validation [7/16] Loss: 0.58408  focal_loss 0.05988  dice_loss 0.52420 
Epoch [20/300] Validation [8/16] Loss: 0.70803  focal_loss 0.07334  dice_loss 0.63470 
Epoch [20/300] Validation [9/16] Loss: 0.67769  focal_loss 0.09087  dice_loss 0.58682 
Epoch [20/300] Validation [10/16] Loss: 0.88523  focal_loss 0.18321  dice_loss 0.70202 
Epoch [20/300] Validation [11/16] Loss: 0.62441  focal_loss 0.05741  dice_loss 0.56700 
Epoch [20/300] Validation [12/16] Loss: 0.76370  focal_loss 0.07280  dice_loss 0.69090 
Epoch [20/300] Validation [13/16] Loss: 0.71184  focal_loss 0.09678  dice_loss 0.61506 
Epoch [20/300] Validation [14/16] Loss: 0.85358  focal_loss 0.13015  dice_loss 0.72343 
Epoch [20/300] Validation [15/16] Loss: 0.75094  focal_loss 0.14767  dice_loss 0.60327 
Epoch [20/300] Validation [16/16] Loss: 0.55456  focal_loss 0.08176  dice_loss 0.47279 
Epoch [20/300] Validation metric {'Val/mean dice_metric': 0.44114285707473755, 'Val/mean miou_metric': 0.3227611482143402, 'Val/mean f1': 0.49645835161209106, 'Val/mean precision': 0.46873679757118225, 'Val/mean recall': 0.5276650190353394, 'Val/mean hd95_metric': 102.58243560791016}
Cheakpoint...
Epoch [20/300] best acc:tensor([0.4440], device='cuda:0'), Now : mean acc: tensor([0.4411], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.44114285707473755, 'Val/mean miou_metric': 0.3227611482143402, 'Val/mean f1': 0.49645835161209106, 'Val/mean precision': 0.46873679757118225, 'Val/mean recall': 0.5276650190353394, 'Val/mean hd95_metric': 102.58243560791016}
Epoch [21/300] Training [1/62] Loss: 0.77775 
Epoch [21/300] Training [2/62] Loss: 0.81666 
Epoch [21/300] Training [3/62] Loss: 0.70619 
Epoch [21/300] Training [4/62] Loss: 0.68407 
Epoch [21/300] Training [5/62] Loss: 0.72549 
Epoch [21/300] Training [6/62] Loss: 0.82466 
Epoch [21/300] Training [7/62] Loss: 0.63553 
Epoch [21/300] Training [8/62] Loss: 0.73807 
Epoch [21/300] Training [9/62] Loss: 0.64574 
Epoch [21/300] Training [10/62] Loss: 0.60499 
Epoch [21/300] Training [11/62] Loss: 0.65331 
Epoch [21/300] Training [12/62] Loss: 0.75121 
Epoch [21/300] Training [13/62] Loss: 0.72039 
Epoch [21/300] Training [14/62] Loss: 0.73600 
Epoch [21/300] Training [15/62] Loss: 0.59015 
Epoch [21/300] Training [16/62] Loss: 0.73679 
Epoch [21/300] Training [17/62] Loss: 0.91105 
Epoch [21/300] Training [18/62] Loss: 0.68276 
Epoch [21/300] Training [19/62] Loss: 0.55753 
Epoch [21/300] Training [20/62] Loss: 0.75487 
Epoch [21/300] Training [21/62] Loss: 0.61773 
Epoch [21/300] Training [22/62] Loss: 0.63732 
Epoch [21/300] Training [23/62] Loss: 0.73675 
Epoch [21/300] Training [24/62] Loss: 0.77396 
Epoch [21/300] Training [25/62] Loss: 0.71465 
Epoch [21/300] Training [26/62] Loss: 0.68561 
Epoch [21/300] Training [27/62] Loss: 0.70588 
Epoch [21/300] Training [28/62] Loss: 0.73711 
Epoch [21/300] Training [29/62] Loss: 0.87635 
Epoch [21/300] Training [30/62] Loss: 0.71850 
Epoch [21/300] Training [31/62] Loss: 0.83392 
Epoch [21/300] Training [32/62] Loss: 0.78589 
Epoch [21/300] Training [33/62] Loss: 0.91364 
Epoch [21/300] Training [34/62] Loss: 0.70063 
Epoch [21/300] Training [35/62] Loss: 0.79320 
Epoch [21/300] Training [36/62] Loss: 0.83755 
Epoch [21/300] Training [37/62] Loss: 0.75050 
Epoch [21/300] Training [38/62] Loss: 0.63127 
Epoch [21/300] Training [39/62] Loss: 0.56552 
Epoch [21/300] Training [40/62] Loss: 0.71162 
Epoch [21/300] Training [41/62] Loss: 0.71940 
Epoch [21/300] Training [42/62] Loss: 0.76064 
Epoch [21/300] Training [43/62] Loss: 0.92454 
Epoch [21/300] Training [44/62] Loss: 0.75272 
Epoch [21/300] Training [45/62] Loss: 0.77777 
Epoch [21/300] Training [46/62] Loss: 0.78688 
Epoch [21/300] Training [47/62] Loss: 0.60166 
Epoch [21/300] Training [48/62] Loss: 0.80105 
Epoch [21/300] Training [49/62] Loss: 0.90294 
Epoch [21/300] Training [50/62] Loss: 0.79414 
Epoch [21/300] Training [51/62] Loss: 0.56313 
Epoch [21/300] Training [52/62] Loss: 0.58096 
Epoch [21/300] Training [53/62] Loss: 0.71289 
Epoch [21/300] Training [54/62] Loss: 0.70259 
Epoch [21/300] Training [55/62] Loss: 0.50273 
Epoch [21/300] Training [56/62] Loss: 0.76171 
Epoch [21/300] Training [57/62] Loss: 0.71300 
Epoch [21/300] Training [58/62] Loss: 0.72556 
Epoch [21/300] Training [59/62] Loss: 0.70169 
Epoch [21/300] Training [60/62] Loss: 0.56614 
Epoch [21/300] Training [61/62] Loss: 0.70778 
Epoch [21/300] Training [62/62] Loss: 0.35120 
Epoch [21/300] Training metric {'Train/mean dice_metric': 0.4566277861595154, 'Train/mean miou_metric': 0.33719944953918457, 'Train/mean f1': 0.50999516248703, 'Train/mean precision': 0.4927176237106323, 'Train/mean recall': 0.5285284519195557, 'Train/mean hd95_metric': 96.82660675048828}
Epoch [21/300] Validation [1/16] Loss: 0.55361  focal_loss 0.10613  dice_loss 0.44748 
Epoch [21/300] Validation [2/16] Loss: 0.73743  focal_loss 0.10228  dice_loss 0.63515 
Epoch [21/300] Validation [3/16] Loss: 0.88625  focal_loss 0.20362  dice_loss 0.68262 
Epoch [21/300] Validation [4/16] Loss: 0.72486  focal_loss 0.12248  dice_loss 0.60239 
Epoch [21/300] Validation [5/16] Loss: 0.70398  focal_loss 0.08317  dice_loss 0.62081 
Epoch [21/300] Validation [6/16] Loss: 0.60422  focal_loss 0.07322  dice_loss 0.53099 
Epoch [21/300] Validation [7/16] Loss: 0.60289  focal_loss 0.09097  dice_loss 0.51193 
Epoch [21/300] Validation [8/16] Loss: 0.71046  focal_loss 0.10308  dice_loss 0.60738 
Epoch [21/300] Validation [9/16] Loss: 0.68534  focal_loss 0.09198  dice_loss 0.59336 
Epoch [21/300] Validation [10/16] Loss: 0.69110  focal_loss 0.11295  dice_loss 0.57815 
Epoch [21/300] Validation [11/16] Loss: 0.59905  focal_loss 0.08261  dice_loss 0.51644 
Epoch [21/300] Validation [12/16] Loss: 0.78223  focal_loss 0.10605  dice_loss 0.67618 
Epoch [21/300] Validation [13/16] Loss: 0.69018  focal_loss 0.10314  dice_loss 0.58704 
Epoch [21/300] Validation [14/16] Loss: 0.86424  focal_loss 0.14573  dice_loss 0.71851 
Epoch [21/300] Validation [15/16] Loss: 0.55916  focal_loss 0.06537  dice_loss 0.49380 
Epoch [21/300] Validation [16/16] Loss: 0.43885  focal_loss 0.05526  dice_loss 0.38359 
Epoch [21/300] Validation metric {'Val/mean dice_metric': 0.4651012420654297, 'Val/mean miou_metric': 0.3445550203323364, 'Val/mean f1': 0.5175200700759888, 'Val/mean precision': 0.481673002243042, 'Val/mean recall': 0.5591318011283875, 'Val/mean hd95_metric': 99.2897720336914}
Cheakpoint...
Epoch [21/300] best acc:tensor([0.4651], device='cuda:0'), Now : mean acc: tensor([0.4651], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.4651012420654297, 'Val/mean miou_metric': 0.3445550203323364, 'Val/mean f1': 0.5175200700759888, 'Val/mean precision': 0.481673002243042, 'Val/mean recall': 0.5591318011283875, 'Val/mean hd95_metric': 99.2897720336914}
Epoch [22/300] Training [1/62] Loss: 0.66622 
Epoch [22/300] Training [2/62] Loss: 0.75546 
Epoch [22/300] Training [3/62] Loss: 0.67768 
Epoch [22/300] Training [4/62] Loss: 0.83367 
Epoch [22/300] Training [5/62] Loss: 0.73717 
Epoch [22/300] Training [6/62] Loss: 0.64176 
Epoch [22/300] Training [7/62] Loss: 0.75859 
Epoch [22/300] Training [8/62] Loss: 0.65942 
Epoch [22/300] Training [9/62] Loss: 0.63368 
Epoch [22/300] Training [10/62] Loss: 0.59116 
Epoch [22/300] Training [11/62] Loss: 0.57906 
Epoch [22/300] Training [12/62] Loss: 0.56098 
Epoch [22/300] Training [13/62] Loss: 0.57569 
Epoch [22/300] Training [14/62] Loss: 0.73651 
Epoch [22/300] Training [15/62] Loss: 0.64348 
Epoch [22/300] Training [16/62] Loss: 0.88425 
Epoch [22/300] Training [17/62] Loss: 0.84235 
Epoch [22/300] Training [18/62] Loss: 0.78178 
Epoch [22/300] Training [19/62] Loss: 0.63908 
Epoch [22/300] Training [20/62] Loss: 0.85965 
Epoch [22/300] Training [21/62] Loss: 0.74284 
Epoch [22/300] Training [22/62] Loss: 0.70544 
Epoch [22/300] Training [23/62] Loss: 0.79124 
Epoch [22/300] Training [24/62] Loss: 0.71966 
Epoch [22/300] Training [25/62] Loss: 0.64680 
Epoch [22/300] Training [26/62] Loss: 0.73409 
Epoch [22/300] Training [27/62] Loss: 0.74247 
Epoch [22/300] Training [28/62] Loss: 0.60705 
Epoch [22/300] Training [29/62] Loss: 0.71971 
Epoch [22/300] Training [30/62] Loss: 0.60724 
Epoch [22/300] Training [31/62] Loss: 0.59115 
Epoch [22/300] Training [32/62] Loss: 0.66128 
Epoch [22/300] Training [33/62] Loss: 0.84579 
Epoch [22/300] Training [34/62] Loss: 0.77106 
Epoch [22/300] Training [35/62] Loss: 0.74290 
Epoch [22/300] Training [36/62] Loss: 0.65163 
Epoch [22/300] Training [37/62] Loss: 0.66761 
Epoch [22/300] Training [38/62] Loss: 0.76863 
Epoch [22/300] Training [39/62] Loss: 0.69493 
Epoch [22/300] Training [40/62] Loss: 0.78018 
Epoch [22/300] Training [41/62] Loss: 0.80437 
Epoch [22/300] Training [42/62] Loss: 0.72024 
Epoch [22/300] Training [43/62] Loss: 0.69099 
Epoch [22/300] Training [44/62] Loss: 0.90049 
Epoch [22/300] Training [45/62] Loss: 0.79531 
Epoch [22/300] Training [46/62] Loss: 0.86687 
Epoch [22/300] Training [47/62] Loss: 0.70809 
Epoch [22/300] Training [48/62] Loss: 0.77964 
Epoch [22/300] Training [49/62] Loss: 0.57383 
Epoch [22/300] Training [50/62] Loss: 0.70797 
Epoch [22/300] Training [51/62] Loss: 0.63903 
Epoch [22/300] Training [52/62] Loss: 0.75263 
Epoch [22/300] Training [53/62] Loss: 0.72316 
Epoch [22/300] Training [54/62] Loss: 0.67309 
Epoch [22/300] Training [55/62] Loss: 0.72569 
Epoch [22/300] Training [56/62] Loss: 0.60847 
Epoch [22/300] Training [57/62] Loss: 0.71972 
Epoch [22/300] Training [58/62] Loss: 0.69480 
Epoch [22/300] Training [59/62] Loss: 0.57942 
Epoch [22/300] Training [60/62] Loss: 0.76423 
Epoch [22/300] Training [61/62] Loss: 0.73691 
Epoch [22/300] Training [62/62] Loss: 0.72926 
Epoch [22/300] Training metric {'Train/mean dice_metric': 0.4687393307685852, 'Train/mean miou_metric': 0.3469303250312805, 'Train/mean f1': 0.5253887176513672, 'Train/mean precision': 0.4937480092048645, 'Train/mean recall': 0.5613623261451721, 'Train/mean hd95_metric': 99.52641296386719}
Epoch [22/300] Validation [1/16] Loss: 0.66789  focal_loss 0.16471  dice_loss 0.50318 
Epoch [22/300] Validation [2/16] Loss: 0.74876  focal_loss 0.12171  dice_loss 0.62705 
Epoch [22/300] Validation [3/16] Loss: 0.87338  focal_loss 0.21358  dice_loss 0.65980 
Epoch [22/300] Validation [4/16] Loss: 0.73172  focal_loss 0.16850  dice_loss 0.56322 
Epoch [22/300] Validation [5/16] Loss: 0.52974  focal_loss 0.05315  dice_loss 0.47659 
Epoch [22/300] Validation [6/16] Loss: 0.53577  focal_loss 0.08233  dice_loss 0.45344 
Epoch [22/300] Validation [7/16] Loss: 0.56974  focal_loss 0.10371  dice_loss 0.46603 
Epoch [22/300] Validation [8/16] Loss: 0.70284  focal_loss 0.10566  dice_loss 0.59718 
Epoch [22/300] Validation [9/16] Loss: 0.75432  focal_loss 0.16805  dice_loss 0.58626 
Epoch [22/300] Validation [10/16] Loss: 0.67782  focal_loss 0.13653  dice_loss 0.54130 
Epoch [22/300] Validation [11/16] Loss: 0.63507  focal_loss 0.11292  dice_loss 0.52215 
Epoch [22/300] Validation [12/16] Loss: 0.73865  focal_loss 0.08010  dice_loss 0.65855 
Epoch [22/300] Validation [13/16] Loss: 0.62992  focal_loss 0.10938  dice_loss 0.52055 
Epoch [22/300] Validation [14/16] Loss: 0.86853  focal_loss 0.16835  dice_loss 0.70018 
Epoch [22/300] Validation [15/16] Loss: 0.70758  focal_loss 0.16432  dice_loss 0.54326 
Epoch [22/300] Validation [16/16] Loss: 0.53079  focal_loss 0.11675  dice_loss 0.41404 
Epoch [22/300] Validation metric {'Val/mean dice_metric': 0.4743975102901459, 'Val/mean miou_metric': 0.3521907925605774, 'Val/mean f1': 0.5255917906761169, 'Val/mean precision': 0.4950947165489197, 'Val/mean recall': 0.5600926280021667, 'Val/mean hd95_metric': 97.20355987548828}
Cheakpoint...
Epoch [22/300] best acc:tensor([0.4744], device='cuda:0'), Now : mean acc: tensor([0.4744], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.4743975102901459, 'Val/mean miou_metric': 0.3521907925605774, 'Val/mean f1': 0.5255917906761169, 'Val/mean precision': 0.4950947165489197, 'Val/mean recall': 0.5600926280021667, 'Val/mean hd95_metric': 97.20355987548828}
Epoch [23/300] Training [1/62] Loss: 0.73352 
Epoch [23/300] Training [2/62] Loss: 0.73681 
Epoch [23/300] Training [3/62] Loss: 0.86038 
Epoch [23/300] Training [4/62] Loss: 0.74679 
Epoch [23/300] Training [5/62] Loss: 0.78721 
Epoch [23/300] Training [6/62] Loss: 0.65754 
Epoch [23/300] Training [7/62] Loss: 0.76502 
Epoch [23/300] Training [8/62] Loss: 0.57714 
Epoch [23/300] Training [9/62] Loss: 0.72433 
Epoch [23/300] Training [10/62] Loss: 0.63795 
Epoch [23/300] Training [11/62] Loss: 0.68159 
Epoch [23/300] Training [12/62] Loss: 0.68207 
Epoch [23/300] Training [13/62] Loss: 0.93549 
Epoch [23/300] Training [14/62] Loss: 0.70879 
Epoch [23/300] Training [15/62] Loss: 0.76758 
Epoch [23/300] Training [16/62] Loss: 0.87308 
Epoch [23/300] Training [17/62] Loss: 0.69204 
Epoch [23/300] Training [18/62] Loss: 0.58804 
Epoch [23/300] Training [19/62] Loss: 0.59431 
Epoch [23/300] Training [20/62] Loss: 0.73655 
Epoch [23/300] Training [21/62] Loss: 0.62952 
Epoch [23/300] Training [22/62] Loss: 0.66372 
Epoch [23/300] Training [23/62] Loss: 0.87613 
Epoch [23/300] Training [24/62] Loss: 0.63053 
Epoch [23/300] Training [25/62] Loss: 0.80758 
Epoch [23/300] Training [26/62] Loss: 0.65576 
Epoch [23/300] Training [27/62] Loss: 0.72590 
Epoch [23/300] Training [28/62] Loss: 0.56830 
Epoch [23/300] Training [29/62] Loss: 0.66764 
Epoch [23/300] Training [30/62] Loss: 0.76383 
Epoch [23/300] Training [31/62] Loss: 0.83514 
Epoch [23/300] Training [32/62] Loss: 0.53045 
Epoch [23/300] Training [33/62] Loss: 0.85587 
Epoch [23/300] Training [34/62] Loss: 0.78886 
Epoch [23/300] Training [35/62] Loss: 0.59947 
Epoch [23/300] Training [36/62] Loss: 0.74944 
Epoch [23/300] Training [37/62] Loss: 0.60752 
Epoch [23/300] Training [38/62] Loss: 0.73870 
Epoch [23/300] Training [39/62] Loss: 0.79775 
Epoch [23/300] Training [40/62] Loss: 0.62536 
Epoch [23/300] Training [41/62] Loss: 0.77324 
Epoch [23/300] Training [42/62] Loss: 0.84729 
Epoch [23/300] Training [43/62] Loss: 0.75464 
Epoch [23/300] Training [44/62] Loss: 0.63518 
Epoch [23/300] Training [45/62] Loss: 0.68267 
Epoch [23/300] Training [46/62] Loss: 0.53644 
Epoch [23/300] Training [47/62] Loss: 0.67089 
Epoch [23/300] Training [48/62] Loss: 0.62151 
Epoch [23/300] Training [49/62] Loss: 0.59815 
Epoch [23/300] Training [50/62] Loss: 0.74554 
Epoch [23/300] Training [51/62] Loss: 0.74869 
Epoch [23/300] Training [52/62] Loss: 0.62777 
Epoch [23/300] Training [53/62] Loss: 0.73709 
Epoch [23/300] Training [54/62] Loss: 0.80004 
Epoch [23/300] Training [55/62] Loss: 0.70601 
Epoch [23/300] Training [56/62] Loss: 0.67576 
Epoch [23/300] Training [57/62] Loss: 0.59210 
Epoch [23/300] Training [58/62] Loss: 0.74764 
Epoch [23/300] Training [59/62] Loss: 0.77275 
Epoch [23/300] Training [60/62] Loss: 0.51662 
Epoch [23/300] Training [61/62] Loss: 0.57099 
Epoch [23/300] Training [62/62] Loss: 0.69104 
Epoch [23/300] Training metric {'Train/mean dice_metric': 0.4888133108615875, 'Train/mean miou_metric': 0.36470383405685425, 'Train/mean f1': 0.5352681279182434, 'Train/mean precision': 0.5104690790176392, 'Train/mean recall': 0.5625997185707092, 'Train/mean hd95_metric': 96.61896514892578}
Epoch [23/300] Validation [1/16] Loss: 0.61970  focal_loss 0.11306  dice_loss 0.50664 
Epoch [23/300] Validation [2/16] Loss: 0.74615  focal_loss 0.11188  dice_loss 0.63427 
Epoch [23/300] Validation [3/16] Loss: 0.77805  focal_loss 0.14267  dice_loss 0.63538 
Epoch [23/300] Validation [4/16] Loss: 0.74349  focal_loss 0.14534  dice_loss 0.59814 
Epoch [23/300] Validation [5/16] Loss: 0.62859  focal_loss 0.07016  dice_loss 0.55842 
Epoch [23/300] Validation [6/16] Loss: 0.58882  focal_loss 0.07207  dice_loss 0.51674 
Epoch [23/300] Validation [7/16] Loss: 0.57214  focal_loss 0.07893  dice_loss 0.49321 
Epoch [23/300] Validation [8/16] Loss: 0.65643  focal_loss 0.06536  dice_loss 0.59107 
Epoch [23/300] Validation [9/16] Loss: 0.72442  focal_loss 0.13051  dice_loss 0.59391 
Epoch [23/300] Validation [10/16] Loss: 0.77382  focal_loss 0.15343  dice_loss 0.62039 
Epoch [23/300] Validation [11/16] Loss: 0.55556  focal_loss 0.07648  dice_loss 0.47908 
Epoch [23/300] Validation [12/16] Loss: 0.70007  focal_loss 0.07028  dice_loss 0.62978 
Epoch [23/300] Validation [13/16] Loss: 0.68101  focal_loss 0.09521  dice_loss 0.58580 
Epoch [23/300] Validation [14/16] Loss: 0.77967  focal_loss 0.10239  dice_loss 0.67728 
Epoch [23/300] Validation [15/16] Loss: 0.61803  focal_loss 0.08301  dice_loss 0.53502 
Epoch [23/300] Validation [16/16] Loss: 0.40019  focal_loss 0.05896  dice_loss 0.34124 
Epoch [23/300] Validation metric {'Val/mean dice_metric': 0.4938529133796692, 'Val/mean miou_metric': 0.3689425587654114, 'Val/mean f1': 0.535564124584198, 'Val/mean precision': 0.5007950663566589, 'Val/mean recall': 0.5755212903022766, 'Val/mean hd95_metric': 96.60630798339844}
Cheakpoint...
Epoch [23/300] best acc:tensor([0.4939], device='cuda:0'), Now : mean acc: tensor([0.4939], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.4938529133796692, 'Val/mean miou_metric': 0.3689425587654114, 'Val/mean f1': 0.535564124584198, 'Val/mean precision': 0.5007950663566589, 'Val/mean recall': 0.5755212903022766, 'Val/mean hd95_metric': 96.60630798339844}
Epoch [24/300] Training [1/62] Loss: 0.58181 
Epoch [24/300] Training [2/62] Loss: 0.72953 
Epoch [24/300] Training [3/62] Loss: 0.74921 
Epoch [24/300] Training [4/62] Loss: 0.51840 
Epoch [24/300] Training [5/62] Loss: 0.71267 
Epoch [24/300] Training [6/62] Loss: 0.68074 
Epoch [24/300] Training [7/62] Loss: 0.86881 
Epoch [24/300] Training [8/62] Loss: 0.65263 
Epoch [24/300] Training [9/62] Loss: 0.81419 
Epoch [24/300] Training [10/62] Loss: 0.64099 
Epoch [24/300] Training [11/62] Loss: 0.67682 
Epoch [24/300] Training [12/62] Loss: 0.53575 
Epoch [24/300] Training [13/62] Loss: 0.69911 
Epoch [24/300] Training [14/62] Loss: 0.76873 
Epoch [24/300] Training [15/62] Loss: 0.58095 
Epoch [24/300] Training [16/62] Loss: 0.70020 
Epoch [24/300] Training [17/62] Loss: 0.85456 
Epoch [24/300] Training [18/62] Loss: 0.54858 
Epoch [24/300] Training [19/62] Loss: 0.76637 
Epoch [24/300] Training [20/62] Loss: 0.60854 
Epoch [24/300] Training [21/62] Loss: 0.65636 
Epoch [24/300] Training [22/62] Loss: 0.77422 
Epoch [24/300] Training [23/62] Loss: 0.61775 
Epoch [24/300] Training [24/62] Loss: 0.66356 
Epoch [24/300] Training [25/62] Loss: 0.53546 
Epoch [24/300] Training [26/62] Loss: 0.76620 
Epoch [24/300] Training [27/62] Loss: 0.62733 
Epoch [24/300] Training [28/62] Loss: 0.54973 
Epoch [24/300] Training [29/62] Loss: 0.71730 
Epoch [24/300] Training [30/62] Loss: 0.67144 
Epoch [24/300] Training [31/62] Loss: 0.74908 
Epoch [24/300] Training [32/62] Loss: 0.87844 
Epoch [24/300] Training [33/62] Loss: 0.68563 
Epoch [24/300] Training [34/62] Loss: 0.70568 
Epoch [24/300] Training [35/62] Loss: 0.62442 
Epoch [24/300] Training [36/62] Loss: 0.70899 
Epoch [24/300] Training [37/62] Loss: 0.69175 
Epoch [24/300] Training [38/62] Loss: 0.76466 
Epoch [24/300] Training [39/62] Loss: 0.62040 
Epoch [24/300] Training [40/62] Loss: 0.77799 
Epoch [24/300] Training [41/62] Loss: 0.66257 
Epoch [24/300] Training [42/62] Loss: 0.55059 
Epoch [24/300] Training [43/62] Loss: 0.88034 
Epoch [24/300] Training [44/62] Loss: 0.61621 
Epoch [24/300] Training [45/62] Loss: 0.61887 
Epoch [24/300] Training [46/62] Loss: 0.56362 
Epoch [24/300] Training [47/62] Loss: 0.79103 
Epoch [24/300] Training [48/62] Loss: 0.58264 
Epoch [24/300] Training [49/62] Loss: 0.75822 
Epoch [24/300] Training [50/62] Loss: 0.56465 
Epoch [24/300] Training [51/62] Loss: 0.73563 
Epoch [24/300] Training [52/62] Loss: 0.64829 
Epoch [24/300] Training [53/62] Loss: 0.75236 
Epoch [24/300] Training [54/62] Loss: 0.52070 
Epoch [24/300] Training [55/62] Loss: 0.75093 
Epoch [24/300] Training [56/62] Loss: 0.70104 
Epoch [24/300] Training [57/62] Loss: 0.80704 
Epoch [24/300] Training [58/62] Loss: 0.57308 
Epoch [24/300] Training [59/62] Loss: 0.68281 
Epoch [24/300] Training [60/62] Loss: 0.68835 
Epoch [24/300] Training [61/62] Loss: 0.72436 
Epoch [24/300] Training [62/62] Loss: 0.77704 
Epoch [24/300] Training metric {'Train/mean dice_metric': 0.5062887072563171, 'Train/mean miou_metric': 0.3801920711994171, 'Train/mean f1': 0.5472202301025391, 'Train/mean precision': 0.525261640548706, 'Train/mean recall': 0.5710949301719666, 'Train/mean hd95_metric': 94.80040740966797}
Epoch [24/300] Validation [1/16] Loss: 0.63679  focal_loss 0.18480  dice_loss 0.45199 
Epoch [24/300] Validation [2/16] Loss: 0.67143  focal_loss 0.09275  dice_loss 0.57869 
Epoch [24/300] Validation [3/16] Loss: 0.83003  focal_loss 0.18119  dice_loss 0.64884 
Epoch [24/300] Validation [4/16] Loss: 0.68992  focal_loss 0.12645  dice_loss 0.56348 
Epoch [24/300] Validation [5/16] Loss: 0.65740  focal_loss 0.06578  dice_loss 0.59162 
Epoch [24/300] Validation [6/16] Loss: 0.54620  focal_loss 0.06280  dice_loss 0.48340 
Epoch [24/300] Validation [7/16] Loss: 0.72174  focal_loss 0.15401  dice_loss 0.56773 
Epoch [24/300] Validation [8/16] Loss: 0.78045  focal_loss 0.12792  dice_loss 0.65253 
Epoch [24/300] Validation [9/16] Loss: 0.73894  focal_loss 0.13315  dice_loss 0.60579 
Epoch [24/300] Validation [10/16] Loss: 0.79260  focal_loss 0.17500  dice_loss 0.61761 
Epoch [24/300] Validation [11/16] Loss: 0.53812  focal_loss 0.08826  dice_loss 0.44986 
Epoch [24/300] Validation [12/16] Loss: 0.68868  focal_loss 0.06881  dice_loss 0.61987 
Epoch [24/300] Validation [13/16] Loss: 0.66748  focal_loss 0.11957  dice_loss 0.54791 
Epoch [24/300] Validation [14/16] Loss: 0.91318  focal_loss 0.16573  dice_loss 0.74745 
Epoch [24/300] Validation [15/16] Loss: 0.51161  focal_loss 0.08494  dice_loss 0.42666 
Epoch [24/300] Validation [16/16] Loss: 0.34014  focal_loss 0.04750  dice_loss 0.29264 
Epoch [24/300] Validation metric {'Val/mean dice_metric': 0.504418134689331, 'Val/mean miou_metric': 0.3809718191623688, 'Val/mean f1': 0.5439803600311279, 'Val/mean precision': 0.5277446508407593, 'Val/mean recall': 0.5612467527389526, 'Val/mean hd95_metric': 94.50138854980469}
Cheakpoint...
Epoch [24/300] best acc:tensor([0.5044], device='cuda:0'), Now : mean acc: tensor([0.5044], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.504418134689331, 'Val/mean miou_metric': 0.3809718191623688, 'Val/mean f1': 0.5439803600311279, 'Val/mean precision': 0.5277446508407593, 'Val/mean recall': 0.5612467527389526, 'Val/mean hd95_metric': 94.50138854980469}
Epoch [25/300] Training [1/62] Loss: 0.75593 
Epoch [25/300] Training [2/62] Loss: 0.67243 
Epoch [25/300] Training [3/62] Loss: 0.62492 
Epoch [25/300] Training [4/62] Loss: 0.48828 
Epoch [25/300] Training [5/62] Loss: 0.80647 
Epoch [25/300] Training [6/62] Loss: 0.79621 
Epoch [25/300] Training [7/62] Loss: 0.55315 
Epoch [25/300] Training [8/62] Loss: 0.64454 
Epoch [25/300] Training [9/62] Loss: 0.49802 
Epoch [25/300] Training [10/62] Loss: 0.63737 
Epoch [25/300] Training [11/62] Loss: 0.67342 
Epoch [25/300] Training [12/62] Loss: 0.62733 
Epoch [25/300] Training [13/62] Loss: 0.69796 
Epoch [25/300] Training [14/62] Loss: 0.43486 
Epoch [25/300] Training [15/62] Loss: 0.75783 
Epoch [25/300] Training [16/62] Loss: 0.54217 
Epoch [25/300] Training [17/62] Loss: 0.71277 
Epoch [25/300] Training [18/62] Loss: 0.83224 
Epoch [25/300] Training [19/62] Loss: 0.64755 
Epoch [25/300] Training [20/62] Loss: 0.76914 
Epoch [25/300] Training [21/62] Loss: 0.70964 
Epoch [25/300] Training [22/62] Loss: 0.59035 
Epoch [25/300] Training [23/62] Loss: 0.75557 
Epoch [25/300] Training [24/62] Loss: 0.60804 
Epoch [25/300] Training [25/62] Loss: 0.49557 
Epoch [25/300] Training [26/62] Loss: 0.73783 
Epoch [25/300] Training [27/62] Loss: 0.55587 
Epoch [25/300] Training [28/62] Loss: 0.46444 
Epoch [25/300] Training [29/62] Loss: 0.59667 
Epoch [25/300] Training [30/62] Loss: 0.70569 
Epoch [25/300] Training [31/62] Loss: 0.55753 
Epoch [25/300] Training [32/62] Loss: 0.88256 
Epoch [25/300] Training [33/62] Loss: 0.76641 
Epoch [25/300] Training [34/62] Loss: 0.51887 
Epoch [25/300] Training [35/62] Loss: 0.70645 
Epoch [25/300] Training [36/62] Loss: 0.77209 
Epoch [25/300] Training [37/62] Loss: 0.81852 
Epoch [25/300] Training [38/62] Loss: 0.59287 
Epoch [25/300] Training [39/62] Loss: 0.65989 
Epoch [25/300] Training [40/62] Loss: 0.66387 
Epoch [25/300] Training [41/62] Loss: 0.68329 
Epoch [25/300] Training [42/62] Loss: 0.91706 
Epoch [25/300] Training [43/62] Loss: 0.76690 
Epoch [25/300] Training [44/62] Loss: 0.68246 
Epoch [25/300] Training [45/62] Loss: 0.63371 
Epoch [25/300] Training [46/62] Loss: 0.70146 
Epoch [25/300] Training [47/62] Loss: 0.76736 
Epoch [25/300] Training [48/62] Loss: 0.77329 
Epoch [25/300] Training [49/62] Loss: 0.64747 
Epoch [25/300] Training [50/62] Loss: 0.47653 
Epoch [25/300] Training [51/62] Loss: 0.65400 
Epoch [25/300] Training [52/62] Loss: 0.82715 
Epoch [25/300] Training [53/62] Loss: 0.71144 
Epoch [25/300] Training [54/62] Loss: 0.75930 
Epoch [25/300] Training [55/62] Loss: 0.68231 
Epoch [25/300] Training [56/62] Loss: 0.68723 
Epoch [25/300] Training [57/62] Loss: 0.87044 
Epoch [25/300] Training [58/62] Loss: 0.50879 
Epoch [25/300] Training [59/62] Loss: 0.64216 
Epoch [25/300] Training [60/62] Loss: 0.68596 
Epoch [25/300] Training [61/62] Loss: 0.62923 
Epoch [25/300] Training [62/62] Loss: 0.87401 
Epoch [25/300] Training metric {'Train/mean dice_metric': 0.5149235725402832, 'Train/mean miou_metric': 0.39099806547164917, 'Train/mean f1': 0.5560791492462158, 'Train/mean precision': 0.5253897905349731, 'Train/mean recall': 0.5905762314796448, 'Train/mean hd95_metric': 93.17225646972656}
Epoch [25/300] Validation [1/16] Loss: 0.55351  focal_loss 0.11453  dice_loss 0.43898 
Epoch [25/300] Validation [2/16] Loss: 0.73826  focal_loss 0.10794  dice_loss 0.63031 
Epoch [25/300] Validation [3/16] Loss: 0.79577  focal_loss 0.15652  dice_loss 0.63925 
Epoch [25/300] Validation [4/16] Loss: 0.69483  focal_loss 0.15275  dice_loss 0.54208 
Epoch [25/300] Validation [5/16] Loss: 0.58925  focal_loss 0.05434  dice_loss 0.53491 
Epoch [25/300] Validation [6/16] Loss: 0.66201  focal_loss 0.10462  dice_loss 0.55739 
Epoch [25/300] Validation [7/16] Loss: 0.59799  focal_loss 0.08002  dice_loss 0.51797 
Epoch [25/300] Validation [8/16] Loss: 0.69755  focal_loss 0.08926  dice_loss 0.60829 
Epoch [25/300] Validation [9/16] Loss: 0.55660  focal_loss 0.06930  dice_loss 0.48730 
Epoch [25/300] Validation [10/16] Loss: 0.64964  focal_loss 0.10517  dice_loss 0.54447 
Epoch [25/300] Validation [11/16] Loss: 0.56460  focal_loss 0.07607  dice_loss 0.48853 
Epoch [25/300] Validation [12/16] Loss: 0.66241  focal_loss 0.06085  dice_loss 0.60157 
Epoch [25/300] Validation [13/16] Loss: 0.68334  focal_loss 0.11303  dice_loss 0.57031 
Epoch [25/300] Validation [14/16] Loss: 0.82750  focal_loss 0.14076  dice_loss 0.68674 
Epoch [25/300] Validation [15/16] Loss: 0.49660  focal_loss 0.06694  dice_loss 0.42965 
Epoch [25/300] Validation [16/16] Loss: 0.45246  focal_loss 0.05399  dice_loss 0.39846 
Epoch [25/300] Validation metric {'Val/mean dice_metric': 0.521312952041626, 'Val/mean miou_metric': 0.3961539566516876, 'Val/mean f1': 0.5576032400131226, 'Val/mean precision': 0.5307871103286743, 'Val/mean recall': 0.5872730612754822, 'Val/mean hd95_metric': 92.16368103027344}
Cheakpoint...
Epoch [25/300] best acc:tensor([0.5213], device='cuda:0'), Now : mean acc: tensor([0.5213], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.521312952041626, 'Val/mean miou_metric': 0.3961539566516876, 'Val/mean f1': 0.5576032400131226, 'Val/mean precision': 0.5307871103286743, 'Val/mean recall': 0.5872730612754822, 'Val/mean hd95_metric': 92.16368103027344}
Epoch [26/300] Training [1/62] Loss: 0.65384 
Epoch [26/300] Training [2/62] Loss: 0.70169 
Epoch [26/300] Training [3/62] Loss: 0.58194 
Epoch [26/300] Training [4/62] Loss: 0.86200 
Epoch [26/300] Training [5/62] Loss: 0.65269 
Epoch [26/300] Training [6/62] Loss: 0.80118 
Epoch [26/300] Training [7/62] Loss: 0.81545 
Epoch [26/300] Training [8/62] Loss: 0.88693 
Epoch [26/300] Training [9/62] Loss: 0.78303 
Epoch [26/300] Training [10/62] Loss: 0.77119 
Epoch [26/300] Training [11/62] Loss: 0.59868 
Epoch [26/300] Training [12/62] Loss: 0.78374 
Epoch [26/300] Training [13/62] Loss: 0.70081 
Epoch [26/300] Training [14/62] Loss: 0.66772 
Epoch [26/300] Training [15/62] Loss: 0.61865 
Epoch [26/300] Training [16/62] Loss: 0.63770 
Epoch [26/300] Training [17/62] Loss: 0.78091 
Epoch [26/300] Training [18/62] Loss: 0.76355 
Epoch [26/300] Training [19/62] Loss: 0.68168 
Epoch [26/300] Training [20/62] Loss: 0.68291 
Epoch [26/300] Training [21/62] Loss: 0.72970 
Epoch [26/300] Training [22/62] Loss: 0.67725 
Epoch [26/300] Training [23/62] Loss: 0.69967 
Epoch [26/300] Training [24/62] Loss: 0.76692 
Epoch [26/300] Training [25/62] Loss: 0.65911 
Epoch [26/300] Training [26/62] Loss: 0.63652 
Epoch [26/300] Training [27/62] Loss: 0.79997 
Epoch [26/300] Training [28/62] Loss: 0.72289 
Epoch [26/300] Training [29/62] Loss: 0.77585 
Epoch [26/300] Training [30/62] Loss: 0.51030 
Epoch [26/300] Training [31/62] Loss: 0.59862 
Epoch [26/300] Training [32/62] Loss: 0.74825 
Epoch [26/300] Training [33/62] Loss: 0.82556 
Epoch [26/300] Training [34/62] Loss: 0.66297 
Epoch [26/300] Training [35/62] Loss: 0.68900 
Epoch [26/300] Training [36/62] Loss: 0.68367 
Epoch [26/300] Training [37/62] Loss: 0.67747 
Epoch [26/300] Training [38/62] Loss: 0.56225 
Epoch [26/300] Training [39/62] Loss: 0.68036 
Epoch [26/300] Training [40/62] Loss: 0.63952 
Epoch [26/300] Training [41/62] Loss: 0.49780 
Epoch [26/300] Training [42/62] Loss: 0.63993 
Epoch [26/300] Training [43/62] Loss: 0.69833 
Epoch [26/300] Training [44/62] Loss: 0.65821 
Epoch [26/300] Training [45/62] Loss: 0.56820 
Epoch [26/300] Training [46/62] Loss: 0.49051 
Epoch [26/300] Training [47/62] Loss: 0.68449 
Epoch [26/300] Training [48/62] Loss: 0.52267 
Epoch [26/300] Training [49/62] Loss: 0.63914 
Epoch [26/300] Training [50/62] Loss: 0.47273 
Epoch [26/300] Training [51/62] Loss: 0.45031 
Epoch [26/300] Training [52/62] Loss: 0.54299 
Epoch [26/300] Training [53/62] Loss: 0.45051 
Epoch [26/300] Training [54/62] Loss: 0.62728 
Epoch [26/300] Training [55/62] Loss: 0.74446 
Epoch [26/300] Training [56/62] Loss: 0.72847 
Epoch [26/300] Training [57/62] Loss: 0.60961 
Epoch [26/300] Training [58/62] Loss: 0.68409 
Epoch [26/300] Training [59/62] Loss: 0.72449 
Epoch [26/300] Training [60/62] Loss: 0.63094 
Epoch [26/300] Training [61/62] Loss: 0.65920 
Epoch [26/300] Training [62/62] Loss: 0.67408 
Epoch [26/300] Training metric {'Train/mean dice_metric': 0.515405535697937, 'Train/mean miou_metric': 0.3875150680541992, 'Train/mean f1': 0.5578103065490723, 'Train/mean precision': 0.5287726521492004, 'Train/mean recall': 0.5902225375175476, 'Train/mean hd95_metric': 90.90287780761719}
Epoch [26/300] Validation [1/16] Loss: 0.69338  focal_loss 0.17672  dice_loss 0.51666 
Epoch [26/300] Validation [2/16] Loss: 0.63414  focal_loss 0.07890  dice_loss 0.55524 
Epoch [26/300] Validation [3/16] Loss: 0.79858  focal_loss 0.17635  dice_loss 0.62223 
Epoch [26/300] Validation [4/16] Loss: 0.67265  focal_loss 0.12663  dice_loss 0.54603 
Epoch [26/300] Validation [5/16] Loss: 0.56420  focal_loss 0.04244  dice_loss 0.52176 
Epoch [26/300] Validation [6/16] Loss: 0.55192  focal_loss 0.06559  dice_loss 0.48633 
Epoch [26/300] Validation [7/16] Loss: 0.59511  focal_loss 0.09621  dice_loss 0.49890 
Epoch [26/300] Validation [8/16] Loss: 0.66602  focal_loss 0.07394  dice_loss 0.59208 
Epoch [26/300] Validation [9/16] Loss: 0.64587  focal_loss 0.07877  dice_loss 0.56710 
Epoch [26/300] Validation [10/16] Loss: 0.79749  focal_loss 0.16127  dice_loss 0.63622 
Epoch [26/300] Validation [11/16] Loss: 0.50345  focal_loss 0.06425  dice_loss 0.43919 
Epoch [26/300] Validation [12/16] Loss: 0.64706  focal_loss 0.05913  dice_loss 0.58793 
Epoch [26/300] Validation [13/16] Loss: 0.57796  focal_loss 0.07592  dice_loss 0.50205 
Epoch [26/300] Validation [14/16] Loss: 0.78423  focal_loss 0.11945  dice_loss 0.66479 
Epoch [26/300] Validation [15/16] Loss: 0.49148  focal_loss 0.09671  dice_loss 0.39478 
Epoch [26/300] Validation [16/16] Loss: 0.36527  focal_loss 0.06783  dice_loss 0.29744 
Epoch [26/300] Validation metric {'Val/mean dice_metric': 0.5183430314064026, 'Val/mean miou_metric': 0.39128053188323975, 'Val/mean f1': 0.5544092655181885, 'Val/mean precision': 0.5399525165557861, 'Val/mean recall': 0.5696614384651184, 'Val/mean hd95_metric': 87.35459899902344}
Cheakpoint...
Epoch [26/300] best acc:tensor([0.5213], device='cuda:0'), Now : mean acc: tensor([0.5183], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5183430314064026, 'Val/mean miou_metric': 0.39128053188323975, 'Val/mean f1': 0.5544092655181885, 'Val/mean precision': 0.5399525165557861, 'Val/mean recall': 0.5696614384651184, 'Val/mean hd95_metric': 87.35459899902344}
Epoch [27/300] Training [1/62] Loss: 0.62159 
Epoch [27/300] Training [2/62] Loss: 0.73806 
Epoch [27/300] Training [3/62] Loss: 0.76335 
Epoch [27/300] Training [4/62] Loss: 0.69903 
Epoch [27/300] Training [5/62] Loss: 0.73113 
Epoch [27/300] Training [6/62] Loss: 0.60316 
Epoch [27/300] Training [7/62] Loss: 0.49113 
Epoch [27/300] Training [8/62] Loss: 0.85979 
Epoch [27/300] Training [9/62] Loss: 0.58060 
Epoch [27/300] Training [10/62] Loss: 0.64324 
Epoch [27/300] Training [11/62] Loss: 0.59311 
Epoch [27/300] Training [12/62] Loss: 0.74251 
Epoch [27/300] Training [13/62] Loss: 0.76233 
Epoch [27/300] Training [14/62] Loss: 0.65609 
Epoch [27/300] Training [15/62] Loss: 0.72848 
Epoch [27/300] Training [16/62] Loss: 0.82253 
Epoch [27/300] Training [17/62] Loss: 0.71612 
Epoch [27/300] Training [18/62] Loss: 0.71821 
Epoch [27/300] Training [19/62] Loss: 0.70490 
Epoch [27/300] Training [20/62] Loss: 0.66833 
Epoch [27/300] Training [21/62] Loss: 0.84767 
Epoch [27/300] Training [22/62] Loss: 0.53028 
Epoch [27/300] Training [23/62] Loss: 0.44121 
Epoch [27/300] Training [24/62] Loss: 0.67920 
Epoch [27/300] Training [25/62] Loss: 0.70697 
Epoch [27/300] Training [26/62] Loss: 0.55581 
Epoch [27/300] Training [27/62] Loss: 0.51571 
Epoch [27/300] Training [28/62] Loss: 0.53390 
Epoch [27/300] Training [29/62] Loss: 0.74031 
Epoch [27/300] Training [30/62] Loss: 0.57470 
Epoch [27/300] Training [31/62] Loss: 0.56251 
Epoch [27/300] Training [32/62] Loss: 0.63829 
Epoch [27/300] Training [33/62] Loss: 0.65420 
Epoch [27/300] Training [34/62] Loss: 0.65467 
Epoch [27/300] Training [35/62] Loss: 0.67257 
Epoch [27/300] Training [36/62] Loss: 0.53793 
Epoch [27/300] Training [37/62] Loss: 0.65681 
Epoch [27/300] Training [38/62] Loss: 0.71577 
Epoch [27/300] Training [39/62] Loss: 0.66954 
Epoch [27/300] Training [40/62] Loss: 0.51221 
Epoch [27/300] Training [41/62] Loss: 0.43308 
Epoch [27/300] Training [42/62] Loss: 0.80443 
Epoch [27/300] Training [43/62] Loss: 0.52845 
Epoch [27/300] Training [44/62] Loss: 0.66056 
Epoch [27/300] Training [45/62] Loss: 0.56730 
Epoch [27/300] Training [46/62] Loss: 0.43114 
Epoch [27/300] Training [47/62] Loss: 0.79264 
Epoch [27/300] Training [48/62] Loss: 0.68391 
Epoch [27/300] Training [49/62] Loss: 0.55953 
Epoch [27/300] Training [50/62] Loss: 0.63904 
Epoch [27/300] Training [51/62] Loss: 0.57441 
Epoch [27/300] Training [52/62] Loss: 0.66114 
Epoch [27/300] Training [53/62] Loss: 0.64230 
Epoch [27/300] Training [54/62] Loss: 0.63357 
Epoch [27/300] Training [55/62] Loss: 0.62094 
Epoch [27/300] Training [56/62] Loss: 0.49316 
Epoch [27/300] Training [57/62] Loss: 0.67631 
Epoch [27/300] Training [58/62] Loss: 0.65589 
Epoch [27/300] Training [59/62] Loss: 0.66503 
Epoch [27/300] Training [60/62] Loss: 0.76325 
Epoch [27/300] Training [61/62] Loss: 0.61027 
Epoch [27/300] Training [62/62] Loss: 0.44092 
Epoch [27/300] Training metric {'Train/mean dice_metric': 0.5339710712432861, 'Train/mean miou_metric': 0.40894341468811035, 'Train/mean f1': 0.5677697658538818, 'Train/mean precision': 0.5474006533622742, 'Train/mean recall': 0.5897133350372314, 'Train/mean hd95_metric': 87.81721496582031}
Epoch [27/300] Validation [1/16] Loss: 0.58312  focal_loss 0.11118  dice_loss 0.47194 
Epoch [27/300] Validation [2/16] Loss: 0.67719  focal_loss 0.10612  dice_loss 0.57106 
Epoch [27/300] Validation [3/16] Loss: 0.94356  focal_loss 0.25806  dice_loss 0.68550 
Epoch [27/300] Validation [4/16] Loss: 0.63623  focal_loss 0.10289  dice_loss 0.53333 
Epoch [27/300] Validation [5/16] Loss: 0.61781  focal_loss 0.06802  dice_loss 0.54979 
Epoch [27/300] Validation [6/16] Loss: 0.57746  focal_loss 0.08502  dice_loss 0.49244 
Epoch [27/300] Validation [7/16] Loss: 0.52520  focal_loss 0.07511  dice_loss 0.45009 
Epoch [27/300] Validation [8/16] Loss: 0.63639  focal_loss 0.07285  dice_loss 0.56354 
Epoch [27/300] Validation [9/16] Loss: 0.63783  focal_loss 0.10431  dice_loss 0.53352 
Epoch [27/300] Validation [10/16] Loss: 0.69062  focal_loss 0.12022  dice_loss 0.57040 
Epoch [27/300] Validation [11/16] Loss: 0.52034  focal_loss 0.06288  dice_loss 0.45747 
Epoch [27/300] Validation [12/16] Loss: 0.70468  focal_loss 0.08703  dice_loss 0.61766 
Epoch [27/300] Validation [13/16] Loss: 0.60595  focal_loss 0.08911  dice_loss 0.51684 
Epoch [27/300] Validation [14/16] Loss: 0.80542  focal_loss 0.13138  dice_loss 0.67404 
Epoch [27/300] Validation [15/16] Loss: 0.51217  focal_loss 0.06767  dice_loss 0.44449 
Epoch [27/300] Validation [16/16] Loss: 0.47997  focal_loss 0.09403  dice_loss 0.38594 
Epoch [27/300] Validation metric {'Val/mean dice_metric': 0.5365734696388245, 'Val/mean miou_metric': 0.41016685962677, 'Val/mean f1': 0.5683220624923706, 'Val/mean precision': 0.5322675108909607, 'Val/mean recall': 0.6096161007881165, 'Val/mean hd95_metric': 91.01136779785156}
Cheakpoint...
Epoch [27/300] best acc:tensor([0.5366], device='cuda:0'), Now : mean acc: tensor([0.5366], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5365734696388245, 'Val/mean miou_metric': 0.41016685962677, 'Val/mean f1': 0.5683220624923706, 'Val/mean precision': 0.5322675108909607, 'Val/mean recall': 0.6096161007881165, 'Val/mean hd95_metric': 91.01136779785156}
Epoch [28/300] Training [1/62] Loss: 0.56639 
Epoch [28/300] Training [2/62] Loss: 0.61059 
Epoch [28/300] Training [3/62] Loss: 0.70313 
Epoch [28/300] Training [4/62] Loss: 0.57391 
Epoch [28/300] Training [5/62] Loss: 0.77704 
Epoch [28/300] Training [6/62] Loss: 0.44213 
Epoch [28/300] Training [7/62] Loss: 0.71224 
Epoch [28/300] Training [8/62] Loss: 0.71758 
Epoch [28/300] Training [9/62] Loss: 0.54825 
Epoch [28/300] Training [10/62] Loss: 0.69686 
Epoch [28/300] Training [11/62] Loss: 0.60453 
Epoch [28/300] Training [12/62] Loss: 0.45487 
Epoch [28/300] Training [13/62] Loss: 0.59201 
Epoch [28/300] Training [14/62] Loss: 0.70338 
Epoch [28/300] Training [15/62] Loss: 0.69407 
Epoch [28/300] Training [16/62] Loss: 0.60599 
Epoch [28/300] Training [17/62] Loss: 0.58858 
Epoch [28/300] Training [18/62] Loss: 0.73499 
Epoch [28/300] Training [19/62] Loss: 0.68625 
Epoch [28/300] Training [20/62] Loss: 0.69890 
Epoch [28/300] Training [21/62] Loss: 0.41690 
Epoch [28/300] Training [22/62] Loss: 0.53161 
Epoch [28/300] Training [23/62] Loss: 0.38456 
Epoch [28/300] Training [24/62] Loss: 0.63604 
Epoch [28/300] Training [25/62] Loss: 0.58817 
Epoch [28/300] Training [26/62] Loss: 0.55156 
Epoch [28/300] Training [27/62] Loss: 0.53148 
Epoch [28/300] Training [28/62] Loss: 0.57300 
Epoch [28/300] Training [29/62] Loss: 0.88522 
Epoch [28/300] Training [30/62] Loss: 0.75367 
Epoch [28/300] Training [31/62] Loss: 0.59247 
Epoch [28/300] Training [32/62] Loss: 0.74499 
Epoch [28/300] Training [33/62] Loss: 0.77869 
Epoch [28/300] Training [34/62] Loss: 0.64573 
Epoch [28/300] Training [35/62] Loss: 0.60149 
Epoch [28/300] Training [36/62] Loss: 0.85871 
Epoch [28/300] Training [37/62] Loss: 0.60060 
Epoch [28/300] Training [38/62] Loss: 0.57980 
Epoch [28/300] Training [39/62] Loss: 0.69660 
Epoch [28/300] Training [40/62] Loss: 0.78728 
Epoch [28/300] Training [41/62] Loss: 0.59920 
Epoch [28/300] Training [42/62] Loss: 0.60768 
Epoch [28/300] Training [43/62] Loss: 0.86696 
Epoch [28/300] Training [44/62] Loss: 0.65270 
Epoch [28/300] Training [45/62] Loss: 0.55254 
Epoch [28/300] Training [46/62] Loss: 0.73683 
Epoch [28/300] Training [47/62] Loss: 0.65841 
Epoch [28/300] Training [48/62] Loss: 0.43072 
Epoch [28/300] Training [49/62] Loss: 0.57067 
Epoch [28/300] Training [50/62] Loss: 0.66136 
Epoch [28/300] Training [51/62] Loss: 0.66629 
Epoch [28/300] Training [52/62] Loss: 0.85166 
Epoch [28/300] Training [53/62] Loss: 0.48969 
Epoch [28/300] Training [54/62] Loss: 0.71442 
Epoch [28/300] Training [55/62] Loss: 0.78890 
Epoch [28/300] Training [56/62] Loss: 0.66987 
Epoch [28/300] Training [57/62] Loss: 0.68418 
Epoch [28/300] Training [58/62] Loss: 0.63922 
Epoch [28/300] Training [59/62] Loss: 0.66197 
Epoch [28/300] Training [60/62] Loss: 0.77280 
Epoch [28/300] Training [61/62] Loss: 0.49703 
Epoch [28/300] Training [62/62] Loss: 0.54704 
Epoch [28/300] Training metric {'Train/mean dice_metric': 0.5473060011863708, 'Train/mean miou_metric': 0.42124244570732117, 'Train/mean f1': 0.5746976733207703, 'Train/mean precision': 0.5620680451393127, 'Train/mean recall': 0.5879078507423401, 'Train/mean hd95_metric': 87.04727172851562}
Epoch [28/300] Validation [1/16] Loss: 0.47628  focal_loss 0.10303  dice_loss 0.37324 
Epoch [28/300] Validation [2/16] Loss: 0.64871  focal_loss 0.06156  dice_loss 0.58714 
Epoch [28/300] Validation [3/16] Loss: 0.78649  focal_loss 0.15359  dice_loss 0.63290 
Epoch [28/300] Validation [4/16] Loss: 0.70727  focal_loss 0.14193  dice_loss 0.56535 
Epoch [28/300] Validation [5/16] Loss: 0.50264  focal_loss 0.03491  dice_loss 0.46773 
Epoch [28/300] Validation [6/16] Loss: 0.51301  focal_loss 0.05579  dice_loss 0.45721 
Epoch [28/300] Validation [7/16] Loss: 0.58175  focal_loss 0.07370  dice_loss 0.50805 
Epoch [28/300] Validation [8/16] Loss: 0.69426  focal_loss 0.06755  dice_loss 0.62671 
Epoch [28/300] Validation [9/16] Loss: 0.52451  focal_loss 0.05624  dice_loss 0.46827 
Epoch [28/300] Validation [10/16] Loss: 0.75148  focal_loss 0.14146  dice_loss 0.61002 
Epoch [28/300] Validation [11/16] Loss: 0.54188  focal_loss 0.07323  dice_loss 0.46865 
Epoch [28/300] Validation [12/16] Loss: 0.68091  focal_loss 0.06371  dice_loss 0.61720 
Epoch [28/300] Validation [13/16] Loss: 0.61768  focal_loss 0.10645  dice_loss 0.51123 
Epoch [28/300] Validation [14/16] Loss: 0.76567  focal_loss 0.10764  dice_loss 0.65803 
Epoch [28/300] Validation [15/16] Loss: 0.44727  focal_loss 0.05448  dice_loss 0.39279 
Epoch [28/300] Validation [16/16] Loss: 0.33692  focal_loss 0.04634  dice_loss 0.29058 
Epoch [28/300] Validation metric {'Val/mean dice_metric': 0.5503208637237549, 'Val/mean miou_metric': 0.42463698983192444, 'Val/mean f1': 0.5766284465789795, 'Val/mean precision': 0.5570740699768066, 'Val/mean recall': 0.5976055264472961, 'Val/mean hd95_metric': 87.28733825683594}
Cheakpoint...
Epoch [28/300] best acc:tensor([0.5503], device='cuda:0'), Now : mean acc: tensor([0.5503], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5503208637237549, 'Val/mean miou_metric': 0.42463698983192444, 'Val/mean f1': 0.5766284465789795, 'Val/mean precision': 0.5570740699768066, 'Val/mean recall': 0.5976055264472961, 'Val/mean hd95_metric': 87.28733825683594}
Epoch [29/300] Training [1/62] Loss: 0.53732 
Epoch [29/300] Training [2/62] Loss: 0.67593 
Epoch [29/300] Training [3/62] Loss: 0.68016 
Epoch [29/300] Training [4/62] Loss: 0.44970 
Epoch [29/300] Training [5/62] Loss: 0.48852 
Epoch [29/300] Training [6/62] Loss: 0.56807 
Epoch [29/300] Training [7/62] Loss: 0.58799 
Epoch [29/300] Training [8/62] Loss: 0.82333 
Epoch [29/300] Training [9/62] Loss: 0.57455 
Epoch [29/300] Training [10/62] Loss: 0.49709 
Epoch [29/300] Training [11/62] Loss: 0.74829 
Epoch [29/300] Training [12/62] Loss: 0.66250 
Epoch [29/300] Training [13/62] Loss: 0.48899 
Epoch [29/300] Training [14/62] Loss: 0.58157 
Epoch [29/300] Training [15/62] Loss: 0.74430 
Epoch [29/300] Training [16/62] Loss: 0.70268 
Epoch [29/300] Training [17/62] Loss: 0.65901 
Epoch [29/300] Training [18/62] Loss: 0.49731 
Epoch [29/300] Training [19/62] Loss: 0.49072 
Epoch [29/300] Training [20/62] Loss: 0.37265 
Epoch [29/300] Training [21/62] Loss: 0.60442 
Epoch [29/300] Training [22/62] Loss: 0.41318 
Epoch [29/300] Training [23/62] Loss: 0.75688 
Epoch [29/300] Training [24/62] Loss: 0.51869 
Epoch [29/300] Training [25/62] Loss: 0.53612 
Epoch [29/300] Training [26/62] Loss: 0.60023 
Epoch [29/300] Training [27/62] Loss: 0.53637 
Epoch [29/300] Training [28/62] Loss: 0.89569 
Epoch [29/300] Training [29/62] Loss: 0.57585 
Epoch [29/300] Training [30/62] Loss: 0.61799 
Epoch [29/300] Training [31/62] Loss: 0.41157 
Epoch [29/300] Training [32/62] Loss: 0.60546 
Epoch [29/300] Training [33/62] Loss: 0.58605 
Epoch [29/300] Training [34/62] Loss: 0.68188 
Epoch [29/300] Training [35/62] Loss: 0.63001 
Epoch [29/300] Training [36/62] Loss: 0.64875 
Epoch [29/300] Training [37/62] Loss: 0.59793 
Epoch [29/300] Training [38/62] Loss: 0.81262 
Epoch [29/300] Training [39/62] Loss: 0.91136 
Epoch [29/300] Training [40/62] Loss: 0.50176 
Epoch [29/300] Training [41/62] Loss: 0.70103 
Epoch [29/300] Training [42/62] Loss: 0.55701 
Epoch [29/300] Training [43/62] Loss: 0.70266 
Epoch [29/300] Training [44/62] Loss: 0.52257 
Epoch [29/300] Training [45/62] Loss: 0.57834 
Epoch [29/300] Training [46/62] Loss: 0.76442 
Epoch [29/300] Training [47/62] Loss: 0.76120 
Epoch [29/300] Training [48/62] Loss: 0.80196 
Epoch [29/300] Training [49/62] Loss: 0.75399 
Epoch [29/300] Training [50/62] Loss: 0.82101 
Epoch [29/300] Training [51/62] Loss: 0.65751 
Epoch [29/300] Training [52/62] Loss: 0.47330 
Epoch [29/300] Training [53/62] Loss: 0.77636 
Epoch [29/300] Training [54/62] Loss: 0.58573 
Epoch [29/300] Training [55/62] Loss: 0.55198 
Epoch [29/300] Training [56/62] Loss: 0.55262 
Epoch [29/300] Training [57/62] Loss: 0.73301 
Epoch [29/300] Training [58/62] Loss: 0.55754 
Epoch [29/300] Training [59/62] Loss: 0.49804 
Epoch [29/300] Training [60/62] Loss: 0.46492 
Epoch [29/300] Training [61/62] Loss: 0.52328 
Epoch [29/300] Training [62/62] Loss: 0.22238 
Epoch [29/300] Training metric {'Train/mean dice_metric': 0.5608916282653809, 'Train/mean miou_metric': 0.4362551271915436, 'Train/mean f1': 0.5945574045181274, 'Train/mean precision': 0.5903614163398743, 'Train/mean recall': 0.5988134741783142, 'Train/mean hd95_metric': 85.24500274658203}
Epoch [29/300] Validation [1/16] Loss: 0.40745  focal_loss 0.10626  dice_loss 0.30119 
Epoch [29/300] Validation [2/16] Loss: 0.52838  focal_loss 0.10993  dice_loss 0.41845 
Epoch [29/300] Validation [3/16] Loss: 0.73028  focal_loss 0.20728  dice_loss 0.52300 
Epoch [29/300] Validation [4/16] Loss: 0.65612  focal_loss 0.17381  dice_loss 0.48231 
Epoch [29/300] Validation [5/16] Loss: 0.46993  focal_loss 0.05632  dice_loss 0.41362 
Epoch [29/300] Validation [6/16] Loss: 0.49860  focal_loss 0.08645  dice_loss 0.41215 
Epoch [29/300] Validation [7/16] Loss: 0.46818  focal_loss 0.10832  dice_loss 0.35986 
Epoch [29/300] Validation [8/16] Loss: 0.63379  focal_loss 0.09868  dice_loss 0.53511 
Epoch [29/300] Validation [9/16] Loss: 0.48046  focal_loss 0.10097  dice_loss 0.37950 
Epoch [29/300] Validation [10/16] Loss: 0.76188  focal_loss 0.18495  dice_loss 0.57692 
Epoch [29/300] Validation [11/16] Loss: 0.51802  focal_loss 0.10008  dice_loss 0.41794 
Epoch [29/300] Validation [12/16] Loss: 0.63884  focal_loss 0.10498  dice_loss 0.53386 
Epoch [29/300] Validation [13/16] Loss: 0.56056  focal_loss 0.14116  dice_loss 0.41940 
Epoch [29/300] Validation [14/16] Loss: 0.72994  focal_loss 0.13641  dice_loss 0.59353 
Epoch [29/300] Validation [15/16] Loss: 0.52436  focal_loss 0.12546  dice_loss 0.39891 
Epoch [29/300] Validation [16/16] Loss: 0.31986  focal_loss 0.07962  dice_loss 0.24024 
Epoch [29/300] Validation metric {'Val/mean dice_metric': 0.5698174834251404, 'Val/mean miou_metric': 0.44615113735198975, 'Val/mean f1': 0.5966238975524902, 'Val/mean precision': 0.5888304114341736, 'Val/mean recall': 0.6046265363693237, 'Val/mean hd95_metric': 84.1904067993164}
Cheakpoint...
Epoch [29/300] best acc:tensor([0.5698], device='cuda:0'), Now : mean acc: tensor([0.5698], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5698174834251404, 'Val/mean miou_metric': 0.44615113735198975, 'Val/mean f1': 0.5966238975524902, 'Val/mean precision': 0.5888304114341736, 'Val/mean recall': 0.6046265363693237, 'Val/mean hd95_metric': 84.1904067993164}
Epoch [30/300] Training [1/62] Loss: 0.44037 
Epoch [30/300] Training [2/62] Loss: 0.42703 
Epoch [30/300] Training [3/62] Loss: 0.73911 
Epoch [30/300] Training [4/62] Loss: 0.53838 
Epoch [30/300] Training [5/62] Loss: 0.67715 
Epoch [30/300] Training [6/62] Loss: 0.49470 
Epoch [30/300] Training [7/62] Loss: 0.55597 
Epoch [30/300] Training [8/62] Loss: 0.69565 
Epoch [30/300] Training [9/62] Loss: 0.35381 
Epoch [30/300] Training [10/62] Loss: 0.50344 
Epoch [30/300] Training [11/62] Loss: 0.61627 
Epoch [30/300] Training [12/62] Loss: 0.57062 
Epoch [30/300] Training [13/62] Loss: 0.54249 
Epoch [30/300] Training [14/62] Loss: 0.63404 
Epoch [30/300] Training [15/62] Loss: 0.51247 
Epoch [30/300] Training [16/62] Loss: 0.57488 
Epoch [30/300] Training [17/62] Loss: 0.61362 
Epoch [30/300] Training [18/62] Loss: 0.68094 
Epoch [30/300] Training [19/62] Loss: 0.34311 
Epoch [30/300] Training [20/62] Loss: 0.45573 
Epoch [30/300] Training [21/62] Loss: 0.52459 
Epoch [30/300] Training [22/62] Loss: 0.65107 
Epoch [30/300] Training [23/62] Loss: 0.89360 
Epoch [30/300] Training [24/62] Loss: 0.61338 
Epoch [30/300] Training [25/62] Loss: 0.56350 
Epoch [30/300] Training [26/62] Loss: 0.55384 
Epoch [30/300] Training [27/62] Loss: 0.64294 
Epoch [30/300] Training [28/62] Loss: 0.55584 
Epoch [30/300] Training [29/62] Loss: 0.79164 
Epoch [30/300] Training [30/62] Loss: 0.49809 
Epoch [30/300] Training [31/62] Loss: 0.58612 
Epoch [30/300] Training [32/62] Loss: 0.51718 
Epoch [30/300] Training [33/62] Loss: 0.57969 
Epoch [30/300] Training [34/62] Loss: 0.50035 
Epoch [30/300] Training [35/62] Loss: 0.47266 
Epoch [30/300] Training [36/62] Loss: 0.50488 
Epoch [30/300] Training [37/62] Loss: 0.47990 
Epoch [30/300] Training [38/62] Loss: 0.64825 
Epoch [30/300] Training [39/62] Loss: 0.57334 
Epoch [30/300] Training [40/62] Loss: 0.50455 
Epoch [30/300] Training [41/62] Loss: 0.78580 
Epoch [30/300] Training [42/62] Loss: 1.07118 
Epoch [30/300] Training [43/62] Loss: 0.54482 
Epoch [30/300] Training [44/62] Loss: 0.57873 
Epoch [30/300] Training [45/62] Loss: 0.59493 
Epoch [30/300] Training [46/62] Loss: 0.52057 
Epoch [30/300] Training [47/62] Loss: 0.60579 
Epoch [30/300] Training [48/62] Loss: 0.58016 
Epoch [30/300] Training [49/62] Loss: 0.66063 
Epoch [30/300] Training [50/62] Loss: 0.74866 
Epoch [30/300] Training [51/62] Loss: 0.54519 
Epoch [30/300] Training [52/62] Loss: 0.34644 
Epoch [30/300] Training [53/62] Loss: 0.63900 
Epoch [30/300] Training [54/62] Loss: 0.90212 
Epoch [30/300] Training [55/62] Loss: 0.78864 
Epoch [30/300] Training [56/62] Loss: 0.55352 
Epoch [30/300] Training [57/62] Loss: 0.59101 
Epoch [30/300] Training [58/62] Loss: 0.59785 
Epoch [30/300] Training [59/62] Loss: 0.79960 
Epoch [30/300] Training [60/62] Loss: 0.57386 
Epoch [30/300] Training [61/62] Loss: 0.56339 
Epoch [30/300] Training [62/62] Loss: 0.37967 
Epoch [30/300] Training metric {'Train/mean dice_metric': 0.5891203284263611, 'Train/mean miou_metric': 0.46177616715431213, 'Train/mean f1': 0.6142571568489075, 'Train/mean precision': 0.6078804135322571, 'Train/mean recall': 0.6207690238952637, 'Train/mean hd95_metric': 82.20427703857422}
Epoch [30/300] Validation [1/16] Loss: 0.46363  focal_loss 0.08074  dice_loss 0.38289 
Epoch [30/300] Validation [2/16] Loss: 0.64594  focal_loss 0.08459  dice_loss 0.56135 
Epoch [30/300] Validation [3/16] Loss: 0.68913  focal_loss 0.12045  dice_loss 0.56869 
Epoch [30/300] Validation [4/16] Loss: 0.65433  focal_loss 0.12876  dice_loss 0.52557 
Epoch [30/300] Validation [5/16] Loss: 0.60784  focal_loss 0.05266  dice_loss 0.55518 
Epoch [30/300] Validation [6/16] Loss: 0.53478  focal_loss 0.08191  dice_loss 0.45287 
Epoch [30/300] Validation [7/16] Loss: 0.65102  focal_loss 0.10781  dice_loss 0.54321 
Epoch [30/300] Validation [8/16] Loss: 0.67114  focal_loss 0.09899  dice_loss 0.57215 
Epoch [30/300] Validation [9/16] Loss: 0.50450  focal_loss 0.06388  dice_loss 0.44063 
Epoch [30/300] Validation [10/16] Loss: 0.60209  focal_loss 0.10784  dice_loss 0.49425 
Epoch [30/300] Validation [11/16] Loss: 0.55194  focal_loss 0.08708  dice_loss 0.46486 
Epoch [30/300] Validation [12/16] Loss: 0.65614  focal_loss 0.08109  dice_loss 0.57505 
Epoch [30/300] Validation [13/16] Loss: 0.63562  focal_loss 0.13219  dice_loss 0.50343 
Epoch [30/300] Validation [14/16] Loss: 0.77593  focal_loss 0.14600  dice_loss 0.62993 
Epoch [30/300] Validation [15/16] Loss: 0.52087  focal_loss 0.07807  dice_loss 0.44280 
Epoch [30/300] Validation [16/16] Loss: 0.38334  focal_loss 0.06642  dice_loss 0.31692 
Epoch [30/300] Validation metric {'Val/mean dice_metric': 0.5859277248382568, 'Val/mean miou_metric': 0.4569995403289795, 'Val/mean f1': 0.6090883612632751, 'Val/mean precision': 0.5901168584823608, 'Val/mean recall': 0.6293200850486755, 'Val/mean hd95_metric': 86.2860336303711}
Cheakpoint...
Epoch [30/300] best acc:tensor([0.5859], device='cuda:0'), Now : mean acc: tensor([0.5859], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5859277248382568, 'Val/mean miou_metric': 0.4569995403289795, 'Val/mean f1': 0.6090883612632751, 'Val/mean precision': 0.5901168584823608, 'Val/mean recall': 0.6293200850486755, 'Val/mean hd95_metric': 86.2860336303711}
Epoch [31/300] Training [1/62] Loss: 0.60760 
Epoch [31/300] Training [2/62] Loss: 0.62087 
Epoch [31/300] Training [3/62] Loss: 0.71033 
Epoch [31/300] Training [4/62] Loss: 0.64527 
Epoch [31/300] Training [5/62] Loss: 0.46844 
Epoch [31/300] Training [6/62] Loss: 0.54898 
Epoch [31/300] Training [7/62] Loss: 0.92229 
Epoch [31/300] Training [8/62] Loss: 0.63822 
Epoch [31/300] Training [9/62] Loss: 0.71773 
Epoch [31/300] Training [10/62] Loss: 0.61893 
Epoch [31/300] Training [11/62] Loss: 0.63452 
Epoch [31/300] Training [12/62] Loss: 0.70538 
Epoch [31/300] Training [13/62] Loss: 0.61347 
Epoch [31/300] Training [14/62] Loss: 0.53203 
Epoch [31/300] Training [15/62] Loss: 0.56500 
Epoch [31/300] Training [16/62] Loss: 0.67393 
Epoch [31/300] Training [17/62] Loss: 0.61218 
Epoch [31/300] Training [18/62] Loss: 0.62795 
Epoch [31/300] Training [19/62] Loss: 0.55389 
Epoch [31/300] Training [20/62] Loss: 0.62218 
Epoch [31/300] Training [21/62] Loss: 0.59592 
Epoch [31/300] Training [22/62] Loss: 0.70701 
Epoch [31/300] Training [23/62] Loss: 0.62893 
Epoch [31/300] Training [24/62] Loss: 0.76351 
Epoch [31/300] Training [25/62] Loss: 0.52769 
Epoch [31/300] Training [26/62] Loss: 0.58999 
Epoch [31/300] Training [27/62] Loss: 0.32652 
Epoch [31/300] Training [28/62] Loss: 0.64154 
Epoch [31/300] Training [29/62] Loss: 0.71013 
Epoch [31/300] Training [30/62] Loss: 0.54506 
Epoch [31/300] Training [31/62] Loss: 0.49721 
Epoch [31/300] Training [32/62] Loss: 0.58293 
Epoch [31/300] Training [33/62] Loss: 0.64458 
Epoch [31/300] Training [34/62] Loss: 0.66264 
Epoch [31/300] Training [35/62] Loss: 0.58014 
Epoch [31/300] Training [36/62] Loss: 0.53637 
Epoch [31/300] Training [37/62] Loss: 0.56546 
Epoch [31/300] Training [38/62] Loss: 0.44278 
Epoch [31/300] Training [39/62] Loss: 0.75709 
Epoch [31/300] Training [40/62] Loss: 0.55786 
Epoch [31/300] Training [41/62] Loss: 0.59827 
Epoch [31/300] Training [42/62] Loss: 0.64821 
Epoch [31/300] Training [43/62] Loss: 0.63559 
Epoch [31/300] Training [44/62] Loss: 0.70033 
Epoch [31/300] Training [45/62] Loss: 0.45866 
Epoch [31/300] Training [46/62] Loss: 0.63191 
Epoch [31/300] Training [47/62] Loss: 0.64041 
Epoch [31/300] Training [48/62] Loss: 0.55158 
Epoch [31/300] Training [49/62] Loss: 0.45819 
Epoch [31/300] Training [50/62] Loss: 0.56990 
Epoch [31/300] Training [51/62] Loss: 0.57934 
Epoch [31/300] Training [52/62] Loss: 0.41894 
Epoch [31/300] Training [53/62] Loss: 0.54761 
Epoch [31/300] Training [54/62] Loss: 0.55986 
Epoch [31/300] Training [55/62] Loss: 0.51503 
Epoch [31/300] Training [56/62] Loss: 0.64968 
Epoch [31/300] Training [57/62] Loss: 0.59559 
Epoch [31/300] Training [58/62] Loss: 0.43501 
Epoch [31/300] Training [59/62] Loss: 0.54360 
Epoch [31/300] Training [60/62] Loss: 0.61871 
Epoch [31/300] Training [61/62] Loss: 0.46744 
Epoch [31/300] Training [62/62] Loss: 0.36694 
Epoch [31/300] Training metric {'Train/mean dice_metric': 0.5804961323738098, 'Train/mean miou_metric': 0.45627135038375854, 'Train/mean f1': 0.6126869916915894, 'Train/mean precision': 0.5970545411109924, 'Train/mean recall': 0.6291601061820984, 'Train/mean hd95_metric': 85.34020233154297}
Epoch [31/300] Validation [1/16] Loss: 0.45266  focal_loss 0.13844  dice_loss 0.31422 
Epoch [31/300] Validation [2/16] Loss: 0.51447  focal_loss 0.08842  dice_loss 0.42605 
Epoch [31/300] Validation [3/16] Loss: 0.82122  focal_loss 0.21694  dice_loss 0.60428 
Epoch [31/300] Validation [4/16] Loss: 0.56185  focal_loss 0.10765  dice_loss 0.45420 
Epoch [31/300] Validation [5/16] Loss: 0.50702  focal_loss 0.06147  dice_loss 0.44554 
Epoch [31/300] Validation [6/16] Loss: 0.42960  focal_loss 0.05794  dice_loss 0.37166 
Epoch [31/300] Validation [7/16] Loss: 0.46228  focal_loss 0.06492  dice_loss 0.39736 
Epoch [31/300] Validation [8/16] Loss: 0.71424  focal_loss 0.11082  dice_loss 0.60342 
Epoch [31/300] Validation [9/16] Loss: 0.63540  focal_loss 0.14923  dice_loss 0.48617 
Epoch [31/300] Validation [10/16] Loss: 0.67489  focal_loss 0.13481  dice_loss 0.54008 
Epoch [31/300] Validation [11/16] Loss: 0.48614  focal_loss 0.08284  dice_loss 0.40330 
Epoch [31/300] Validation [12/16] Loss: 0.63017  focal_loss 0.07495  dice_loss 0.55522 
Epoch [31/300] Validation [13/16] Loss: 0.56190  focal_loss 0.10549  dice_loss 0.45641 
Epoch [31/300] Validation [14/16] Loss: 0.77452  focal_loss 0.12365  dice_loss 0.65086 
Epoch [31/300] Validation [15/16] Loss: 0.53631  focal_loss 0.12197  dice_loss 0.41434 
Epoch [31/300] Validation [16/16] Loss: 0.27533  focal_loss 0.03741  dice_loss 0.23792 
Epoch [31/300] Validation metric {'Val/mean dice_metric': 0.5835141539573669, 'Val/mean miou_metric': 0.4597114026546478, 'Val/mean f1': 0.6083342432975769, 'Val/mean precision': 0.5875949859619141, 'Val/mean recall': 0.6305911540985107, 'Val/mean hd95_metric': 86.68981170654297}
Cheakpoint...
Epoch [31/300] best acc:tensor([0.5859], device='cuda:0'), Now : mean acc: tensor([0.5835], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5835141539573669, 'Val/mean miou_metric': 0.4597114026546478, 'Val/mean f1': 0.6083342432975769, 'Val/mean precision': 0.5875949859619141, 'Val/mean recall': 0.6305911540985107, 'Val/mean hd95_metric': 86.68981170654297}
Epoch [32/300] Training [1/62] Loss: 0.80447 
Epoch [32/300] Training [2/62] Loss: 0.51478 
Epoch [32/300] Training [3/62] Loss: 0.65765 
Epoch [32/300] Training [4/62] Loss: 0.53977 
Epoch [32/300] Training [5/62] Loss: 0.54872 
Epoch [32/300] Training [6/62] Loss: 0.72038 
Epoch [32/300] Training [7/62] Loss: 0.72690 
Epoch [32/300] Training [8/62] Loss: 0.55505 
Epoch [32/300] Training [9/62] Loss: 0.47521 
Epoch [32/300] Training [10/62] Loss: 0.43716 
Epoch [32/300] Training [11/62] Loss: 0.66267 
Epoch [32/300] Training [12/62] Loss: 0.57370 
Epoch [32/300] Training [13/62] Loss: 0.75549 
Epoch [32/300] Training [14/62] Loss: 0.38741 
Epoch [32/300] Training [15/62] Loss: 0.50165 
Epoch [32/300] Training [16/62] Loss: 0.47490 
Epoch [32/300] Training [17/62] Loss: 0.49841 
Epoch [32/300] Training [18/62] Loss: 0.52785 
Epoch [32/300] Training [19/62] Loss: 0.67297 
Epoch [32/300] Training [20/62] Loss: 0.57403 
Epoch [32/300] Training [21/62] Loss: 0.57792 
Epoch [32/300] Training [22/62] Loss: 0.50543 
Epoch [32/300] Training [23/62] Loss: 0.83888 
Epoch [32/300] Training [24/62] Loss: 0.52491 
Epoch [32/300] Training [25/62] Loss: 0.52055 
Epoch [32/300] Training [26/62] Loss: 0.54323 
Epoch [32/300] Training [27/62] Loss: 0.50039 
Epoch [32/300] Training [28/62] Loss: 0.38920 
Epoch [32/300] Training [29/62] Loss: 0.70442 
Epoch [32/300] Training [30/62] Loss: 0.34348 
Epoch [32/300] Training [31/62] Loss: 0.57947 
Epoch [32/300] Training [32/62] Loss: 0.42478 
Epoch [32/300] Training [33/62] Loss: 0.68299 
Epoch [32/300] Training [34/62] Loss: 0.50095 
Epoch [32/300] Training [35/62] Loss: 0.61084 
Epoch [32/300] Training [36/62] Loss: 0.55340 
Epoch [32/300] Training [37/62] Loss: 0.58309 
Epoch [32/300] Training [38/62] Loss: 0.51497 
Epoch [32/300] Training [39/62] Loss: 0.69264 
Epoch [32/300] Training [40/62] Loss: 0.47631 
Epoch [32/300] Training [41/62] Loss: 0.58961 
Epoch [32/300] Training [42/62] Loss: 0.43829 
Epoch [32/300] Training [43/62] Loss: 0.50911 
Epoch [32/300] Training [44/62] Loss: 0.54870 
Epoch [32/300] Training [45/62] Loss: 0.58394 
Epoch [32/300] Training [46/62] Loss: 0.60321 
Epoch [32/300] Training [47/62] Loss: 0.49878 
Epoch [32/300] Training [48/62] Loss: 0.60252 
Epoch [32/300] Training [49/62] Loss: 0.26868 
Epoch [32/300] Training [50/62] Loss: 0.56363 
Epoch [32/300] Training [51/62] Loss: 0.66514 
Epoch [32/300] Training [52/62] Loss: 0.46921 
Epoch [32/300] Training [53/62] Loss: 0.72867 
Epoch [32/300] Training [54/62] Loss: 0.48405 
Epoch [32/300] Training [55/62] Loss: 0.64579 
Epoch [32/300] Training [56/62] Loss: 0.63416 
Epoch [32/300] Training [57/62] Loss: 0.75651 
Epoch [32/300] Training [58/62] Loss: 0.57190 
Epoch [32/300] Training [59/62] Loss: 0.58434 
Epoch [32/300] Training [60/62] Loss: 0.56397 
Epoch [32/300] Training [61/62] Loss: 0.70318 
Epoch [32/300] Training [62/62] Loss: 0.53250 
Epoch [32/300] Training metric {'Train/mean dice_metric': 0.6062816977500916, 'Train/mean miou_metric': 0.4812975525856018, 'Train/mean f1': 0.6298515200614929, 'Train/mean precision': 0.6266951560974121, 'Train/mean recall': 0.6330398917198181, 'Train/mean hd95_metric': 76.78501892089844}
Epoch [32/300] Validation [1/16] Loss: 0.45779  focal_loss 0.09922  dice_loss 0.35857 
Epoch [32/300] Validation [2/16] Loss: 0.72181  focal_loss 0.11429  dice_loss 0.60752 
Epoch [32/300] Validation [3/16] Loss: 0.81352  focal_loss 0.20214  dice_loss 0.61138 
Epoch [32/300] Validation [4/16] Loss: 0.64683  focal_loss 0.13347  dice_loss 0.51336 
Epoch [32/300] Validation [5/16] Loss: 0.57266  focal_loss 0.07435  dice_loss 0.49831 
Epoch [32/300] Validation [6/16] Loss: 0.52367  focal_loss 0.06685  dice_loss 0.45682 
Epoch [32/300] Validation [7/16] Loss: 0.56813  focal_loss 0.09191  dice_loss 0.47622 
Epoch [32/300] Validation [8/16] Loss: 0.79487  focal_loss 0.13597  dice_loss 0.65890 
Epoch [32/300] Validation [9/16] Loss: 0.55586  focal_loss 0.08683  dice_loss 0.46903 
Epoch [32/300] Validation [10/16] Loss: 0.60812  focal_loss 0.08604  dice_loss 0.52209 
Epoch [32/300] Validation [11/16] Loss: 0.53643  focal_loss 0.08393  dice_loss 0.45250 
Epoch [32/300] Validation [12/16] Loss: 0.72826  focal_loss 0.11277  dice_loss 0.61549 
Epoch [32/300] Validation [13/16] Loss: 0.67263  focal_loss 0.12379  dice_loss 0.54884 
Epoch [32/300] Validation [14/16] Loss: 0.80778  focal_loss 0.16058  dice_loss 0.64721 
Epoch [32/300] Validation [15/16] Loss: 0.46734  focal_loss 0.07587  dice_loss 0.39147 
Epoch [32/300] Validation [16/16] Loss: 0.36760  focal_loss 0.04595  dice_loss 0.32165 
Epoch [32/300] Validation metric {'Val/mean dice_metric': 0.5964967608451843, 'Val/mean miou_metric': 0.4713226556777954, 'Val/mean f1': 0.6186702847480774, 'Val/mean precision': 0.5817995667457581, 'Val/mean recall': 0.6605304479598999, 'Val/mean hd95_metric': 79.79682159423828}
Cheakpoint...
Epoch [32/300] best acc:tensor([0.5965], device='cuda:0'), Now : mean acc: tensor([0.5965], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.5964967608451843, 'Val/mean miou_metric': 0.4713226556777954, 'Val/mean f1': 0.6186702847480774, 'Val/mean precision': 0.5817995667457581, 'Val/mean recall': 0.6605304479598999, 'Val/mean hd95_metric': 79.79682159423828}
Epoch [33/300] Training [1/62] Loss: 0.78165 
Epoch [33/300] Training [2/62] Loss: 0.60968 
Epoch [33/300] Training [3/62] Loss: 0.67867 
Epoch [33/300] Training [4/62] Loss: 0.68198 
Epoch [33/300] Training [5/62] Loss: 0.56477 
Epoch [33/300] Training [6/62] Loss: 0.60338 
Epoch [33/300] Training [7/62] Loss: 0.67046 
Epoch [33/300] Training [8/62] Loss: 0.45210 
Epoch [33/300] Training [9/62] Loss: 0.53773 
Epoch [33/300] Training [10/62] Loss: 0.54941 
Epoch [33/300] Training [11/62] Loss: 0.45981 
Epoch [33/300] Training [12/62] Loss: 0.63835 
Epoch [33/300] Training [13/62] Loss: 0.63617 
Epoch [33/300] Training [14/62] Loss: 0.50417 
Epoch [33/300] Training [15/62] Loss: 0.53509 
Epoch [33/300] Training [16/62] Loss: 0.62048 
Epoch [33/300] Training [17/62] Loss: 0.45372 
Epoch [33/300] Training [18/62] Loss: 0.59458 
Epoch [33/300] Training [19/62] Loss: 0.55503 
Epoch [33/300] Training [20/62] Loss: 0.60520 
Epoch [33/300] Training [21/62] Loss: 0.45774 
Epoch [33/300] Training [22/62] Loss: 0.53342 
Epoch [33/300] Training [23/62] Loss: 0.31298 
Epoch [33/300] Training [24/62] Loss: 0.57595 
Epoch [33/300] Training [25/62] Loss: 0.63023 
Epoch [33/300] Training [26/62] Loss: 0.58915 
Epoch [33/300] Training [27/62] Loss: 0.60427 
Epoch [33/300] Training [28/62] Loss: 0.53362 
Epoch [33/300] Training [29/62] Loss: 0.51180 
Epoch [33/300] Training [30/62] Loss: 0.68021 
Epoch [33/300] Training [31/62] Loss: 0.61625 
Epoch [33/300] Training [32/62] Loss: 0.64420 
Epoch [33/300] Training [33/62] Loss: 0.61939 
Epoch [33/300] Training [34/62] Loss: 0.64240 
Epoch [33/300] Training [35/62] Loss: 0.54402 
Epoch [33/300] Training [36/62] Loss: 0.70053 
Epoch [33/300] Training [37/62] Loss: 0.38999 
Epoch [33/300] Training [38/62] Loss: 0.49558 
Epoch [33/300] Training [39/62] Loss: 0.51453 
Epoch [33/300] Training [40/62] Loss: 0.32086 
Epoch [33/300] Training [41/62] Loss: 0.39393 
Epoch [33/300] Training [42/62] Loss: 0.37476 
Epoch [33/300] Training [43/62] Loss: 0.80094 
Epoch [33/300] Training [44/62] Loss: 1.21615 
Epoch [33/300] Training [45/62] Loss: 0.52962 
Epoch [33/300] Training [46/62] Loss: 0.61367 
Epoch [33/300] Training [47/62] Loss: 0.44702 
Epoch [33/300] Training [48/62] Loss: 0.50012 
Epoch [33/300] Training [49/62] Loss: 0.61420 
Epoch [33/300] Training [50/62] Loss: 0.43669 
Epoch [33/300] Training [51/62] Loss: 0.49818 
Epoch [33/300] Training [52/62] Loss: 0.71830 
Epoch [33/300] Training [53/62] Loss: 0.34681 
Epoch [33/300] Training [54/62] Loss: 0.50274 
Epoch [33/300] Training [55/62] Loss: 0.73594 
Epoch [33/300] Training [56/62] Loss: 0.46928 
Epoch [33/300] Training [57/62] Loss: 0.53559 
Epoch [33/300] Training [58/62] Loss: 0.41033 
Epoch [33/300] Training [59/62] Loss: 0.48870 
Epoch [33/300] Training [60/62] Loss: 0.68503 
Epoch [33/300] Training [61/62] Loss: 0.43283 
Epoch [33/300] Training [62/62] Loss: 0.53621 
Epoch [33/300] Training metric {'Train/mean dice_metric': 0.6097782254219055, 'Train/mean miou_metric': 0.48397502303123474, 'Train/mean f1': 0.6303916573524475, 'Train/mean precision': 0.6174664497375488, 'Train/mean recall': 0.6438695788383484, 'Train/mean hd95_metric': 77.51630401611328}
Epoch [33/300] Validation [1/16] Loss: 0.54303  focal_loss 0.17964  dice_loss 0.36339 
Epoch [33/300] Validation [2/16] Loss: 0.58014  focal_loss 0.09383  dice_loss 0.48631 
Epoch [33/300] Validation [3/16] Loss: 0.64207  focal_loss 0.11911  dice_loss 0.52296 
Epoch [33/300] Validation [4/16] Loss: 0.51522  focal_loss 0.11775  dice_loss 0.39748 
Epoch [33/300] Validation [5/16] Loss: 0.53347  focal_loss 0.08184  dice_loss 0.45163 
Epoch [33/300] Validation [6/16] Loss: 0.46369  focal_loss 0.09156  dice_loss 0.37213 
Epoch [33/300] Validation [7/16] Loss: 0.42274  focal_loss 0.06432  dice_loss 0.35841 
Epoch [33/300] Validation [8/16] Loss: 0.58332  focal_loss 0.07309  dice_loss 0.51023 
Epoch [33/300] Validation [9/16] Loss: 0.35084  focal_loss 0.05275  dice_loss 0.29808 
Epoch [33/300] Validation [10/16] Loss: 0.50028  focal_loss 0.07763  dice_loss 0.42265 
Epoch [33/300] Validation [11/16] Loss: 0.45503  focal_loss 0.08447  dice_loss 0.37056 
Epoch [33/300] Validation [12/16] Loss: 0.67753  focal_loss 0.11174  dice_loss 0.56580 
Epoch [33/300] Validation [13/16] Loss: 0.49354  focal_loss 0.09287  dice_loss 0.40067 
Epoch [33/300] Validation [14/16] Loss: 0.73736  focal_loss 0.12551  dice_loss 0.61185 
Epoch [33/300] Validation [15/16] Loss: 0.36400  focal_loss 0.04504  dice_loss 0.31896 
Epoch [33/300] Validation [16/16] Loss: 0.27602  focal_loss 0.03215  dice_loss 0.24387 
Epoch [33/300] Validation metric {'Val/mean dice_metric': 0.6153162717819214, 'Val/mean miou_metric': 0.4908686578273773, 'Val/mean f1': 0.6346352696418762, 'Val/mean precision': 0.6101528406143188, 'Val/mean recall': 0.6611645221710205, 'Val/mean hd95_metric': 77.42921447753906}
Cheakpoint...
Epoch [33/300] best acc:tensor([0.6153], device='cuda:0'), Now : mean acc: tensor([0.6153], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6153162717819214, 'Val/mean miou_metric': 0.4908686578273773, 'Val/mean f1': 0.6346352696418762, 'Val/mean precision': 0.6101528406143188, 'Val/mean recall': 0.6611645221710205, 'Val/mean hd95_metric': 77.42921447753906}
Epoch [34/300] Training [1/62] Loss: 0.59245 
Epoch [34/300] Training [2/62] Loss: 0.75095 
Epoch [34/300] Training [3/62] Loss: 0.43559 
Epoch [34/300] Training [4/62] Loss: 0.41429 
Epoch [34/300] Training [5/62] Loss: 0.62995 
Epoch [34/300] Training [6/62] Loss: 0.40414 
Epoch [34/300] Training [7/62] Loss: 0.50583 
Epoch [34/300] Training [8/62] Loss: 0.32829 
Epoch [34/300] Training [9/62] Loss: 0.57045 
Epoch [34/300] Training [10/62] Loss: 0.36854 
Epoch [34/300] Training [11/62] Loss: 0.50877 
Epoch [34/300] Training [12/62] Loss: 0.42193 
Epoch [34/300] Training [13/62] Loss: 0.65409 
Epoch [34/300] Training [14/62] Loss: 0.73776 
Epoch [34/300] Training [15/62] Loss: 0.45435 
Epoch [34/300] Training [16/62] Loss: 0.61578 
Epoch [34/300] Training [17/62] Loss: 0.71153 
Epoch [34/300] Training [18/62] Loss: 0.48439 
Epoch [34/300] Training [19/62] Loss: 0.46814 
Epoch [34/300] Training [20/62] Loss: 0.51222 
Epoch [34/300] Training [21/62] Loss: 0.72326 
Epoch [34/300] Training [22/62] Loss: 0.82913 
Epoch [34/300] Training [23/62] Loss: 0.54822 
Epoch [34/300] Training [24/62] Loss: 0.47068 
Epoch [34/300] Training [25/62] Loss: 0.45791 
Epoch [34/300] Training [26/62] Loss: 0.35006 
Epoch [34/300] Training [27/62] Loss: 0.54847 
Epoch [34/300] Training [28/62] Loss: 0.54243 
Epoch [34/300] Training [29/62] Loss: 0.59619 
Epoch [34/300] Training [30/62] Loss: 0.49647 
Epoch [34/300] Training [31/62] Loss: 0.67184 
Epoch [34/300] Training [32/62] Loss: 0.37182 
Epoch [34/300] Training [33/62] Loss: 0.51202 
Epoch [34/300] Training [34/62] Loss: 0.69750 
Epoch [34/300] Training [35/62] Loss: 0.62039 
Epoch [34/300] Training [36/62] Loss: 0.65453 
Epoch [34/300] Training [37/62] Loss: 0.38914 
Epoch [34/300] Training [38/62] Loss: 0.63287 
Epoch [34/300] Training [39/62] Loss: 0.56973 
Epoch [34/300] Training [40/62] Loss: 0.64866 
Epoch [34/300] Training [41/62] Loss: 0.42923 
Epoch [34/300] Training [42/62] Loss: 0.60910 
Epoch [34/300] Training [43/62] Loss: 0.61218 
Epoch [34/300] Training [44/62] Loss: 0.57254 
Epoch [34/300] Training [45/62] Loss: 0.36853 
Epoch [34/300] Training [46/62] Loss: 0.49037 
Epoch [34/300] Training [47/62] Loss: 0.39743 
Epoch [34/300] Training [48/62] Loss: 0.57529 
Epoch [34/300] Training [49/62] Loss: 0.72565 
Epoch [34/300] Training [50/62] Loss: 0.52061 
Epoch [34/300] Training [51/62] Loss: 0.72001 
Epoch [34/300] Training [52/62] Loss: 0.48837 
Epoch [34/300] Training [53/62] Loss: 0.59346 
Epoch [34/300] Training [54/62] Loss: 0.51889 
Epoch [34/300] Training [55/62] Loss: 0.46622 
Epoch [34/300] Training [56/62] Loss: 0.57186 
Epoch [34/300] Training [57/62] Loss: 0.55788 
Epoch [34/300] Training [58/62] Loss: 0.49518 
Epoch [34/300] Training [59/62] Loss: 0.63243 
Epoch [34/300] Training [60/62] Loss: 0.33940 
Epoch [34/300] Training [61/62] Loss: 0.70151 
Epoch [34/300] Training [62/62] Loss: 0.16091 
Epoch [34/300] Training metric {'Train/mean dice_metric': 0.6204910278320312, 'Train/mean miou_metric': 0.500585675239563, 'Train/mean f1': 0.6476815342903137, 'Train/mean precision': 0.6445209980010986, 'Train/mean recall': 0.6508731842041016, 'Train/mean hd95_metric': 73.2132568359375}
Epoch [34/300] Validation [1/16] Loss: 0.42544  focal_loss 0.13127  dice_loss 0.29417 
Epoch [34/300] Validation [2/16] Loss: 0.56413  focal_loss 0.10894  dice_loss 0.45519 
Epoch [34/300] Validation [3/16] Loss: 0.57083  focal_loss 0.13192  dice_loss 0.43890 
Epoch [34/300] Validation [4/16] Loss: 0.42789  focal_loss 0.10425  dice_loss 0.32365 
Epoch [34/300] Validation [5/16] Loss: 0.43402  focal_loss 0.05776  dice_loss 0.37626 
Epoch [34/300] Validation [6/16] Loss: 0.43899  focal_loss 0.09574  dice_loss 0.34325 
Epoch [34/300] Validation [7/16] Loss: 0.45001  focal_loss 0.08796  dice_loss 0.36205 
Epoch [34/300] Validation [8/16] Loss: 0.62134  focal_loss 0.10736  dice_loss 0.51397 
Epoch [34/300] Validation [9/16] Loss: 0.36378  focal_loss 0.07559  dice_loss 0.28820 
Epoch [34/300] Validation [10/16] Loss: 0.67540  focal_loss 0.16850  dice_loss 0.50689 
Epoch [34/300] Validation [11/16] Loss: 0.42970  focal_loss 0.07836  dice_loss 0.35135 
Epoch [34/300] Validation [12/16] Loss: 0.63356  focal_loss 0.08895  dice_loss 0.54461 
Epoch [34/300] Validation [13/16] Loss: 0.61798  focal_loss 0.16611  dice_loss 0.45187 
Epoch [34/300] Validation [14/16] Loss: 0.88883  focal_loss 0.17432  dice_loss 0.71452 
Epoch [34/300] Validation [15/16] Loss: 0.41159  focal_loss 0.07674  dice_loss 0.33485 
Epoch [34/300] Validation [16/16] Loss: 0.35741  focal_loss 0.12249  dice_loss 0.23493 
Epoch [34/300] Validation metric {'Val/mean dice_metric': 0.622870147228241, 'Val/mean miou_metric': 0.5021587610244751, 'Val/mean f1': 0.6414124369621277, 'Val/mean precision': 0.6334972977638245, 'Val/mean recall': 0.6495278477668762, 'Val/mean hd95_metric': 75.02960968017578}
Cheakpoint...
Epoch [34/300] best acc:tensor([0.6229], device='cuda:0'), Now : mean acc: tensor([0.6229], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.622870147228241, 'Val/mean miou_metric': 0.5021587610244751, 'Val/mean f1': 0.6414124369621277, 'Val/mean precision': 0.6334972977638245, 'Val/mean recall': 0.6495278477668762, 'Val/mean hd95_metric': 75.02960968017578}
Epoch [35/300] Training [1/62] Loss: 0.53862 
Epoch [35/300] Training [2/62] Loss: 0.55026 
Epoch [35/300] Training [3/62] Loss: 0.35130 
Epoch [35/300] Training [4/62] Loss: 0.57064 
Epoch [35/300] Training [5/62] Loss: 0.39703 
Epoch [35/300] Training [6/62] Loss: 0.52224 
Epoch [35/300] Training [7/62] Loss: 0.27624 
Epoch [35/300] Training [8/62] Loss: 0.46134 
Epoch [35/300] Training [9/62] Loss: 0.50740 
Epoch [35/300] Training [10/62] Loss: 0.58162 
Epoch [35/300] Training [11/62] Loss: 0.49725 
Epoch [35/300] Training [12/62] Loss: 0.54554 
Epoch [35/300] Training [13/62] Loss: 0.35938 
Epoch [35/300] Training [14/62] Loss: 0.40245 
Epoch [35/300] Training [15/62] Loss: 0.58655 
Epoch [35/300] Training [16/62] Loss: 0.61199 
Epoch [35/300] Training [17/62] Loss: 0.67610 
Epoch [35/300] Training [18/62] Loss: 0.29726 
Epoch [35/300] Training [19/62] Loss: 0.50687 
Epoch [35/300] Training [20/62] Loss: 0.62938 
Epoch [35/300] Training [21/62] Loss: 0.36853 
Epoch [35/300] Training [22/62] Loss: 0.30753 
Epoch [35/300] Training [23/62] Loss: 0.40137 
Epoch [35/300] Training [24/62] Loss: 0.57383 
Epoch [35/300] Training [25/62] Loss: 0.76973 
Epoch [35/300] Training [26/62] Loss: 0.29729 
Epoch [35/300] Training [27/62] Loss: 0.58078 
Epoch [35/300] Training [28/62] Loss: 0.38582 
Epoch [35/300] Training [29/62] Loss: 0.43075 
Epoch [35/300] Training [30/62] Loss: 0.35432 
Epoch [35/300] Training [31/62] Loss: 0.38979 
Epoch [35/300] Training [32/62] Loss: 0.41428 
Epoch [35/300] Training [33/62] Loss: 0.52003 
Epoch [35/300] Training [34/62] Loss: 0.42911 
Epoch [35/300] Training [35/62] Loss: 0.45736 
Epoch [35/300] Training [36/62] Loss: 0.39572 
Epoch [35/300] Training [37/62] Loss: 0.36913 
Epoch [35/300] Training [38/62] Loss: 0.86268 
Epoch [35/300] Training [39/62] Loss: 0.70074 
Epoch [35/300] Training [40/62] Loss: 0.43743 
Epoch [35/300] Training [41/62] Loss: 0.55123 
Epoch [35/300] Training [42/62] Loss: 0.66520 
Epoch [35/300] Training [43/62] Loss: 0.62172 
Epoch [35/300] Training [44/62] Loss: 0.57295 
Epoch [35/300] Training [45/62] Loss: 0.63800 
Epoch [35/300] Training [46/62] Loss: 0.78057 
Epoch [35/300] Training [47/62] Loss: 0.45039 
Epoch [35/300] Training [48/62] Loss: 0.72234 
Epoch [35/300] Training [49/62] Loss: 0.53247 
Epoch [35/300] Training [50/62] Loss: 0.52306 
Epoch [35/300] Training [51/62] Loss: 0.44016 
Epoch [35/300] Training [52/62] Loss: 0.62794 
Epoch [35/300] Training [53/62] Loss: 0.41755 
Epoch [35/300] Training [54/62] Loss: 0.49740 
Epoch [35/300] Training [55/62] Loss: 0.45178 
Epoch [35/300] Training [56/62] Loss: 0.58380 
Epoch [35/300] Training [57/62] Loss: 0.38696 
Epoch [35/300] Training [58/62] Loss: 0.70867 
Epoch [35/300] Training [59/62] Loss: 0.66367 
Epoch [35/300] Training [60/62] Loss: 0.53514 
Epoch [35/300] Training [61/62] Loss: 0.40748 
Epoch [35/300] Training [62/62] Loss: 0.25234 
Epoch [35/300] Training metric {'Train/mean dice_metric': 0.6515535116195679, 'Train/mean miou_metric': 0.5293846130371094, 'Train/mean f1': 0.6646671891212463, 'Train/mean precision': 0.6504796147346497, 'Train/mean recall': 0.679487407207489, 'Train/mean hd95_metric': 72.46959686279297}
Epoch [35/300] Validation [1/16] Loss: 0.29899  focal_loss 0.06246  dice_loss 0.23653 
Epoch [35/300] Validation [2/16] Loss: 0.50737  focal_loss 0.07568  dice_loss 0.43169 
Epoch [35/300] Validation [3/16] Loss: 0.54724  focal_loss 0.12316  dice_loss 0.42408 
Epoch [35/300] Validation [4/16] Loss: 0.57603  focal_loss 0.11783  dice_loss 0.45820 
Epoch [35/300] Validation [5/16] Loss: 0.39146  focal_loss 0.03954  dice_loss 0.35192 
Epoch [35/300] Validation [6/16] Loss: 0.39882  focal_loss 0.07344  dice_loss 0.32538 
Epoch [35/300] Validation [7/16] Loss: 0.34103  focal_loss 0.04511  dice_loss 0.29592 
Epoch [35/300] Validation [8/16] Loss: 0.67030  focal_loss 0.13258  dice_loss 0.53772 
Epoch [35/300] Validation [9/16] Loss: 0.32536  focal_loss 0.04268  dice_loss 0.28269 
Epoch [35/300] Validation [10/16] Loss: 0.46888  focal_loss 0.07485  dice_loss 0.39403 
Epoch [35/300] Validation [11/16] Loss: 0.38195  focal_loss 0.05620  dice_loss 0.32575 
Epoch [35/300] Validation [12/16] Loss: 0.54501  focal_loss 0.05353  dice_loss 0.49148 
Epoch [35/300] Validation [13/16] Loss: 0.43219  focal_loss 0.07703  dice_loss 0.35516 
Epoch [35/300] Validation [14/16] Loss: 0.81421  focal_loss 0.14989  dice_loss 0.66432 
Epoch [35/300] Validation [15/16] Loss: 0.35283  focal_loss 0.04950  dice_loss 0.30333 
Epoch [35/300] Validation [16/16] Loss: 0.18499  focal_loss 0.02468  dice_loss 0.16031 
Epoch [35/300] Validation metric {'Val/mean dice_metric': 0.6577818393707275, 'Val/mean miou_metric': 0.5364799499511719, 'Val/mean f1': 0.6692805886268616, 'Val/mean precision': 0.6531025767326355, 'Val/mean recall': 0.6862804293632507, 'Val/mean hd95_metric': 72.59780883789062}
Cheakpoint...
Epoch [35/300] best acc:tensor([0.6578], device='cuda:0'), Now : mean acc: tensor([0.6578], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6577818393707275, 'Val/mean miou_metric': 0.5364799499511719, 'Val/mean f1': 0.6692805886268616, 'Val/mean precision': 0.6531025767326355, 'Val/mean recall': 0.6862804293632507, 'Val/mean hd95_metric': 72.59780883789062}
Epoch [36/300] Training [1/62] Loss: 0.49701 
Epoch [36/300] Training [2/62] Loss: 0.48025 
Epoch [36/300] Training [3/62] Loss: 0.39992 
Epoch [36/300] Training [4/62] Loss: 0.58494 
Epoch [36/300] Training [5/62] Loss: 0.36776 
Epoch [36/300] Training [6/62] Loss: 0.61180 
Epoch [36/300] Training [7/62] Loss: 0.50541 
Epoch [36/300] Training [8/62] Loss: 0.53644 
Epoch [36/300] Training [9/62] Loss: 0.48255 
Epoch [36/300] Training [10/62] Loss: 0.58125 
Epoch [36/300] Training [11/62] Loss: 0.41347 
Epoch [36/300] Training [12/62] Loss: 0.40655 
Epoch [36/300] Training [13/62] Loss: 0.59197 
Epoch [36/300] Training [14/62] Loss: 0.48445 
Epoch [36/300] Training [15/62] Loss: 0.32901 
Epoch [36/300] Training [16/62] Loss: 0.46950 
Epoch [36/300] Training [17/62] Loss: 0.79890 
Epoch [36/300] Training [18/62] Loss: 0.72174 
Epoch [36/300] Training [19/62] Loss: 0.53953 
Epoch [36/300] Training [20/62] Loss: 0.48818 
Epoch [36/300] Training [21/62] Loss: 0.52019 
Epoch [36/300] Training [22/62] Loss: 0.64649 
Epoch [36/300] Training [23/62] Loss: 0.48625 
Epoch [36/300] Training [24/62] Loss: 0.64828 
Epoch [36/300] Training [25/62] Loss: 0.32893 
Epoch [36/300] Training [26/62] Loss: 0.56164 
Epoch [36/300] Training [27/62] Loss: 0.53737 
Epoch [36/300] Training [28/62] Loss: 0.58392 
Epoch [36/300] Training [29/62] Loss: 0.54269 
Epoch [36/300] Training [30/62] Loss: 0.64976 
Epoch [36/300] Training [31/62] Loss: 0.44850 
Epoch [36/300] Training [32/62] Loss: 0.44079 
Epoch [36/300] Training [33/62] Loss: 0.40099 
Epoch [36/300] Training [34/62] Loss: 0.33836 
Epoch [36/300] Training [35/62] Loss: 0.52330 
Epoch [36/300] Training [36/62] Loss: 0.45366 
Epoch [36/300] Training [37/62] Loss: 0.53548 
Epoch [36/300] Training [38/62] Loss: 0.42526 
Epoch [36/300] Training [39/62] Loss: 0.41665 
Epoch [36/300] Training [40/62] Loss: 0.42513 
Epoch [36/300] Training [41/62] Loss: 0.52900 
Epoch [36/300] Training [42/62] Loss: 0.37665 
Epoch [36/300] Training [43/62] Loss: 0.29124 
Epoch [36/300] Training [44/62] Loss: 0.46510 
Epoch [36/300] Training [45/62] Loss: 0.46772 
Epoch [36/300] Training [46/62] Loss: 0.67926 
Epoch [36/300] Training [47/62] Loss: 0.51285 
Epoch [36/300] Training [48/62] Loss: 0.59308 
Epoch [36/300] Training [49/62] Loss: 0.31251 
Epoch [36/300] Training [50/62] Loss: 0.54929 
Epoch [36/300] Training [51/62] Loss: 0.54540 
Epoch [36/300] Training [52/62] Loss: 0.46006 
Epoch [36/300] Training [53/62] Loss: 0.42993 
Epoch [36/300] Training [54/62] Loss: 0.42866 
Epoch [36/300] Training [55/62] Loss: 0.54377 
Epoch [36/300] Training [56/62] Loss: 0.59100 
Epoch [36/300] Training [57/62] Loss: 0.37220 
Epoch [36/300] Training [58/62] Loss: 0.54662 
Epoch [36/300] Training [59/62] Loss: 0.45214 
Epoch [36/300] Training [60/62] Loss: 0.48759 
Epoch [36/300] Training [61/62] Loss: 0.41451 
Epoch [36/300] Training [62/62] Loss: 0.52589 
Epoch [36/300] Training metric {'Train/mean dice_metric': 0.6587070226669312, 'Train/mean miou_metric': 0.5393654108047485, 'Train/mean f1': 0.6762319803237915, 'Train/mean precision': 0.6621897220611572, 'Train/mean recall': 0.690882682800293, 'Train/mean hd95_metric': 68.65189361572266}
Epoch [36/300] Validation [1/16] Loss: 0.41997  focal_loss 0.08047  dice_loss 0.33950 
Epoch [36/300] Validation [2/16] Loss: 0.54406  focal_loss 0.06554  dice_loss 0.47852 
Epoch [36/300] Validation [3/16] Loss: 0.68752  focal_loss 0.15863  dice_loss 0.52889 
Epoch [36/300] Validation [4/16] Loss: 0.61756  focal_loss 0.12162  dice_loss 0.49594 
Epoch [36/300] Validation [5/16] Loss: 0.52357  focal_loss 0.05161  dice_loss 0.47196 
Epoch [36/300] Validation [6/16] Loss: 0.40566  focal_loss 0.03483  dice_loss 0.37084 
Epoch [36/300] Validation [7/16] Loss: 0.32388  focal_loss 0.04397  dice_loss 0.27992 
Epoch [36/300] Validation [8/16] Loss: 0.68317  focal_loss 0.09834  dice_loss 0.58483 
Epoch [36/300] Validation [9/16] Loss: 0.36242  focal_loss 0.03560  dice_loss 0.32682 
Epoch [36/300] Validation [10/16] Loss: 0.58882  focal_loss 0.07508  dice_loss 0.51374 
Epoch [36/300] Validation [11/16] Loss: 0.38004  focal_loss 0.06630  dice_loss 0.31374 
Epoch [36/300] Validation [12/16] Loss: 0.61411  focal_loss 0.04942  dice_loss 0.56469 
Epoch [36/300] Validation [13/16] Loss: 0.48540  focal_loss 0.06143  dice_loss 0.42398 
Epoch [36/300] Validation [14/16] Loss: 0.71319  focal_loss 0.07586  dice_loss 0.63732 
Epoch [36/300] Validation [15/16] Loss: 0.44989  focal_loss 0.06117  dice_loss 0.38872 
Epoch [36/300] Validation [16/16] Loss: 0.23415  focal_loss 0.02585  dice_loss 0.20830 
Epoch [36/300] Validation metric {'Val/mean dice_metric': 0.6569264531135559, 'Val/mean miou_metric': 0.5382014513015747, 'Val/mean f1': 0.6732319593429565, 'Val/mean precision': 0.6595857739448547, 'Val/mean recall': 0.6874547600746155, 'Val/mean hd95_metric': 69.85533142089844}
Cheakpoint...
Epoch [36/300] best acc:tensor([0.6578], device='cuda:0'), Now : mean acc: tensor([0.6569], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6569264531135559, 'Val/mean miou_metric': 0.5382014513015747, 'Val/mean f1': 0.6732319593429565, 'Val/mean precision': 0.6595857739448547, 'Val/mean recall': 0.6874547600746155, 'Val/mean hd95_metric': 69.85533142089844}
Epoch [37/300] Training [1/62] Loss: 0.47493 
Epoch [37/300] Training [2/62] Loss: 0.44127 
Epoch [37/300] Training [3/62] Loss: 0.51233 
Epoch [37/300] Training [4/62] Loss: 0.52347 
Epoch [37/300] Training [5/62] Loss: 0.44855 
Epoch [37/300] Training [6/62] Loss: 0.38621 
Epoch [37/300] Training [7/62] Loss: 0.54782 
Epoch [37/300] Training [8/62] Loss: 0.47929 
Epoch [37/300] Training [9/62] Loss: 0.62338 
Epoch [37/300] Training [10/62] Loss: 0.40432 
Epoch [37/300] Training [11/62] Loss: 0.55133 
Epoch [37/300] Training [12/62] Loss: 0.41041 
Epoch [37/300] Training [13/62] Loss: 0.55605 
Epoch [37/300] Training [14/62] Loss: 0.52135 
Epoch [37/300] Training [15/62] Loss: 0.50645 
Epoch [37/300] Training [16/62] Loss: 0.74422 
Epoch [37/300] Training [17/62] Loss: 0.53830 
Epoch [37/300] Training [18/62] Loss: 0.33474 
Epoch [37/300] Training [19/62] Loss: 0.53242 
Epoch [37/300] Training [20/62] Loss: 0.45186 
Epoch [37/300] Training [21/62] Loss: 0.28182 
Epoch [37/300] Training [22/62] Loss: 0.28172 
Epoch [37/300] Training [23/62] Loss: 0.30324 
Epoch [37/300] Training [24/62] Loss: 0.24221 
Epoch [37/300] Training [25/62] Loss: 0.39473 
Epoch [37/300] Training [26/62] Loss: 0.42176 
Epoch [37/300] Training [27/62] Loss: 0.44619 
Epoch [37/300] Training [28/62] Loss: 0.53488 
Epoch [37/300] Training [29/62] Loss: 0.42509 
Epoch [37/300] Training [30/62] Loss: 0.50479 
Epoch [37/300] Training [31/62] Loss: 0.38512 
Epoch [37/300] Training [32/62] Loss: 0.30984 
Epoch [37/300] Training [33/62] Loss: 0.52490 
Epoch [37/300] Training [34/62] Loss: 0.59373 
Epoch [37/300] Training [35/62] Loss: 0.47968 
Epoch [37/300] Training [36/62] Loss: 0.94984 
Epoch [37/300] Training [37/62] Loss: 0.46777 
Epoch [37/300] Training [38/62] Loss: 0.41171 
Epoch [37/300] Training [39/62] Loss: 0.37351 
Epoch [37/300] Training [40/62] Loss: 0.41813 
Epoch [37/300] Training [41/62] Loss: 0.57072 
Epoch [37/300] Training [42/62] Loss: 0.39970 
Epoch [37/300] Training [43/62] Loss: 0.40059 
Epoch [37/300] Training [44/62] Loss: 0.42508 
Epoch [37/300] Training [45/62] Loss: 0.43249 
Epoch [37/300] Training [46/62] Loss: 0.45487 
Epoch [37/300] Training [47/62] Loss: 0.52276 
Epoch [37/300] Training [48/62] Loss: 0.33871 
Epoch [37/300] Training [49/62] Loss: 0.54806 
Epoch [37/300] Training [50/62] Loss: 0.42714 
Epoch [37/300] Training [51/62] Loss: 0.50139 
Epoch [37/300] Training [52/62] Loss: 0.53860 
Epoch [37/300] Training [53/62] Loss: 0.46183 
Epoch [37/300] Training [54/62] Loss: 0.38426 
Epoch [37/300] Training [55/62] Loss: 0.67751 
Epoch [37/300] Training [56/62] Loss: 0.57663 
Epoch [37/300] Training [57/62] Loss: 0.44369 
Epoch [37/300] Training [58/62] Loss: 0.41824 
Epoch [37/300] Training [59/62] Loss: 0.35396 
Epoch [37/300] Training [60/62] Loss: 0.47982 
Epoch [37/300] Training [61/62] Loss: 0.69658 
Epoch [37/300] Training [62/62] Loss: 0.10658 
Epoch [37/300] Training metric {'Train/mean dice_metric': 0.6785733699798584, 'Train/mean miou_metric': 0.5642929673194885, 'Train/mean f1': 0.6987219452857971, 'Train/mean precision': 0.6925240755081177, 'Train/mean recall': 0.7050317525863647, 'Train/mean hd95_metric': 63.09405517578125}
Epoch [37/300] Validation [1/16] Loss: 0.54597  focal_loss 0.22218  dice_loss 0.32380 
Epoch [37/300] Validation [2/16] Loss: 0.43686  focal_loss 0.09023  dice_loss 0.34662 
Epoch [37/300] Validation [3/16] Loss: 0.68002  focal_loss 0.21900  dice_loss 0.46102 
Epoch [37/300] Validation [4/16] Loss: 0.56992  focal_loss 0.21701  dice_loss 0.35290 
Epoch [37/300] Validation [5/16] Loss: 0.51164  focal_loss 0.06241  dice_loss 0.44923 
Epoch [37/300] Validation [6/16] Loss: 0.44561  focal_loss 0.08789  dice_loss 0.35772 
Epoch [37/300] Validation [7/16] Loss: 0.55098  focal_loss 0.14413  dice_loss 0.40685 
Epoch [37/300] Validation [8/16] Loss: 0.64628  focal_loss 0.16026  dice_loss 0.48602 
Epoch [37/300] Validation [9/16] Loss: 0.49496  focal_loss 0.10901  dice_loss 0.38595 
Epoch [37/300] Validation [10/16] Loss: 0.54732  focal_loss 0.14174  dice_loss 0.40558 
Epoch [37/300] Validation [11/16] Loss: 0.46116  focal_loss 0.09065  dice_loss 0.37051 
Epoch [37/300] Validation [12/16] Loss: 0.48909  focal_loss 0.07320  dice_loss 0.41589 
Epoch [37/300] Validation [13/16] Loss: 0.44542  focal_loss 0.11818  dice_loss 0.32725 
Epoch [37/300] Validation [14/16] Loss: 0.89510  focal_loss 0.18415  dice_loss 0.71095 
Epoch [37/300] Validation [15/16] Loss: 0.47360  focal_loss 0.10422  dice_loss 0.36938 
Epoch [37/300] Validation [16/16] Loss: 0.48877  focal_loss 0.20812  dice_loss 0.28065 
Epoch [37/300] Validation metric {'Val/mean dice_metric': 0.6687669157981873, 'Val/mean miou_metric': 0.5538249611854553, 'Val/mean f1': 0.6827168464660645, 'Val/mean precision': 0.681233823299408, 'Val/mean recall': 0.6842063069343567, 'Val/mean hd95_metric': 65.44502258300781}
Cheakpoint...
Epoch [37/300] best acc:tensor([0.6688], device='cuda:0'), Now : mean acc: tensor([0.6688], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6687669157981873, 'Val/mean miou_metric': 0.5538249611854553, 'Val/mean f1': 0.6827168464660645, 'Val/mean precision': 0.681233823299408, 'Val/mean recall': 0.6842063069343567, 'Val/mean hd95_metric': 65.44502258300781}
Epoch [38/300] Training [1/62] Loss: 0.58336 
Epoch [38/300] Training [2/62] Loss: 0.55009 
Epoch [38/300] Training [3/62] Loss: 0.35354 
Epoch [38/300] Training [4/62] Loss: 0.73153 
Epoch [38/300] Training [5/62] Loss: 0.38476 
Epoch [38/300] Training [6/62] Loss: 0.37516 
Epoch [38/300] Training [7/62] Loss: 0.67691 
Epoch [38/300] Training [8/62] Loss: 0.54366 
Epoch [38/300] Training [9/62] Loss: 0.61984 
Epoch [38/300] Training [10/62] Loss: 0.45185 
Epoch [38/300] Training [11/62] Loss: 0.62313 
Epoch [38/300] Training [12/62] Loss: 0.43458 
Epoch [38/300] Training [13/62] Loss: 0.47532 
Epoch [38/300] Training [14/62] Loss: 0.33618 
Epoch [38/300] Training [15/62] Loss: 0.42747 
Epoch [38/300] Training [16/62] Loss: 0.49006 
Epoch [38/300] Training [17/62] Loss: 0.46541 
Epoch [38/300] Training [18/62] Loss: 0.67078 
Epoch [38/300] Training [19/62] Loss: 0.57336 
Epoch [38/300] Training [20/62] Loss: 0.54834 
Epoch [38/300] Training [21/62] Loss: 0.52445 
Epoch [38/300] Training [22/62] Loss: 0.41667 
Epoch [38/300] Training [23/62] Loss: 0.46243 
Epoch [38/300] Training [24/62] Loss: 0.55991 
Epoch [38/300] Training [25/62] Loss: 0.77657 
Epoch [38/300] Training [26/62] Loss: 0.37623 
Epoch [38/300] Training [27/62] Loss: 0.49988 
Epoch [38/300] Training [28/62] Loss: 0.34403 
Epoch [38/300] Training [29/62] Loss: 0.51014 
Epoch [38/300] Training [30/62] Loss: 0.35929 
Epoch [38/300] Training [31/62] Loss: 0.32698 
Epoch [38/300] Training [32/62] Loss: 0.57625 
Epoch [38/300] Training [33/62] Loss: 0.43731 
Epoch [38/300] Training [34/62] Loss: 0.38995 
Epoch [38/300] Training [35/62] Loss: 0.34052 
Epoch [38/300] Training [36/62] Loss: 0.49420 
Epoch [38/300] Training [37/62] Loss: 0.60144 
Epoch [38/300] Training [38/62] Loss: 0.46882 
Epoch [38/300] Training [39/62] Loss: 0.35740 
Epoch [38/300] Training [40/62] Loss: 0.30493 
Epoch [38/300] Training [41/62] Loss: 0.71618 
Epoch [38/300] Training [42/62] Loss: 0.38594 
Epoch [38/300] Training [43/62] Loss: 0.45429 
Epoch [38/300] Training [44/62] Loss: 0.42175 
Epoch [38/300] Training [45/62] Loss: 0.61020 
Epoch [38/300] Training [46/62] Loss: 0.62323 
Epoch [38/300] Training [47/62] Loss: 0.50605 
Epoch [38/300] Training [48/62] Loss: 0.39996 
Epoch [38/300] Training [49/62] Loss: 0.73702 
Epoch [38/300] Training [50/62] Loss: 0.51677 
Epoch [38/300] Training [51/62] Loss: 0.30941 
Epoch [38/300] Training [52/62] Loss: 0.28305 
Epoch [38/300] Training [53/62] Loss: 0.44415 
Epoch [38/300] Training [54/62] Loss: 0.53668 
Epoch [38/300] Training [55/62] Loss: 0.80373 
Epoch [38/300] Training [56/62] Loss: 0.33102 
Epoch [38/300] Training [57/62] Loss: 0.39471 
Epoch [38/300] Training [58/62] Loss: 0.39903 
Epoch [38/300] Training [59/62] Loss: 0.50515 
Epoch [38/300] Training [60/62] Loss: 0.44970 
Epoch [38/300] Training [61/62] Loss: 0.27489 
Epoch [38/300] Training [62/62] Loss: 0.88828 
Epoch [38/300] Training metric {'Train/mean dice_metric': 0.674554705619812, 'Train/mean miou_metric': 0.5550320148468018, 'Train/mean f1': 0.6841782927513123, 'Train/mean precision': 0.6828116774559021, 'Train/mean recall': 0.685550332069397, 'Train/mean hd95_metric': 66.99427795410156}
Epoch [38/300] Validation [1/16] Loss: 0.40624  focal_loss 0.12665  dice_loss 0.27959 
Epoch [38/300] Validation [2/16] Loss: 0.51070  focal_loss 0.09601  dice_loss 0.41469 
Epoch [38/300] Validation [3/16] Loss: 0.49820  focal_loss 0.09542  dice_loss 0.40278 
Epoch [38/300] Validation [4/16] Loss: 0.47832  focal_loss 0.11193  dice_loss 0.36639 
Epoch [38/300] Validation [5/16] Loss: 0.41102  focal_loss 0.05434  dice_loss 0.35669 
Epoch [38/300] Validation [6/16] Loss: 0.38585  focal_loss 0.08427  dice_loss 0.30158 
Epoch [38/300] Validation [7/16] Loss: 0.42683  focal_loss 0.08203  dice_loss 0.34480 
Epoch [38/300] Validation [8/16] Loss: 0.61144  focal_loss 0.09828  dice_loss 0.51316 
Epoch [38/300] Validation [9/16] Loss: 0.39520  focal_loss 0.11052  dice_loss 0.28468 
Epoch [38/300] Validation [10/16] Loss: 0.45928  focal_loss 0.09612  dice_loss 0.36316 
Epoch [38/300] Validation [11/16] Loss: 0.43744  focal_loss 0.09543  dice_loss 0.34202 
Epoch [38/300] Validation [12/16] Loss: 0.57024  focal_loss 0.09921  dice_loss 0.47103 
Epoch [38/300] Validation [13/16] Loss: 0.41311  focal_loss 0.07157  dice_loss 0.34154 
Epoch [38/300] Validation [14/16] Loss: 0.72097  focal_loss 0.10662  dice_loss 0.61435 
Epoch [38/300] Validation [15/16] Loss: 0.32372  focal_loss 0.07515  dice_loss 0.24857 
Epoch [38/300] Validation [16/16] Loss: 0.20688  focal_loss 0.03334  dice_loss 0.17354 
Epoch [38/300] Validation metric {'Val/mean dice_metric': 0.6760990619659424, 'Val/mean miou_metric': 0.5575237274169922, 'Val/mean f1': 0.6828596591949463, 'Val/mean precision': 0.6784777045249939, 'Val/mean recall': 0.6872986555099487, 'Val/mean hd95_metric': 67.58949279785156}
Cheakpoint...
Epoch [38/300] best acc:tensor([0.6761], device='cuda:0'), Now : mean acc: tensor([0.6761], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6760990619659424, 'Val/mean miou_metric': 0.5575237274169922, 'Val/mean f1': 0.6828596591949463, 'Val/mean precision': 0.6784777045249939, 'Val/mean recall': 0.6872986555099487, 'Val/mean hd95_metric': 67.58949279785156}
Epoch [39/300] Training [1/62] Loss: 0.40544 
Epoch [39/300] Training [2/62] Loss: 0.35517 
Epoch [39/300] Training [3/62] Loss: 0.60378 
Epoch [39/300] Training [4/62] Loss: 0.67150 
Epoch [39/300] Training [5/62] Loss: 0.26750 
Epoch [39/300] Training [6/62] Loss: 0.54336 
Epoch [39/300] Training [7/62] Loss: 0.36718 
Epoch [39/300] Training [8/62] Loss: 0.48120 
Epoch [39/300] Training [9/62] Loss: 0.41234 
Epoch [39/300] Training [10/62] Loss: 0.49433 
Epoch [39/300] Training [11/62] Loss: 0.40974 
Epoch [39/300] Training [12/62] Loss: 0.45963 
Epoch [39/300] Training [13/62] Loss: 0.32297 
Epoch [39/300] Training [14/62] Loss: 0.41151 
Epoch [39/300] Training [15/62] Loss: 0.27401 
Epoch [39/300] Training [16/62] Loss: 0.43602 
Epoch [39/300] Training [17/62] Loss: 0.36977 
Epoch [39/300] Training [18/62] Loss: 0.62722 
Epoch [39/300] Training [19/62] Loss: 0.43650 
Epoch [39/300] Training [20/62] Loss: 0.26882 
Epoch [39/300] Training [21/62] Loss: 0.45280 
Epoch [39/300] Training [22/62] Loss: 0.39904 
Epoch [39/300] Training [23/62] Loss: 0.18014 
Epoch [39/300] Training [24/62] Loss: 0.53320 
Epoch [39/300] Training [25/62] Loss: 0.27556 
Epoch [39/300] Training [26/62] Loss: 0.60435 
Epoch [39/300] Training [27/62] Loss: 0.47011 
Epoch [39/300] Training [28/62] Loss: 0.40788 
Epoch [39/300] Training [29/62] Loss: 0.46541 
Epoch [39/300] Training [30/62] Loss: 0.53390 
Epoch [39/300] Training [31/62] Loss: 0.58061 
Epoch [39/300] Training [32/62] Loss: 0.44726 
Epoch [39/300] Training [33/62] Loss: 0.49976 
Epoch [39/300] Training [34/62] Loss: 0.41065 
Epoch [39/300] Training [35/62] Loss: 0.73145 
Epoch [39/300] Training [36/62] Loss: 0.38079 
Epoch [39/300] Training [37/62] Loss: 0.50606 
Epoch [39/300] Training [38/62] Loss: 0.53605 
Epoch [39/300] Training [39/62] Loss: 0.56760 
Epoch [39/300] Training [40/62] Loss: 0.39920 
Epoch [39/300] Training [41/62] Loss: 0.39963 
Epoch [39/300] Training [42/62] Loss: 0.50823 
Epoch [39/300] Training [43/62] Loss: 0.28472 
Epoch [39/300] Training [44/62] Loss: 0.52298 
Epoch [39/300] Training [45/62] Loss: 0.54647 
Epoch [39/300] Training [46/62] Loss: 0.34295 
Epoch [39/300] Training [47/62] Loss: 0.45945 
Epoch [39/300] Training [48/62] Loss: 0.38498 
Epoch [39/300] Training [49/62] Loss: 0.43972 
Epoch [39/300] Training [50/62] Loss: 0.39548 
Epoch [39/300] Training [51/62] Loss: 0.32953 
Epoch [39/300] Training [52/62] Loss: 0.33775 
Epoch [39/300] Training [53/62] Loss: 0.43455 
Epoch [39/300] Training [54/62] Loss: 0.37929 
Epoch [39/300] Training [55/62] Loss: 0.36033 
Epoch [39/300] Training [56/62] Loss: 0.31829 
Epoch [39/300] Training [57/62] Loss: 0.53678 
Epoch [39/300] Training [58/62] Loss: 0.43492 
Epoch [39/300] Training [59/62] Loss: 0.61647 
Epoch [39/300] Training [60/62] Loss: 0.51543 
Epoch [39/300] Training [61/62] Loss: 0.47199 
Epoch [39/300] Training [62/62] Loss: 0.76554 
Epoch [39/300] Training metric {'Train/mean dice_metric': 0.6946644186973572, 'Train/mean miou_metric': 0.5800409913063049, 'Train/mean f1': 0.7130391001701355, 'Train/mean precision': 0.7083841562271118, 'Train/mean recall': 0.7177557945251465, 'Train/mean hd95_metric': 63.20616149902344}
Epoch [39/300] Validation [1/16] Loss: 0.48660  focal_loss 0.12323  dice_loss 0.36337 
Epoch [39/300] Validation [2/16] Loss: 0.52046  focal_loss 0.07229  dice_loss 0.44817 
Epoch [39/300] Validation [3/16] Loss: 0.76559  focal_loss 0.21606  dice_loss 0.54953 
Epoch [39/300] Validation [4/16] Loss: 0.36242  focal_loss 0.05044  dice_loss 0.31199 
Epoch [39/300] Validation [5/16] Loss: 0.42442  focal_loss 0.04157  dice_loss 0.38286 
Epoch [39/300] Validation [6/16] Loss: 0.36869  focal_loss 0.03565  dice_loss 0.33304 
Epoch [39/300] Validation [7/16] Loss: 0.38042  focal_loss 0.05716  dice_loss 0.32326 
Epoch [39/300] Validation [8/16] Loss: 0.54025  focal_loss 0.04389  dice_loss 0.49637 
Epoch [39/300] Validation [9/16] Loss: 0.40080  focal_loss 0.05441  dice_loss 0.34639 
Epoch [39/300] Validation [10/16] Loss: 0.57725  focal_loss 0.10545  dice_loss 0.47179 
Epoch [39/300] Validation [11/16] Loss: 0.34395  focal_loss 0.04177  dice_loss 0.30218 
Epoch [39/300] Validation [12/16] Loss: 0.49116  focal_loss 0.04022  dice_loss 0.45094 
Epoch [39/300] Validation [13/16] Loss: 0.57476  focal_loss 0.10781  dice_loss 0.46695 
Epoch [39/300] Validation [14/16] Loss: 0.73935  focal_loss 0.10967  dice_loss 0.62969 
Epoch [39/300] Validation [15/16] Loss: 0.44523  focal_loss 0.05147  dice_loss 0.39375 
Epoch [39/300] Validation [16/16] Loss: 0.20877  focal_loss 0.02485  dice_loss 0.18392 
Epoch [39/300] Validation metric {'Val/mean dice_metric': 0.6866121888160706, 'Val/mean miou_metric': 0.5730272531509399, 'Val/mean f1': 0.7065455317497253, 'Val/mean precision': 0.7011473774909973, 'Val/mean recall': 0.7120273113250732, 'Val/mean hd95_metric': 64.14436340332031}
Cheakpoint...
Epoch [39/300] best acc:tensor([0.6866], device='cuda:0'), Now : mean acc: tensor([0.6866], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6866121888160706, 'Val/mean miou_metric': 0.5730272531509399, 'Val/mean f1': 0.7065455317497253, 'Val/mean precision': 0.7011473774909973, 'Val/mean recall': 0.7120273113250732, 'Val/mean hd95_metric': 64.14436340332031}
Epoch [40/300] Training [1/62] Loss: 0.49694 
Epoch [40/300] Training [2/62] Loss: 0.36208 
Epoch [40/300] Training [3/62] Loss: 0.50856 
Epoch [40/300] Training [4/62] Loss: 0.50080 
Epoch [40/300] Training [5/62] Loss: 0.53287 
Epoch [40/300] Training [6/62] Loss: 0.46217 
Epoch [40/300] Training [7/62] Loss: 0.49602 
Epoch [40/300] Training [8/62] Loss: 0.38238 
Epoch [40/300] Training [9/62] Loss: 0.48948 
Epoch [40/300] Training [10/62] Loss: 0.45122 
Epoch [40/300] Training [11/62] Loss: 0.45130 
Epoch [40/300] Training [12/62] Loss: 0.60041 
Epoch [40/300] Training [13/62] Loss: 0.45537 
Epoch [40/300] Training [14/62] Loss: 0.40700 
Epoch [40/300] Training [15/62] Loss: 0.30712 
Epoch [40/300] Training [16/62] Loss: 0.42577 
Epoch [40/300] Training [17/62] Loss: 0.39214 
Epoch [40/300] Training [18/62] Loss: 0.53095 
Epoch [40/300] Training [19/62] Loss: 0.39794 
Epoch [40/300] Training [20/62] Loss: 0.40825 
Epoch [40/300] Training [21/62] Loss: 0.31213 
Epoch [40/300] Training [22/62] Loss: 0.53621 
Epoch [40/300] Training [23/62] Loss: 0.44631 
Epoch [40/300] Training [24/62] Loss: 0.30610 
Epoch [40/300] Training [25/62] Loss: 0.42935 
Epoch [40/300] Training [26/62] Loss: 0.55276 
Epoch [40/300] Training [27/62] Loss: 0.68767 
Epoch [40/300] Training [28/62] Loss: 0.34875 
Epoch [40/300] Training [29/62] Loss: 0.53943 
Epoch [40/300] Training [30/62] Loss: 0.43400 
Epoch [40/300] Training [31/62] Loss: 0.47119 
Epoch [40/300] Training [32/62] Loss: 0.52317 
Epoch [40/300] Training [33/62] Loss: 0.57233 
Epoch [40/300] Training [34/62] Loss: 0.44272 
Epoch [40/300] Training [35/62] Loss: 0.28265 
Epoch [40/300] Training [36/62] Loss: 0.40466 
Epoch [40/300] Training [37/62] Loss: 0.46366 
Epoch [40/300] Training [38/62] Loss: 0.47872 
Epoch [40/300] Training [39/62] Loss: 0.40474 
Epoch [40/300] Training [40/62] Loss: 0.63021 
Epoch [40/300] Training [41/62] Loss: 0.32785 
Epoch [40/300] Training [42/62] Loss: 0.63568 
Epoch [40/300] Training [43/62] Loss: 0.33133 
Epoch [40/300] Training [44/62] Loss: 0.34774 
Epoch [40/300] Training [45/62] Loss: 0.49661 
Epoch [40/300] Training [46/62] Loss: 0.52853 
Epoch [40/300] Training [47/62] Loss: 0.32937 
Epoch [40/300] Training [48/62] Loss: 0.39403 
Epoch [40/300] Training [49/62] Loss: 0.30551 
Epoch [40/300] Training [50/62] Loss: 0.43670 
Epoch [40/300] Training [51/62] Loss: 0.47895 
Epoch [40/300] Training [52/62] Loss: 0.27488 
Epoch [40/300] Training [53/62] Loss: 0.31798 
Epoch [40/300] Training [54/62] Loss: 0.26511 
Epoch [40/300] Training [55/62] Loss: 0.37574 
Epoch [40/300] Training [56/62] Loss: 0.40435 
Epoch [40/300] Training [57/62] Loss: 0.38590 
Epoch [40/300] Training [58/62] Loss: 0.56654 
Epoch [40/300] Training [59/62] Loss: 0.64401 
Epoch [40/300] Training [60/62] Loss: 0.56205 
Epoch [40/300] Training [61/62] Loss: 0.37673 
Epoch [40/300] Training [62/62] Loss: 0.10770 
Epoch [40/300] Training metric {'Train/mean dice_metric': 0.696962296962738, 'Train/mean miou_metric': 0.583842933177948, 'Train/mean f1': 0.7136614322662354, 'Train/mean precision': 0.7154560685157776, 'Train/mean recall': 0.7118757367134094, 'Train/mean hd95_metric': 63.325340270996094}
Epoch [40/300] Validation [1/16] Loss: 0.59779  focal_loss 0.28762  dice_loss 0.31017 
Epoch [40/300] Validation [2/16] Loss: 0.44534  focal_loss 0.08356  dice_loss 0.36178 
Epoch [40/300] Validation [3/16] Loss: 0.50118  focal_loss 0.11235  dice_loss 0.38883 
Epoch [40/300] Validation [4/16] Loss: 0.38298  focal_loss 0.10712  dice_loss 0.27586 
Epoch [40/300] Validation [5/16] Loss: 0.41792  focal_loss 0.06192  dice_loss 0.35600 
Epoch [40/300] Validation [6/16] Loss: 0.31960  focal_loss 0.06521  dice_loss 0.25439 
Epoch [40/300] Validation [7/16] Loss: 0.33516  focal_loss 0.10359  dice_loss 0.23157 
Epoch [40/300] Validation [8/16] Loss: 0.59305  focal_loss 0.14335  dice_loss 0.44970 
Epoch [40/300] Validation [9/16] Loss: 0.32454  focal_loss 0.07215  dice_loss 0.25239 
Epoch [40/300] Validation [10/16] Loss: 0.56709  focal_loss 0.15137  dice_loss 0.41572 
Epoch [40/300] Validation [11/16] Loss: 0.25891  focal_loss 0.05293  dice_loss 0.20599 
Epoch [40/300] Validation [12/16] Loss: 0.53378  focal_loss 0.11004  dice_loss 0.42373 
Epoch [40/300] Validation [13/16] Loss: 0.57583  focal_loss 0.17364  dice_loss 0.40219 
Epoch [40/300] Validation [14/16] Loss: 0.70075  focal_loss 0.18777  dice_loss 0.51298 
Epoch [40/300] Validation [15/16] Loss: 0.32637  focal_loss 0.08183  dice_loss 0.24454 
Epoch [40/300] Validation [16/16] Loss: 0.15201  focal_loss 0.02067  dice_loss 0.13134 
Epoch [40/300] Validation metric {'Val/mean dice_metric': 0.6959993243217468, 'Val/mean miou_metric': 0.5835461616516113, 'Val/mean f1': 0.7110862731933594, 'Val/mean precision': 0.7084463238716125, 'Val/mean recall': 0.7137459516525269, 'Val/mean hd95_metric': 63.348793029785156}
Cheakpoint...
Epoch [40/300] best acc:tensor([0.6960], device='cuda:0'), Now : mean acc: tensor([0.6960], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6959993243217468, 'Val/mean miou_metric': 0.5835461616516113, 'Val/mean f1': 0.7110862731933594, 'Val/mean precision': 0.7084463238716125, 'Val/mean recall': 0.7137459516525269, 'Val/mean hd95_metric': 63.348793029785156}
Epoch [41/300] Training [1/62] Loss: 0.34060 
Epoch [41/300] Training [2/62] Loss: 0.39786 
Epoch [41/300] Training [3/62] Loss: 0.26916 
Epoch [41/300] Training [4/62] Loss: 0.44353 
Epoch [41/300] Training [5/62] Loss: 0.50416 
Epoch [41/300] Training [6/62] Loss: 0.56056 
Epoch [41/300] Training [7/62] Loss: 0.47337 
Epoch [41/300] Training [8/62] Loss: 0.42875 
Epoch [41/300] Training [9/62] Loss: 0.53947 
Epoch [41/300] Training [10/62] Loss: 0.48748 
Epoch [41/300] Training [11/62] Loss: 0.38496 
Epoch [41/300] Training [12/62] Loss: 0.32478 
Epoch [41/300] Training [13/62] Loss: 0.27574 
Epoch [41/300] Training [14/62] Loss: 0.32479 
Epoch [41/300] Training [15/62] Loss: 0.28586 
Epoch [41/300] Training [16/62] Loss: 0.31311 
Epoch [41/300] Training [17/62] Loss: 0.48886 
Epoch [41/300] Training [18/62] Loss: 0.31990 
Epoch [41/300] Training [19/62] Loss: 0.65702 
Epoch [41/300] Training [20/62] Loss: 0.67403 
Epoch [41/300] Training [21/62] Loss: 0.44341 
Epoch [41/300] Training [22/62] Loss: 0.33047 
Epoch [41/300] Training [23/62] Loss: 0.42815 
Epoch [41/300] Training [24/62] Loss: 0.48305 
Epoch [41/300] Training [25/62] Loss: 0.58465 
Epoch [41/300] Training [26/62] Loss: 0.49264 
Epoch [41/300] Training [27/62] Loss: 0.63020 
Epoch [41/300] Training [28/62] Loss: 0.63218 
Epoch [41/300] Training [29/62] Loss: 0.88167 
Epoch [41/300] Training [30/62] Loss: 0.59934 
Epoch [41/300] Training [31/62] Loss: 0.55970 
Epoch [41/300] Training [32/62] Loss: 0.62357 
Epoch [41/300] Training [33/62] Loss: 0.48557 
Epoch [41/300] Training [34/62] Loss: 0.39044 
Epoch [41/300] Training [35/62] Loss: 0.56096 
Epoch [41/300] Training [36/62] Loss: 0.29216 
Epoch [41/300] Training [37/62] Loss: 0.54078 
Epoch [41/300] Training [38/62] Loss: 0.37777 
Epoch [41/300] Training [39/62] Loss: 0.26223 
Epoch [41/300] Training [40/62] Loss: 0.56252 
Epoch [41/300] Training [41/62] Loss: 0.22165 
Epoch [41/300] Training [42/62] Loss: 0.62505 
Epoch [41/300] Training [43/62] Loss: 0.39783 
Epoch [41/300] Training [44/62] Loss: 0.24118 
Epoch [41/300] Training [45/62] Loss: 0.25876 
Epoch [41/300] Training [46/62] Loss: 0.32694 
Epoch [41/300] Training [47/62] Loss: 0.51961 
Epoch [41/300] Training [48/62] Loss: 0.40260 
Epoch [41/300] Training [49/62] Loss: 0.65584 
Epoch [41/300] Training [50/62] Loss: 0.35220 
Epoch [41/300] Training [51/62] Loss: 0.33753 
Epoch [41/300] Training [52/62] Loss: 0.39867 
Epoch [41/300] Training [53/62] Loss: 0.35797 
Epoch [41/300] Training [54/62] Loss: 0.50629 
Epoch [41/300] Training [55/62] Loss: 0.23044 
Epoch [41/300] Training [56/62] Loss: 0.27984 
Epoch [41/300] Training [57/62] Loss: 0.34166 
Epoch [41/300] Training [58/62] Loss: 0.38239 
Epoch [41/300] Training [59/62] Loss: 0.37454 
Epoch [41/300] Training [60/62] Loss: 0.23517 
Epoch [41/300] Training [61/62] Loss: 0.45024 
Epoch [41/300] Training [62/62] Loss: 0.07647 
Epoch [41/300] Training metric {'Train/mean dice_metric': 0.7026330828666687, 'Train/mean miou_metric': 0.5896766185760498, 'Train/mean f1': 0.7187105417251587, 'Train/mean precision': 0.70677250623703, 'Train/mean recall': 0.7310587167739868, 'Train/mean hd95_metric': 62.13467025756836}
Epoch [41/300] Validation [1/16] Loss: 0.46439  focal_loss 0.15218  dice_loss 0.31221 
Epoch [41/300] Validation [2/16] Loss: 0.45928  focal_loss 0.07792  dice_loss 0.38136 
Epoch [41/300] Validation [3/16] Loss: 0.51036  focal_loss 0.12291  dice_loss 0.38745 
Epoch [41/300] Validation [4/16] Loss: 0.49726  focal_loss 0.11199  dice_loss 0.38528 
Epoch [41/300] Validation [5/16] Loss: 0.45341  focal_loss 0.05896  dice_loss 0.39445 
Epoch [41/300] Validation [6/16] Loss: 0.41481  focal_loss 0.07165  dice_loss 0.34317 
Epoch [41/300] Validation [7/16] Loss: 0.40567  focal_loss 0.09027  dice_loss 0.31539 
Epoch [41/300] Validation [8/16] Loss: 0.53343  focal_loss 0.07606  dice_loss 0.45737 
Epoch [41/300] Validation [9/16] Loss: 0.36714  focal_loss 0.07342  dice_loss 0.29372 
Epoch [41/300] Validation [10/16] Loss: 0.58281  focal_loss 0.09306  dice_loss 0.48975 
Epoch [41/300] Validation [11/16] Loss: 0.35315  focal_loss 0.07904  dice_loss 0.27411 
Epoch [41/300] Validation [12/16] Loss: 0.41552  focal_loss 0.06793  dice_loss 0.34759 
Epoch [41/300] Validation [13/16] Loss: 0.49354  focal_loss 0.09972  dice_loss 0.39382 
Epoch [41/300] Validation [14/16] Loss: 0.52163  focal_loss 0.09029  dice_loss 0.43134 
Epoch [41/300] Validation [15/16] Loss: 0.30702  focal_loss 0.04645  dice_loss 0.26057 
Epoch [41/300] Validation [16/16] Loss: 0.19973  focal_loss 0.03472  dice_loss 0.16501 
Epoch [41/300] Validation metric {'Val/mean dice_metric': 0.6997206211090088, 'Val/mean miou_metric': 0.5869616270065308, 'Val/mean f1': 0.7109954953193665, 'Val/mean precision': 0.676686704158783, 'Val/mean recall': 0.7489692568778992, 'Val/mean hd95_metric': 64.41764068603516}
Cheakpoint...
Epoch [41/300] best acc:tensor([0.6997], device='cuda:0'), Now : mean acc: tensor([0.6997], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6997206211090088, 'Val/mean miou_metric': 0.5869616270065308, 'Val/mean f1': 0.7109954953193665, 'Val/mean precision': 0.676686704158783, 'Val/mean recall': 0.7489692568778992, 'Val/mean hd95_metric': 64.41764068603516}
Epoch [42/300] Training [1/62] Loss: 0.27103 
Epoch [42/300] Training [2/62] Loss: 0.54681 
Epoch [42/300] Training [3/62] Loss: 0.44533 
Epoch [42/300] Training [4/62] Loss: 0.30711 
Epoch [42/300] Training [5/62] Loss: 0.40718 
Epoch [42/300] Training [6/62] Loss: 0.43737 
Epoch [42/300] Training [7/62] Loss: 0.39693 
Epoch [42/300] Training [8/62] Loss: 0.33952 
Epoch [42/300] Training [9/62] Loss: 0.53755 
Epoch [42/300] Training [10/62] Loss: 0.50081 
Epoch [42/300] Training [11/62] Loss: 0.23546 
Epoch [42/300] Training [12/62] Loss: 0.34214 
Epoch [42/300] Training [13/62] Loss: 0.41961 
Epoch [42/300] Training [14/62] Loss: 0.27937 
Epoch [42/300] Training [15/62] Loss: 0.24227 
Epoch [42/300] Training [16/62] Loss: 0.29615 
Epoch [42/300] Training [17/62] Loss: 0.50019 
Epoch [42/300] Training [18/62] Loss: 0.23190 
Epoch [42/300] Training [19/62] Loss: 0.37856 
Epoch [42/300] Training [20/62] Loss: 0.38760 
Epoch [42/300] Training [21/62] Loss: 0.64055 
Epoch [42/300] Training [22/62] Loss: 0.49636 
Epoch [42/300] Training [23/62] Loss: 0.36810 
Epoch [42/300] Training [24/62] Loss: 0.33533 
Epoch [42/300] Training [25/62] Loss: 0.56527 
Epoch [42/300] Training [26/62] Loss: 0.51690 
Epoch [42/300] Training [27/62] Loss: 0.29353 
Epoch [42/300] Training [28/62] Loss: 0.76185 
Epoch [42/300] Training [29/62] Loss: 0.33458 
Epoch [42/300] Training [30/62] Loss: 0.31592 
Epoch [42/300] Training [31/62] Loss: 0.37698 
Epoch [42/300] Training [32/62] Loss: 0.35672 
Epoch [42/300] Training [33/62] Loss: 0.42391 
Epoch [42/300] Training [34/62] Loss: 0.59407 
Epoch [42/300] Training [35/62] Loss: 0.48398 
Epoch [42/300] Training [36/62] Loss: 0.23280 
Epoch [42/300] Training [37/62] Loss: 0.18776 
Epoch [42/300] Training [38/62] Loss: 0.33335 
Epoch [42/300] Training [39/62] Loss: 0.51166 
Epoch [42/300] Training [40/62] Loss: 0.53122 
Epoch [42/300] Training [41/62] Loss: 0.58447 
Epoch [42/300] Training [42/62] Loss: 0.41433 
Epoch [42/300] Training [43/62] Loss: 0.41144 
Epoch [42/300] Training [44/62] Loss: 0.36657 
Epoch [42/300] Training [45/62] Loss: 0.27310 
Epoch [42/300] Training [46/62] Loss: 0.38542 
Epoch [42/300] Training [47/62] Loss: 0.57887 
Epoch [42/300] Training [48/62] Loss: 0.55524 
Epoch [42/300] Training [49/62] Loss: 0.68466 
Epoch [42/300] Training [50/62] Loss: 0.36661 
Epoch [42/300] Training [51/62] Loss: 0.43623 
Epoch [42/300] Training [52/62] Loss: 0.29331 
Epoch [42/300] Training [53/62] Loss: 0.34829 
Epoch [42/300] Training [54/62] Loss: 0.37604 
Epoch [42/300] Training [55/62] Loss: 0.41751 
Epoch [42/300] Training [56/62] Loss: 0.58460 
Epoch [42/300] Training [57/62] Loss: 0.62052 
Epoch [42/300] Training [58/62] Loss: 0.36404 
Epoch [42/300] Training [59/62] Loss: 0.28969 
Epoch [42/300] Training [60/62] Loss: 0.45930 
Epoch [42/300] Training [61/62] Loss: 0.28442 
Epoch [42/300] Training [62/62] Loss: 0.27909 
Epoch [42/300] Training metric {'Train/mean dice_metric': 0.7087863087654114, 'Train/mean miou_metric': 0.6013662815093994, 'Train/mean f1': 0.7337574362754822, 'Train/mean precision': 0.7130616903305054, 'Train/mean recall': 0.755690336227417, 'Train/mean hd95_metric': 57.53048324584961}
Epoch [42/300] Validation [1/16] Loss: 0.31317  focal_loss 0.08322  dice_loss 0.22995 
Epoch [42/300] Validation [2/16] Loss: 0.39039  focal_loss 0.06998  dice_loss 0.32041 
Epoch [42/300] Validation [3/16] Loss: 0.57544  focal_loss 0.18901  dice_loss 0.38643 
Epoch [42/300] Validation [4/16] Loss: 0.35703  focal_loss 0.05091  dice_loss 0.30612 
Epoch [42/300] Validation [5/16] Loss: 0.37417  focal_loss 0.03631  dice_loss 0.33786 
Epoch [42/300] Validation [6/16] Loss: 0.36190  focal_loss 0.07693  dice_loss 0.28497 
Epoch [42/300] Validation [7/16] Loss: 0.37022  focal_loss 0.06658  dice_loss 0.30364 
Epoch [42/300] Validation [8/16] Loss: 0.62987  focal_loss 0.11655  dice_loss 0.51331 
Epoch [42/300] Validation [9/16] Loss: 0.41423  focal_loss 0.07981  dice_loss 0.33441 
Epoch [42/300] Validation [10/16] Loss: 0.58179  focal_loss 0.13288  dice_loss 0.44891 
Epoch [42/300] Validation [11/16] Loss: 0.25677  focal_loss 0.05377  dice_loss 0.20300 
Epoch [42/300] Validation [12/16] Loss: 0.45523  focal_loss 0.06537  dice_loss 0.38986 
Epoch [42/300] Validation [13/16] Loss: 0.42713  focal_loss 0.13955  dice_loss 0.28758 
Epoch [42/300] Validation [14/16] Loss: 0.56240  focal_loss 0.11682  dice_loss 0.44558 
Epoch [42/300] Validation [15/16] Loss: 0.49273  focal_loss 0.15234  dice_loss 0.34039 
Epoch [42/300] Validation [16/16] Loss: 0.12761  focal_loss 0.02036  dice_loss 0.10725 
Epoch [42/300] Validation metric {'Val/mean dice_metric': 0.7079700231552124, 'Val/mean miou_metric': 0.6005864143371582, 'Val/mean f1': 0.7272257208824158, 'Val/mean precision': 0.713557243347168, 'Val/mean recall': 0.7414281964302063, 'Val/mean hd95_metric': 58.27348709106445}
Cheakpoint...
Epoch [42/300] best acc:tensor([0.7080], device='cuda:0'), Now : mean acc: tensor([0.7080], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7079700231552124, 'Val/mean miou_metric': 0.6005864143371582, 'Val/mean f1': 0.7272257208824158, 'Val/mean precision': 0.713557243347168, 'Val/mean recall': 0.7414281964302063, 'Val/mean hd95_metric': 58.27348709106445}
Epoch [43/300] Training [1/62] Loss: 0.41873 
Epoch [43/300] Training [2/62] Loss: 0.29127 
Epoch [43/300] Training [3/62] Loss: 0.66581 
Epoch [43/300] Training [4/62] Loss: 0.24667 
Epoch [43/300] Training [5/62] Loss: 0.35469 
Epoch [43/300] Training [6/62] Loss: 0.56968 
Epoch [43/300] Training [7/62] Loss: 0.45562 
Epoch [43/300] Training [8/62] Loss: 0.52206 
Epoch [43/300] Training [9/62] Loss: 0.29514 
Epoch [43/300] Training [10/62] Loss: 0.39931 
Epoch [43/300] Training [11/62] Loss: 0.46763 
Epoch [43/300] Training [12/62] Loss: 0.61519 
Epoch [43/300] Training [13/62] Loss: 0.54515 
Epoch [43/300] Training [14/62] Loss: 0.25169 
Epoch [43/300] Training [15/62] Loss: 0.46646 
Epoch [43/300] Training [16/62] Loss: 0.27237 
Epoch [43/300] Training [17/62] Loss: 0.67369 
Epoch [43/300] Training [18/62] Loss: 0.40368 
Epoch [43/300] Training [19/62] Loss: 0.28330 
Epoch [43/300] Training [20/62] Loss: 0.45431 
Epoch [43/300] Training [21/62] Loss: 0.28702 
Epoch [43/300] Training [22/62] Loss: 0.57997 
Epoch [43/300] Training [23/62] Loss: 0.48826 
Epoch [43/300] Training [24/62] Loss: 0.38913 
Epoch [43/300] Training [25/62] Loss: 0.45980 
Epoch [43/300] Training [26/62] Loss: 0.50487 
Epoch [43/300] Training [27/62] Loss: 0.49323 
Epoch [43/300] Training [28/62] Loss: 0.64353 
Epoch [43/300] Training [29/62] Loss: 0.35358 
Epoch [43/300] Training [30/62] Loss: 0.53999 
Epoch [43/300] Training [31/62] Loss: 0.37738 
Epoch [43/300] Training [32/62] Loss: 0.54009 
Epoch [43/300] Training [33/62] Loss: 0.32989 
Epoch [43/300] Training [34/62] Loss: 0.62138 
Epoch [43/300] Training [35/62] Loss: 0.36995 
Epoch [43/300] Training [36/62] Loss: 0.51132 
Epoch [43/300] Training [37/62] Loss: 0.37410 
Epoch [43/300] Training [38/62] Loss: 0.34794 
Epoch [43/300] Training [39/62] Loss: 0.39167 
Epoch [43/300] Training [40/62] Loss: 0.70093 
Epoch [43/300] Training [41/62] Loss: 0.76784 
Epoch [43/300] Training [42/62] Loss: 0.34456 
Epoch [43/300] Training [43/62] Loss: 0.49448 
Epoch [43/300] Training [44/62] Loss: 0.43371 
Epoch [43/300] Training [45/62] Loss: 0.41131 
Epoch [43/300] Training [46/62] Loss: 0.51401 
Epoch [43/300] Training [47/62] Loss: 0.29378 
Epoch [43/300] Training [48/62] Loss: 0.46733 
Epoch [43/300] Training [49/62] Loss: 0.33102 
Epoch [43/300] Training [50/62] Loss: 0.34759 
Epoch [43/300] Training [51/62] Loss: 0.54761 
Epoch [43/300] Training [52/62] Loss: 0.35722 
Epoch [43/300] Training [53/62] Loss: 0.42501 
Epoch [43/300] Training [54/62] Loss: 0.39843 
Epoch [43/300] Training [55/62] Loss: 0.48052 
Epoch [43/300] Training [56/62] Loss: 0.33380 
Epoch [43/300] Training [57/62] Loss: 0.34863 
Epoch [43/300] Training [58/62] Loss: 0.33680 
Epoch [43/300] Training [59/62] Loss: 0.35956 
Epoch [43/300] Training [60/62] Loss: 0.25327 
Epoch [43/300] Training [61/62] Loss: 0.39960 
Epoch [43/300] Training [62/62] Loss: 1.52528 
Epoch [43/300] Training metric {'Train/mean dice_metric': 0.7059453725814819, 'Train/mean miou_metric': 0.5923369526863098, 'Train/mean f1': 0.7199196815490723, 'Train/mean precision': 0.70929354429245, 'Train/mean recall': 0.7308690547943115, 'Train/mean hd95_metric': 59.71683120727539}
Epoch [43/300] Validation [1/16] Loss: 0.36967  focal_loss 0.12930  dice_loss 0.24036 
Epoch [43/300] Validation [2/16] Loss: 0.42297  focal_loss 0.07765  dice_loss 0.34532 
Epoch [43/300] Validation [3/16] Loss: 0.46704  focal_loss 0.11923  dice_loss 0.34781 
Epoch [43/300] Validation [4/16] Loss: 0.67893  focal_loss 0.26294  dice_loss 0.41599 
Epoch [43/300] Validation [5/16] Loss: 0.56347  focal_loss 0.14534  dice_loss 0.41813 
Epoch [43/300] Validation [6/16] Loss: 0.32274  focal_loss 0.06136  dice_loss 0.26138 
Epoch [43/300] Validation [7/16] Loss: 0.54254  focal_loss 0.18431  dice_loss 0.35823 
Epoch [43/300] Validation [8/16] Loss: 0.54346  focal_loss 0.10279  dice_loss 0.44068 
Epoch [43/300] Validation [9/16] Loss: 0.57552  focal_loss 0.18958  dice_loss 0.38594 
Epoch [43/300] Validation [10/16] Loss: 0.51723  focal_loss 0.13881  dice_loss 0.37842 
Epoch [43/300] Validation [11/16] Loss: 0.34089  focal_loss 0.07809  dice_loss 0.26280 
Epoch [43/300] Validation [12/16] Loss: 0.46389  focal_loss 0.07180  dice_loss 0.39209 
Epoch [43/300] Validation [13/16] Loss: 0.45679  focal_loss 0.12620  dice_loss 0.33060 
Epoch [43/300] Validation [14/16] Loss: 0.75415  focal_loss 0.23851  dice_loss 0.51565 
Epoch [43/300] Validation [15/16] Loss: 0.54587  focal_loss 0.16382  dice_loss 0.38204 
Epoch [43/300] Validation [16/16] Loss: 0.30398  focal_loss 0.04618  dice_loss 0.25779 
Epoch [43/300] Validation metric {'Val/mean dice_metric': 0.6985105872154236, 'Val/mean miou_metric': 0.5872578620910645, 'Val/mean f1': 0.7061370611190796, 'Val/mean precision': 0.6801114678382874, 'Val/mean recall': 0.7342337369918823, 'Val/mean hd95_metric': 62.88169860839844}
Cheakpoint...
Epoch [43/300] best acc:tensor([0.7080], device='cuda:0'), Now : mean acc: tensor([0.6985], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6985105872154236, 'Val/mean miou_metric': 0.5872578620910645, 'Val/mean f1': 0.7061370611190796, 'Val/mean precision': 0.6801114678382874, 'Val/mean recall': 0.7342337369918823, 'Val/mean hd95_metric': 62.88169860839844}
Epoch [44/300] Training [1/62] Loss: 0.35361 
Epoch [44/300] Training [2/62] Loss: 0.42439 
Epoch [44/300] Training [3/62] Loss: 0.55926 
Epoch [44/300] Training [4/62] Loss: 0.55485 
Epoch [44/300] Training [5/62] Loss: 0.35936 
Epoch [44/300] Training [6/62] Loss: 0.47099 
Epoch [44/300] Training [7/62] Loss: 0.55125 
Epoch [44/300] Training [8/62] Loss: 0.61117 
Epoch [44/300] Training [9/62] Loss: 0.50373 
Epoch [44/300] Training [10/62] Loss: 0.54774 
Epoch [44/300] Training [11/62] Loss: 0.34440 
Epoch [44/300] Training [12/62] Loss: 0.66099 
Epoch [44/300] Training [13/62] Loss: 0.42270 
Epoch [44/300] Training [14/62] Loss: 0.24291 
Epoch [44/300] Training [15/62] Loss: 0.33983 
Epoch [44/300] Training [16/62] Loss: 0.42580 
Epoch [44/300] Training [17/62] Loss: 0.55247 
Epoch [44/300] Training [18/62] Loss: 0.44286 
Epoch [44/300] Training [19/62] Loss: 0.40966 
Epoch [44/300] Training [20/62] Loss: 0.29182 
Epoch [44/300] Training [21/62] Loss: 0.35066 
Epoch [44/300] Training [22/62] Loss: 0.76930 
Epoch [44/300] Training [23/62] Loss: 0.45501 
Epoch [44/300] Training [24/62] Loss: 0.54138 
Epoch [44/300] Training [25/62] Loss: 0.44933 
Epoch [44/300] Training [26/62] Loss: 0.42398 
Epoch [44/300] Training [27/62] Loss: 0.41830 
Epoch [44/300] Training [28/62] Loss: 0.55960 
Epoch [44/300] Training [29/62] Loss: 0.53431 
Epoch [44/300] Training [30/62] Loss: 0.37362 
Epoch [44/300] Training [31/62] Loss: 0.41830 
Epoch [44/300] Training [32/62] Loss: 0.44364 
Epoch [44/300] Training [33/62] Loss: 0.54409 
Epoch [44/300] Training [34/62] Loss: 0.54814 
Epoch [44/300] Training [35/62] Loss: 0.58398 
Epoch [44/300] Training [36/62] Loss: 0.35766 
Epoch [44/300] Training [37/62] Loss: 0.46023 
Epoch [44/300] Training [38/62] Loss: 0.41308 
Epoch [44/300] Training [39/62] Loss: 0.78820 
Epoch [44/300] Training [40/62] Loss: 0.50011 
Epoch [44/300] Training [41/62] Loss: 0.45452 
Epoch [44/300] Training [42/62] Loss: 0.36909 
Epoch [44/300] Training [43/62] Loss: 0.39718 
Epoch [44/300] Training [44/62] Loss: 0.42213 
Epoch [44/300] Training [45/62] Loss: 0.45310 
Epoch [44/300] Training [46/62] Loss: 0.37657 
Epoch [44/300] Training [47/62] Loss: 0.60335 
Epoch [44/300] Training [48/62] Loss: 0.47002 
Epoch [44/300] Training [49/62] Loss: 0.48396 
Epoch [44/300] Training [50/62] Loss: 0.68019 
Epoch [44/300] Training [51/62] Loss: 0.48743 
Epoch [44/300] Training [52/62] Loss: 0.35747 
Epoch [44/300] Training [53/62] Loss: 0.38661 
Epoch [44/300] Training [54/62] Loss: 0.30218 
Epoch [44/300] Training [55/62] Loss: 0.45709 
Epoch [44/300] Training [56/62] Loss: 0.39064 
Epoch [44/300] Training [57/62] Loss: 0.51536 
Epoch [44/300] Training [58/62] Loss: 0.29547 
Epoch [44/300] Training [59/62] Loss: 0.43911 
Epoch [44/300] Training [60/62] Loss: 0.35695 
Epoch [44/300] Training [61/62] Loss: 0.37967 
Epoch [44/300] Training [62/62] Loss: 0.14758 
Epoch [44/300] Training metric {'Train/mean dice_metric': 0.6867709755897522, 'Train/mean miou_metric': 0.5743570327758789, 'Train/mean f1': 0.7018380165100098, 'Train/mean precision': 0.6924365162849426, 'Train/mean recall': 0.7114983201026917, 'Train/mean hd95_metric': 64.60077667236328}
Epoch [44/300] Validation [1/16] Loss: 0.25218  focal_loss 0.04503  dice_loss 0.20715 
Epoch [44/300] Validation [2/16] Loss: 0.53822  focal_loss 0.14452  dice_loss 0.39369 
Epoch [44/300] Validation [3/16] Loss: 0.70111  focal_loss 0.22826  dice_loss 0.47285 
Epoch [44/300] Validation [4/16] Loss: 0.48657  focal_loss 0.12728  dice_loss 0.35928 
Epoch [44/300] Validation [5/16] Loss: 0.47164  focal_loss 0.05006  dice_loss 0.42158 
Epoch [44/300] Validation [6/16] Loss: 0.47580  focal_loss 0.11959  dice_loss 0.35621 
Epoch [44/300] Validation [7/16] Loss: 0.43710  focal_loss 0.11389  dice_loss 0.32321 
Epoch [44/300] Validation [8/16] Loss: 0.57471  focal_loss 0.12104  dice_loss 0.45367 
Epoch [44/300] Validation [9/16] Loss: 0.44057  focal_loss 0.10347  dice_loss 0.33710 
Epoch [44/300] Validation [10/16] Loss: 0.37643  focal_loss 0.05408  dice_loss 0.32234 
Epoch [44/300] Validation [11/16] Loss: 0.35390  focal_loss 0.06358  dice_loss 0.29032 
Epoch [44/300] Validation [12/16] Loss: 0.54562  focal_loss 0.11345  dice_loss 0.43217 
Epoch [44/300] Validation [13/16] Loss: 0.46439  focal_loss 0.13052  dice_loss 0.33386 
Epoch [44/300] Validation [14/16] Loss: 0.73367  focal_loss 0.17976  dice_loss 0.55390 
Epoch [44/300] Validation [15/16] Loss: 0.52522  focal_loss 0.13568  dice_loss 0.38953 
Epoch [44/300] Validation [16/16] Loss: 0.27400  focal_loss 0.05043  dice_loss 0.22357 
Epoch [44/300] Validation metric {'Val/mean dice_metric': 0.6857959032058716, 'Val/mean miou_metric': 0.5725230574607849, 'Val/mean f1': 0.6958945989608765, 'Val/mean precision': 0.6927141547203064, 'Val/mean recall': 0.6991045475006104, 'Val/mean hd95_metric': 65.98858642578125}
Cheakpoint...
Epoch [44/300] best acc:tensor([0.7080], device='cuda:0'), Now : mean acc: tensor([0.6858], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.6857959032058716, 'Val/mean miou_metric': 0.5725230574607849, 'Val/mean f1': 0.6958945989608765, 'Val/mean precision': 0.6927141547203064, 'Val/mean recall': 0.6991045475006104, 'Val/mean hd95_metric': 65.98858642578125}
Epoch [45/300] Training [1/62] Loss: 0.27973 
Epoch [45/300] Training [2/62] Loss: 0.18511 
Epoch [45/300] Training [3/62] Loss: 0.38852 
Epoch [45/300] Training [4/62] Loss: 0.20656 
Epoch [45/300] Training [5/62] Loss: 0.38288 
Epoch [45/300] Training [6/62] Loss: 0.29977 
Epoch [45/300] Training [7/62] Loss: 0.43508 
Epoch [45/300] Training [8/62] Loss: 0.37492 
Epoch [45/300] Training [9/62] Loss: 0.56498 
Epoch [45/300] Training [10/62] Loss: 0.43579 
Epoch [45/300] Training [11/62] Loss: 0.43854 
Epoch [45/300] Training [12/62] Loss: 0.39014 
Epoch [45/300] Training [13/62] Loss: 0.35047 
Epoch [45/300] Training [14/62] Loss: 0.50869 
Epoch [45/300] Training [15/62] Loss: 0.36708 
Epoch [45/300] Training [16/62] Loss: 0.42119 
Epoch [45/300] Training [17/62] Loss: 0.26022 
Epoch [45/300] Training [18/62] Loss: 0.45019 
Epoch [45/300] Training [19/62] Loss: 0.41905 
Epoch [45/300] Training [20/62] Loss: 0.43483 
Epoch [45/300] Training [21/62] Loss: 0.65827 
Epoch [45/300] Training [22/62] Loss: 0.50170 
Epoch [45/300] Training [23/62] Loss: 0.38037 
Epoch [45/300] Training [24/62] Loss: 0.31788 
Epoch [45/300] Training [25/62] Loss: 0.36410 
Epoch [45/300] Training [26/62] Loss: 0.40973 
Epoch [45/300] Training [27/62] Loss: 0.25112 
Epoch [45/300] Training [28/62] Loss: 0.34302 
Epoch [45/300] Training [29/62] Loss: 0.35240 
Epoch [45/300] Training [30/62] Loss: 0.42436 
Epoch [45/300] Training [31/62] Loss: 0.39273 
Epoch [45/300] Training [32/62] Loss: 0.36262 
Epoch [45/300] Training [33/62] Loss: 0.43327 
Epoch [45/300] Training [34/62] Loss: 0.20274 
Epoch [45/300] Training [35/62] Loss: 0.36261 
Epoch [45/300] Training [36/62] Loss: 0.36896 
Epoch [45/300] Training [37/62] Loss: 0.44412 
Epoch [45/300] Training [38/62] Loss: 0.41387 
Epoch [45/300] Training [39/62] Loss: 0.64075 
Epoch [45/300] Training [40/62] Loss: 0.40007 
Epoch [45/300] Training [41/62] Loss: 0.45520 
Epoch [45/300] Training [42/62] Loss: 0.44464 
Epoch [45/300] Training [43/62] Loss: 0.40324 
Epoch [45/300] Training [44/62] Loss: 0.40914 
Epoch [45/300] Training [45/62] Loss: 0.35551 
Epoch [45/300] Training [46/62] Loss: 0.26316 
Epoch [45/300] Training [47/62] Loss: 0.39978 
Epoch [45/300] Training [48/62] Loss: 0.40165 
Epoch [45/300] Training [49/62] Loss: 0.40249 
Epoch [45/300] Training [50/62] Loss: 0.31018 
Epoch [45/300] Training [51/62] Loss: 0.41257 
Epoch [45/300] Training [52/62] Loss: 0.51026 
Epoch [45/300] Training [53/62] Loss: 0.19808 
Epoch [45/300] Training [54/62] Loss: 0.28111 
Epoch [45/300] Training [55/62] Loss: 0.51625 
Epoch [45/300] Training [56/62] Loss: 0.57981 
Epoch [45/300] Training [57/62] Loss: 0.39353 
Epoch [45/300] Training [58/62] Loss: 0.44135 
Epoch [45/300] Training [59/62] Loss: 0.25738 
Epoch [45/300] Training [60/62] Loss: 0.35691 
Epoch [45/300] Training [61/62] Loss: 0.42009 
Epoch [45/300] Training [62/62] Loss: 0.07815 
Epoch [45/300] Training metric {'Train/mean dice_metric': 0.7348711490631104, 'Train/mean miou_metric': 0.6267918348312378, 'Train/mean f1': 0.7466374635696411, 'Train/mean precision': 0.727846086025238, 'Train/mean recall': 0.7664248943328857, 'Train/mean hd95_metric': 53.98249816894531}
Epoch [45/300] Validation [1/16] Loss: 0.53825  focal_loss 0.21018  dice_loss 0.32807 
Epoch [45/300] Validation [2/16] Loss: 0.52536  focal_loss 0.12850  dice_loss 0.39685 
Epoch [45/300] Validation [3/16] Loss: 0.48766  focal_loss 0.09590  dice_loss 0.39176 
Epoch [45/300] Validation [4/16] Loss: 0.40064  focal_loss 0.13035  dice_loss 0.27029 
Epoch [45/300] Validation [5/16] Loss: 0.39533  focal_loss 0.05550  dice_loss 0.33982 
Epoch [45/300] Validation [6/16] Loss: 0.32153  focal_loss 0.06411  dice_loss 0.25742 
Epoch [45/300] Validation [7/16] Loss: 0.22409  focal_loss 0.03168  dice_loss 0.19242 
Epoch [45/300] Validation [8/16] Loss: 0.53903  focal_loss 0.11615  dice_loss 0.42287 
Epoch [45/300] Validation [9/16] Loss: 0.40290  focal_loss 0.09285  dice_loss 0.31004 
Epoch [45/300] Validation [10/16] Loss: 0.37593  focal_loss 0.05213  dice_loss 0.32380 
Epoch [45/300] Validation [11/16] Loss: 0.31643  focal_loss 0.05845  dice_loss 0.25798 
Epoch [45/300] Validation [12/16] Loss: 0.45857  focal_loss 0.06852  dice_loss 0.39005 
Epoch [45/300] Validation [13/16] Loss: 0.42432  focal_loss 0.12517  dice_loss 0.29915 
Epoch [45/300] Validation [14/16] Loss: 0.65381  focal_loss 0.11710  dice_loss 0.53671 
Epoch [45/300] Validation [15/16] Loss: 0.39805  focal_loss 0.06829  dice_loss 0.32976 
Epoch [45/300] Validation [16/16] Loss: 0.28701  focal_loss 0.06403  dice_loss 0.22298 
Epoch [45/300] Validation metric {'Val/mean dice_metric': 0.726292610168457, 'Val/mean miou_metric': 0.6180438995361328, 'Val/mean f1': 0.7362044453620911, 'Val/mean precision': 0.7283344268798828, 'Val/mean recall': 0.7442463636398315, 'Val/mean hd95_metric': 56.90255355834961}
Cheakpoint...
Epoch [45/300] best acc:tensor([0.7263], device='cuda:0'), Now : mean acc: tensor([0.7263], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.726292610168457, 'Val/mean miou_metric': 0.6180438995361328, 'Val/mean f1': 0.7362044453620911, 'Val/mean precision': 0.7283344268798828, 'Val/mean recall': 0.7442463636398315, 'Val/mean hd95_metric': 56.90255355834961}
Epoch [46/300] Training [1/62] Loss: 0.31784 
Epoch [46/300] Training [2/62] Loss: 0.27522 
Epoch [46/300] Training [3/62] Loss: 0.27128 
Epoch [46/300] Training [4/62] Loss: 0.32792 
Epoch [46/300] Training [5/62] Loss: 0.29843 
Epoch [46/300] Training [6/62] Loss: 0.34887 
Epoch [46/300] Training [7/62] Loss: 0.35585 
Epoch [46/300] Training [8/62] Loss: 0.36839 
Epoch [46/300] Training [9/62] Loss: 0.18558 
Epoch [46/300] Training [10/62] Loss: 0.22738 
Epoch [46/300] Training [11/62] Loss: 0.30611 
Epoch [46/300] Training [12/62] Loss: 0.41373 
Epoch [46/300] Training [13/62] Loss: 0.46529 
Epoch [46/300] Training [14/62] Loss: 0.73023 
Epoch [46/300] Training [15/62] Loss: 0.18771 
Epoch [46/300] Training [16/62] Loss: 0.42935 
Epoch [46/300] Training [17/62] Loss: 0.60207 
Epoch [46/300] Training [18/62] Loss: 0.31758 
Epoch [46/300] Training [19/62] Loss: 0.32912 
Epoch [46/300] Training [20/62] Loss: 0.28290 
Epoch [46/300] Training [21/62] Loss: 0.20224 
Epoch [46/300] Training [22/62] Loss: 0.43388 
Epoch [46/300] Training [23/62] Loss: 0.33431 
Epoch [46/300] Training [24/62] Loss: 0.39106 
Epoch [46/300] Training [25/62] Loss: 0.49333 
Epoch [46/300] Training [26/62] Loss: 0.39099 
Epoch [46/300] Training [27/62] Loss: 0.41801 
Epoch [46/300] Training [28/62] Loss: 0.34707 
Epoch [46/300] Training [29/62] Loss: 0.45463 
Epoch [46/300] Training [30/62] Loss: 0.44551 
Epoch [46/300] Training [31/62] Loss: 0.34425 
Epoch [46/300] Training [32/62] Loss: 0.33234 
Epoch [46/300] Training [33/62] Loss: 0.43370 
Epoch [46/300] Training [34/62] Loss: 0.39415 
Epoch [46/300] Training [35/62] Loss: 0.44763 
Epoch [46/300] Training [36/62] Loss: 0.18424 
Epoch [46/300] Training [37/62] Loss: 0.29476 
Epoch [46/300] Training [38/62] Loss: 0.27835 
Epoch [46/300] Training [39/62] Loss: 0.54653 
Epoch [46/300] Training [40/62] Loss: 0.44300 
Epoch [46/300] Training [41/62] Loss: 0.28919 
Epoch [46/300] Training [42/62] Loss: 0.39560 
Epoch [46/300] Training [43/62] Loss: 0.31525 
Epoch [46/300] Training [44/62] Loss: 0.29998 
Epoch [46/300] Training [45/62] Loss: 0.30299 
Epoch [46/300] Training [46/62] Loss: 0.17104 
Epoch [46/300] Training [47/62] Loss: 0.48871 
Epoch [46/300] Training [48/62] Loss: 0.25032 
Epoch [46/300] Training [49/62] Loss: 0.29270 
Epoch [46/300] Training [50/62] Loss: 0.34796 
Epoch [46/300] Training [51/62] Loss: 0.46333 
Epoch [46/300] Training [52/62] Loss: 0.28479 
Epoch [46/300] Training [53/62] Loss: 0.50521 
Epoch [46/300] Training [54/62] Loss: 0.59879 
Epoch [46/300] Training [55/62] Loss: 0.79582 
Epoch [46/300] Training [56/62] Loss: 0.36099 
Epoch [46/300] Training [57/62] Loss: 0.41256 
Epoch [46/300] Training [58/62] Loss: 0.41472 
Epoch [46/300] Training [59/62] Loss: 0.43821 
Epoch [46/300] Training [60/62] Loss: 0.23521 
Epoch [46/300] Training [61/62] Loss: 0.32953 
Epoch [46/300] Training [62/62] Loss: 0.56913 
Epoch [46/300] Training metric {'Train/mean dice_metric': 0.7508366703987122, 'Train/mean miou_metric': 0.6465356349945068, 'Train/mean f1': 0.7619665861129761, 'Train/mean precision': 0.7573603987693787, 'Train/mean recall': 0.766629159450531, 'Train/mean hd95_metric': 49.94363784790039}
Epoch [46/300] Validation [1/16] Loss: 0.53928  focal_loss 0.25175  dice_loss 0.28754 
Epoch [46/300] Validation [2/16] Loss: 0.42957  focal_loss 0.07904  dice_loss 0.35053 
Epoch [46/300] Validation [3/16] Loss: 0.47280  focal_loss 0.08826  dice_loss 0.38454 
Epoch [46/300] Validation [4/16] Loss: 0.28816  focal_loss 0.08455  dice_loss 0.20360 
Epoch [46/300] Validation [5/16] Loss: 0.36258  focal_loss 0.05051  dice_loss 0.31208 
Epoch [46/300] Validation [6/16] Loss: 0.27406  focal_loss 0.03564  dice_loss 0.23842 
Epoch [46/300] Validation [7/16] Loss: 0.35407  focal_loss 0.05983  dice_loss 0.29424 
Epoch [46/300] Validation [8/16] Loss: 0.46411  focal_loss 0.05044  dice_loss 0.41367 
Epoch [46/300] Validation [9/16] Loss: 0.32638  focal_loss 0.07221  dice_loss 0.25418 
Epoch [46/300] Validation [10/16] Loss: 0.48147  focal_loss 0.08033  dice_loss 0.40114 
Epoch [46/300] Validation [11/16] Loss: 0.28060  focal_loss 0.05090  dice_loss 0.22970 
Epoch [46/300] Validation [12/16] Loss: 0.35695  focal_loss 0.06164  dice_loss 0.29530 
Epoch [46/300] Validation [13/16] Loss: 0.29316  focal_loss 0.05395  dice_loss 0.23922 
Epoch [46/300] Validation [14/16] Loss: 0.69091  focal_loss 0.10801  dice_loss 0.58290 
Epoch [46/300] Validation [15/16] Loss: 0.19008  focal_loss 0.02035  dice_loss 0.16973 
Epoch [46/300] Validation [16/16] Loss: 0.14579  focal_loss 0.02199  dice_loss 0.12380 
Epoch [46/300] Validation metric {'Val/mean dice_metric': 0.7496101260185242, 'Val/mean miou_metric': 0.6450097560882568, 'Val/mean f1': 0.7573844194412231, 'Val/mean precision': 0.7453281879425049, 'Val/mean recall': 0.7698370814323425, 'Val/mean hd95_metric': 51.89719009399414}
Cheakpoint...
Epoch [46/300] best acc:tensor([0.7496], device='cuda:0'), Now : mean acc: tensor([0.7496], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7496101260185242, 'Val/mean miou_metric': 0.6450097560882568, 'Val/mean f1': 0.7573844194412231, 'Val/mean precision': 0.7453281879425049, 'Val/mean recall': 0.7698370814323425, 'Val/mean hd95_metric': 51.89719009399414}
Epoch [47/300] Training [1/62] Loss: 0.30174 
Epoch [47/300] Training [2/62] Loss: 0.41509 
Epoch [47/300] Training [3/62] Loss: 0.31029 
Epoch [47/300] Training [4/62] Loss: 0.42666 
Epoch [47/300] Training [5/62] Loss: 0.59180 
Epoch [47/300] Training [6/62] Loss: 0.49455 
Epoch [47/300] Training [7/62] Loss: 0.39799 
Epoch [47/300] Training [8/62] Loss: 0.45329 
Epoch [47/300] Training [9/62] Loss: 0.31723 
Epoch [47/300] Training [10/62] Loss: 0.36921 
Epoch [47/300] Training [11/62] Loss: 0.33782 
Epoch [47/300] Training [12/62] Loss: 0.21653 
Epoch [47/300] Training [13/62] Loss: 0.31759 
Epoch [47/300] Training [14/62] Loss: 0.42135 
Epoch [47/300] Training [15/62] Loss: 0.31961 
Epoch [47/300] Training [16/62] Loss: 0.51810 
Epoch [47/300] Training [17/62] Loss: 0.30786 
Epoch [47/300] Training [18/62] Loss: 0.37239 
Epoch [47/300] Training [19/62] Loss: 0.41113 
Epoch [47/300] Training [20/62] Loss: 0.36671 
Epoch [47/300] Training [21/62] Loss: 0.45310 
Epoch [47/300] Training [22/62] Loss: 0.33022 
Epoch [47/300] Training [23/62] Loss: 0.39367 
Epoch [47/300] Training [24/62] Loss: 0.15842 
Epoch [47/300] Training [25/62] Loss: 0.55951 
Epoch [47/300] Training [26/62] Loss: 0.13824 
Epoch [47/300] Training [27/62] Loss: 0.32260 
Epoch [47/300] Training [28/62] Loss: 0.78197 
Epoch [47/300] Training [29/62] Loss: 0.37332 
Epoch [47/300] Training [30/62] Loss: 0.48057 
Epoch [47/300] Training [31/62] Loss: 0.41477 
Epoch [47/300] Training [32/62] Loss: 0.33417 
Epoch [47/300] Training [33/62] Loss: 0.46879 
Epoch [47/300] Training [34/62] Loss: 0.47171 
Epoch [47/300] Training [35/62] Loss: 0.55996 
Epoch [47/300] Training [36/62] Loss: 0.39697 
Epoch [47/300] Training [37/62] Loss: 0.36132 
Epoch [47/300] Training [38/62] Loss: 0.37526 
Epoch [47/300] Training [39/62] Loss: 0.25910 
Epoch [47/300] Training [40/62] Loss: 0.49648 
Epoch [47/300] Training [41/62] Loss: 0.33790 
Epoch [47/300] Training [42/62] Loss: 0.29599 
Epoch [47/300] Training [43/62] Loss: 0.52543 
Epoch [47/300] Training [44/62] Loss: 0.46134 
Epoch [47/300] Training [45/62] Loss: 0.69154 
Epoch [47/300] Training [46/62] Loss: 0.50079 
Epoch [47/300] Training [47/62] Loss: 0.41494 
Epoch [47/300] Training [48/62] Loss: 0.46215 
Epoch [47/300] Training [49/62] Loss: 0.36474 
Epoch [47/300] Training [50/62] Loss: 0.45019 
Epoch [47/300] Training [51/62] Loss: 0.48276 
Epoch [47/300] Training [52/62] Loss: 0.32878 
Epoch [47/300] Training [53/62] Loss: 0.34057 
Epoch [47/300] Training [54/62] Loss: 0.39683 
Epoch [47/300] Training [55/62] Loss: 0.52701 
Epoch [47/300] Training [56/62] Loss: 0.33740 
Epoch [47/300] Training [57/62] Loss: 0.40643 
Epoch [47/300] Training [58/62] Loss: 0.40034 
Epoch [47/300] Training [59/62] Loss: 0.37850 
Epoch [47/300] Training [60/62] Loss: 0.45789 
Epoch [47/300] Training [61/62] Loss: 0.60923 
Epoch [47/300] Training [62/62] Loss: 0.10682 
Epoch [47/300] Training metric {'Train/mean dice_metric': 0.7252108454704285, 'Train/mean miou_metric': 0.6146659851074219, 'Train/mean f1': 0.7311618328094482, 'Train/mean precision': 0.7220362424850464, 'Train/mean recall': 0.7405210137367249, 'Train/mean hd95_metric': 57.60325241088867}
Epoch [47/300] Validation [1/16] Loss: 0.56103  focal_loss 0.19305  dice_loss 0.36797 
Epoch [47/300] Validation [2/16] Loss: 0.41609  focal_loss 0.09819  dice_loss 0.31790 
Epoch [47/300] Validation [3/16] Loss: 0.74751  focal_loss 0.29244  dice_loss 0.45507 
Epoch [47/300] Validation [4/16] Loss: 0.29704  focal_loss 0.06581  dice_loss 0.23123 
Epoch [47/300] Validation [5/16] Loss: 0.40785  focal_loss 0.04650  dice_loss 0.36135 
Epoch [47/300] Validation [6/16] Loss: 0.39729  focal_loss 0.05386  dice_loss 0.34343 
Epoch [47/300] Validation [7/16] Loss: 0.24073  focal_loss 0.04263  dice_loss 0.19809 
Epoch [47/300] Validation [8/16] Loss: 0.55783  focal_loss 0.06528  dice_loss 0.49256 
Epoch [47/300] Validation [9/16] Loss: 0.35082  focal_loss 0.05651  dice_loss 0.29431 
Epoch [47/300] Validation [10/16] Loss: 0.40965  focal_loss 0.07129  dice_loss 0.33836 
Epoch [47/300] Validation [11/16] Loss: 0.31125  focal_loss 0.04803  dice_loss 0.26322 
Epoch [47/300] Validation [12/16] Loss: 0.41409  focal_loss 0.05506  dice_loss 0.35903 
Epoch [47/300] Validation [13/16] Loss: 0.40164  focal_loss 0.10905  dice_loss 0.29259 
Epoch [47/300] Validation [14/16] Loss: 0.65255  focal_loss 0.13548  dice_loss 0.51707 
Epoch [47/300] Validation [15/16] Loss: 0.36716  focal_loss 0.08770  dice_loss 0.27947 
Epoch [47/300] Validation [16/16] Loss: 0.21868  focal_loss 0.02670  dice_loss 0.19199 
Epoch [47/300] Validation metric {'Val/mean dice_metric': 0.7221324443817139, 'Val/mean miou_metric': 0.6120707988739014, 'Val/mean f1': 0.7221717834472656, 'Val/mean precision': 0.713847815990448, 'Val/mean recall': 0.7306923270225525, 'Val/mean hd95_metric': 57.63023376464844}
Cheakpoint...
Epoch [47/300] best acc:tensor([0.7496], device='cuda:0'), Now : mean acc: tensor([0.7221], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7221324443817139, 'Val/mean miou_metric': 0.6120707988739014, 'Val/mean f1': 0.7221717834472656, 'Val/mean precision': 0.713847815990448, 'Val/mean recall': 0.7306923270225525, 'Val/mean hd95_metric': 57.63023376464844}
Epoch [48/300] Training [1/62] Loss: 0.40353 
Epoch [48/300] Training [2/62] Loss: 0.55713 
Epoch [48/300] Training [3/62] Loss: 0.34857 
Epoch [48/300] Training [4/62] Loss: 0.58635 
Epoch [48/300] Training [5/62] Loss: 0.36742 
Epoch [48/300] Training [6/62] Loss: 0.32162 
Epoch [48/300] Training [7/62] Loss: 0.49473 
Epoch [48/300] Training [8/62] Loss: 0.19319 
Epoch [48/300] Training [9/62] Loss: 0.26917 
Epoch [48/300] Training [10/62] Loss: 0.34172 
Epoch [48/300] Training [11/62] Loss: 0.60972 
Epoch [48/300] Training [12/62] Loss: 0.54325 
Epoch [48/300] Training [13/62] Loss: 0.25887 
Epoch [48/300] Training [14/62] Loss: 0.37791 
Epoch [48/300] Training [15/62] Loss: 0.36466 
Epoch [48/300] Training [16/62] Loss: 0.24696 
Epoch [48/300] Training [17/62] Loss: 0.24171 
Epoch [48/300] Training [18/62] Loss: 0.21071 
Epoch [48/300] Training [19/62] Loss: 0.53799 
Epoch [48/300] Training [20/62] Loss: 0.10804 
Epoch [48/300] Training [21/62] Loss: 0.48709 
Epoch [48/300] Training [22/62] Loss: 0.22245 
Epoch [48/300] Training [23/62] Loss: 0.53011 
Epoch [48/300] Training [24/62] Loss: 0.65016 
Epoch [48/300] Training [25/62] Loss: 0.25945 
Epoch [48/300] Training [26/62] Loss: 0.57579 
Epoch [48/300] Training [27/62] Loss: 0.41488 
Epoch [48/300] Training [28/62] Loss: 0.40128 
Epoch [48/300] Training [29/62] Loss: 0.35487 
Epoch [48/300] Training [30/62] Loss: 0.31646 
Epoch [48/300] Training [31/62] Loss: 0.36485 
Epoch [48/300] Training [32/62] Loss: 0.32981 
Epoch [48/300] Training [33/62] Loss: 0.37440 
Epoch [48/300] Training [34/62] Loss: 0.55247 
Epoch [48/300] Training [35/62] Loss: 0.30105 
Epoch [48/300] Training [36/62] Loss: 0.68055 
Epoch [48/300] Training [37/62] Loss: 0.56897 
Epoch [48/300] Training [38/62] Loss: 0.38319 
Epoch [48/300] Training [39/62] Loss: 0.44275 
Epoch [48/300] Training [40/62] Loss: 0.24255 
Epoch [48/300] Training [41/62] Loss: 0.33784 
Epoch [48/300] Training [42/62] Loss: 0.53653 
Epoch [48/300] Training [43/62] Loss: 0.60883 
Epoch [48/300] Training [44/62] Loss: 0.34080 
Epoch [48/300] Training [45/62] Loss: 0.36087 
Epoch [48/300] Training [46/62] Loss: 0.46842 
Epoch [48/300] Training [47/62] Loss: 0.61319 
Epoch [48/300] Training [48/62] Loss: 0.42129 
Epoch [48/300] Training [49/62] Loss: 0.24663 
Epoch [48/300] Training [50/62] Loss: 0.31484 
Epoch [48/300] Training [51/62] Loss: 0.34322 
Epoch [48/300] Training [52/62] Loss: 0.29221 
Epoch [48/300] Training [53/62] Loss: 0.35337 
Epoch [48/300] Training [54/62] Loss: 0.25749 
Epoch [48/300] Training [55/62] Loss: 0.51737 
Epoch [48/300] Training [56/62] Loss: 0.42384 
Epoch [48/300] Training [57/62] Loss: 0.36733 
Epoch [48/300] Training [58/62] Loss: 0.56661 
Epoch [48/300] Training [59/62] Loss: 0.48217 
Epoch [48/300] Training [60/62] Loss: 0.26420 
Epoch [48/300] Training [61/62] Loss: 0.25938 
Epoch [48/300] Training [62/62] Loss: 0.32368 
Epoch [48/300] Training metric {'Train/mean dice_metric': 0.7401688694953918, 'Train/mean miou_metric': 0.6323924660682678, 'Train/mean f1': 0.7506853938102722, 'Train/mean precision': 0.7445259094238281, 'Train/mean recall': 0.7569476962089539, 'Train/mean hd95_metric': 55.32572555541992}
Epoch [48/300] Validation [1/16] Loss: 0.23575  focal_loss 0.04588  dice_loss 0.18987 
Epoch [48/300] Validation [2/16] Loss: 0.48348  focal_loss 0.09614  dice_loss 0.38734 
Epoch [48/300] Validation [3/16] Loss: 0.41406  focal_loss 0.06690  dice_loss 0.34716 
Epoch [48/300] Validation [4/16] Loss: 0.25256  focal_loss 0.04803  dice_loss 0.20453 
Epoch [48/300] Validation [5/16] Loss: 0.39070  focal_loss 0.03943  dice_loss 0.35126 
Epoch [48/300] Validation [6/16] Loss: 0.28202  focal_loss 0.03697  dice_loss 0.24505 
Epoch [48/300] Validation [7/16] Loss: 0.30167  focal_loss 0.05904  dice_loss 0.24263 
Epoch [48/300] Validation [8/16] Loss: 0.55435  focal_loss 0.09332  dice_loss 0.46104 
Epoch [48/300] Validation [9/16] Loss: 0.27043  focal_loss 0.05906  dice_loss 0.21137 
Epoch [48/300] Validation [10/16] Loss: 0.46841  focal_loss 0.07000  dice_loss 0.39841 
Epoch [48/300] Validation [11/16] Loss: 0.27636  focal_loss 0.04123  dice_loss 0.23514 
Epoch [48/300] Validation [12/16] Loss: 0.36049  focal_loss 0.04367  dice_loss 0.31682 
Epoch [48/300] Validation [13/16] Loss: 0.33820  focal_loss 0.06718  dice_loss 0.27102 
Epoch [48/300] Validation [14/16] Loss: 0.73748  focal_loss 0.20860  dice_loss 0.52888 
Epoch [48/300] Validation [15/16] Loss: 0.29061  focal_loss 0.04599  dice_loss 0.24462 
Epoch [48/300] Validation [16/16] Loss: 0.22043  focal_loss 0.02602  dice_loss 0.19442 
Epoch [48/300] Validation metric {'Val/mean dice_metric': 0.7428123950958252, 'Val/mean miou_metric': 0.6370189785957336, 'Val/mean f1': 0.7503795623779297, 'Val/mean precision': 0.7343667149543762, 'Val/mean recall': 0.7671062350273132, 'Val/mean hd95_metric': 56.65560531616211}
Cheakpoint...
Epoch [48/300] best acc:tensor([0.7496], device='cuda:0'), Now : mean acc: tensor([0.7428], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7428123950958252, 'Val/mean miou_metric': 0.6370189785957336, 'Val/mean f1': 0.7503795623779297, 'Val/mean precision': 0.7343667149543762, 'Val/mean recall': 0.7671062350273132, 'Val/mean hd95_metric': 56.65560531616211}
Epoch [49/300] Training [1/62] Loss: 0.36872 
Epoch [49/300] Training [2/62] Loss: 0.30055 
Epoch [49/300] Training [3/62] Loss: 0.35983 
Epoch [49/300] Training [4/62] Loss: 0.41285 
Epoch [49/300] Training [5/62] Loss: 0.36543 
Epoch [49/300] Training [6/62] Loss: 0.44193 
Epoch [49/300] Training [7/62] Loss: 0.18829 
Epoch [49/300] Training [8/62] Loss: 0.34570 
Epoch [49/300] Training [9/62] Loss: 0.32295 
Epoch [49/300] Training [10/62] Loss: 0.26608 
Epoch [49/300] Training [11/62] Loss: 0.27381 
Epoch [49/300] Training [12/62] Loss: 0.35364 
Epoch [49/300] Training [13/62] Loss: 0.23255 
Epoch [49/300] Training [14/62] Loss: 0.35771 
Epoch [49/300] Training [15/62] Loss: 0.58232 
Epoch [49/300] Training [16/62] Loss: 0.50204 
Epoch [49/300] Training [17/62] Loss: 0.24002 
Epoch [49/300] Training [18/62] Loss: 0.29497 
Epoch [49/300] Training [19/62] Loss: 0.18064 
Epoch [49/300] Training [20/62] Loss: 0.41853 
Epoch [49/300] Training [21/62] Loss: 0.30548 
Epoch [49/300] Training [22/62] Loss: 0.28215 
Epoch [49/300] Training [23/62] Loss: 0.31898 
Epoch [49/300] Training [24/62] Loss: 0.39128 
Epoch [49/300] Training [25/62] Loss: 0.21903 
Epoch [49/300] Training [26/62] Loss: 0.49123 
Epoch [49/300] Training [27/62] Loss: 0.43393 
Epoch [49/300] Training [28/62] Loss: 0.46704 
Epoch [49/300] Training [29/62] Loss: 0.38348 
Epoch [49/300] Training [30/62] Loss: 0.43284 
Epoch [49/300] Training [31/62] Loss: 0.47304 
Epoch [49/300] Training [32/62] Loss: 0.31588 
Epoch [49/300] Training [33/62] Loss: 0.35966 
Epoch [49/300] Training [34/62] Loss: 0.39463 
Epoch [49/300] Training [35/62] Loss: 0.28277 
Epoch [49/300] Training [36/62] Loss: 0.36918 
Epoch [49/300] Training [37/62] Loss: 0.29496 
Epoch [49/300] Training [38/62] Loss: 0.27706 
Epoch [49/300] Training [39/62] Loss: 0.18333 
Epoch [49/300] Training [40/62] Loss: 0.44781 
Epoch [49/300] Training [41/62] Loss: 0.26345 
Epoch [49/300] Training [42/62] Loss: 0.28751 
Epoch [49/300] Training [43/62] Loss: 0.53339 
Epoch [49/300] Training [44/62] Loss: 0.64020 
Epoch [49/300] Training [45/62] Loss: 0.28552 
Epoch [49/300] Training [46/62] Loss: 0.57485 
Epoch [49/300] Training [47/62] Loss: 0.32210 
Epoch [49/300] Training [48/62] Loss: 0.25444 
Epoch [49/300] Training [49/62] Loss: 0.56517 
Epoch [49/300] Training [50/62] Loss: 0.35414 
Epoch [49/300] Training [51/62] Loss: 0.39586 
Epoch [49/300] Training [52/62] Loss: 0.49764 
Epoch [49/300] Training [53/62] Loss: 0.31031 
Epoch [49/300] Training [54/62] Loss: 0.65093 
Epoch [49/300] Training [55/62] Loss: 0.53351 
Epoch [49/300] Training [56/62] Loss: 0.29838 
Epoch [49/300] Training [57/62] Loss: 0.19099 
Epoch [49/300] Training [58/62] Loss: 0.33069 
Epoch [49/300] Training [59/62] Loss: 0.32555 
Epoch [49/300] Training [60/62] Loss: 0.45413 
Epoch [49/300] Training [61/62] Loss: 0.36303 
Epoch [49/300] Training [62/62] Loss: 0.36545 
Epoch [49/300] Training metric {'Train/mean dice_metric': 0.7545619010925293, 'Train/mean miou_metric': 0.6464689373970032, 'Train/mean f1': 0.7632129788398743, 'Train/mean precision': 0.7515996694564819, 'Train/mean recall': 0.7751907706260681, 'Train/mean hd95_metric': 53.79194641113281}
Epoch [49/300] Validation [1/16] Loss: 0.65567  focal_loss 0.32808  dice_loss 0.32759 
Epoch [49/300] Validation [2/16] Loss: 0.40842  focal_loss 0.11821  dice_loss 0.29021 
Epoch [49/300] Validation [3/16] Loss: 0.67827  focal_loss 0.26809  dice_loss 0.41019 
Epoch [49/300] Validation [4/16] Loss: 0.38831  focal_loss 0.13627  dice_loss 0.25205 
Epoch [49/300] Validation [5/16] Loss: 0.40815  focal_loss 0.06485  dice_loss 0.34330 
Epoch [49/300] Validation [6/16] Loss: 0.28941  focal_loss 0.06603  dice_loss 0.22338 
Epoch [49/300] Validation [7/16] Loss: 0.33894  focal_loss 0.08613  dice_loss 0.25281 
Epoch [49/300] Validation [8/16] Loss: 0.62330  focal_loss 0.15228  dice_loss 0.47102 
Epoch [49/300] Validation [9/16] Loss: 0.27965  focal_loss 0.06226  dice_loss 0.21738 
Epoch [49/300] Validation [10/16] Loss: 0.32490  focal_loss 0.06680  dice_loss 0.25810 
Epoch [49/300] Validation [11/16] Loss: 0.23788  focal_loss 0.05417  dice_loss 0.18371 
Epoch [49/300] Validation [12/16] Loss: 0.39903  focal_loss 0.07611  dice_loss 0.32292 
Epoch [49/300] Validation [13/16] Loss: 0.30193  focal_loss 0.08852  dice_loss 0.21341 
Epoch [49/300] Validation [14/16] Loss: 0.79504  focal_loss 0.19348  dice_loss 0.60155 
Epoch [49/300] Validation [15/16] Loss: 0.38595  focal_loss 0.08799  dice_loss 0.29796 
Epoch [49/300] Validation [16/16] Loss: 0.22927  focal_loss 0.06377  dice_loss 0.16550 
Epoch [49/300] Validation metric {'Val/mean dice_metric': 0.7469937205314636, 'Val/mean miou_metric': 0.639307975769043, 'Val/mean f1': 0.7527612447738647, 'Val/mean precision': 0.7493188381195068, 'Val/mean recall': 0.7562353610992432, 'Val/mean hd95_metric': 55.559940338134766}
Cheakpoint...
Epoch [49/300] best acc:tensor([0.7496], device='cuda:0'), Now : mean acc: tensor([0.7470], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7469937205314636, 'Val/mean miou_metric': 0.639307975769043, 'Val/mean f1': 0.7527612447738647, 'Val/mean precision': 0.7493188381195068, 'Val/mean recall': 0.7562353610992432, 'Val/mean hd95_metric': 55.559940338134766}
Epoch [50/300] Training [1/62] Loss: 0.42933 
Epoch [50/300] Training [2/62] Loss: 0.33751 
Epoch [50/300] Training [3/62] Loss: 0.23761 
Epoch [50/300] Training [4/62] Loss: 0.47325 
Epoch [50/300] Training [5/62] Loss: 0.50861 
Epoch [50/300] Training [6/62] Loss: 0.17239 
Epoch [50/300] Training [7/62] Loss: 0.42862 
Epoch [50/300] Training [8/62] Loss: 0.34139 
Epoch [50/300] Training [9/62] Loss: 0.29157 
Epoch [50/300] Training [10/62] Loss: 0.25073 
Epoch [50/300] Training [11/62] Loss: 0.44910 
Epoch [50/300] Training [12/62] Loss: 0.26703 
Epoch [50/300] Training [13/62] Loss: 0.24428 
Epoch [50/300] Training [14/62] Loss: 0.36771 
Epoch [50/300] Training [15/62] Loss: 0.39965 
Epoch [50/300] Training [16/62] Loss: 0.38750 
Epoch [50/300] Training [17/62] Loss: 0.23593 
Epoch [50/300] Training [18/62] Loss: 0.36271 
Epoch [50/300] Training [19/62] Loss: 0.29294 
Epoch [50/300] Training [20/62] Loss: 0.39949 
Epoch [50/300] Training [21/62] Loss: 0.23464 
Epoch [50/300] Training [22/62] Loss: 0.65523 
Epoch [50/300] Training [23/62] Loss: 0.41199 
Epoch [50/300] Training [24/62] Loss: 0.27995 
Epoch [50/300] Training [25/62] Loss: 0.31390 
Epoch [50/300] Training [26/62] Loss: 0.24574 
Epoch [50/300] Training [27/62] Loss: 0.24302 
Epoch [50/300] Training [28/62] Loss: 0.30865 
Epoch [50/300] Training [29/62] Loss: 0.34392 
Epoch [50/300] Training [30/62] Loss: 0.34586 
Epoch [50/300] Training [31/62] Loss: 0.38433 
Epoch [50/300] Training [32/62] Loss: 0.28192 
Epoch [50/300] Training [33/62] Loss: 0.48080 
Epoch [50/300] Training [34/62] Loss: 0.30897 
Epoch [50/300] Training [35/62] Loss: 0.45547 
Epoch [50/300] Training [36/62] Loss: 0.23492 
Epoch [50/300] Training [37/62] Loss: 0.24817 
Epoch [50/300] Training [38/62] Loss: 0.51011 
Epoch [50/300] Training [39/62] Loss: 0.22934 
Epoch [50/300] Training [40/62] Loss: 0.61465 
Epoch [50/300] Training [41/62] Loss: 0.54487 
Epoch [50/300] Training [42/62] Loss: 0.41538 
Epoch [50/300] Training [43/62] Loss: 0.36711 
Epoch [50/300] Training [44/62] Loss: 0.31605 
Epoch [50/300] Training [45/62] Loss: 0.40770 
Epoch [50/300] Training [46/62] Loss: 0.29445 
Epoch [50/300] Training [47/62] Loss: 0.42054 
Epoch [50/300] Training [48/62] Loss: 0.25660 
Epoch [50/300] Training [49/62] Loss: 0.26672 
Epoch [50/300] Training [50/62] Loss: 0.56016 
Epoch [50/300] Training [51/62] Loss: 0.23543 
Epoch [50/300] Training [52/62] Loss: 0.37931 
Epoch [50/300] Training [53/62] Loss: 0.62722 
Epoch [50/300] Training [54/62] Loss: 0.43276 
Epoch [50/300] Training [55/62] Loss: 0.22786 
Epoch [50/300] Training [56/62] Loss: 0.25782 
Epoch [50/300] Training [57/62] Loss: 0.33405 
Epoch [50/300] Training [58/62] Loss: 0.81113 
Epoch [50/300] Training [59/62] Loss: 0.53316 
Epoch [50/300] Training [60/62] Loss: 0.43113 
Epoch [50/300] Training [61/62] Loss: 0.35752 
Epoch [50/300] Training [62/62] Loss: 0.32690 
Epoch [50/300] Training metric {'Train/mean dice_metric': 0.7501758933067322, 'Train/mean miou_metric': 0.6482604146003723, 'Train/mean f1': 0.7666608691215515, 'Train/mean precision': 0.7649440765380859, 'Train/mean recall': 0.7683853507041931, 'Train/mean hd95_metric': 53.33463668823242}
Epoch [50/300] Validation [1/16] Loss: 0.22754  focal_loss 0.03803  dice_loss 0.18951 
Epoch [50/300] Validation [2/16] Loss: 0.45111  focal_loss 0.07801  dice_loss 0.37311 
Epoch [50/300] Validation [3/16] Loss: 0.56166  focal_loss 0.09682  dice_loss 0.46484 
Epoch [50/300] Validation [4/16] Loss: 0.39743  focal_loss 0.08340  dice_loss 0.31403 
Epoch [50/300] Validation [5/16] Loss: 0.37461  focal_loss 0.04381  dice_loss 0.33080 
Epoch [50/300] Validation [6/16] Loss: 0.27681  focal_loss 0.02345  dice_loss 0.25336 
Epoch [50/300] Validation [7/16] Loss: 0.24933  focal_loss 0.03786  dice_loss 0.21146 
Epoch [50/300] Validation [8/16] Loss: 0.61389  focal_loss 0.12673  dice_loss 0.48716 
Epoch [50/300] Validation [9/16] Loss: 0.28729  focal_loss 0.05169  dice_loss 0.23560 
Epoch [50/300] Validation [10/16] Loss: 0.53731  focal_loss 0.12598  dice_loss 0.41133 
Epoch [50/300] Validation [11/16] Loss: 0.31280  focal_loss 0.03746  dice_loss 0.27534 
Epoch [50/300] Validation [12/16] Loss: 0.54103  focal_loss 0.09054  dice_loss 0.45049 
Epoch [50/300] Validation [13/16] Loss: 0.33672  focal_loss 0.05194  dice_loss 0.28477 
Epoch [50/300] Validation [14/16] Loss: 0.69270  focal_loss 0.12509  dice_loss 0.56761 
Epoch [50/300] Validation [15/16] Loss: 0.21068  focal_loss 0.02117  dice_loss 0.18950 
Epoch [50/300] Validation [16/16] Loss: 0.26005  focal_loss 0.03159  dice_loss 0.22846 
Epoch [50/300] Validation metric {'Val/mean dice_metric': 0.7461066246032715, 'Val/mean miou_metric': 0.6434776782989502, 'Val/mean f1': 0.7617481350898743, 'Val/mean precision': 0.7484099864959717, 'Val/mean recall': 0.7755703926086426, 'Val/mean hd95_metric': 55.37379837036133}
Cheakpoint...
Epoch [50/300] best acc:tensor([0.7496], device='cuda:0'), Now : mean acc: tensor([0.7461], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7461066246032715, 'Val/mean miou_metric': 0.6434776782989502, 'Val/mean f1': 0.7617481350898743, 'Val/mean precision': 0.7484099864959717, 'Val/mean recall': 0.7755703926086426, 'Val/mean hd95_metric': 55.37379837036133}
Epoch [51/300] Training [1/62] Loss: 0.30033 
Epoch [51/300] Training [2/62] Loss: 0.49017 
Epoch [51/300] Training [3/62] Loss: 0.51058 
Epoch [51/300] Training [4/62] Loss: 0.43876 
Epoch [51/300] Training [5/62] Loss: 0.43530 
Epoch [51/300] Training [6/62] Loss: 0.25527 
Epoch [51/300] Training [7/62] Loss: 0.40989 
Epoch [51/300] Training [8/62] Loss: 0.31349 
Epoch [51/300] Training [9/62] Loss: 0.21901 
Epoch [51/300] Training [10/62] Loss: 0.38228 
Epoch [51/300] Training [11/62] Loss: 0.42658 
Epoch [51/300] Training [12/62] Loss: 0.40703 
Epoch [51/300] Training [13/62] Loss: 0.43456 
Epoch [51/300] Training [14/62] Loss: 0.64123 
Epoch [51/300] Training [15/62] Loss: 0.37213 
Epoch [51/300] Training [16/62] Loss: 0.38078 
Epoch [51/300] Training [17/62] Loss: 0.46571 
Epoch [51/300] Training [18/62] Loss: 0.37274 
Epoch [51/300] Training [19/62] Loss: 0.24535 
Epoch [51/300] Training [20/62] Loss: 0.25259 
Epoch [51/300] Training [21/62] Loss: 0.21281 
Epoch [51/300] Training [22/62] Loss: 0.25809 
Epoch [51/300] Training [23/62] Loss: 0.26551 
Epoch [51/300] Training [24/62] Loss: 0.47546 
Epoch [51/300] Training [25/62] Loss: 0.23262 
Epoch [51/300] Training [26/62] Loss: 0.18864 
Epoch [51/300] Training [27/62] Loss: 0.36667 
Epoch [51/300] Training [28/62] Loss: 0.22946 
Epoch [51/300] Training [29/62] Loss: 0.30298 
Epoch [51/300] Training [30/62] Loss: 0.32086 
Epoch [51/300] Training [31/62] Loss: 0.31318 
Epoch [51/300] Training [32/62] Loss: 0.44303 
Epoch [51/300] Training [33/62] Loss: 0.30649 
Epoch [51/300] Training [34/62] Loss: 0.28035 
Epoch [51/300] Training [35/62] Loss: 0.32121 
Epoch [51/300] Training [36/62] Loss: 0.39897 
Epoch [51/300] Training [37/62] Loss: 0.24668 
Epoch [51/300] Training [38/62] Loss: 0.33926 
Epoch [51/300] Training [39/62] Loss: 0.37618 
Epoch [51/300] Training [40/62] Loss: 0.33396 
Epoch [51/300] Training [41/62] Loss: 0.22886 
Epoch [51/300] Training [42/62] Loss: 0.56917 
Epoch [51/300] Training [43/62] Loss: 0.49998 
Epoch [51/300] Training [44/62] Loss: 0.38224 
Epoch [51/300] Training [45/62] Loss: 0.36051 
Epoch [51/300] Training [46/62] Loss: 0.25487 
Epoch [51/300] Training [47/62] Loss: 0.35884 
Epoch [51/300] Training [48/62] Loss: 0.48076 
Epoch [51/300] Training [49/62] Loss: 0.43898 
Epoch [51/300] Training [50/62] Loss: 0.46165 
Epoch [51/300] Training [51/62] Loss: 0.44751 
Epoch [51/300] Training [52/62] Loss: 0.28196 
Epoch [51/300] Training [53/62] Loss: 0.29055 
Epoch [51/300] Training [54/62] Loss: 0.16707 
Epoch [51/300] Training [55/62] Loss: 0.42762 
Epoch [51/300] Training [56/62] Loss: 0.49660 
Epoch [51/300] Training [57/62] Loss: 0.33219 
Epoch [51/300] Training [58/62] Loss: 0.44376 
Epoch [51/300] Training [59/62] Loss: 0.25889 
Epoch [51/300] Training [60/62] Loss: 0.33916 
Epoch [51/300] Training [61/62] Loss: 0.32404 
Epoch [51/300] Training [62/62] Loss: 0.92290 
Epoch [51/300] Training metric {'Train/mean dice_metric': 0.7535486221313477, 'Train/mean miou_metric': 0.6499485373497009, 'Train/mean f1': 0.7595300078392029, 'Train/mean precision': 0.749430239200592, 'Train/mean recall': 0.7699055671691895, 'Train/mean hd95_metric': 52.430728912353516}
Epoch [51/300] Validation [1/16] Loss: 0.43628  focal_loss 0.15691  dice_loss 0.27937 
Epoch [51/300] Validation [2/16] Loss: 0.37728  focal_loss 0.05019  dice_loss 0.32709 
Epoch [51/300] Validation [3/16] Loss: 0.71766  focal_loss 0.24584  dice_loss 0.47182 
Epoch [51/300] Validation [4/16] Loss: 0.42318  focal_loss 0.06560  dice_loss 0.35758 
Epoch [51/300] Validation [5/16] Loss: 0.45804  focal_loss 0.02847  dice_loss 0.42957 
Epoch [51/300] Validation [6/16] Loss: 0.30188  focal_loss 0.02058  dice_loss 0.28131 
Epoch [51/300] Validation [7/16] Loss: 0.27573  focal_loss 0.04333  dice_loss 0.23240 
Epoch [51/300] Validation [8/16] Loss: 0.53644  focal_loss 0.04826  dice_loss 0.48818 
Epoch [51/300] Validation [9/16] Loss: 0.38172  focal_loss 0.03226  dice_loss 0.34946 
Epoch [51/300] Validation [10/16] Loss: 0.73519  focal_loss 0.12557  dice_loss 0.60962 
Epoch [51/300] Validation [11/16] Loss: 0.34128  focal_loss 0.04308  dice_loss 0.29819 
Epoch [51/300] Validation [12/16] Loss: 0.50559  focal_loss 0.05633  dice_loss 0.44926 
Epoch [51/300] Validation [13/16] Loss: 0.38225  focal_loss 0.06004  dice_loss 0.32221 
Epoch [51/300] Validation [14/16] Loss: 0.57365  focal_loss 0.05014  dice_loss 0.52350 
Epoch [51/300] Validation [15/16] Loss: 0.33228  focal_loss 0.02903  dice_loss 0.30325 
Epoch [51/300] Validation [16/16] Loss: 0.11812  focal_loss 0.01411  dice_loss 0.10401 
Epoch [51/300] Validation metric {'Val/mean dice_metric': 0.7428284883499146, 'Val/mean miou_metric': 0.6393795609474182, 'Val/mean f1': 0.7520559430122375, 'Val/mean precision': 0.7408159971237183, 'Val/mean recall': 0.7636422514915466, 'Val/mean hd95_metric': 55.7193717956543}
Cheakpoint...
Epoch [51/300] best acc:tensor([0.7496], device='cuda:0'), Now : mean acc: tensor([0.7428], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7428284883499146, 'Val/mean miou_metric': 0.6393795609474182, 'Val/mean f1': 0.7520559430122375, 'Val/mean precision': 0.7408159971237183, 'Val/mean recall': 0.7636422514915466, 'Val/mean hd95_metric': 55.7193717956543}
Epoch [52/300] Training [1/62] Loss: 0.31990 
Epoch [52/300] Training [2/62] Loss: 0.26339 
Epoch [52/300] Training [3/62] Loss: 0.33656 
Epoch [52/300] Training [4/62] Loss: 0.49014 
Epoch [52/300] Training [5/62] Loss: 0.12612 
Epoch [52/300] Training [6/62] Loss: 0.37459 
Epoch [52/300] Training [7/62] Loss: 0.32219 
Epoch [52/300] Training [8/62] Loss: 0.18351 
Epoch [52/300] Training [9/62] Loss: 0.29723 
Epoch [52/300] Training [10/62] Loss: 0.33206 
Epoch [52/300] Training [11/62] Loss: 0.38027 
Epoch [52/300] Training [12/62] Loss: 0.29129 
Epoch [52/300] Training [13/62] Loss: 0.59207 
Epoch [52/300] Training [14/62] Loss: 0.31950 
Epoch [52/300] Training [15/62] Loss: 0.20205 
Epoch [52/300] Training [16/62] Loss: 0.24750 
Epoch [52/300] Training [17/62] Loss: 0.39941 
Epoch [52/300] Training [18/62] Loss: 0.45871 
Epoch [52/300] Training [19/62] Loss: 0.45503 
Epoch [52/300] Training [20/62] Loss: 0.58529 
Epoch [52/300] Training [21/62] Loss: 0.36054 
Epoch [52/300] Training [22/62] Loss: 0.27526 
Epoch [52/300] Training [23/62] Loss: 0.38671 
Epoch [52/300] Training [24/62] Loss: 0.37007 
Epoch [52/300] Training [25/62] Loss: 0.20568 
Epoch [52/300] Training [26/62] Loss: 0.34254 
Epoch [52/300] Training [27/62] Loss: 0.32736 
Epoch [52/300] Training [28/62] Loss: 0.30243 
Epoch [52/300] Training [29/62] Loss: 0.31035 
Epoch [52/300] Training [30/62] Loss: 0.36778 
Epoch [52/300] Training [31/62] Loss: 0.46118 
Epoch [52/300] Training [32/62] Loss: 0.52980 
Epoch [52/300] Training [33/62] Loss: 0.39272 
Epoch [52/300] Training [34/62] Loss: 0.34326 
Epoch [52/300] Training [35/62] Loss: 0.45113 
Epoch [52/300] Training [36/62] Loss: 0.27387 
Epoch [52/300] Training [37/62] Loss: 0.48172 
Epoch [52/300] Training [38/62] Loss: 0.31213 
Epoch [52/300] Training [39/62] Loss: 0.40408 
Epoch [52/300] Training [40/62] Loss: 0.36548 
Epoch [52/300] Training [41/62] Loss: 0.29948 
Epoch [52/300] Training [42/62] Loss: 0.32365 
Epoch [52/300] Training [43/62] Loss: 0.27054 
Epoch [52/300] Training [44/62] Loss: 0.22647 
Epoch [52/300] Training [45/62] Loss: 0.42117 
Epoch [52/300] Training [46/62] Loss: 0.35816 
Epoch [52/300] Training [47/62] Loss: 0.28118 
Epoch [52/300] Training [48/62] Loss: 0.25286 
Epoch [52/300] Training [49/62] Loss: 0.30367 
Epoch [52/300] Training [50/62] Loss: 0.30235 
Epoch [52/300] Training [51/62] Loss: 0.21177 
Epoch [52/300] Training [52/62] Loss: 0.43807 
Epoch [52/300] Training [53/62] Loss: 0.40008 
Epoch [52/300] Training [54/62] Loss: 0.34181 
Epoch [52/300] Training [55/62] Loss: 0.27499 
Epoch [52/300] Training [56/62] Loss: 0.26985 
Epoch [52/300] Training [57/62] Loss: 0.31682 
Epoch [52/300] Training [58/62] Loss: 0.22947 
Epoch [52/300] Training [59/62] Loss: 0.33350 
Epoch [52/300] Training [60/62] Loss: 0.39138 
Epoch [52/300] Training [61/62] Loss: 0.74149 
Epoch [52/300] Training [62/62] Loss: 0.47643 
Epoch [52/300] Training metric {'Train/mean dice_metric': 0.7646287083625793, 'Train/mean miou_metric': 0.6617136001586914, 'Train/mean f1': 0.7826367020606995, 'Train/mean precision': 0.7761051654815674, 'Train/mean recall': 0.789279043674469, 'Train/mean hd95_metric': 47.624366760253906}
Epoch [52/300] Validation [1/16] Loss: 0.53475  focal_loss 0.22130  dice_loss 0.31345 
Epoch [52/300] Validation [2/16] Loss: 0.51429  focal_loss 0.16496  dice_loss 0.34933 
Epoch [52/300] Validation [3/16] Loss: 0.36116  focal_loss 0.08788  dice_loss 0.27328 
Epoch [52/300] Validation [4/16] Loss: 0.34991  focal_loss 0.08901  dice_loss 0.26090 
Epoch [52/300] Validation [5/16] Loss: 0.34978  focal_loss 0.04599  dice_loss 0.30379 
Epoch [52/300] Validation [6/16] Loss: 0.35377  focal_loss 0.07587  dice_loss 0.27789 
Epoch [52/300] Validation [7/16] Loss: 0.32566  focal_loss 0.08573  dice_loss 0.23992 
Epoch [52/300] Validation [8/16] Loss: 0.62767  focal_loss 0.15197  dice_loss 0.47570 
Epoch [52/300] Validation [9/16] Loss: 0.25571  focal_loss 0.05422  dice_loss 0.20149 
Epoch [52/300] Validation [10/16] Loss: 0.36407  focal_loss 0.08291  dice_loss 0.28116 
Epoch [52/300] Validation [11/16] Loss: 0.22580  focal_loss 0.03560  dice_loss 0.19020 
Epoch [52/300] Validation [12/16] Loss: 0.47947  focal_loss 0.10683  dice_loss 0.37265 
Epoch [52/300] Validation [13/16] Loss: 0.37669  focal_loss 0.10886  dice_loss 0.26783 
Epoch [52/300] Validation [14/16] Loss: 0.64684  focal_loss 0.20974  dice_loss 0.43710 
Epoch [52/300] Validation [15/16] Loss: 0.20976  focal_loss 0.04535  dice_loss 0.16440 
Epoch [52/300] Validation [16/16] Loss: 0.20458  focal_loss 0.05873  dice_loss 0.14584 
Epoch [52/300] Validation metric {'Val/mean dice_metric': 0.7591035962104797, 'Val/mean miou_metric': 0.6549485325813293, 'Val/mean f1': 0.7721153497695923, 'Val/mean precision': 0.7740261554718018, 'Val/mean recall': 0.7702139616012573, 'Val/mean hd95_metric': 49.1002082824707}
Cheakpoint...
Epoch [52/300] best acc:tensor([0.7591], device='cuda:0'), Now : mean acc: tensor([0.7591], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7591035962104797, 'Val/mean miou_metric': 0.6549485325813293, 'Val/mean f1': 0.7721153497695923, 'Val/mean precision': 0.7740261554718018, 'Val/mean recall': 0.7702139616012573, 'Val/mean hd95_metric': 49.1002082824707}
Epoch [53/300] Training [1/62] Loss: 0.15464 
Epoch [53/300] Training [2/62] Loss: 0.36326 
Epoch [53/300] Training [3/62] Loss: 0.41279 
Epoch [53/300] Training [4/62] Loss: 0.19066 
Epoch [53/300] Training [5/62] Loss: 0.25479 
Epoch [53/300] Training [6/62] Loss: 0.56905 
Epoch [53/300] Training [7/62] Loss: 0.26331 
Epoch [53/300] Training [8/62] Loss: 0.43625 
Epoch [53/300] Training [9/62] Loss: 0.51500 
Epoch [53/300] Training [10/62] Loss: 0.39263 
Epoch [53/300] Training [11/62] Loss: 0.23484 
Epoch [53/300] Training [12/62] Loss: 0.23572 
Epoch [53/300] Training [13/62] Loss: 0.49262 
Epoch [53/300] Training [14/62] Loss: 0.32182 
Epoch [53/300] Training [15/62] Loss: 0.24295 
Epoch [53/300] Training [16/62] Loss: 0.30319 
Epoch [53/300] Training [17/62] Loss: 0.37514 
Epoch [53/300] Training [18/62] Loss: 0.35660 
Epoch [53/300] Training [19/62] Loss: 0.55099 
Epoch [53/300] Training [20/62] Loss: 0.53976 
Epoch [53/300] Training [21/62] Loss: 0.33738 
Epoch [53/300] Training [22/62] Loss: 0.41395 
Epoch [53/300] Training [23/62] Loss: 0.35855 
Epoch [53/300] Training [24/62] Loss: 0.30157 
Epoch [53/300] Training [25/62] Loss: 0.35253 
Epoch [53/300] Training [26/62] Loss: 0.23793 
Epoch [53/300] Training [27/62] Loss: 0.46244 
Epoch [53/300] Training [28/62] Loss: 0.28206 
Epoch [53/300] Training [29/62] Loss: 0.30060 
Epoch [53/300] Training [30/62] Loss: 0.54712 
Epoch [53/300] Training [31/62] Loss: 0.48060 
Epoch [53/300] Training [32/62] Loss: 0.39014 
Epoch [53/300] Training [33/62] Loss: 0.42117 
Epoch [53/300] Training [34/62] Loss: 0.54996 
Epoch [53/300] Training [35/62] Loss: 0.63330 
Epoch [53/300] Training [36/62] Loss: 0.25468 
Epoch [53/300] Training [37/62] Loss: 0.30237 
Epoch [53/300] Training [38/62] Loss: 0.38258 
Epoch [53/300] Training [39/62] Loss: 0.30350 
Epoch [53/300] Training [40/62] Loss: 0.37200 
Epoch [53/300] Training [41/62] Loss: 0.31392 
Epoch [53/300] Training [42/62] Loss: 0.23913 
Epoch [53/300] Training [43/62] Loss: 0.27268 
Epoch [53/300] Training [44/62] Loss: 0.45263 
Epoch [53/300] Training [45/62] Loss: 0.38559 
Epoch [53/300] Training [46/62] Loss: 0.31246 
Epoch [53/300] Training [47/62] Loss: 0.29082 
Epoch [53/300] Training [48/62] Loss: 0.44095 
Epoch [53/300] Training [49/62] Loss: 0.22381 
Epoch [53/300] Training [50/62] Loss: 0.41335 
Epoch [53/300] Training [51/62] Loss: 0.36648 
Epoch [53/300] Training [52/62] Loss: 0.24549 
Epoch [53/300] Training [53/62] Loss: 0.14051 
Epoch [53/300] Training [54/62] Loss: 0.24306 
Epoch [53/300] Training [55/62] Loss: 0.61858 
Epoch [53/300] Training [56/62] Loss: 0.25727 
Epoch [53/300] Training [57/62] Loss: 0.22786 
Epoch [53/300] Training [58/62] Loss: 0.23046 
Epoch [53/300] Training [59/62] Loss: 0.27438 
Epoch [53/300] Training [60/62] Loss: 0.29403 
Epoch [53/300] Training [61/62] Loss: 0.26415 
Epoch [53/300] Training [62/62] Loss: 0.08219 
Epoch [53/300] Training metric {'Train/mean dice_metric': 0.7627935409545898, 'Train/mean miou_metric': 0.6610528230667114, 'Train/mean f1': 0.7755756974220276, 'Train/mean precision': 0.766545295715332, 'Train/mean recall': 0.7848214507102966, 'Train/mean hd95_metric': 49.78896713256836}
Epoch [53/300] Validation [1/16] Loss: 0.19833  focal_loss 0.05071  dice_loss 0.14762 
Epoch [53/300] Validation [2/16] Loss: 0.44292  focal_loss 0.10026  dice_loss 0.34266 
Epoch [53/300] Validation [3/16] Loss: 0.37481  focal_loss 0.07475  dice_loss 0.30006 
Epoch [53/300] Validation [4/16] Loss: 0.41248  focal_loss 0.12706  dice_loss 0.28542 
Epoch [53/300] Validation [5/16] Loss: 0.36979  focal_loss 0.05765  dice_loss 0.31213 
Epoch [53/300] Validation [6/16] Loss: 0.26012  focal_loss 0.04904  dice_loss 0.21107 
Epoch [53/300] Validation [7/16] Loss: 0.28469  focal_loss 0.06295  dice_loss 0.22173 
Epoch [53/300] Validation [8/16] Loss: 0.43025  focal_loss 0.08373  dice_loss 0.34652 
Epoch [53/300] Validation [9/16] Loss: 0.28905  focal_loss 0.06556  dice_loss 0.22349 
Epoch [53/300] Validation [10/16] Loss: 0.35956  focal_loss 0.07287  dice_loss 0.28669 
Epoch [53/300] Validation [11/16] Loss: 0.24846  focal_loss 0.04949  dice_loss 0.19897 
Epoch [53/300] Validation [12/16] Loss: 0.34284  focal_loss 0.06501  dice_loss 0.27783 
Epoch [53/300] Validation [13/16] Loss: 0.45521  focal_loss 0.14239  dice_loss 0.31282 
Epoch [53/300] Validation [14/16] Loss: 0.83466  focal_loss 0.27795  dice_loss 0.55671 
Epoch [53/300] Validation [15/16] Loss: 0.27772  focal_loss 0.07324  dice_loss 0.20448 
Epoch [53/300] Validation [16/16] Loss: 0.23950  focal_loss 0.05666  dice_loss 0.18284 
Epoch [53/300] Validation metric {'Val/mean dice_metric': 0.7614387273788452, 'Val/mean miou_metric': 0.660423755645752, 'Val/mean f1': 0.7710754871368408, 'Val/mean precision': 0.7525562047958374, 'Val/mean recall': 0.7905290722846985, 'Val/mean hd95_metric': 52.293025970458984}
Cheakpoint...
Epoch [53/300] best acc:tensor([0.7614], device='cuda:0'), Now : mean acc: tensor([0.7614], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7614387273788452, 'Val/mean miou_metric': 0.660423755645752, 'Val/mean f1': 0.7710754871368408, 'Val/mean precision': 0.7525562047958374, 'Val/mean recall': 0.7905290722846985, 'Val/mean hd95_metric': 52.293025970458984}
Epoch [54/300] Training [1/62] Loss: 0.45821 
Epoch [54/300] Training [2/62] Loss: 0.42929 
Epoch [54/300] Training [3/62] Loss: 0.27095 
Epoch [54/300] Training [4/62] Loss: 0.27526 
Epoch [54/300] Training [5/62] Loss: 0.42980 
Epoch [54/300] Training [6/62] Loss: 0.52603 
Epoch [54/300] Training [7/62] Loss: 0.32932 
Epoch [54/300] Training [8/62] Loss: 0.54241 
Epoch [54/300] Training [9/62] Loss: 0.19356 
Epoch [54/300] Training [10/62] Loss: 0.33972 
Epoch [54/300] Training [11/62] Loss: 0.21723 
Epoch [54/300] Training [12/62] Loss: 0.20173 
Epoch [54/300] Training [13/62] Loss: 0.49362 
Epoch [54/300] Training [14/62] Loss: 0.38692 
Epoch [54/300] Training [15/62] Loss: 0.33204 
Epoch [54/300] Training [16/62] Loss: 0.20985 
Epoch [54/300] Training [17/62] Loss: 0.43028 
Epoch [54/300] Training [18/62] Loss: 0.47569 
Epoch [54/300] Training [19/62] Loss: 0.30311 
Epoch [54/300] Training [20/62] Loss: 0.24170 
Epoch [54/300] Training [21/62] Loss: 0.31371 
Epoch [54/300] Training [22/62] Loss: 0.27066 
Epoch [54/300] Training [23/62] Loss: 0.21465 
Epoch [54/300] Training [24/62] Loss: 0.34079 
Epoch [54/300] Training [25/62] Loss: 0.29086 
Epoch [54/300] Training [26/62] Loss: 0.44790 
Epoch [54/300] Training [27/62] Loss: 0.24373 
Epoch [54/300] Training [28/62] Loss: 0.22545 
Epoch [54/300] Training [29/62] Loss: 0.14493 
Epoch [54/300] Training [30/62] Loss: 0.28812 
Epoch [54/300] Training [31/62] Loss: 0.33457 
Epoch [54/300] Training [32/62] Loss: 0.30028 
Epoch [54/300] Training [33/62] Loss: 0.34202 
Epoch [54/300] Training [34/62] Loss: 0.28975 
Epoch [54/300] Training [35/62] Loss: 0.30831 
Epoch [54/300] Training [36/62] Loss: 0.38532 
Epoch [54/300] Training [37/62] Loss: 0.31363 
Epoch [54/300] Training [38/62] Loss: 0.58634 
Epoch [54/300] Training [39/62] Loss: 0.16306 
Epoch [54/300] Training [40/62] Loss: 0.35158 
Epoch [54/300] Training [41/62] Loss: 0.30593 
Epoch [54/300] Training [42/62] Loss: 0.44787 
Epoch [54/300] Training [43/62] Loss: 0.39371 
Epoch [54/300] Training [44/62] Loss: 0.30825 
Epoch [54/300] Training [45/62] Loss: 0.32301 
Epoch [54/300] Training [46/62] Loss: 0.25438 
Epoch [54/300] Training [47/62] Loss: 0.25398 
Epoch [54/300] Training [48/62] Loss: 0.55900 
Epoch [54/300] Training [49/62] Loss: 0.50992 
Epoch [54/300] Training [50/62] Loss: 0.60782 
Epoch [54/300] Training [51/62] Loss: 0.36996 
Epoch [54/300] Training [52/62] Loss: 0.38766 
Epoch [54/300] Training [53/62] Loss: 0.51495 
Epoch [54/300] Training [54/62] Loss: 0.30248 
Epoch [54/300] Training [55/62] Loss: 0.41632 
Epoch [54/300] Training [56/62] Loss: 0.41090 
Epoch [54/300] Training [57/62] Loss: 0.59444 
Epoch [54/300] Training [58/62] Loss: 0.31500 
Epoch [54/300] Training [59/62] Loss: 0.42928 
Epoch [54/300] Training [60/62] Loss: 0.25575 
Epoch [54/300] Training [61/62] Loss: 0.36707 
Epoch [54/300] Training [62/62] Loss: 0.78353 
Epoch [54/300] Training metric {'Train/mean dice_metric': 0.7548505663871765, 'Train/mean miou_metric': 0.6552430987358093, 'Train/mean f1': 0.7692745923995972, 'Train/mean precision': 0.7512747049331665, 'Train/mean recall': 0.7881581783294678, 'Train/mean hd95_metric': 51.27733612060547}
Epoch [54/300] Validation [1/16] Loss: 0.46859  focal_loss 0.26777  dice_loss 0.20082 
Epoch [54/300] Validation [2/16] Loss: 0.41601  focal_loss 0.10739  dice_loss 0.30863 
Epoch [54/300] Validation [3/16] Loss: 0.91094  focal_loss 0.42273  dice_loss 0.48821 
Epoch [54/300] Validation [4/16] Loss: 0.48150  focal_loss 0.17657  dice_loss 0.30492 
Epoch [54/300] Validation [5/16] Loss: 0.36137  focal_loss 0.05591  dice_loss 0.30546 
Epoch [54/300] Validation [6/16] Loss: 0.23008  focal_loss 0.03906  dice_loss 0.19102 
Epoch [54/300] Validation [7/16] Loss: 0.20391  focal_loss 0.05484  dice_loss 0.14907 
Epoch [54/300] Validation [8/16] Loss: 0.54604  focal_loss 0.09968  dice_loss 0.44636 
Epoch [54/300] Validation [9/16] Loss: 0.31894  focal_loss 0.06662  dice_loss 0.25231 
Epoch [54/300] Validation [10/16] Loss: 0.47981  focal_loss 0.09133  dice_loss 0.38848 
Epoch [54/300] Validation [11/16] Loss: 0.19229  focal_loss 0.03558  dice_loss 0.15670 
Epoch [54/300] Validation [12/16] Loss: 0.39254  focal_loss 0.07824  dice_loss 0.31430 
Epoch [54/300] Validation [13/16] Loss: 0.24425  focal_loss 0.05052  dice_loss 0.19373 
Epoch [54/300] Validation [14/16] Loss: 0.49450  focal_loss 0.08756  dice_loss 0.40694 
Epoch [54/300] Validation [15/16] Loss: 0.24136  focal_loss 0.06151  dice_loss 0.17984 
Epoch [54/300] Validation [16/16] Loss: 0.10786  focal_loss 0.02160  dice_loss 0.08626 
Epoch [54/300] Validation metric {'Val/mean dice_metric': 0.7524479031562805, 'Val/mean miou_metric': 0.6536035537719727, 'Val/mean f1': 0.7635712027549744, 'Val/mean precision': 0.739853024482727, 'Val/mean recall': 0.7888604998588562, 'Val/mean hd95_metric': 51.985042572021484}
Cheakpoint...
Epoch [54/300] best acc:tensor([0.7614], device='cuda:0'), Now : mean acc: tensor([0.7524], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7524479031562805, 'Val/mean miou_metric': 0.6536035537719727, 'Val/mean f1': 0.7635712027549744, 'Val/mean precision': 0.739853024482727, 'Val/mean recall': 0.7888604998588562, 'Val/mean hd95_metric': 51.985042572021484}
Epoch [55/300] Training [1/62] Loss: 0.34530 
Epoch [55/300] Training [2/62] Loss: 0.48018 
Epoch [55/300] Training [3/62] Loss: 0.40785 
Epoch [55/300] Training [4/62] Loss: 0.47898 
Epoch [55/300] Training [5/62] Loss: 0.39353 
Epoch [55/300] Training [6/62] Loss: 0.25053 
Epoch [55/300] Training [7/62] Loss: 0.24227 
Epoch [55/300] Training [8/62] Loss: 0.31599 
Epoch [55/300] Training [9/62] Loss: 0.44714 
Epoch [55/300] Training [10/62] Loss: 0.37525 
Epoch [55/300] Training [11/62] Loss: 0.25168 
Epoch [55/300] Training [12/62] Loss: 0.38519 
Epoch [55/300] Training [13/62] Loss: 0.45395 
Epoch [55/300] Training [14/62] Loss: 0.32675 
Epoch [55/300] Training [15/62] Loss: 0.72894 
Epoch [55/300] Training [16/62] Loss: 0.52226 
Epoch [55/300] Training [17/62] Loss: 0.28992 
Epoch [55/300] Training [18/62] Loss: 0.55715 
Epoch [55/300] Training [19/62] Loss: 0.31071 
Epoch [55/300] Training [20/62] Loss: 0.28879 
Epoch [55/300] Training [21/62] Loss: 0.37111 
Epoch [55/300] Training [22/62] Loss: 0.36075 
Epoch [55/300] Training [23/62] Loss: 0.39409 
Epoch [55/300] Training [24/62] Loss: 0.40284 
Epoch [55/300] Training [25/62] Loss: 0.18884 
Epoch [55/300] Training [26/62] Loss: 0.31157 
Epoch [55/300] Training [27/62] Loss: 0.32427 
Epoch [55/300] Training [28/62] Loss: 0.26723 
Epoch [55/300] Training [29/62] Loss: 0.30810 
Epoch [55/300] Training [30/62] Loss: 0.37191 
Epoch [55/300] Training [31/62] Loss: 0.21565 
Epoch [55/300] Training [32/62] Loss: 0.22799 
Epoch [55/300] Training [33/62] Loss: 0.38121 
Epoch [55/300] Training [34/62] Loss: 0.32261 
Epoch [55/300] Training [35/62] Loss: 0.40411 
Epoch [55/300] Training [36/62] Loss: 0.31975 
Epoch [55/300] Training [37/62] Loss: 0.30959 
Epoch [55/300] Training [38/62] Loss: 0.30464 
Epoch [55/300] Training [39/62] Loss: 0.38464 
Epoch [55/300] Training [40/62] Loss: 0.39070 
Epoch [55/300] Training [41/62] Loss: 0.29577 
Epoch [55/300] Training [42/62] Loss: 0.43381 
Epoch [55/300] Training [43/62] Loss: 0.34183 
Epoch [55/300] Training [44/62] Loss: 0.38337 
Epoch [55/300] Training [45/62] Loss: 0.25530 
Epoch [55/300] Training [46/62] Loss: 0.38682 
Epoch [55/300] Training [47/62] Loss: 0.29788 
Epoch [55/300] Training [48/62] Loss: 0.44482 
Epoch [55/300] Training [49/62] Loss: 0.56616 
Epoch [55/300] Training [50/62] Loss: 0.38964 
Epoch [55/300] Training [51/62] Loss: 0.34629 
Epoch [55/300] Training [52/62] Loss: 0.37249 
Epoch [55/300] Training [53/62] Loss: 0.36882 
Epoch [55/300] Training [54/62] Loss: 0.19040 
Epoch [55/300] Training [55/62] Loss: 0.30237 
Epoch [55/300] Training [56/62] Loss: 0.20855 
Epoch [55/300] Training [57/62] Loss: 0.20376 
Epoch [55/300] Training [58/62] Loss: 0.18506 
Epoch [55/300] Training [59/62] Loss: 0.17531 
Epoch [55/300] Training [60/62] Loss: 0.29584 
Epoch [55/300] Training [61/62] Loss: 0.20724 
Epoch [55/300] Training [62/62] Loss: 0.84037 
Epoch [55/300] Training metric {'Train/mean dice_metric': 0.7611116170883179, 'Train/mean miou_metric': 0.658434271812439, 'Train/mean f1': 0.7691223621368408, 'Train/mean precision': 0.7511446475982666, 'Train/mean recall': 0.7879816889762878, 'Train/mean hd95_metric': 51.84627151489258}
Epoch [55/300] Validation [1/16] Loss: 0.48436  focal_loss 0.28865  dice_loss 0.19570 
Epoch [55/300] Validation [2/16] Loss: 0.49504  focal_loss 0.13572  dice_loss 0.35932 
Epoch [55/300] Validation [3/16] Loss: 0.49114  focal_loss 0.16372  dice_loss 0.32743 
Epoch [55/300] Validation [4/16] Loss: 0.52994  focal_loss 0.22377  dice_loss 0.30617 
Epoch [55/300] Validation [5/16] Loss: 0.37649  focal_loss 0.10042  dice_loss 0.27606 
Epoch [55/300] Validation [6/16] Loss: 0.29055  focal_loss 0.08876  dice_loss 0.20179 
Epoch [55/300] Validation [7/16] Loss: 0.24613  focal_loss 0.09273  dice_loss 0.15340 
Epoch [55/300] Validation [8/16] Loss: 0.57063  focal_loss 0.20589  dice_loss 0.36474 
Epoch [55/300] Validation [9/16] Loss: 0.40624  focal_loss 0.13540  dice_loss 0.27084 
Epoch [55/300] Validation [10/16] Loss: 0.44645  focal_loss 0.16032  dice_loss 0.28614 
Epoch [55/300] Validation [11/16] Loss: 0.24547  focal_loss 0.06340  dice_loss 0.18207 
Epoch [55/300] Validation [12/16] Loss: 0.39529  focal_loss 0.08376  dice_loss 0.31153 
Epoch [55/300] Validation [13/16] Loss: 0.44322  focal_loss 0.16526  dice_loss 0.27796 
Epoch [55/300] Validation [14/16] Loss: 0.70207  focal_loss 0.25104  dice_loss 0.45104 
Epoch [55/300] Validation [15/16] Loss: 0.21531  focal_loss 0.04847  dice_loss 0.16684 
Epoch [55/300] Validation [16/16] Loss: 0.13381  focal_loss 0.03374  dice_loss 0.10007 
Epoch [55/300] Validation metric {'Val/mean dice_metric': 0.7572292685508728, 'Val/mean miou_metric': 0.6560248136520386, 'Val/mean f1': 0.760661780834198, 'Val/mean precision': 0.7457006573677063, 'Val/mean recall': 0.7762355208396912, 'Val/mean hd95_metric': 52.517086029052734}
Cheakpoint...
Epoch [55/300] best acc:tensor([0.7614], device='cuda:0'), Now : mean acc: tensor([0.7572], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7572292685508728, 'Val/mean miou_metric': 0.6560248136520386, 'Val/mean f1': 0.760661780834198, 'Val/mean precision': 0.7457006573677063, 'Val/mean recall': 0.7762355208396912, 'Val/mean hd95_metric': 52.517086029052734}
Epoch [56/300] Training [1/62] Loss: 0.23231 
Epoch [56/300] Training [2/62] Loss: 0.31785 
Epoch [56/300] Training [3/62] Loss: 0.35220 
Epoch [56/300] Training [4/62] Loss: 0.66022 
Epoch [56/300] Training [5/62] Loss: 0.30809 
Epoch [56/300] Training [6/62] Loss: 0.51701 
Epoch [56/300] Training [7/62] Loss: 0.23812 
Epoch [56/300] Training [8/62] Loss: 0.14523 
Epoch [56/300] Training [9/62] Loss: 0.41478 
Epoch [56/300] Training [10/62] Loss: 0.33552 
Epoch [56/300] Training [11/62] Loss: 0.13684 
Epoch [56/300] Training [12/62] Loss: 0.21127 
Epoch [56/300] Training [13/62] Loss: 0.51721 
Epoch [56/300] Training [14/62] Loss: 0.28363 
Epoch [56/300] Training [15/62] Loss: 0.42380 
Epoch [56/300] Training [16/62] Loss: 0.31123 
Epoch [56/300] Training [17/62] Loss: 0.33727 
Epoch [56/300] Training [18/62] Loss: 0.29633 
Epoch [56/300] Training [19/62] Loss: 0.16401 
Epoch [56/300] Training [20/62] Loss: 0.37677 
Epoch [56/300] Training [21/62] Loss: 0.46001 
Epoch [56/300] Training [22/62] Loss: 0.40036 
Epoch [56/300] Training [23/62] Loss: 0.43814 
Epoch [56/300] Training [24/62] Loss: 0.38942 
Epoch [56/300] Training [25/62] Loss: 0.20494 
Epoch [56/300] Training [26/62] Loss: 0.46643 
Epoch [56/300] Training [27/62] Loss: 0.28844 
Epoch [56/300] Training [28/62] Loss: 0.30035 
Epoch [56/300] Training [29/62] Loss: 0.29487 
Epoch [56/300] Training [30/62] Loss: 0.64632 
Epoch [56/300] Training [31/62] Loss: 0.31659 
Epoch [56/300] Training [32/62] Loss: 0.38265 
Epoch [56/300] Training [33/62] Loss: 0.41881 
Epoch [56/300] Training [34/62] Loss: 0.35282 
Epoch [56/300] Training [35/62] Loss: 0.42903 
Epoch [56/300] Training [36/62] Loss: 0.41202 
Epoch [56/300] Training [37/62] Loss: 0.37424 
Epoch [56/300] Training [38/62] Loss: 0.34065 
Epoch [56/300] Training [39/62] Loss: 0.21248 
Epoch [56/300] Training [40/62] Loss: 0.23030 
Epoch [56/300] Training [41/62] Loss: 0.20086 
Epoch [56/300] Training [42/62] Loss: 0.48722 
Epoch [56/300] Training [43/62] Loss: 0.41802 
Epoch [56/300] Training [44/62] Loss: 0.26171 
Epoch [56/300] Training [45/62] Loss: 0.39096 
Epoch [56/300] Training [46/62] Loss: 0.26000 
Epoch [56/300] Training [47/62] Loss: 0.24649 
Epoch [56/300] Training [48/62] Loss: 0.15318 
Epoch [56/300] Training [49/62] Loss: 0.42572 
Epoch [56/300] Training [50/62] Loss: 0.26519 
Epoch [56/300] Training [51/62] Loss: 0.39460 
Epoch [56/300] Training [52/62] Loss: 0.35541 
Epoch [56/300] Training [53/62] Loss: 0.24736 
Epoch [56/300] Training [54/62] Loss: 0.30977 
Epoch [56/300] Training [55/62] Loss: 0.27401 
Epoch [56/300] Training [56/62] Loss: 0.24696 
Epoch [56/300] Training [57/62] Loss: 0.28531 
Epoch [56/300] Training [58/62] Loss: 0.44029 
Epoch [56/300] Training [59/62] Loss: 0.30079 
Epoch [56/300] Training [60/62] Loss: 0.30326 
Epoch [56/300] Training [61/62] Loss: 0.38568 
Epoch [56/300] Training [62/62] Loss: 0.10361 
Epoch [56/300] Training metric {'Train/mean dice_metric': 0.773281991481781, 'Train/mean miou_metric': 0.6743813157081604, 'Train/mean f1': 0.7861998677253723, 'Train/mean precision': 0.7752020359039307, 'Train/mean recall': 0.7975142002105713, 'Train/mean hd95_metric': 46.684608459472656}
Epoch [56/300] Validation [1/16] Loss: 0.41778  focal_loss 0.23226  dice_loss 0.18552 
Epoch [56/300] Validation [2/16] Loss: 0.38897  focal_loss 0.08363  dice_loss 0.30533 
Epoch [56/300] Validation [3/16] Loss: 0.63700  focal_loss 0.20881  dice_loss 0.42819 
Epoch [56/300] Validation [4/16] Loss: 0.30359  focal_loss 0.07229  dice_loss 0.23130 
Epoch [56/300] Validation [5/16] Loss: 0.41087  focal_loss 0.09877  dice_loss 0.31210 
Epoch [56/300] Validation [6/16] Loss: 0.31685  focal_loss 0.07419  dice_loss 0.24266 
Epoch [56/300] Validation [7/16] Loss: 0.50379  focal_loss 0.18118  dice_loss 0.32261 
Epoch [56/300] Validation [8/16] Loss: 0.61754  focal_loss 0.15947  dice_loss 0.45807 
Epoch [56/300] Validation [9/16] Loss: 0.32908  focal_loss 0.10597  dice_loss 0.22311 
Epoch [56/300] Validation [10/16] Loss: 0.52408  focal_loss 0.12986  dice_loss 0.39423 
Epoch [56/300] Validation [11/16] Loss: 0.24315  focal_loss 0.05957  dice_loss 0.18358 
Epoch [56/300] Validation [12/16] Loss: 0.43323  focal_loss 0.09882  dice_loss 0.33441 
Epoch [56/300] Validation [13/16] Loss: 0.39667  focal_loss 0.10111  dice_loss 0.29556 
Epoch [56/300] Validation [14/16] Loss: 0.84318  focal_loss 0.20170  dice_loss 0.64148 
Epoch [56/300] Validation [15/16] Loss: 0.39316  focal_loss 0.13227  dice_loss 0.26090 
Epoch [56/300] Validation [16/16] Loss: 0.19295  focal_loss 0.04108  dice_loss 0.15187 
Epoch [56/300] Validation metric {'Val/mean dice_metric': 0.7599530816078186, 'Val/mean miou_metric': 0.6599747538566589, 'Val/mean f1': 0.7694636583328247, 'Val/mean precision': 0.739693284034729, 'Val/mean recall': 0.8017308115959167, 'Val/mean hd95_metric': 50.34049987792969}
Cheakpoint...
Epoch [56/300] best acc:tensor([0.7614], device='cuda:0'), Now : mean acc: tensor([0.7600], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7599530816078186, 'Val/mean miou_metric': 0.6599747538566589, 'Val/mean f1': 0.7694636583328247, 'Val/mean precision': 0.739693284034729, 'Val/mean recall': 0.8017308115959167, 'Val/mean hd95_metric': 50.34049987792969}
Epoch [57/300] Training [1/62] Loss: 0.44496 
Epoch [57/300] Training [2/62] Loss: 0.46041 
Epoch [57/300] Training [3/62] Loss: 0.36517 
Epoch [57/300] Training [4/62] Loss: 0.39865 
Epoch [57/300] Training [5/62] Loss: 0.26520 
Epoch [57/300] Training [6/62] Loss: 0.35881 
Epoch [57/300] Training [7/62] Loss: 0.34970 
Epoch [57/300] Training [8/62] Loss: 0.29092 
Epoch [57/300] Training [9/62] Loss: 0.32084 
Epoch [57/300] Training [10/62] Loss: 0.24538 
Epoch [57/300] Training [11/62] Loss: 0.31468 
Epoch [57/300] Training [12/62] Loss: 0.25558 
Epoch [57/300] Training [13/62] Loss: 0.38565 
Epoch [57/300] Training [14/62] Loss: 0.20616 
Epoch [57/300] Training [15/62] Loss: 0.27846 
Epoch [57/300] Training [16/62] Loss: 0.51245 
Epoch [57/300] Training [17/62] Loss: 0.25153 
Epoch [57/300] Training [18/62] Loss: 0.33017 
Epoch [57/300] Training [19/62] Loss: 0.37231 
Epoch [57/300] Training [20/62] Loss: 0.37480 
Epoch [57/300] Training [21/62] Loss: 0.40660 
Epoch [57/300] Training [22/62] Loss: 0.42485 
Epoch [57/300] Training [23/62] Loss: 0.28749 
Epoch [57/300] Training [24/62] Loss: 0.33053 
Epoch [57/300] Training [25/62] Loss: 0.28202 
Epoch [57/300] Training [26/62] Loss: 0.21021 
Epoch [57/300] Training [27/62] Loss: 0.22625 
Epoch [57/300] Training [28/62] Loss: 0.16725 
Epoch [57/300] Training [29/62] Loss: 0.26515 
Epoch [57/300] Training [30/62] Loss: 0.26584 
Epoch [57/300] Training [31/62] Loss: 0.40405 
Epoch [57/300] Training [32/62] Loss: 0.21002 
Epoch [57/300] Training [33/62] Loss: 0.44554 
Epoch [57/300] Training [34/62] Loss: 0.28649 
Epoch [57/300] Training [35/62] Loss: 0.19165 
Epoch [57/300] Training [36/62] Loss: 0.21691 
Epoch [57/300] Training [37/62] Loss: 0.22485 
Epoch [57/300] Training [38/62] Loss: 0.44727 
Epoch [57/300] Training [39/62] Loss: 0.35346 
Epoch [57/300] Training [40/62] Loss: 0.16231 
Epoch [57/300] Training [41/62] Loss: 0.21374 
Epoch [57/300] Training [42/62] Loss: 0.32552 
Epoch [57/300] Training [43/62] Loss: 0.35675 
Epoch [57/300] Training [44/62] Loss: 0.32446 
Epoch [57/300] Training [45/62] Loss: 0.28360 
Epoch [57/300] Training [46/62] Loss: 0.26326 
Epoch [57/300] Training [47/62] Loss: 0.20756 
Epoch [57/300] Training [48/62] Loss: 0.39509 
Epoch [57/300] Training [49/62] Loss: 0.30827 
Epoch [57/300] Training [50/62] Loss: 0.31692 
Epoch [57/300] Training [51/62] Loss: 0.48544 
Epoch [57/300] Training [52/62] Loss: 0.25414 
Epoch [57/300] Training [53/62] Loss: 0.30066 
Epoch [57/300] Training [54/62] Loss: 0.31922 
Epoch [57/300] Training [55/62] Loss: 0.52838 
Epoch [57/300] Training [56/62] Loss: 0.40667 
Epoch [57/300] Training [57/62] Loss: 0.44671 
Epoch [57/300] Training [58/62] Loss: 0.43451 
Epoch [57/300] Training [59/62] Loss: 0.31120 
Epoch [57/300] Training [60/62] Loss: 0.40751 
Epoch [57/300] Training [61/62] Loss: 0.19341 
Epoch [57/300] Training [62/62] Loss: 0.59392 
Epoch [57/300] Training metric {'Train/mean dice_metric': 0.7779955267906189, 'Train/mean miou_metric': 0.6786232590675354, 'Train/mean f1': 0.8013976216316223, 'Train/mean precision': 0.7882317304611206, 'Train/mean recall': 0.8150107264518738, 'Train/mean hd95_metric': 45.84243392944336}
Epoch [57/300] Validation [1/16] Loss: 0.33823  focal_loss 0.09229  dice_loss 0.24594 
Epoch [57/300] Validation [2/16] Loss: 0.38933  focal_loss 0.05649  dice_loss 0.33284 
Epoch [57/300] Validation [3/16] Loss: 0.40191  focal_loss 0.06471  dice_loss 0.33719 
Epoch [57/300] Validation [4/16] Loss: 0.36908  focal_loss 0.10685  dice_loss 0.26223 
Epoch [57/300] Validation [5/16] Loss: 0.37957  focal_loss 0.04746  dice_loss 0.33211 
Epoch [57/300] Validation [6/16] Loss: 0.28331  focal_loss 0.02490  dice_loss 0.25841 
Epoch [57/300] Validation [7/16] Loss: 0.23947  focal_loss 0.04811  dice_loss 0.19137 
Epoch [57/300] Validation [8/16] Loss: 0.52459  focal_loss 0.08366  dice_loss 0.44093 
Epoch [57/300] Validation [9/16] Loss: 0.35005  focal_loss 0.04715  dice_loss 0.30290 
Epoch [57/300] Validation [10/16] Loss: 0.46368  focal_loss 0.09219  dice_loss 0.37149 
Epoch [57/300] Validation [11/16] Loss: 0.27199  focal_loss 0.04006  dice_loss 0.23193 
Epoch [57/300] Validation [12/16] Loss: 0.41107  focal_loss 0.06936  dice_loss 0.34171 
Epoch [57/300] Validation [13/16] Loss: 0.42147  focal_loss 0.13615  dice_loss 0.28532 
Epoch [57/300] Validation [14/16] Loss: 0.70674  focal_loss 0.19772  dice_loss 0.50903 
Epoch [57/300] Validation [15/16] Loss: 0.29892  focal_loss 0.05277  dice_loss 0.24615 
Epoch [57/300] Validation [16/16] Loss: 0.13413  focal_loss 0.01356  dice_loss 0.12057 
Epoch [57/300] Validation metric {'Val/mean dice_metric': 0.7685728669166565, 'Val/mean miou_metric': 0.6685923337936401, 'Val/mean f1': 0.7895259857177734, 'Val/mean precision': 0.7894957661628723, 'Val/mean recall': 0.7895563840866089, 'Val/mean hd95_metric': 47.66975402832031}
Cheakpoint...
Epoch [57/300] best acc:tensor([0.7686], device='cuda:0'), Now : mean acc: tensor([0.7686], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7685728669166565, 'Val/mean miou_metric': 0.6685923337936401, 'Val/mean f1': 0.7895259857177734, 'Val/mean precision': 0.7894957661628723, 'Val/mean recall': 0.7895563840866089, 'Val/mean hd95_metric': 47.66975402832031}
Epoch [58/300] Training [1/62] Loss: 0.31516 
Epoch [58/300] Training [2/62] Loss: 0.37929 
Epoch [58/300] Training [3/62] Loss: 0.35750 
Epoch [58/300] Training [4/62] Loss: 0.27069 
Epoch [58/300] Training [5/62] Loss: 0.77306 
Epoch [58/300] Training [6/62] Loss: 0.20521 
Epoch [58/300] Training [7/62] Loss: 0.30981 
Epoch [58/300] Training [8/62] Loss: 0.25330 
Epoch [58/300] Training [9/62] Loss: 0.46085 
Epoch [58/300] Training [10/62] Loss: 0.21297 
Epoch [58/300] Training [11/62] Loss: 0.36646 
Epoch [58/300] Training [12/62] Loss: 0.28319 
Epoch [58/300] Training [13/62] Loss: 0.47213 
Epoch [58/300] Training [14/62] Loss: 0.19542 
Epoch [58/300] Training [15/62] Loss: 0.53730 
Epoch [58/300] Training [16/62] Loss: 0.40769 
Epoch [58/300] Training [17/62] Loss: 0.33448 
Epoch [58/300] Training [18/62] Loss: 0.15452 
Epoch [58/300] Training [19/62] Loss: 0.21221 
Epoch [58/300] Training [20/62] Loss: 0.27797 
Epoch [58/300] Training [21/62] Loss: 0.44135 
Epoch [58/300] Training [22/62] Loss: 0.26023 
Epoch [58/300] Training [23/62] Loss: 0.23580 
Epoch [58/300] Training [24/62] Loss: 0.40385 
Epoch [58/300] Training [25/62] Loss: 0.30984 
Epoch [58/300] Training [26/62] Loss: 0.29530 
Epoch [58/300] Training [27/62] Loss: 0.18497 
Epoch [58/300] Training [28/62] Loss: 0.23178 
Epoch [58/300] Training [29/62] Loss: 0.25921 
Epoch [58/300] Training [30/62] Loss: 0.24520 
Epoch [58/300] Training [31/62] Loss: 0.28560 
Epoch [58/300] Training [32/62] Loss: 0.41629 
Epoch [58/300] Training [33/62] Loss: 0.36549 
Epoch [58/300] Training [34/62] Loss: 0.30124 
Epoch [58/300] Training [35/62] Loss: 0.23773 
Epoch [58/300] Training [36/62] Loss: 0.48753 
Epoch [58/300] Training [37/62] Loss: 0.23041 
Epoch [58/300] Training [38/62] Loss: 0.18935 
Epoch [58/300] Training [39/62] Loss: 0.33152 
Epoch [58/300] Training [40/62] Loss: 0.31787 
Epoch [58/300] Training [41/62] Loss: 0.34172 
Epoch [58/300] Training [42/62] Loss: 0.30647 
Epoch [58/300] Training [43/62] Loss: 0.27437 
Epoch [58/300] Training [44/62] Loss: 0.31353 
Epoch [58/300] Training [45/62] Loss: 0.33480 
Epoch [58/300] Training [46/62] Loss: 0.35159 
Epoch [58/300] Training [47/62] Loss: 0.81382 
Epoch [58/300] Training [48/62] Loss: 0.23399 
Epoch [58/300] Training [49/62] Loss: 0.19436 
Epoch [58/300] Training [50/62] Loss: 0.20627 
Epoch [58/300] Training [51/62] Loss: 0.33148 
Epoch [58/300] Training [52/62] Loss: 0.23458 
Epoch [58/300] Training [53/62] Loss: 0.35785 
Epoch [58/300] Training [54/62] Loss: 0.23939 
Epoch [58/300] Training [55/62] Loss: 0.17822 
Epoch [58/300] Training [56/62] Loss: 0.22498 
Epoch [58/300] Training [57/62] Loss: 0.21614 
Epoch [58/300] Training [58/62] Loss: 0.22762 
Epoch [58/300] Training [59/62] Loss: 0.13193 
Epoch [58/300] Training [60/62] Loss: 0.50995 
Epoch [58/300] Training [61/62] Loss: 0.28762 
Epoch [58/300] Training [62/62] Loss: 0.08234 
Epoch [58/300] Training metric {'Train/mean dice_metric': 0.7905899882316589, 'Train/mean miou_metric': 0.6916823983192444, 'Train/mean f1': 0.8008396625518799, 'Train/mean precision': 0.7967744469642639, 'Train/mean recall': 0.8049464821815491, 'Train/mean hd95_metric': 44.0605354309082}
Epoch [58/300] Validation [1/16] Loss: 0.38835  focal_loss 0.20259  dice_loss 0.18576 
Epoch [58/300] Validation [2/16] Loss: 0.45119  focal_loss 0.14550  dice_loss 0.30570 
Epoch [58/300] Validation [3/16] Loss: 0.71952  focal_loss 0.35378  dice_loss 0.36574 
Epoch [58/300] Validation [4/16] Loss: 0.35678  focal_loss 0.12380  dice_loss 0.23298 
Epoch [58/300] Validation [5/16] Loss: 0.46997  focal_loss 0.13689  dice_loss 0.33308 
Epoch [58/300] Validation [6/16] Loss: 0.29650  focal_loss 0.08122  dice_loss 0.21528 
Epoch [58/300] Validation [7/16] Loss: 0.17928  focal_loss 0.03511  dice_loss 0.14417 
Epoch [58/300] Validation [8/16] Loss: 0.57382  focal_loss 0.14297  dice_loss 0.43085 
Epoch [58/300] Validation [9/16] Loss: 0.26313  focal_loss 0.06890  dice_loss 0.19423 
Epoch [58/300] Validation [10/16] Loss: 0.22709  focal_loss 0.03824  dice_loss 0.18885 
Epoch [58/300] Validation [11/16] Loss: 0.21052  focal_loss 0.04869  dice_loss 0.16183 
Epoch [58/300] Validation [12/16] Loss: 0.35696  focal_loss 0.09698  dice_loss 0.25998 
Epoch [58/300] Validation [13/16] Loss: 0.34468  focal_loss 0.10894  dice_loss 0.23574 
Epoch [58/300] Validation [14/16] Loss: 0.57209  focal_loss 0.17875  dice_loss 0.39335 
Epoch [58/300] Validation [15/16] Loss: 0.28360  focal_loss 0.10276  dice_loss 0.18084 
Epoch [58/300] Validation [16/16] Loss: 0.09573  focal_loss 0.01958  dice_loss 0.07615 
Epoch [58/300] Validation metric {'Val/mean dice_metric': 0.7864285111427307, 'Val/mean miou_metric': 0.6891786456108093, 'Val/mean f1': 0.7936678528785706, 'Val/mean precision': 0.7889481782913208, 'Val/mean recall': 0.7984442114830017, 'Val/mean hd95_metric': 45.398765563964844}
Cheakpoint...
Epoch [58/300] best acc:tensor([0.7864], device='cuda:0'), Now : mean acc: tensor([0.7864], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7864285111427307, 'Val/mean miou_metric': 0.6891786456108093, 'Val/mean f1': 0.7936678528785706, 'Val/mean precision': 0.7889481782913208, 'Val/mean recall': 0.7984442114830017, 'Val/mean hd95_metric': 45.398765563964844}
Epoch [59/300] Training [1/62] Loss: 0.17129 
Epoch [59/300] Training [2/62] Loss: 0.15349 
Epoch [59/300] Training [3/62] Loss: 0.18989 
Epoch [59/300] Training [4/62] Loss: 0.26386 
Epoch [59/300] Training [5/62] Loss: 0.27724 
Epoch [59/300] Training [6/62] Loss: 0.35258 
Epoch [59/300] Training [7/62] Loss: 0.22215 
Epoch [59/300] Training [8/62] Loss: 0.40485 
Epoch [59/300] Training [9/62] Loss: 0.24506 
Epoch [59/300] Training [10/62] Loss: 0.35831 
Epoch [59/300] Training [11/62] Loss: 0.27639 
Epoch [59/300] Training [12/62] Loss: 0.24125 
Epoch [59/300] Training [13/62] Loss: 0.31274 
Epoch [59/300] Training [14/62] Loss: 0.27246 
Epoch [59/300] Training [15/62] Loss: 0.31555 
Epoch [59/300] Training [16/62] Loss: 0.34031 
Epoch [59/300] Training [17/62] Loss: 0.42577 
Epoch [59/300] Training [18/62] Loss: 0.24288 
Epoch [59/300] Training [19/62] Loss: 0.39255 
Epoch [59/300] Training [20/62] Loss: 0.38824 
Epoch [59/300] Training [21/62] Loss: 0.29131 
Epoch [59/300] Training [22/62] Loss: 0.18088 
Epoch [59/300] Training [23/62] Loss: 0.16272 
Epoch [59/300] Training [24/62] Loss: 0.25665 
Epoch [59/300] Training [25/62] Loss: 0.35185 
Epoch [59/300] Training [26/62] Loss: 0.35382 
Epoch [59/300] Training [27/62] Loss: 0.18794 
Epoch [59/300] Training [28/62] Loss: 0.22262 
Epoch [59/300] Training [29/62] Loss: 0.19218 
Epoch [59/300] Training [30/62] Loss: 0.15773 
Epoch [59/300] Training [31/62] Loss: 0.22262 
Epoch [59/300] Training [32/62] Loss: 0.29478 
Epoch [59/300] Training [33/62] Loss: 0.31377 
Epoch [59/300] Training [34/62] Loss: 0.29384 
Epoch [59/300] Training [35/62] Loss: 0.17678 
Epoch [59/300] Training [36/62] Loss: 0.54057 
Epoch [59/300] Training [37/62] Loss: 0.33869 
Epoch [59/300] Training [38/62] Loss: 0.35500 
Epoch [59/300] Training [39/62] Loss: 0.43150 
Epoch [59/300] Training [40/62] Loss: 0.26572 
Epoch [59/300] Training [41/62] Loss: 0.36688 
Epoch [59/300] Training [42/62] Loss: 0.33843 
Epoch [59/300] Training [43/62] Loss: 0.17989 
Epoch [59/300] Training [44/62] Loss: 0.39660 
Epoch [59/300] Training [45/62] Loss: 0.24270 
Epoch [59/300] Training [46/62] Loss: 0.37666 
Epoch [59/300] Training [47/62] Loss: 0.20595 
Epoch [59/300] Training [48/62] Loss: 0.42038 
Epoch [59/300] Training [49/62] Loss: 0.21839 
Epoch [59/300] Training [50/62] Loss: 0.48949 
Epoch [59/300] Training [51/62] Loss: 0.32866 
Epoch [59/300] Training [52/62] Loss: 0.28155 
Epoch [59/300] Training [53/62] Loss: 0.55520 
Epoch [59/300] Training [54/62] Loss: 0.53916 
Epoch [59/300] Training [55/62] Loss: 0.32752 
Epoch [59/300] Training [56/62] Loss: 0.27537 
Epoch [59/300] Training [57/62] Loss: 0.32003 
Epoch [59/300] Training [58/62] Loss: 0.28995 
Epoch [59/300] Training [59/62] Loss: 0.13546 
Epoch [59/300] Training [60/62] Loss: 0.29577 
Epoch [59/300] Training [61/62] Loss: 0.20224 
Epoch [59/300] Training [62/62] Loss: 0.15438 
Epoch [59/300] Training metric {'Train/mean dice_metric': 0.7962741255760193, 'Train/mean miou_metric': 0.7012158632278442, 'Train/mean f1': 0.8138538599014282, 'Train/mean precision': 0.8086632490158081, 'Train/mean recall': 0.8191115856170654, 'Train/mean hd95_metric': 41.038272857666016}
Epoch [59/300] Validation [1/16] Loss: 0.54091  focal_loss 0.22505  dice_loss 0.31586 
Epoch [59/300] Validation [2/16] Loss: 0.43147  focal_loss 0.10365  dice_loss 0.32782 
Epoch [59/300] Validation [3/16] Loss: 0.32755  focal_loss 0.07018  dice_loss 0.25738 
Epoch [59/300] Validation [4/16] Loss: 0.39936  focal_loss 0.11373  dice_loss 0.28564 
Epoch [59/300] Validation [5/16] Loss: 0.37026  focal_loss 0.06014  dice_loss 0.31012 
Epoch [59/300] Validation [6/16] Loss: 0.24050  focal_loss 0.05094  dice_loss 0.18956 
Epoch [59/300] Validation [7/16] Loss: 0.24998  focal_loss 0.06474  dice_loss 0.18524 
Epoch [59/300] Validation [8/16] Loss: 0.64383  focal_loss 0.20615  dice_loss 0.43768 
Epoch [59/300] Validation [9/16] Loss: 0.32005  focal_loss 0.09086  dice_loss 0.22920 
Epoch [59/300] Validation [10/16] Loss: 0.44854  focal_loss 0.11329  dice_loss 0.33525 
Epoch [59/300] Validation [11/16] Loss: 0.17462  focal_loss 0.03981  dice_loss 0.13480 
Epoch [59/300] Validation [12/16] Loss: 0.38717  focal_loss 0.09308  dice_loss 0.29409 
Epoch [59/300] Validation [13/16] Loss: 0.32915  focal_loss 0.05957  dice_loss 0.26958 
Epoch [59/300] Validation [14/16] Loss: 0.66625  focal_loss 0.20085  dice_loss 0.46540 
Epoch [59/300] Validation [15/16] Loss: 0.30381  focal_loss 0.08189  dice_loss 0.22192 
Epoch [59/300] Validation [16/16] Loss: 0.18035  focal_loss 0.04695  dice_loss 0.13340 
Epoch [59/300] Validation metric {'Val/mean dice_metric': 0.7845996618270874, 'Val/mean miou_metric': 0.6894568204879761, 'Val/mean f1': 0.793583869934082, 'Val/mean precision': 0.7776286005973816, 'Val/mean recall': 0.8102076053619385, 'Val/mean hd95_metric': 45.63630294799805}
Cheakpoint...
Epoch [59/300] best acc:tensor([0.7864], device='cuda:0'), Now : mean acc: tensor([0.7846], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7845996618270874, 'Val/mean miou_metric': 0.6894568204879761, 'Val/mean f1': 0.793583869934082, 'Val/mean precision': 0.7776286005973816, 'Val/mean recall': 0.8102076053619385, 'Val/mean hd95_metric': 45.63630294799805}
Epoch [60/300] Training [1/62] Loss: 0.14697 
Epoch [60/300] Training [2/62] Loss: 0.17423 
Epoch [60/300] Training [3/62] Loss: 0.11834 
Epoch [60/300] Training [4/62] Loss: 0.33413 
Epoch [60/300] Training [5/62] Loss: 0.55146 
Epoch [60/300] Training [6/62] Loss: 0.36048 
Epoch [60/300] Training [7/62] Loss: 0.39088 
Epoch [60/300] Training [8/62] Loss: 0.28974 
Epoch [60/300] Training [9/62] Loss: 0.13140 
Epoch [60/300] Training [10/62] Loss: 0.49230 
Epoch [60/300] Training [11/62] Loss: 0.31466 
Epoch [60/300] Training [12/62] Loss: 0.41539 
Epoch [60/300] Training [13/62] Loss: 0.22144 
Epoch [60/300] Training [14/62] Loss: 0.18125 
Epoch [60/300] Training [15/62] Loss: 0.17842 
Epoch [60/300] Training [16/62] Loss: 0.40668 
Epoch [60/300] Training [17/62] Loss: 0.27119 
Epoch [60/300] Training [18/62] Loss: 0.23028 
Epoch [60/300] Training [19/62] Loss: 0.29623 
Epoch [60/300] Training [20/62] Loss: 0.41738 
Epoch [60/300] Training [21/62] Loss: 0.33457 
Epoch [60/300] Training [22/62] Loss: 0.27051 
Epoch [60/300] Training [23/62] Loss: 0.25927 
Epoch [60/300] Training [24/62] Loss: 0.22850 
Epoch [60/300] Training [25/62] Loss: 0.42151 
Epoch [60/300] Training [26/62] Loss: 0.40978 
Epoch [60/300] Training [27/62] Loss: 0.29626 
Epoch [60/300] Training [28/62] Loss: 0.39604 
Epoch [60/300] Training [29/62] Loss: 0.27798 
Epoch [60/300] Training [30/62] Loss: 0.42153 
Epoch [60/300] Training [31/62] Loss: 0.31330 
Epoch [60/300] Training [32/62] Loss: 0.32943 
Epoch [60/300] Training [33/62] Loss: 0.27559 
Epoch [60/300] Training [34/62] Loss: 0.25773 
Epoch [60/300] Training [35/62] Loss: 0.39011 
Epoch [60/300] Training [36/62] Loss: 0.21117 
Epoch [60/300] Training [37/62] Loss: 0.36511 
Epoch [60/300] Training [38/62] Loss: 0.28175 
Epoch [60/300] Training [39/62] Loss: 0.35672 
Epoch [60/300] Training [40/62] Loss: 0.41705 
Epoch [60/300] Training [41/62] Loss: 0.33072 
Epoch [60/300] Training [42/62] Loss: 0.30350 
Epoch [60/300] Training [43/62] Loss: 0.32096 
Epoch [60/300] Training [44/62] Loss: 0.29242 
Epoch [60/300] Training [45/62] Loss: 0.30554 
Epoch [60/300] Training [46/62] Loss: 0.38194 
Epoch [60/300] Training [47/62] Loss: 0.32085 
Epoch [60/300] Training [48/62] Loss: 0.30383 
Epoch [60/300] Training [49/62] Loss: 0.36279 
Epoch [60/300] Training [50/62] Loss: 0.41476 
Epoch [60/300] Training [51/62] Loss: 0.33369 
Epoch [60/300] Training [52/62] Loss: 0.51728 
Epoch [60/300] Training [53/62] Loss: 0.25777 
Epoch [60/300] Training [54/62] Loss: 0.18994 
Epoch [60/300] Training [55/62] Loss: 0.19980 
Epoch [60/300] Training [56/62] Loss: 0.36214 
Epoch [60/300] Training [57/62] Loss: 0.27132 
Epoch [60/300] Training [58/62] Loss: 0.20217 
Epoch [60/300] Training [59/62] Loss: 0.16680 
Epoch [60/300] Training [60/62] Loss: 0.43663 
Epoch [60/300] Training [61/62] Loss: 0.58017 
Epoch [60/300] Training [62/62] Loss: 0.21443 
Epoch [60/300] Training metric {'Train/mean dice_metric': 0.786904513835907, 'Train/mean miou_metric': 0.6897504329681396, 'Train/mean f1': 0.7987340092658997, 'Train/mean precision': 0.786904513835907, 'Train/mean recall': 0.8109246492385864, 'Train/mean hd95_metric': 45.42898941040039}
Epoch [60/300] Validation [1/16] Loss: 0.27314  focal_loss 0.07773  dice_loss 0.19541 
Epoch [60/300] Validation [2/16] Loss: 0.47632  focal_loss 0.12110  dice_loss 0.35523 
Epoch [60/300] Validation [3/16] Loss: 0.61894  focal_loss 0.14933  dice_loss 0.46961 
Epoch [60/300] Validation [4/16] Loss: 0.49761  focal_loss 0.13817  dice_loss 0.35944 
Epoch [60/300] Validation [5/16] Loss: 0.46881  focal_loss 0.07137  dice_loss 0.39744 
Epoch [60/300] Validation [6/16] Loss: 0.45617  focal_loss 0.10749  dice_loss 0.34868 
Epoch [60/300] Validation [7/16] Loss: 0.37022  focal_loss 0.08187  dice_loss 0.28836 
Epoch [60/300] Validation [8/16] Loss: 0.72739  focal_loss 0.19440  dice_loss 0.53299 
Epoch [60/300] Validation [9/16] Loss: 0.42074  focal_loss 0.09136  dice_loss 0.32938 
Epoch [60/300] Validation [10/16] Loss: 0.54404  focal_loss 0.13755  dice_loss 0.40650 
Epoch [60/300] Validation [11/16] Loss: 0.37350  focal_loss 0.08237  dice_loss 0.29113 
Epoch [60/300] Validation [12/16] Loss: 0.63490  focal_loss 0.13540  dice_loss 0.49950 
Epoch [60/300] Validation [13/16] Loss: 0.57087  focal_loss 0.13712  dice_loss 0.43374 
Epoch [60/300] Validation [14/16] Loss: 0.72089  focal_loss 0.19692  dice_loss 0.52396 
Epoch [60/300] Validation [15/16] Loss: 0.20966  focal_loss 0.02697  dice_loss 0.18268 
Epoch [60/300] Validation [16/16] Loss: 0.25440  focal_loss 0.03746  dice_loss 0.21694 
Epoch [60/300] Validation metric {'Val/mean dice_metric': 0.7637927532196045, 'Val/mean miou_metric': 0.6649898886680603, 'Val/mean f1': 0.7683253884315491, 'Val/mean precision': 0.7240424156188965, 'Val/mean recall': 0.8183779716491699, 'Val/mean hd95_metric': 51.91233825683594}
Cheakpoint...
Epoch [60/300] best acc:tensor([0.7864], device='cuda:0'), Now : mean acc: tensor([0.7638], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7637927532196045, 'Val/mean miou_metric': 0.6649898886680603, 'Val/mean f1': 0.7683253884315491, 'Val/mean precision': 0.7240424156188965, 'Val/mean recall': 0.8183779716491699, 'Val/mean hd95_metric': 51.91233825683594}
Epoch [61/300] Training [1/62] Loss: 0.33817 
Epoch [61/300] Training [2/62] Loss: 0.44623 
Epoch [61/300] Training [3/62] Loss: 0.28957 
Epoch [61/300] Training [4/62] Loss: 0.27011 
Epoch [61/300] Training [5/62] Loss: 0.45890 
Epoch [61/300] Training [6/62] Loss: 0.46969 
Epoch [61/300] Training [7/62] Loss: 0.38365 
Epoch [61/300] Training [8/62] Loss: 0.18334 
Epoch [61/300] Training [9/62] Loss: 0.67194 
Epoch [61/300] Training [10/62] Loss: 0.55422 
Epoch [61/300] Training [11/62] Loss: 0.34072 
Epoch [61/300] Training [12/62] Loss: 0.38548 
Epoch [61/300] Training [13/62] Loss: 0.32596 
Epoch [61/300] Training [14/62] Loss: 0.26424 
Epoch [61/300] Training [15/62] Loss: 0.22111 
Epoch [61/300] Training [16/62] Loss: 0.26821 
Epoch [61/300] Training [17/62] Loss: 0.26604 
Epoch [61/300] Training [18/62] Loss: 0.30758 
Epoch [61/300] Training [19/62] Loss: 0.09428 
Epoch [61/300] Training [20/62] Loss: 0.20394 
Epoch [61/300] Training [21/62] Loss: 0.27342 
Epoch [61/300] Training [22/62] Loss: 0.36314 
Epoch [61/300] Training [23/62] Loss: 0.35350 
Epoch [61/300] Training [24/62] Loss: 0.20173 
Epoch [61/300] Training [25/62] Loss: 0.50353 
Epoch [61/300] Training [26/62] Loss: 0.25746 
Epoch [61/300] Training [27/62] Loss: 0.16060 
Epoch [61/300] Training [28/62] Loss: 0.32853 
Epoch [61/300] Training [29/62] Loss: 0.24946 
Epoch [61/300] Training [30/62] Loss: 0.20687 
Epoch [61/300] Training [31/62] Loss: 0.27360 
Epoch [61/300] Training [32/62] Loss: 0.34284 
Epoch [61/300] Training [33/62] Loss: 0.31814 
Epoch [61/300] Training [34/62] Loss: 0.38500 
Epoch [61/300] Training [35/62] Loss: 0.18637 
Epoch [61/300] Training [36/62] Loss: 0.33629 
Epoch [61/300] Training [37/62] Loss: 0.55963 
Epoch [61/300] Training [38/62] Loss: 0.22399 
Epoch [61/300] Training [39/62] Loss: 0.27292 
Epoch [61/300] Training [40/62] Loss: 0.28057 
Epoch [61/300] Training [41/62] Loss: 0.25207 
Epoch [61/300] Training [42/62] Loss: 0.21872 
Epoch [61/300] Training [43/62] Loss: 0.20354 
Epoch [61/300] Training [44/62] Loss: 0.30623 
Epoch [61/300] Training [45/62] Loss: 0.37899 
Epoch [61/300] Training [46/62] Loss: 0.30172 
Epoch [61/300] Training [47/62] Loss: 0.59474 
Epoch [61/300] Training [48/62] Loss: 0.42596 
Epoch [61/300] Training [49/62] Loss: 0.40514 
Epoch [61/300] Training [50/62] Loss: 0.23422 
Epoch [61/300] Training [51/62] Loss: 0.29526 
Epoch [61/300] Training [52/62] Loss: 0.27342 
Epoch [61/300] Training [53/62] Loss: 0.33950 
Epoch [61/300] Training [54/62] Loss: 0.23836 
Epoch [61/300] Training [55/62] Loss: 0.57116 
Epoch [61/300] Training [56/62] Loss: 0.22483 
Epoch [61/300] Training [57/62] Loss: 0.38799 
Epoch [61/300] Training [58/62] Loss: 0.32548 
Epoch [61/300] Training [59/62] Loss: 0.48940 
Epoch [61/300] Training [60/62] Loss: 0.35220 
Epoch [61/300] Training [61/62] Loss: 0.29022 
Epoch [61/300] Training [62/62] Loss: 0.18305 
Epoch [61/300] Training metric {'Train/mean dice_metric': 0.7796688079833984, 'Train/mean miou_metric': 0.6833544969558716, 'Train/mean f1': 0.7892354726791382, 'Train/mean precision': 0.7750115990638733, 'Train/mean recall': 0.8039911985397339, 'Train/mean hd95_metric': 45.932796478271484}
Epoch [61/300] Validation [1/16] Loss: 0.16280  focal_loss 0.03601  dice_loss 0.12679 
Epoch [61/300] Validation [2/16] Loss: 0.39174  focal_loss 0.09717  dice_loss 0.29457 
Epoch [61/300] Validation [3/16] Loss: 0.58963  focal_loss 0.17540  dice_loss 0.41423 
Epoch [61/300] Validation [4/16] Loss: 0.44317  focal_loss 0.15228  dice_loss 0.29089 
Epoch [61/300] Validation [5/16] Loss: 0.34705  focal_loss 0.05990  dice_loss 0.28715 
Epoch [61/300] Validation [6/16] Loss: 0.28218  focal_loss 0.04112  dice_loss 0.24106 
Epoch [61/300] Validation [7/16] Loss: 0.26824  focal_loss 0.05544  dice_loss 0.21280 
Epoch [61/300] Validation [8/16] Loss: 0.47390  focal_loss 0.08105  dice_loss 0.39285 
Epoch [61/300] Validation [9/16] Loss: 0.41692  focal_loss 0.15333  dice_loss 0.26359 
Epoch [61/300] Validation [10/16] Loss: 0.39959  focal_loss 0.08925  dice_loss 0.31034 
Epoch [61/300] Validation [11/16] Loss: 0.28063  focal_loss 0.04775  dice_loss 0.23288 
Epoch [61/300] Validation [12/16] Loss: 0.47142  focal_loss 0.07278  dice_loss 0.39864 
Epoch [61/300] Validation [13/16] Loss: 0.41720  focal_loss 0.10968  dice_loss 0.30752 
Epoch [61/300] Validation [14/16] Loss: 0.66269  focal_loss 0.18293  dice_loss 0.47975 
Epoch [61/300] Validation [15/16] Loss: 0.19596  focal_loss 0.03729  dice_loss 0.15867 
Epoch [61/300] Validation [16/16] Loss: 0.11587  focal_loss 0.02559  dice_loss 0.09028 
Epoch [61/300] Validation metric {'Val/mean dice_metric': 0.7718406915664673, 'Val/mean miou_metric': 0.674426794052124, 'Val/mean f1': 0.7800881862640381, 'Val/mean precision': 0.7591744661331177, 'Val/mean recall': 0.8021869659423828, 'Val/mean hd95_metric': 49.27342987060547}
Cheakpoint...
Epoch [61/300] best acc:tensor([0.7864], device='cuda:0'), Now : mean acc: tensor([0.7718], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7718406915664673, 'Val/mean miou_metric': 0.674426794052124, 'Val/mean f1': 0.7800881862640381, 'Val/mean precision': 0.7591744661331177, 'Val/mean recall': 0.8021869659423828, 'Val/mean hd95_metric': 49.27342987060547}
Epoch [62/300] Training [1/62] Loss: 0.20783 
Epoch [62/300] Training [2/62] Loss: 0.25522 
Epoch [62/300] Training [3/62] Loss: 0.29847 
Epoch [62/300] Training [4/62] Loss: 0.34583 
Epoch [62/300] Training [5/62] Loss: 0.37376 
Epoch [62/300] Training [6/62] Loss: 0.28049 
Epoch [62/300] Training [7/62] Loss: 0.38211 
Epoch [62/300] Training [8/62] Loss: 0.29838 
Epoch [62/300] Training [9/62] Loss: 0.34651 
Epoch [62/300] Training [10/62] Loss: 0.45681 
Epoch [62/300] Training [11/62] Loss: 0.21855 
Epoch [62/300] Training [12/62] Loss: 0.31752 
Epoch [62/300] Training [13/62] Loss: 0.25590 
Epoch [62/300] Training [14/62] Loss: 0.25856 
Epoch [62/300] Training [15/62] Loss: 0.45796 
Epoch [62/300] Training [16/62] Loss: 0.33306 
Epoch [62/300] Training [17/62] Loss: 0.34677 
Epoch [62/300] Training [18/62] Loss: 0.26445 
Epoch [62/300] Training [19/62] Loss: 0.26784 
Epoch [62/300] Training [20/62] Loss: 0.33818 
Epoch [62/300] Training [21/62] Loss: 0.33523 
Epoch [62/300] Training [22/62] Loss: 0.18855 
Epoch [62/300] Training [23/62] Loss: 0.18005 
Epoch [62/300] Training [24/62] Loss: 0.11364 
Epoch [62/300] Training [25/62] Loss: 0.22504 
Epoch [62/300] Training [26/62] Loss: 0.38372 
Epoch [62/300] Training [27/62] Loss: 0.26762 
Epoch [62/300] Training [28/62] Loss: 0.18769 
Epoch [62/300] Training [29/62] Loss: 0.28816 
Epoch [62/300] Training [30/62] Loss: 0.47702 
Epoch [62/300] Training [31/62] Loss: 0.26253 
Epoch [62/300] Training [32/62] Loss: 0.42432 
Epoch [62/300] Training [33/62] Loss: 0.42526 
Epoch [62/300] Training [34/62] Loss: 0.34203 
Epoch [62/300] Training [35/62] Loss: 0.30198 
Epoch [62/300] Training [36/62] Loss: 0.20798 
Epoch [62/300] Training [37/62] Loss: 0.39834 
Epoch [62/300] Training [38/62] Loss: 0.27581 
Epoch [62/300] Training [39/62] Loss: 0.24243 
Epoch [62/300] Training [40/62] Loss: 0.16433 
Epoch [62/300] Training [41/62] Loss: 0.16313 
Epoch [62/300] Training [42/62] Loss: 0.32623 
Epoch [62/300] Training [43/62] Loss: 0.19831 
Epoch [62/300] Training [44/62] Loss: 0.24806 
Epoch [62/300] Training [45/62] Loss: 0.18623 
Epoch [62/300] Training [46/62] Loss: 0.28349 
Epoch [62/300] Training [47/62] Loss: 0.27271 
Epoch [62/300] Training [48/62] Loss: 0.21200 
Epoch [62/300] Training [49/62] Loss: 0.20662 
Epoch [62/300] Training [50/62] Loss: 0.17679 
Epoch [62/300] Training [51/62] Loss: 0.28625 
Epoch [62/300] Training [52/62] Loss: 0.35260 
Epoch [62/300] Training [53/62] Loss: 0.32497 
Epoch [62/300] Training [54/62] Loss: 0.20371 
Epoch [62/300] Training [55/62] Loss: 0.15179 
Epoch [62/300] Training [56/62] Loss: 0.27032 
Epoch [62/300] Training [57/62] Loss: 0.22087 
Epoch [62/300] Training [58/62] Loss: 0.37834 
Epoch [62/300] Training [59/62] Loss: 0.28546 
Epoch [62/300] Training [60/62] Loss: 0.27396 
Epoch [62/300] Training [61/62] Loss: 0.14893 
Epoch [62/300] Training [62/62] Loss: 0.03947 
Epoch [62/300] Training metric {'Train/mean dice_metric': 0.8065818548202515, 'Train/mean miou_metric': 0.7119726538658142, 'Train/mean f1': 0.8257021307945251, 'Train/mean precision': 0.8172074556350708, 'Train/mean recall': 0.834375262260437, 'Train/mean hd95_metric': 43.22785186767578}
Epoch [62/300] Validation [1/16] Loss: 0.23616  focal_loss 0.07574  dice_loss 0.16042 
Epoch [62/300] Validation [2/16] Loss: 0.45026  focal_loss 0.11540  dice_loss 0.33486 
Epoch [62/300] Validation [3/16] Loss: 0.52704  focal_loss 0.17940  dice_loss 0.34764 
Epoch [62/300] Validation [4/16] Loss: 0.21957  focal_loss 0.05531  dice_loss 0.16426 
Epoch [62/300] Validation [5/16] Loss: 0.34710  focal_loss 0.06970  dice_loss 0.27740 
Epoch [62/300] Validation [6/16] Loss: 0.25534  focal_loss 0.05955  dice_loss 0.19579 
Epoch [62/300] Validation [7/16] Loss: 0.38333  focal_loss 0.14519  dice_loss 0.23814 
Epoch [62/300] Validation [8/16] Loss: 0.56192  focal_loss 0.19317  dice_loss 0.36875 
Epoch [62/300] Validation [9/16] Loss: 0.35178  focal_loss 0.12571  dice_loss 0.22607 
Epoch [62/300] Validation [10/16] Loss: 0.60709  focal_loss 0.21666  dice_loss 0.39044 
Epoch [62/300] Validation [11/16] Loss: 0.25443  focal_loss 0.06644  dice_loss 0.18800 
Epoch [62/300] Validation [12/16] Loss: 0.39526  focal_loss 0.08311  dice_loss 0.31215 
Epoch [62/300] Validation [13/16] Loss: 0.36417  focal_loss 0.11280  dice_loss 0.25137 
Epoch [62/300] Validation [14/16] Loss: 0.55245  focal_loss 0.19157  dice_loss 0.36088 
Epoch [62/300] Validation [15/16] Loss: 0.24367  focal_loss 0.08063  dice_loss 0.16304 
Epoch [62/300] Validation [16/16] Loss: 0.21948  focal_loss 0.03531  dice_loss 0.18418 
Epoch [62/300] Validation metric {'Val/mean dice_metric': 0.796245276927948, 'Val/mean miou_metric': 0.7005389928817749, 'Val/mean f1': 0.812323272228241, 'Val/mean precision': 0.7879734635353088, 'Val/mean recall': 0.8382259011268616, 'Val/mean hd95_metric': 46.332759857177734}
Cheakpoint...
Epoch [62/300] best acc:tensor([0.7962], device='cuda:0'), Now : mean acc: tensor([0.7962], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.796245276927948, 'Val/mean miou_metric': 0.7005389928817749, 'Val/mean f1': 0.812323272228241, 'Val/mean precision': 0.7879734635353088, 'Val/mean recall': 0.8382259011268616, 'Val/mean hd95_metric': 46.332759857177734}
Epoch [63/300] Training [1/62] Loss: 0.40353 
Epoch [63/300] Training [2/62] Loss: 0.56945 
Epoch [63/300] Training [3/62] Loss: 0.16580 
Epoch [63/300] Training [4/62] Loss: 0.16480 
Epoch [63/300] Training [5/62] Loss: 0.12795 
Epoch [63/300] Training [6/62] Loss: 0.20438 
Epoch [63/300] Training [7/62] Loss: 0.16163 
Epoch [63/300] Training [8/62] Loss: 0.21415 
Epoch [63/300] Training [9/62] Loss: 0.14279 
Epoch [63/300] Training [10/62] Loss: 0.41038 
Epoch [63/300] Training [11/62] Loss: 0.24981 
Epoch [63/300] Training [12/62] Loss: 0.19659 
Epoch [63/300] Training [13/62] Loss: 0.30955 
Epoch [63/300] Training [14/62] Loss: 0.23832 
Epoch [63/300] Training [15/62] Loss: 0.42300 
Epoch [63/300] Training [16/62] Loss: 0.24659 
Epoch [63/300] Training [17/62] Loss: 0.31064 
Epoch [63/300] Training [18/62] Loss: 0.30021 
Epoch [63/300] Training [19/62] Loss: 0.14667 
Epoch [63/300] Training [20/62] Loss: 0.26766 
Epoch [63/300] Training [21/62] Loss: 0.29934 
Epoch [63/300] Training [22/62] Loss: 0.30222 
Epoch [63/300] Training [23/62] Loss: 0.22419 
Epoch [63/300] Training [24/62] Loss: 0.15977 
Epoch [63/300] Training [25/62] Loss: 0.31549 
Epoch [63/300] Training [26/62] Loss: 0.22920 
Epoch [63/300] Training [27/62] Loss: 0.53402 
Epoch [63/300] Training [28/62] Loss: 0.35090 
Epoch [63/300] Training [29/62] Loss: 0.30765 
Epoch [63/300] Training [30/62] Loss: 0.28669 
Epoch [63/300] Training [31/62] Loss: 0.27201 
Epoch [63/300] Training [32/62] Loss: 0.23213 
Epoch [63/300] Training [33/62] Loss: 0.21411 
Epoch [63/300] Training [34/62] Loss: 0.35720 
Epoch [63/300] Training [35/62] Loss: 0.33747 
Epoch [63/300] Training [36/62] Loss: 0.30625 
Epoch [63/300] Training [37/62] Loss: 0.25368 
Epoch [63/300] Training [38/62] Loss: 0.31319 
Epoch [63/300] Training [39/62] Loss: 0.22708 
Epoch [63/300] Training [40/62] Loss: 0.40688 
Epoch [63/300] Training [41/62] Loss: 0.17254 
Epoch [63/300] Training [42/62] Loss: 0.30851 
Epoch [63/300] Training [43/62] Loss: 0.23550 
Epoch [63/300] Training [44/62] Loss: 0.20489 
Epoch [63/300] Training [45/62] Loss: 0.39887 
Epoch [63/300] Training [46/62] Loss: 0.19081 
Epoch [63/300] Training [47/62] Loss: 0.19840 
Epoch [63/300] Training [48/62] Loss: 0.17730 
Epoch [63/300] Training [49/62] Loss: 0.51798 
Epoch [63/300] Training [50/62] Loss: 0.24276 
Epoch [63/300] Training [51/62] Loss: 0.15932 
Epoch [63/300] Training [52/62] Loss: 0.26940 
Epoch [63/300] Training [53/62] Loss: 0.27506 
Epoch [63/300] Training [54/62] Loss: 0.25447 
Epoch [63/300] Training [55/62] Loss: 0.40024 
Epoch [63/300] Training [56/62] Loss: 0.17812 
Epoch [63/300] Training [57/62] Loss: 0.30145 
Epoch [63/300] Training [58/62] Loss: 0.17064 
Epoch [63/300] Training [59/62] Loss: 0.16415 
Epoch [63/300] Training [60/62] Loss: 0.18057 
Epoch [63/300] Training [61/62] Loss: 0.28743 
Epoch [63/300] Training [62/62] Loss: 0.07967 
Epoch [63/300] Training metric {'Train/mean dice_metric': 0.8182229399681091, 'Train/mean miou_metric': 0.7271233201026917, 'Train/mean f1': 0.830977737903595, 'Train/mean precision': 0.8218980431556702, 'Train/mean recall': 0.8402603268623352, 'Train/mean hd95_metric': 37.55132293701172}
Epoch [63/300] Validation [1/16] Loss: 0.17650  focal_loss 0.03335  dice_loss 0.14314 
Epoch [63/300] Validation [2/16] Loss: 0.47260  focal_loss 0.15019  dice_loss 0.32241 
Epoch [63/300] Validation [3/16] Loss: 0.38474  focal_loss 0.08554  dice_loss 0.29920 
Epoch [63/300] Validation [4/16] Loss: 0.36298  focal_loss 0.09393  dice_loss 0.26905 
Epoch [63/300] Validation [5/16] Loss: 0.36069  focal_loss 0.05779  dice_loss 0.30290 
Epoch [63/300] Validation [6/16] Loss: 0.23713  focal_loss 0.02703  dice_loss 0.21010 
Epoch [63/300] Validation [7/16] Loss: 0.31835  focal_loss 0.06311  dice_loss 0.25524 
Epoch [63/300] Validation [8/16] Loss: 0.37365  focal_loss 0.06586  dice_loss 0.30779 
Epoch [63/300] Validation [9/16] Loss: 0.31261  focal_loss 0.05405  dice_loss 0.25857 
Epoch [63/300] Validation [10/16] Loss: 0.39429  focal_loss 0.09618  dice_loss 0.29812 
Epoch [63/300] Validation [11/16] Loss: 0.36244  focal_loss 0.07370  dice_loss 0.28874 
Epoch [63/300] Validation [12/16] Loss: 0.45584  focal_loss 0.10972  dice_loss 0.34612 
Epoch [63/300] Validation [13/16] Loss: 0.39003  focal_loss 0.09189  dice_loss 0.29814 
Epoch [63/300] Validation [14/16] Loss: 0.71261  focal_loss 0.18704  dice_loss 0.52557 
Epoch [63/300] Validation [15/16] Loss: 0.23253  focal_loss 0.04040  dice_loss 0.19213 
Epoch [63/300] Validation [16/16] Loss: 0.10403  focal_loss 0.01332  dice_loss 0.09071 
Epoch [63/300] Validation metric {'Val/mean dice_metric': 0.8050587177276611, 'Val/mean miou_metric': 0.7132558822631836, 'Val/mean f1': 0.8135835528373718, 'Val/mean precision': 0.7882093191146851, 'Val/mean recall': 0.8406456708908081, 'Val/mean hd95_metric': 42.65830993652344}
Cheakpoint...
Epoch [63/300] best acc:tensor([0.8051], device='cuda:0'), Now : mean acc: tensor([0.8051], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8050587177276611, 'Val/mean miou_metric': 0.7132558822631836, 'Val/mean f1': 0.8135835528373718, 'Val/mean precision': 0.7882093191146851, 'Val/mean recall': 0.8406456708908081, 'Val/mean hd95_metric': 42.65830993652344}
Epoch [64/300] Training [1/62] Loss: 0.29731 
Epoch [64/300] Training [2/62] Loss: 0.29000 
Epoch [64/300] Training [3/62] Loss: 0.26885 
Epoch [64/300] Training [4/62] Loss: 0.42913 
Epoch [64/300] Training [5/62] Loss: 0.30383 
Epoch [64/300] Training [6/62] Loss: 0.18017 
Epoch [64/300] Training [7/62] Loss: 0.19488 
Epoch [64/300] Training [8/62] Loss: 0.17922 
Epoch [64/300] Training [9/62] Loss: 0.15635 
Epoch [64/300] Training [10/62] Loss: 0.17054 
Epoch [64/300] Training [11/62] Loss: 0.26419 
Epoch [64/300] Training [12/62] Loss: 0.27953 
Epoch [64/300] Training [13/62] Loss: 0.23793 
Epoch [64/300] Training [14/62] Loss: 0.43288 
Epoch [64/300] Training [15/62] Loss: 0.31288 
Epoch [64/300] Training [16/62] Loss: 0.21492 
Epoch [64/300] Training [17/62] Loss: 0.38474 
Epoch [64/300] Training [18/62] Loss: 0.44920 
Epoch [64/300] Training [19/62] Loss: 0.26057 
Epoch [64/300] Training [20/62] Loss: 0.24758 
Epoch [64/300] Training [21/62] Loss: 0.17644 
Epoch [64/300] Training [22/62] Loss: 0.48103 
Epoch [64/300] Training [23/62] Loss: 0.41145 
Epoch [64/300] Training [24/62] Loss: 0.34914 
Epoch [64/300] Training [25/62] Loss: 0.41725 
Epoch [64/300] Training [26/62] Loss: 0.19738 
Epoch [64/300] Training [27/62] Loss: 0.25172 
Epoch [64/300] Training [28/62] Loss: 0.35888 
Epoch [64/300] Training [29/62] Loss: 0.26807 
Epoch [64/300] Training [30/62] Loss: 0.25559 
Epoch [64/300] Training [31/62] Loss: 0.33144 
Epoch [64/300] Training [32/62] Loss: 0.26412 
Epoch [64/300] Training [33/62] Loss: 0.23197 
Epoch [64/300] Training [34/62] Loss: 0.23323 
Epoch [64/300] Training [35/62] Loss: 0.32063 
Epoch [64/300] Training [36/62] Loss: 0.25670 
Epoch [64/300] Training [37/62] Loss: 0.33992 
Epoch [64/300] Training [38/62] Loss: 0.21110 
Epoch [64/300] Training [39/62] Loss: 0.24592 
Epoch [64/300] Training [40/62] Loss: 0.17526 
Epoch [64/300] Training [41/62] Loss: 0.14581 
Epoch [64/300] Training [42/62] Loss: 0.31972 
Epoch [64/300] Training [43/62] Loss: 0.24204 
Epoch [64/300] Training [44/62] Loss: 0.35483 
Epoch [64/300] Training [45/62] Loss: 0.18622 
Epoch [64/300] Training [46/62] Loss: 0.59488 
Epoch [64/300] Training [47/62] Loss: 0.64691 
Epoch [64/300] Training [48/62] Loss: 0.19767 
Epoch [64/300] Training [49/62] Loss: 0.19619 
Epoch [64/300] Training [50/62] Loss: 0.34538 
Epoch [64/300] Training [51/62] Loss: 0.27990 
Epoch [64/300] Training [52/62] Loss: 0.50248 
Epoch [64/300] Training [53/62] Loss: 0.25777 
Epoch [64/300] Training [54/62] Loss: 0.23392 
Epoch [64/300] Training [55/62] Loss: 0.25724 
Epoch [64/300] Training [56/62] Loss: 0.50019 
Epoch [64/300] Training [57/62] Loss: 0.41687 
Epoch [64/300] Training [58/62] Loss: 0.23124 
Epoch [64/300] Training [59/62] Loss: 0.23602 
Epoch [64/300] Training [60/62] Loss: 0.20978 
Epoch [64/300] Training [61/62] Loss: 0.18004 
Epoch [64/300] Training [62/62] Loss: 0.50611 
Epoch [64/300] Training metric {'Train/mean dice_metric': 0.804789125919342, 'Train/mean miou_metric': 0.706464946269989, 'Train/mean f1': 0.8188680410385132, 'Train/mean precision': 0.8162097334861755, 'Train/mean recall': 0.82154381275177, 'Train/mean hd95_metric': 40.766536712646484}
Epoch [64/300] Validation [1/16] Loss: 0.32093  focal_loss 0.08202  dice_loss 0.23891 
Epoch [64/300] Validation [2/16] Loss: 0.53115  focal_loss 0.14177  dice_loss 0.38938 
Epoch [64/300] Validation [3/16] Loss: 0.40909  focal_loss 0.08905  dice_loss 0.32004 
Epoch [64/300] Validation [4/16] Loss: 0.41631  focal_loss 0.10207  dice_loss 0.31423 
Epoch [64/300] Validation [5/16] Loss: 0.42109  focal_loss 0.06032  dice_loss 0.36078 
Epoch [64/300] Validation [6/16] Loss: 0.36063  focal_loss 0.04696  dice_loss 0.31367 
Epoch [64/300] Validation [7/16] Loss: 0.27974  focal_loss 0.05422  dice_loss 0.22552 
Epoch [64/300] Validation [8/16] Loss: 0.53573  focal_loss 0.09218  dice_loss 0.44354 
Epoch [64/300] Validation [9/16] Loss: 0.35018  focal_loss 0.07914  dice_loss 0.27104 
Epoch [64/300] Validation [10/16] Loss: 0.44568  focal_loss 0.08726  dice_loss 0.35842 
Epoch [64/300] Validation [11/16] Loss: 0.28997  focal_loss 0.06673  dice_loss 0.22324 
Epoch [64/300] Validation [12/16] Loss: 0.54490  focal_loss 0.10904  dice_loss 0.43586 
Epoch [64/300] Validation [13/16] Loss: 0.48947  focal_loss 0.12745  dice_loss 0.36202 
Epoch [64/300] Validation [14/16] Loss: 0.73742  focal_loss 0.20450  dice_loss 0.53292 
Epoch [64/300] Validation [15/16] Loss: 0.25786  focal_loss 0.05662  dice_loss 0.20124 
Epoch [64/300] Validation [16/16] Loss: 0.21223  focal_loss 0.02025  dice_loss 0.19198 
Epoch [64/300] Validation metric {'Val/mean dice_metric': 0.7842414975166321, 'Val/mean miou_metric': 0.6840056777000427, 'Val/mean f1': 0.7930444478988647, 'Val/mean precision': 0.7644138336181641, 'Val/mean recall': 0.8239031434059143, 'Val/mean hd95_metric': 46.874088287353516}
Cheakpoint...
Epoch [64/300] best acc:tensor([0.8051], device='cuda:0'), Now : mean acc: tensor([0.7842], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7842414975166321, 'Val/mean miou_metric': 0.6840056777000427, 'Val/mean f1': 0.7930444478988647, 'Val/mean precision': 0.7644138336181641, 'Val/mean recall': 0.8239031434059143, 'Val/mean hd95_metric': 46.874088287353516}
Epoch [65/300] Training [1/62] Loss: 0.49970 
Epoch [65/300] Training [2/62] Loss: 0.31022 
Epoch [65/300] Training [3/62] Loss: 0.55546 
Epoch [65/300] Training [4/62] Loss: 0.37497 
Epoch [65/300] Training [5/62] Loss: 0.27188 
Epoch [65/300] Training [6/62] Loss: 0.42795 
Epoch [65/300] Training [7/62] Loss: 0.54105 
Epoch [65/300] Training [8/62] Loss: 0.21879 
Epoch [65/300] Training [9/62] Loss: 0.29349 
Epoch [65/300] Training [10/62] Loss: 0.22974 
Epoch [65/300] Training [11/62] Loss: 0.17765 
Epoch [65/300] Training [12/62] Loss: 0.39780 
Epoch [65/300] Training [13/62] Loss: 0.67619 
Epoch [65/300] Training [14/62] Loss: 0.22388 
Epoch [65/300] Training [15/62] Loss: 0.28792 
Epoch [65/300] Training [16/62] Loss: 0.42384 
Epoch [65/300] Training [17/62] Loss: 0.46126 
Epoch [65/300] Training [18/62] Loss: 0.32993 
Epoch [65/300] Training [19/62] Loss: 0.37792 
Epoch [65/300] Training [20/62] Loss: 0.20308 
Epoch [65/300] Training [21/62] Loss: 0.21029 
Epoch [65/300] Training [22/62] Loss: 0.20425 
Epoch [65/300] Training [23/62] Loss: 0.50918 
Epoch [65/300] Training [24/62] Loss: 0.47166 
Epoch [65/300] Training [25/62] Loss: 0.30693 
Epoch [65/300] Training [26/62] Loss: 0.22242 
Epoch [65/300] Training [27/62] Loss: 0.44828 
Epoch [65/300] Training [28/62] Loss: 0.27377 
Epoch [65/300] Training [29/62] Loss: 0.29226 
Epoch [65/300] Training [30/62] Loss: 0.31686 
Epoch [65/300] Training [31/62] Loss: 0.28769 
Epoch [65/300] Training [32/62] Loss: 0.25980 
Epoch [65/300] Training [33/62] Loss: 0.12981 
Epoch [65/300] Training [34/62] Loss: 0.20748 
Epoch [65/300] Training [35/62] Loss: 0.21618 
Epoch [65/300] Training [36/62] Loss: 0.24508 
Epoch [65/300] Training [37/62] Loss: 0.23021 
Epoch [65/300] Training [38/62] Loss: 0.17086 
Epoch [65/300] Training [39/62] Loss: 0.42356 
Epoch [65/300] Training [40/62] Loss: 0.44182 
Epoch [65/300] Training [41/62] Loss: 0.15108 
Epoch [65/300] Training [42/62] Loss: 0.12539 
Epoch [65/300] Training [43/62] Loss: 0.29916 
Epoch [65/300] Training [44/62] Loss: 0.17184 
Epoch [65/300] Training [45/62] Loss: 0.24577 
Epoch [65/300] Training [46/62] Loss: 0.12452 
Epoch [65/300] Training [47/62] Loss: 0.36367 
Epoch [65/300] Training [48/62] Loss: 0.32891 
Epoch [65/300] Training [49/62] Loss: 0.24024 
Epoch [65/300] Training [50/62] Loss: 0.18570 
Epoch [65/300] Training [51/62] Loss: 0.27849 
Epoch [65/300] Training [52/62] Loss: 0.26288 
Epoch [65/300] Training [53/62] Loss: 0.15354 
Epoch [65/300] Training [54/62] Loss: 0.43918 
Epoch [65/300] Training [55/62] Loss: 0.23995 
Epoch [65/300] Training [56/62] Loss: 0.26648 
Epoch [65/300] Training [57/62] Loss: 0.18214 
Epoch [65/300] Training [58/62] Loss: 0.25591 
Epoch [65/300] Training [59/62] Loss: 0.29289 
Epoch [65/300] Training [60/62] Loss: 0.30757 
Epoch [65/300] Training [61/62] Loss: 0.35498 
Epoch [65/300] Training [62/62] Loss: 0.27380 
Epoch [65/300] Training metric {'Train/mean dice_metric': 0.7970796823501587, 'Train/mean miou_metric': 0.7008288502693176, 'Train/mean f1': 0.8062379360198975, 'Train/mean precision': 0.7888509035110474, 'Train/mean recall': 0.8244088292121887, 'Train/mean hd95_metric': 44.14754104614258}
Epoch [65/300] Validation [1/16] Loss: 0.13997  focal_loss 0.04436  dice_loss 0.09561 
Epoch [65/300] Validation [2/16] Loss: 0.39399  focal_loss 0.13458  dice_loss 0.25942 
Epoch [65/300] Validation [3/16] Loss: 0.71448  focal_loss 0.36695  dice_loss 0.34753 
Epoch [65/300] Validation [4/16] Loss: 0.36541  focal_loss 0.13136  dice_loss 0.23405 
Epoch [65/300] Validation [5/16] Loss: 0.32385  focal_loss 0.08249  dice_loss 0.24136 
Epoch [65/300] Validation [6/16] Loss: 0.25187  focal_loss 0.05484  dice_loss 0.19703 
Epoch [65/300] Validation [7/16] Loss: 0.24629  focal_loss 0.08549  dice_loss 0.16080 
Epoch [65/300] Validation [8/16] Loss: 0.36947  focal_loss 0.10203  dice_loss 0.26745 
Epoch [65/300] Validation [9/16] Loss: 0.27834  focal_loss 0.08424  dice_loss 0.19410 
Epoch [65/300] Validation [10/16] Loss: 0.36055  focal_loss 0.09777  dice_loss 0.26278 
Epoch [65/300] Validation [11/16] Loss: 0.26082  focal_loss 0.06878  dice_loss 0.19205 
Epoch [65/300] Validation [12/16] Loss: 0.36948  focal_loss 0.07969  dice_loss 0.28980 
Epoch [65/300] Validation [13/16] Loss: 0.40973  focal_loss 0.14220  dice_loss 0.26753 
Epoch [65/300] Validation [14/16] Loss: 0.61158  focal_loss 0.20905  dice_loss 0.40252 
Epoch [65/300] Validation [15/16] Loss: 0.28157  focal_loss 0.11107  dice_loss 0.17050 
Epoch [65/300] Validation [16/16] Loss: 0.09317  focal_loss 0.01860  dice_loss 0.07457 
Epoch [65/300] Validation metric {'Val/mean dice_metric': 0.7936587929725647, 'Val/mean miou_metric': 0.6975263953208923, 'Val/mean f1': 0.7992306351661682, 'Val/mean precision': 0.7807906866073608, 'Val/mean recall': 0.8185626864433289, 'Val/mean hd95_metric': 45.604957580566406}
Cheakpoint...
Epoch [65/300] best acc:tensor([0.8051], device='cuda:0'), Now : mean acc: tensor([0.7937], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.7936587929725647, 'Val/mean miou_metric': 0.6975263953208923, 'Val/mean f1': 0.7992306351661682, 'Val/mean precision': 0.7807906866073608, 'Val/mean recall': 0.8185626864433289, 'Val/mean hd95_metric': 45.604957580566406}
Epoch [66/300] Training [1/62] Loss: 0.28074 
Epoch [66/300] Training [2/62] Loss: 0.29045 
Epoch [66/300] Training [3/62] Loss: 0.44945 
Epoch [66/300] Training [4/62] Loss: 0.13791 
Epoch [66/300] Training [5/62] Loss: 0.28106 
Epoch [66/300] Training [6/62] Loss: 0.71750 
Epoch [66/300] Training [7/62] Loss: 0.22511 
Epoch [66/300] Training [8/62] Loss: 0.24412 
Epoch [66/300] Training [9/62] Loss: 0.19260 
Epoch [66/300] Training [10/62] Loss: 0.27162 
Epoch [66/300] Training [11/62] Loss: 0.27241 
Epoch [66/300] Training [12/62] Loss: 0.34213 
Epoch [66/300] Training [13/62] Loss: 0.32562 
Epoch [66/300] Training [14/62] Loss: 0.35302 
Epoch [66/300] Training [15/62] Loss: 0.16474 
Epoch [66/300] Training [16/62] Loss: 0.39000 
Epoch [66/300] Training [17/62] Loss: 0.27375 
Epoch [66/300] Training [18/62] Loss: 0.13111 
Epoch [66/300] Training [19/62] Loss: 0.44264 
Epoch [66/300] Training [20/62] Loss: 0.34956 
Epoch [66/300] Training [21/62] Loss: 0.36938 
Epoch [66/300] Training [22/62] Loss: 0.23295 
Epoch [66/300] Training [23/62] Loss: 0.40358 
Epoch [66/300] Training [24/62] Loss: 0.34869 
Epoch [66/300] Training [25/62] Loss: 0.24228 
Epoch [66/300] Training [26/62] Loss: 0.30108 
Epoch [66/300] Training [27/62] Loss: 0.18446 
Epoch [66/300] Training [28/62] Loss: 0.16535 
Epoch [66/300] Training [29/62] Loss: 0.23253 
Epoch [66/300] Training [30/62] Loss: 0.36187 
Epoch [66/300] Training [31/62] Loss: 0.41772 
Epoch [66/300] Training [32/62] Loss: 0.20601 
Epoch [66/300] Training [33/62] Loss: 0.17864 
Epoch [66/300] Training [34/62] Loss: 0.18464 
Epoch [66/300] Training [35/62] Loss: 0.23168 
Epoch [66/300] Training [36/62] Loss: 0.29358 
Epoch [66/300] Training [37/62] Loss: 0.33710 
Epoch [66/300] Training [38/62] Loss: 0.20409 
Epoch [66/300] Training [39/62] Loss: 0.26281 
Epoch [66/300] Training [40/62] Loss: 0.32670 
Epoch [66/300] Training [41/62] Loss: 0.33752 
Epoch [66/300] Training [42/62] Loss: 0.24642 
Epoch [66/300] Training [43/62] Loss: 0.31022 
Epoch [66/300] Training [44/62] Loss: 0.41072 
Epoch [66/300] Training [45/62] Loss: 0.22081 
Epoch [66/300] Training [46/62] Loss: 0.16931 
Epoch [66/300] Training [47/62] Loss: 0.20088 
Epoch [66/300] Training [48/62] Loss: 0.31948 
Epoch [66/300] Training [49/62] Loss: 0.22495 
Epoch [66/300] Training [50/62] Loss: 0.36554 
Epoch [66/300] Training [51/62] Loss: 0.22329 
Epoch [66/300] Training [52/62] Loss: 0.25429 
Epoch [66/300] Training [53/62] Loss: 0.43455 
Epoch [66/300] Training [54/62] Loss: 0.17389 
Epoch [66/300] Training [55/62] Loss: 0.24688 
Epoch [66/300] Training [56/62] Loss: 0.43912 
Epoch [66/300] Training [57/62] Loss: 0.18807 
Epoch [66/300] Training [58/62] Loss: 0.28342 
Epoch [66/300] Training [59/62] Loss: 0.19100 
Epoch [66/300] Training [60/62] Loss: 0.37680 
Epoch [66/300] Training [61/62] Loss: 0.19504 
Epoch [66/300] Training [62/62] Loss: 0.65351 
Epoch [66/300] Training metric {'Train/mean dice_metric': 0.8103520274162292, 'Train/mean miou_metric': 0.7157052159309387, 'Train/mean f1': 0.8224188685417175, 'Train/mean precision': 0.8087947964668274, 'Train/mean recall': 0.8365098237991333, 'Train/mean hd95_metric': 40.564876556396484}
Epoch [66/300] Validation [1/16] Loss: 0.31647  focal_loss 0.09174  dice_loss 0.22472 
Epoch [66/300] Validation [2/16] Loss: 0.49170  focal_loss 0.14803  dice_loss 0.34367 
Epoch [66/300] Validation [3/16] Loss: 0.36899  focal_loss 0.08162  dice_loss 0.28737 
Epoch [66/300] Validation [4/16] Loss: 0.44388  focal_loss 0.18163  dice_loss 0.26225 
Epoch [66/300] Validation [5/16] Loss: 0.44481  focal_loss 0.08819  dice_loss 0.35662 
Epoch [66/300] Validation [6/16] Loss: 0.39791  focal_loss 0.13262  dice_loss 0.26529 
Epoch [66/300] Validation [7/16] Loss: 0.32592  focal_loss 0.10848  dice_loss 0.21743 
Epoch [66/300] Validation [8/16] Loss: 0.33922  focal_loss 0.06054  dice_loss 0.27868 
Epoch [66/300] Validation [9/16] Loss: 0.20592  focal_loss 0.04167  dice_loss 0.16424 
Epoch [66/300] Validation [10/16] Loss: 0.45963  focal_loss 0.13404  dice_loss 0.32559 
Epoch [66/300] Validation [11/16] Loss: 0.27575  focal_loss 0.07257  dice_loss 0.20317 
Epoch [66/300] Validation [12/16] Loss: 0.34342  focal_loss 0.06554  dice_loss 0.27788 
Epoch [66/300] Validation [13/16] Loss: 0.38854  focal_loss 0.11939  dice_loss 0.26916 
Epoch [66/300] Validation [14/16] Loss: 0.63047  focal_loss 0.16526  dice_loss 0.46521 
Epoch [66/300] Validation [15/16] Loss: 0.18996  focal_loss 0.04281  dice_loss 0.14715 
Epoch [66/300] Validation [16/16] Loss: 0.17782  focal_loss 0.04090  dice_loss 0.13692 
Epoch [66/300] Validation metric {'Val/mean dice_metric': 0.799283504486084, 'Val/mean miou_metric': 0.7032515406608582, 'Val/mean f1': 0.8089799880981445, 'Val/mean precision': 0.8022428750991821, 'Val/mean recall': 0.815831184387207, 'Val/mean hd95_metric': 42.892276763916016}
Cheakpoint...
Epoch [66/300] best acc:tensor([0.8051], device='cuda:0'), Now : mean acc: tensor([0.7993], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.799283504486084, 'Val/mean miou_metric': 0.7032515406608582, 'Val/mean f1': 0.8089799880981445, 'Val/mean precision': 0.8022428750991821, 'Val/mean recall': 0.815831184387207, 'Val/mean hd95_metric': 42.892276763916016}
Epoch [67/300] Training [1/62] Loss: 0.20695 
Epoch [67/300] Training [2/62] Loss: 0.22820 
Epoch [67/300] Training [3/62] Loss: 0.47205 
Epoch [67/300] Training [4/62] Loss: 0.33051 
Epoch [67/300] Training [5/62] Loss: 0.28009 
Epoch [67/300] Training [6/62] Loss: 0.29448 
Epoch [67/300] Training [7/62] Loss: 0.25412 
Epoch [67/300] Training [8/62] Loss: 0.28704 
Epoch [67/300] Training [9/62] Loss: 0.34537 
Epoch [67/300] Training [10/62] Loss: 0.30717 
Epoch [67/300] Training [11/62] Loss: 0.25597 
Epoch [67/300] Training [12/62] Loss: 0.31149 
Epoch [67/300] Training [13/62] Loss: 0.29386 
Epoch [67/300] Training [14/62] Loss: 0.36183 
Epoch [67/300] Training [15/62] Loss: 0.32901 
Epoch [67/300] Training [16/62] Loss: 0.24460 
Epoch [67/300] Training [17/62] Loss: 0.36320 
Epoch [67/300] Training [18/62] Loss: 0.26325 
Epoch [67/300] Training [19/62] Loss: 0.42401 
Epoch [67/300] Training [20/62] Loss: 0.34761 
Epoch [67/300] Training [21/62] Loss: 0.15043 
Epoch [67/300] Training [22/62] Loss: 0.33157 
Epoch [67/300] Training [23/62] Loss: 0.24308 
Epoch [67/300] Training [24/62] Loss: 0.20724 
Epoch [67/300] Training [25/62] Loss: 0.21554 
Epoch [67/300] Training [26/62] Loss: 0.18620 
Epoch [67/300] Training [27/62] Loss: 0.34553 
Epoch [67/300] Training [28/62] Loss: 0.34460 
Epoch [67/300] Training [29/62] Loss: 0.29230 
Epoch [67/300] Training [30/62] Loss: 0.32970 
Epoch [67/300] Training [31/62] Loss: 0.20247 
Epoch [67/300] Training [32/62] Loss: 0.32155 
Epoch [67/300] Training [33/62] Loss: 0.21908 
Epoch [67/300] Training [34/62] Loss: 0.22654 
Epoch [67/300] Training [35/62] Loss: 0.28108 
Epoch [67/300] Training [36/62] Loss: 0.17035 
Epoch [67/300] Training [37/62] Loss: 0.25863 
Epoch [67/300] Training [38/62] Loss: 0.12872 
Epoch [67/300] Training [39/62] Loss: 0.15461 
Epoch [67/300] Training [40/62] Loss: 0.12013 
Epoch [67/300] Training [41/62] Loss: 0.28564 
Epoch [67/300] Training [42/62] Loss: 0.32920 
Epoch [67/300] Training [43/62] Loss: 0.34633 
Epoch [67/300] Training [44/62] Loss: 0.15984 
Epoch [67/300] Training [45/62] Loss: 0.40439 
Epoch [67/300] Training [46/62] Loss: 0.40496 
Epoch [67/300] Training [47/62] Loss: 0.28390 
Epoch [67/300] Training [48/62] Loss: 0.14941 
Epoch [67/300] Training [49/62] Loss: 0.40133 
Epoch [67/300] Training [50/62] Loss: 0.28583 
Epoch [67/300] Training [51/62] Loss: 0.18540 
Epoch [67/300] Training [52/62] Loss: 0.35812 
Epoch [67/300] Training [53/62] Loss: 0.34571 
Epoch [67/300] Training [54/62] Loss: 0.39279 
Epoch [67/300] Training [55/62] Loss: 0.23219 
Epoch [67/300] Training [56/62] Loss: 0.36052 
Epoch [67/300] Training [57/62] Loss: 0.45038 
Epoch [67/300] Training [58/62] Loss: 0.39478 
Epoch [67/300] Training [59/62] Loss: 0.40319 
Epoch [67/300] Training [60/62] Loss: 0.12232 
Epoch [67/300] Training [61/62] Loss: 0.26236 
Epoch [67/300] Training [62/62] Loss: 0.06764 
Epoch [67/300] Training metric {'Train/mean dice_metric': 0.8044186234474182, 'Train/mean miou_metric': 0.7098721265792847, 'Train/mean f1': 0.814602255821228, 'Train/mean precision': 0.800511360168457, 'Train/mean recall': 0.8291981220245361, 'Train/mean hd95_metric': 40.92195129394531}
Epoch [67/300] Validation [1/16] Loss: 0.52562  focal_loss 0.27745  dice_loss 0.24816 
Epoch [67/300] Validation [2/16] Loss: 0.41381  focal_loss 0.14817  dice_loss 0.26564 
Epoch [67/300] Validation [3/16] Loss: 0.40793  focal_loss 0.10343  dice_loss 0.30450 
Epoch [67/300] Validation [4/16] Loss: 0.26511  focal_loss 0.08191  dice_loss 0.18319 
Epoch [67/300] Validation [5/16] Loss: 0.39805  focal_loss 0.07810  dice_loss 0.31995 
Epoch [67/300] Validation [6/16] Loss: 0.29646  focal_loss 0.07312  dice_loss 0.22334 
Epoch [67/300] Validation [7/16] Loss: 0.35231  focal_loss 0.12434  dice_loss 0.22797 
Epoch [67/300] Validation [8/16] Loss: 0.41620  focal_loss 0.13350  dice_loss 0.28270 
Epoch [67/300] Validation [9/16] Loss: 0.28066  focal_loss 0.05315  dice_loss 0.22750 
Epoch [67/300] Validation [10/16] Loss: 0.52139  focal_loss 0.10291  dice_loss 0.41849 
Epoch [67/300] Validation [11/16] Loss: 0.25252  focal_loss 0.08730  dice_loss 0.16523 
Epoch [67/300] Validation [12/16] Loss: 0.29995  focal_loss 0.04925  dice_loss 0.25070 
Epoch [67/300] Validation [13/16] Loss: 0.37170  focal_loss 0.10417  dice_loss 0.26753 
Epoch [67/300] Validation [14/16] Loss: 0.52518  focal_loss 0.13136  dice_loss 0.39382 
Epoch [67/300] Validation [15/16] Loss: 0.25371  focal_loss 0.08976  dice_loss 0.16395 
Epoch [67/300] Validation [16/16] Loss: 0.13485  focal_loss 0.03961  dice_loss 0.09525 
Epoch [67/300] Validation metric {'Val/mean dice_metric': 0.79616379737854, 'Val/mean miou_metric': 0.700427234172821, 'Val/mean f1': 0.8042462468147278, 'Val/mean precision': 0.7945545315742493, 'Val/mean recall': 0.814177393913269, 'Val/mean hd95_metric': 44.67881774902344}
Cheakpoint...
Epoch [67/300] best acc:tensor([0.8051], device='cuda:0'), Now : mean acc: tensor([0.7962], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.79616379737854, 'Val/mean miou_metric': 0.700427234172821, 'Val/mean f1': 0.8042462468147278, 'Val/mean precision': 0.7945545315742493, 'Val/mean recall': 0.814177393913269, 'Val/mean hd95_metric': 44.67881774902344}
Epoch [68/300] Training [1/62] Loss: 0.11670 
Epoch [68/300] Training [2/62] Loss: 0.24339 
Epoch [68/300] Training [3/62] Loss: 0.15437 
Epoch [68/300] Training [4/62] Loss: 0.26915 
Epoch [68/300] Training [5/62] Loss: 0.28329 
Epoch [68/300] Training [6/62] Loss: 0.19569 
Epoch [68/300] Training [7/62] Loss: 0.17116 
Epoch [68/300] Training [8/62] Loss: 0.27865 
Epoch [68/300] Training [9/62] Loss: 0.25096 
Epoch [68/300] Training [10/62] Loss: 0.16395 
Epoch [68/300] Training [11/62] Loss: 0.32731 
Epoch [68/300] Training [12/62] Loss: 0.19771 
Epoch [68/300] Training [13/62] Loss: 0.10593 
Epoch [68/300] Training [14/62] Loss: 0.22885 
Epoch [68/300] Training [15/62] Loss: 0.19386 
Epoch [68/300] Training [16/62] Loss: 0.42418 
Epoch [68/300] Training [17/62] Loss: 0.19946 
Epoch [68/300] Training [18/62] Loss: 0.30480 
Epoch [68/300] Training [19/62] Loss: 0.38191 
Epoch [68/300] Training [20/62] Loss: 0.23972 
Epoch [68/300] Training [21/62] Loss: 0.26772 
Epoch [68/300] Training [22/62] Loss: 0.28991 
Epoch [68/300] Training [23/62] Loss: 0.40295 
Epoch [68/300] Training [24/62] Loss: 0.43051 
Epoch [68/300] Training [25/62] Loss: 0.43017 
Epoch [68/300] Training [26/62] Loss: 0.17448 
Epoch [68/300] Training [27/62] Loss: 0.37508 
Epoch [68/300] Training [28/62] Loss: 0.10740 
Epoch [68/300] Training [29/62] Loss: 0.20372 
Epoch [68/300] Training [30/62] Loss: 0.32202 
Epoch [68/300] Training [31/62] Loss: 0.23485 
Epoch [68/300] Training [32/62] Loss: 0.16653 
Epoch [68/300] Training [33/62] Loss: 0.29879 
Epoch [68/300] Training [34/62] Loss: 0.39030 
Epoch [68/300] Training [35/62] Loss: 0.26871 
Epoch [68/300] Training [36/62] Loss: 0.32617 
Epoch [68/300] Training [37/62] Loss: 0.39617 
Epoch [68/300] Training [38/62] Loss: 0.35311 
Epoch [68/300] Training [39/62] Loss: 0.18744 
Epoch [68/300] Training [40/62] Loss: 0.24022 
Epoch [68/300] Training [41/62] Loss: 0.19056 
Epoch [68/300] Training [42/62] Loss: 0.32170 
Epoch [68/300] Training [43/62] Loss: 0.24142 
Epoch [68/300] Training [44/62] Loss: 0.17246 
Epoch [68/300] Training [45/62] Loss: 0.39861 
Epoch [68/300] Training [46/62] Loss: 0.28968 
Epoch [68/300] Training [47/62] Loss: 0.11423 
Epoch [68/300] Training [48/62] Loss: 0.26427 
Epoch [68/300] Training [49/62] Loss: 0.33217 
Epoch [68/300] Training [50/62] Loss: 0.25009 
Epoch [68/300] Training [51/62] Loss: 0.21015 
Epoch [68/300] Training [52/62] Loss: 0.35730 
Epoch [68/300] Training [53/62] Loss: 0.29054 
Epoch [68/300] Training [54/62] Loss: 0.32284 
Epoch [68/300] Training [55/62] Loss: 0.23105 
Epoch [68/300] Training [56/62] Loss: 0.20588 
Epoch [68/300] Training [57/62] Loss: 0.22044 
Epoch [68/300] Training [58/62] Loss: 0.32335 
Epoch [68/300] Training [59/62] Loss: 0.23730 
Epoch [68/300] Training [60/62] Loss: 0.23671 
Epoch [68/300] Training [61/62] Loss: 0.36976 
Epoch [68/300] Training [62/62] Loss: 0.17084 
Epoch [68/300] Training metric {'Train/mean dice_metric': 0.8184067010879517, 'Train/mean miou_metric': 0.7256935238838196, 'Train/mean f1': 0.8335855603218079, 'Train/mean precision': 0.8259186148643494, 'Train/mean recall': 0.8413960933685303, 'Train/mean hd95_metric': 36.510616302490234}
Epoch [68/300] Validation [1/16] Loss: 0.13874  focal_loss 0.03513  dice_loss 0.10361 
Epoch [68/300] Validation [2/16] Loss: 0.35063  focal_loss 0.08429  dice_loss 0.26634 
Epoch [68/300] Validation [3/16] Loss: 0.42203  focal_loss 0.12995  dice_loss 0.29208 
Epoch [68/300] Validation [4/16] Loss: 0.28289  focal_loss 0.07989  dice_loss 0.20301 
Epoch [68/300] Validation [5/16] Loss: 0.27089  focal_loss 0.04611  dice_loss 0.22477 
Epoch [68/300] Validation [6/16] Loss: 0.25313  focal_loss 0.06647  dice_loss 0.18665 
Epoch [68/300] Validation [7/16] Loss: 0.29372  focal_loss 0.09334  dice_loss 0.20038 
Epoch [68/300] Validation [8/16] Loss: 0.39711  focal_loss 0.10988  dice_loss 0.28723 
Epoch [68/300] Validation [9/16] Loss: 0.25483  focal_loss 0.05959  dice_loss 0.19524 
Epoch [68/300] Validation [10/16] Loss: 0.45596  focal_loss 0.16207  dice_loss 0.29389 
Epoch [68/300] Validation [11/16] Loss: 0.20596  focal_loss 0.03888  dice_loss 0.16708 
Epoch [68/300] Validation [12/16] Loss: 0.37747  focal_loss 0.10116  dice_loss 0.27632 
Epoch [68/300] Validation [13/16] Loss: 0.30195  focal_loss 0.06849  dice_loss 0.23346 
Epoch [68/300] Validation [14/16] Loss: 0.39406  focal_loss 0.07031  dice_loss 0.32375 
Epoch [68/300] Validation [15/16] Loss: 0.15600  focal_loss 0.03818  dice_loss 0.11782 
Epoch [68/300] Validation [16/16] Loss: 0.10511  focal_loss 0.01943  dice_loss 0.08568 
Epoch [68/300] Validation metric {'Val/mean dice_metric': 0.8154758214950562, 'Val/mean miou_metric': 0.7229657173156738, 'Val/mean f1': 0.8257467746734619, 'Val/mean precision': 0.8097668886184692, 'Val/mean recall': 0.8423699736595154, 'Val/mean hd95_metric': 39.094600677490234}
Cheakpoint...
Epoch [68/300] best acc:tensor([0.8155], device='cuda:0'), Now : mean acc: tensor([0.8155], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8154758214950562, 'Val/mean miou_metric': 0.7229657173156738, 'Val/mean f1': 0.8257467746734619, 'Val/mean precision': 0.8097668886184692, 'Val/mean recall': 0.8423699736595154, 'Val/mean hd95_metric': 39.094600677490234}
Epoch [69/300] Training [1/62] Loss: 0.22912 
Epoch [69/300] Training [2/62] Loss: 0.32391 
Epoch [69/300] Training [3/62] Loss: 0.15685 
Epoch [69/300] Training [4/62] Loss: 0.27662 
Epoch [69/300] Training [5/62] Loss: 0.17185 
Epoch [69/300] Training [6/62] Loss: 0.30637 
Epoch [69/300] Training [7/62] Loss: 0.20213 
Epoch [69/300] Training [8/62] Loss: 0.29286 
Epoch [69/300] Training [9/62] Loss: 0.31656 
Epoch [69/300] Training [10/62] Loss: 0.28707 
Epoch [69/300] Training [11/62] Loss: 0.24156 
Epoch [69/300] Training [12/62] Loss: 0.17302 
Epoch [69/300] Training [13/62] Loss: 0.36240 
Epoch [69/300] Training [14/62] Loss: 0.21069 
Epoch [69/300] Training [15/62] Loss: 0.36577 
Epoch [69/300] Training [16/62] Loss: 0.13894 
Epoch [69/300] Training [17/62] Loss: 0.27698 
Epoch [69/300] Training [18/62] Loss: 0.19463 
Epoch [69/300] Training [19/62] Loss: 0.25509 
Epoch [69/300] Training [20/62] Loss: 0.18684 
Epoch [69/300] Training [21/62] Loss: 0.17672 
Epoch [69/300] Training [22/62] Loss: 0.20130 
Epoch [69/300] Training [23/62] Loss: 0.27578 
Epoch [69/300] Training [24/62] Loss: 0.39034 
Epoch [69/300] Training [25/62] Loss: 0.19224 
Epoch [69/300] Training [26/62] Loss: 0.11286 
Epoch [69/300] Training [27/62] Loss: 0.51503 
Epoch [69/300] Training [28/62] Loss: 0.17958 
Epoch [69/300] Training [29/62] Loss: 0.33496 
Epoch [69/300] Training [30/62] Loss: 0.35181 
Epoch [69/300] Training [31/62] Loss: 0.34506 
Epoch [69/300] Training [32/62] Loss: 0.13343 
Epoch [69/300] Training [33/62] Loss: 0.14622 
Epoch [69/300] Training [34/62] Loss: 0.18234 
Epoch [69/300] Training [35/62] Loss: 0.15888 
Epoch [69/300] Training [36/62] Loss: 0.28925 
Epoch [69/300] Training [37/62] Loss: 0.30483 
Epoch [69/300] Training [38/62] Loss: 0.39155 
Epoch [69/300] Training [39/62] Loss: 0.16019 
Epoch [69/300] Training [40/62] Loss: 0.45773 
Epoch [69/300] Training [41/62] Loss: 0.15551 
Epoch [69/300] Training [42/62] Loss: 0.23865 
Epoch [69/300] Training [43/62] Loss: 0.66205 
Epoch [69/300] Training [44/62] Loss: 0.27053 
Epoch [69/300] Training [45/62] Loss: 0.23711 
Epoch [69/300] Training [46/62] Loss: 0.36338 
Epoch [69/300] Training [47/62] Loss: 0.24326 
Epoch [69/300] Training [48/62] Loss: 0.23201 
Epoch [69/300] Training [49/62] Loss: 0.46962 
Epoch [69/300] Training [50/62] Loss: 0.26042 
Epoch [69/300] Training [51/62] Loss: 0.31697 
Epoch [69/300] Training [52/62] Loss: 0.30727 
Epoch [69/300] Training [53/62] Loss: 0.23474 
Epoch [69/300] Training [54/62] Loss: 0.20845 
Epoch [69/300] Training [55/62] Loss: 0.25360 
Epoch [69/300] Training [56/62] Loss: 0.28681 
Epoch [69/300] Training [57/62] Loss: 0.31581 
Epoch [69/300] Training [58/62] Loss: 0.17659 
Epoch [69/300] Training [59/62] Loss: 0.36227 
Epoch [69/300] Training [60/62] Loss: 0.16854 
Epoch [69/300] Training [61/62] Loss: 0.22777 
Epoch [69/300] Training [62/62] Loss: 0.22544 
Epoch [69/300] Training metric {'Train/mean dice_metric': 0.8192940950393677, 'Train/mean miou_metric': 0.7314842939376831, 'Train/mean f1': 0.8345959782600403, 'Train/mean precision': 0.8197144269943237, 'Train/mean recall': 0.8500280380249023, 'Train/mean hd95_metric': 37.415367126464844}
Epoch [69/300] Validation [1/16] Loss: 0.30341  focal_loss 0.11909  dice_loss 0.18431 
Epoch [69/300] Validation [2/16] Loss: 0.51128  focal_loss 0.14939  dice_loss 0.36189 
Epoch [69/300] Validation [3/16] Loss: 0.59279  focal_loss 0.27174  dice_loss 0.32105 
Epoch [69/300] Validation [4/16] Loss: 0.25729  focal_loss 0.07323  dice_loss 0.18406 
Epoch [69/300] Validation [5/16] Loss: 0.37141  focal_loss 0.09239  dice_loss 0.27902 
Epoch [69/300] Validation [6/16] Loss: 0.29447  focal_loss 0.07538  dice_loss 0.21909 
Epoch [69/300] Validation [7/16] Loss: 0.17952  focal_loss 0.04152  dice_loss 0.13799 
Epoch [69/300] Validation [8/16] Loss: 0.31310  focal_loss 0.05804  dice_loss 0.25507 
Epoch [69/300] Validation [9/16] Loss: 0.40603  focal_loss 0.12943  dice_loss 0.27660 
Epoch [69/300] Validation [10/16] Loss: 0.39008  focal_loss 0.10786  dice_loss 0.28222 
Epoch [69/300] Validation [11/16] Loss: 0.27159  focal_loss 0.07549  dice_loss 0.19610 
Epoch [69/300] Validation [12/16] Loss: 0.32027  focal_loss 0.06610  dice_loss 0.25417 
Epoch [69/300] Validation [13/16] Loss: 0.31071  focal_loss 0.08041  dice_loss 0.23030 
Epoch [69/300] Validation [14/16] Loss: 0.68039  focal_loss 0.21366  dice_loss 0.46673 
Epoch [69/300] Validation [15/16] Loss: 0.27800  focal_loss 0.09214  dice_loss 0.18586 
Epoch [69/300] Validation [16/16] Loss: 0.10210  focal_loss 0.01675  dice_loss 0.08536 
Epoch [69/300] Validation metric {'Val/mean dice_metric': 0.8082646131515503, 'Val/mean miou_metric': 0.7189074754714966, 'Val/mean f1': 0.8167831897735596, 'Val/mean precision': 0.8064096570014954, 'Val/mean recall': 0.8274270296096802, 'Val/mean hd95_metric': 40.9909782409668}
Cheakpoint...
Epoch [69/300] best acc:tensor([0.8155], device='cuda:0'), Now : mean acc: tensor([0.8083], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8082646131515503, 'Val/mean miou_metric': 0.7189074754714966, 'Val/mean f1': 0.8167831897735596, 'Val/mean precision': 0.8064096570014954, 'Val/mean recall': 0.8274270296096802, 'Val/mean hd95_metric': 40.9909782409668}
Epoch [70/300] Training [1/62] Loss: 0.17726 
Epoch [70/300] Training [2/62] Loss: 0.18258 
Epoch [70/300] Training [3/62] Loss: 0.17279 
Epoch [70/300] Training [4/62] Loss: 0.41605 
Epoch [70/300] Training [5/62] Loss: 0.23874 
Epoch [70/300] Training [6/62] Loss: 0.35480 
Epoch [70/300] Training [7/62] Loss: 0.18868 
Epoch [70/300] Training [8/62] Loss: 0.31093 
Epoch [70/300] Training [9/62] Loss: 0.34725 
Epoch [70/300] Training [10/62] Loss: 0.12352 
Epoch [70/300] Training [11/62] Loss: 0.28425 
Epoch [70/300] Training [12/62] Loss: 0.22416 
Epoch [70/300] Training [13/62] Loss: 0.33423 
Epoch [70/300] Training [14/62] Loss: 0.34257 
Epoch [70/300] Training [15/62] Loss: 0.32528 
Epoch [70/300] Training [16/62] Loss: 0.30762 
Epoch [70/300] Training [17/62] Loss: 0.34517 
Epoch [70/300] Training [18/62] Loss: 0.29557 
Epoch [70/300] Training [19/62] Loss: 0.26310 
Epoch [70/300] Training [20/62] Loss: 0.30439 
Epoch [70/300] Training [21/62] Loss: 0.24052 
Epoch [70/300] Training [22/62] Loss: 0.20748 
Epoch [70/300] Training [23/62] Loss: 0.33232 
Epoch [70/300] Training [24/62] Loss: 0.38381 
Epoch [70/300] Training [25/62] Loss: 0.44738 
Epoch [70/300] Training [26/62] Loss: 0.22472 
Epoch [70/300] Training [27/62] Loss: 0.19682 
Epoch [70/300] Training [28/62] Loss: 0.19474 
Epoch [70/300] Training [29/62] Loss: 0.15010 
Epoch [70/300] Training [30/62] Loss: 0.31250 
Epoch [70/300] Training [31/62] Loss: 0.32482 
Epoch [70/300] Training [32/62] Loss: 0.25833 
Epoch [70/300] Training [33/62] Loss: 0.19480 
Epoch [70/300] Training [34/62] Loss: 0.16324 
Epoch [70/300] Training [35/62] Loss: 0.49618 
Epoch [70/300] Training [36/62] Loss: 0.41061 
Epoch [70/300] Training [37/62] Loss: 0.18456 
Epoch [70/300] Training [38/62] Loss: 0.30132 
Epoch [70/300] Training [39/62] Loss: 0.42650 
Epoch [70/300] Training [40/62] Loss: 0.15532 
Epoch [70/300] Training [41/62] Loss: 0.43034 
Epoch [70/300] Training [42/62] Loss: 0.34523 
Epoch [70/300] Training [43/62] Loss: 0.10143 
Epoch [70/300] Training [44/62] Loss: 0.33547 
Epoch [70/300] Training [45/62] Loss: 0.17005 
Epoch [70/300] Training [46/62] Loss: 0.42838 
Epoch [70/300] Training [47/62] Loss: 0.26684 
Epoch [70/300] Training [48/62] Loss: 0.28752 
Epoch [70/300] Training [49/62] Loss: 0.30967 
Epoch [70/300] Training [50/62] Loss: 0.36452 
Epoch [70/300] Training [51/62] Loss: 0.21366 
Epoch [70/300] Training [52/62] Loss: 0.23865 
Epoch [70/300] Training [53/62] Loss: 0.25433 
Epoch [70/300] Training [54/62] Loss: 0.31524 
Epoch [70/300] Training [55/62] Loss: 0.19662 
Epoch [70/300] Training [56/62] Loss: 0.24433 
Epoch [70/300] Training [57/62] Loss: 0.19207 
Epoch [70/300] Training [58/62] Loss: 0.27455 
Epoch [70/300] Training [59/62] Loss: 0.24500 
Epoch [70/300] Training [60/62] Loss: 0.12805 
Epoch [70/300] Training [61/62] Loss: 0.14316 
Epoch [70/300] Training [62/62] Loss: 0.03588 
Epoch [70/300] Training metric {'Train/mean dice_metric': 0.8129516839981079, 'Train/mean miou_metric': 0.7223383784294128, 'Train/mean f1': 0.8320217728614807, 'Train/mean precision': 0.8225864171981812, 'Train/mean recall': 0.8416761755943298, 'Train/mean hd95_metric': 40.23073959350586}
Epoch [70/300] Validation [1/16] Loss: 0.27424  focal_loss 0.09619  dice_loss 0.17805 
Epoch [70/300] Validation [2/16] Loss: 0.38411  focal_loss 0.13563  dice_loss 0.24848 
Epoch [70/300] Validation [3/16] Loss: 0.41001  focal_loss 0.11454  dice_loss 0.29547 
Epoch [70/300] Validation [4/16] Loss: 0.27993  focal_loss 0.10486  dice_loss 0.17507 
Epoch [70/300] Validation [5/16] Loss: 0.40422  focal_loss 0.09140  dice_loss 0.31282 
Epoch [70/300] Validation [6/16] Loss: 0.29725  focal_loss 0.07750  dice_loss 0.21975 
Epoch [70/300] Validation [7/16] Loss: 0.26404  focal_loss 0.09804  dice_loss 0.16600 
Epoch [70/300] Validation [8/16] Loss: 0.32852  focal_loss 0.06797  dice_loss 0.26054 
Epoch [70/300] Validation [9/16] Loss: 0.27828  focal_loss 0.10133  dice_loss 0.17694 
Epoch [70/300] Validation [10/16] Loss: 0.43641  focal_loss 0.13770  dice_loss 0.29872 
Epoch [70/300] Validation [11/16] Loss: 0.24415  focal_loss 0.07365  dice_loss 0.17050 
Epoch [70/300] Validation [12/16] Loss: 0.52273  focal_loss 0.15437  dice_loss 0.36836 
Epoch [70/300] Validation [13/16] Loss: 0.43625  focal_loss 0.17556  dice_loss 0.26069 
Epoch [70/300] Validation [14/16] Loss: 0.54111  focal_loss 0.14534  dice_loss 0.39577 
Epoch [70/300] Validation [15/16] Loss: 0.17093  focal_loss 0.03751  dice_loss 0.13342 
Epoch [70/300] Validation [16/16] Loss: 0.08251  focal_loss 0.02246  dice_loss 0.06005 
Epoch [70/300] Validation metric {'Val/mean dice_metric': 0.8057568073272705, 'Val/mean miou_metric': 0.7149865031242371, 'Val/mean f1': 0.8213640451431274, 'Val/mean precision': 0.8040962219238281, 'Val/mean recall': 0.8393898010253906, 'Val/mean hd95_metric': 42.172969818115234}
Cheakpoint...
Epoch [70/300] best acc:tensor([0.8155], device='cuda:0'), Now : mean acc: tensor([0.8058], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8057568073272705, 'Val/mean miou_metric': 0.7149865031242371, 'Val/mean f1': 0.8213640451431274, 'Val/mean precision': 0.8040962219238281, 'Val/mean recall': 0.8393898010253906, 'Val/mean hd95_metric': 42.172969818115234}
Epoch [71/300] Training [1/62] Loss: 0.23442 
Epoch [71/300] Training [2/62] Loss: 0.27632 
Epoch [71/300] Training [3/62] Loss: 0.17140 
Epoch [71/300] Training [4/62] Loss: 0.21297 
Epoch [71/300] Training [5/62] Loss: 0.28623 
Epoch [71/300] Training [6/62] Loss: 0.21973 
Epoch [71/300] Training [7/62] Loss: 0.23997 
Epoch [71/300] Training [8/62] Loss: 0.19543 
Epoch [71/300] Training [9/62] Loss: 0.20882 
Epoch [71/300] Training [10/62] Loss: 0.60819 
Epoch [71/300] Training [11/62] Loss: 0.36684 
Epoch [71/300] Training [12/62] Loss: 0.33131 
Epoch [71/300] Training [13/62] Loss: 0.14133 
Epoch [71/300] Training [14/62] Loss: 0.30615 
Epoch [71/300] Training [15/62] Loss: 0.49790 
Epoch [71/300] Training [16/62] Loss: 0.20704 
Epoch [71/300] Training [17/62] Loss: 0.23152 
Epoch [71/300] Training [18/62] Loss: 0.22042 
Epoch [71/300] Training [19/62] Loss: 0.22788 
Epoch [71/300] Training [20/62] Loss: 0.39024 
Epoch [71/300] Training [21/62] Loss: 0.12641 
Epoch [71/300] Training [22/62] Loss: 0.25545 
Epoch [71/300] Training [23/62] Loss: 0.13512 
Epoch [71/300] Training [24/62] Loss: 0.29209 
Epoch [71/300] Training [25/62] Loss: 0.36626 
Epoch [71/300] Training [26/62] Loss: 0.18537 
Epoch [71/300] Training [27/62] Loss: 0.32897 
Epoch [71/300] Training [28/62] Loss: 0.30564 
Epoch [71/300] Training [29/62] Loss: 0.16768 
Epoch [71/300] Training [30/62] Loss: 0.13387 
Epoch [71/300] Training [31/62] Loss: 0.28320 
Epoch [71/300] Training [32/62] Loss: 0.25980 
Epoch [71/300] Training [33/62] Loss: 0.23623 
Epoch [71/300] Training [34/62] Loss: 0.21320 
Epoch [71/300] Training [35/62] Loss: 0.37062 
Epoch [71/300] Training [36/62] Loss: 0.18618 
Epoch [71/300] Training [37/62] Loss: 0.19902 
Epoch [71/300] Training [38/62] Loss: 0.15417 
Epoch [71/300] Training [39/62] Loss: 0.31683 
Epoch [71/300] Training [40/62] Loss: 0.18474 
Epoch [71/300] Training [41/62] Loss: 0.33407 
Epoch [71/300] Training [42/62] Loss: 0.25046 
Epoch [71/300] Training [43/62] Loss: 0.32908 
Epoch [71/300] Training [44/62] Loss: 0.19362 
Epoch [71/300] Training [45/62] Loss: 0.28110 
Epoch [71/300] Training [46/62] Loss: 0.19355 
Epoch [71/300] Training [47/62] Loss: 0.18052 
Epoch [71/300] Training [48/62] Loss: 0.16613 
Epoch [71/300] Training [49/62] Loss: 0.23528 
Epoch [71/300] Training [50/62] Loss: 0.25669 
Epoch [71/300] Training [51/62] Loss: 0.19574 
Epoch [71/300] Training [52/62] Loss: 0.22364 
Epoch [71/300] Training [53/62] Loss: 0.16168 
Epoch [71/300] Training [54/62] Loss: 0.24383 
Epoch [71/300] Training [55/62] Loss: 0.18846 
Epoch [71/300] Training [56/62] Loss: 0.27503 
Epoch [71/300] Training [57/62] Loss: 0.17236 
Epoch [71/300] Training [58/62] Loss: 0.16655 
Epoch [71/300] Training [59/62] Loss: 0.16954 
Epoch [71/300] Training [60/62] Loss: 0.20141 
Epoch [71/300] Training [61/62] Loss: 0.16109 
Epoch [71/300] Training [62/62] Loss: 0.12671 
Epoch [71/300] Training metric {'Train/mean dice_metric': 0.8352988362312317, 'Train/mean miou_metric': 0.7481241226196289, 'Train/mean f1': 0.8547741174697876, 'Train/mean precision': 0.8486336469650269, 'Train/mean recall': 0.8610039949417114, 'Train/mean hd95_metric': 33.009395599365234}
Epoch [71/300] Validation [1/16] Loss: 0.16143  focal_loss 0.05816  dice_loss 0.10326 
Epoch [71/300] Validation [2/16] Loss: 0.35822  focal_loss 0.09573  dice_loss 0.26249 
Epoch [71/300] Validation [3/16] Loss: 0.51480  focal_loss 0.20128  dice_loss 0.31352 
Epoch [71/300] Validation [4/16] Loss: 0.28833  focal_loss 0.09816  dice_loss 0.19017 
Epoch [71/300] Validation [5/16] Loss: 0.37172  focal_loss 0.12508  dice_loss 0.24664 
Epoch [71/300] Validation [6/16] Loss: 0.30418  focal_loss 0.08622  dice_loss 0.21796 
Epoch [71/300] Validation [7/16] Loss: 0.24630  focal_loss 0.09198  dice_loss 0.15432 
Epoch [71/300] Validation [8/16] Loss: 0.34707  focal_loss 0.07702  dice_loss 0.27005 
Epoch [71/300] Validation [9/16] Loss: 0.30870  focal_loss 0.10510  dice_loss 0.20360 
Epoch [71/300] Validation [10/16] Loss: 0.44249  focal_loss 0.15496  dice_loss 0.28753 
Epoch [71/300] Validation [11/16] Loss: 0.28359  focal_loss 0.07654  dice_loss 0.20704 
Epoch [71/300] Validation [12/16] Loss: 0.28937  focal_loss 0.05896  dice_loss 0.23041 
Epoch [71/300] Validation [13/16] Loss: 0.25884  focal_loss 0.05911  dice_loss 0.19972 
Epoch [71/300] Validation [14/16] Loss: 0.45502  focal_loss 0.11411  dice_loss 0.34091 
Epoch [71/300] Validation [15/16] Loss: 0.15903  focal_loss 0.03168  dice_loss 0.12735 
Epoch [71/300] Validation [16/16] Loss: 0.10387  focal_loss 0.03043  dice_loss 0.07344 
Epoch [71/300] Validation metric {'Val/mean dice_metric': 0.8269815444946289, 'Val/mean miou_metric': 0.7391451001167297, 'Val/mean f1': 0.8412368893623352, 'Val/mean precision': 0.8287535905838013, 'Val/mean recall': 0.8541019558906555, 'Val/mean hd95_metric': 36.09414291381836}
Cheakpoint...
Epoch [71/300] best acc:tensor([0.8270], device='cuda:0'), Now : mean acc: tensor([0.8270], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8269815444946289, 'Val/mean miou_metric': 0.7391451001167297, 'Val/mean f1': 0.8412368893623352, 'Val/mean precision': 0.8287535905838013, 'Val/mean recall': 0.8541019558906555, 'Val/mean hd95_metric': 36.09414291381836}
Epoch [72/300] Training [1/62] Loss: 0.29084 
Epoch [72/300] Training [2/62] Loss: 0.33485 
Epoch [72/300] Training [3/62] Loss: 0.40359 
Epoch [72/300] Training [4/62] Loss: 0.25576 
Epoch [72/300] Training [5/62] Loss: 0.26449 
Epoch [72/300] Training [6/62] Loss: 0.27479 
Epoch [72/300] Training [7/62] Loss: 0.26522 
Epoch [72/300] Training [8/62] Loss: 0.25876 
Epoch [72/300] Training [9/62] Loss: 0.15695 
Epoch [72/300] Training [10/62] Loss: 0.31215 
Epoch [72/300] Training [11/62] Loss: 0.32960 
Epoch [72/300] Training [12/62] Loss: 0.19958 
Epoch [72/300] Training [13/62] Loss: 0.25560 
Epoch [72/300] Training [14/62] Loss: 0.26559 
Epoch [72/300] Training [15/62] Loss: 0.16203 
Epoch [72/300] Training [16/62] Loss: 0.31374 
Epoch [72/300] Training [17/62] Loss: 0.39522 
Epoch [72/300] Training [18/62] Loss: 0.19801 
Epoch [72/300] Training [19/62] Loss: 0.23825 
Epoch [72/300] Training [20/62] Loss: 0.24502 
Epoch [72/300] Training [21/62] Loss: 0.16152 
Epoch [72/300] Training [22/62] Loss: 0.32015 
Epoch [72/300] Training [23/62] Loss: 0.26491 
Epoch [72/300] Training [24/62] Loss: 0.23272 
Epoch [72/300] Training [25/62] Loss: 0.27781 
Epoch [72/300] Training [26/62] Loss: 0.27437 
Epoch [72/300] Training [27/62] Loss: 0.10917 
Epoch [72/300] Training [28/62] Loss: 0.21254 
Epoch [72/300] Training [29/62] Loss: 0.31064 
Epoch [72/300] Training [30/62] Loss: 0.10296 
Epoch [72/300] Training [31/62] Loss: 0.21456 
Epoch [72/300] Training [32/62] Loss: 0.21356 
Epoch [72/300] Training [33/62] Loss: 0.21172 
Epoch [72/300] Training [34/62] Loss: 0.24172 
Epoch [72/300] Training [35/62] Loss: 0.23088 
Epoch [72/300] Training [36/62] Loss: 0.21864 
Epoch [72/300] Training [37/62] Loss: 0.61655 
Epoch [72/300] Training [38/62] Loss: 0.34860 
Epoch [72/300] Training [39/62] Loss: 0.30822 
Epoch [72/300] Training [40/62] Loss: 0.09986 
Epoch [72/300] Training [41/62] Loss: 0.17741 
Epoch [72/300] Training [42/62] Loss: 0.24131 
Epoch [72/300] Training [43/62] Loss: 0.22189 
Epoch [72/300] Training [44/62] Loss: 0.26959 
Epoch [72/300] Training [45/62] Loss: 0.30179 
Epoch [72/300] Training [46/62] Loss: 0.24600 
Epoch [72/300] Training [47/62] Loss: 0.21346 
Epoch [72/300] Training [48/62] Loss: 0.27691 
Epoch [72/300] Training [49/62] Loss: 0.18603 
Epoch [72/300] Training [50/62] Loss: 0.31253 
Epoch [72/300] Training [51/62] Loss: 0.43784 
Epoch [72/300] Training [52/62] Loss: 0.18198 
Epoch [72/300] Training [53/62] Loss: 0.16731 
Epoch [72/300] Training [54/62] Loss: 0.47787 
Epoch [72/300] Training [55/62] Loss: 0.25875 
Epoch [72/300] Training [56/62] Loss: 0.10599 
Epoch [72/300] Training [57/62] Loss: 0.47323 
Epoch [72/300] Training [58/62] Loss: 0.25308 
Epoch [72/300] Training [59/62] Loss: 0.30536 
Epoch [72/300] Training [60/62] Loss: 0.24985 
Epoch [72/300] Training [61/62] Loss: 0.25341 
Epoch [72/300] Training [62/62] Loss: 0.13245 
Epoch [72/300] Training metric {'Train/mean dice_metric': 0.8203687071800232, 'Train/mean miou_metric': 0.732339084148407, 'Train/mean f1': 0.8336621522903442, 'Train/mean precision': 0.8182402849197388, 'Train/mean recall': 0.8496764898300171, 'Train/mean hd95_metric': 37.921669006347656}
Epoch [72/300] Validation [1/16] Loss: 0.26677  focal_loss 0.07608  dice_loss 0.19070 
Epoch [72/300] Validation [2/16] Loss: 0.48816  focal_loss 0.15870  dice_loss 0.32946 
Epoch [72/300] Validation [3/16] Loss: 0.31415  focal_loss 0.07386  dice_loss 0.24029 
Epoch [72/300] Validation [4/16] Loss: 0.40573  focal_loss 0.13601  dice_loss 0.26971 
Epoch [72/300] Validation [5/16] Loss: 0.35284  focal_loss 0.04963  dice_loss 0.30321 
Epoch [72/300] Validation [6/16] Loss: 0.35521  focal_loss 0.08873  dice_loss 0.26648 
Epoch [72/300] Validation [7/16] Loss: 0.18097  focal_loss 0.04165  dice_loss 0.13932 
Epoch [72/300] Validation [8/16] Loss: 0.53421  focal_loss 0.16658  dice_loss 0.36763 
Epoch [72/300] Validation [9/16] Loss: 0.37600  focal_loss 0.12298  dice_loss 0.25302 
Epoch [72/300] Validation [10/16] Loss: 0.53561  focal_loss 0.12824  dice_loss 0.40737 
Epoch [72/300] Validation [11/16] Loss: 0.19517  focal_loss 0.04658  dice_loss 0.14860 
Epoch [72/300] Validation [12/16] Loss: 0.34719  focal_loss 0.05790  dice_loss 0.28929 
Epoch [72/300] Validation [13/16] Loss: 0.48716  focal_loss 0.17648  dice_loss 0.31068 
Epoch [72/300] Validation [14/16] Loss: 0.69012  focal_loss 0.27809  dice_loss 0.41202 
Epoch [72/300] Validation [15/16] Loss: 0.34895  focal_loss 0.10061  dice_loss 0.24835 
Epoch [72/300] Validation [16/16] Loss: 0.16236  focal_loss 0.02910  dice_loss 0.13326 
Epoch [72/300] Validation metric {'Val/mean dice_metric': 0.805836021900177, 'Val/mean miou_metric': 0.7143110632896423, 'Val/mean f1': 0.8172794580459595, 'Val/mean precision': 0.8090784549713135, 'Val/mean recall': 0.8256484866142273, 'Val/mean hd95_metric': 41.84419250488281}
Cheakpoint...
Epoch [72/300] best acc:tensor([0.8270], device='cuda:0'), Now : mean acc: tensor([0.8058], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.805836021900177, 'Val/mean miou_metric': 0.7143110632896423, 'Val/mean f1': 0.8172794580459595, 'Val/mean precision': 0.8090784549713135, 'Val/mean recall': 0.8256484866142273, 'Val/mean hd95_metric': 41.84419250488281}
Epoch [73/300] Training [1/62] Loss: 0.31358 
Epoch [73/300] Training [2/62] Loss: 0.30793 
Epoch [73/300] Training [3/62] Loss: 0.52207 
Epoch [73/300] Training [4/62] Loss: 0.25742 
Epoch [73/300] Training [5/62] Loss: 0.15692 
Epoch [73/300] Training [6/62] Loss: 0.26043 
Epoch [73/300] Training [7/62] Loss: 0.24286 
Epoch [73/300] Training [8/62] Loss: 0.13710 
Epoch [73/300] Training [9/62] Loss: 0.33815 
Epoch [73/300] Training [10/62] Loss: 0.28442 
Epoch [73/300] Training [11/62] Loss: 0.21467 
Epoch [73/300] Training [12/62] Loss: 0.21577 
Epoch [73/300] Training [13/62] Loss: 0.15062 
Epoch [73/300] Training [14/62] Loss: 0.24536 
Epoch [73/300] Training [15/62] Loss: 0.42325 
Epoch [73/300] Training [16/62] Loss: 0.22968 
Epoch [73/300] Training [17/62] Loss: 0.35823 
Epoch [73/300] Training [18/62] Loss: 0.31575 
Epoch [73/300] Training [19/62] Loss: 0.18562 
Epoch [73/300] Training [20/62] Loss: 0.22186 
Epoch [73/300] Training [21/62] Loss: 0.16807 
Epoch [73/300] Training [22/62] Loss: 0.22135 
Epoch [73/300] Training [23/62] Loss: 0.73005 
Epoch [73/300] Training [24/62] Loss: 0.44423 
Epoch [73/300] Training [25/62] Loss: 0.23618 
Epoch [73/300] Training [26/62] Loss: 0.23676 
Epoch [73/300] Training [27/62] Loss: 0.35074 
Epoch [73/300] Training [28/62] Loss: 0.36888 
Epoch [73/300] Training [29/62] Loss: 0.27321 
Epoch [73/300] Training [30/62] Loss: 0.20041 
Epoch [73/300] Training [31/62] Loss: 0.28590 
Epoch [73/300] Training [32/62] Loss: 0.21433 
Epoch [73/300] Training [33/62] Loss: 0.61960 
Epoch [73/300] Training [34/62] Loss: 0.26167 
Epoch [73/300] Training [35/62] Loss: 0.20609 
Epoch [73/300] Training [36/62] Loss: 0.16617 
Epoch [73/300] Training [37/62] Loss: 0.38537 
Epoch [73/300] Training [38/62] Loss: 0.28384 
Epoch [73/300] Training [39/62] Loss: 0.45806 
Epoch [73/300] Training [40/62] Loss: 0.22688 
Epoch [73/300] Training [41/62] Loss: 0.21571 
Epoch [73/300] Training [42/62] Loss: 0.27995 
Epoch [73/300] Training [43/62] Loss: 0.16987 
Epoch [73/300] Training [44/62] Loss: 0.15877 
Epoch [73/300] Training [45/62] Loss: 0.17569 
Epoch [73/300] Training [46/62] Loss: 0.24338 
Epoch [73/300] Training [47/62] Loss: 0.27415 
Epoch [73/300] Training [48/62] Loss: 0.13998 
Epoch [73/300] Training [49/62] Loss: 0.14004 
Epoch [73/300] Training [50/62] Loss: 0.19580 
Epoch [73/300] Training [51/62] Loss: 0.19405 
Epoch [73/300] Training [52/62] Loss: 0.20016 
Epoch [73/300] Training [53/62] Loss: 0.20182 
Epoch [73/300] Training [54/62] Loss: 0.20827 
Epoch [73/300] Training [55/62] Loss: 0.17960 
Epoch [73/300] Training [56/62] Loss: 0.43560 
Epoch [73/300] Training [57/62] Loss: 0.13238 
Epoch [73/300] Training [58/62] Loss: 0.15687 
Epoch [73/300] Training [59/62] Loss: 0.15587 
Epoch [73/300] Training [60/62] Loss: 0.14270 
Epoch [73/300] Training [61/62] Loss: 0.23442 
Epoch [73/300] Training [62/62] Loss: 0.14203 
Epoch [73/300] Training metric {'Train/mean dice_metric': 0.8212663531303406, 'Train/mean miou_metric': 0.7296682000160217, 'Train/mean f1': 0.8315859436988831, 'Train/mean precision': 0.8354870676994324, 'Train/mean recall': 0.827721118927002, 'Train/mean hd95_metric': 35.98811340332031}
Epoch [73/300] Validation [1/16] Loss: 0.11605  focal_loss 0.02517  dice_loss 0.09088 
Epoch [73/300] Validation [2/16] Loss: 0.43010  focal_loss 0.10209  dice_loss 0.32801 
Epoch [73/300] Validation [3/16] Loss: 0.92657  focal_loss 0.43363  dice_loss 0.49294 
Epoch [73/300] Validation [4/16] Loss: 0.32657  focal_loss 0.10425  dice_loss 0.22232 
Epoch [73/300] Validation [5/16] Loss: 0.36495  focal_loss 0.06860  dice_loss 0.29635 
Epoch [73/300] Validation [6/16] Loss: 0.24305  focal_loss 0.05988  dice_loss 0.18317 
Epoch [73/300] Validation [7/16] Loss: 0.24670  focal_loss 0.06692  dice_loss 0.17979 
Epoch [73/300] Validation [8/16] Loss: 0.48216  focal_loss 0.09531  dice_loss 0.38685 
Epoch [73/300] Validation [9/16] Loss: 0.44434  focal_loss 0.14657  dice_loss 0.29777 
Epoch [73/300] Validation [10/16] Loss: 0.52257  focal_loss 0.11747  dice_loss 0.40510 
Epoch [73/300] Validation [11/16] Loss: 0.26681  focal_loss 0.07586  dice_loss 0.19095 
Epoch [73/300] Validation [12/16] Loss: 0.46911  focal_loss 0.08368  dice_loss 0.38543 
Epoch [73/300] Validation [13/16] Loss: 0.30346  focal_loss 0.08818  dice_loss 0.21528 
Epoch [73/300] Validation [14/16] Loss: 0.47615  focal_loss 0.14444  dice_loss 0.33171 
Epoch [73/300] Validation [15/16] Loss: 0.16522  focal_loss 0.03252  dice_loss 0.13270 
Epoch [73/300] Validation [16/16] Loss: 0.06351  focal_loss 0.01145  dice_loss 0.05206 
Epoch [73/300] Validation metric {'Val/mean dice_metric': 0.8067396283149719, 'Val/mean miou_metric': 0.715778112411499, 'Val/mean f1': 0.8124324679374695, 'Val/mean precision': 0.7987152934074402, 'Val/mean recall': 0.8266290426254272, 'Val/mean hd95_metric': 40.20976257324219}
Cheakpoint...
Epoch [73/300] best acc:tensor([0.8270], device='cuda:0'), Now : mean acc: tensor([0.8067], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8067396283149719, 'Val/mean miou_metric': 0.715778112411499, 'Val/mean f1': 0.8124324679374695, 'Val/mean precision': 0.7987152934074402, 'Val/mean recall': 0.8266290426254272, 'Val/mean hd95_metric': 40.20976257324219}
Epoch [74/300] Training [1/62] Loss: 0.11759 
Epoch [74/300] Training [2/62] Loss: 0.39613 
Epoch [74/300] Training [3/62] Loss: 0.26287 
Epoch [74/300] Training [4/62] Loss: 0.21782 
Epoch [74/300] Training [5/62] Loss: 0.34408 
Epoch [74/300] Training [6/62] Loss: 0.18777 
Epoch [74/300] Training [7/62] Loss: 0.21843 
Epoch [74/300] Training [8/62] Loss: 0.19392 
Epoch [74/300] Training [9/62] Loss: 0.16318 
Epoch [74/300] Training [10/62] Loss: 0.23749 
Epoch [74/300] Training [11/62] Loss: 0.19482 
Epoch [74/300] Training [12/62] Loss: 0.50243 
Epoch [74/300] Training [13/62] Loss: 0.25152 
Epoch [74/300] Training [14/62] Loss: 0.29764 
Epoch [74/300] Training [15/62] Loss: 0.18889 
Epoch [74/300] Training [16/62] Loss: 0.22638 
Epoch [74/300] Training [17/62] Loss: 0.17922 
Epoch [74/300] Training [18/62] Loss: 0.08523 
Epoch [74/300] Training [19/62] Loss: 0.25175 
Epoch [74/300] Training [20/62] Loss: 0.18118 
Epoch [74/300] Training [21/62] Loss: 0.16807 
Epoch [74/300] Training [22/62] Loss: 0.26573 
Epoch [74/300] Training [23/62] Loss: 0.33908 
Epoch [74/300] Training [24/62] Loss: 0.39084 
Epoch [74/300] Training [25/62] Loss: 0.24141 
Epoch [74/300] Training [26/62] Loss: 0.13319 
Epoch [74/300] Training [27/62] Loss: 0.44940 
Epoch [74/300] Training [28/62] Loss: 0.15051 
Epoch [74/300] Training [29/62] Loss: 0.13908 
Epoch [74/300] Training [30/62] Loss: 0.21610 
Epoch [74/300] Training [31/62] Loss: 0.36843 
Epoch [74/300] Training [32/62] Loss: 0.15010 
Epoch [74/300] Training [33/62] Loss: 0.32889 
Epoch [74/300] Training [34/62] Loss: 0.16599 
Epoch [74/300] Training [35/62] Loss: 0.22176 
Epoch [74/300] Training [36/62] Loss: 0.27592 
Epoch [74/300] Training [37/62] Loss: 0.23886 
Epoch [74/300] Training [38/62] Loss: 0.12334 
Epoch [74/300] Training [39/62] Loss: 0.34515 
Epoch [74/300] Training [40/62] Loss: 0.24610 
Epoch [74/300] Training [41/62] Loss: 0.27288 
Epoch [74/300] Training [42/62] Loss: 0.30681 
Epoch [74/300] Training [43/62] Loss: 0.25795 
Epoch [74/300] Training [44/62] Loss: 0.21335 
Epoch [74/300] Training [45/62] Loss: 0.25605 
Epoch [74/300] Training [46/62] Loss: 0.31130 
Epoch [74/300] Training [47/62] Loss: 0.35295 
Epoch [74/300] Training [48/62] Loss: 0.16541 
Epoch [74/300] Training [49/62] Loss: 0.43195 
Epoch [74/300] Training [50/62] Loss: 0.20479 
Epoch [74/300] Training [51/62] Loss: 0.43977 
Epoch [74/300] Training [52/62] Loss: 0.31318 
Epoch [74/300] Training [53/62] Loss: 0.25473 
Epoch [74/300] Training [54/62] Loss: 0.23589 
Epoch [74/300] Training [55/62] Loss: 0.20482 
Epoch [74/300] Training [56/62] Loss: 0.23086 
Epoch [74/300] Training [57/62] Loss: 0.47755 
Epoch [74/300] Training [58/62] Loss: 0.23486 
Epoch [74/300] Training [59/62] Loss: 0.22051 
Epoch [74/300] Training [60/62] Loss: 0.19730 
Epoch [74/300] Training [61/62] Loss: 0.26350 
Epoch [74/300] Training [62/62] Loss: 0.12911 
Epoch [74/300] Training metric {'Train/mean dice_metric': 0.8276616930961609, 'Train/mean miou_metric': 0.7397273182868958, 'Train/mean f1': 0.8410360813140869, 'Train/mean precision': 0.8311014771461487, 'Train/mean recall': 0.8512111306190491, 'Train/mean hd95_metric': 35.63640213012695}
Epoch [74/300] Validation [1/16] Loss: 0.15917  focal_loss 0.04674  dice_loss 0.11242 
Epoch [74/300] Validation [2/16] Loss: 0.40314  focal_loss 0.13534  dice_loss 0.26779 
Epoch [74/300] Validation [3/16] Loss: 0.53929  focal_loss 0.23748  dice_loss 0.30181 
Epoch [74/300] Validation [4/16] Loss: 0.38209  focal_loss 0.14667  dice_loss 0.23542 
Epoch [74/300] Validation [5/16] Loss: 0.35060  focal_loss 0.08079  dice_loss 0.26982 
Epoch [74/300] Validation [6/16] Loss: 0.29720  focal_loss 0.09845  dice_loss 0.19874 
Epoch [74/300] Validation [7/16] Loss: 0.20904  focal_loss 0.06493  dice_loss 0.14411 
Epoch [74/300] Validation [8/16] Loss: 0.44390  focal_loss 0.07653  dice_loss 0.36737 
Epoch [74/300] Validation [9/16] Loss: 0.32150  focal_loss 0.12676  dice_loss 0.19474 
Epoch [74/300] Validation [10/16] Loss: 0.36507  focal_loss 0.12406  dice_loss 0.24101 
Epoch [74/300] Validation [11/16] Loss: 0.33046  focal_loss 0.11511  dice_loss 0.21535 
Epoch [74/300] Validation [12/16] Loss: 0.41488  focal_loss 0.09110  dice_loss 0.32379 
Epoch [74/300] Validation [13/16] Loss: 0.36581  focal_loss 0.11130  dice_loss 0.25451 
Epoch [74/300] Validation [14/16] Loss: 0.64261  focal_loss 0.21773  dice_loss 0.42487 
Epoch [74/300] Validation [15/16] Loss: 0.15571  focal_loss 0.04169  dice_loss 0.11402 
Epoch [74/300] Validation [16/16] Loss: 0.08418  focal_loss 0.01552  dice_loss 0.06866 
Epoch [74/300] Validation metric {'Val/mean dice_metric': 0.8174916505813599, 'Val/mean miou_metric': 0.7286681532859802, 'Val/mean f1': 0.8247596621513367, 'Val/mean precision': 0.79900723695755, 'Val/mean recall': 0.8522273302078247, 'Val/mean hd95_metric': 39.50239181518555}
Cheakpoint...
Epoch [74/300] best acc:tensor([0.8270], device='cuda:0'), Now : mean acc: tensor([0.8175], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8174916505813599, 'Val/mean miou_metric': 0.7286681532859802, 'Val/mean f1': 0.8247596621513367, 'Val/mean precision': 0.79900723695755, 'Val/mean recall': 0.8522273302078247, 'Val/mean hd95_metric': 39.50239181518555}
Epoch [75/300] Training [1/62] Loss: 0.23140 
Epoch [75/300] Training [2/62] Loss: 0.20905 
Epoch [75/300] Training [3/62] Loss: 0.28140 
Epoch [75/300] Training [4/62] Loss: 0.26319 
Epoch [75/300] Training [5/62] Loss: 0.34140 
Epoch [75/300] Training [6/62] Loss: 0.21590 
Epoch [75/300] Training [7/62] Loss: 0.23227 
Epoch [75/300] Training [8/62] Loss: 0.21518 
Epoch [75/300] Training [9/62] Loss: 0.32805 
Epoch [75/300] Training [10/62] Loss: 0.21871 
Epoch [75/300] Training [11/62] Loss: 0.11568 
Epoch [75/300] Training [12/62] Loss: 0.22527 
Epoch [75/300] Training [13/62] Loss: 0.27978 
Epoch [75/300] Training [14/62] Loss: 0.39980 
Epoch [75/300] Training [15/62] Loss: 0.37175 
Epoch [75/300] Training [16/62] Loss: 0.23813 
Epoch [75/300] Training [17/62] Loss: 0.17498 
Epoch [75/300] Training [18/62] Loss: 0.11908 
Epoch [75/300] Training [19/62] Loss: 0.36589 
Epoch [75/300] Training [20/62] Loss: 0.33594 
Epoch [75/300] Training [21/62] Loss: 0.26284 
Epoch [75/300] Training [22/62] Loss: 0.24860 
Epoch [75/300] Training [23/62] Loss: 0.21005 
Epoch [75/300] Training [24/62] Loss: 0.18370 
Epoch [75/300] Training [25/62] Loss: 0.15607 
Epoch [75/300] Training [26/62] Loss: 0.16830 
Epoch [75/300] Training [27/62] Loss: 0.22966 
Epoch [75/300] Training [28/62] Loss: 0.41321 
Epoch [75/300] Training [29/62] Loss: 0.18559 
Epoch [75/300] Training [30/62] Loss: 0.20065 
Epoch [75/300] Training [31/62] Loss: 0.42435 
Epoch [75/300] Training [32/62] Loss: 0.33780 
Epoch [75/300] Training [33/62] Loss: 0.13000 
Epoch [75/300] Training [34/62] Loss: 0.30385 
Epoch [75/300] Training [35/62] Loss: 0.41876 
Epoch [75/300] Training [36/62] Loss: 0.19369 
Epoch [75/300] Training [37/62] Loss: 0.27133 
Epoch [75/300] Training [38/62] Loss: 0.23064 
Epoch [75/300] Training [39/62] Loss: 0.20482 
Epoch [75/300] Training [40/62] Loss: 0.18914 
Epoch [75/300] Training [41/62] Loss: 0.15965 
Epoch [75/300] Training [42/62] Loss: 0.26196 
Epoch [75/300] Training [43/62] Loss: 0.17739 
Epoch [75/300] Training [44/62] Loss: 0.23578 
Epoch [75/300] Training [45/62] Loss: 0.41480 
Epoch [75/300] Training [46/62] Loss: 0.40391 
Epoch [75/300] Training [47/62] Loss: 0.25055 
Epoch [75/300] Training [48/62] Loss: 0.15917 
Epoch [75/300] Training [49/62] Loss: 0.19116 
Epoch [75/300] Training [50/62] Loss: 0.22801 
Epoch [75/300] Training [51/62] Loss: 0.21918 
Epoch [75/300] Training [52/62] Loss: 0.17004 
Epoch [75/300] Training [53/62] Loss: 0.30611 
Epoch [75/300] Training [54/62] Loss: 0.20267 
Epoch [75/300] Training [55/62] Loss: 0.26548 
Epoch [75/300] Training [56/62] Loss: 0.25293 
Epoch [75/300] Training [57/62] Loss: 0.15743 
Epoch [75/300] Training [58/62] Loss: 0.46127 
Epoch [75/300] Training [59/62] Loss: 0.27299 
Epoch [75/300] Training [60/62] Loss: 0.16625 
Epoch [75/300] Training [61/62] Loss: 0.34745 
Epoch [75/300] Training [62/62] Loss: 0.12630 
Epoch [75/300] Training metric {'Train/mean dice_metric': 0.8268910646438599, 'Train/mean miou_metric': 0.7399783730506897, 'Train/mean f1': 0.8409408330917358, 'Train/mean precision': 0.8243739008903503, 'Train/mean recall': 0.8581872582435608, 'Train/mean hd95_metric': 38.10928726196289}
Epoch [75/300] Validation [1/16] Loss: 0.22875  focal_loss 0.06166  dice_loss 0.16709 
Epoch [75/300] Validation [2/16] Loss: 0.53933  focal_loss 0.18890  dice_loss 0.35042 
Epoch [75/300] Validation [3/16] Loss: 0.68807  focal_loss 0.26418  dice_loss 0.42389 
Epoch [75/300] Validation [4/16] Loss: 0.50073  focal_loss 0.14273  dice_loss 0.35800 
Epoch [75/300] Validation [5/16] Loss: 0.35801  focal_loss 0.06291  dice_loss 0.29510 
Epoch [75/300] Validation [6/16] Loss: 0.32946  focal_loss 0.06703  dice_loss 0.26242 
Epoch [75/300] Validation [7/16] Loss: 0.25221  focal_loss 0.04350  dice_loss 0.20871 
Epoch [75/300] Validation [8/16] Loss: 0.32388  focal_loss 0.05418  dice_loss 0.26970 
Epoch [75/300] Validation [9/16] Loss: 0.27746  focal_loss 0.06668  dice_loss 0.21078 
Epoch [75/300] Validation [10/16] Loss: 0.53398  focal_loss 0.09421  dice_loss 0.43978 
Epoch [75/300] Validation [11/16] Loss: 0.24417  focal_loss 0.04567  dice_loss 0.19850 
Epoch [75/300] Validation [12/16] Loss: 0.43448  focal_loss 0.08791  dice_loss 0.34657 
Epoch [75/300] Validation [13/16] Loss: 0.36652  focal_loss 0.09741  dice_loss 0.26912 
Epoch [75/300] Validation [14/16] Loss: 0.59893  focal_loss 0.17335  dice_loss 0.42558 
Epoch [75/300] Validation [15/16] Loss: 0.21109  focal_loss 0.03357  dice_loss 0.17752 
Epoch [75/300] Validation [16/16] Loss: 0.15279  focal_loss 0.04096  dice_loss 0.11183 
Epoch [75/300] Validation metric {'Val/mean dice_metric': 0.8093861937522888, 'Val/mean miou_metric': 0.7203773856163025, 'Val/mean f1': 0.8170907497406006, 'Val/mean precision': 0.7893882989883423, 'Val/mean recall': 0.8468082547187805, 'Val/mean hd95_metric': 43.51372146606445}
Cheakpoint...
Epoch [75/300] best acc:tensor([0.8270], device='cuda:0'), Now : mean acc: tensor([0.8094], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8093861937522888, 'Val/mean miou_metric': 0.7203773856163025, 'Val/mean f1': 0.8170907497406006, 'Val/mean precision': 0.7893882989883423, 'Val/mean recall': 0.8468082547187805, 'Val/mean hd95_metric': 43.51372146606445}
Epoch [76/300] Training [1/62] Loss: 0.30789 
Epoch [76/300] Training [2/62] Loss: 0.19904 
Epoch [76/300] Training [3/62] Loss: 0.51811 
Epoch [76/300] Training [4/62] Loss: 0.18266 
Epoch [76/300] Training [5/62] Loss: 0.27340 
Epoch [76/300] Training [6/62] Loss: 0.21745 
Epoch [76/300] Training [7/62] Loss: 0.25469 
Epoch [76/300] Training [8/62] Loss: 0.17980 
Epoch [76/300] Training [9/62] Loss: 0.32247 
Epoch [76/300] Training [10/62] Loss: 0.23609 
Epoch [76/300] Training [11/62] Loss: 0.26782 
Epoch [76/300] Training [12/62] Loss: 0.26756 
Epoch [76/300] Training [13/62] Loss: 0.60603 
Epoch [76/300] Training [14/62] Loss: 0.17836 
Epoch [76/300] Training [15/62] Loss: 0.34905 
Epoch [76/300] Training [16/62] Loss: 0.13704 
Epoch [76/300] Training [17/62] Loss: 0.23009 
Epoch [76/300] Training [18/62] Loss: 0.29568 
Epoch [76/300] Training [19/62] Loss: 0.27541 
Epoch [76/300] Training [20/62] Loss: 0.26820 
Epoch [76/300] Training [21/62] Loss: 0.19988 
Epoch [76/300] Training [22/62] Loss: 0.25463 
Epoch [76/300] Training [23/62] Loss: 0.20901 
Epoch [76/300] Training [24/62] Loss: 0.19834 
Epoch [76/300] Training [25/62] Loss: 0.17863 
Epoch [76/300] Training [26/62] Loss: 0.17527 
Epoch [76/300] Training [27/62] Loss: 0.30580 
Epoch [76/300] Training [28/62] Loss: 0.14955 
Epoch [76/300] Training [29/62] Loss: 0.20990 
Epoch [76/300] Training [30/62] Loss: 0.35195 
Epoch [76/300] Training [31/62] Loss: 0.20129 
Epoch [76/300] Training [32/62] Loss: 0.23633 
Epoch [76/300] Training [33/62] Loss: 0.18707 
Epoch [76/300] Training [34/62] Loss: 0.13931 
Epoch [76/300] Training [35/62] Loss: 0.09792 
Epoch [76/300] Training [36/62] Loss: 0.14995 
Epoch [76/300] Training [37/62] Loss: 0.18340 
Epoch [76/300] Training [38/62] Loss: 0.22431 
Epoch [76/300] Training [39/62] Loss: 0.12333 
Epoch [76/300] Training [40/62] Loss: 0.30581 
Epoch [76/300] Training [41/62] Loss: 0.32174 
Epoch [76/300] Training [42/62] Loss: 0.23971 
Epoch [76/300] Training [43/62] Loss: 0.30863 
Epoch [76/300] Training [44/62] Loss: 0.19293 
Epoch [76/300] Training [45/62] Loss: 0.16585 
Epoch [76/300] Training [46/62] Loss: 0.12802 
Epoch [76/300] Training [47/62] Loss: 0.21581 
Epoch [76/300] Training [48/62] Loss: 0.25048 
Epoch [76/300] Training [49/62] Loss: 0.28257 
Epoch [76/300] Training [50/62] Loss: 0.18430 
Epoch [76/300] Training [51/62] Loss: 0.15217 
Epoch [76/300] Training [52/62] Loss: 0.22572 
Epoch [76/300] Training [53/62] Loss: 0.23277 
Epoch [76/300] Training [54/62] Loss: 0.28081 
Epoch [76/300] Training [55/62] Loss: 0.26346 
Epoch [76/300] Training [56/62] Loss: 0.27483 
Epoch [76/300] Training [57/62] Loss: 0.29493 
Epoch [76/300] Training [58/62] Loss: 0.16874 
Epoch [76/300] Training [59/62] Loss: 0.13874 
Epoch [76/300] Training [60/62] Loss: 0.26023 
Epoch [76/300] Training [61/62] Loss: 0.31372 
Epoch [76/300] Training [62/62] Loss: 0.70955 
Epoch [76/300] Training metric {'Train/mean dice_metric': 0.8365914821624756, 'Train/mean miou_metric': 0.747760534286499, 'Train/mean f1': 0.8521803617477417, 'Train/mean precision': 0.847539484500885, 'Train/mean recall': 0.85687255859375, 'Train/mean hd95_metric': 34.79722595214844}
Epoch [76/300] Validation [1/16] Loss: 0.31550  focal_loss 0.09266  dice_loss 0.22284 
Epoch [76/300] Validation [2/16] Loss: 0.44684  focal_loss 0.13065  dice_loss 0.31619 
Epoch [76/300] Validation [3/16] Loss: 0.34472  focal_loss 0.06518  dice_loss 0.27954 
Epoch [76/300] Validation [4/16] Loss: 0.32071  focal_loss 0.11835  dice_loss 0.20236 
Epoch [76/300] Validation [5/16] Loss: 0.31838  focal_loss 0.07386  dice_loss 0.24451 
Epoch [76/300] Validation [6/16] Loss: 0.20043  focal_loss 0.04158  dice_loss 0.15884 
Epoch [76/300] Validation [7/16] Loss: 0.31897  focal_loss 0.10289  dice_loss 0.21608 
Epoch [76/300] Validation [8/16] Loss: 0.48950  focal_loss 0.16385  dice_loss 0.32565 
Epoch [76/300] Validation [9/16] Loss: 0.21141  focal_loss 0.04156  dice_loss 0.16985 
Epoch [76/300] Validation [10/16] Loss: 0.49371  focal_loss 0.10958  dice_loss 0.38413 
Epoch [76/300] Validation [11/16] Loss: 0.23018  focal_loss 0.04399  dice_loss 0.18619 
Epoch [76/300] Validation [12/16] Loss: 0.38206  focal_loss 0.06575  dice_loss 0.31631 
Epoch [76/300] Validation [13/16] Loss: 0.28028  focal_loss 0.08087  dice_loss 0.19941 
Epoch [76/300] Validation [14/16] Loss: 0.47456  focal_loss 0.12092  dice_loss 0.35364 
Epoch [76/300] Validation [15/16] Loss: 0.24072  focal_loss 0.07417  dice_loss 0.16655 
Epoch [76/300] Validation [16/16] Loss: 0.12726  focal_loss 0.03043  dice_loss 0.09683 
Epoch [76/300] Validation metric {'Val/mean dice_metric': 0.8245388269424438, 'Val/mean miou_metric': 0.7335769534111023, 'Val/mean f1': 0.8401704430580139, 'Val/mean precision': 0.8417062759399414, 'Val/mean recall': 0.8386402726173401, 'Val/mean hd95_metric': 37.20907211303711}
Cheakpoint...
Epoch [76/300] best acc:tensor([0.8270], device='cuda:0'), Now : mean acc: tensor([0.8245], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8245388269424438, 'Val/mean miou_metric': 0.7335769534111023, 'Val/mean f1': 0.8401704430580139, 'Val/mean precision': 0.8417062759399414, 'Val/mean recall': 0.8386402726173401, 'Val/mean hd95_metric': 37.20907211303711}
Epoch [77/300] Training [1/62] Loss: 0.15790 
Epoch [77/300] Training [2/62] Loss: 0.31641 
Epoch [77/300] Training [3/62] Loss: 0.16553 
Epoch [77/300] Training [4/62] Loss: 0.19979 
Epoch [77/300] Training [5/62] Loss: 0.41811 
Epoch [77/300] Training [6/62] Loss: 0.17178 
Epoch [77/300] Training [7/62] Loss: 0.30081 
Epoch [77/300] Training [8/62] Loss: 0.46519 
Epoch [77/300] Training [9/62] Loss: 0.19997 
Epoch [77/300] Training [10/62] Loss: 0.18334 
Epoch [77/300] Training [11/62] Loss: 0.28668 
Epoch [77/300] Training [12/62] Loss: 0.23952 
Epoch [77/300] Training [13/62] Loss: 0.25967 
Epoch [77/300] Training [14/62] Loss: 0.21856 
Epoch [77/300] Training [15/62] Loss: 0.27920 
Epoch [77/300] Training [16/62] Loss: 0.27719 
Epoch [77/300] Training [17/62] Loss: 0.14739 
Epoch [77/300] Training [18/62] Loss: 0.27887 
Epoch [77/300] Training [19/62] Loss: 0.26706 
Epoch [77/300] Training [20/62] Loss: 0.16142 
Epoch [77/300] Training [21/62] Loss: 0.17394 
Epoch [77/300] Training [22/62] Loss: 0.17671 
Epoch [77/300] Training [23/62] Loss: 0.13160 
Epoch [77/300] Training [24/62] Loss: 0.27655 
Epoch [77/300] Training [25/62] Loss: 0.14459 
Epoch [77/300] Training [26/62] Loss: 0.20035 
Epoch [77/300] Training [27/62] Loss: 0.19864 
Epoch [77/300] Training [28/62] Loss: 0.38716 
Epoch [77/300] Training [29/62] Loss: 0.34105 
Epoch [77/300] Training [30/62] Loss: 0.28294 
Epoch [77/300] Training [31/62] Loss: 0.14900 
Epoch [77/300] Training [32/62] Loss: 0.19543 
Epoch [77/300] Training [33/62] Loss: 0.18765 
Epoch [77/300] Training [34/62] Loss: 0.37065 
Epoch [77/300] Training [35/62] Loss: 0.24192 
Epoch [77/300] Training [36/62] Loss: 0.31224 
Epoch [77/300] Training [37/62] Loss: 0.18331 
Epoch [77/300] Training [38/62] Loss: 0.32875 
Epoch [77/300] Training [39/62] Loss: 0.14996 
Epoch [77/300] Training [40/62] Loss: 0.14113 
Epoch [77/300] Training [41/62] Loss: 0.22640 
Epoch [77/300] Training [42/62] Loss: 0.15633 
Epoch [77/300] Training [43/62] Loss: 0.16763 
Epoch [77/300] Training [44/62] Loss: 0.35784 
Epoch [77/300] Training [45/62] Loss: 0.18084 
Epoch [77/300] Training [46/62] Loss: 0.17704 
Epoch [77/300] Training [47/62] Loss: 0.21840 
Epoch [77/300] Training [48/62] Loss: 0.27107 
Epoch [77/300] Training [49/62] Loss: 0.16478 
Epoch [77/300] Training [50/62] Loss: 0.16228 
Epoch [77/300] Training [51/62] Loss: 0.22665 
Epoch [77/300] Training [52/62] Loss: 0.32236 
Epoch [77/300] Training [53/62] Loss: 0.39540 
Epoch [77/300] Training [54/62] Loss: 0.08649 
Epoch [77/300] Training [55/62] Loss: 0.12595 
Epoch [77/300] Training [56/62] Loss: 0.41359 
Epoch [77/300] Training [57/62] Loss: 0.13008 
Epoch [77/300] Training [58/62] Loss: 0.19279 
Epoch [77/300] Training [59/62] Loss: 0.16248 
Epoch [77/300] Training [60/62] Loss: 0.19635 
Epoch [77/300] Training [61/62] Loss: 0.34235 
Epoch [77/300] Training [62/62] Loss: 0.75742 
Epoch [77/300] Training metric {'Train/mean dice_metric': 0.8408167958259583, 'Train/mean miou_metric': 0.7523205876350403, 'Train/mean f1': 0.8534755110740662, 'Train/mean precision': 0.8531339764595032, 'Train/mean recall': 0.853817343711853, 'Train/mean hd95_metric': 33.372859954833984}
Epoch [77/300] Validation [1/16] Loss: 0.18605  focal_loss 0.05940  dice_loss 0.12665 
Epoch [77/300] Validation [2/16] Loss: 0.45433  focal_loss 0.13232  dice_loss 0.32200 
Epoch [77/300] Validation [3/16] Loss: 0.82427  focal_loss 0.38864  dice_loss 0.43564 
Epoch [77/300] Validation [4/16] Loss: 0.25091  focal_loss 0.07127  dice_loss 0.17964 
Epoch [77/300] Validation [5/16] Loss: 0.40733  focal_loss 0.09105  dice_loss 0.31628 
Epoch [77/300] Validation [6/16] Loss: 0.21850  focal_loss 0.04260  dice_loss 0.17590 
Epoch [77/300] Validation [7/16] Loss: 0.24676  focal_loss 0.05853  dice_loss 0.18823 
Epoch [77/300] Validation [8/16] Loss: 0.29954  focal_loss 0.07109  dice_loss 0.22845 
Epoch [77/300] Validation [9/16] Loss: 0.24257  focal_loss 0.06140  dice_loss 0.18116 
Epoch [77/300] Validation [10/16] Loss: 0.33061  focal_loss 0.06969  dice_loss 0.26092 
Epoch [77/300] Validation [11/16] Loss: 0.15651  focal_loss 0.03556  dice_loss 0.12095 
Epoch [77/300] Validation [12/16] Loss: 0.38644  focal_loss 0.09251  dice_loss 0.29393 
Epoch [77/300] Validation [13/16] Loss: 0.35297  focal_loss 0.10256  dice_loss 0.25041 
Epoch [77/300] Validation [14/16] Loss: 0.54816  focal_loss 0.14352  dice_loss 0.40465 
Epoch [77/300] Validation [15/16] Loss: 0.18227  focal_loss 0.03601  dice_loss 0.14627 
Epoch [77/300] Validation [16/16] Loss: 0.09958  focal_loss 0.01467  dice_loss 0.08491 
Epoch [77/300] Validation metric {'Val/mean dice_metric': 0.8297445178031921, 'Val/mean miou_metric': 0.7409003973007202, 'Val/mean f1': 0.8363712430000305, 'Val/mean precision': 0.8225256204605103, 'Val/mean recall': 0.850691020488739, 'Val/mean hd95_metric': 36.374725341796875}
Cheakpoint...
Epoch [77/300] best acc:tensor([0.8297], device='cuda:0'), Now : mean acc: tensor([0.8297], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8297445178031921, 'Val/mean miou_metric': 0.7409003973007202, 'Val/mean f1': 0.8363712430000305, 'Val/mean precision': 0.8225256204605103, 'Val/mean recall': 0.850691020488739, 'Val/mean hd95_metric': 36.374725341796875}
Epoch [78/300] Training [1/62] Loss: 0.11449 
Epoch [78/300] Training [2/62] Loss: 0.26474 
Epoch [78/300] Training [3/62] Loss: 0.12319 
Epoch [78/300] Training [4/62] Loss: 0.16433 
Epoch [78/300] Training [5/62] Loss: 0.23821 
Epoch [78/300] Training [6/62] Loss: 0.20945 
Epoch [78/300] Training [7/62] Loss: 0.39884 
Epoch [78/300] Training [8/62] Loss: 0.20199 
Epoch [78/300] Training [9/62] Loss: 0.22109 
Epoch [78/300] Training [10/62] Loss: 0.32178 
Epoch [78/300] Training [11/62] Loss: 0.35277 
Epoch [78/300] Training [12/62] Loss: 0.17217 
Epoch [78/300] Training [13/62] Loss: 0.35213 
Epoch [78/300] Training [14/62] Loss: 0.31772 
Epoch [78/300] Training [15/62] Loss: 0.23745 
Epoch [78/300] Training [16/62] Loss: 0.23488 
Epoch [78/300] Training [17/62] Loss: 0.34485 
Epoch [78/300] Training [18/62] Loss: 0.36811 
Epoch [78/300] Training [19/62] Loss: 0.17448 
Epoch [78/300] Training [20/62] Loss: 0.20212 
Epoch [78/300] Training [21/62] Loss: 0.21370 
Epoch [78/300] Training [22/62] Loss: 0.32580 
Epoch [78/300] Training [23/62] Loss: 0.14474 
Epoch [78/300] Training [24/62] Loss: 0.25128 
Epoch [78/300] Training [25/62] Loss: 0.16991 
Epoch [78/300] Training [26/62] Loss: 0.13005 
Epoch [78/300] Training [27/62] Loss: 0.14179 
Epoch [78/300] Training [28/62] Loss: 0.23605 
Epoch [78/300] Training [29/62] Loss: 0.26205 
Epoch [78/300] Training [30/62] Loss: 0.28326 
Epoch [78/300] Training [31/62] Loss: 0.21488 
Epoch [78/300] Training [32/62] Loss: 0.39861 
Epoch [78/300] Training [33/62] Loss: 0.20092 
Epoch [78/300] Training [34/62] Loss: 0.20777 
Epoch [78/300] Training [35/62] Loss: 0.14684 
Epoch [78/300] Training [36/62] Loss: 0.16227 
Epoch [78/300] Training [37/62] Loss: 0.28060 
Epoch [78/300] Training [38/62] Loss: 0.29834 
Epoch [78/300] Training [39/62] Loss: 0.14710 
Epoch [78/300] Training [40/62] Loss: 0.26557 
Epoch [78/300] Training [41/62] Loss: 0.27623 
Epoch [78/300] Training [42/62] Loss: 0.14273 
Epoch [78/300] Training [43/62] Loss: 0.15077 
Epoch [78/300] Training [44/62] Loss: 0.16641 
Epoch [78/300] Training [45/62] Loss: 0.32729 
Epoch [78/300] Training [46/62] Loss: 0.17559 
Epoch [78/300] Training [47/62] Loss: 0.22834 
Epoch [78/300] Training [48/62] Loss: 0.34331 
Epoch [78/300] Training [49/62] Loss: 0.40208 
Epoch [78/300] Training [50/62] Loss: 0.30154 
Epoch [78/300] Training [51/62] Loss: 0.38317 
Epoch [78/300] Training [52/62] Loss: 0.33169 
Epoch [78/300] Training [53/62] Loss: 0.32899 
Epoch [78/300] Training [54/62] Loss: 0.31300 
Epoch [78/300] Training [55/62] Loss: 0.61029 
Epoch [78/300] Training [56/62] Loss: 0.15908 
Epoch [78/300] Training [57/62] Loss: 0.15400 
Epoch [78/300] Training [58/62] Loss: 0.28570 
Epoch [78/300] Training [59/62] Loss: 0.23833 
Epoch [78/300] Training [60/62] Loss: 0.17021 
Epoch [78/300] Training [61/62] Loss: 0.26706 
Epoch [78/300] Training [62/62] Loss: 0.20831 
Epoch [78/300] Training metric {'Train/mean dice_metric': 0.8338344693183899, 'Train/mean miou_metric': 0.7487590909004211, 'Train/mean f1': 0.8379077911376953, 'Train/mean precision': 0.8148582577705383, 'Train/mean recall': 0.8622992634773254, 'Train/mean hd95_metric': 35.6231689453125}
Epoch [78/300] Validation [1/16] Loss: 0.19205  focal_loss 0.04487  dice_loss 0.14718 
Epoch [78/300] Validation [2/16] Loss: 0.29123  focal_loss 0.04073  dice_loss 0.25050 
Epoch [78/300] Validation [3/16] Loss: 0.67751  focal_loss 0.31736  dice_loss 0.36015 
Epoch [78/300] Validation [4/16] Loss: 0.37924  focal_loss 0.10659  dice_loss 0.27265 
Epoch [78/300] Validation [5/16] Loss: 0.40374  focal_loss 0.10621  dice_loss 0.29753 
Epoch [78/300] Validation [6/16] Loss: 0.34045  focal_loss 0.06672  dice_loss 0.27373 
Epoch [78/300] Validation [7/16] Loss: 0.26950  focal_loss 0.06609  dice_loss 0.20341 
Epoch [78/300] Validation [8/16] Loss: 0.32401  focal_loss 0.05023  dice_loss 0.27378 
Epoch [78/300] Validation [9/16] Loss: 0.35722  focal_loss 0.10048  dice_loss 0.25674 
Epoch [78/300] Validation [10/16] Loss: 0.36035  focal_loss 0.07248  dice_loss 0.28786 
Epoch [78/300] Validation [11/16] Loss: 0.28158  focal_loss 0.06513  dice_loss 0.21644 
Epoch [78/300] Validation [12/16] Loss: 0.43334  focal_loss 0.06136  dice_loss 0.37198 
Epoch [78/300] Validation [13/16] Loss: 0.31359  focal_loss 0.06636  dice_loss 0.24723 
Epoch [78/300] Validation [14/16] Loss: 0.49286  focal_loss 0.11241  dice_loss 0.38045 
Epoch [78/300] Validation [15/16] Loss: 0.25439  focal_loss 0.04909  dice_loss 0.20530 
Epoch [78/300] Validation [16/16] Loss: 0.11029  focal_loss 0.01891  dice_loss 0.09139 
Epoch [78/300] Validation metric {'Val/mean dice_metric': 0.8197874426841736, 'Val/mean miou_metric': 0.7328061461448669, 'Val/mean f1': 0.8218035697937012, 'Val/mean precision': 0.7918342351913452, 'Val/mean recall': 0.8541308045387268, 'Val/mean hd95_metric': 38.717350006103516}
Cheakpoint...
Epoch [78/300] best acc:tensor([0.8297], device='cuda:0'), Now : mean acc: tensor([0.8198], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8197874426841736, 'Val/mean miou_metric': 0.7328061461448669, 'Val/mean f1': 0.8218035697937012, 'Val/mean precision': 0.7918342351913452, 'Val/mean recall': 0.8541308045387268, 'Val/mean hd95_metric': 38.717350006103516}
Epoch [79/300] Training [1/62] Loss: 0.25592 
Epoch [79/300] Training [2/62] Loss: 0.35977 
Epoch [79/300] Training [3/62] Loss: 0.22583 
Epoch [79/300] Training [4/62] Loss: 0.29570 
Epoch [79/300] Training [5/62] Loss: 0.23221 
Epoch [79/300] Training [6/62] Loss: 0.16241 
Epoch [79/300] Training [7/62] Loss: 0.23453 
Epoch [79/300] Training [8/62] Loss: 0.16716 
Epoch [79/300] Training [9/62] Loss: 0.15726 
Epoch [79/300] Training [10/62] Loss: 0.19042 
Epoch [79/300] Training [11/62] Loss: 0.28922 
Epoch [79/300] Training [12/62] Loss: 0.13655 
Epoch [79/300] Training [13/62] Loss: 0.48839 
Epoch [79/300] Training [14/62] Loss: 0.35732 
Epoch [79/300] Training [15/62] Loss: 0.21841 
Epoch [79/300] Training [16/62] Loss: 0.30488 
Epoch [79/300] Training [17/62] Loss: 0.15897 
Epoch [79/300] Training [18/62] Loss: 0.24140 
Epoch [79/300] Training [19/62] Loss: 0.14961 
Epoch [79/300] Training [20/62] Loss: 0.21680 
Epoch [79/300] Training [21/62] Loss: 0.11949 
Epoch [79/300] Training [22/62] Loss: 0.14145 
Epoch [79/300] Training [23/62] Loss: 0.17975 
Epoch [79/300] Training [24/62] Loss: 0.18249 
Epoch [79/300] Training [25/62] Loss: 0.57827 
Epoch [79/300] Training [26/62] Loss: 0.24832 
Epoch [79/300] Training [27/62] Loss: 0.24643 
Epoch [79/300] Training [28/62] Loss: 0.18162 
Epoch [79/300] Training [29/62] Loss: 0.14010 
Epoch [79/300] Training [30/62] Loss: 0.18735 
Epoch [79/300] Training [31/62] Loss: 0.22809 
Epoch [79/300] Training [32/62] Loss: 0.29385 
Epoch [79/300] Training [33/62] Loss: 0.21905 
Epoch [79/300] Training [34/62] Loss: 0.19244 
Epoch [79/300] Training [35/62] Loss: 0.29787 
Epoch [79/300] Training [36/62] Loss: 0.21383 
Epoch [79/300] Training [37/62] Loss: 0.29359 
Epoch [79/300] Training [38/62] Loss: 0.15984 
Epoch [79/300] Training [39/62] Loss: 0.16852 
Epoch [79/300] Training [40/62] Loss: 0.14338 
Epoch [79/300] Training [41/62] Loss: 0.21206 
Epoch [79/300] Training [42/62] Loss: 0.15758 
Epoch [79/300] Training [43/62] Loss: 0.28428 
Epoch [79/300] Training [44/62] Loss: 0.11518 
Epoch [79/300] Training [45/62] Loss: 0.28509 
Epoch [79/300] Training [46/62] Loss: 0.19757 
Epoch [79/300] Training [47/62] Loss: 0.52507 
Epoch [79/300] Training [48/62] Loss: 0.25151 
Epoch [79/300] Training [49/62] Loss: 0.24846 
Epoch [79/300] Training [50/62] Loss: 0.23201 
Epoch [79/300] Training [51/62] Loss: 0.28868 
Epoch [79/300] Training [52/62] Loss: 0.20200 
Epoch [79/300] Training [53/62] Loss: 0.21247 
Epoch [79/300] Training [54/62] Loss: 0.38268 
Epoch [79/300] Training [55/62] Loss: 0.16706 
Epoch [79/300] Training [56/62] Loss: 0.19401 
Epoch [79/300] Training [57/62] Loss: 0.14886 
Epoch [79/300] Training [58/62] Loss: 0.31562 
Epoch [79/300] Training [59/62] Loss: 0.30273 
Epoch [79/300] Training [60/62] Loss: 0.16127 
Epoch [79/300] Training [61/62] Loss: 0.36913 
Epoch [79/300] Training [62/62] Loss: 0.08453 
Epoch [79/300] Training metric {'Train/mean dice_metric': 0.8365446329116821, 'Train/mean miou_metric': 0.7502665519714355, 'Train/mean f1': 0.8517225980758667, 'Train/mean precision': 0.839541494846344, 'Train/mean recall': 0.8642625212669373, 'Train/mean hd95_metric': 33.58087921142578}
Epoch [79/300] Validation [1/16] Loss: 0.15227  focal_loss 0.04135  dice_loss 0.11092 
Epoch [79/300] Validation [2/16] Loss: 0.37767  focal_loss 0.09559  dice_loss 0.28208 
Epoch [79/300] Validation [3/16] Loss: 0.26748  focal_loss 0.04034  dice_loss 0.22714 
Epoch [79/300] Validation [4/16] Loss: 0.21990  focal_loss 0.03020  dice_loss 0.18970 
Epoch [79/300] Validation [5/16] Loss: 0.39530  focal_loss 0.06555  dice_loss 0.32975 
Epoch [79/300] Validation [6/16] Loss: 0.30960  focal_loss 0.04519  dice_loss 0.26442 
Epoch [79/300] Validation [7/16] Loss: 0.19374  focal_loss 0.04020  dice_loss 0.15354 
Epoch [79/300] Validation [8/16] Loss: 0.51190  focal_loss 0.10074  dice_loss 0.41116 
Epoch [79/300] Validation [9/16] Loss: 0.28654  focal_loss 0.07451  dice_loss 0.21202 
Epoch [79/300] Validation [10/16] Loss: 0.23053  focal_loss 0.03109  dice_loss 0.19943 
Epoch [79/300] Validation [11/16] Loss: 0.30160  focal_loss 0.07374  dice_loss 0.22786 
Epoch [79/300] Validation [12/16] Loss: 0.32144  focal_loss 0.05667  dice_loss 0.26477 
Epoch [79/300] Validation [13/16] Loss: 0.25093  focal_loss 0.04466  dice_loss 0.20626 
Epoch [79/300] Validation [14/16] Loss: 0.57785  focal_loss 0.10468  dice_loss 0.47317 
Epoch [79/300] Validation [15/16] Loss: 0.27697  focal_loss 0.06403  dice_loss 0.21293 
Epoch [79/300] Validation [16/16] Loss: 0.09826  focal_loss 0.01566  dice_loss 0.08260 
Epoch [79/300] Validation metric {'Val/mean dice_metric': 0.82745760679245, 'Val/mean miou_metric': 0.7401260733604431, 'Val/mean f1': 0.8395388722419739, 'Val/mean precision': 0.8112102150917053, 'Val/mean recall': 0.8699175715446472, 'Val/mean hd95_metric': 38.47809600830078}
Cheakpoint...
Epoch [79/300] best acc:tensor([0.8297], device='cuda:0'), Now : mean acc: tensor([0.8275], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.82745760679245, 'Val/mean miou_metric': 0.7401260733604431, 'Val/mean f1': 0.8395388722419739, 'Val/mean precision': 0.8112102150917053, 'Val/mean recall': 0.8699175715446472, 'Val/mean hd95_metric': 38.47809600830078}
Epoch [80/300] Training [1/62] Loss: 0.22596 
Epoch [80/300] Training [2/62] Loss: 0.30079 
Epoch [80/300] Training [3/62] Loss: 0.19197 
Epoch [80/300] Training [4/62] Loss: 0.18805 
Epoch [80/300] Training [5/62] Loss: 0.22041 
Epoch [80/300] Training [6/62] Loss: 0.24999 
Epoch [80/300] Training [7/62] Loss: 0.27117 
Epoch [80/300] Training [8/62] Loss: 0.16518 
Epoch [80/300] Training [9/62] Loss: 0.18689 
Epoch [80/300] Training [10/62] Loss: 0.15748 
Epoch [80/300] Training [11/62] Loss: 0.15280 
Epoch [80/300] Training [12/62] Loss: 0.13535 
Epoch [80/300] Training [13/62] Loss: 0.16333 
Epoch [80/300] Training [14/62] Loss: 0.10050 
Epoch [80/300] Training [15/62] Loss: 0.10673 
Epoch [80/300] Training [16/62] Loss: 0.34647 
Epoch [80/300] Training [17/62] Loss: 0.21553 
Epoch [80/300] Training [18/62] Loss: 0.18793 
Epoch [80/300] Training [19/62] Loss: 0.32067 
Epoch [80/300] Training [20/62] Loss: 0.21122 
Epoch [80/300] Training [21/62] Loss: 0.25607 
Epoch [80/300] Training [22/62] Loss: 0.40562 
Epoch [80/300] Training [23/62] Loss: 0.22294 
Epoch [80/300] Training [24/62] Loss: 0.22412 
Epoch [80/300] Training [25/62] Loss: 0.39835 
Epoch [80/300] Training [26/62] Loss: 0.19416 
Epoch [80/300] Training [27/62] Loss: 0.19700 
Epoch [80/300] Training [28/62] Loss: 0.16888 
Epoch [80/300] Training [29/62] Loss: 0.10376 
Epoch [80/300] Training [30/62] Loss: 0.20125 
Epoch [80/300] Training [31/62] Loss: 0.27107 
Epoch [80/300] Training [32/62] Loss: 0.27030 
Epoch [80/300] Training [33/62] Loss: 0.18023 
Epoch [80/300] Training [34/62] Loss: 0.20583 
Epoch [80/300] Training [35/62] Loss: 0.33011 
Epoch [80/300] Training [36/62] Loss: 0.26927 
Epoch [80/300] Training [37/62] Loss: 0.22972 
Epoch [80/300] Training [38/62] Loss: 0.17242 
Epoch [80/300] Training [39/62] Loss: 0.13125 
Epoch [80/300] Training [40/62] Loss: 0.25114 
Epoch [80/300] Training [41/62] Loss: 0.29689 
Epoch [80/300] Training [42/62] Loss: 0.21742 
Epoch [80/300] Training [43/62] Loss: 0.13337 
Epoch [80/300] Training [44/62] Loss: 0.23969 
Epoch [80/300] Training [45/62] Loss: 0.16576 
Epoch [80/300] Training [46/62] Loss: 0.12275 
Epoch [80/300] Training [47/62] Loss: 0.28678 
Epoch [80/300] Training [48/62] Loss: 0.22863 
Epoch [80/300] Training [49/62] Loss: 0.14018 
Epoch [80/300] Training [50/62] Loss: 0.27240 
Epoch [80/300] Training [51/62] Loss: 0.20336 
Epoch [80/300] Training [52/62] Loss: 0.25022 
Epoch [80/300] Training [53/62] Loss: 0.33047 
Epoch [80/300] Training [54/62] Loss: 0.43321 
Epoch [80/300] Training [55/62] Loss: 0.17587 
Epoch [80/300] Training [56/62] Loss: 0.24466 
Epoch [80/300] Training [57/62] Loss: 0.21512 
Epoch [80/300] Training [58/62] Loss: 0.33292 
Epoch [80/300] Training [59/62] Loss: 0.22578 
Epoch [80/300] Training [60/62] Loss: 0.18029 
Epoch [80/300] Training [61/62] Loss: 0.22774 
Epoch [80/300] Training [62/62] Loss: 0.20264 
Epoch [80/300] Training metric {'Train/mean dice_metric': 0.8462942838668823, 'Train/mean miou_metric': 0.7595245838165283, 'Train/mean f1': 0.8612090945243835, 'Train/mean precision': 0.8501695990562439, 'Train/mean recall': 0.8725390434265137, 'Train/mean hd95_metric': 30.81813621520996}
Epoch [80/300] Validation [1/16] Loss: 0.12026  focal_loss 0.03416  dice_loss 0.08611 
Epoch [80/300] Validation [2/16] Loss: 0.41290  focal_loss 0.09743  dice_loss 0.31547 
Epoch [80/300] Validation [3/16] Loss: 0.41250  focal_loss 0.13933  dice_loss 0.27317 
Epoch [80/300] Validation [4/16] Loss: 0.27600  focal_loss 0.07700  dice_loss 0.19901 
Epoch [80/300] Validation [5/16] Loss: 0.39786  focal_loss 0.09401  dice_loss 0.30385 
Epoch [80/300] Validation [6/16] Loss: 0.19113  focal_loss 0.03208  dice_loss 0.15905 
Epoch [80/300] Validation [7/16] Loss: 0.23261  focal_loss 0.06819  dice_loss 0.16442 
Epoch [80/300] Validation [8/16] Loss: 0.44529  focal_loss 0.15444  dice_loss 0.29085 
Epoch [80/300] Validation [9/16] Loss: 0.25708  focal_loss 0.07389  dice_loss 0.18319 
Epoch [80/300] Validation [10/16] Loss: 0.43305  focal_loss 0.15322  dice_loss 0.27983 
Epoch [80/300] Validation [11/16] Loss: 0.15288  focal_loss 0.03959  dice_loss 0.11329 
Epoch [80/300] Validation [12/16] Loss: 0.34302  focal_loss 0.05702  dice_loss 0.28600 
Epoch [80/300] Validation [13/16] Loss: 0.32047  focal_loss 0.07419  dice_loss 0.24628 
Epoch [80/300] Validation [14/16] Loss: 0.56958  focal_loss 0.17953  dice_loss 0.39006 
Epoch [80/300] Validation [15/16] Loss: 0.15306  focal_loss 0.04223  dice_loss 0.11082 
Epoch [80/300] Validation [16/16] Loss: 0.06666  focal_loss 0.01090  dice_loss 0.05576 
Epoch [80/300] Validation metric {'Val/mean dice_metric': 0.8361595273017883, 'Val/mean miou_metric': 0.7488667368888855, 'Val/mean f1': 0.8497419357299805, 'Val/mean precision': 0.8329585790634155, 'Val/mean recall': 0.8672155141830444, 'Val/mean hd95_metric': 33.48274612426758}
Cheakpoint...
Epoch [80/300] best acc:tensor([0.8362], device='cuda:0'), Now : mean acc: tensor([0.8362], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8361595273017883, 'Val/mean miou_metric': 0.7488667368888855, 'Val/mean f1': 0.8497419357299805, 'Val/mean precision': 0.8329585790634155, 'Val/mean recall': 0.8672155141830444, 'Val/mean hd95_metric': 33.48274612426758}
Epoch [81/300] Training [1/62] Loss: 0.22996 
Epoch [81/300] Training [2/62] Loss: 0.19166 
Epoch [81/300] Training [3/62] Loss: 0.11673 
Epoch [81/300] Training [4/62] Loss: 0.16490 
Epoch [81/300] Training [5/62] Loss: 0.12152 
Epoch [81/300] Training [6/62] Loss: 0.27436 
Epoch [81/300] Training [7/62] Loss: 0.09591 
Epoch [81/300] Training [8/62] Loss: 0.27504 
Epoch [81/300] Training [9/62] Loss: 0.11973 
Epoch [81/300] Training [10/62] Loss: 0.13274 
Epoch [81/300] Training [11/62] Loss: 0.18122 
Epoch [81/300] Training [12/62] Loss: 0.11908 
Epoch [81/300] Training [13/62] Loss: 0.12780 
Epoch [81/300] Training [14/62] Loss: 0.27894 
Epoch [81/300] Training [15/62] Loss: 0.29802 
Epoch [81/300] Training [16/62] Loss: 0.11990 
Epoch [81/300] Training [17/62] Loss: 0.27967 
Epoch [81/300] Training [18/62] Loss: 0.30775 
Epoch [81/300] Training [19/62] Loss: 0.15217 
Epoch [81/300] Training [20/62] Loss: 0.29523 
Epoch [81/300] Training [21/62] Loss: 0.18611 
Epoch [81/300] Training [22/62] Loss: 0.12119 
Epoch [81/300] Training [23/62] Loss: 0.26162 
Epoch [81/300] Training [24/62] Loss: 0.10565 
Epoch [81/300] Training [25/62] Loss: 0.19660 
Epoch [81/300] Training [26/62] Loss: 0.19116 
Epoch [81/300] Training [27/62] Loss: 0.17526 
Epoch [81/300] Training [28/62] Loss: 0.16039 
Epoch [81/300] Training [29/62] Loss: 0.15350 
Epoch [81/300] Training [30/62] Loss: 0.21650 
Epoch [81/300] Training [31/62] Loss: 0.16185 
Epoch [81/300] Training [32/62] Loss: 0.12210 
Epoch [81/300] Training [33/62] Loss: 0.13665 
Epoch [81/300] Training [34/62] Loss: 0.25720 
Epoch [81/300] Training [35/62] Loss: 0.11373 
Epoch [81/300] Training [36/62] Loss: 0.26496 
Epoch [81/300] Training [37/62] Loss: 0.16943 
Epoch [81/300] Training [38/62] Loss: 0.42191 
Epoch [81/300] Training [39/62] Loss: 0.22148 
Epoch [81/300] Training [40/62] Loss: 0.14274 
Epoch [81/300] Training [41/62] Loss: 0.44400 
Epoch [81/300] Training [42/62] Loss: 0.15386 
Epoch [81/300] Training [43/62] Loss: 0.18805 
Epoch [81/300] Training [44/62] Loss: 0.19175 
Epoch [81/300] Training [45/62] Loss: 0.35920 
Epoch [81/300] Training [46/62] Loss: 0.19798 
Epoch [81/300] Training [47/62] Loss: 0.20152 
Epoch [81/300] Training [48/62] Loss: 0.27501 
Epoch [81/300] Training [49/62] Loss: 0.24125 
Epoch [81/300] Training [50/62] Loss: 0.32970 
Epoch [81/300] Training [51/62] Loss: 0.26999 
Epoch [81/300] Training [52/62] Loss: 0.46598 
Epoch [81/300] Training [53/62] Loss: 0.20200 
Epoch [81/300] Training [54/62] Loss: 0.36777 
Epoch [81/300] Training [55/62] Loss: 0.21505 
Epoch [81/300] Training [56/62] Loss: 0.33747 
Epoch [81/300] Training [57/62] Loss: 0.27713 
Epoch [81/300] Training [58/62] Loss: 0.14356 
Epoch [81/300] Training [59/62] Loss: 0.18519 
Epoch [81/300] Training [60/62] Loss: 0.24167 
Epoch [81/300] Training [61/62] Loss: 0.23844 
Epoch [81/300] Training [62/62] Loss: 0.22668 
Epoch [81/300] Training metric {'Train/mean dice_metric': 0.853304922580719, 'Train/mean miou_metric': 0.7708578109741211, 'Train/mean f1': 0.8646036386489868, 'Train/mean precision': 0.8451824188232422, 'Train/mean recall': 0.8849383592605591, 'Train/mean hd95_metric': 31.32758903503418}
Epoch [81/300] Validation [1/16] Loss: 0.15757  focal_loss 0.05142  dice_loss 0.10615 
Epoch [81/300] Validation [2/16] Loss: 0.36619  focal_loss 0.10502  dice_loss 0.26117 
Epoch [81/300] Validation [3/16] Loss: 0.32040  focal_loss 0.08171  dice_loss 0.23869 
Epoch [81/300] Validation [4/16] Loss: 0.36341  focal_loss 0.14477  dice_loss 0.21864 
Epoch [81/300] Validation [5/16] Loss: 0.30011  focal_loss 0.08161  dice_loss 0.21850 
Epoch [81/300] Validation [6/16] Loss: 0.34842  focal_loss 0.11259  dice_loss 0.23584 
Epoch [81/300] Validation [7/16] Loss: 0.33237  focal_loss 0.11365  dice_loss 0.21873 
Epoch [81/300] Validation [8/16] Loss: 0.48101  focal_loss 0.11317  dice_loss 0.36784 
Epoch [81/300] Validation [9/16] Loss: 0.29483  focal_loss 0.09061  dice_loss 0.20422 
Epoch [81/300] Validation [10/16] Loss: 0.31059  focal_loss 0.08631  dice_loss 0.22428 
Epoch [81/300] Validation [11/16] Loss: 0.22767  focal_loss 0.06445  dice_loss 0.16322 
Epoch [81/300] Validation [12/16] Loss: 0.35758  focal_loss 0.09047  dice_loss 0.26711 
Epoch [81/300] Validation [13/16] Loss: 0.36185  focal_loss 0.15325  dice_loss 0.20859 
Epoch [81/300] Validation [14/16] Loss: 0.65740  focal_loss 0.25342  dice_loss 0.40397 
Epoch [81/300] Validation [15/16] Loss: 0.28850  focal_loss 0.09363  dice_loss 0.19487 
Epoch [81/300] Validation [16/16] Loss: 0.07705  focal_loss 0.01404  dice_loss 0.06300 
Epoch [81/300] Validation metric {'Val/mean dice_metric': 0.8394434452056885, 'Val/mean miou_metric': 0.7543967962265015, 'Val/mean f1': 0.8493691086769104, 'Val/mean precision': 0.8393149375915527, 'Val/mean recall': 0.8596670627593994, 'Val/mean hd95_metric': 35.07598114013672}
Cheakpoint...
Epoch [81/300] best acc:tensor([0.8394], device='cuda:0'), Now : mean acc: tensor([0.8394], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8394434452056885, 'Val/mean miou_metric': 0.7543967962265015, 'Val/mean f1': 0.8493691086769104, 'Val/mean precision': 0.8393149375915527, 'Val/mean recall': 0.8596670627593994, 'Val/mean hd95_metric': 35.07598114013672}
Epoch [82/300] Training [1/62] Loss: 0.20417 
Epoch [82/300] Training [2/62] Loss: 0.12590 
Epoch [82/300] Training [3/62] Loss: 0.21661 
Epoch [82/300] Training [4/62] Loss: 0.14507 
Epoch [82/300] Training [5/62] Loss: 0.20354 
Epoch [82/300] Training [6/62] Loss: 0.22990 
Epoch [82/300] Training [7/62] Loss: 0.18977 
Epoch [82/300] Training [8/62] Loss: 0.30540 
Epoch [82/300] Training [9/62] Loss: 0.12366 
Epoch [82/300] Training [10/62] Loss: 0.21337 
Epoch [82/300] Training [11/62] Loss: 0.17925 
Epoch [82/300] Training [12/62] Loss: 0.13009 
Epoch [82/300] Training [13/62] Loss: 0.19100 
Epoch [82/300] Training [14/62] Loss: 0.19119 
Epoch [82/300] Training [15/62] Loss: 0.16699 
Epoch [82/300] Training [16/62] Loss: 0.17431 
Epoch [82/300] Training [17/62] Loss: 0.29808 
Epoch [82/300] Training [18/62] Loss: 0.17786 
Epoch [82/300] Training [19/62] Loss: 0.29374 
Epoch [82/300] Training [20/62] Loss: 0.23936 
Epoch [82/300] Training [21/62] Loss: 0.22209 
Epoch [82/300] Training [22/62] Loss: 0.14070 
Epoch [82/300] Training [23/62] Loss: 0.23364 
Epoch [82/300] Training [24/62] Loss: 0.30479 
Epoch [82/300] Training [25/62] Loss: 0.14144 
Epoch [82/300] Training [26/62] Loss: 0.32777 
Epoch [82/300] Training [27/62] Loss: 0.17831 
Epoch [82/300] Training [28/62] Loss: 0.30249 
Epoch [82/300] Training [29/62] Loss: 0.30319 
Epoch [82/300] Training [30/62] Loss: 0.16724 
Epoch [82/300] Training [31/62] Loss: 0.41255 
Epoch [82/300] Training [32/62] Loss: 0.38150 
Epoch [82/300] Training [33/62] Loss: 0.14131 
Epoch [82/300] Training [34/62] Loss: 0.37616 
Epoch [82/300] Training [35/62] Loss: 0.17977 
Epoch [82/300] Training [36/62] Loss: 0.17262 
Epoch [82/300] Training [37/62] Loss: 0.18690 
Epoch [82/300] Training [38/62] Loss: 0.16860 
Epoch [82/300] Training [39/62] Loss: 0.20181 
Epoch [82/300] Training [40/62] Loss: 0.37512 
Epoch [82/300] Training [41/62] Loss: 0.06661 
Epoch [82/300] Training [42/62] Loss: 0.21267 
Epoch [82/300] Training [43/62] Loss: 0.19528 
Epoch [82/300] Training [44/62] Loss: 0.25742 
Epoch [82/300] Training [45/62] Loss: 0.32566 
Epoch [82/300] Training [46/62] Loss: 0.12666 
Epoch [82/300] Training [47/62] Loss: 0.25377 
Epoch [82/300] Training [48/62] Loss: 0.10865 
Epoch [82/300] Training [49/62] Loss: 0.23159 
Epoch [82/300] Training [50/62] Loss: 0.14675 
Epoch [82/300] Training [51/62] Loss: 0.26425 
Epoch [82/300] Training [52/62] Loss: 0.30113 
Epoch [82/300] Training [53/62] Loss: 0.37437 
Epoch [82/300] Training [54/62] Loss: 0.22451 
Epoch [82/300] Training [55/62] Loss: 0.21314 
Epoch [82/300] Training [56/62] Loss: 0.16468 
Epoch [82/300] Training [57/62] Loss: 0.24682 
Epoch [82/300] Training [58/62] Loss: 0.20704 
Epoch [82/300] Training [59/62] Loss: 0.15130 
Epoch [82/300] Training [60/62] Loss: 0.15109 
Epoch [82/300] Training [61/62] Loss: 0.26495 
Epoch [82/300] Training [62/62] Loss: 0.08713 
Epoch [82/300] Training metric {'Train/mean dice_metric': 0.8490869998931885, 'Train/mean miou_metric': 0.766320526599884, 'Train/mean f1': 0.86822110414505, 'Train/mean precision': 0.8603712916374207, 'Train/mean recall': 0.8762154579162598, 'Train/mean hd95_metric': 30.125476837158203}
Epoch [82/300] Validation [1/16] Loss: 0.18222  focal_loss 0.06509  dice_loss 0.11713 
Epoch [82/300] Validation [2/16] Loss: 0.49077  focal_loss 0.15390  dice_loss 0.33687 
Epoch [82/300] Validation [3/16] Loss: 0.54143  focal_loss 0.25265  dice_loss 0.28878 
Epoch [82/300] Validation [4/16] Loss: 0.32392  focal_loss 0.12072  dice_loss 0.20321 
Epoch [82/300] Validation [5/16] Loss: 0.36655  focal_loss 0.10491  dice_loss 0.26164 
Epoch [82/300] Validation [6/16] Loss: 0.17837  focal_loss 0.03183  dice_loss 0.14654 
Epoch [82/300] Validation [7/16] Loss: 0.31829  focal_loss 0.13238  dice_loss 0.18591 
Epoch [82/300] Validation [8/16] Loss: 0.27426  focal_loss 0.04700  dice_loss 0.22727 
Epoch [82/300] Validation [9/16] Loss: 0.20819  focal_loss 0.04609  dice_loss 0.16209 
Epoch [82/300] Validation [10/16] Loss: 0.30710  focal_loss 0.05519  dice_loss 0.25190 
Epoch [82/300] Validation [11/16] Loss: 0.17818  focal_loss 0.04247  dice_loss 0.13571 
Epoch [82/300] Validation [12/16] Loss: 0.33110  focal_loss 0.06429  dice_loss 0.26680 
Epoch [82/300] Validation [13/16] Loss: 0.28559  focal_loss 0.07124  dice_loss 0.21435 
Epoch [82/300] Validation [14/16] Loss: 0.50722  focal_loss 0.10728  dice_loss 0.39994 
Epoch [82/300] Validation [15/16] Loss: 0.13184  focal_loss 0.03114  dice_loss 0.10071 
Epoch [82/300] Validation [16/16] Loss: 0.07684  focal_loss 0.01578  dice_loss 0.06106 
Epoch [82/300] Validation metric {'Val/mean dice_metric': 0.8395096659660339, 'Val/mean miou_metric': 0.7563034296035767, 'Val/mean f1': 0.858138382434845, 'Val/mean precision': 0.8571593165397644, 'Val/mean recall': 0.8591194748878479, 'Val/mean hd95_metric': 33.15565490722656}
Cheakpoint...
Epoch [82/300] best acc:tensor([0.8395], device='cuda:0'), Now : mean acc: tensor([0.8395], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8395096659660339, 'Val/mean miou_metric': 0.7563034296035767, 'Val/mean f1': 0.858138382434845, 'Val/mean precision': 0.8571593165397644, 'Val/mean recall': 0.8591194748878479, 'Val/mean hd95_metric': 33.15565490722656}
Epoch [83/300] Training [1/62] Loss: 0.19610 
Epoch [83/300] Training [2/62] Loss: 0.24744 
Epoch [83/300] Training [3/62] Loss: 0.15561 
Epoch [83/300] Training [4/62] Loss: 0.18127 
Epoch [83/300] Training [5/62] Loss: 0.18268 
Epoch [83/300] Training [6/62] Loss: 0.31249 
Epoch [83/300] Training [7/62] Loss: 0.14269 
Epoch [83/300] Training [8/62] Loss: 0.14396 
Epoch [83/300] Training [9/62] Loss: 0.19165 
Epoch [83/300] Training [10/62] Loss: 0.19937 
Epoch [83/300] Training [11/62] Loss: 0.12746 
Epoch [83/300] Training [12/62] Loss: 0.17837 
Epoch [83/300] Training [13/62] Loss: 0.22215 
Epoch [83/300] Training [14/62] Loss: 0.34709 
Epoch [83/300] Training [15/62] Loss: 0.19549 
Epoch [83/300] Training [16/62] Loss: 0.21876 
Epoch [83/300] Training [17/62] Loss: 0.22760 
Epoch [83/300] Training [18/62] Loss: 0.24377 
Epoch [83/300] Training [19/62] Loss: 0.11484 
Epoch [83/300] Training [20/62] Loss: 0.21831 
Epoch [83/300] Training [21/62] Loss: 0.15292 
Epoch [83/300] Training [22/62] Loss: 0.20909 
Epoch [83/300] Training [23/62] Loss: 0.34743 
Epoch [83/300] Training [24/62] Loss: 0.35415 
Epoch [83/300] Training [25/62] Loss: 0.21393 
Epoch [83/300] Training [26/62] Loss: 0.11536 
Epoch [83/300] Training [27/62] Loss: 0.24686 
Epoch [83/300] Training [28/62] Loss: 0.15315 
Epoch [83/300] Training [29/62] Loss: 0.15546 
Epoch [83/300] Training [30/62] Loss: 0.28602 
Epoch [83/300] Training [31/62] Loss: 0.13000 
Epoch [83/300] Training [32/62] Loss: 0.16447 
Epoch [83/300] Training [33/62] Loss: 0.21451 
Epoch [83/300] Training [34/62] Loss: 0.10185 
Epoch [83/300] Training [35/62] Loss: 0.11094 
Epoch [83/300] Training [36/62] Loss: 0.11725 
Epoch [83/300] Training [37/62] Loss: 0.15819 
Epoch [83/300] Training [38/62] Loss: 0.12875 
Epoch [83/300] Training [39/62] Loss: 0.32084 
Epoch [83/300] Training [40/62] Loss: 0.50402 
Epoch [83/300] Training [41/62] Loss: 0.13273 
Epoch [83/300] Training [42/62] Loss: 0.31442 
Epoch [83/300] Training [43/62] Loss: 0.16713 
Epoch [83/300] Training [44/62] Loss: 0.18443 
Epoch [83/300] Training [45/62] Loss: 0.10895 
Epoch [83/300] Training [46/62] Loss: 0.25550 
Epoch [83/300] Training [47/62] Loss: 0.20591 
Epoch [83/300] Training [48/62] Loss: 0.19114 
Epoch [83/300] Training [49/62] Loss: 0.22963 
Epoch [83/300] Training [50/62] Loss: 0.21753 
Epoch [83/300] Training [51/62] Loss: 0.42820 
Epoch [83/300] Training [52/62] Loss: 0.14089 
Epoch [83/300] Training [53/62] Loss: 0.21662 
Epoch [83/300] Training [54/62] Loss: 0.17490 
Epoch [83/300] Training [55/62] Loss: 0.49051 
Epoch [83/300] Training [56/62] Loss: 0.18449 
Epoch [83/300] Training [57/62] Loss: 0.19123 
Epoch [83/300] Training [58/62] Loss: 0.23898 
Epoch [83/300] Training [59/62] Loss: 0.13076 
Epoch [83/300] Training [60/62] Loss: 0.21336 
Epoch [83/300] Training [61/62] Loss: 0.19198 
Epoch [83/300] Training [62/62] Loss: 0.06050 
Epoch [83/300] Training metric {'Train/mean dice_metric': 0.8570295572280884, 'Train/mean miou_metric': 0.7766269445419312, 'Train/mean f1': 0.8640345335006714, 'Train/mean precision': 0.8474668860435486, 'Train/mean recall': 0.8812627792358398, 'Train/mean hd95_metric': 31.16288948059082}
Epoch [83/300] Validation [1/16] Loss: 0.37653  focal_loss 0.19697  dice_loss 0.17956 
Epoch [83/300] Validation [2/16] Loss: 0.42677  focal_loss 0.13681  dice_loss 0.28997 
Epoch [83/300] Validation [3/16] Loss: 0.30620  focal_loss 0.07149  dice_loss 0.23471 
Epoch [83/300] Validation [4/16] Loss: 0.28305  focal_loss 0.08823  dice_loss 0.19482 
Epoch [83/300] Validation [5/16] Loss: 0.36253  focal_loss 0.06571  dice_loss 0.29682 
Epoch [83/300] Validation [6/16] Loss: 0.27430  focal_loss 0.07026  dice_loss 0.20404 
Epoch [83/300] Validation [7/16] Loss: 0.26100  focal_loss 0.07828  dice_loss 0.18271 
Epoch [83/300] Validation [8/16] Loss: 0.44384  focal_loss 0.13682  dice_loss 0.30702 
Epoch [83/300] Validation [9/16] Loss: 0.30530  focal_loss 0.07416  dice_loss 0.23114 
Epoch [83/300] Validation [10/16] Loss: 0.39164  focal_loss 0.08469  dice_loss 0.30695 
Epoch [83/300] Validation [11/16] Loss: 0.29379  focal_loss 0.07362  dice_loss 0.22017 
Epoch [83/300] Validation [12/16] Loss: 0.41348  focal_loss 0.08482  dice_loss 0.32866 
Epoch [83/300] Validation [13/16] Loss: 0.24337  focal_loss 0.05452  dice_loss 0.18886 
Epoch [83/300] Validation [14/16] Loss: 0.57048  focal_loss 0.18053  dice_loss 0.38995 
Epoch [83/300] Validation [15/16] Loss: 0.32791  focal_loss 0.11712  dice_loss 0.21079 
Epoch [83/300] Validation [16/16] Loss: 0.09495  focal_loss 0.02397  dice_loss 0.07098 
Epoch [83/300] Validation metric {'Val/mean dice_metric': 0.8402125835418701, 'Val/mean miou_metric': 0.7580923438072205, 'Val/mean f1': 0.8483714461326599, 'Val/mean precision': 0.8320604562759399, 'Val/mean recall': 0.865334689617157, 'Val/mean hd95_metric': 35.456329345703125}
Cheakpoint...
Epoch [83/300] best acc:tensor([0.8402], device='cuda:0'), Now : mean acc: tensor([0.8402], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8402125835418701, 'Val/mean miou_metric': 0.7580923438072205, 'Val/mean f1': 0.8483714461326599, 'Val/mean precision': 0.8320604562759399, 'Val/mean recall': 0.865334689617157, 'Val/mean hd95_metric': 35.456329345703125}
Epoch [84/300] Training [1/62] Loss: 0.24677 
Epoch [84/300] Training [2/62] Loss: 0.30915 
Epoch [84/300] Training [3/62] Loss: 0.18504 
Epoch [84/300] Training [4/62] Loss: 0.15177 
Epoch [84/300] Training [5/62] Loss: 0.33240 
Epoch [84/300] Training [6/62] Loss: 0.28532 
Epoch [84/300] Training [7/62] Loss: 0.09429 
Epoch [84/300] Training [8/62] Loss: 0.28179 
Epoch [84/300] Training [9/62] Loss: 0.20430 
Epoch [84/300] Training [10/62] Loss: 0.19318 
Epoch [84/300] Training [11/62] Loss: 0.16098 
Epoch [84/300] Training [12/62] Loss: 0.15009 
Epoch [84/300] Training [13/62] Loss: 0.29680 
Epoch [84/300] Training [14/62] Loss: 0.13599 
Epoch [84/300] Training [15/62] Loss: 0.14386 
Epoch [84/300] Training [16/62] Loss: 0.12059 
Epoch [84/300] Training [17/62] Loss: 0.34257 
Epoch [84/300] Training [18/62] Loss: 0.22856 
Epoch [84/300] Training [19/62] Loss: 0.23320 
Epoch [84/300] Training [20/62] Loss: 0.17968 
Epoch [84/300] Training [21/62] Loss: 0.23622 
Epoch [84/300] Training [22/62] Loss: 0.18515 
Epoch [84/300] Training [23/62] Loss: 0.37190 
Epoch [84/300] Training [24/62] Loss: 0.24300 
Epoch [84/300] Training [25/62] Loss: 0.19638 
Epoch [84/300] Training [26/62] Loss: 0.17625 
Epoch [84/300] Training [27/62] Loss: 0.25332 
Epoch [84/300] Training [28/62] Loss: 0.22392 
Epoch [84/300] Training [29/62] Loss: 0.14708 
Epoch [84/300] Training [30/62] Loss: 0.17809 
Epoch [84/300] Training [31/62] Loss: 0.20271 
Epoch [84/300] Training [32/62] Loss: 0.20589 
Epoch [84/300] Training [33/62] Loss: 0.20821 
Epoch [84/300] Training [34/62] Loss: 0.32303 
Epoch [84/300] Training [35/62] Loss: 0.31244 
Epoch [84/300] Training [36/62] Loss: 0.16074 
Epoch [84/300] Training [37/62] Loss: 0.16808 
Epoch [84/300] Training [38/62] Loss: 0.20187 
Epoch [84/300] Training [39/62] Loss: 0.77438 
Epoch [84/300] Training [40/62] Loss: 0.37660 
Epoch [84/300] Training [41/62] Loss: 0.26132 
Epoch [84/300] Training [42/62] Loss: 0.13871 
Epoch [84/300] Training [43/62] Loss: 0.36505 
Epoch [84/300] Training [44/62] Loss: 0.25061 
Epoch [84/300] Training [45/62] Loss: 0.19237 
Epoch [84/300] Training [46/62] Loss: 0.25299 
Epoch [84/300] Training [47/62] Loss: 0.12566 
Epoch [84/300] Training [48/62] Loss: 0.21344 
Epoch [84/300] Training [49/62] Loss: 0.21002 
Epoch [84/300] Training [50/62] Loss: 0.25073 
Epoch [84/300] Training [51/62] Loss: 0.23110 
Epoch [84/300] Training [52/62] Loss: 0.23175 
Epoch [84/300] Training [53/62] Loss: 0.15871 
Epoch [84/300] Training [54/62] Loss: 0.35132 
Epoch [84/300] Training [55/62] Loss: 0.23597 
Epoch [84/300] Training [56/62] Loss: 0.11506 
Epoch [84/300] Training [57/62] Loss: 0.17283 
Epoch [84/300] Training [58/62] Loss: 0.22071 
Epoch [84/300] Training [59/62] Loss: 0.14565 
Epoch [84/300] Training [60/62] Loss: 0.33524 
Epoch [84/300] Training [61/62] Loss: 0.24188 
Epoch [84/300] Training [62/62] Loss: 0.24554 
Epoch [84/300] Training metric {'Train/mean dice_metric': 0.8434669971466064, 'Train/mean miou_metric': 0.7598974108695984, 'Train/mean f1': 0.8596751093864441, 'Train/mean precision': 0.8541634678840637, 'Train/mean recall': 0.8652584552764893, 'Train/mean hd95_metric': 31.125545501708984}
Epoch [84/300] Validation [1/16] Loss: 0.14830  focal_loss 0.03924  dice_loss 0.10905 
Epoch [84/300] Validation [2/16] Loss: 0.33058  focal_loss 0.07658  dice_loss 0.25399 
Epoch [84/300] Validation [3/16] Loss: 0.26190  focal_loss 0.03616  dice_loss 0.22574 
Epoch [84/300] Validation [4/16] Loss: 0.31669  focal_loss 0.10242  dice_loss 0.21427 
Epoch [84/300] Validation [5/16] Loss: 0.29344  focal_loss 0.05076  dice_loss 0.24267 
Epoch [84/300] Validation [6/16] Loss: 0.18978  focal_loss 0.02364  dice_loss 0.16614 
Epoch [84/300] Validation [7/16] Loss: 0.26901  focal_loss 0.09506  dice_loss 0.17395 
Epoch [84/300] Validation [8/16] Loss: 0.38676  focal_loss 0.08737  dice_loss 0.29939 
Epoch [84/300] Validation [9/16] Loss: 0.31342  focal_loss 0.11215  dice_loss 0.20127 
Epoch [84/300] Validation [10/16] Loss: 0.31254  focal_loss 0.07546  dice_loss 0.23707 
Epoch [84/300] Validation [11/16] Loss: 0.15567  focal_loss 0.03434  dice_loss 0.12133 
Epoch [84/300] Validation [12/16] Loss: 0.31582  focal_loss 0.04681  dice_loss 0.26901 
Epoch [84/300] Validation [13/16] Loss: 0.36419  focal_loss 0.11895  dice_loss 0.24524 
Epoch [84/300] Validation [14/16] Loss: 0.45295  focal_loss 0.09115  dice_loss 0.36180 
Epoch [84/300] Validation [15/16] Loss: 0.16336  focal_loss 0.02872  dice_loss 0.13464 
Epoch [84/300] Validation [16/16] Loss: 0.09566  focal_loss 0.01479  dice_loss 0.08087 
Epoch [84/300] Validation metric {'Val/mean dice_metric': 0.8377330303192139, 'Val/mean miou_metric': 0.7522994875907898, 'Val/mean f1': 0.8520815968513489, 'Val/mean precision': 0.8455924987792969, 'Val/mean recall': 0.8586710095405579, 'Val/mean hd95_metric': 34.38966751098633}
Cheakpoint...
Epoch [84/300] best acc:tensor([0.8402], device='cuda:0'), Now : mean acc: tensor([0.8377], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8377330303192139, 'Val/mean miou_metric': 0.7522994875907898, 'Val/mean f1': 0.8520815968513489, 'Val/mean precision': 0.8455924987792969, 'Val/mean recall': 0.8586710095405579, 'Val/mean hd95_metric': 34.38966751098633}
Epoch [85/300] Training [1/62] Loss: 0.33659 
Epoch [85/300] Training [2/62] Loss: 0.17260 
Epoch [85/300] Training [3/62] Loss: 0.16854 
Epoch [85/300] Training [4/62] Loss: 0.13031 
Epoch [85/300] Training [5/62] Loss: 0.14287 
Epoch [85/300] Training [6/62] Loss: 0.10274 
Epoch [85/300] Training [7/62] Loss: 0.30152 
Epoch [85/300] Training [8/62] Loss: 0.16464 
Epoch [85/300] Training [9/62] Loss: 0.34415 
Epoch [85/300] Training [10/62] Loss: 0.32440 
Epoch [85/300] Training [11/62] Loss: 0.15278 
Epoch [85/300] Training [12/62] Loss: 0.24941 
Epoch [85/300] Training [13/62] Loss: 0.18144 
Epoch [85/300] Training [14/62] Loss: 0.10826 
Epoch [85/300] Training [15/62] Loss: 0.26215 
Epoch [85/300] Training [16/62] Loss: 0.25216 
Epoch [85/300] Training [17/62] Loss: 0.14846 
Epoch [85/300] Training [18/62] Loss: 0.11483 
Epoch [85/300] Training [19/62] Loss: 0.22605 
Epoch [85/300] Training [20/62] Loss: 0.19775 
Epoch [85/300] Training [21/62] Loss: 0.12522 
Epoch [85/300] Training [22/62] Loss: 0.15578 
Epoch [85/300] Training [23/62] Loss: 0.27909 
Epoch [85/300] Training [24/62] Loss: 0.23504 
Epoch [85/300] Training [25/62] Loss: 0.09918 
Epoch [85/300] Training [26/62] Loss: 0.21238 
Epoch [85/300] Training [27/62] Loss: 0.22584 
Epoch [85/300] Training [28/62] Loss: 0.17647 
Epoch [85/300] Training [29/62] Loss: 0.16632 
Epoch [85/300] Training [30/62] Loss: 0.15141 
Epoch [85/300] Training [31/62] Loss: 0.15919 
Epoch [85/300] Training [32/62] Loss: 0.20965 
Epoch [85/300] Training [33/62] Loss: 0.13126 
Epoch [85/300] Training [34/62] Loss: 0.22195 
Epoch [85/300] Training [35/62] Loss: 0.22856 
Epoch [85/300] Training [36/62] Loss: 0.12530 
Epoch [85/300] Training [37/62] Loss: 0.34639 
Epoch [85/300] Training [38/62] Loss: 0.17143 
Epoch [85/300] Training [39/62] Loss: 0.30555 
Epoch [85/300] Training [40/62] Loss: 0.21384 
Epoch [85/300] Training [41/62] Loss: 0.13333 
Epoch [85/300] Training [42/62] Loss: 0.31920 
Epoch [85/300] Training [43/62] Loss: 0.13800 
Epoch [85/300] Training [44/62] Loss: 0.18447 
Epoch [85/300] Training [45/62] Loss: 0.21572 
Epoch [85/300] Training [46/62] Loss: 0.11568 
Epoch [85/300] Training [47/62] Loss: 0.24719 
Epoch [85/300] Training [48/62] Loss: 0.27947 
Epoch [85/300] Training [49/62] Loss: 0.16294 
Epoch [85/300] Training [50/62] Loss: 0.10620 
Epoch [85/300] Training [51/62] Loss: 0.31874 
Epoch [85/300] Training [52/62] Loss: 0.13156 
Epoch [85/300] Training [53/62] Loss: 0.23284 
Epoch [85/300] Training [54/62] Loss: 0.17225 
Epoch [85/300] Training [55/62] Loss: 0.09291 
Epoch [85/300] Training [56/62] Loss: 0.17849 
Epoch [85/300] Training [57/62] Loss: 0.32366 
Epoch [85/300] Training [58/62] Loss: 0.16429 
Epoch [85/300] Training [59/62] Loss: 0.19871 
Epoch [85/300] Training [60/62] Loss: 0.34529 
Epoch [85/300] Training [61/62] Loss: 0.18145 
Epoch [85/300] Training [62/62] Loss: 0.05873 
Epoch [85/300] Training metric {'Train/mean dice_metric': 0.8631278276443481, 'Train/mean miou_metric': 0.7813438773155212, 'Train/mean f1': 0.8818933963775635, 'Train/mean precision': 0.8732894659042358, 'Train/mean recall': 0.890668511390686, 'Train/mean hd95_metric': 28.80812644958496}
Epoch [85/300] Validation [1/16] Loss: 0.21622  focal_loss 0.06358  dice_loss 0.15264 
Epoch [85/300] Validation [2/16] Loss: 0.44835  focal_loss 0.12863  dice_loss 0.31972 
Epoch [85/300] Validation [3/16] Loss: 0.80844  focal_loss 0.42561  dice_loss 0.38283 
Epoch [85/300] Validation [4/16] Loss: 0.41857  focal_loss 0.17255  dice_loss 0.24602 
Epoch [85/300] Validation [5/16] Loss: 0.41556  focal_loss 0.10604  dice_loss 0.30952 
Epoch [85/300] Validation [6/16] Loss: 0.23258  focal_loss 0.04600  dice_loss 0.18658 
Epoch [85/300] Validation [7/16] Loss: 0.20235  focal_loss 0.05466  dice_loss 0.14769 
Epoch [85/300] Validation [8/16] Loss: 0.31922  focal_loss 0.06676  dice_loss 0.25246 
Epoch [85/300] Validation [9/16] Loss: 0.34597  focal_loss 0.09868  dice_loss 0.24729 
Epoch [85/300] Validation [10/16] Loss: 0.35507  focal_loss 0.06996  dice_loss 0.28511 
Epoch [85/300] Validation [11/16] Loss: 0.23103  focal_loss 0.05825  dice_loss 0.17277 
Epoch [85/300] Validation [12/16] Loss: 0.30253  focal_loss 0.05341  dice_loss 0.24912 
Epoch [85/300] Validation [13/16] Loss: 0.27630  focal_loss 0.07496  dice_loss 0.20133 
Epoch [85/300] Validation [14/16] Loss: 0.43579  focal_loss 0.09157  dice_loss 0.34422 
Epoch [85/300] Validation [15/16] Loss: 0.12601  focal_loss 0.03155  dice_loss 0.09446 
Epoch [85/300] Validation [16/16] Loss: 0.11124  focal_loss 0.02562  dice_loss 0.08562 
Epoch [85/300] Validation metric {'Val/mean dice_metric': 0.8456740975379944, 'Val/mean miou_metric': 0.7623900175094604, 'Val/mean f1': 0.8670647144317627, 'Val/mean precision': 0.8636715412139893, 'Val/mean recall': 0.8704846501350403, 'Val/mean hd95_metric': 33.049217224121094}
Cheakpoint...
Epoch [85/300] best acc:tensor([0.8457], device='cuda:0'), Now : mean acc: tensor([0.8457], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8456740975379944, 'Val/mean miou_metric': 0.7623900175094604, 'Val/mean f1': 0.8670647144317627, 'Val/mean precision': 0.8636715412139893, 'Val/mean recall': 0.8704846501350403, 'Val/mean hd95_metric': 33.049217224121094}
Epoch [86/300] Training [1/62] Loss: 0.18943 
Epoch [86/300] Training [2/62] Loss: 0.27439 
Epoch [86/300] Training [3/62] Loss: 0.13679 
Epoch [86/300] Training [4/62] Loss: 0.31867 
Epoch [86/300] Training [5/62] Loss: 0.17843 
Epoch [86/300] Training [6/62] Loss: 0.18505 
Epoch [86/300] Training [7/62] Loss: 0.22390 
Epoch [86/300] Training [8/62] Loss: 0.12878 
Epoch [86/300] Training [9/62] Loss: 0.18265 
Epoch [86/300] Training [10/62] Loss: 0.31431 
Epoch [86/300] Training [11/62] Loss: 0.18293 
Epoch [86/300] Training [12/62] Loss: 0.17658 
Epoch [86/300] Training [13/62] Loss: 0.25801 
Epoch [86/300] Training [14/62] Loss: 0.28493 
Epoch [86/300] Training [15/62] Loss: 0.31971 
Epoch [86/300] Training [16/62] Loss: 0.16795 
Epoch [86/300] Training [17/62] Loss: 0.27248 
Epoch [86/300] Training [18/62] Loss: 0.26283 
Epoch [86/300] Training [19/62] Loss: 0.14682 
Epoch [86/300] Training [20/62] Loss: 0.17335 
Epoch [86/300] Training [21/62] Loss: 0.23487 
Epoch [86/300] Training [22/62] Loss: 0.18585 
Epoch [86/300] Training [23/62] Loss: 0.11425 
Epoch [86/300] Training [24/62] Loss: 0.31423 
Epoch [86/300] Training [25/62] Loss: 0.11003 
Epoch [86/300] Training [26/62] Loss: 0.25270 
Epoch [86/300] Training [27/62] Loss: 0.15613 
Epoch [86/300] Training [28/62] Loss: 0.18124 
Epoch [86/300] Training [29/62] Loss: 0.16699 
Epoch [86/300] Training [30/62] Loss: 0.21976 
Epoch [86/300] Training [31/62] Loss: 0.16125 
Epoch [86/300] Training [32/62] Loss: 0.17853 
Epoch [86/300] Training [33/62] Loss: 0.20663 
Epoch [86/300] Training [34/62] Loss: 0.22517 
Epoch [86/300] Training [35/62] Loss: 0.17555 
Epoch [86/300] Training [36/62] Loss: 0.30374 
Epoch [86/300] Training [37/62] Loss: 0.27408 
Epoch [86/300] Training [38/62] Loss: 0.29503 
Epoch [86/300] Training [39/62] Loss: 0.11177 
Epoch [86/300] Training [40/62] Loss: 0.15133 
Epoch [86/300] Training [41/62] Loss: 0.17814 
Epoch [86/300] Training [42/62] Loss: 0.11150 
Epoch [86/300] Training [43/62] Loss: 0.16607 
Epoch [86/300] Training [44/62] Loss: 0.31379 
Epoch [86/300] Training [45/62] Loss: 0.14657 
Epoch [86/300] Training [46/62] Loss: 0.42213 
Epoch [86/300] Training [47/62] Loss: 0.16230 
Epoch [86/300] Training [48/62] Loss: 0.11663 
Epoch [86/300] Training [49/62] Loss: 0.19626 
Epoch [86/300] Training [50/62] Loss: 0.11027 
Epoch [86/300] Training [51/62] Loss: 0.08326 
Epoch [86/300] Training [52/62] Loss: 0.19072 
Epoch [86/300] Training [53/62] Loss: 0.20825 
Epoch [86/300] Training [54/62] Loss: 0.22497 
Epoch [86/300] Training [55/62] Loss: 0.16267 
Epoch [86/300] Training [56/62] Loss: 0.15413 
Epoch [86/300] Training [57/62] Loss: 0.20802 
Epoch [86/300] Training [58/62] Loss: 0.12040 
Epoch [86/300] Training [59/62] Loss: 0.21906 
Epoch [86/300] Training [60/62] Loss: 0.17705 
Epoch [86/300] Training [61/62] Loss: 0.13469 
Epoch [86/300] Training [62/62] Loss: 0.08216 
Epoch [86/300] Training metric {'Train/mean dice_metric': 0.8635047078132629, 'Train/mean miou_metric': 0.7843628525733948, 'Train/mean f1': 0.8831848502159119, 'Train/mean precision': 0.8760208487510681, 'Train/mean recall': 0.8904668688774109, 'Train/mean hd95_metric': 26.641700744628906}
Epoch [86/300] Validation [1/16] Loss: 0.24817  focal_loss 0.10000  dice_loss 0.14816 
Epoch [86/300] Validation [2/16] Loss: 0.37401  focal_loss 0.10192  dice_loss 0.27209 
Epoch [86/300] Validation [3/16] Loss: 0.27963  focal_loss 0.04393  dice_loss 0.23570 
Epoch [86/300] Validation [4/16] Loss: 0.34155  focal_loss 0.11862  dice_loss 0.22292 
Epoch [86/300] Validation [5/16] Loss: 0.41556  focal_loss 0.07835  dice_loss 0.33721 
Epoch [86/300] Validation [6/16] Loss: 0.24698  focal_loss 0.03817  dice_loss 0.20881 
Epoch [86/300] Validation [7/16] Loss: 0.25171  focal_loss 0.08387  dice_loss 0.16784 
Epoch [86/300] Validation [8/16] Loss: 0.25732  focal_loss 0.05702  dice_loss 0.20030 
Epoch [86/300] Validation [9/16] Loss: 0.22835  focal_loss 0.05941  dice_loss 0.16894 
Epoch [86/300] Validation [10/16] Loss: 0.42761  focal_loss 0.11055  dice_loss 0.31706 
Epoch [86/300] Validation [11/16] Loss: 0.24306  focal_loss 0.05411  dice_loss 0.18894 
Epoch [86/300] Validation [12/16] Loss: 0.42329  focal_loss 0.10174  dice_loss 0.32155 
Epoch [86/300] Validation [13/16] Loss: 0.20099  focal_loss 0.03445  dice_loss 0.16654 
Epoch [86/300] Validation [14/16] Loss: 0.76326  focal_loss 0.24230  dice_loss 0.52096 
Epoch [86/300] Validation [15/16] Loss: 0.19024  focal_loss 0.04414  dice_loss 0.14610 
Epoch [86/300] Validation [16/16] Loss: 0.10658  focal_loss 0.02181  dice_loss 0.08476 
Epoch [86/300] Validation metric {'Val/mean dice_metric': 0.8474651575088501, 'Val/mean miou_metric': 0.7649642825126648, 'Val/mean f1': 0.8663380742073059, 'Val/mean precision': 0.8580844402313232, 'Val/mean recall': 0.8747521042823792, 'Val/mean hd95_metric': 31.785966873168945}
Cheakpoint...
Epoch [86/300] best acc:tensor([0.8475], device='cuda:0'), Now : mean acc: tensor([0.8475], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8474651575088501, 'Val/mean miou_metric': 0.7649642825126648, 'Val/mean f1': 0.8663380742073059, 'Val/mean precision': 0.8580844402313232, 'Val/mean recall': 0.8747521042823792, 'Val/mean hd95_metric': 31.785966873168945}
Epoch [87/300] Training [1/62] Loss: 0.38425 
Epoch [87/300] Training [2/62] Loss: 0.17031 
Epoch [87/300] Training [3/62] Loss: 0.09164 
Epoch [87/300] Training [4/62] Loss: 0.21216 
Epoch [87/300] Training [5/62] Loss: 0.21649 
Epoch [87/300] Training [6/62] Loss: 0.26644 
Epoch [87/300] Training [7/62] Loss: 0.19654 
Epoch [87/300] Training [8/62] Loss: 0.13612 
Epoch [87/300] Training [9/62] Loss: 0.14835 
Epoch [87/300] Training [10/62] Loss: 0.20665 
Epoch [87/300] Training [11/62] Loss: 0.26223 
Epoch [87/300] Training [12/62] Loss: 0.18449 
Epoch [87/300] Training [13/62] Loss: 0.15735 
Epoch [87/300] Training [14/62] Loss: 0.18260 
Epoch [87/300] Training [15/62] Loss: 0.14396 
Epoch [87/300] Training [16/62] Loss: 0.24939 
Epoch [87/300] Training [17/62] Loss: 0.31625 
Epoch [87/300] Training [18/62] Loss: 0.39389 
Epoch [87/300] Training [19/62] Loss: 0.18242 
Epoch [87/300] Training [20/62] Loss: 0.16471 
Epoch [87/300] Training [21/62] Loss: 0.18757 
Epoch [87/300] Training [22/62] Loss: 0.28710 
Epoch [87/300] Training [23/62] Loss: 0.17198 
Epoch [87/300] Training [24/62] Loss: 0.11048 
Epoch [87/300] Training [25/62] Loss: 0.12372 
Epoch [87/300] Training [26/62] Loss: 0.17446 
Epoch [87/300] Training [27/62] Loss: 0.23844 
Epoch [87/300] Training [28/62] Loss: 0.18326 
Epoch [87/300] Training [29/62] Loss: 0.12466 
Epoch [87/300] Training [30/62] Loss: 0.20838 
Epoch [87/300] Training [31/62] Loss: 0.26889 
Epoch [87/300] Training [32/62] Loss: 0.13101 
Epoch [87/300] Training [33/62] Loss: 0.13024 
Epoch [87/300] Training [34/62] Loss: 0.16643 
Epoch [87/300] Training [35/62] Loss: 0.17753 
Epoch [87/300] Training [36/62] Loss: 0.19966 
Epoch [87/300] Training [37/62] Loss: 0.20091 
Epoch [87/300] Training [38/62] Loss: 0.15482 
Epoch [87/300] Training [39/62] Loss: 0.34700 
Epoch [87/300] Training [40/62] Loss: 0.35993 
Epoch [87/300] Training [41/62] Loss: 0.27022 
Epoch [87/300] Training [42/62] Loss: 0.16227 
Epoch [87/300] Training [43/62] Loss: 0.28075 
Epoch [87/300] Training [44/62] Loss: 0.18446 
Epoch [87/300] Training [45/62] Loss: 0.27123 
Epoch [87/300] Training [46/62] Loss: 0.17993 
Epoch [87/300] Training [47/62] Loss: 0.24597 
Epoch [87/300] Training [48/62] Loss: 0.16083 
Epoch [87/300] Training [49/62] Loss: 0.24699 
Epoch [87/300] Training [50/62] Loss: 0.34382 
Epoch [87/300] Training [51/62] Loss: 0.27774 
Epoch [87/300] Training [52/62] Loss: 0.23331 
Epoch [87/300] Training [53/62] Loss: 0.22375 
Epoch [87/300] Training [54/62] Loss: 0.28004 
Epoch [87/300] Training [55/62] Loss: 0.25174 
Epoch [87/300] Training [56/62] Loss: 0.14360 
Epoch [87/300] Training [57/62] Loss: 0.35400 
Epoch [87/300] Training [58/62] Loss: 0.12980 
Epoch [87/300] Training [59/62] Loss: 0.15097 
Epoch [87/300] Training [60/62] Loss: 0.11645 
Epoch [87/300] Training [61/62] Loss: 0.21359 
Epoch [87/300] Training [62/62] Loss: 0.92605 
Epoch [87/300] Training metric {'Train/mean dice_metric': 0.8544050455093384, 'Train/mean miou_metric': 0.772596001625061, 'Train/mean f1': 0.8656619787216187, 'Train/mean precision': 0.856489360332489, 'Train/mean recall': 0.8750331997871399, 'Train/mean hd95_metric': 32.11518859863281}
Epoch [87/300] Validation [1/16] Loss: 0.16075  focal_loss 0.04812  dice_loss 0.11263 
Epoch [87/300] Validation [2/16] Loss: 0.37805  focal_loss 0.11401  dice_loss 0.26403 
Epoch [87/300] Validation [3/16] Loss: 0.61123  focal_loss 0.27709  dice_loss 0.33414 
Epoch [87/300] Validation [4/16] Loss: 0.28688  focal_loss 0.08125  dice_loss 0.20563 
Epoch [87/300] Validation [5/16] Loss: 0.32944  focal_loss 0.06697  dice_loss 0.26247 
Epoch [87/300] Validation [6/16] Loss: 0.31638  focal_loss 0.07320  dice_loss 0.24318 
Epoch [87/300] Validation [7/16] Loss: 0.24681  focal_loss 0.07430  dice_loss 0.17251 
Epoch [87/300] Validation [8/16] Loss: 0.49575  focal_loss 0.17578  dice_loss 0.31997 
Epoch [87/300] Validation [9/16] Loss: 0.30512  focal_loss 0.10006  dice_loss 0.20506 
Epoch [87/300] Validation [10/16] Loss: 0.45620  focal_loss 0.11566  dice_loss 0.34053 
Epoch [87/300] Validation [11/16] Loss: 0.18846  focal_loss 0.04568  dice_loss 0.14278 
Epoch [87/300] Validation [12/16] Loss: 0.41072  focal_loss 0.11945  dice_loss 0.29127 
Epoch [87/300] Validation [13/16] Loss: 0.28914  focal_loss 0.08580  dice_loss 0.20334 
Epoch [87/300] Validation [14/16] Loss: 0.59553  focal_loss 0.19418  dice_loss 0.40136 
Epoch [87/300] Validation [15/16] Loss: 0.21713  focal_loss 0.06967  dice_loss 0.14746 
Epoch [87/300] Validation [16/16] Loss: 0.27073  focal_loss 0.05691  dice_loss 0.21382 
Epoch [87/300] Validation metric {'Val/mean dice_metric': 0.839095950126648, 'Val/mean miou_metric': 0.7555406093597412, 'Val/mean f1': 0.8467245697975159, 'Val/mean precision': 0.834162712097168, 'Val/mean recall': 0.8596704006195068, 'Val/mean hd95_metric': 36.656246185302734}
Cheakpoint...
Epoch [87/300] best acc:tensor([0.8475], device='cuda:0'), Now : mean acc: tensor([0.8391], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.839095950126648, 'Val/mean miou_metric': 0.7555406093597412, 'Val/mean f1': 0.8467245697975159, 'Val/mean precision': 0.834162712097168, 'Val/mean recall': 0.8596704006195068, 'Val/mean hd95_metric': 36.656246185302734}
Epoch [88/300] Training [1/62] Loss: 0.15884 
Epoch [88/300] Training [2/62] Loss: 0.20789 
Epoch [88/300] Training [3/62] Loss: 0.30169 
Epoch [88/300] Training [4/62] Loss: 0.19027 
Epoch [88/300] Training [5/62] Loss: 0.39227 
Epoch [88/300] Training [6/62] Loss: 0.15968 
Epoch [88/300] Training [7/62] Loss: 0.29202 
Epoch [88/300] Training [8/62] Loss: 0.35487 
Epoch [88/300] Training [9/62] Loss: 0.32789 
Epoch [88/300] Training [10/62] Loss: 0.17111 
Epoch [88/300] Training [11/62] Loss: 0.13877 
Epoch [88/300] Training [12/62] Loss: 0.27393 
Epoch [88/300] Training [13/62] Loss: 0.13135 
Epoch [88/300] Training [14/62] Loss: 0.16247 
Epoch [88/300] Training [15/62] Loss: 0.14774 
Epoch [88/300] Training [16/62] Loss: 0.13340 
Epoch [88/300] Training [17/62] Loss: 0.29827 
Epoch [88/300] Training [18/62] Loss: 0.28153 
Epoch [88/300] Training [19/62] Loss: 0.17600 
Epoch [88/300] Training [20/62] Loss: 0.18997 
Epoch [88/300] Training [21/62] Loss: 0.25507 
Epoch [88/300] Training [22/62] Loss: 0.36823 
Epoch [88/300] Training [23/62] Loss: 0.24990 
Epoch [88/300] Training [24/62] Loss: 0.22910 
Epoch [88/300] Training [25/62] Loss: 0.20425 
Epoch [88/300] Training [26/62] Loss: 0.25313 
Epoch [88/300] Training [27/62] Loss: 0.13784 
Epoch [88/300] Training [28/62] Loss: 0.18939 
Epoch [88/300] Training [29/62] Loss: 0.29435 
Epoch [88/300] Training [30/62] Loss: 0.30230 
Epoch [88/300] Training [31/62] Loss: 0.16538 
Epoch [88/300] Training [32/62] Loss: 0.16644 
Epoch [88/300] Training [33/62] Loss: 0.22230 
Epoch [88/300] Training [34/62] Loss: 0.09953 
Epoch [88/300] Training [35/62] Loss: 0.26634 
Epoch [88/300] Training [36/62] Loss: 0.11915 
Epoch [88/300] Training [37/62] Loss: 0.11335 
Epoch [88/300] Training [38/62] Loss: 0.24742 
Epoch [88/300] Training [39/62] Loss: 0.16119 
Epoch [88/300] Training [40/62] Loss: 0.30437 
Epoch [88/300] Training [41/62] Loss: 0.09529 
Epoch [88/300] Training [42/62] Loss: 0.13626 
Epoch [88/300] Training [43/62] Loss: 0.13144 
Epoch [88/300] Training [44/62] Loss: 0.40881 
Epoch [88/300] Training [45/62] Loss: 0.13363 
Epoch [88/300] Training [46/62] Loss: 0.10702 
Epoch [88/300] Training [47/62] Loss: 0.13031 
Epoch [88/300] Training [48/62] Loss: 0.15766 
Epoch [88/300] Training [49/62] Loss: 0.23144 
Epoch [88/300] Training [50/62] Loss: 0.18958 
Epoch [88/300] Training [51/62] Loss: 0.31314 
Epoch [88/300] Training [52/62] Loss: 0.37042 
Epoch [88/300] Training [53/62] Loss: 0.15342 
Epoch [88/300] Training [54/62] Loss: 0.14375 
Epoch [88/300] Training [55/62] Loss: 0.17854 
Epoch [88/300] Training [56/62] Loss: 0.23210 
Epoch [88/300] Training [57/62] Loss: 0.23678 
Epoch [88/300] Training [58/62] Loss: 0.18553 
Epoch [88/300] Training [59/62] Loss: 0.20498 
Epoch [88/300] Training [60/62] Loss: 0.12587 
Epoch [88/300] Training [61/62] Loss: 0.22070 
Epoch [88/300] Training [62/62] Loss: 0.10512 
Epoch [88/300] Training metric {'Train/mean dice_metric': 0.8522394299507141, 'Train/mean miou_metric': 0.7736586928367615, 'Train/mean f1': 0.8678562641143799, 'Train/mean precision': 0.8495770692825317, 'Train/mean recall': 0.8869392275810242, 'Train/mean hd95_metric': 29.0662784576416}
Epoch [88/300] Validation [1/16] Loss: 0.20197  focal_loss 0.05884  dice_loss 0.14313 
Epoch [88/300] Validation [2/16] Loss: 0.51838  focal_loss 0.17606  dice_loss 0.34233 
Epoch [88/300] Validation [3/16] Loss: 0.28640  focal_loss 0.08098  dice_loss 0.20542 
Epoch [88/300] Validation [4/16] Loss: 0.31775  focal_loss 0.11821  dice_loss 0.19954 
Epoch [88/300] Validation [5/16] Loss: 0.30508  focal_loss 0.07928  dice_loss 0.22579 
Epoch [88/300] Validation [6/16] Loss: 0.30869  focal_loss 0.07866  dice_loss 0.23003 
Epoch [88/300] Validation [7/16] Loss: 0.23919  focal_loss 0.09294  dice_loss 0.14626 
Epoch [88/300] Validation [8/16] Loss: 0.50011  focal_loss 0.16730  dice_loss 0.33281 
Epoch [88/300] Validation [9/16] Loss: 0.32780  focal_loss 0.10125  dice_loss 0.22655 
Epoch [88/300] Validation [10/16] Loss: 0.21767  focal_loss 0.02964  dice_loss 0.18803 
Epoch [88/300] Validation [11/16] Loss: 0.17768  focal_loss 0.05601  dice_loss 0.12167 
Epoch [88/300] Validation [12/16] Loss: 0.43106  focal_loss 0.10913  dice_loss 0.32192 
Epoch [88/300] Validation [13/16] Loss: 0.41248  focal_loss 0.16380  dice_loss 0.24868 
Epoch [88/300] Validation [14/16] Loss: 0.69742  focal_loss 0.26955  dice_loss 0.42787 
Epoch [88/300] Validation [15/16] Loss: 0.12031  focal_loss 0.02439  dice_loss 0.09592 
Epoch [88/300] Validation [16/16] Loss: 0.17453  focal_loss 0.04588  dice_loss 0.12866 
Epoch [88/300] Validation metric {'Val/mean dice_metric': 0.8394834399223328, 'Val/mean miou_metric': 0.757920503616333, 'Val/mean f1': 0.8537631034851074, 'Val/mean precision': 0.8419439792633057, 'Val/mean recall': 0.865918755531311, 'Val/mean hd95_metric': 33.15303421020508}
Cheakpoint...
Epoch [88/300] best acc:tensor([0.8475], device='cuda:0'), Now : mean acc: tensor([0.8395], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8394834399223328, 'Val/mean miou_metric': 0.757920503616333, 'Val/mean f1': 0.8537631034851074, 'Val/mean precision': 0.8419439792633057, 'Val/mean recall': 0.865918755531311, 'Val/mean hd95_metric': 33.15303421020508}
Epoch [89/300] Training [1/62] Loss: 0.26073 
Epoch [89/300] Training [2/62] Loss: 0.09484 
Epoch [89/300] Training [3/62] Loss: 0.19426 
Epoch [89/300] Training [4/62] Loss: 0.23969 
Epoch [89/300] Training [5/62] Loss: 0.21362 
Epoch [89/300] Training [6/62] Loss: 0.19830 
Epoch [89/300] Training [7/62] Loss: 0.26820 
Epoch [89/300] Training [8/62] Loss: 0.32109 
Epoch [89/300] Training [9/62] Loss: 0.13024 
Epoch [89/300] Training [10/62] Loss: 0.25310 
Epoch [89/300] Training [11/62] Loss: 0.28340 
Epoch [89/300] Training [12/62] Loss: 0.23666 
Epoch [89/300] Training [13/62] Loss: 0.08508 
Epoch [89/300] Training [14/62] Loss: 0.20951 
Epoch [89/300] Training [15/62] Loss: 0.32265 
Epoch [89/300] Training [16/62] Loss: 0.13974 
Epoch [89/300] Training [17/62] Loss: 0.14228 
Epoch [89/300] Training [18/62] Loss: 0.19278 
Epoch [89/300] Training [19/62] Loss: 0.23105 
Epoch [89/300] Training [20/62] Loss: 0.09311 
Epoch [89/300] Training [21/62] Loss: 0.13151 
Epoch [89/300] Training [22/62] Loss: 0.12966 
Epoch [89/300] Training [23/62] Loss: 0.32373 
Epoch [89/300] Training [24/62] Loss: 0.24009 
Epoch [89/300] Training [25/62] Loss: 0.29637 
Epoch [89/300] Training [26/62] Loss: 0.20810 
Epoch [89/300] Training [27/62] Loss: 0.13699 
Epoch [89/300] Training [28/62] Loss: 0.27612 
Epoch [89/300] Training [29/62] Loss: 0.14105 
Epoch [89/300] Training [30/62] Loss: 0.30376 
Epoch [89/300] Training [31/62] Loss: 0.18307 
Epoch [89/300] Training [32/62] Loss: 0.17457 
Epoch [89/300] Training [33/62] Loss: 0.10213 
Epoch [89/300] Training [34/62] Loss: 0.17157 
Epoch [89/300] Training [35/62] Loss: 0.17583 
Epoch [89/300] Training [36/62] Loss: 0.23207 
Epoch [89/300] Training [37/62] Loss: 0.31879 
Epoch [89/300] Training [38/62] Loss: 0.14781 
Epoch [89/300] Training [39/62] Loss: 0.32064 
Epoch [89/300] Training [40/62] Loss: 0.23872 
Epoch [89/300] Training [41/62] Loss: 0.14176 
Epoch [89/300] Training [42/62] Loss: 0.28159 
Epoch [89/300] Training [43/62] Loss: 0.23817 
Epoch [89/300] Training [44/62] Loss: 0.23076 
Epoch [89/300] Training [45/62] Loss: 0.13900 
Epoch [89/300] Training [46/62] Loss: 0.23401 
Epoch [89/300] Training [47/62] Loss: 0.20615 
Epoch [89/300] Training [48/62] Loss: 0.37667 
Epoch [89/300] Training [49/62] Loss: 0.56642 
Epoch [89/300] Training [50/62] Loss: 0.16837 
Epoch [89/300] Training [51/62] Loss: 0.21767 
Epoch [89/300] Training [52/62] Loss: 0.32129 
Epoch [89/300] Training [53/62] Loss: 0.19939 
Epoch [89/300] Training [54/62] Loss: 0.15002 
Epoch [89/300] Training [55/62] Loss: 0.26442 
Epoch [89/300] Training [56/62] Loss: 0.21755 
Epoch [89/300] Training [57/62] Loss: 0.23634 
Epoch [89/300] Training [58/62] Loss: 0.20961 
Epoch [89/300] Training [59/62] Loss: 0.22383 
Epoch [89/300] Training [60/62] Loss: 0.40780 
Epoch [89/300] Training [61/62] Loss: 0.24937 
Epoch [89/300] Training [62/62] Loss: 1.13787 
Epoch [89/300] Training metric {'Train/mean dice_metric': 0.8465855121612549, 'Train/mean miou_metric': 0.7634133100509644, 'Train/mean f1': 0.8597941994667053, 'Train/mean precision': 0.8511826395988464, 'Train/mean recall': 0.8685817718505859, 'Train/mean hd95_metric': 32.260189056396484}
Epoch [89/300] Validation [1/16] Loss: 0.41168  focal_loss 0.15409  dice_loss 0.25759 
Epoch [89/300] Validation [2/16] Loss: 0.32764  focal_loss 0.08478  dice_loss 0.24287 
Epoch [89/300] Validation [3/16] Loss: 0.66658  focal_loss 0.31454  dice_loss 0.35204 
Epoch [89/300] Validation [4/16] Loss: 0.25987  focal_loss 0.06832  dice_loss 0.19155 
Epoch [89/300] Validation [5/16] Loss: 0.31288  focal_loss 0.08111  dice_loss 0.23177 
Epoch [89/300] Validation [6/16] Loss: 0.22721  focal_loss 0.04689  dice_loss 0.18032 
Epoch [89/300] Validation [7/16] Loss: 0.25576  focal_loss 0.08123  dice_loss 0.17454 
Epoch [89/300] Validation [8/16] Loss: 0.59890  focal_loss 0.19770  dice_loss 0.40120 
Epoch [89/300] Validation [9/16] Loss: 0.21081  focal_loss 0.05416  dice_loss 0.15665 
Epoch [89/300] Validation [10/16] Loss: 0.48993  focal_loss 0.11583  dice_loss 0.37411 
Epoch [89/300] Validation [11/16] Loss: 0.16828  focal_loss 0.03461  dice_loss 0.13368 
Epoch [89/300] Validation [12/16] Loss: 0.36076  focal_loss 0.07289  dice_loss 0.28787 
Epoch [89/300] Validation [13/16] Loss: 0.31006  focal_loss 0.10325  dice_loss 0.20682 
Epoch [89/300] Validation [14/16] Loss: 0.47227  focal_loss 0.06461  dice_loss 0.40766 
Epoch [89/300] Validation [15/16] Loss: 0.31558  focal_loss 0.10570  dice_loss 0.20988 
Epoch [89/300] Validation [16/16] Loss: 0.07620  focal_loss 0.01254  dice_loss 0.06366 
Epoch [89/300] Validation metric {'Val/mean dice_metric': 0.8319227695465088, 'Val/mean miou_metric': 0.7479404211044312, 'Val/mean f1': 0.8394531011581421, 'Val/mean precision': 0.8300093412399292, 'Val/mean recall': 0.8491142392158508, 'Val/mean hd95_metric': 35.92292785644531}
Cheakpoint...
Epoch [89/300] best acc:tensor([0.8475], device='cuda:0'), Now : mean acc: tensor([0.8319], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8319227695465088, 'Val/mean miou_metric': 0.7479404211044312, 'Val/mean f1': 0.8394531011581421, 'Val/mean precision': 0.8300093412399292, 'Val/mean recall': 0.8491142392158508, 'Val/mean hd95_metric': 35.92292785644531}
Epoch [90/300] Training [1/62] Loss: 0.16916 
Epoch [90/300] Training [2/62] Loss: 0.08745 
Epoch [90/300] Training [3/62] Loss: 0.29831 
Epoch [90/300] Training [4/62] Loss: 0.22242 
Epoch [90/300] Training [5/62] Loss: 0.26168 
Epoch [90/300] Training [6/62] Loss: 0.13085 
Epoch [90/300] Training [7/62] Loss: 0.22822 
Epoch [90/300] Training [8/62] Loss: 0.21838 
Epoch [90/300] Training [9/62] Loss: 0.14801 
Epoch [90/300] Training [10/62] Loss: 0.12570 
Epoch [90/300] Training [11/62] Loss: 0.15553 
Epoch [90/300] Training [12/62] Loss: 0.24477 
Epoch [90/300] Training [13/62] Loss: 0.11274 
Epoch [90/300] Training [14/62] Loss: 0.20989 
Epoch [90/300] Training [15/62] Loss: 0.29153 
Epoch [90/300] Training [16/62] Loss: 0.12078 
Epoch [90/300] Training [17/62] Loss: 0.09567 
Epoch [90/300] Training [18/62] Loss: 0.11975 
Epoch [90/300] Training [19/62] Loss: 0.24152 
Epoch [90/300] Training [20/62] Loss: 0.09776 
Epoch [90/300] Training [21/62] Loss: 0.17893 
Epoch [90/300] Training [22/62] Loss: 0.12098 
Epoch [90/300] Training [23/62] Loss: 0.13767 
Epoch [90/300] Training [24/62] Loss: 0.35859 
Epoch [90/300] Training [25/62] Loss: 0.14038 
Epoch [90/300] Training [26/62] Loss: 0.29468 
Epoch [90/300] Training [27/62] Loss: 0.11585 
Epoch [90/300] Training [28/62] Loss: 0.16788 
Epoch [90/300] Training [29/62] Loss: 0.26966 
Epoch [90/300] Training [30/62] Loss: 0.11327 
Epoch [90/300] Training [31/62] Loss: 0.20376 
Epoch [90/300] Training [32/62] Loss: 0.26332 
Epoch [90/300] Training [33/62] Loss: 0.13627 
Epoch [90/300] Training [34/62] Loss: 0.19819 
Epoch [90/300] Training [35/62] Loss: 0.27011 
Epoch [90/300] Training [36/62] Loss: 0.15592 
Epoch [90/300] Training [37/62] Loss: 0.24875 
Epoch [90/300] Training [38/62] Loss: 0.11688 
Epoch [90/300] Training [39/62] Loss: 0.16304 
Epoch [90/300] Training [40/62] Loss: 0.11060 
Epoch [90/300] Training [41/62] Loss: 0.17637 
Epoch [90/300] Training [42/62] Loss: 0.20472 
Epoch [90/300] Training [43/62] Loss: 0.24817 
Epoch [90/300] Training [44/62] Loss: 0.16608 
Epoch [90/300] Training [45/62] Loss: 0.17063 
Epoch [90/300] Training [46/62] Loss: 0.18818 
Epoch [90/300] Training [47/62] Loss: 0.12701 
Epoch [90/300] Training [48/62] Loss: 0.21740 
Epoch [90/300] Training [49/62] Loss: 0.25425 
Epoch [90/300] Training [50/62] Loss: 0.19985 
Epoch [90/300] Training [51/62] Loss: 0.22330 
Epoch [90/300] Training [52/62] Loss: 0.28304 
Epoch [90/300] Training [53/62] Loss: 0.26973 
Epoch [90/300] Training [54/62] Loss: 0.17215 
Epoch [90/300] Training [55/62] Loss: 0.12356 
Epoch [90/300] Training [56/62] Loss: 0.10646 
Epoch [90/300] Training [57/62] Loss: 0.27187 
Epoch [90/300] Training [58/62] Loss: 0.11755 
Epoch [90/300] Training [59/62] Loss: 0.28914 
Epoch [90/300] Training [60/62] Loss: 0.30330 
Epoch [90/300] Training [61/62] Loss: 0.17648 
Epoch [90/300] Training [62/62] Loss: 0.07849 
Epoch [90/300] Training metric {'Train/mean dice_metric': 0.8678238391876221, 'Train/mean miou_metric': 0.7905889749526978, 'Train/mean f1': 0.8871534466743469, 'Train/mean precision': 0.8798315525054932, 'Train/mean recall': 0.8945982456207275, 'Train/mean hd95_metric': 25.747690200805664}
Epoch [90/300] Validation [1/16] Loss: 0.20754  focal_loss 0.08364  dice_loss 0.12390 
Epoch [90/300] Validation [2/16] Loss: 0.47524  focal_loss 0.18682  dice_loss 0.28842 
Epoch [90/300] Validation [3/16] Loss: 0.26803  focal_loss 0.06513  dice_loss 0.20290 
Epoch [90/300] Validation [4/16] Loss: 0.50608  focal_loss 0.26389  dice_loss 0.24218 
Epoch [90/300] Validation [5/16] Loss: 0.31497  focal_loss 0.11544  dice_loss 0.19953 
Epoch [90/300] Validation [6/16] Loss: 0.28680  focal_loss 0.07651  dice_loss 0.21029 
Epoch [90/300] Validation [7/16] Loss: 0.22192  focal_loss 0.07058  dice_loss 0.15133 
Epoch [90/300] Validation [8/16] Loss: 0.41020  focal_loss 0.17364  dice_loss 0.23655 
Epoch [90/300] Validation [9/16] Loss: 0.25063  focal_loss 0.08356  dice_loss 0.16707 
Epoch [90/300] Validation [10/16] Loss: 0.35776  focal_loss 0.14493  dice_loss 0.21283 
Epoch [90/300] Validation [11/16] Loss: 0.14706  focal_loss 0.04981  dice_loss 0.09724 
Epoch [90/300] Validation [12/16] Loss: 0.33197  focal_loss 0.08383  dice_loss 0.24814 
Epoch [90/300] Validation [13/16] Loss: 0.28970  focal_loss 0.09461  dice_loss 0.19508 
Epoch [90/300] Validation [14/16] Loss: 0.63739  focal_loss 0.22048  dice_loss 0.41691 
Epoch [90/300] Validation [15/16] Loss: 0.13742  focal_loss 0.03457  dice_loss 0.10285 
Epoch [90/300] Validation [16/16] Loss: 0.22023  focal_loss 0.09935  dice_loss 0.12089 
Epoch [90/300] Validation metric {'Val/mean dice_metric': 0.855235755443573, 'Val/mean miou_metric': 0.7761228084564209, 'Val/mean f1': 0.8712936639785767, 'Val/mean precision': 0.874108612537384, 'Val/mean recall': 0.8684968948364258, 'Val/mean hd95_metric': 29.478910446166992}
Cheakpoint...
Epoch [90/300] best acc:tensor([0.8552], device='cuda:0'), Now : mean acc: tensor([0.8552], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.855235755443573, 'Val/mean miou_metric': 0.7761228084564209, 'Val/mean f1': 0.8712936639785767, 'Val/mean precision': 0.874108612537384, 'Val/mean recall': 0.8684968948364258, 'Val/mean hd95_metric': 29.478910446166992}
Epoch [91/300] Training [1/62] Loss: 0.27276 
Epoch [91/300] Training [2/62] Loss: 0.19713 
Epoch [91/300] Training [3/62] Loss: 0.21026 
Epoch [91/300] Training [4/62] Loss: 0.12122 
Epoch [91/300] Training [5/62] Loss: 0.16152 
Epoch [91/300] Training [6/62] Loss: 0.26281 
Epoch [91/300] Training [7/62] Loss: 0.16978 
Epoch [91/300] Training [8/62] Loss: 0.18849 
Epoch [91/300] Training [9/62] Loss: 0.20053 
Epoch [91/300] Training [10/62] Loss: 0.19620 
Epoch [91/300] Training [11/62] Loss: 0.15889 
Epoch [91/300] Training [12/62] Loss: 0.12589 
Epoch [91/300] Training [13/62] Loss: 0.28278 
Epoch [91/300] Training [14/62] Loss: 0.23054 
Epoch [91/300] Training [15/62] Loss: 0.13827 
Epoch [91/300] Training [16/62] Loss: 0.17195 
Epoch [91/300] Training [17/62] Loss: 0.12080 
Epoch [91/300] Training [18/62] Loss: 0.08986 
Epoch [91/300] Training [19/62] Loss: 0.17059 
Epoch [91/300] Training [20/62] Loss: 0.11081 
Epoch [91/300] Training [21/62] Loss: 0.13294 
Epoch [91/300] Training [22/62] Loss: 0.11455 
Epoch [91/300] Training [23/62] Loss: 0.09856 
Epoch [91/300] Training [24/62] Loss: 0.18706 
Epoch [91/300] Training [25/62] Loss: 0.24792 
Epoch [91/300] Training [26/62] Loss: 0.12856 
Epoch [91/300] Training [27/62] Loss: 0.53589 
Epoch [91/300] Training [28/62] Loss: 0.23840 
Epoch [91/300] Training [29/62] Loss: 0.23530 
Epoch [91/300] Training [30/62] Loss: 0.24046 
Epoch [91/300] Training [31/62] Loss: 0.09573 
Epoch [91/300] Training [32/62] Loss: 0.24967 
Epoch [91/300] Training [33/62] Loss: 0.33863 
Epoch [91/300] Training [34/62] Loss: 0.12128 
Epoch [91/300] Training [35/62] Loss: 0.14771 
Epoch [91/300] Training [36/62] Loss: 0.20106 
Epoch [91/300] Training [37/62] Loss: 0.22820 
Epoch [91/300] Training [38/62] Loss: 0.24384 
Epoch [91/300] Training [39/62] Loss: 0.11116 
Epoch [91/300] Training [40/62] Loss: 0.23128 
Epoch [91/300] Training [41/62] Loss: 0.11607 
Epoch [91/300] Training [42/62] Loss: 0.30362 
Epoch [91/300] Training [43/62] Loss: 0.22093 
Epoch [91/300] Training [44/62] Loss: 0.19943 
Epoch [91/300] Training [45/62] Loss: 0.20753 
Epoch [91/300] Training [46/62] Loss: 0.12436 
Epoch [91/300] Training [47/62] Loss: 0.24423 
Epoch [91/300] Training [48/62] Loss: 0.22480 
Epoch [91/300] Training [49/62] Loss: 0.22389 
Epoch [91/300] Training [50/62] Loss: 0.29173 
Epoch [91/300] Training [51/62] Loss: 0.20747 
Epoch [91/300] Training [52/62] Loss: 0.25140 
Epoch [91/300] Training [53/62] Loss: 0.20191 
Epoch [91/300] Training [54/62] Loss: 0.16714 
Epoch [91/300] Training [55/62] Loss: 0.12302 
Epoch [91/300] Training [56/62] Loss: 0.17762 
Epoch [91/300] Training [57/62] Loss: 0.25857 
Epoch [91/300] Training [58/62] Loss: 0.27700 
Epoch [91/300] Training [59/62] Loss: 0.25264 
Epoch [91/300] Training [60/62] Loss: 0.13055 
Epoch [91/300] Training [61/62] Loss: 0.26634 
Epoch [91/300] Training [62/62] Loss: 0.11205 
Epoch [91/300] Training metric {'Train/mean dice_metric': 0.8642981648445129, 'Train/mean miou_metric': 0.7864022850990295, 'Train/mean f1': 0.8809767961502075, 'Train/mean precision': 0.8669499754905701, 'Train/mean recall': 0.8954648971557617, 'Train/mean hd95_metric': 27.37375831604004}
Epoch [91/300] Validation [1/16] Loss: 0.37374  focal_loss 0.20347  dice_loss 0.17027 
Epoch [91/300] Validation [2/16] Loss: 0.36228  focal_loss 0.11547  dice_loss 0.24681 
Epoch [91/300] Validation [3/16] Loss: 0.54463  focal_loss 0.20994  dice_loss 0.33469 
Epoch [91/300] Validation [4/16] Loss: 0.21846  focal_loss 0.05315  dice_loss 0.16531 
Epoch [91/300] Validation [5/16] Loss: 0.35049  focal_loss 0.09474  dice_loss 0.25575 
Epoch [91/300] Validation [6/16] Loss: 0.26097  focal_loss 0.05452  dice_loss 0.20645 
Epoch [91/300] Validation [7/16] Loss: 0.20830  focal_loss 0.04564  dice_loss 0.16266 
Epoch [91/300] Validation [8/16] Loss: 0.25811  focal_loss 0.04251  dice_loss 0.21559 
Epoch [91/300] Validation [9/16] Loss: 0.20154  focal_loss 0.05137  dice_loss 0.15017 
Epoch [91/300] Validation [10/16] Loss: 0.44448  focal_loss 0.18041  dice_loss 0.26407 
Epoch [91/300] Validation [11/16] Loss: 0.14155  focal_loss 0.03094  dice_loss 0.11061 
Epoch [91/300] Validation [12/16] Loss: 0.37399  focal_loss 0.08184  dice_loss 0.29215 
Epoch [91/300] Validation [13/16] Loss: 0.28779  focal_loss 0.10060  dice_loss 0.18719 
Epoch [91/300] Validation [14/16] Loss: 0.58011  focal_loss 0.18026  dice_loss 0.39985 
Epoch [91/300] Validation [15/16] Loss: 0.15256  focal_loss 0.03419  dice_loss 0.11836 
Epoch [91/300] Validation [16/16] Loss: 0.07737  focal_loss 0.01429  dice_loss 0.06309 
Epoch [91/300] Validation metric {'Val/mean dice_metric': 0.8516804575920105, 'Val/mean miou_metric': 0.7721686363220215, 'Val/mean f1': 0.8643343448638916, 'Val/mean precision': 0.8574695587158203, 'Val/mean recall': 0.8713099360466003, 'Val/mean hd95_metric': 31.50554084777832}
Cheakpoint...
Epoch [91/300] best acc:tensor([0.8552], device='cuda:0'), Now : mean acc: tensor([0.8517], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8516804575920105, 'Val/mean miou_metric': 0.7721686363220215, 'Val/mean f1': 0.8643343448638916, 'Val/mean precision': 0.8574695587158203, 'Val/mean recall': 0.8713099360466003, 'Val/mean hd95_metric': 31.50554084777832}
Epoch [92/300] Training [1/62] Loss: 0.20220 
Epoch [92/300] Training [2/62] Loss: 0.27028 
Epoch [92/300] Training [3/62] Loss: 0.16949 
Epoch [92/300] Training [4/62] Loss: 0.16759 
Epoch [92/300] Training [5/62] Loss: 0.26716 
Epoch [92/300] Training [6/62] Loss: 0.12408 
Epoch [92/300] Training [7/62] Loss: 0.37611 
Epoch [92/300] Training [8/62] Loss: 0.24669 
Epoch [92/300] Training [9/62] Loss: 0.09981 
Epoch [92/300] Training [10/62] Loss: 0.09584 
Epoch [92/300] Training [11/62] Loss: 0.13187 
Epoch [92/300] Training [12/62] Loss: 0.30195 
Epoch [92/300] Training [13/62] Loss: 0.21550 
Epoch [92/300] Training [14/62] Loss: 0.17513 
Epoch [92/300] Training [15/62] Loss: 0.23824 
Epoch [92/300] Training [16/62] Loss: 0.25900 
Epoch [92/300] Training [17/62] Loss: 0.26621 
Epoch [92/300] Training [18/62] Loss: 0.19072 
Epoch [92/300] Training [19/62] Loss: 0.11430 
Epoch [92/300] Training [20/62] Loss: 0.11132 
Epoch [92/300] Training [21/62] Loss: 0.17820 
Epoch [92/300] Training [22/62] Loss: 0.15218 
Epoch [92/300] Training [23/62] Loss: 0.40007 
Epoch [92/300] Training [24/62] Loss: 0.26843 
Epoch [92/300] Training [25/62] Loss: 0.18334 
Epoch [92/300] Training [26/62] Loss: 0.10129 
Epoch [92/300] Training [27/62] Loss: 0.28468 
Epoch [92/300] Training [28/62] Loss: 0.16006 
Epoch [92/300] Training [29/62] Loss: 0.22937 
Epoch [92/300] Training [30/62] Loss: 0.13280 
Epoch [92/300] Training [31/62] Loss: 0.16876 
Epoch [92/300] Training [32/62] Loss: 0.23667 
Epoch [92/300] Training [33/62] Loss: 0.36989 
Epoch [92/300] Training [34/62] Loss: 0.18053 
Epoch [92/300] Training [35/62] Loss: 0.33225 
Epoch [92/300] Training [36/62] Loss: 0.11946 
Epoch [92/300] Training [37/62] Loss: 0.32775 
Epoch [92/300] Training [38/62] Loss: 0.19364 
Epoch [92/300] Training [39/62] Loss: 0.16739 
Epoch [92/300] Training [40/62] Loss: 0.16988 
Epoch [92/300] Training [41/62] Loss: 0.29509 
Epoch [92/300] Training [42/62] Loss: 0.29187 
Epoch [92/300] Training [43/62] Loss: 0.11803 
Epoch [92/300] Training [44/62] Loss: 0.20673 
Epoch [92/300] Training [45/62] Loss: 0.14641 
Epoch [92/300] Training [46/62] Loss: 0.18066 
Epoch [92/300] Training [47/62] Loss: 0.19632 
Epoch [92/300] Training [48/62] Loss: 0.22384 
Epoch [92/300] Training [49/62] Loss: 0.25095 
Epoch [92/300] Training [50/62] Loss: 0.17225 
Epoch [92/300] Training [51/62] Loss: 0.14759 
Epoch [92/300] Training [52/62] Loss: 0.32858 
Epoch [92/300] Training [53/62] Loss: 0.11308 
Epoch [92/300] Training [54/62] Loss: 0.16063 
Epoch [92/300] Training [55/62] Loss: 0.11126 
Epoch [92/300] Training [56/62] Loss: 0.19390 
Epoch [92/300] Training [57/62] Loss: 0.16559 
Epoch [92/300] Training [58/62] Loss: 0.14445 
Epoch [92/300] Training [59/62] Loss: 0.17225 
Epoch [92/300] Training [60/62] Loss: 0.22435 
Epoch [92/300] Training [61/62] Loss: 0.21257 
Epoch [92/300] Training [62/62] Loss: 3.35613 
Epoch [92/300] Training metric {'Train/mean dice_metric': 0.8572065234184265, 'Train/mean miou_metric': 0.7760465145111084, 'Train/mean f1': 0.8729320168495178, 'Train/mean precision': 0.8682262301445007, 'Train/mean recall': 0.8776891231536865, 'Train/mean hd95_metric': 29.82845687866211}
Epoch [92/300] Validation [1/16] Loss: 0.52980  focal_loss 0.31474  dice_loss 0.21506 
Epoch [92/300] Validation [2/16] Loss: 0.34376  focal_loss 0.08762  dice_loss 0.25614 
Epoch [92/300] Validation [3/16] Loss: 0.71049  focal_loss 0.35876  dice_loss 0.35173 
Epoch [92/300] Validation [4/16] Loss: 0.43476  focal_loss 0.19678  dice_loss 0.23799 
Epoch [92/300] Validation [5/16] Loss: 0.33936  focal_loss 0.06160  dice_loss 0.27775 
Epoch [92/300] Validation [6/16] Loss: 0.25859  focal_loss 0.04213  dice_loss 0.21646 
Epoch [92/300] Validation [7/16] Loss: 0.23897  focal_loss 0.07874  dice_loss 0.16023 
Epoch [92/300] Validation [8/16] Loss: 0.54779  focal_loss 0.18339  dice_loss 0.36439 
Epoch [92/300] Validation [9/16] Loss: 0.24141  focal_loss 0.07787  dice_loss 0.16355 
Epoch [92/300] Validation [10/16] Loss: 0.55029  focal_loss 0.15159  dice_loss 0.39870 
Epoch [92/300] Validation [11/16] Loss: 0.15743  focal_loss 0.04017  dice_loss 0.11726 
Epoch [92/300] Validation [12/16] Loss: 0.32070  focal_loss 0.06144  dice_loss 0.25926 
Epoch [92/300] Validation [13/16] Loss: 0.34365  focal_loss 0.09675  dice_loss 0.24690 
Epoch [92/300] Validation [14/16] Loss: 0.65464  focal_loss 0.19765  dice_loss 0.45699 
Epoch [92/300] Validation [15/16] Loss: 0.34126  focal_loss 0.11201  dice_loss 0.22925 
Epoch [92/300] Validation [16/16] Loss: 0.12449  focal_loss 0.03577  dice_loss 0.08872 
Epoch [92/300] Validation metric {'Val/mean dice_metric': 0.8358311057090759, 'Val/mean miou_metric': 0.7535081505775452, 'Val/mean f1': 0.8517107367515564, 'Val/mean precision': 0.8605315685272217, 'Val/mean recall': 0.8430688977241516, 'Val/mean hd95_metric': 34.98219299316406}
Cheakpoint...
Epoch [92/300] best acc:tensor([0.8552], device='cuda:0'), Now : mean acc: tensor([0.8358], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8358311057090759, 'Val/mean miou_metric': 0.7535081505775452, 'Val/mean f1': 0.8517107367515564, 'Val/mean precision': 0.8605315685272217, 'Val/mean recall': 0.8430688977241516, 'Val/mean hd95_metric': 34.98219299316406}
Epoch [93/300] Training [1/62] Loss: 0.26598 
Epoch [93/300] Training [2/62] Loss: 0.17402 
Epoch [93/300] Training [3/62] Loss: 0.14175 
Epoch [93/300] Training [4/62] Loss: 0.12461 
Epoch [93/300] Training [5/62] Loss: 0.26494 
Epoch [93/300] Training [6/62] Loss: 0.21563 
Epoch [93/300] Training [7/62] Loss: 0.22598 
Epoch [93/300] Training [8/62] Loss: 0.33905 
Epoch [93/300] Training [9/62] Loss: 0.25977 
Epoch [93/300] Training [10/62] Loss: 0.30301 
Epoch [93/300] Training [11/62] Loss: 0.25563 
Epoch [93/300] Training [12/62] Loss: 0.42003 
Epoch [93/300] Training [13/62] Loss: 0.17892 
Epoch [93/300] Training [14/62] Loss: 0.15958 
Epoch [93/300] Training [15/62] Loss: 0.41604 
Epoch [93/300] Training [16/62] Loss: 0.27121 
Epoch [93/300] Training [17/62] Loss: 0.17780 
Epoch [93/300] Training [18/62] Loss: 0.22684 
Epoch [93/300] Training [19/62] Loss: 0.21325 
Epoch [93/300] Training [20/62] Loss: 0.18322 
Epoch [93/300] Training [21/62] Loss: 0.19245 
Epoch [93/300] Training [22/62] Loss: 0.26830 
Epoch [93/300] Training [23/62] Loss: 0.19716 
Epoch [93/300] Training [24/62] Loss: 0.14918 
Epoch [93/300] Training [25/62] Loss: 0.34105 
Epoch [93/300] Training [26/62] Loss: 0.22094 
Epoch [93/300] Training [27/62] Loss: 0.22905 
Epoch [93/300] Training [28/62] Loss: 0.26470 
Epoch [93/300] Training [29/62] Loss: 0.29075 
Epoch [93/300] Training [30/62] Loss: 0.10048 
Epoch [93/300] Training [31/62] Loss: 0.19975 
Epoch [93/300] Training [32/62] Loss: 0.09954 
Epoch [93/300] Training [33/62] Loss: 0.26396 
Epoch [93/300] Training [34/62] Loss: 0.17926 
Epoch [93/300] Training [35/62] Loss: 0.22119 
Epoch [93/300] Training [36/62] Loss: 0.27146 
Epoch [93/300] Training [37/62] Loss: 0.38054 
Epoch [93/300] Training [38/62] Loss: 0.20593 
Epoch [93/300] Training [39/62] Loss: 0.26573 
Epoch [93/300] Training [40/62] Loss: 0.13388 
Epoch [93/300] Training [41/62] Loss: 0.32417 
Epoch [93/300] Training [42/62] Loss: 0.14721 
Epoch [93/300] Training [43/62] Loss: 0.09014 
Epoch [93/300] Training [44/62] Loss: 0.15949 
Epoch [93/300] Training [45/62] Loss: 0.21635 
Epoch [93/300] Training [46/62] Loss: 0.10370 
Epoch [93/300] Training [47/62] Loss: 0.13953 
Epoch [93/300] Training [48/62] Loss: 0.18004 
Epoch [93/300] Training [49/62] Loss: 0.38160 
Epoch [93/300] Training [50/62] Loss: 0.15741 
Epoch [93/300] Training [51/62] Loss: 0.07265 
Epoch [93/300] Training [52/62] Loss: 0.15809 
Epoch [93/300] Training [53/62] Loss: 0.12283 
Epoch [93/300] Training [54/62] Loss: 0.29185 
Epoch [93/300] Training [55/62] Loss: 0.44663 
Epoch [93/300] Training [56/62] Loss: 0.22225 
Epoch [93/300] Training [57/62] Loss: 0.13015 
Epoch [93/300] Training [58/62] Loss: 0.15730 
Epoch [93/300] Training [59/62] Loss: 0.22359 
Epoch [93/300] Training [60/62] Loss: 0.13950 
Epoch [93/300] Training [61/62] Loss: 0.12765 
Epoch [93/300] Training [62/62] Loss: 0.14722 
Epoch [93/300] Training metric {'Train/mean dice_metric': 0.8538087010383606, 'Train/mean miou_metric': 0.7740438580513, 'Train/mean f1': 0.8660667538642883, 'Train/mean precision': 0.8599372506141663, 'Train/mean recall': 0.8722841739654541, 'Train/mean hd95_metric': 31.415645599365234}
Epoch [93/300] Validation [1/16] Loss: 0.31380  focal_loss 0.10622  dice_loss 0.20758 
Epoch [93/300] Validation [2/16] Loss: 0.34763  focal_loss 0.10901  dice_loss 0.23862 
Epoch [93/300] Validation [3/16] Loss: 0.66009  focal_loss 0.32631  dice_loss 0.33377 
Epoch [93/300] Validation [4/16] Loss: 0.20459  focal_loss 0.03577  dice_loss 0.16882 
Epoch [93/300] Validation [5/16] Loss: 0.30838  focal_loss 0.05566  dice_loss 0.25271 
Epoch [93/300] Validation [6/16] Loss: 0.23037  focal_loss 0.04527  dice_loss 0.18511 
Epoch [93/300] Validation [7/16] Loss: 0.25990  focal_loss 0.08237  dice_loss 0.17753 
Epoch [93/300] Validation [8/16] Loss: 0.42189  focal_loss 0.12219  dice_loss 0.29970 
Epoch [93/300] Validation [9/16] Loss: 0.29548  focal_loss 0.09445  dice_loss 0.20103 
Epoch [93/300] Validation [10/16] Loss: 0.24357  focal_loss 0.03065  dice_loss 0.21292 
Epoch [93/300] Validation [11/16] Loss: 0.12765  focal_loss 0.02504  dice_loss 0.10262 
Epoch [93/300] Validation [12/16] Loss: 0.30257  focal_loss 0.05570  dice_loss 0.24687 
Epoch [93/300] Validation [13/16] Loss: 0.27499  focal_loss 0.10042  dice_loss 0.17457 
Epoch [93/300] Validation [14/16] Loss: 0.45030  focal_loss 0.10351  dice_loss 0.34679 
Epoch [93/300] Validation [15/16] Loss: 0.18954  focal_loss 0.03836  dice_loss 0.15119 
Epoch [93/300] Validation [16/16] Loss: 0.07809  focal_loss 0.01379  dice_loss 0.06430 
Epoch [93/300] Validation metric {'Val/mean dice_metric': 0.8443164825439453, 'Val/mean miou_metric': 0.7635096907615662, 'Val/mean f1': 0.8483352065086365, 'Val/mean precision': 0.8371210098266602, 'Val/mean recall': 0.859853982925415, 'Val/mean hd95_metric': 34.46906280517578}
Cheakpoint...
Epoch [93/300] best acc:tensor([0.8552], device='cuda:0'), Now : mean acc: tensor([0.8443], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8443164825439453, 'Val/mean miou_metric': 0.7635096907615662, 'Val/mean f1': 0.8483352065086365, 'Val/mean precision': 0.8371210098266602, 'Val/mean recall': 0.859853982925415, 'Val/mean hd95_metric': 34.46906280517578}
Epoch [94/300] Training [1/62] Loss: 0.22903 
Epoch [94/300] Training [2/62] Loss: 0.18077 
Epoch [94/300] Training [3/62] Loss: 0.10085 
Epoch [94/300] Training [4/62] Loss: 0.21171 
Epoch [94/300] Training [5/62] Loss: 0.13911 
Epoch [94/300] Training [6/62] Loss: 0.27085 
Epoch [94/300] Training [7/62] Loss: 0.15381 
Epoch [94/300] Training [8/62] Loss: 0.20730 
Epoch [94/300] Training [9/62] Loss: 0.09796 
Epoch [94/300] Training [10/62] Loss: 0.16298 
Epoch [94/300] Training [11/62] Loss: 0.17268 
Epoch [94/300] Training [12/62] Loss: 0.12181 
Epoch [94/300] Training [13/62] Loss: 0.17579 
Epoch [94/300] Training [14/62] Loss: 0.20330 
Epoch [94/300] Training [15/62] Loss: 0.19971 
Epoch [94/300] Training [16/62] Loss: 0.20800 
Epoch [94/300] Training [17/62] Loss: 0.09767 
Epoch [94/300] Training [18/62] Loss: 0.12455 
Epoch [94/300] Training [19/62] Loss: 0.12532 
Epoch [94/300] Training [20/62] Loss: 0.17664 
Epoch [94/300] Training [21/62] Loss: 0.24380 
Epoch [94/300] Training [22/62] Loss: 0.18425 
Epoch [94/300] Training [23/62] Loss: 0.12538 
Epoch [94/300] Training [24/62] Loss: 0.14006 
Epoch [94/300] Training [25/62] Loss: 0.09951 
Epoch [94/300] Training [26/62] Loss: 0.07075 
Epoch [94/300] Training [27/62] Loss: 0.20309 
Epoch [94/300] Training [28/62] Loss: 0.13166 
Epoch [94/300] Training [29/62] Loss: 0.22755 
Epoch [94/300] Training [30/62] Loss: 0.14753 
Epoch [94/300] Training [31/62] Loss: 0.23630 
Epoch [94/300] Training [32/62] Loss: 0.16323 
Epoch [94/300] Training [33/62] Loss: 0.11529 
Epoch [94/300] Training [34/62] Loss: 0.15369 
Epoch [94/300] Training [35/62] Loss: 0.22917 
Epoch [94/300] Training [36/62] Loss: 0.08695 
Epoch [94/300] Training [37/62] Loss: 0.19475 
Epoch [94/300] Training [38/62] Loss: 0.12186 
Epoch [94/300] Training [39/62] Loss: 0.15941 
Epoch [94/300] Training [40/62] Loss: 0.27247 
Epoch [94/300] Training [41/62] Loss: 0.16466 
Epoch [94/300] Training [42/62] Loss: 0.18899 
Epoch [94/300] Training [43/62] Loss: 0.11449 
Epoch [94/300] Training [44/62] Loss: 0.16362 
Epoch [94/300] Training [45/62] Loss: 0.22196 
Epoch [94/300] Training [46/62] Loss: 0.22257 
Epoch [94/300] Training [47/62] Loss: 0.11898 
Epoch [94/300] Training [48/62] Loss: 0.23450 
Epoch [94/300] Training [49/62] Loss: 0.14372 
Epoch [94/300] Training [50/62] Loss: 0.43540 
Epoch [94/300] Training [51/62] Loss: 0.15228 
Epoch [94/300] Training [52/62] Loss: 0.25276 
Epoch [94/300] Training [53/62] Loss: 0.11658 
Epoch [94/300] Training [54/62] Loss: 0.21137 
Epoch [94/300] Training [55/62] Loss: 0.13506 
Epoch [94/300] Training [56/62] Loss: 0.26435 
Epoch [94/300] Training [57/62] Loss: 0.11807 
Epoch [94/300] Training [58/62] Loss: 0.31754 
Epoch [94/300] Training [59/62] Loss: 0.26259 
Epoch [94/300] Training [60/62] Loss: 0.27309 
Epoch [94/300] Training [61/62] Loss: 0.18683 
Epoch [94/300] Training [62/62] Loss: 0.06346 
Epoch [94/300] Training metric {'Train/mean dice_metric': 0.8769289255142212, 'Train/mean miou_metric': 0.8001827001571655, 'Train/mean f1': 0.892449676990509, 'Train/mean precision': 0.8850574493408203, 'Train/mean recall': 0.8999664187431335, 'Train/mean hd95_metric': 24.55706024169922}
Epoch [94/300] Validation [1/16] Loss: 0.13101  focal_loss 0.04115  dice_loss 0.08986 
Epoch [94/300] Validation [2/16] Loss: 0.44562  focal_loss 0.16841  dice_loss 0.27720 
Epoch [94/300] Validation [3/16] Loss: 0.32462  focal_loss 0.06628  dice_loss 0.25833 
Epoch [94/300] Validation [4/16] Loss: 0.24153  focal_loss 0.08229  dice_loss 0.15924 
Epoch [94/300] Validation [5/16] Loss: 0.42726  focal_loss 0.12741  dice_loss 0.29985 
Epoch [94/300] Validation [6/16] Loss: 0.22264  focal_loss 0.04830  dice_loss 0.17434 
Epoch [94/300] Validation [7/16] Loss: 0.25147  focal_loss 0.09125  dice_loss 0.16021 
Epoch [94/300] Validation [8/16] Loss: 0.37222  focal_loss 0.10165  dice_loss 0.27057 
Epoch [94/300] Validation [9/16] Loss: 0.26202  focal_loss 0.08175  dice_loss 0.18027 
Epoch [94/300] Validation [10/16] Loss: 0.48529  focal_loss 0.17125  dice_loss 0.31404 
Epoch [94/300] Validation [11/16] Loss: 0.16929  focal_loss 0.03925  dice_loss 0.13004 
Epoch [94/300] Validation [12/16] Loss: 0.33770  focal_loss 0.07860  dice_loss 0.25910 
Epoch [94/300] Validation [13/16] Loss: 0.27838  focal_loss 0.09395  dice_loss 0.18443 
Epoch [94/300] Validation [14/16] Loss: 0.49749  focal_loss 0.13313  dice_loss 0.36437 
Epoch [94/300] Validation [15/16] Loss: 0.24293  focal_loss 0.09814  dice_loss 0.14479 
Epoch [94/300] Validation [16/16] Loss: 0.07398  focal_loss 0.01211  dice_loss 0.06187 
Epoch [94/300] Validation metric {'Val/mean dice_metric': 0.8623117804527283, 'Val/mean miou_metric': 0.7826985120773315, 'Val/mean f1': 0.877010703086853, 'Val/mean precision': 0.8661776185035706, 'Val/mean recall': 0.8881182670593262, 'Val/mean hd95_metric': 28.861801147460938}
Cheakpoint...
Epoch [94/300] best acc:tensor([0.8623], device='cuda:0'), Now : mean acc: tensor([0.8623], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8623117804527283, 'Val/mean miou_metric': 0.7826985120773315, 'Val/mean f1': 0.877010703086853, 'Val/mean precision': 0.8661776185035706, 'Val/mean recall': 0.8881182670593262, 'Val/mean hd95_metric': 28.861801147460938}
Epoch [95/300] Training [1/62] Loss: 0.17489 
Epoch [95/300] Training [2/62] Loss: 0.20056 
Epoch [95/300] Training [3/62] Loss: 0.24007 
Epoch [95/300] Training [4/62] Loss: 0.29620 
Epoch [95/300] Training [5/62] Loss: 0.12019 
Epoch [95/300] Training [6/62] Loss: 0.20178 
Epoch [95/300] Training [7/62] Loss: 0.15687 
Epoch [95/300] Training [8/62] Loss: 0.08443 
Epoch [95/300] Training [9/62] Loss: 0.10905 
Epoch [95/300] Training [10/62] Loss: 0.26953 
Epoch [95/300] Training [11/62] Loss: 0.12139 
Epoch [95/300] Training [12/62] Loss: 0.11722 
Epoch [95/300] Training [13/62] Loss: 0.22144 
Epoch [95/300] Training [14/62] Loss: 0.24011 
Epoch [95/300] Training [15/62] Loss: 0.32075 
Epoch [95/300] Training [16/62] Loss: 0.25831 
Epoch [95/300] Training [17/62] Loss: 0.13009 
Epoch [95/300] Training [18/62] Loss: 0.14466 
Epoch [95/300] Training [19/62] Loss: 0.18927 
Epoch [95/300] Training [20/62] Loss: 0.19039 
Epoch [95/300] Training [21/62] Loss: 0.16699 
Epoch [95/300] Training [22/62] Loss: 0.12724 
Epoch [95/300] Training [23/62] Loss: 0.27538 
Epoch [95/300] Training [24/62] Loss: 0.19577 
Epoch [95/300] Training [25/62] Loss: 0.16762 
Epoch [95/300] Training [26/62] Loss: 0.33772 
Epoch [95/300] Training [27/62] Loss: 0.20462 
Epoch [95/300] Training [28/62] Loss: 0.23501 
Epoch [95/300] Training [29/62] Loss: 0.21924 
Epoch [95/300] Training [30/62] Loss: 0.27638 
Epoch [95/300] Training [31/62] Loss: 0.15786 
Epoch [95/300] Training [32/62] Loss: 0.24782 
Epoch [95/300] Training [33/62] Loss: 0.14716 
Epoch [95/300] Training [34/62] Loss: 0.30575 
Epoch [95/300] Training [35/62] Loss: 0.15852 
Epoch [95/300] Training [36/62] Loss: 0.21408 
Epoch [95/300] Training [37/62] Loss: 0.09230 
Epoch [95/300] Training [38/62] Loss: 0.13850 
Epoch [95/300] Training [39/62] Loss: 0.23628 
Epoch [95/300] Training [40/62] Loss: 0.13105 
Epoch [95/300] Training [41/62] Loss: 0.14295 
Epoch [95/300] Training [42/62] Loss: 0.31369 
Epoch [95/300] Training [43/62] Loss: 0.17478 
Epoch [95/300] Training [44/62] Loss: 0.18855 
Epoch [95/300] Training [45/62] Loss: 0.09507 
Epoch [95/300] Training [46/62] Loss: 0.15418 
Epoch [95/300] Training [47/62] Loss: 0.16238 
Epoch [95/300] Training [48/62] Loss: 0.16722 
Epoch [95/300] Training [49/62] Loss: 0.26184 
Epoch [95/300] Training [50/62] Loss: 0.16257 
Epoch [95/300] Training [51/62] Loss: 0.11341 
Epoch [95/300] Training [52/62] Loss: 0.13564 
Epoch [95/300] Training [53/62] Loss: 0.20159 
Epoch [95/300] Training [54/62] Loss: 0.11459 
Epoch [95/300] Training [55/62] Loss: 0.22647 
Epoch [95/300] Training [56/62] Loss: 0.10287 
Epoch [95/300] Training [57/62] Loss: 0.17225 
Epoch [95/300] Training [58/62] Loss: 0.10467 
Epoch [95/300] Training [59/62] Loss: 0.19785 
Epoch [95/300] Training [60/62] Loss: 0.18639 
Epoch [95/300] Training [61/62] Loss: 0.09627 
Epoch [95/300] Training [62/62] Loss: 0.07251 
Epoch [95/300] Training metric {'Train/mean dice_metric': 0.8737682104110718, 'Train/mean miou_metric': 0.7979645133018494, 'Train/mean f1': 0.8913704752922058, 'Train/mean precision': 0.887395977973938, 'Train/mean recall': 0.8953807353973389, 'Train/mean hd95_metric': 25.244104385375977}
Epoch [95/300] Validation [1/16] Loss: 0.41336  focal_loss 0.20513  dice_loss 0.20823 
Epoch [95/300] Validation [2/16] Loss: 0.37977  focal_loss 0.13312  dice_loss 0.24665 
Epoch [95/300] Validation [3/16] Loss: 0.27973  focal_loss 0.05088  dice_loss 0.22885 
Epoch [95/300] Validation [4/16] Loss: 0.28095  focal_loss 0.11742  dice_loss 0.16353 
Epoch [95/300] Validation [5/16] Loss: 0.38936  focal_loss 0.11172  dice_loss 0.27765 
Epoch [95/300] Validation [6/16] Loss: 0.26645  focal_loss 0.05810  dice_loss 0.20835 
Epoch [95/300] Validation [7/16] Loss: 0.19564  focal_loss 0.06454  dice_loss 0.13110 
Epoch [95/300] Validation [8/16] Loss: 0.53015  focal_loss 0.17050  dice_loss 0.35966 
Epoch [95/300] Validation [9/16] Loss: 0.24894  focal_loss 0.06202  dice_loss 0.18692 
Epoch [95/300] Validation [10/16] Loss: 0.35086  focal_loss 0.07970  dice_loss 0.27116 
Epoch [95/300] Validation [11/16] Loss: 0.17210  focal_loss 0.04322  dice_loss 0.12888 
Epoch [95/300] Validation [12/16] Loss: 0.45488  focal_loss 0.10438  dice_loss 0.35050 
Epoch [95/300] Validation [13/16] Loss: 0.30575  focal_loss 0.11534  dice_loss 0.19041 
Epoch [95/300] Validation [14/16] Loss: 0.50781  focal_loss 0.10461  dice_loss 0.40320 
Epoch [95/300] Validation [15/16] Loss: 0.10537  focal_loss 0.02109  dice_loss 0.08428 
Epoch [95/300] Validation [16/16] Loss: 0.13794  focal_loss 0.04132  dice_loss 0.09662 
Epoch [95/300] Validation metric {'Val/mean dice_metric': 0.8575623035430908, 'Val/mean miou_metric': 0.7798320055007935, 'Val/mean f1': 0.8687971234321594, 'Val/mean precision': 0.8576023578643799, 'Val/mean recall': 0.8802879452705383, 'Val/mean hd95_metric': 30.589906692504883}
Cheakpoint...
Epoch [95/300] best acc:tensor([0.8623], device='cuda:0'), Now : mean acc: tensor([0.8576], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8575623035430908, 'Val/mean miou_metric': 0.7798320055007935, 'Val/mean f1': 0.8687971234321594, 'Val/mean precision': 0.8576023578643799, 'Val/mean recall': 0.8802879452705383, 'Val/mean hd95_metric': 30.589906692504883}
Epoch [96/300] Training [1/62] Loss: 0.08255 
Epoch [96/300] Training [2/62] Loss: 0.11242 
Epoch [96/300] Training [3/62] Loss: 0.26286 
Epoch [96/300] Training [4/62] Loss: 0.32775 
Epoch [96/300] Training [5/62] Loss: 0.22632 
Epoch [96/300] Training [6/62] Loss: 0.21060 
Epoch [96/300] Training [7/62] Loss: 0.16257 
Epoch [96/300] Training [8/62] Loss: 0.30992 
Epoch [96/300] Training [9/62] Loss: 0.15427 
Epoch [96/300] Training [10/62] Loss: 0.10268 
Epoch [96/300] Training [11/62] Loss: 0.19171 
Epoch [96/300] Training [12/62] Loss: 0.18450 
Epoch [96/300] Training [13/62] Loss: 0.21005 
Epoch [96/300] Training [14/62] Loss: 0.15229 
Epoch [96/300] Training [15/62] Loss: 0.20454 
Epoch [96/300] Training [16/62] Loss: 0.16784 
Epoch [96/300] Training [17/62] Loss: 0.19138 
Epoch [96/300] Training [18/62] Loss: 0.15717 
Epoch [96/300] Training [19/62] Loss: 0.29834 
Epoch [96/300] Training [20/62] Loss: 0.11895 
Epoch [96/300] Training [21/62] Loss: 0.14346 
Epoch [96/300] Training [22/62] Loss: 0.27577 
Epoch [96/300] Training [23/62] Loss: 0.22485 
Epoch [96/300] Training [24/62] Loss: 0.11750 
Epoch [96/300] Training [25/62] Loss: 0.19796 
Epoch [96/300] Training [26/62] Loss: 0.24766 
Epoch [96/300] Training [27/62] Loss: 0.17946 
Epoch [96/300] Training [28/62] Loss: 0.10061 
Epoch [96/300] Training [29/62] Loss: 0.21677 
Epoch [96/300] Training [30/62] Loss: 0.19322 
Epoch [96/300] Training [31/62] Loss: 0.23878 
Epoch [96/300] Training [32/62] Loss: 0.22008 
Epoch [96/300] Training [33/62] Loss: 0.30329 
Epoch [96/300] Training [34/62] Loss: 0.41264 
Epoch [96/300] Training [35/62] Loss: 0.24519 
Epoch [96/300] Training [36/62] Loss: 0.17411 
Epoch [96/300] Training [37/62] Loss: 0.23238 
Epoch [96/300] Training [38/62] Loss: 0.17821 
Epoch [96/300] Training [39/62] Loss: 0.14304 
Epoch [96/300] Training [40/62] Loss: 0.19494 
Epoch [96/300] Training [41/62] Loss: 0.16720 
Epoch [96/300] Training [42/62] Loss: 0.17052 
Epoch [96/300] Training [43/62] Loss: 0.16016 
Epoch [96/300] Training [44/62] Loss: 0.12622 
Epoch [96/300] Training [45/62] Loss: 0.19278 
Epoch [96/300] Training [46/62] Loss: 0.13108 
Epoch [96/300] Training [47/62] Loss: 0.15016 
Epoch [96/300] Training [48/62] Loss: 0.19517 
Epoch [96/300] Training [49/62] Loss: 0.20301 
Epoch [96/300] Training [50/62] Loss: 0.10821 
Epoch [96/300] Training [51/62] Loss: 0.26250 
Epoch [96/300] Training [52/62] Loss: 0.44453 
Epoch [96/300] Training [53/62] Loss: 0.09797 
Epoch [96/300] Training [54/62] Loss: 0.18854 
Epoch [96/300] Training [55/62] Loss: 0.31141 
Epoch [96/300] Training [56/62] Loss: 0.15761 
Epoch [96/300] Training [57/62] Loss: 0.26362 
Epoch [96/300] Training [58/62] Loss: 0.24858 
Epoch [96/300] Training [59/62] Loss: 0.09638 
Epoch [96/300] Training [60/62] Loss: 0.15410 
Epoch [96/300] Training [61/62] Loss: 0.47631 
Epoch [96/300] Training [62/62] Loss: 0.05412 
Epoch [96/300] Training metric {'Train/mean dice_metric': 0.8657110929489136, 'Train/mean miou_metric': 0.7892062664031982, 'Train/mean f1': 0.8721320629119873, 'Train/mean precision': 0.8674163222312927, 'Train/mean recall': 0.8768993616104126, 'Train/mean hd95_metric': 27.46075439453125}
Epoch [96/300] Validation [1/16] Loss: 0.18988  focal_loss 0.05921  dice_loss 0.13067 
Epoch [96/300] Validation [2/16] Loss: 0.39439  focal_loss 0.09601  dice_loss 0.29838 
Epoch [96/300] Validation [3/16] Loss: 0.37138  focal_loss 0.05632  dice_loss 0.31506 
Epoch [96/300] Validation [4/16] Loss: 0.18897  focal_loss 0.02830  dice_loss 0.16067 
Epoch [96/300] Validation [5/16] Loss: 0.31361  focal_loss 0.04882  dice_loss 0.26479 
Epoch [96/300] Validation [6/16] Loss: 0.21250  focal_loss 0.02328  dice_loss 0.18922 
Epoch [96/300] Validation [7/16] Loss: 0.27166  focal_loss 0.03713  dice_loss 0.23453 
Epoch [96/300] Validation [8/16] Loss: 0.39359  focal_loss 0.08841  dice_loss 0.30518 
Epoch [96/300] Validation [9/16] Loss: 0.28706  focal_loss 0.05295  dice_loss 0.23411 
Epoch [96/300] Validation [10/16] Loss: 0.37569  focal_loss 0.04674  dice_loss 0.32895 
Epoch [96/300] Validation [11/16] Loss: 0.19002  focal_loss 0.03179  dice_loss 0.15824 
Epoch [96/300] Validation [12/16] Loss: 0.44995  focal_loss 0.07313  dice_loss 0.37682 
Epoch [96/300] Validation [13/16] Loss: 0.31127  focal_loss 0.07969  dice_loss 0.23158 
Epoch [96/300] Validation [14/16] Loss: 0.45703  focal_loss 0.05865  dice_loss 0.39838 
Epoch [96/300] Validation [15/16] Loss: 0.20092  focal_loss 0.04454  dice_loss 0.15638 
Epoch [96/300] Validation [16/16] Loss: 0.12023  focal_loss 0.02595  dice_loss 0.09428 
Epoch [96/300] Validation metric {'Val/mean dice_metric': 0.8503372073173523, 'Val/mean miou_metric': 0.7713708281517029, 'Val/mean f1': 0.8555412888526917, 'Val/mean precision': 0.8481191396713257, 'Val/mean recall': 0.8630945086479187, 'Val/mean hd95_metric': 30.8200626373291}
Cheakpoint...
Epoch [96/300] best acc:tensor([0.8623], device='cuda:0'), Now : mean acc: tensor([0.8503], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8503372073173523, 'Val/mean miou_metric': 0.7713708281517029, 'Val/mean f1': 0.8555412888526917, 'Val/mean precision': 0.8481191396713257, 'Val/mean recall': 0.8630945086479187, 'Val/mean hd95_metric': 30.8200626373291}
Epoch [97/300] Training [1/62] Loss: 0.12683 
Epoch [97/300] Training [2/62] Loss: 0.24052 
Epoch [97/300] Training [3/62] Loss: 0.18628 
Epoch [97/300] Training [4/62] Loss: 0.22355 
Epoch [97/300] Training [5/62] Loss: 0.17381 
Epoch [97/300] Training [6/62] Loss: 0.24453 
Epoch [97/300] Training [7/62] Loss: 0.18234 
Epoch [97/300] Training [8/62] Loss: 0.10585 
Epoch [97/300] Training [9/62] Loss: 0.09857 
Epoch [97/300] Training [10/62] Loss: 0.15611 
Epoch [97/300] Training [11/62] Loss: 0.16715 
Epoch [97/300] Training [12/62] Loss: 0.09979 
Epoch [97/300] Training [13/62] Loss: 0.20425 
Epoch [97/300] Training [14/62] Loss: 0.26873 
Epoch [97/300] Training [15/62] Loss: 0.09592 
Epoch [97/300] Training [16/62] Loss: 0.12115 
Epoch [97/300] Training [17/62] Loss: 0.12156 
Epoch [97/300] Training [18/62] Loss: 0.09195 
Epoch [97/300] Training [19/62] Loss: 0.31960 
Epoch [97/300] Training [20/62] Loss: 0.15449 
Epoch [97/300] Training [21/62] Loss: 0.11349 
Epoch [97/300] Training [22/62] Loss: 0.09518 
Epoch [97/300] Training [23/62] Loss: 0.11696 
Epoch [97/300] Training [24/62] Loss: 0.34199 
Epoch [97/300] Training [25/62] Loss: 0.17228 
Epoch [97/300] Training [26/62] Loss: 0.17740 
Epoch [97/300] Training [27/62] Loss: 0.11190 
Epoch [97/300] Training [28/62] Loss: 0.15317 
Epoch [97/300] Training [29/62] Loss: 0.18387 
Epoch [97/300] Training [30/62] Loss: 0.20283 
Epoch [97/300] Training [31/62] Loss: 0.16718 
Epoch [97/300] Training [32/62] Loss: 0.16664 
Epoch [97/300] Training [33/62] Loss: 0.15825 
Epoch [97/300] Training [34/62] Loss: 0.16847 
Epoch [97/300] Training [35/62] Loss: 0.17086 
Epoch [97/300] Training [36/62] Loss: 0.14179 
Epoch [97/300] Training [37/62] Loss: 0.11183 
Epoch [97/300] Training [38/62] Loss: 0.09645 
Epoch [97/300] Training [39/62] Loss: 0.39541 
Epoch [97/300] Training [40/62] Loss: 0.24094 
Epoch [97/300] Training [41/62] Loss: 0.08578 
Epoch [97/300] Training [42/62] Loss: 0.25334 
Epoch [97/300] Training [43/62] Loss: 0.14574 
Epoch [97/300] Training [44/62] Loss: 0.27928 
Epoch [97/300] Training [45/62] Loss: 0.23767 
Epoch [97/300] Training [46/62] Loss: 0.21229 
Epoch [97/300] Training [47/62] Loss: 0.19941 
Epoch [97/300] Training [48/62] Loss: 0.13443 
Epoch [97/300] Training [49/62] Loss: 0.14564 
Epoch [97/300] Training [50/62] Loss: 0.26019 
Epoch [97/300] Training [51/62] Loss: 0.15097 
Epoch [97/300] Training [52/62] Loss: 0.14145 
Epoch [97/300] Training [53/62] Loss: 0.25116 
Epoch [97/300] Training [54/62] Loss: 0.28848 
Epoch [97/300] Training [55/62] Loss: 0.21441 
Epoch [97/300] Training [56/62] Loss: 0.11195 
Epoch [97/300] Training [57/62] Loss: 0.21989 
Epoch [97/300] Training [58/62] Loss: 0.15086 
Epoch [97/300] Training [59/62] Loss: 0.23664 
Epoch [97/300] Training [60/62] Loss: 0.15217 
Epoch [97/300] Training [61/62] Loss: 0.22816 
Epoch [97/300] Training [62/62] Loss: 0.04362 
Epoch [97/300] Training metric {'Train/mean dice_metric': 0.8774381279945374, 'Train/mean miou_metric': 0.8003174066543579, 'Train/mean f1': 0.8963993191719055, 'Train/mean precision': 0.887427806854248, 'Train/mean recall': 0.905553936958313, 'Train/mean hd95_metric': 24.07847023010254}
Epoch [97/300] Validation [1/16] Loss: 0.14222  focal_loss 0.04268  dice_loss 0.09954 
Epoch [97/300] Validation [2/16] Loss: 0.40442  focal_loss 0.10731  dice_loss 0.29711 
Epoch [97/300] Validation [3/16] Loss: 0.30058  focal_loss 0.08056  dice_loss 0.22002 
Epoch [97/300] Validation [4/16] Loss: 0.37444  focal_loss 0.12932  dice_loss 0.24512 
Epoch [97/300] Validation [5/16] Loss: 0.20231  focal_loss 0.02897  dice_loss 0.17334 
Epoch [97/300] Validation [6/16] Loss: 0.22445  focal_loss 0.05366  dice_loss 0.17079 
Epoch [97/300] Validation [7/16] Loss: 0.36343  focal_loss 0.11266  dice_loss 0.25077 
Epoch [97/300] Validation [8/16] Loss: 0.63160  focal_loss 0.17467  dice_loss 0.45693 
Epoch [97/300] Validation [9/16] Loss: 0.26659  focal_loss 0.07572  dice_loss 0.19087 
Epoch [97/300] Validation [10/16] Loss: 0.33063  focal_loss 0.06655  dice_loss 0.26408 
Epoch [97/300] Validation [11/16] Loss: 0.13473  focal_loss 0.02617  dice_loss 0.10856 
Epoch [97/300] Validation [12/16] Loss: 0.31405  focal_loss 0.05967  dice_loss 0.25438 
Epoch [97/300] Validation [13/16] Loss: 0.42686  focal_loss 0.15706  dice_loss 0.26980 
Epoch [97/300] Validation [14/16] Loss: 0.66075  focal_loss 0.21510  dice_loss 0.44565 
Epoch [97/300] Validation [15/16] Loss: 0.18765  focal_loss 0.03614  dice_loss 0.15151 
Epoch [97/300] Validation [16/16] Loss: 0.07364  focal_loss 0.01753  dice_loss 0.05611 
Epoch [97/300] Validation metric {'Val/mean dice_metric': 0.8580617308616638, 'Val/mean miou_metric': 0.7786373496055603, 'Val/mean f1': 0.876823902130127, 'Val/mean precision': 0.8668549656867981, 'Val/mean recall': 0.8870247602462769, 'Val/mean hd95_metric': 29.16078758239746}
Cheakpoint...
Epoch [97/300] best acc:tensor([0.8623], device='cuda:0'), Now : mean acc: tensor([0.8581], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8580617308616638, 'Val/mean miou_metric': 0.7786373496055603, 'Val/mean f1': 0.876823902130127, 'Val/mean precision': 0.8668549656867981, 'Val/mean recall': 0.8870247602462769, 'Val/mean hd95_metric': 29.16078758239746}
Epoch [98/300] Training [1/62] Loss: 0.41704 
Epoch [98/300] Training [2/62] Loss: 0.28970 
Epoch [98/300] Training [3/62] Loss: 0.10465 
Epoch [98/300] Training [4/62] Loss: 0.31994 
Epoch [98/300] Training [5/62] Loss: 0.09704 
Epoch [98/300] Training [6/62] Loss: 0.19697 
Epoch [98/300] Training [7/62] Loss: 0.20703 
Epoch [98/300] Training [8/62] Loss: 0.23921 
Epoch [98/300] Training [9/62] Loss: 0.28563 
Epoch [98/300] Training [10/62] Loss: 0.42216 
Epoch [98/300] Training [11/62] Loss: 0.11177 
Epoch [98/300] Training [12/62] Loss: 0.17812 
Epoch [98/300] Training [13/62] Loss: 0.22428 
Epoch [98/300] Training [14/62] Loss: 0.15719 
Epoch [98/300] Training [15/62] Loss: 0.22661 
Epoch [98/300] Training [16/62] Loss: 0.12388 
Epoch [98/300] Training [17/62] Loss: 0.14848 
Epoch [98/300] Training [18/62] Loss: 0.15626 
Epoch [98/300] Training [19/62] Loss: 0.27952 
Epoch [98/300] Training [20/62] Loss: 0.12646 
Epoch [98/300] Training [21/62] Loss: 0.19535 
Epoch [98/300] Training [22/62] Loss: 0.17981 
Epoch [98/300] Training [23/62] Loss: 0.19123 
Epoch [98/300] Training [24/62] Loss: 0.26033 
Epoch [98/300] Training [25/62] Loss: 0.25577 
Epoch [98/300] Training [26/62] Loss: 0.16475 
Epoch [98/300] Training [27/62] Loss: 0.10033 
Epoch [98/300] Training [28/62] Loss: 0.20279 
Epoch [98/300] Training [29/62] Loss: 0.20656 
Epoch [98/300] Training [30/62] Loss: 0.31736 
Epoch [98/300] Training [31/62] Loss: 0.27839 
Epoch [98/300] Training [32/62] Loss: 0.14224 
Epoch [98/300] Training [33/62] Loss: 0.31654 
Epoch [98/300] Training [34/62] Loss: 0.23146 
Epoch [98/300] Training [35/62] Loss: 0.20899 
Epoch [98/300] Training [36/62] Loss: 0.21961 
Epoch [98/300] Training [37/62] Loss: 0.31244 
Epoch [98/300] Training [38/62] Loss: 0.20579 
Epoch [98/300] Training [39/62] Loss: 0.17822 
Epoch [98/300] Training [40/62] Loss: 0.19834 
Epoch [98/300] Training [41/62] Loss: 0.13686 
Epoch [98/300] Training [42/62] Loss: 0.19401 
Epoch [98/300] Training [43/62] Loss: 0.22017 
Epoch [98/300] Training [44/62] Loss: 0.09154 
Epoch [98/300] Training [45/62] Loss: 0.17170 
Epoch [98/300] Training [46/62] Loss: 0.24799 
Epoch [98/300] Training [47/62] Loss: 0.29452 
Epoch [98/300] Training [48/62] Loss: 0.29817 
Epoch [98/300] Training [49/62] Loss: 0.28088 
Epoch [98/300] Training [50/62] Loss: 0.10001 
Epoch [98/300] Training [51/62] Loss: 0.21769 
Epoch [98/300] Training [52/62] Loss: 0.19214 
Epoch [98/300] Training [53/62] Loss: 0.29065 
Epoch [98/300] Training [54/62] Loss: 0.17386 
Epoch [98/300] Training [55/62] Loss: 0.24211 
Epoch [98/300] Training [56/62] Loss: 0.10124 
Epoch [98/300] Training [57/62] Loss: 0.11413 
Epoch [98/300] Training [58/62] Loss: 0.17560 
Epoch [98/300] Training [59/62] Loss: 0.11012 
Epoch [98/300] Training [60/62] Loss: 0.16179 
Epoch [98/300] Training [61/62] Loss: 0.14046 
Epoch [98/300] Training [62/62] Loss: 0.09250 
Epoch [98/300] Training metric {'Train/mean dice_metric': 0.8591734766960144, 'Train/mean miou_metric': 0.780332088470459, 'Train/mean f1': 0.8738973140716553, 'Train/mean precision': 0.8669644594192505, 'Train/mean recall': 0.8809418082237244, 'Train/mean hd95_metric': 27.97454833984375}
Epoch [98/300] Validation [1/16] Loss: 0.16328  focal_loss 0.05142  dice_loss 0.11186 
Epoch [98/300] Validation [2/16] Loss: 0.41028  focal_loss 0.12108  dice_loss 0.28920 
Epoch [98/300] Validation [3/16] Loss: 0.28991  focal_loss 0.05425  dice_loss 0.23566 
Epoch [98/300] Validation [4/16] Loss: 0.22744  focal_loss 0.06201  dice_loss 0.16543 
Epoch [98/300] Validation [5/16] Loss: 0.37782  focal_loss 0.08894  dice_loss 0.28888 
Epoch [98/300] Validation [6/16] Loss: 0.24408  focal_loss 0.05141  dice_loss 0.19266 
Epoch [98/300] Validation [7/16] Loss: 0.20445  focal_loss 0.06192  dice_loss 0.14253 
Epoch [98/300] Validation [8/16] Loss: 0.28054  focal_loss 0.05043  dice_loss 0.23011 
Epoch [98/300] Validation [9/16] Loss: 0.19498  focal_loss 0.04174  dice_loss 0.15324 
Epoch [98/300] Validation [10/16] Loss: 0.45562  focal_loss 0.14856  dice_loss 0.30705 
Epoch [98/300] Validation [11/16] Loss: 0.23434  focal_loss 0.04748  dice_loss 0.18686 
Epoch [98/300] Validation [12/16] Loss: 0.36755  focal_loss 0.07224  dice_loss 0.29530 
Epoch [98/300] Validation [13/16] Loss: 0.32031  focal_loss 0.10281  dice_loss 0.21750 
Epoch [98/300] Validation [14/16] Loss: 0.54498  focal_loss 0.12504  dice_loss 0.41995 
Epoch [98/300] Validation [15/16] Loss: 0.15047  focal_loss 0.02244  dice_loss 0.12803 
Epoch [98/300] Validation [16/16] Loss: 0.06225  focal_loss 0.01096  dice_loss 0.05129 
Epoch [98/300] Validation metric {'Val/mean dice_metric': 0.8463709354400635, 'Val/mean miou_metric': 0.7668988108634949, 'Val/mean f1': 0.8650293350219727, 'Val/mean precision': 0.860449492931366, 'Val/mean recall': 0.8696582317352295, 'Val/mean hd95_metric': 30.82443618774414}
Cheakpoint...
Epoch [98/300] best acc:tensor([0.8623], device='cuda:0'), Now : mean acc: tensor([0.8464], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8463709354400635, 'Val/mean miou_metric': 0.7668988108634949, 'Val/mean f1': 0.8650293350219727, 'Val/mean precision': 0.860449492931366, 'Val/mean recall': 0.8696582317352295, 'Val/mean hd95_metric': 30.82443618774414}
Epoch [99/300] Training [1/62] Loss: 0.13657 
Epoch [99/300] Training [2/62] Loss: 0.10994 
Epoch [99/300] Training [3/62] Loss: 0.12692 
Epoch [99/300] Training [4/62] Loss: 0.17425 
Epoch [99/300] Training [5/62] Loss: 0.15157 
Epoch [99/300] Training [6/62] Loss: 0.13711 
Epoch [99/300] Training [7/62] Loss: 0.15107 
Epoch [99/300] Training [8/62] Loss: 0.30399 
Epoch [99/300] Training [9/62] Loss: 0.15607 
Epoch [99/300] Training [10/62] Loss: 0.17049 
Epoch [99/300] Training [11/62] Loss: 0.11617 
Epoch [99/300] Training [12/62] Loss: 0.11196 
Epoch [99/300] Training [13/62] Loss: 0.15412 
Epoch [99/300] Training [14/62] Loss: 0.12075 
Epoch [99/300] Training [15/62] Loss: 0.12327 
Epoch [99/300] Training [16/62] Loss: 0.12884 
Epoch [99/300] Training [17/62] Loss: 0.15420 
Epoch [99/300] Training [18/62] Loss: 0.19174 
Epoch [99/300] Training [19/62] Loss: 0.28984 
Epoch [99/300] Training [20/62] Loss: 0.25252 
Epoch [99/300] Training [21/62] Loss: 0.24008 
Epoch [99/300] Training [22/62] Loss: 0.16361 
Epoch [99/300] Training [23/62] Loss: 0.13877 
Epoch [99/300] Training [24/62] Loss: 0.10790 
Epoch [99/300] Training [25/62] Loss: 0.16682 
Epoch [99/300] Training [26/62] Loss: 0.23193 
Epoch [99/300] Training [27/62] Loss: 0.17366 
Epoch [99/300] Training [28/62] Loss: 0.14815 
Epoch [99/300] Training [29/62] Loss: 0.13487 
Epoch [99/300] Training [30/62] Loss: 0.18724 
Epoch [99/300] Training [31/62] Loss: 0.11962 
Epoch [99/300] Training [32/62] Loss: 0.10561 
Epoch [99/300] Training [33/62] Loss: 0.21903 
Epoch [99/300] Training [34/62] Loss: 0.13401 
Epoch [99/300] Training [35/62] Loss: 0.16720 
Epoch [99/300] Training [36/62] Loss: 0.14879 
Epoch [99/300] Training [37/62] Loss: 0.18818 
Epoch [99/300] Training [38/62] Loss: 0.21527 
Epoch [99/300] Training [39/62] Loss: 0.24963 
Epoch [99/300] Training [40/62] Loss: 0.35379 
Epoch [99/300] Training [41/62] Loss: 0.21866 
Epoch [99/300] Training [42/62] Loss: 0.14183 
Epoch [99/300] Training [43/62] Loss: 0.32049 
Epoch [99/300] Training [44/62] Loss: 0.15524 
Epoch [99/300] Training [45/62] Loss: 0.27324 
Epoch [99/300] Training [46/62] Loss: 0.14025 
Epoch [99/300] Training [47/62] Loss: 0.14868 
Epoch [99/300] Training [48/62] Loss: 0.19901 
Epoch [99/300] Training [49/62] Loss: 0.22037 
Epoch [99/300] Training [50/62] Loss: 0.09118 
Epoch [99/300] Training [51/62] Loss: 0.21910 
Epoch [99/300] Training [52/62] Loss: 0.19807 
Epoch [99/300] Training [53/62] Loss: 0.15917 
Epoch [99/300] Training [54/62] Loss: 0.15367 
Epoch [99/300] Training [55/62] Loss: 0.24824 
Epoch [99/300] Training [56/62] Loss: 0.18173 
Epoch [99/300] Training [57/62] Loss: 0.28820 
Epoch [99/300] Training [58/62] Loss: 0.18694 
Epoch [99/300] Training [59/62] Loss: 0.20694 
Epoch [99/300] Training [60/62] Loss: 0.14213 
Epoch [99/300] Training [61/62] Loss: 0.18396 
Epoch [99/300] Training [62/62] Loss: 0.28144 
Epoch [99/300] Training metric {'Train/mean dice_metric': 0.8773618936538696, 'Train/mean miou_metric': 0.8018708825111389, 'Train/mean f1': 0.8903318643569946, 'Train/mean precision': 0.8819295763969421, 'Train/mean recall': 0.8988958597183228, 'Train/mean hd95_metric': 25.77043342590332}
Epoch [99/300] Validation [1/16] Loss: 0.43794  focal_loss 0.22635  dice_loss 0.21159 
Epoch [99/300] Validation [2/16] Loss: 0.42951  focal_loss 0.11063  dice_loss 0.31888 
Epoch [99/300] Validation [3/16] Loss: 0.53764  focal_loss 0.21089  dice_loss 0.32675 
Epoch [99/300] Validation [4/16] Loss: 0.29668  focal_loss 0.12129  dice_loss 0.17539 
Epoch [99/300] Validation [5/16] Loss: 0.38066  focal_loss 0.06820  dice_loss 0.31246 
Epoch [99/300] Validation [6/16] Loss: 0.31239  focal_loss 0.07895  dice_loss 0.23344 
Epoch [99/300] Validation [7/16] Loss: 0.21754  focal_loss 0.08158  dice_loss 0.13596 
Epoch [99/300] Validation [8/16] Loss: 0.32159  focal_loss 0.05459  dice_loss 0.26700 
Epoch [99/300] Validation [9/16] Loss: 0.27362  focal_loss 0.07079  dice_loss 0.20282 
Epoch [99/300] Validation [10/16] Loss: 0.43450  focal_loss 0.12339  dice_loss 0.31110 
Epoch [99/300] Validation [11/16] Loss: 0.19648  focal_loss 0.04657  dice_loss 0.14992 
Epoch [99/300] Validation [12/16] Loss: 0.37632  focal_loss 0.05818  dice_loss 0.31813 
Epoch [99/300] Validation [13/16] Loss: 0.43387  focal_loss 0.18750  dice_loss 0.24637 
Epoch [99/300] Validation [14/16] Loss: 0.57803  focal_loss 0.17894  dice_loss 0.39909 
Epoch [99/300] Validation [15/16] Loss: 0.12636  focal_loss 0.02867  dice_loss 0.09769 
Epoch [99/300] Validation [16/16] Loss: 0.08723  focal_loss 0.02646  dice_loss 0.06077 
Epoch [99/300] Validation metric {'Val/mean dice_metric': 0.8568741679191589, 'Val/mean miou_metric': 0.7785606384277344, 'Val/mean f1': 0.8640803098678589, 'Val/mean precision': 0.8491764068603516, 'Val/mean recall': 0.8795167803764343, 'Val/mean hd95_metric': 31.282766342163086}
Cheakpoint...
Epoch [99/300] best acc:tensor([0.8623], device='cuda:0'), Now : mean acc: tensor([0.8569], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8568741679191589, 'Val/mean miou_metric': 0.7785606384277344, 'Val/mean f1': 0.8640803098678589, 'Val/mean precision': 0.8491764068603516, 'Val/mean recall': 0.8795167803764343, 'Val/mean hd95_metric': 31.282766342163086}
Epoch [100/300] Training [1/62] Loss: 0.20140 
Epoch [100/300] Training [2/62] Loss: 0.12273 
Epoch [100/300] Training [3/62] Loss: 0.31769 
Epoch [100/300] Training [4/62] Loss: 0.15181 
Epoch [100/300] Training [5/62] Loss: 0.14713 
Epoch [100/300] Training [6/62] Loss: 0.24498 
Epoch [100/300] Training [7/62] Loss: 0.25902 
Epoch [100/300] Training [8/62] Loss: 0.12465 
Epoch [100/300] Training [9/62] Loss: 0.14592 
Epoch [100/300] Training [10/62] Loss: 0.13506 
Epoch [100/300] Training [11/62] Loss: 0.20488 
Epoch [100/300] Training [12/62] Loss: 0.16340 
Epoch [100/300] Training [13/62] Loss: 0.11958 
Epoch [100/300] Training [14/62] Loss: 0.13207 
Epoch [100/300] Training [15/62] Loss: 0.16720 
Epoch [100/300] Training [16/62] Loss: 0.28506 
Epoch [100/300] Training [17/62] Loss: 0.19509 
Epoch [100/300] Training [18/62] Loss: 0.11113 
Epoch [100/300] Training [19/62] Loss: 0.11808 
Epoch [100/300] Training [20/62] Loss: 0.12751 
Epoch [100/300] Training [21/62] Loss: 0.15487 
Epoch [100/300] Training [22/62] Loss: 0.12809 
Epoch [100/300] Training [23/62] Loss: 0.14872 
Epoch [100/300] Training [24/62] Loss: 0.12385 
Epoch [100/300] Training [25/62] Loss: 0.23277 
Epoch [100/300] Training [26/62] Loss: 0.13697 
Epoch [100/300] Training [27/62] Loss: 0.20747 
Epoch [100/300] Training [28/62] Loss: 0.16830 
Epoch [100/300] Training [29/62] Loss: 0.28185 
Epoch [100/300] Training [30/62] Loss: 0.13404 
Epoch [100/300] Training [31/62] Loss: 0.08802 
Epoch [100/300] Training [32/62] Loss: 0.17500 
Epoch [100/300] Training [33/62] Loss: 0.16470 
Epoch [100/300] Training [34/62] Loss: 0.24716 
Epoch [100/300] Training [35/62] Loss: 0.14333 
Epoch [100/300] Training [36/62] Loss: 0.12917 
Epoch [100/300] Training [37/62] Loss: 0.11275 
Epoch [100/300] Training [38/62] Loss: 0.18418 
Epoch [100/300] Training [39/62] Loss: 0.15067 
Epoch [100/300] Training [40/62] Loss: 0.08203 
Epoch [100/300] Training [41/62] Loss: 0.20847 
Epoch [100/300] Training [42/62] Loss: 0.19895 
Epoch [100/300] Training [43/62] Loss: 0.16917 
Epoch [100/300] Training [44/62] Loss: 0.19531 
Epoch [100/300] Training [45/62] Loss: 0.21359 
Epoch [100/300] Training [46/62] Loss: 0.12311 
Epoch [100/300] Training [47/62] Loss: 0.27727 
Epoch [100/300] Training [48/62] Loss: 0.10134 
Epoch [100/300] Training [49/62] Loss: 0.13910 
Epoch [100/300] Training [50/62] Loss: 0.20795 
Epoch [100/300] Training [51/62] Loss: 0.18546 
Epoch [100/300] Training [52/62] Loss: 0.20695 
Epoch [100/300] Training [53/62] Loss: 0.16361 
Epoch [100/300] Training [54/62] Loss: 0.13224 
Epoch [100/300] Training [55/62] Loss: 0.45574 
Epoch [100/300] Training [56/62] Loss: 0.14098 
Epoch [100/300] Training [57/62] Loss: 0.15255 
Epoch [100/300] Training [58/62] Loss: 0.17242 
Epoch [100/300] Training [59/62] Loss: 0.27846 
Epoch [100/300] Training [60/62] Loss: 0.12578 
Epoch [100/300] Training [61/62] Loss: 0.16893 
Epoch [100/300] Training [62/62] Loss: 0.07190 
Epoch [100/300] Training metric {'Train/mean dice_metric': 0.8824307918548584, 'Train/mean miou_metric': 0.8080312013626099, 'Train/mean f1': 0.8911927342414856, 'Train/mean precision': 0.8819602727890015, 'Train/mean recall': 0.9006205201148987, 'Train/mean hd95_metric': 24.5684871673584}
Epoch [100/300] Validation [1/16] Loss: 0.37177  focal_loss 0.19214  dice_loss 0.17962 
Epoch [100/300] Validation [2/16] Loss: 0.39293  focal_loss 0.13373  dice_loss 0.25920 
Epoch [100/300] Validation [3/16] Loss: 0.38611  focal_loss 0.16271  dice_loss 0.22340 
Epoch [100/300] Validation [4/16] Loss: 0.25574  focal_loss 0.11346  dice_loss 0.14228 
Epoch [100/300] Validation [5/16] Loss: 0.23901  focal_loss 0.04470  dice_loss 0.19430 
Epoch [100/300] Validation [6/16] Loss: 0.25599  focal_loss 0.06978  dice_loss 0.18620 
Epoch [100/300] Validation [7/16] Loss: 0.34540  focal_loss 0.15527  dice_loss 0.19013 
Epoch [100/300] Validation [8/16] Loss: 0.43992  focal_loss 0.12762  dice_loss 0.31230 
Epoch [100/300] Validation [9/16] Loss: 0.30396  focal_loss 0.10790  dice_loss 0.19605 
Epoch [100/300] Validation [10/16] Loss: 0.40209  focal_loss 0.14833  dice_loss 0.25376 
Epoch [100/300] Validation [11/16] Loss: 0.25885  focal_loss 0.09333  dice_loss 0.16551 
Epoch [100/300] Validation [12/16] Loss: 0.34412  focal_loss 0.08388  dice_loss 0.26024 
Epoch [100/300] Validation [13/16] Loss: 0.35052  focal_loss 0.12441  dice_loss 0.22611 
Epoch [100/300] Validation [14/16] Loss: 0.52202  focal_loss 0.17043  dice_loss 0.35159 
Epoch [100/300] Validation [15/16] Loss: 0.23138  focal_loss 0.08151  dice_loss 0.14987 
Epoch [100/300] Validation [16/16] Loss: 0.08107  focal_loss 0.01600  dice_loss 0.06507 
Epoch [100/300] Validation metric {'Val/mean dice_metric': 0.8645579814910889, 'Val/mean miou_metric': 0.787537157535553, 'Val/mean f1': 0.8718082904815674, 'Val/mean precision': 0.8720942139625549, 'Val/mean recall': 0.8715224862098694, 'Val/mean hd95_metric': 28.256547927856445}
Cheakpoint...
Epoch [100/300] best acc:tensor([0.8646], device='cuda:0'), Now : mean acc: tensor([0.8646], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8645579814910889, 'Val/mean miou_metric': 0.787537157535553, 'Val/mean f1': 0.8718082904815674, 'Val/mean precision': 0.8720942139625549, 'Val/mean recall': 0.8715224862098694, 'Val/mean hd95_metric': 28.256547927856445}
Epoch [101/300] Training [1/62] Loss: 0.17743 
Epoch [101/300] Training [2/62] Loss: 0.17150 
Epoch [101/300] Training [3/62] Loss: 0.21512 
Epoch [101/300] Training [4/62] Loss: 0.19570 
Epoch [101/300] Training [5/62] Loss: 0.22096 
Epoch [101/300] Training [6/62] Loss: 0.15564 
Epoch [101/300] Training [7/62] Loss: 0.16461 
Epoch [101/300] Training [8/62] Loss: 0.19594 
Epoch [101/300] Training [9/62] Loss: 0.21787 
Epoch [101/300] Training [10/62] Loss: 0.21402 
Epoch [101/300] Training [11/62] Loss: 0.17885 
Epoch [101/300] Training [12/62] Loss: 0.12590 
Epoch [101/300] Training [13/62] Loss: 0.10276 
Epoch [101/300] Training [14/62] Loss: 0.11568 
Epoch [101/300] Training [15/62] Loss: 0.12967 
Epoch [101/300] Training [16/62] Loss: 0.16059 
Epoch [101/300] Training [17/62] Loss: 0.20093 
Epoch [101/300] Training [18/62] Loss: 0.22787 
Epoch [101/300] Training [19/62] Loss: 0.11602 
Epoch [101/300] Training [20/62] Loss: 0.14232 
Epoch [101/300] Training [21/62] Loss: 0.10725 
Epoch [101/300] Training [22/62] Loss: 0.18615 
Epoch [101/300] Training [23/62] Loss: 0.13795 
Epoch [101/300] Training [24/62] Loss: 0.26622 
Epoch [101/300] Training [25/62] Loss: 0.13277 
Epoch [101/300] Training [26/62] Loss: 0.16118 
Epoch [101/300] Training [27/62] Loss: 0.17239 
Epoch [101/300] Training [28/62] Loss: 0.17811 
Epoch [101/300] Training [29/62] Loss: 0.14441 
Epoch [101/300] Training [30/62] Loss: 0.08591 
Epoch [101/300] Training [31/62] Loss: 0.12925 
Epoch [101/300] Training [32/62] Loss: 0.13781 
Epoch [101/300] Training [33/62] Loss: 0.15468 
Epoch [101/300] Training [34/62] Loss: 0.27617 
Epoch [101/300] Training [35/62] Loss: 0.13125 
Epoch [101/300] Training [36/62] Loss: 0.12853 
Epoch [101/300] Training [37/62] Loss: 0.16158 
Epoch [101/300] Training [38/62] Loss: 0.15183 
Epoch [101/300] Training [39/62] Loss: 0.26236 
Epoch [101/300] Training [40/62] Loss: 0.11923 
Epoch [101/300] Training [41/62] Loss: 0.14374 
Epoch [101/300] Training [42/62] Loss: 0.09140 
Epoch [101/300] Training [43/62] Loss: 0.18039 
Epoch [101/300] Training [44/62] Loss: 0.27137 
Epoch [101/300] Training [45/62] Loss: 0.17045 
Epoch [101/300] Training [46/62] Loss: 0.11110 
Epoch [101/300] Training [47/62] Loss: 0.12547 
Epoch [101/300] Training [48/62] Loss: 0.20127 
Epoch [101/300] Training [49/62] Loss: 0.45305 
Epoch [101/300] Training [50/62] Loss: 0.20901 
Epoch [101/300] Training [51/62] Loss: 0.12212 
Epoch [101/300] Training [52/62] Loss: 0.27852 
Epoch [101/300] Training [53/62] Loss: 0.15296 
Epoch [101/300] Training [54/62] Loss: 0.40330 
Epoch [101/300] Training [55/62] Loss: 0.10043 
Epoch [101/300] Training [56/62] Loss: 0.32622 
Epoch [101/300] Training [57/62] Loss: 0.17598 
Epoch [101/300] Training [58/62] Loss: 0.21770 
Epoch [101/300] Training [59/62] Loss: 0.22949 
Epoch [101/300] Training [60/62] Loss: 0.18942 
Epoch [101/300] Training [61/62] Loss: 0.10034 
Epoch [101/300] Training [62/62] Loss: 0.13253 
Epoch [101/300] Training metric {'Train/mean dice_metric': 0.8787481784820557, 'Train/mean miou_metric': 0.8024511933326721, 'Train/mean f1': 0.8935818076133728, 'Train/mean precision': 0.8859777450561523, 'Train/mean recall': 0.9013175368309021, 'Train/mean hd95_metric': 24.721670150756836}
Epoch [101/300] Validation [1/16] Loss: 0.19919  focal_loss 0.07227  dice_loss 0.12692 
Epoch [101/300] Validation [2/16] Loss: 0.35667  focal_loss 0.09218  dice_loss 0.26448 
Epoch [101/300] Validation [3/16] Loss: 0.52436  focal_loss 0.19919  dice_loss 0.32517 
Epoch [101/300] Validation [4/16] Loss: 0.28333  focal_loss 0.09305  dice_loss 0.19028 
Epoch [101/300] Validation [5/16] Loss: 0.32564  focal_loss 0.05931  dice_loss 0.26633 
Epoch [101/300] Validation [6/16] Loss: 0.22271  focal_loss 0.04042  dice_loss 0.18228 
Epoch [101/300] Validation [7/16] Loss: 0.17252  focal_loss 0.03493  dice_loss 0.13759 
Epoch [101/300] Validation [8/16] Loss: 0.56279  focal_loss 0.18479  dice_loss 0.37800 
Epoch [101/300] Validation [9/16] Loss: 0.24692  focal_loss 0.05656  dice_loss 0.19036 
Epoch [101/300] Validation [10/16] Loss: 0.30500  focal_loss 0.08369  dice_loss 0.22131 
Epoch [101/300] Validation [11/16] Loss: 0.18950  focal_loss 0.04240  dice_loss 0.14711 
Epoch [101/300] Validation [12/16] Loss: 0.35250  focal_loss 0.07422  dice_loss 0.27828 
Epoch [101/300] Validation [13/16] Loss: 0.27823  focal_loss 0.05164  dice_loss 0.22659 
Epoch [101/300] Validation [14/16] Loss: 0.37202  focal_loss 0.07708  dice_loss 0.29494 
Epoch [101/300] Validation [15/16] Loss: 0.18570  focal_loss 0.03539  dice_loss 0.15031 
Epoch [101/300] Validation [16/16] Loss: 0.09509  focal_loss 0.01441  dice_loss 0.08068 
Epoch [101/300] Validation metric {'Val/mean dice_metric': 0.8632196187973022, 'Val/mean miou_metric': 0.7851300239562988, 'Val/mean f1': 0.8759848475456238, 'Val/mean precision': 0.8651688694953918, 'Val/mean recall': 0.8870747685432434, 'Val/mean hd95_metric': 28.527084350585938}
Cheakpoint...
Epoch [101/300] best acc:tensor([0.8646], device='cuda:0'), Now : mean acc: tensor([0.8632], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8632196187973022, 'Val/mean miou_metric': 0.7851300239562988, 'Val/mean f1': 0.8759848475456238, 'Val/mean precision': 0.8651688694953918, 'Val/mean recall': 0.8870747685432434, 'Val/mean hd95_metric': 28.527084350585938}
Epoch [102/300] Training [1/62] Loss: 0.35434 
Epoch [102/300] Training [2/62] Loss: 0.19496 
Epoch [102/300] Training [3/62] Loss: 0.19348 
Epoch [102/300] Training [4/62] Loss: 0.20219 
Epoch [102/300] Training [5/62] Loss: 0.18296 
Epoch [102/300] Training [6/62] Loss: 0.17765 
Epoch [102/300] Training [7/62] Loss: 0.15783 
Epoch [102/300] Training [8/62] Loss: 0.15809 
Epoch [102/300] Training [9/62] Loss: 0.17063 
Epoch [102/300] Training [10/62] Loss: 0.12262 
Epoch [102/300] Training [11/62] Loss: 0.17180 
Epoch [102/300] Training [12/62] Loss: 0.09786 
Epoch [102/300] Training [13/62] Loss: 0.18728 
Epoch [102/300] Training [14/62] Loss: 0.11463 
Epoch [102/300] Training [15/62] Loss: 0.30376 
Epoch [102/300] Training [16/62] Loss: 0.18164 
Epoch [102/300] Training [17/62] Loss: 0.32529 
Epoch [102/300] Training [18/62] Loss: 0.15023 
Epoch [102/300] Training [19/62] Loss: 0.13970 
Epoch [102/300] Training [20/62] Loss: 0.12299 
Epoch [102/300] Training [21/62] Loss: 0.16012 
Epoch [102/300] Training [22/62] Loss: 0.27481 
Epoch [102/300] Training [23/62] Loss: 0.16576 
Epoch [102/300] Training [24/62] Loss: 0.23022 
Epoch [102/300] Training [25/62] Loss: 0.14882 
Epoch [102/300] Training [26/62] Loss: 0.20187 
Epoch [102/300] Training [27/62] Loss: 0.12591 
Epoch [102/300] Training [28/62] Loss: 0.13246 
Epoch [102/300] Training [29/62] Loss: 0.08100 
Epoch [102/300] Training [30/62] Loss: 0.18518 
Epoch [102/300] Training [31/62] Loss: 0.15310 
Epoch [102/300] Training [32/62] Loss: 0.11285 
Epoch [102/300] Training [33/62] Loss: 0.23588 
Epoch [102/300] Training [34/62] Loss: 0.12391 
Epoch [102/300] Training [35/62] Loss: 0.23482 
Epoch [102/300] Training [36/62] Loss: 0.14683 
Epoch [102/300] Training [37/62] Loss: 0.13839 
Epoch [102/300] Training [38/62] Loss: 0.14403 
Epoch [102/300] Training [39/62] Loss: 0.09661 
Epoch [102/300] Training [40/62] Loss: 0.11727 
Epoch [102/300] Training [41/62] Loss: 0.09649 
Epoch [102/300] Training [42/62] Loss: 0.19173 
Epoch [102/300] Training [43/62] Loss: 0.10832 
Epoch [102/300] Training [44/62] Loss: 0.21355 
Epoch [102/300] Training [45/62] Loss: 0.10810 
Epoch [102/300] Training [46/62] Loss: 0.30453 
Epoch [102/300] Training [47/62] Loss: 0.21379 
Epoch [102/300] Training [48/62] Loss: 0.14175 
Epoch [102/300] Training [49/62] Loss: 0.14905 
Epoch [102/300] Training [50/62] Loss: 0.16931 
Epoch [102/300] Training [51/62] Loss: 0.13888 
Epoch [102/300] Training [52/62] Loss: 0.20764 
Epoch [102/300] Training [53/62] Loss: 0.17314 
Epoch [102/300] Training [54/62] Loss: 0.11871 
Epoch [102/300] Training [55/62] Loss: 0.22887 
Epoch [102/300] Training [56/62] Loss: 0.12327 
Epoch [102/300] Training [57/62] Loss: 0.35142 
Epoch [102/300] Training [58/62] Loss: 0.12674 
Epoch [102/300] Training [59/62] Loss: 0.19319 
Epoch [102/300] Training [60/62] Loss: 0.16479 
Epoch [102/300] Training [61/62] Loss: 0.40929 
Epoch [102/300] Training [62/62] Loss: 0.08358 
Epoch [102/300] Training metric {'Train/mean dice_metric': 0.8801489472389221, 'Train/mean miou_metric': 0.8053286671638489, 'Train/mean f1': 0.8948546051979065, 'Train/mean precision': 0.891299843788147, 'Train/mean recall': 0.8984377980232239, 'Train/mean hd95_metric': 24.083145141601562}
Epoch [102/300] Validation [1/16] Loss: 0.11250  focal_loss 0.02694  dice_loss 0.08556 
Epoch [102/300] Validation [2/16] Loss: 0.33715  focal_loss 0.08801  dice_loss 0.24914 
Epoch [102/300] Validation [3/16] Loss: 0.38711  focal_loss 0.09433  dice_loss 0.29278 
Epoch [102/300] Validation [4/16] Loss: 0.16776  focal_loss 0.03910  dice_loss 0.12865 
Epoch [102/300] Validation [5/16] Loss: 0.34750  focal_loss 0.06086  dice_loss 0.28664 
Epoch [102/300] Validation [6/16] Loss: 0.28214  focal_loss 0.05045  dice_loss 0.23169 
Epoch [102/300] Validation [7/16] Loss: 0.23183  focal_loss 0.07096  dice_loss 0.16087 
Epoch [102/300] Validation [8/16] Loss: 0.43726  focal_loss 0.14520  dice_loss 0.29206 
Epoch [102/300] Validation [9/16] Loss: 0.27975  focal_loss 0.09249  dice_loss 0.18726 
Epoch [102/300] Validation [10/16] Loss: 0.35258  focal_loss 0.09806  dice_loss 0.25452 
Epoch [102/300] Validation [11/16] Loss: 0.19708  focal_loss 0.03639  dice_loss 0.16068 
Epoch [102/300] Validation [12/16] Loss: 0.51633  focal_loss 0.16756  dice_loss 0.34877 
Epoch [102/300] Validation [13/16] Loss: 0.28737  focal_loss 0.05728  dice_loss 0.23009 
Epoch [102/300] Validation [14/16] Loss: 0.47762  focal_loss 0.11019  dice_loss 0.36743 
Epoch [102/300] Validation [15/16] Loss: 0.29199  focal_loss 0.08085  dice_loss 0.21114 
Epoch [102/300] Validation [16/16] Loss: 0.07154  focal_loss 0.01305  dice_loss 0.05849 
Epoch [102/300] Validation metric {'Val/mean dice_metric': 0.8629087805747986, 'Val/mean miou_metric': 0.7847803831100464, 'Val/mean f1': 0.8701915740966797, 'Val/mean precision': 0.8463341593742371, 'Val/mean recall': 0.8954331278800964, 'Val/mean hd95_metric': 30.664291381835938}
Cheakpoint...
Epoch [102/300] best acc:tensor([0.8646], device='cuda:0'), Now : mean acc: tensor([0.8629], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8629087805747986, 'Val/mean miou_metric': 0.7847803831100464, 'Val/mean f1': 0.8701915740966797, 'Val/mean precision': 0.8463341593742371, 'Val/mean recall': 0.8954331278800964, 'Val/mean hd95_metric': 30.664291381835938}
Epoch [103/300] Training [1/62] Loss: 0.25660 
Epoch [103/300] Training [2/62] Loss: 0.14382 
Epoch [103/300] Training [3/62] Loss: 0.10545 
Epoch [103/300] Training [4/62] Loss: 0.27193 
Epoch [103/300] Training [5/62] Loss: 0.37317 
Epoch [103/300] Training [6/62] Loss: 0.31934 
Epoch [103/300] Training [7/62] Loss: 0.12211 
Epoch [103/300] Training [8/62] Loss: 0.13270 
Epoch [103/300] Training [9/62] Loss: 0.33286 
Epoch [103/300] Training [10/62] Loss: 0.12248 
Epoch [103/300] Training [11/62] Loss: 0.14815 
Epoch [103/300] Training [12/62] Loss: 0.27874 
Epoch [103/300] Training [13/62] Loss: 0.19496 
Epoch [103/300] Training [14/62] Loss: 0.08824 
Epoch [103/300] Training [15/62] Loss: 0.16712 
Epoch [103/300] Training [16/62] Loss: 0.16456 
Epoch [103/300] Training [17/62] Loss: 0.22029 
Epoch [103/300] Training [18/62] Loss: 0.12365 
Epoch [103/300] Training [19/62] Loss: 0.18776 
Epoch [103/300] Training [20/62] Loss: 0.19170 
Epoch [103/300] Training [21/62] Loss: 0.31196 
Epoch [103/300] Training [22/62] Loss: 0.10458 
Epoch [103/300] Training [23/62] Loss: 0.28353 
Epoch [103/300] Training [24/62] Loss: 0.26309 
Epoch [103/300] Training [25/62] Loss: 0.22248 
Epoch [103/300] Training [26/62] Loss: 0.10054 
Epoch [103/300] Training [27/62] Loss: 0.19525 
Epoch [103/300] Training [28/62] Loss: 0.17539 
Epoch [103/300] Training [29/62] Loss: 0.10205 
Epoch [103/300] Training [30/62] Loss: 0.24798 
Epoch [103/300] Training [31/62] Loss: 0.13707 
Epoch [103/300] Training [32/62] Loss: 0.15456 
Epoch [103/300] Training [33/62] Loss: 0.11474 
Epoch [103/300] Training [34/62] Loss: 0.14466 
Epoch [103/300] Training [35/62] Loss: 0.21388 
Epoch [103/300] Training [36/62] Loss: 0.15716 
Epoch [103/300] Training [37/62] Loss: 0.12868 
Epoch [103/300] Training [38/62] Loss: 0.11514 
Epoch [103/300] Training [39/62] Loss: 0.07788 
Epoch [103/300] Training [40/62] Loss: 0.20455 
Epoch [103/300] Training [41/62] Loss: 0.23133 
Epoch [103/300] Training [42/62] Loss: 0.27443 
Epoch [103/300] Training [43/62] Loss: 0.29362 
Epoch [103/300] Training [44/62] Loss: 0.16057 
Epoch [103/300] Training [45/62] Loss: 0.22342 
Epoch [103/300] Training [46/62] Loss: 0.17727 
Epoch [103/300] Training [47/62] Loss: 0.12000 
Epoch [103/300] Training [48/62] Loss: 0.23871 
Epoch [103/300] Training [49/62] Loss: 0.09055 
Epoch [103/300] Training [50/62] Loss: 0.16478 
Epoch [103/300] Training [51/62] Loss: 0.13243 
Epoch [103/300] Training [52/62] Loss: 0.15734 
Epoch [103/300] Training [53/62] Loss: 0.22981 
Epoch [103/300] Training [54/62] Loss: 0.18186 
Epoch [103/300] Training [55/62] Loss: 0.11060 
Epoch [103/300] Training [56/62] Loss: 0.28427 
Epoch [103/300] Training [57/62] Loss: 0.20547 
Epoch [103/300] Training [58/62] Loss: 0.16976 
Epoch [103/300] Training [59/62] Loss: 0.19858 
Epoch [103/300] Training [60/62] Loss: 0.24812 
Epoch [103/300] Training [61/62] Loss: 0.13660 
Epoch [103/300] Training [62/62] Loss: 0.08721 
Epoch [103/300] Training metric {'Train/mean dice_metric': 0.870797336101532, 'Train/mean miou_metric': 0.7954077124595642, 'Train/mean f1': 0.8850857019424438, 'Train/mean precision': 0.8711341619491577, 'Train/mean recall': 0.8994914293289185, 'Train/mean hd95_metric': 27.85236358642578}
Epoch [103/300] Validation [1/16] Loss: 0.14030  focal_loss 0.02905  dice_loss 0.11125 
Epoch [103/300] Validation [2/16] Loss: 0.44083  focal_loss 0.14883  dice_loss 0.29201 
Epoch [103/300] Validation [3/16] Loss: 0.63426  focal_loss 0.31861  dice_loss 0.31565 
Epoch [103/300] Validation [4/16] Loss: 0.27672  focal_loss 0.11900  dice_loss 0.15771 
Epoch [103/300] Validation [5/16] Loss: 0.32109  focal_loss 0.06589  dice_loss 0.25520 
Epoch [103/300] Validation [6/16] Loss: 0.29757  focal_loss 0.05802  dice_loss 0.23955 
Epoch [103/300] Validation [7/16] Loss: 0.18355  focal_loss 0.05043  dice_loss 0.13312 
Epoch [103/300] Validation [8/16] Loss: 0.27274  focal_loss 0.04646  dice_loss 0.22628 
Epoch [103/300] Validation [9/16] Loss: 0.21720  focal_loss 0.04988  dice_loss 0.16732 
Epoch [103/300] Validation [10/16] Loss: 0.35179  focal_loss 0.06671  dice_loss 0.28508 
Epoch [103/300] Validation [11/16] Loss: 0.15858  focal_loss 0.03532  dice_loss 0.12326 
Epoch [103/300] Validation [12/16] Loss: 0.36383  focal_loss 0.05770  dice_loss 0.30612 
Epoch [103/300] Validation [13/16] Loss: 0.38214  focal_loss 0.12820  dice_loss 0.25393 
Epoch [103/300] Validation [14/16] Loss: 0.40822  focal_loss 0.07539  dice_loss 0.33282 
Epoch [103/300] Validation [15/16] Loss: 0.15467  focal_loss 0.03260  dice_loss 0.12207 
Epoch [103/300] Validation [16/16] Loss: 0.11906  focal_loss 0.02564  dice_loss 0.09341 
Epoch [103/300] Validation metric {'Val/mean dice_metric': 0.8577238321304321, 'Val/mean miou_metric': 0.7803730964660645, 'Val/mean f1': 0.8702095150947571, 'Val/mean precision': 0.8564984202384949, 'Val/mean recall': 0.8843668699264526, 'Val/mean hd95_metric': 32.57366943359375}
Cheakpoint...
Epoch [103/300] best acc:tensor([0.8646], device='cuda:0'), Now : mean acc: tensor([0.8577], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8577238321304321, 'Val/mean miou_metric': 0.7803730964660645, 'Val/mean f1': 0.8702095150947571, 'Val/mean precision': 0.8564984202384949, 'Val/mean recall': 0.8843668699264526, 'Val/mean hd95_metric': 32.57366943359375}
Epoch [104/300] Training [1/62] Loss: 0.09391 
Epoch [104/300] Training [2/62] Loss: 0.13358 
Epoch [104/300] Training [3/62] Loss: 0.24655 
Epoch [104/300] Training [4/62] Loss: 0.27050 
Epoch [104/300] Training [5/62] Loss: 0.26853 
Epoch [104/300] Training [6/62] Loss: 0.14462 
Epoch [104/300] Training [7/62] Loss: 0.23977 
Epoch [104/300] Training [8/62] Loss: 0.09573 
Epoch [104/300] Training [9/62] Loss: 0.14485 
Epoch [104/300] Training [10/62] Loss: 0.16940 
Epoch [104/300] Training [11/62] Loss: 0.24422 
Epoch [104/300] Training [12/62] Loss: 0.18463 
Epoch [104/300] Training [13/62] Loss: 0.08697 
Epoch [104/300] Training [14/62] Loss: 0.16706 
Epoch [104/300] Training [15/62] Loss: 0.09758 
Epoch [104/300] Training [16/62] Loss: 0.28246 
Epoch [104/300] Training [17/62] Loss: 0.21837 
Epoch [104/300] Training [18/62] Loss: 0.27945 
Epoch [104/300] Training [19/62] Loss: 0.32030 
Epoch [104/300] Training [20/62] Loss: 0.13342 
Epoch [104/300] Training [21/62] Loss: 0.21899 
Epoch [104/300] Training [22/62] Loss: 0.13771 
Epoch [104/300] Training [23/62] Loss: 0.22778 
Epoch [104/300] Training [24/62] Loss: 0.14668 
Epoch [104/300] Training [25/62] Loss: 0.08122 
Epoch [104/300] Training [26/62] Loss: 0.12583 
Epoch [104/300] Training [27/62] Loss: 0.22256 
Epoch [104/300] Training [28/62] Loss: 0.31533 
Epoch [104/300] Training [29/62] Loss: 0.08672 
Epoch [104/300] Training [30/62] Loss: 0.11796 
Epoch [104/300] Training [31/62] Loss: 0.25384 
Epoch [104/300] Training [32/62] Loss: 0.16148 
Epoch [104/300] Training [33/62] Loss: 0.13580 
Epoch [104/300] Training [34/62] Loss: 0.16520 
Epoch [104/300] Training [35/62] Loss: 0.16163 
Epoch [104/300] Training [36/62] Loss: 0.22809 
Epoch [104/300] Training [37/62] Loss: 0.36629 
Epoch [104/300] Training [38/62] Loss: 0.21529 
Epoch [104/300] Training [39/62] Loss: 0.15150 
Epoch [104/300] Training [40/62] Loss: 0.15493 
Epoch [104/300] Training [41/62] Loss: 0.24245 
Epoch [104/300] Training [42/62] Loss: 0.21021 
Epoch [104/300] Training [43/62] Loss: 0.21258 
Epoch [104/300] Training [44/62] Loss: 0.13062 
Epoch [104/300] Training [45/62] Loss: 0.20603 
Epoch [104/300] Training [46/62] Loss: 0.29287 
Epoch [104/300] Training [47/62] Loss: 0.08576 
Epoch [104/300] Training [48/62] Loss: 0.17962 
Epoch [104/300] Training [49/62] Loss: 0.11620 
Epoch [104/300] Training [50/62] Loss: 0.20739 
Epoch [104/300] Training [51/62] Loss: 0.17520 
Epoch [104/300] Training [52/62] Loss: 0.24760 
Epoch [104/300] Training [53/62] Loss: 0.31433 
Epoch [104/300] Training [54/62] Loss: 0.10200 
Epoch [104/300] Training [55/62] Loss: 0.20483 
Epoch [104/300] Training [56/62] Loss: 0.24194 
Epoch [104/300] Training [57/62] Loss: 0.16365 
Epoch [104/300] Training [58/62] Loss: 0.19125 
Epoch [104/300] Training [59/62] Loss: 0.11891 
Epoch [104/300] Training [60/62] Loss: 0.10741 
Epoch [104/300] Training [61/62] Loss: 0.13307 
Epoch [104/300] Training [62/62] Loss: 0.16062 
Epoch [104/300] Training metric {'Train/mean dice_metric': 0.8722440004348755, 'Train/mean miou_metric': 0.7962045073509216, 'Train/mean f1': 0.8898599147796631, 'Train/mean precision': 0.8846307396888733, 'Train/mean recall': 0.8951513767242432, 'Train/mean hd95_metric': 26.33460807800293}
Epoch [104/300] Validation [1/16] Loss: 0.10458  focal_loss 0.03474  dice_loss 0.06984 
Epoch [104/300] Validation [2/16] Loss: 0.42374  focal_loss 0.14818  dice_loss 0.27556 
Epoch [104/300] Validation [3/16] Loss: 0.67115  focal_loss 0.32243  dice_loss 0.34873 
Epoch [104/300] Validation [4/16] Loss: 0.35152  focal_loss 0.14470  dice_loss 0.20682 
Epoch [104/300] Validation [5/16] Loss: 0.40897  focal_loss 0.12256  dice_loss 0.28641 
Epoch [104/300] Validation [6/16] Loss: 0.27740  focal_loss 0.07929  dice_loss 0.19810 
Epoch [104/300] Validation [7/16] Loss: 0.21578  focal_loss 0.05847  dice_loss 0.15731 
Epoch [104/300] Validation [8/16] Loss: 0.43610  focal_loss 0.12630  dice_loss 0.30980 
Epoch [104/300] Validation [9/16] Loss: 0.18789  focal_loss 0.05171  dice_loss 0.13618 
Epoch [104/300] Validation [10/16] Loss: 0.32507  focal_loss 0.10251  dice_loss 0.22256 
Epoch [104/300] Validation [11/16] Loss: 0.16680  focal_loss 0.03982  dice_loss 0.12698 
Epoch [104/300] Validation [12/16] Loss: 0.44965  focal_loss 0.09991  dice_loss 0.34974 
Epoch [104/300] Validation [13/16] Loss: 0.24323  focal_loss 0.05322  dice_loss 0.19001 
Epoch [104/300] Validation [14/16] Loss: 0.41665  focal_loss 0.13558  dice_loss 0.28107 
Epoch [104/300] Validation [15/16] Loss: 0.18971  focal_loss 0.06700  dice_loss 0.12270 
Epoch [104/300] Validation [16/16] Loss: 0.06544  focal_loss 0.01224  dice_loss 0.05320 
Epoch [104/300] Validation metric {'Val/mean dice_metric': 0.8572654724121094, 'Val/mean miou_metric': 0.7794386148452759, 'Val/mean f1': 0.8724361062049866, 'Val/mean precision': 0.861719012260437, 'Val/mean recall': 0.8834231495857239, 'Val/mean hd95_metric': 30.775096893310547}
Cheakpoint...
Epoch [104/300] best acc:tensor([0.8646], device='cuda:0'), Now : mean acc: tensor([0.8573], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8572654724121094, 'Val/mean miou_metric': 0.7794386148452759, 'Val/mean f1': 0.8724361062049866, 'Val/mean precision': 0.861719012260437, 'Val/mean recall': 0.8834231495857239, 'Val/mean hd95_metric': 30.775096893310547}
Epoch [105/300] Training [1/62] Loss: 0.07281 
Epoch [105/300] Training [2/62] Loss: 0.06599 
Epoch [105/300] Training [3/62] Loss: 0.10982 
Epoch [105/300] Training [4/62] Loss: 0.08986 
Epoch [105/300] Training [5/62] Loss: 0.12793 
Epoch [105/300] Training [6/62] Loss: 0.14522 
Epoch [105/300] Training [7/62] Loss: 0.17540 
Epoch [105/300] Training [8/62] Loss: 0.13110 
Epoch [105/300] Training [9/62] Loss: 0.35972 
Epoch [105/300] Training [10/62] Loss: 0.22923 
Epoch [105/300] Training [11/62] Loss: 0.15652 
Epoch [105/300] Training [12/62] Loss: 0.30607 
Epoch [105/300] Training [13/62] Loss: 0.15222 
Epoch [105/300] Training [14/62] Loss: 0.35416 
Epoch [105/300] Training [15/62] Loss: 0.13607 
Epoch [105/300] Training [16/62] Loss: 0.37316 
Epoch [105/300] Training [17/62] Loss: 0.09173 
Epoch [105/300] Training [18/62] Loss: 0.10662 
Epoch [105/300] Training [19/62] Loss: 0.26034 
Epoch [105/300] Training [20/62] Loss: 0.21143 
Epoch [105/300] Training [21/62] Loss: 0.12949 
Epoch [105/300] Training [22/62] Loss: 0.23685 
Epoch [105/300] Training [23/62] Loss: 0.36263 
Epoch [105/300] Training [24/62] Loss: 0.16536 
Epoch [105/300] Training [25/62] Loss: 0.09571 
Epoch [105/300] Training [26/62] Loss: 0.12938 
Epoch [105/300] Training [27/62] Loss: 0.28729 
Epoch [105/300] Training [28/62] Loss: 0.20973 
Epoch [105/300] Training [29/62] Loss: 0.18898 
Epoch [105/300] Training [30/62] Loss: 0.30462 
Epoch [105/300] Training [31/62] Loss: 0.17638 
Epoch [105/300] Training [32/62] Loss: 0.18688 
Epoch [105/300] Training [33/62] Loss: 0.13647 
Epoch [105/300] Training [34/62] Loss: 0.28662 
Epoch [105/300] Training [35/62] Loss: 0.15911 
Epoch [105/300] Training [36/62] Loss: 0.16833 
Epoch [105/300] Training [37/62] Loss: 0.20354 
Epoch [105/300] Training [38/62] Loss: 0.14185 
Epoch [105/300] Training [39/62] Loss: 0.17436 
Epoch [105/300] Training [40/62] Loss: 0.22835 
Epoch [105/300] Training [41/62] Loss: 0.14537 
Epoch [105/300] Training [42/62] Loss: 0.18281 
Epoch [105/300] Training [43/62] Loss: 0.18616 
Epoch [105/300] Training [44/62] Loss: 0.09544 
Epoch [105/300] Training [45/62] Loss: 0.10276 
Epoch [105/300] Training [46/62] Loss: 0.11558 
Epoch [105/300] Training [47/62] Loss: 0.14336 
Epoch [105/300] Training [48/62] Loss: 0.18450 
Epoch [105/300] Training [49/62] Loss: 0.11539 
Epoch [105/300] Training [50/62] Loss: 0.20891 
Epoch [105/300] Training [51/62] Loss: 0.20882 
Epoch [105/300] Training [52/62] Loss: 0.11009 
Epoch [105/300] Training [53/62] Loss: 0.13348 
Epoch [105/300] Training [54/62] Loss: 0.28956 
Epoch [105/300] Training [55/62] Loss: 0.18006 
Epoch [105/300] Training [56/62] Loss: 0.31572 
Epoch [105/300] Training [57/62] Loss: 0.24644 
Epoch [105/300] Training [58/62] Loss: 0.10404 
Epoch [105/300] Training [59/62] Loss: 0.13861 
Epoch [105/300] Training [60/62] Loss: 0.17064 
Epoch [105/300] Training [61/62] Loss: 0.26666 
Epoch [105/300] Training [62/62] Loss: 0.10134 
Epoch [105/300] Training metric {'Train/mean dice_metric': 0.8715066313743591, 'Train/mean miou_metric': 0.7997187376022339, 'Train/mean f1': 0.8940765857696533, 'Train/mean precision': 0.8850278854370117, 'Train/mean recall': 0.9033122062683105, 'Train/mean hd95_metric': 25.245473861694336}
Epoch [105/300] Validation [1/16] Loss: 0.45474  focal_loss 0.28083  dice_loss 0.17391 
Epoch [105/300] Validation [2/16] Loss: 0.35355  focal_loss 0.09098  dice_loss 0.26258 
Epoch [105/300] Validation [3/16] Loss: 0.29956  focal_loss 0.07616  dice_loss 0.22340 
Epoch [105/300] Validation [4/16] Loss: 0.26072  focal_loss 0.08519  dice_loss 0.17553 
Epoch [105/300] Validation [5/16] Loss: 0.41383  focal_loss 0.11330  dice_loss 0.30053 
Epoch [105/300] Validation [6/16] Loss: 0.23503  focal_loss 0.04474  dice_loss 0.19029 
Epoch [105/300] Validation [7/16] Loss: 0.31626  focal_loss 0.12276  dice_loss 0.19350 
Epoch [105/300] Validation [8/16] Loss: 0.38712  focal_loss 0.10518  dice_loss 0.28195 
Epoch [105/300] Validation [9/16] Loss: 0.15943  focal_loss 0.03701  dice_loss 0.12242 
Epoch [105/300] Validation [10/16] Loss: 0.33277  focal_loss 0.08795  dice_loss 0.24481 
Epoch [105/300] Validation [11/16] Loss: 0.12272  focal_loss 0.02245  dice_loss 0.10027 
Epoch [105/300] Validation [12/16] Loss: 0.31338  focal_loss 0.06496  dice_loss 0.24842 
Epoch [105/300] Validation [13/16] Loss: 0.31823  focal_loss 0.08700  dice_loss 0.23123 
Epoch [105/300] Validation [14/16] Loss: 0.36479  focal_loss 0.08215  dice_loss 0.28264 
Epoch [105/300] Validation [15/16] Loss: 0.31668  focal_loss 0.11851  dice_loss 0.19817 
Epoch [105/300] Validation [16/16] Loss: 0.06756  focal_loss 0.01382  dice_loss 0.05374 
Epoch [105/300] Validation metric {'Val/mean dice_metric': 0.8575430512428284, 'Val/mean miou_metric': 0.783048152923584, 'Val/mean f1': 0.8787950277328491, 'Val/mean precision': 0.8772281408309937, 'Val/mean recall': 0.8803675770759583, 'Val/mean hd95_metric': 27.902498245239258}
Cheakpoint...
Epoch [105/300] best acc:tensor([0.8646], device='cuda:0'), Now : mean acc: tensor([0.8575], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8575430512428284, 'Val/mean miou_metric': 0.783048152923584, 'Val/mean f1': 0.8787950277328491, 'Val/mean precision': 0.8772281408309937, 'Val/mean recall': 0.8803675770759583, 'Val/mean hd95_metric': 27.902498245239258}
Epoch [106/300] Training [1/62] Loss: 0.10002 
Epoch [106/300] Training [2/62] Loss: 0.15052 
Epoch [106/300] Training [3/62] Loss: 0.14726 
Epoch [106/300] Training [4/62] Loss: 0.25228 
Epoch [106/300] Training [5/62] Loss: 0.27478 
Epoch [106/300] Training [6/62] Loss: 0.17371 
Epoch [106/300] Training [7/62] Loss: 0.15423 
Epoch [106/300] Training [8/62] Loss: 0.27263 
Epoch [106/300] Training [9/62] Loss: 0.16105 
Epoch [106/300] Training [10/62] Loss: 0.17817 
Epoch [106/300] Training [11/62] Loss: 0.23644 
Epoch [106/300] Training [12/62] Loss: 0.09741 
Epoch [106/300] Training [13/62] Loss: 0.21049 
Epoch [106/300] Training [14/62] Loss: 0.16744 
Epoch [106/300] Training [15/62] Loss: 0.11429 
Epoch [106/300] Training [16/62] Loss: 0.15943 
Epoch [106/300] Training [17/62] Loss: 0.13006 
Epoch [106/300] Training [18/62] Loss: 0.16506 
Epoch [106/300] Training [19/62] Loss: 0.23659 
Epoch [106/300] Training [20/62] Loss: 0.17529 
Epoch [106/300] Training [21/62] Loss: 0.11631 
Epoch [106/300] Training [22/62] Loss: 0.17094 
Epoch [106/300] Training [23/62] Loss: 0.21101 
Epoch [106/300] Training [24/62] Loss: 0.20511 
Epoch [106/300] Training [25/62] Loss: 0.15555 
Epoch [106/300] Training [26/62] Loss: 0.18707 
Epoch [106/300] Training [27/62] Loss: 0.14967 
Epoch [106/300] Training [28/62] Loss: 0.25201 
Epoch [106/300] Training [29/62] Loss: 0.13164 
Epoch [106/300] Training [30/62] Loss: 0.10654 
Epoch [106/300] Training [31/62] Loss: 0.14588 
Epoch [106/300] Training [32/62] Loss: 0.13373 
Epoch [106/300] Training [33/62] Loss: 0.20995 
Epoch [106/300] Training [34/62] Loss: 0.08353 
Epoch [106/300] Training [35/62] Loss: 0.22984 
Epoch [106/300] Training [36/62] Loss: 0.21768 
Epoch [106/300] Training [37/62] Loss: 0.23029 
Epoch [106/300] Training [38/62] Loss: 0.19775 
Epoch [106/300] Training [39/62] Loss: 0.14050 
Epoch [106/300] Training [40/62] Loss: 0.23692 
Epoch [106/300] Training [41/62] Loss: 0.13149 
Epoch [106/300] Training [42/62] Loss: 0.09349 
Epoch [106/300] Training [43/62] Loss: 0.12818 
Epoch [106/300] Training [44/62] Loss: 0.20246 
Epoch [106/300] Training [45/62] Loss: 0.13938 
Epoch [106/300] Training [46/62] Loss: 0.12378 
Epoch [106/300] Training [47/62] Loss: 0.11393 
Epoch [106/300] Training [48/62] Loss: 0.08753 
Epoch [106/300] Training [49/62] Loss: 0.23012 
Epoch [106/300] Training [50/62] Loss: 0.10924 
Epoch [106/300] Training [51/62] Loss: 0.09582 
Epoch [106/300] Training [52/62] Loss: 0.38518 
Epoch [106/300] Training [53/62] Loss: 0.14457 
Epoch [106/300] Training [54/62] Loss: 0.11829 
Epoch [106/300] Training [55/62] Loss: 0.13355 
Epoch [106/300] Training [56/62] Loss: 0.29500 
Epoch [106/300] Training [57/62] Loss: 0.23969 
Epoch [106/300] Training [58/62] Loss: 0.11576 
Epoch [106/300] Training [59/62] Loss: 0.19008 
Epoch [106/300] Training [60/62] Loss: 0.18924 
Epoch [106/300] Training [61/62] Loss: 0.10026 
Epoch [106/300] Training [62/62] Loss: 0.18953 
Epoch [106/300] Training metric {'Train/mean dice_metric': 0.8846942186355591, 'Train/mean miou_metric': 0.8109474182128906, 'Train/mean f1': 0.8993176221847534, 'Train/mean precision': 0.8952251672744751, 'Train/mean recall': 0.9034475088119507, 'Train/mean hd95_metric': 24.448041915893555}
Epoch [106/300] Validation [1/16] Loss: 0.32823  focal_loss 0.17863  dice_loss 0.14960 
Epoch [106/300] Validation [2/16] Loss: 0.34061  focal_loss 0.07704  dice_loss 0.26358 
Epoch [106/300] Validation [3/16] Loss: 0.58640  focal_loss 0.25233  dice_loss 0.33407 
Epoch [106/300] Validation [4/16] Loss: 0.22323  focal_loss 0.06045  dice_loss 0.16278 
Epoch [106/300] Validation [5/16] Loss: 0.34595  focal_loss 0.09249  dice_loss 0.25345 
Epoch [106/300] Validation [6/16] Loss: 0.30053  focal_loss 0.07644  dice_loss 0.22409 
Epoch [106/300] Validation [7/16] Loss: 0.28343  focal_loss 0.07456  dice_loss 0.20887 
Epoch [106/300] Validation [8/16] Loss: 0.30911  focal_loss 0.06355  dice_loss 0.24555 
Epoch [106/300] Validation [9/16] Loss: 0.38926  focal_loss 0.11752  dice_loss 0.27174 
Epoch [106/300] Validation [10/16] Loss: 0.26202  focal_loss 0.05755  dice_loss 0.20447 
Epoch [106/300] Validation [11/16] Loss: 0.11960  focal_loss 0.02235  dice_loss 0.09725 
Epoch [106/300] Validation [12/16] Loss: 0.38446  focal_loss 0.07788  dice_loss 0.30658 
Epoch [106/300] Validation [13/16] Loss: 0.26621  focal_loss 0.07834  dice_loss 0.18788 
Epoch [106/300] Validation [14/16] Loss: 0.46465  focal_loss 0.13011  dice_loss 0.33454 
Epoch [106/300] Validation [15/16] Loss: 0.24916  focal_loss 0.07098  dice_loss 0.17818 
Epoch [106/300] Validation [16/16] Loss: 0.07780  focal_loss 0.01247  dice_loss 0.06532 
Epoch [106/300] Validation metric {'Val/mean dice_metric': 0.8669337630271912, 'Val/mean miou_metric': 0.790194571018219, 'Val/mean f1': 0.8774185180664062, 'Val/mean precision': 0.8740614056587219, 'Val/mean recall': 0.8808014392852783, 'Val/mean hd95_metric': 29.276216506958008}
Cheakpoint...
Epoch [106/300] best acc:tensor([0.8669], device='cuda:0'), Now : mean acc: tensor([0.8669], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8669337630271912, 'Val/mean miou_metric': 0.790194571018219, 'Val/mean f1': 0.8774185180664062, 'Val/mean precision': 0.8740614056587219, 'Val/mean recall': 0.8808014392852783, 'Val/mean hd95_metric': 29.276216506958008}
Epoch [107/300] Training [1/62] Loss: 0.22137 
Epoch [107/300] Training [2/62] Loss: 0.19350 
Epoch [107/300] Training [3/62] Loss: 0.10527 
Epoch [107/300] Training [4/62] Loss: 0.12288 
Epoch [107/300] Training [5/62] Loss: 0.12639 
Epoch [107/300] Training [6/62] Loss: 0.15899 
Epoch [107/300] Training [7/62] Loss: 0.12613 
Epoch [107/300] Training [8/62] Loss: 0.06060 
Epoch [107/300] Training [9/62] Loss: 0.14542 
Epoch [107/300] Training [10/62] Loss: 0.16050 
Epoch [107/300] Training [11/62] Loss: 0.19740 
Epoch [107/300] Training [12/62] Loss: 0.17987 
Epoch [107/300] Training [13/62] Loss: 0.13316 
Epoch [107/300] Training [14/62] Loss: 0.16813 
Epoch [107/300] Training [15/62] Loss: 0.18878 
Epoch [107/300] Training [16/62] Loss: 0.19838 
Epoch [107/300] Training [17/62] Loss: 0.11548 
Epoch [107/300] Training [18/62] Loss: 0.26372 
Epoch [107/300] Training [19/62] Loss: 0.13650 
Epoch [107/300] Training [20/62] Loss: 0.15857 
Epoch [107/300] Training [21/62] Loss: 0.09332 
Epoch [107/300] Training [22/62] Loss: 0.19104 
Epoch [107/300] Training [23/62] Loss: 0.14844 
Epoch [107/300] Training [24/62] Loss: 0.23120 
Epoch [107/300] Training [25/62] Loss: 0.17434 
Epoch [107/300] Training [26/62] Loss: 0.10222 
Epoch [107/300] Training [27/62] Loss: 0.10208 
Epoch [107/300] Training [28/62] Loss: 0.10903 
Epoch [107/300] Training [29/62] Loss: 0.34463 
Epoch [107/300] Training [30/62] Loss: 0.14408 
Epoch [107/300] Training [31/62] Loss: 0.13552 
Epoch [107/300] Training [32/62] Loss: 0.13993 
Epoch [107/300] Training [33/62] Loss: 0.12328 
Epoch [107/300] Training [34/62] Loss: 0.12801 
Epoch [107/300] Training [35/62] Loss: 0.10447 
Epoch [107/300] Training [36/62] Loss: 0.14231 
Epoch [107/300] Training [37/62] Loss: 0.12824 
Epoch [107/300] Training [38/62] Loss: 0.15365 
Epoch [107/300] Training [39/62] Loss: 0.18837 
Epoch [107/300] Training [40/62] Loss: 0.26393 
Epoch [107/300] Training [41/62] Loss: 0.18595 
Epoch [107/300] Training [42/62] Loss: 0.14789 
Epoch [107/300] Training [43/62] Loss: 0.12112 
Epoch [107/300] Training [44/62] Loss: 0.10384 
Epoch [107/300] Training [45/62] Loss: 0.11959 
Epoch [107/300] Training [46/62] Loss: 0.10724 
Epoch [107/300] Training [47/62] Loss: 0.13572 
Epoch [107/300] Training [48/62] Loss: 0.20982 
Epoch [107/300] Training [49/62] Loss: 0.31358 
Epoch [107/300] Training [50/62] Loss: 0.13852 
Epoch [107/300] Training [51/62] Loss: 0.14155 
Epoch [107/300] Training [52/62] Loss: 0.25381 
Epoch [107/300] Training [53/62] Loss: 0.14255 
Epoch [107/300] Training [54/62] Loss: 0.22318 
Epoch [107/300] Training [55/62] Loss: 0.14660 
Epoch [107/300] Training [56/62] Loss: 0.14521 
Epoch [107/300] Training [57/62] Loss: 0.09046 
Epoch [107/300] Training [58/62] Loss: 0.11921 
Epoch [107/300] Training [59/62] Loss: 0.15565 
Epoch [107/300] Training [60/62] Loss: 0.21269 
Epoch [107/300] Training [61/62] Loss: 0.19488 
Epoch [107/300] Training [62/62] Loss: 0.12046 
Epoch [107/300] Training metric {'Train/mean dice_metric': 0.8923459053039551, 'Train/mean miou_metric': 0.8218063116073608, 'Train/mean f1': 0.9035422801971436, 'Train/mean precision': 0.8949288129806519, 'Train/mean recall': 0.9123231172561646, 'Train/mean hd95_metric': 23.123018264770508}
Epoch [107/300] Validation [1/16] Loss: 0.10850  focal_loss 0.03483  dice_loss 0.07367 
Epoch [107/300] Validation [2/16] Loss: 0.40249  focal_loss 0.12350  dice_loss 0.27899 
Epoch [107/300] Validation [3/16] Loss: 0.59939  focal_loss 0.32665  dice_loss 0.27274 
Epoch [107/300] Validation [4/16] Loss: 0.31839  focal_loss 0.12730  dice_loss 0.19109 
Epoch [107/300] Validation [5/16] Loss: 0.32788  focal_loss 0.06789  dice_loss 0.25999 
Epoch [107/300] Validation [6/16] Loss: 0.23510  focal_loss 0.05100  dice_loss 0.18411 
Epoch [107/300] Validation [7/16] Loss: 0.23253  focal_loss 0.08768  dice_loss 0.14485 
Epoch [107/300] Validation [8/16] Loss: 0.49109  focal_loss 0.16077  dice_loss 0.33032 
Epoch [107/300] Validation [9/16] Loss: 0.18683  focal_loss 0.04547  dice_loss 0.14136 
Epoch [107/300] Validation [10/16] Loss: 0.66442  focal_loss 0.25599  dice_loss 0.40843 
Epoch [107/300] Validation [11/16] Loss: 0.14705  focal_loss 0.03514  dice_loss 0.11191 
Epoch [107/300] Validation [12/16] Loss: 0.39330  focal_loss 0.11849  dice_loss 0.27481 
Epoch [107/300] Validation [13/16] Loss: 0.31746  focal_loss 0.08727  dice_loss 0.23019 
Epoch [107/300] Validation [14/16] Loss: 0.54990  focal_loss 0.17337  dice_loss 0.37653 
Epoch [107/300] Validation [15/16] Loss: 0.15296  focal_loss 0.04185  dice_loss 0.11111 
Epoch [107/300] Validation [16/16] Loss: 0.09863  focal_loss 0.03241  dice_loss 0.06622 
Epoch [107/300] Validation metric {'Val/mean dice_metric': 0.8721461892127991, 'Val/mean miou_metric': 0.7982860803604126, 'Val/mean f1': 0.8813257813453674, 'Val/mean precision': 0.8598765134811401, 'Val/mean recall': 0.903872549533844, 'Val/mean hd95_metric': 29.028030395507812}
Cheakpoint...
Epoch [107/300] best acc:tensor([0.8721], device='cuda:0'), Now : mean acc: tensor([0.8721], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8721461892127991, 'Val/mean miou_metric': 0.7982860803604126, 'Val/mean f1': 0.8813257813453674, 'Val/mean precision': 0.8598765134811401, 'Val/mean recall': 0.903872549533844, 'Val/mean hd95_metric': 29.028030395507812}
Epoch [108/300] Training [1/62] Loss: 0.16874 
Epoch [108/300] Training [2/62] Loss: 0.15258 
Epoch [108/300] Training [3/62] Loss: 0.14188 
Epoch [108/300] Training [4/62] Loss: 0.25775 
Epoch [108/300] Training [5/62] Loss: 0.13370 
Epoch [108/300] Training [6/62] Loss: 0.23845 
Epoch [108/300] Training [7/62] Loss: 0.26116 
Epoch [108/300] Training [8/62] Loss: 0.18751 
Epoch [108/300] Training [9/62] Loss: 0.26666 
Epoch [108/300] Training [10/62] Loss: 0.09103 
Epoch [108/300] Training [11/62] Loss: 0.14333 
Epoch [108/300] Training [12/62] Loss: 0.35648 
Epoch [108/300] Training [13/62] Loss: 0.18661 
Epoch [108/300] Training [14/62] Loss: 0.07112 
Epoch [108/300] Training [15/62] Loss: 0.14135 
Epoch [108/300] Training [16/62] Loss: 0.09295 
Epoch [108/300] Training [17/62] Loss: 0.29932 
Epoch [108/300] Training [18/62] Loss: 0.08727 
Epoch [108/300] Training [19/62] Loss: 0.06993 
Epoch [108/300] Training [20/62] Loss: 0.15768 
Epoch [108/300] Training [21/62] Loss: 0.09761 
Epoch [108/300] Training [22/62] Loss: 0.16712 
Epoch [108/300] Training [23/62] Loss: 0.21372 
Epoch [108/300] Training [24/62] Loss: 0.11701 
Epoch [108/300] Training [25/62] Loss: 0.19468 
Epoch [108/300] Training [26/62] Loss: 0.20025 
Epoch [108/300] Training [27/62] Loss: 0.15718 
Epoch [108/300] Training [28/62] Loss: 0.13531 
Epoch [108/300] Training [29/62] Loss: 0.19619 
Epoch [108/300] Training [30/62] Loss: 0.12129 
Epoch [108/300] Training [31/62] Loss: 0.10828 
Epoch [108/300] Training [32/62] Loss: 0.25095 
Epoch [108/300] Training [33/62] Loss: 0.19415 
Epoch [108/300] Training [34/62] Loss: 0.14635 
Epoch [108/300] Training [35/62] Loss: 0.12787 
Epoch [108/300] Training [36/62] Loss: 0.14351 
Epoch [108/300] Training [37/62] Loss: 0.10924 
Epoch [108/300] Training [38/62] Loss: 0.14441 
Epoch [108/300] Training [39/62] Loss: 0.09808 
Epoch [108/300] Training [40/62] Loss: 0.25843 
Epoch [108/300] Training [41/62] Loss: 0.11110 
Epoch [108/300] Training [42/62] Loss: 0.13720 
Epoch [108/300] Training [43/62] Loss: 0.14672 
Epoch [108/300] Training [44/62] Loss: 0.12296 
Epoch [108/300] Training [45/62] Loss: 0.16355 
Epoch [108/300] Training [46/62] Loss: 0.11941 
Epoch [108/300] Training [47/62] Loss: 0.15349 
Epoch [108/300] Training [48/62] Loss: 0.18071 
Epoch [108/300] Training [49/62] Loss: 0.20935 
Epoch [108/300] Training [50/62] Loss: 0.10523 
Epoch [108/300] Training [51/62] Loss: 0.10836 
Epoch [108/300] Training [52/62] Loss: 0.15028 
Epoch [108/300] Training [53/62] Loss: 0.24397 
Epoch [108/300] Training [54/62] Loss: 0.24341 
Epoch [108/300] Training [55/62] Loss: 0.14463 
Epoch [108/300] Training [56/62] Loss: 0.26561 
Epoch [108/300] Training [57/62] Loss: 0.23734 
Epoch [108/300] Training [58/62] Loss: 0.11000 
Epoch [108/300] Training [59/62] Loss: 0.21089 
Epoch [108/300] Training [60/62] Loss: 0.15753 
Epoch [108/300] Training [61/62] Loss: 0.15021 
Epoch [108/300] Training [62/62] Loss: 0.12023 
Epoch [108/300] Training metric {'Train/mean dice_metric': 0.8843856453895569, 'Train/mean miou_metric': 0.8129612803459167, 'Train/mean f1': 0.9058300256729126, 'Train/mean precision': 0.8995962738990784, 'Train/mean recall': 0.9121509790420532, 'Train/mean hd95_metric': 22.68842315673828}
Epoch [108/300] Validation [1/16] Loss: 0.34787  focal_loss 0.18640  dice_loss 0.16147 
Epoch [108/300] Validation [2/16] Loss: 0.28538  focal_loss 0.05380  dice_loss 0.23158 
Epoch [108/300] Validation [3/16] Loss: 0.53958  focal_loss 0.22772  dice_loss 0.31185 
Epoch [108/300] Validation [4/16] Loss: 0.26955  focal_loss 0.08816  dice_loss 0.18139 
Epoch [108/300] Validation [5/16] Loss: 0.38300  focal_loss 0.10923  dice_loss 0.27378 
Epoch [108/300] Validation [6/16] Loss: 0.36998  focal_loss 0.09653  dice_loss 0.27345 
Epoch [108/300] Validation [7/16] Loss: 0.24116  focal_loss 0.06382  dice_loss 0.17734 
Epoch [108/300] Validation [8/16] Loss: 0.30082  focal_loss 0.05015  dice_loss 0.25068 
Epoch [108/300] Validation [9/16] Loss: 0.48391  focal_loss 0.18724  dice_loss 0.29667 
Epoch [108/300] Validation [10/16] Loss: 0.39966  focal_loss 0.12328  dice_loss 0.27637 
Epoch [108/300] Validation [11/16] Loss: 0.21100  focal_loss 0.05035  dice_loss 0.16065 
Epoch [108/300] Validation [12/16] Loss: 0.35805  focal_loss 0.06820  dice_loss 0.28985 
Epoch [108/300] Validation [13/16] Loss: 0.35001  focal_loss 0.08597  dice_loss 0.26404 
Epoch [108/300] Validation [14/16] Loss: 0.64490  focal_loss 0.19785  dice_loss 0.44706 
Epoch [108/300] Validation [15/16] Loss: 0.21734  focal_loss 0.05896  dice_loss 0.15838 
Epoch [108/300] Validation [16/16] Loss: 0.07783  focal_loss 0.01323  dice_loss 0.06461 
Epoch [108/300] Validation metric {'Val/mean dice_metric': 0.8614546060562134, 'Val/mean miou_metric': 0.7861254215240479, 'Val/mean f1': 0.8785861730575562, 'Val/mean precision': 0.8692496418952942, 'Val/mean recall': 0.8881253004074097, 'Val/mean hd95_metric': 28.383163452148438}
Cheakpoint...
Epoch [108/300] best acc:tensor([0.8721], device='cuda:0'), Now : mean acc: tensor([0.8615], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8614546060562134, 'Val/mean miou_metric': 0.7861254215240479, 'Val/mean f1': 0.8785861730575562, 'Val/mean precision': 0.8692496418952942, 'Val/mean recall': 0.8881253004074097, 'Val/mean hd95_metric': 28.383163452148438}
Epoch [109/300] Training [1/62] Loss: 0.25608 
Epoch [109/300] Training [2/62] Loss: 0.16617 
Epoch [109/300] Training [3/62] Loss: 0.09085 
Epoch [109/300] Training [4/62] Loss: 0.29982 
Epoch [109/300] Training [5/62] Loss: 0.11644 
Epoch [109/300] Training [6/62] Loss: 0.12425 
Epoch [109/300] Training [7/62] Loss: 0.12555 
Epoch [109/300] Training [8/62] Loss: 0.10135 
Epoch [109/300] Training [9/62] Loss: 0.07663 
Epoch [109/300] Training [10/62] Loss: 0.16511 
Epoch [109/300] Training [11/62] Loss: 0.21963 
Epoch [109/300] Training [12/62] Loss: 0.12471 
Epoch [109/300] Training [13/62] Loss: 0.14049 
Epoch [109/300] Training [14/62] Loss: 0.15438 
Epoch [109/300] Training [15/62] Loss: 0.08375 
Epoch [109/300] Training [16/62] Loss: 0.09198 
Epoch [109/300] Training [17/62] Loss: 0.09651 
Epoch [109/300] Training [18/62] Loss: 0.19286 
Epoch [109/300] Training [19/62] Loss: 0.09139 
Epoch [109/300] Training [20/62] Loss: 0.12564 
Epoch [109/300] Training [21/62] Loss: 0.08246 
Epoch [109/300] Training [22/62] Loss: 0.24530 
Epoch [109/300] Training [23/62] Loss: 0.17701 
Epoch [109/300] Training [24/62] Loss: 0.13895 
Epoch [109/300] Training [25/62] Loss: 0.12957 
Epoch [109/300] Training [26/62] Loss: 0.14318 
Epoch [109/300] Training [27/62] Loss: 0.23242 
Epoch [109/300] Training [28/62] Loss: 0.24057 
Epoch [109/300] Training [29/62] Loss: 0.25553 
Epoch [109/300] Training [30/62] Loss: 0.15194 
Epoch [109/300] Training [31/62] Loss: 0.23653 
Epoch [109/300] Training [32/62] Loss: 0.28403 
Epoch [109/300] Training [33/62] Loss: 0.13753 
Epoch [109/300] Training [34/62] Loss: 0.11059 
Epoch [109/300] Training [35/62] Loss: 0.16679 
Epoch [109/300] Training [36/62] Loss: 0.30689 
Epoch [109/300] Training [37/62] Loss: 0.29531 
Epoch [109/300] Training [38/62] Loss: 0.24171 
Epoch [109/300] Training [39/62] Loss: 0.14174 
Epoch [109/300] Training [40/62] Loss: 0.29761 
Epoch [109/300] Training [41/62] Loss: 0.17786 
Epoch [109/300] Training [42/62] Loss: 0.15725 
Epoch [109/300] Training [43/62] Loss: 0.30640 
Epoch [109/300] Training [44/62] Loss: 0.18989 
Epoch [109/300] Training [45/62] Loss: 0.29077 
Epoch [109/300] Training [46/62] Loss: 0.17265 
Epoch [109/300] Training [47/62] Loss: 0.13902 
Epoch [109/300] Training [48/62] Loss: 0.18084 
Epoch [109/300] Training [49/62] Loss: 0.10003 
Epoch [109/300] Training [50/62] Loss: 0.24699 
Epoch [109/300] Training [51/62] Loss: 0.21713 
Epoch [109/300] Training [52/62] Loss: 0.18348 
Epoch [109/300] Training [53/62] Loss: 0.08932 
Epoch [109/300] Training [54/62] Loss: 0.14538 
Epoch [109/300] Training [55/62] Loss: 0.20794 
Epoch [109/300] Training [56/62] Loss: 0.16216 
Epoch [109/300] Training [57/62] Loss: 0.11344 
Epoch [109/300] Training [58/62] Loss: 0.18903 
Epoch [109/300] Training [59/62] Loss: 0.12754 
Epoch [109/300] Training [60/62] Loss: 0.16327 
Epoch [109/300] Training [61/62] Loss: 0.20982 
Epoch [109/300] Training [62/62] Loss: 0.06185 
Epoch [109/300] Training metric {'Train/mean dice_metric': 0.8814115524291992, 'Train/mean miou_metric': 0.8084145784378052, 'Train/mean f1': 0.8965869545936584, 'Train/mean precision': 0.8932819962501526, 'Train/mean recall': 0.8999165296554565, 'Train/mean hd95_metric': 23.76426887512207}
Epoch [109/300] Validation [1/16] Loss: 0.16746  focal_loss 0.06559  dice_loss 0.10188 
Epoch [109/300] Validation [2/16] Loss: 0.27554  focal_loss 0.06873  dice_loss 0.20680 
Epoch [109/300] Validation [3/16] Loss: 0.58164  focal_loss 0.24577  dice_loss 0.33588 
Epoch [109/300] Validation [4/16] Loss: 0.25397  focal_loss 0.07819  dice_loss 0.17578 
Epoch [109/300] Validation [5/16] Loss: 0.36494  focal_loss 0.10079  dice_loss 0.26415 
Epoch [109/300] Validation [6/16] Loss: 0.21762  focal_loss 0.04079  dice_loss 0.17683 
Epoch [109/300] Validation [7/16] Loss: 0.22117  focal_loss 0.06270  dice_loss 0.15847 
Epoch [109/300] Validation [8/16] Loss: 0.35060  focal_loss 0.10236  dice_loss 0.24824 
Epoch [109/300] Validation [9/16] Loss: 0.35308  focal_loss 0.13709  dice_loss 0.21599 
Epoch [109/300] Validation [10/16] Loss: 0.37994  focal_loss 0.12546  dice_loss 0.25448 
Epoch [109/300] Validation [11/16] Loss: 0.15836  focal_loss 0.03510  dice_loss 0.12326 
Epoch [109/300] Validation [12/16] Loss: 0.30722  focal_loss 0.06433  dice_loss 0.24289 
Epoch [109/300] Validation [13/16] Loss: 0.45550  focal_loss 0.13061  dice_loss 0.32490 
Epoch [109/300] Validation [14/16] Loss: 0.51481  focal_loss 0.14498  dice_loss 0.36983 
Epoch [109/300] Validation [15/16] Loss: 0.21275  focal_loss 0.06871  dice_loss 0.14404 
Epoch [109/300] Validation [16/16] Loss: 0.07464  focal_loss 0.02174  dice_loss 0.05290 
Epoch [109/300] Validation metric {'Val/mean dice_metric': 0.8635419607162476, 'Val/mean miou_metric': 0.7885236740112305, 'Val/mean f1': 0.8780291080474854, 'Val/mean precision': 0.8717392683029175, 'Val/mean recall': 0.8844102621078491, 'Val/mean hd95_metric': 28.644582748413086}
Cheakpoint...
Epoch [109/300] best acc:tensor([0.8721], device='cuda:0'), Now : mean acc: tensor([0.8635], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8635419607162476, 'Val/mean miou_metric': 0.7885236740112305, 'Val/mean f1': 0.8780291080474854, 'Val/mean precision': 0.8717392683029175, 'Val/mean recall': 0.8844102621078491, 'Val/mean hd95_metric': 28.644582748413086}
Epoch [110/300] Training [1/62] Loss: 0.20030 
Epoch [110/300] Training [2/62] Loss: 0.20196 
Epoch [110/300] Training [3/62] Loss: 0.23678 
Epoch [110/300] Training [4/62] Loss: 0.21335 
Epoch [110/300] Training [5/62] Loss: 0.14879 
Epoch [110/300] Training [6/62] Loss: 0.18603 
Epoch [110/300] Training [7/62] Loss: 0.13269 
Epoch [110/300] Training [8/62] Loss: 0.16498 
Epoch [110/300] Training [9/62] Loss: 0.24188 
Epoch [110/300] Training [10/62] Loss: 0.18450 
Epoch [110/300] Training [11/62] Loss: 0.29204 
Epoch [110/300] Training [12/62] Loss: 0.09528 
Epoch [110/300] Training [13/62] Loss: 0.26193 
Epoch [110/300] Training [14/62] Loss: 0.15505 
Epoch [110/300] Training [15/62] Loss: 0.09835 
Epoch [110/300] Training [16/62] Loss: 0.12097 
Epoch [110/300] Training [17/62] Loss: 0.15845 
Epoch [110/300] Training [18/62] Loss: 0.08017 
Epoch [110/300] Training [19/62] Loss: 0.09106 
Epoch [110/300] Training [20/62] Loss: 0.08369 
Epoch [110/300] Training [21/62] Loss: 0.19620 
Epoch [110/300] Training [22/62] Loss: 0.09444 
Epoch [110/300] Training [23/62] Loss: 0.26688 
Epoch [110/300] Training [24/62] Loss: 0.09627 
Epoch [110/300] Training [25/62] Loss: 0.11377 
Epoch [110/300] Training [26/62] Loss: 0.10628 
Epoch [110/300] Training [27/62] Loss: 0.20097 
Epoch [110/300] Training [28/62] Loss: 0.14839 
Epoch [110/300] Training [29/62] Loss: 0.13239 
Epoch [110/300] Training [30/62] Loss: 0.12728 
Epoch [110/300] Training [31/62] Loss: 0.18360 
Epoch [110/300] Training [32/62] Loss: 0.07299 
Epoch [110/300] Training [33/62] Loss: 0.13329 
Epoch [110/300] Training [34/62] Loss: 0.22397 
Epoch [110/300] Training [35/62] Loss: 0.11136 
Epoch [110/300] Training [36/62] Loss: 0.20225 
Epoch [110/300] Training [37/62] Loss: 0.13434 
Epoch [110/300] Training [38/62] Loss: 0.14664 
Epoch [110/300] Training [39/62] Loss: 0.08431 
Epoch [110/300] Training [40/62] Loss: 0.21971 
Epoch [110/300] Training [41/62] Loss: 0.12088 
Epoch [110/300] Training [42/62] Loss: 0.12614 
Epoch [110/300] Training [43/62] Loss: 0.10271 
Epoch [110/300] Training [44/62] Loss: 0.11743 
Epoch [110/300] Training [45/62] Loss: 0.26022 
Epoch [110/300] Training [46/62] Loss: 0.10494 
Epoch [110/300] Training [47/62] Loss: 0.18412 
Epoch [110/300] Training [48/62] Loss: 0.15127 
Epoch [110/300] Training [49/62] Loss: 0.09039 
Epoch [110/300] Training [50/62] Loss: 0.30049 
Epoch [110/300] Training [51/62] Loss: 0.19255 
Epoch [110/300] Training [52/62] Loss: 0.16653 
Epoch [110/300] Training [53/62] Loss: 0.20570 
Epoch [110/300] Training [54/62] Loss: 0.10692 
Epoch [110/300] Training [55/62] Loss: 0.11273 
Epoch [110/300] Training [56/62] Loss: 0.12757 
Epoch [110/300] Training [57/62] Loss: 0.07840 
Epoch [110/300] Training [58/62] Loss: 0.16621 
Epoch [110/300] Training [59/62] Loss: 0.15218 
Epoch [110/300] Training [60/62] Loss: 0.18129 
Epoch [110/300] Training [61/62] Loss: 0.16240 
Epoch [110/300] Training [62/62] Loss: 0.07160 
Epoch [110/300] Training metric {'Train/mean dice_metric': 0.8925947546958923, 'Train/mean miou_metric': 0.8232678771018982, 'Train/mean f1': 0.9066555500030518, 'Train/mean precision': 0.8987953066825867, 'Train/mean recall': 0.9146544337272644, 'Train/mean hd95_metric': 21.89032554626465}
Epoch [110/300] Validation [1/16] Loss: 0.25931  focal_loss 0.10296  dice_loss 0.15635 
Epoch [110/300] Validation [2/16] Loss: 0.46493  focal_loss 0.14418  dice_loss 0.32074 
Epoch [110/300] Validation [3/16] Loss: 0.81088  focal_loss 0.44285  dice_loss 0.36804 
Epoch [110/300] Validation [4/16] Loss: 0.33339  focal_loss 0.13347  dice_loss 0.19992 
Epoch [110/300] Validation [5/16] Loss: 0.30940  focal_loss 0.08938  dice_loss 0.22002 
Epoch [110/300] Validation [6/16] Loss: 0.35139  focal_loss 0.12211  dice_loss 0.22928 
Epoch [110/300] Validation [7/16] Loss: 0.27357  focal_loss 0.09856  dice_loss 0.17501 
Epoch [110/300] Validation [8/16] Loss: 0.39419  focal_loss 0.09610  dice_loss 0.29809 
Epoch [110/300] Validation [9/16] Loss: 0.21916  focal_loss 0.06470  dice_loss 0.15446 
Epoch [110/300] Validation [10/16] Loss: 0.37877  focal_loss 0.10494  dice_loss 0.27383 
Epoch [110/300] Validation [11/16] Loss: 0.23547  focal_loss 0.04804  dice_loss 0.18743 
Epoch [110/300] Validation [12/16] Loss: 0.40512  focal_loss 0.09291  dice_loss 0.31222 
Epoch [110/300] Validation [13/16] Loss: 0.36911  focal_loss 0.13154  dice_loss 0.23757 
Epoch [110/300] Validation [14/16] Loss: 0.61506  focal_loss 0.18597  dice_loss 0.42909 
Epoch [110/300] Validation [15/16] Loss: 0.21209  focal_loss 0.07119  dice_loss 0.14091 
Epoch [110/300] Validation [16/16] Loss: 0.08442  focal_loss 0.01985  dice_loss 0.06457 
Epoch [110/300] Validation metric {'Val/mean dice_metric': 0.8682966828346252, 'Val/mean miou_metric': 0.7950146794319153, 'Val/mean f1': 0.8800849914550781, 'Val/mean precision': 0.8784347176551819, 'Val/mean recall': 0.8817414045333862, 'Val/mean hd95_metric': 28.36117172241211}
Cheakpoint...
Epoch [110/300] best acc:tensor([0.8721], device='cuda:0'), Now : mean acc: tensor([0.8683], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8682966828346252, 'Val/mean miou_metric': 0.7950146794319153, 'Val/mean f1': 0.8800849914550781, 'Val/mean precision': 0.8784347176551819, 'Val/mean recall': 0.8817414045333862, 'Val/mean hd95_metric': 28.36117172241211}
Epoch [111/300] Training [1/62] Loss: 0.21301 
Epoch [111/300] Training [2/62] Loss: 0.17335 
Epoch [111/300] Training [3/62] Loss: 0.18447 
Epoch [111/300] Training [4/62] Loss: 0.17663 
Epoch [111/300] Training [5/62] Loss: 0.13827 
Epoch [111/300] Training [6/62] Loss: 0.08683 
Epoch [111/300] Training [7/62] Loss: 0.13565 
Epoch [111/300] Training [8/62] Loss: 0.10710 
Epoch [111/300] Training [9/62] Loss: 0.15447 
Epoch [111/300] Training [10/62] Loss: 0.13428 
Epoch [111/300] Training [11/62] Loss: 0.21066 
Epoch [111/300] Training [12/62] Loss: 0.06585 
Epoch [111/300] Training [13/62] Loss: 0.11233 
Epoch [111/300] Training [14/62] Loss: 0.13012 
Epoch [111/300] Training [15/62] Loss: 0.27737 
Epoch [111/300] Training [16/62] Loss: 0.20021 
Epoch [111/300] Training [17/62] Loss: 0.11284 
Epoch [111/300] Training [18/62] Loss: 0.18401 
Epoch [111/300] Training [19/62] Loss: 0.08540 
Epoch [111/300] Training [20/62] Loss: 0.18408 
Epoch [111/300] Training [21/62] Loss: 0.07348 
Epoch [111/300] Training [22/62] Loss: 0.19117 
Epoch [111/300] Training [23/62] Loss: 0.28186 
Epoch [111/300] Training [24/62] Loss: 0.14862 
Epoch [111/300] Training [25/62] Loss: 0.16298 
Epoch [111/300] Training [26/62] Loss: 0.18142 
Epoch [111/300] Training [27/62] Loss: 0.08087 
Epoch [111/300] Training [28/62] Loss: 0.11696 
Epoch [111/300] Training [29/62] Loss: 0.19712 
Epoch [111/300] Training [30/62] Loss: 0.23170 
Epoch [111/300] Training [31/62] Loss: 0.14571 
Epoch [111/300] Training [32/62] Loss: 0.17045 
Epoch [111/300] Training [33/62] Loss: 0.18583 
Epoch [111/300] Training [34/62] Loss: 0.17140 
Epoch [111/300] Training [35/62] Loss: 0.12009 
Epoch [111/300] Training [36/62] Loss: 0.14326 
Epoch [111/300] Training [37/62] Loss: 0.18658 
Epoch [111/300] Training [38/62] Loss: 0.20042 
Epoch [111/300] Training [39/62] Loss: 0.09296 
Epoch [111/300] Training [40/62] Loss: 0.12792 
Epoch [111/300] Training [41/62] Loss: 0.10115 
Epoch [111/300] Training [42/62] Loss: 0.26631 
Epoch [111/300] Training [43/62] Loss: 0.27555 
Epoch [111/300] Training [44/62] Loss: 0.18761 
Epoch [111/300] Training [45/62] Loss: 0.40920 
Epoch [111/300] Training [46/62] Loss: 0.20577 
Epoch [111/300] Training [47/62] Loss: 0.16508 
Epoch [111/300] Training [48/62] Loss: 0.14356 
Epoch [111/300] Training [49/62] Loss: 0.12312 
Epoch [111/300] Training [50/62] Loss: 0.09789 
Epoch [111/300] Training [51/62] Loss: 0.27430 
Epoch [111/300] Training [52/62] Loss: 0.15993 
Epoch [111/300] Training [53/62] Loss: 0.14768 
Epoch [111/300] Training [54/62] Loss: 0.20142 
Epoch [111/300] Training [55/62] Loss: 0.18688 
Epoch [111/300] Training [56/62] Loss: 0.09150 
Epoch [111/300] Training [57/62] Loss: 0.17272 
Epoch [111/300] Training [58/62] Loss: 0.13340 
Epoch [111/300] Training [59/62] Loss: 0.12008 
Epoch [111/300] Training [60/62] Loss: 0.37373 
Epoch [111/300] Training [61/62] Loss: 0.16532 
Epoch [111/300] Training [62/62] Loss: 0.20218 
Epoch [111/300] Training metric {'Train/mean dice_metric': 0.8852465748786926, 'Train/mean miou_metric': 0.8122191429138184, 'Train/mean f1': 0.8960127830505371, 'Train/mean precision': 0.8904996514320374, 'Train/mean recall': 0.9015945196151733, 'Train/mean hd95_metric': 24.474550247192383}
Epoch [111/300] Validation [1/16] Loss: 0.13278  focal_loss 0.03808  dice_loss 0.09470 
Epoch [111/300] Validation [2/16] Loss: 0.32827  focal_loss 0.10345  dice_loss 0.22482 
Epoch [111/300] Validation [3/16] Loss: 0.61015  focal_loss 0.31039  dice_loss 0.29976 
Epoch [111/300] Validation [4/16] Loss: 0.38523  focal_loss 0.14840  dice_loss 0.23683 
Epoch [111/300] Validation [5/16] Loss: 0.50148  focal_loss 0.12870  dice_loss 0.37279 
Epoch [111/300] Validation [6/16] Loss: 0.25836  focal_loss 0.05179  dice_loss 0.20657 
Epoch [111/300] Validation [7/16] Loss: 0.40470  focal_loss 0.13033  dice_loss 0.27437 
Epoch [111/300] Validation [8/16] Loss: 0.41032  focal_loss 0.14810  dice_loss 0.26222 
Epoch [111/300] Validation [9/16] Loss: 0.31301  focal_loss 0.09094  dice_loss 0.22207 
Epoch [111/300] Validation [10/16] Loss: 0.32720  focal_loss 0.11544  dice_loss 0.21177 
Epoch [111/300] Validation [11/16] Loss: 0.25346  focal_loss 0.06730  dice_loss 0.18616 
Epoch [111/300] Validation [12/16] Loss: 0.50417  focal_loss 0.16458  dice_loss 0.33959 
Epoch [111/300] Validation [13/16] Loss: 0.38523  focal_loss 0.12720  dice_loss 0.25803 
Epoch [111/300] Validation [14/16] Loss: 0.55838  focal_loss 0.18835  dice_loss 0.37002 
Epoch [111/300] Validation [15/16] Loss: 0.26880  focal_loss 0.11298  dice_loss 0.15582 
Epoch [111/300] Validation [16/16] Loss: 0.11408  focal_loss 0.03138  dice_loss 0.08270 
Epoch [111/300] Validation metric {'Val/mean dice_metric': 0.8618764281272888, 'Val/mean miou_metric': 0.7855985760688782, 'Val/mean f1': 0.8719135522842407, 'Val/mean precision': 0.8608792424201965, 'Val/mean recall': 0.8832345604896545, 'Val/mean hd95_metric': 29.70563316345215}
Cheakpoint...
Epoch [111/300] best acc:tensor([0.8721], device='cuda:0'), Now : mean acc: tensor([0.8619], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8618764281272888, 'Val/mean miou_metric': 0.7855985760688782, 'Val/mean f1': 0.8719135522842407, 'Val/mean precision': 0.8608792424201965, 'Val/mean recall': 0.8832345604896545, 'Val/mean hd95_metric': 29.70563316345215}
Epoch [112/300] Training [1/62] Loss: 0.12170 
Epoch [112/300] Training [2/62] Loss: 0.13044 
Epoch [112/300] Training [3/62] Loss: 0.22299 
Epoch [112/300] Training [4/62] Loss: 0.35873 
Epoch [112/300] Training [5/62] Loss: 0.11879 
Epoch [112/300] Training [6/62] Loss: 0.20869 
Epoch [112/300] Training [7/62] Loss: 0.15729 
Epoch [112/300] Training [8/62] Loss: 0.13971 
Epoch [112/300] Training [9/62] Loss: 0.17144 
Epoch [112/300] Training [10/62] Loss: 0.18391 
Epoch [112/300] Training [11/62] Loss: 0.14798 
Epoch [112/300] Training [12/62] Loss: 0.23730 
Epoch [112/300] Training [13/62] Loss: 0.12146 
Epoch [112/300] Training [14/62] Loss: 0.20458 
Epoch [112/300] Training [15/62] Loss: 0.24028 
Epoch [112/300] Training [16/62] Loss: 0.14011 
Epoch [112/300] Training [17/62] Loss: 0.13303 
Epoch [112/300] Training [18/62] Loss: 0.14895 
Epoch [112/300] Training [19/62] Loss: 0.11044 
Epoch [112/300] Training [20/62] Loss: 0.18388 
Epoch [112/300] Training [21/62] Loss: 0.09854 
Epoch [112/300] Training [22/62] Loss: 0.13364 
Epoch [112/300] Training [23/62] Loss: 0.11373 
Epoch [112/300] Training [24/62] Loss: 0.18734 
Epoch [112/300] Training [25/62] Loss: 0.13695 
Epoch [112/300] Training [26/62] Loss: 0.21197 
Epoch [112/300] Training [27/62] Loss: 0.12926 
Epoch [112/300] Training [28/62] Loss: 0.14467 
Epoch [112/300] Training [29/62] Loss: 0.11539 
Epoch [112/300] Training [30/62] Loss: 0.24522 
Epoch [112/300] Training [31/62] Loss: 0.19564 
Epoch [112/300] Training [32/62] Loss: 0.13075 
Epoch [112/300] Training [33/62] Loss: 0.12929 
Epoch [112/300] Training [34/62] Loss: 0.16051 
Epoch [112/300] Training [35/62] Loss: 0.16619 
Epoch [112/300] Training [36/62] Loss: 0.16706 
Epoch [112/300] Training [37/62] Loss: 0.16703 
Epoch [112/300] Training [38/62] Loss: 0.27164 
Epoch [112/300] Training [39/62] Loss: 0.18481 
Epoch [112/300] Training [40/62] Loss: 0.20195 
Epoch [112/300] Training [41/62] Loss: 0.08357 
Epoch [112/300] Training [42/62] Loss: 0.12021 
Epoch [112/300] Training [43/62] Loss: 0.20504 
Epoch [112/300] Training [44/62] Loss: 0.19916 
Epoch [112/300] Training [45/62] Loss: 0.13929 
Epoch [112/300] Training [46/62] Loss: 0.11307 
Epoch [112/300] Training [47/62] Loss: 0.26275 
Epoch [112/300] Training [48/62] Loss: 0.12934 
Epoch [112/300] Training [49/62] Loss: 0.11824 
Epoch [112/300] Training [50/62] Loss: 0.12245 
Epoch [112/300] Training [51/62] Loss: 0.08841 
Epoch [112/300] Training [52/62] Loss: 0.11144 
Epoch [112/300] Training [53/62] Loss: 0.12419 
Epoch [112/300] Training [54/62] Loss: 0.22607 
Epoch [112/300] Training [55/62] Loss: 0.12304 
Epoch [112/300] Training [56/62] Loss: 0.20950 
Epoch [112/300] Training [57/62] Loss: 0.25998 
Epoch [112/300] Training [58/62] Loss: 0.13181 
Epoch [112/300] Training [59/62] Loss: 0.09644 
Epoch [112/300] Training [60/62] Loss: 0.12696 
Epoch [112/300] Training [61/62] Loss: 0.27792 
Epoch [112/300] Training [62/62] Loss: 0.07918 
Epoch [112/300] Training metric {'Train/mean dice_metric': 0.8899081945419312, 'Train/mean miou_metric': 0.8181860446929932, 'Train/mean f1': 0.9006062150001526, 'Train/mean precision': 0.8960068225860596, 'Train/mean recall': 0.9052532315254211, 'Train/mean hd95_metric': 23.165409088134766}
Epoch [112/300] Validation [1/16] Loss: 0.24731  focal_loss 0.10274  dice_loss 0.14457 
Epoch [112/300] Validation [2/16] Loss: 0.41157  focal_loss 0.10260  dice_loss 0.30897 
Epoch [112/300] Validation [3/16] Loss: 0.37019  focal_loss 0.10661  dice_loss 0.26358 
Epoch [112/300] Validation [4/16] Loss: 0.23847  focal_loss 0.07612  dice_loss 0.16235 
Epoch [112/300] Validation [5/16] Loss: 0.30699  focal_loss 0.07970  dice_loss 0.22729 
Epoch [112/300] Validation [6/16] Loss: 0.17632  focal_loss 0.02843  dice_loss 0.14789 
Epoch [112/300] Validation [7/16] Loss: 0.26652  focal_loss 0.07454  dice_loss 0.19198 
Epoch [112/300] Validation [8/16] Loss: 0.35312  focal_loss 0.07184  dice_loss 0.28128 
Epoch [112/300] Validation [9/16] Loss: 0.25650  focal_loss 0.06570  dice_loss 0.19080 
Epoch [112/300] Validation [10/16] Loss: 0.27098  focal_loss 0.06113  dice_loss 0.20985 
Epoch [112/300] Validation [11/16] Loss: 0.13390  focal_loss 0.01844  dice_loss 0.11547 
Epoch [112/300] Validation [12/16] Loss: 0.28999  focal_loss 0.03365  dice_loss 0.25634 
Epoch [112/300] Validation [13/16] Loss: 0.23668  focal_loss 0.03452  dice_loss 0.20216 
Epoch [112/300] Validation [14/16] Loss: 0.48315  focal_loss 0.12593  dice_loss 0.35722 
Epoch [112/300] Validation [15/16] Loss: 0.15765  focal_loss 0.02626  dice_loss 0.13139 
Epoch [112/300] Validation [16/16] Loss: 0.06470  focal_loss 0.01130  dice_loss 0.05340 
Epoch [112/300] Validation metric {'Val/mean dice_metric': 0.8752679824829102, 'Val/mean miou_metric': 0.8012742400169373, 'Val/mean f1': 0.8837952017784119, 'Val/mean precision': 0.8716709613800049, 'Val/mean recall': 0.8962616920471191, 'Val/mean hd95_metric': 27.165224075317383}
Cheakpoint...
Epoch [112/300] best acc:tensor([0.8753], device='cuda:0'), Now : mean acc: tensor([0.8753], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8752679824829102, 'Val/mean miou_metric': 0.8012742400169373, 'Val/mean f1': 0.8837952017784119, 'Val/mean precision': 0.8716709613800049, 'Val/mean recall': 0.8962616920471191, 'Val/mean hd95_metric': 27.165224075317383}
Epoch [113/300] Training [1/62] Loss: 0.08538 
Epoch [113/300] Training [2/62] Loss: 0.10667 
Epoch [113/300] Training [3/62] Loss: 0.10915 
Epoch [113/300] Training [4/62] Loss: 0.30543 
Epoch [113/300] Training [5/62] Loss: 0.15503 
Epoch [113/300] Training [6/62] Loss: 0.29622 
Epoch [113/300] Training [7/62] Loss: 0.08992 
Epoch [113/300] Training [8/62] Loss: 0.22858 
Epoch [113/300] Training [9/62] Loss: 0.09292 
Epoch [113/300] Training [10/62] Loss: 0.13755 
Epoch [113/300] Training [11/62] Loss: 0.13878 
Epoch [113/300] Training [12/62] Loss: 0.23583 
Epoch [113/300] Training [13/62] Loss: 0.10954 
Epoch [113/300] Training [14/62] Loss: 0.15132 
Epoch [113/300] Training [15/62] Loss: 0.09820 
Epoch [113/300] Training [16/62] Loss: 0.18612 
Epoch [113/300] Training [17/62] Loss: 0.14312 
Epoch [113/300] Training [18/62] Loss: 0.13495 
Epoch [113/300] Training [19/62] Loss: 0.15001 
Epoch [113/300] Training [20/62] Loss: 0.07888 
Epoch [113/300] Training [21/62] Loss: 0.12419 
Epoch [113/300] Training [22/62] Loss: 0.13913 
Epoch [113/300] Training [23/62] Loss: 0.23464 
Epoch [113/300] Training [24/62] Loss: 0.13637 
Epoch [113/300] Training [25/62] Loss: 0.17498 
Epoch [113/300] Training [26/62] Loss: 0.21524 
Epoch [113/300] Training [27/62] Loss: 0.13440 
Epoch [113/300] Training [28/62] Loss: 0.12979 
Epoch [113/300] Training [29/62] Loss: 0.17273 
Epoch [113/300] Training [30/62] Loss: 0.15794 
Epoch [113/300] Training [31/62] Loss: 0.09614 
Epoch [113/300] Training [32/62] Loss: 0.08257 
Epoch [113/300] Training [33/62] Loss: 0.24054 
Epoch [113/300] Training [34/62] Loss: 0.13569 
Epoch [113/300] Training [35/62] Loss: 0.16965 
Epoch [113/300] Training [36/62] Loss: 0.07089 
Epoch [113/300] Training [37/62] Loss: 0.18856 
Epoch [113/300] Training [38/62] Loss: 0.18175 
Epoch [113/300] Training [39/62] Loss: 0.19814 
Epoch [113/300] Training [40/62] Loss: 0.19853 
Epoch [113/300] Training [41/62] Loss: 0.19572 
Epoch [113/300] Training [42/62] Loss: 0.18455 
Epoch [113/300] Training [43/62] Loss: 0.09710 
Epoch [113/300] Training [44/62] Loss: 0.25805 
Epoch [113/300] Training [45/62] Loss: 0.14767 
Epoch [113/300] Training [46/62] Loss: 0.17417 
Epoch [113/300] Training [47/62] Loss: 0.13617 
Epoch [113/300] Training [48/62] Loss: 0.07854 
Epoch [113/300] Training [49/62] Loss: 0.11907 
Epoch [113/300] Training [50/62] Loss: 0.12377 
Epoch [113/300] Training [51/62] Loss: 0.12541 
Epoch [113/300] Training [52/62] Loss: 0.18793 
Epoch [113/300] Training [53/62] Loss: 0.16094 
Epoch [113/300] Training [54/62] Loss: 0.08828 
Epoch [113/300] Training [55/62] Loss: 0.16249 
Epoch [113/300] Training [56/62] Loss: 0.18061 
Epoch [113/300] Training [57/62] Loss: 0.12431 
Epoch [113/300] Training [58/62] Loss: 0.32458 
Epoch [113/300] Training [59/62] Loss: 0.08196 
Epoch [113/300] Training [60/62] Loss: 0.11006 
Epoch [113/300] Training [61/62] Loss: 0.16264 
Epoch [113/300] Training [62/62] Loss: 0.10335 
Epoch [113/300] Training metric {'Train/mean dice_metric': 0.8945044279098511, 'Train/mean miou_metric': 0.8247144222259521, 'Train/mean f1': 0.9065197706222534, 'Train/mean precision': 0.8985655307769775, 'Train/mean recall': 0.9146161675453186, 'Train/mean hd95_metric': 22.43048095703125}
Epoch [113/300] Validation [1/16] Loss: 0.41394  focal_loss 0.22436  dice_loss 0.18958 
Epoch [113/300] Validation [2/16] Loss: 0.23742  focal_loss 0.09007  dice_loss 0.14735 
Epoch [113/300] Validation [3/16] Loss: 0.31260  focal_loss 0.07652  dice_loss 0.23607 
Epoch [113/300] Validation [4/16] Loss: 0.34708  focal_loss 0.10582  dice_loss 0.24125 
Epoch [113/300] Validation [5/16] Loss: 0.29245  focal_loss 0.05622  dice_loss 0.23623 
Epoch [113/300] Validation [6/16] Loss: 0.21307  focal_loss 0.04543  dice_loss 0.16763 
Epoch [113/300] Validation [7/16] Loss: 0.28031  focal_loss 0.11012  dice_loss 0.17019 
Epoch [113/300] Validation [8/16] Loss: 0.34567  focal_loss 0.08282  dice_loss 0.26285 
Epoch [113/300] Validation [9/16] Loss: 0.15785  focal_loss 0.03779  dice_loss 0.12006 
Epoch [113/300] Validation [10/16] Loss: 0.41699  focal_loss 0.14048  dice_loss 0.27651 
Epoch [113/300] Validation [11/16] Loss: 0.17307  focal_loss 0.02751  dice_loss 0.14556 
Epoch [113/300] Validation [12/16] Loss: 0.30955  focal_loss 0.07009  dice_loss 0.23946 
Epoch [113/300] Validation [13/16] Loss: 0.22399  focal_loss 0.04786  dice_loss 0.17613 
Epoch [113/300] Validation [14/16] Loss: 0.49121  focal_loss 0.13391  dice_loss 0.35730 
Epoch [113/300] Validation [15/16] Loss: 0.15758  focal_loss 0.05021  dice_loss 0.10736 
Epoch [113/300] Validation [16/16] Loss: 0.09752  focal_loss 0.02083  dice_loss 0.07669 
Epoch [113/300] Validation metric {'Val/mean dice_metric': 0.8788900971412659, 'Val/mean miou_metric': 0.8050774335861206, 'Val/mean f1': 0.8866145610809326, 'Val/mean precision': 0.8814553618431091, 'Val/mean recall': 0.8918344974517822, 'Val/mean hd95_metric': 26.561952590942383}
Cheakpoint...
Epoch [113/300] best acc:tensor([0.8789], device='cuda:0'), Now : mean acc: tensor([0.8789], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8788900971412659, 'Val/mean miou_metric': 0.8050774335861206, 'Val/mean f1': 0.8866145610809326, 'Val/mean precision': 0.8814553618431091, 'Val/mean recall': 0.8918344974517822, 'Val/mean hd95_metric': 26.561952590942383}
Epoch [114/300] Training [1/62] Loss: 0.15530 
Epoch [114/300] Training [2/62] Loss: 0.13525 
Epoch [114/300] Training [3/62] Loss: 0.11021 
Epoch [114/300] Training [4/62] Loss: 0.10028 
Epoch [114/300] Training [5/62] Loss: 0.20362 
Epoch [114/300] Training [6/62] Loss: 0.11398 
Epoch [114/300] Training [7/62] Loss: 0.15881 
Epoch [114/300] Training [8/62] Loss: 0.17274 
Epoch [114/300] Training [9/62] Loss: 0.13870 
Epoch [114/300] Training [10/62] Loss: 0.10030 
Epoch [114/300] Training [11/62] Loss: 0.17598 
Epoch [114/300] Training [12/62] Loss: 0.33929 
Epoch [114/300] Training [13/62] Loss: 0.14614 
Epoch [114/300] Training [14/62] Loss: 0.14061 
Epoch [114/300] Training [15/62] Loss: 0.15435 
Epoch [114/300] Training [16/62] Loss: 0.09669 
Epoch [114/300] Training [17/62] Loss: 0.21264 
Epoch [114/300] Training [18/62] Loss: 0.16602 
Epoch [114/300] Training [19/62] Loss: 0.11009 
Epoch [114/300] Training [20/62] Loss: 0.08393 
Epoch [114/300] Training [21/62] Loss: 0.14187 
Epoch [114/300] Training [22/62] Loss: 0.12920 
Epoch [114/300] Training [23/62] Loss: 0.11868 
Epoch [114/300] Training [24/62] Loss: 0.15108 
Epoch [114/300] Training [25/62] Loss: 0.21954 
Epoch [114/300] Training [26/62] Loss: 0.24001 
Epoch [114/300] Training [27/62] Loss: 0.13954 
Epoch [114/300] Training [28/62] Loss: 0.20055 
Epoch [114/300] Training [29/62] Loss: 0.14559 
Epoch [114/300] Training [30/62] Loss: 0.21970 
Epoch [114/300] Training [31/62] Loss: 0.24403 
Epoch [114/300] Training [32/62] Loss: 0.13549 
Epoch [114/300] Training [33/62] Loss: 0.20297 
Epoch [114/300] Training [34/62] Loss: 0.09670 
Epoch [114/300] Training [35/62] Loss: 0.24557 
Epoch [114/300] Training [36/62] Loss: 0.16826 
Epoch [114/300] Training [37/62] Loss: 0.22711 
Epoch [114/300] Training [38/62] Loss: 0.14343 
Epoch [114/300] Training [39/62] Loss: 0.13814 
Epoch [114/300] Training [40/62] Loss: 0.09722 
Epoch [114/300] Training [41/62] Loss: 0.19149 
Epoch [114/300] Training [42/62] Loss: 0.17277 
Epoch [114/300] Training [43/62] Loss: 0.15030 
Epoch [114/300] Training [44/62] Loss: 0.12851 
Epoch [114/300] Training [45/62] Loss: 0.11350 
Epoch [114/300] Training [46/62] Loss: 0.10901 
Epoch [114/300] Training [47/62] Loss: 0.12888 
Epoch [114/300] Training [48/62] Loss: 0.18196 
Epoch [114/300] Training [49/62] Loss: 0.30484 
Epoch [114/300] Training [50/62] Loss: 0.23324 
Epoch [114/300] Training [51/62] Loss: 0.07203 
Epoch [114/300] Training [52/62] Loss: 0.22983 
Epoch [114/300] Training [53/62] Loss: 0.14419 
Epoch [114/300] Training [54/62] Loss: 0.14565 
Epoch [114/300] Training [55/62] Loss: 0.20402 
Epoch [114/300] Training [56/62] Loss: 0.27276 
Epoch [114/300] Training [57/62] Loss: 0.08542 
Epoch [114/300] Training [58/62] Loss: 0.24600 
Epoch [114/300] Training [59/62] Loss: 0.15725 
Epoch [114/300] Training [60/62] Loss: 0.15397 
Epoch [114/300] Training [61/62] Loss: 0.11220 
Epoch [114/300] Training [62/62] Loss: 0.05304 
Epoch [114/300] Training metric {'Train/mean dice_metric': 0.8919380903244019, 'Train/mean miou_metric': 0.8195233941078186, 'Train/mean f1': 0.900309681892395, 'Train/mean precision': 0.8930094242095947, 'Train/mean recall': 0.9077303409576416, 'Train/mean hd95_metric': 23.074060440063477}
Epoch [114/300] Validation [1/16] Loss: 0.18278  focal_loss 0.04341  dice_loss 0.13936 
Epoch [114/300] Validation [2/16] Loss: 0.32345  focal_loss 0.09077  dice_loss 0.23268 
Epoch [114/300] Validation [3/16] Loss: 0.70072  focal_loss 0.36733  dice_loss 0.33339 
Epoch [114/300] Validation [4/16] Loss: 0.24921  focal_loss 0.07363  dice_loss 0.17558 
Epoch [114/300] Validation [5/16] Loss: 0.33867  focal_loss 0.07977  dice_loss 0.25891 
Epoch [114/300] Validation [6/16] Loss: 0.23830  focal_loss 0.03270  dice_loss 0.20560 
Epoch [114/300] Validation [7/16] Loss: 0.24264  focal_loss 0.06001  dice_loss 0.18263 
Epoch [114/300] Validation [8/16] Loss: 0.26203  focal_loss 0.05012  dice_loss 0.21191 
Epoch [114/300] Validation [9/16] Loss: 0.27396  focal_loss 0.08383  dice_loss 0.19013 
Epoch [114/300] Validation [10/16] Loss: 0.34186  focal_loss 0.09473  dice_loss 0.24713 
Epoch [114/300] Validation [11/16] Loss: 0.13309  focal_loss 0.02468  dice_loss 0.10842 
Epoch [114/300] Validation [12/16] Loss: 0.33786  focal_loss 0.07332  dice_loss 0.26453 
Epoch [114/300] Validation [13/16] Loss: 0.19875  focal_loss 0.04332  dice_loss 0.15543 
Epoch [114/300] Validation [14/16] Loss: 0.37450  focal_loss 0.09764  dice_loss 0.27686 
Epoch [114/300] Validation [15/16] Loss: 0.25245  focal_loss 0.08156  dice_loss 0.17089 
Epoch [114/300] Validation [16/16] Loss: 0.06756  focal_loss 0.01063  dice_loss 0.05693 
Epoch [114/300] Validation metric {'Val/mean dice_metric': 0.8759593963623047, 'Val/mean miou_metric': 0.8004149198532104, 'Val/mean f1': 0.8842005729675293, 'Val/mean precision': 0.8766723275184631, 'Val/mean recall': 0.8918591737747192, 'Val/mean hd95_metric': 27.69098472595215}
Cheakpoint...
Epoch [114/300] best acc:tensor([0.8789], device='cuda:0'), Now : mean acc: tensor([0.8760], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8759593963623047, 'Val/mean miou_metric': 0.8004149198532104, 'Val/mean f1': 0.8842005729675293, 'Val/mean precision': 0.8766723275184631, 'Val/mean recall': 0.8918591737747192, 'Val/mean hd95_metric': 27.69098472595215}
Epoch [115/300] Training [1/62] Loss: 0.07632 
Epoch [115/300] Training [2/62] Loss: 0.45125 
Epoch [115/300] Training [3/62] Loss: 0.18189 
Epoch [115/300] Training [4/62] Loss: 0.21794 
Epoch [115/300] Training [5/62] Loss: 0.09062 
Epoch [115/300] Training [6/62] Loss: 0.19229 
Epoch [115/300] Training [7/62] Loss: 0.12381 
Epoch [115/300] Training [8/62] Loss: 0.09582 
Epoch [115/300] Training [9/62] Loss: 0.16728 
Epoch [115/300] Training [10/62] Loss: 0.30182 
Epoch [115/300] Training [11/62] Loss: 0.10889 
Epoch [115/300] Training [12/62] Loss: 0.16395 
Epoch [115/300] Training [13/62] Loss: 0.09976 
Epoch [115/300] Training [14/62] Loss: 0.21567 
Epoch [115/300] Training [15/62] Loss: 0.16927 
Epoch [115/300] Training [16/62] Loss: 0.11474 
Epoch [115/300] Training [17/62] Loss: 0.17573 
Epoch [115/300] Training [18/62] Loss: 0.11434 
Epoch [115/300] Training [19/62] Loss: 0.08979 
Epoch [115/300] Training [20/62] Loss: 0.30161 
Epoch [115/300] Training [21/62] Loss: 0.11720 
Epoch [115/300] Training [22/62] Loss: 0.25649 
Epoch [115/300] Training [23/62] Loss: 0.15751 
Epoch [115/300] Training [24/62] Loss: 0.24187 
Epoch [115/300] Training [25/62] Loss: 0.07442 
Epoch [115/300] Training [26/62] Loss: 0.08406 
Epoch [115/300] Training [27/62] Loss: 0.18773 
Epoch [115/300] Training [28/62] Loss: 0.15755 
Epoch [115/300] Training [29/62] Loss: 0.10088 
Epoch [115/300] Training [30/62] Loss: 0.09610 
Epoch [115/300] Training [31/62] Loss: 0.18427 
Epoch [115/300] Training [32/62] Loss: 0.09010 
Epoch [115/300] Training [33/62] Loss: 0.10158 
Epoch [115/300] Training [34/62] Loss: 0.11668 
Epoch [115/300] Training [35/62] Loss: 0.14652 
Epoch [115/300] Training [36/62] Loss: 0.30462 
Epoch [115/300] Training [37/62] Loss: 0.10410 
Epoch [115/300] Training [38/62] Loss: 0.14645 
Epoch [115/300] Training [39/62] Loss: 0.16831 
Epoch [115/300] Training [40/62] Loss: 0.14088 
Epoch [115/300] Training [41/62] Loss: 0.18161 
Epoch [115/300] Training [42/62] Loss: 0.23532 
Epoch [115/300] Training [43/62] Loss: 0.09315 
Epoch [115/300] Training [44/62] Loss: 0.09299 
Epoch [115/300] Training [45/62] Loss: 0.26802 
Epoch [115/300] Training [46/62] Loss: 0.10119 
Epoch [115/300] Training [47/62] Loss: 0.23507 
Epoch [115/300] Training [48/62] Loss: 0.11227 
Epoch [115/300] Training [49/62] Loss: 0.10133 
Epoch [115/300] Training [50/62] Loss: 0.21509 
Epoch [115/300] Training [51/62] Loss: 0.16420 
Epoch [115/300] Training [52/62] Loss: 0.18753 
Epoch [115/300] Training [53/62] Loss: 0.14266 
Epoch [115/300] Training [54/62] Loss: 0.19553 
Epoch [115/300] Training [55/62] Loss: 0.08744 
Epoch [115/300] Training [56/62] Loss: 0.13271 
Epoch [115/300] Training [57/62] Loss: 0.15315 
Epoch [115/300] Training [58/62] Loss: 0.11712 
Epoch [115/300] Training [59/62] Loss: 0.14005 
Epoch [115/300] Training [60/62] Loss: 0.22246 
Epoch [115/300] Training [61/62] Loss: 0.16851 
Epoch [115/300] Training [62/62] Loss: 0.06061 
Epoch [115/300] Training metric {'Train/mean dice_metric': 0.8880598545074463, 'Train/mean miou_metric': 0.8199816346168518, 'Train/mean f1': 0.9089824557304382, 'Train/mean precision': 0.9036162495613098, 'Train/mean recall': 0.9144127368927002, 'Train/mean hd95_metric': 20.601470947265625}
Epoch [115/300] Validation [1/16] Loss: 0.17205  focal_loss 0.06493  dice_loss 0.10713 
Epoch [115/300] Validation [2/16] Loss: 0.31784  focal_loss 0.07709  dice_loss 0.24075 
Epoch [115/300] Validation [3/16] Loss: 0.59078  focal_loss 0.28708  dice_loss 0.30370 
Epoch [115/300] Validation [4/16] Loss: 0.17799  focal_loss 0.04155  dice_loss 0.13644 
Epoch [115/300] Validation [5/16] Loss: 0.32084  focal_loss 0.07727  dice_loss 0.24358 
Epoch [115/300] Validation [6/16] Loss: 0.19928  focal_loss 0.03362  dice_loss 0.16565 
Epoch [115/300] Validation [7/16] Loss: 0.31882  focal_loss 0.10468  dice_loss 0.21413 
Epoch [115/300] Validation [8/16] Loss: 0.37765  focal_loss 0.10786  dice_loss 0.26979 
Epoch [115/300] Validation [9/16] Loss: 0.23197  focal_loss 0.06138  dice_loss 0.17059 
Epoch [115/300] Validation [10/16] Loss: 0.39569  focal_loss 0.10701  dice_loss 0.28868 
Epoch [115/300] Validation [11/16] Loss: 0.13188  focal_loss 0.02601  dice_loss 0.10588 
Epoch [115/300] Validation [12/16] Loss: 0.34835  focal_loss 0.07503  dice_loss 0.27332 
Epoch [115/300] Validation [13/16] Loss: 0.29588  focal_loss 0.08733  dice_loss 0.20855 
Epoch [115/300] Validation [14/16] Loss: 0.48616  focal_loss 0.12973  dice_loss 0.35643 
Epoch [115/300] Validation [15/16] Loss: 0.20406  focal_loss 0.06526  dice_loss 0.13880 
Epoch [115/300] Validation [16/16] Loss: 0.07482  focal_loss 0.01962  dice_loss 0.05519 
Epoch [115/300] Validation metric {'Val/mean dice_metric': 0.8716781735420227, 'Val/mean miou_metric': 0.8007180094718933, 'Val/mean f1': 0.8868861794471741, 'Val/mean precision': 0.8743214011192322, 'Val/mean recall': 0.8998173475265503, 'Val/mean hd95_metric': 26.798362731933594}
Cheakpoint...
Epoch [115/300] best acc:tensor([0.8789], device='cuda:0'), Now : mean acc: tensor([0.8717], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8716781735420227, 'Val/mean miou_metric': 0.8007180094718933, 'Val/mean f1': 0.8868861794471741, 'Val/mean precision': 0.8743214011192322, 'Val/mean recall': 0.8998173475265503, 'Val/mean hd95_metric': 26.798362731933594}
Epoch [116/300] Training [1/62] Loss: 0.19769 
Epoch [116/300] Training [2/62] Loss: 0.11360 
Epoch [116/300] Training [3/62] Loss: 0.13481 
Epoch [116/300] Training [4/62] Loss: 0.12601 
Epoch [116/300] Training [5/62] Loss: 0.23209 
Epoch [116/300] Training [6/62] Loss: 0.09646 
Epoch [116/300] Training [7/62] Loss: 0.15564 
Epoch [116/300] Training [8/62] Loss: 0.12514 
Epoch [116/300] Training [9/62] Loss: 0.23914 
Epoch [116/300] Training [10/62] Loss: 0.13122 
Epoch [116/300] Training [11/62] Loss: 0.11057 
Epoch [116/300] Training [12/62] Loss: 0.31540 
Epoch [116/300] Training [13/62] Loss: 0.09526 
Epoch [116/300] Training [14/62] Loss: 0.16859 
Epoch [116/300] Training [15/62] Loss: 0.17596 
Epoch [116/300] Training [16/62] Loss: 0.11533 
Epoch [116/300] Training [17/62] Loss: 0.11914 
Epoch [116/300] Training [18/62] Loss: 0.25659 
Epoch [116/300] Training [19/62] Loss: 0.07218 
Epoch [116/300] Training [20/62] Loss: 0.12300 
Epoch [116/300] Training [21/62] Loss: 0.15025 
Epoch [116/300] Training [22/62] Loss: 0.11714 
Epoch [116/300] Training [23/62] Loss: 0.12367 
Epoch [116/300] Training [24/62] Loss: 0.13510 
Epoch [116/300] Training [25/62] Loss: 0.19336 
Epoch [116/300] Training [26/62] Loss: 0.13183 
Epoch [116/300] Training [27/62] Loss: 0.10976 
Epoch [116/300] Training [28/62] Loss: 0.08587 
Epoch [116/300] Training [29/62] Loss: 0.08696 
Epoch [116/300] Training [30/62] Loss: 0.11061 
Epoch [116/300] Training [31/62] Loss: 0.09126 
Epoch [116/300] Training [32/62] Loss: 0.15453 
Epoch [116/300] Training [33/62] Loss: 0.14408 
Epoch [116/300] Training [34/62] Loss: 0.10805 
Epoch [116/300] Training [35/62] Loss: 0.14744 
Epoch [116/300] Training [36/62] Loss: 0.10173 
Epoch [116/300] Training [37/62] Loss: 0.28149 
Epoch [116/300] Training [38/62] Loss: 0.06794 
Epoch [116/300] Training [39/62] Loss: 0.12163 
Epoch [116/300] Training [40/62] Loss: 0.26600 
Epoch [116/300] Training [41/62] Loss: 0.08744 
Epoch [116/300] Training [42/62] Loss: 0.15790 
Epoch [116/300] Training [43/62] Loss: 0.13053 
Epoch [116/300] Training [44/62] Loss: 0.17355 
Epoch [116/300] Training [45/62] Loss: 0.21400 
Epoch [116/300] Training [46/62] Loss: 0.09196 
Epoch [116/300] Training [47/62] Loss: 0.09922 
Epoch [116/300] Training [48/62] Loss: 0.31198 
Epoch [116/300] Training [49/62] Loss: 0.07176 
Epoch [116/300] Training [50/62] Loss: 0.09080 
Epoch [116/300] Training [51/62] Loss: 0.11962 
Epoch [116/300] Training [52/62] Loss: 0.21669 
Epoch [116/300] Training [53/62] Loss: 0.15474 
Epoch [116/300] Training [54/62] Loss: 0.07803 
Epoch [116/300] Training [55/62] Loss: 0.12354 
Epoch [116/300] Training [56/62] Loss: 0.26282 
Epoch [116/300] Training [57/62] Loss: 0.18066 
Epoch [116/300] Training [58/62] Loss: 0.24369 
Epoch [116/300] Training [59/62] Loss: 0.14139 
Epoch [116/300] Training [60/62] Loss: 0.12087 
Epoch [116/300] Training [61/62] Loss: 0.09681 
Epoch [116/300] Training [62/62] Loss: 0.09758 
Epoch [116/300] Training metric {'Train/mean dice_metric': 0.8984224796295166, 'Train/mean miou_metric': 0.8294923901557922, 'Train/mean f1': 0.9143431782722473, 'Train/mean precision': 0.9096542596817017, 'Train/mean recall': 0.9190807342529297, 'Train/mean hd95_metric': 20.19258689880371}
Epoch [116/300] Validation [1/16] Loss: 0.15211  focal_loss 0.04825  dice_loss 0.10386 
Epoch [116/300] Validation [2/16] Loss: 0.36292  focal_loss 0.12245  dice_loss 0.24047 
Epoch [116/300] Validation [3/16] Loss: 0.21879  focal_loss 0.04540  dice_loss 0.17339 
Epoch [116/300] Validation [4/16] Loss: 0.23790  focal_loss 0.09498  dice_loss 0.14292 
Epoch [116/300] Validation [5/16] Loss: 0.35781  focal_loss 0.12387  dice_loss 0.23394 
Epoch [116/300] Validation [6/16] Loss: 0.20409  focal_loss 0.04256  dice_loss 0.16153 
Epoch [116/300] Validation [7/16] Loss: 0.33473  focal_loss 0.13613  dice_loss 0.19859 
Epoch [116/300] Validation [8/16] Loss: 0.33896  focal_loss 0.09422  dice_loss 0.24474 
Epoch [116/300] Validation [9/16] Loss: 0.22684  focal_loss 0.05962  dice_loss 0.16722 
Epoch [116/300] Validation [10/16] Loss: 0.29864  focal_loss 0.05125  dice_loss 0.24739 
Epoch [116/300] Validation [11/16] Loss: 0.18169  focal_loss 0.04005  dice_loss 0.14163 
Epoch [116/300] Validation [12/16] Loss: 0.30264  focal_loss 0.06082  dice_loss 0.24182 
Epoch [116/300] Validation [13/16] Loss: 0.28694  focal_loss 0.06801  dice_loss 0.21893 
Epoch [116/300] Validation [14/16] Loss: 0.49823  focal_loss 0.16683  dice_loss 0.33140 
Epoch [116/300] Validation [15/16] Loss: 0.24494  focal_loss 0.07908  dice_loss 0.16586 
Epoch [116/300] Validation [16/16] Loss: 0.10430  focal_loss 0.02054  dice_loss 0.08376 
Epoch [116/300] Validation metric {'Val/mean dice_metric': 0.8816514611244202, 'Val/mean miou_metric': 0.8090899586677551, 'Val/mean f1': 0.8989699482917786, 'Val/mean precision': 0.8969759941101074, 'Val/mean recall': 0.9009727835655212, 'Val/mean hd95_metric': 25.42066192626953}
Cheakpoint...
Epoch [116/300] best acc:tensor([0.8817], device='cuda:0'), Now : mean acc: tensor([0.8817], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8816514611244202, 'Val/mean miou_metric': 0.8090899586677551, 'Val/mean f1': 0.8989699482917786, 'Val/mean precision': 0.8969759941101074, 'Val/mean recall': 0.9009727835655212, 'Val/mean hd95_metric': 25.42066192626953}
Epoch [117/300] Training [1/62] Loss: 0.12486 
Epoch [117/300] Training [2/62] Loss: 0.10232 
Epoch [117/300] Training [3/62] Loss: 0.11738 
Epoch [117/300] Training [4/62] Loss: 0.15687 
Epoch [117/300] Training [5/62] Loss: 0.11747 
Epoch [117/300] Training [6/62] Loss: 0.10515 
Epoch [117/300] Training [7/62] Loss: 0.17446 
Epoch [117/300] Training [8/62] Loss: 0.15319 
Epoch [117/300] Training [9/62] Loss: 0.12288 
Epoch [117/300] Training [10/62] Loss: 0.15779 
Epoch [117/300] Training [11/62] Loss: 0.11800 
Epoch [117/300] Training [12/62] Loss: 0.08882 
Epoch [117/300] Training [13/62] Loss: 0.13877 
Epoch [117/300] Training [14/62] Loss: 0.16256 
Epoch [117/300] Training [15/62] Loss: 0.10061 
Epoch [117/300] Training [16/62] Loss: 0.09601 
Epoch [117/300] Training [17/62] Loss: 0.12469 
Epoch [117/300] Training [18/62] Loss: 0.12245 
Epoch [117/300] Training [19/62] Loss: 0.16309 
Epoch [117/300] Training [20/62] Loss: 0.10323 
Epoch [117/300] Training [21/62] Loss: 0.26132 
Epoch [117/300] Training [22/62] Loss: 0.11356 
Epoch [117/300] Training [23/62] Loss: 0.12722 
Epoch [117/300] Training [24/62] Loss: 0.08514 
Epoch [117/300] Training [25/62] Loss: 0.30110 
Epoch [117/300] Training [26/62] Loss: 0.15549 
Epoch [117/300] Training [27/62] Loss: 0.11230 
Epoch [117/300] Training [28/62] Loss: 0.09581 
Epoch [117/300] Training [29/62] Loss: 0.13420 
Epoch [117/300] Training [30/62] Loss: 0.21857 
Epoch [117/300] Training [31/62] Loss: 0.15203 
Epoch [117/300] Training [32/62] Loss: 0.08580 
Epoch [117/300] Training [33/62] Loss: 0.24901 
Epoch [117/300] Training [34/62] Loss: 0.13477 
Epoch [117/300] Training [35/62] Loss: 0.18744 
Epoch [117/300] Training [36/62] Loss: 0.10078 
Epoch [117/300] Training [37/62] Loss: 0.09752 
Epoch [117/300] Training [38/62] Loss: 0.10899 
Epoch [117/300] Training [39/62] Loss: 0.16427 
Epoch [117/300] Training [40/62] Loss: 0.23619 
Epoch [117/300] Training [41/62] Loss: 0.28557 
Epoch [117/300] Training [42/62] Loss: 0.14226 
Epoch [117/300] Training [43/62] Loss: 0.13370 
Epoch [117/300] Training [44/62] Loss: 0.17435 
Epoch [117/300] Training [45/62] Loss: 0.22481 
Epoch [117/300] Training [46/62] Loss: 0.17040 
Epoch [117/300] Training [47/62] Loss: 0.07269 
Epoch [117/300] Training [48/62] Loss: 0.11001 
Epoch [117/300] Training [49/62] Loss: 0.17050 
Epoch [117/300] Training [50/62] Loss: 0.10494 
Epoch [117/300] Training [51/62] Loss: 0.28723 
Epoch [117/300] Training [52/62] Loss: 0.20236 
Epoch [117/300] Training [53/62] Loss: 0.24700 
Epoch [117/300] Training [54/62] Loss: 0.17087 
Epoch [117/300] Training [55/62] Loss: 0.22595 
Epoch [117/300] Training [56/62] Loss: 0.14131 
Epoch [117/300] Training [57/62] Loss: 0.13847 
Epoch [117/300] Training [58/62] Loss: 0.21025 
Epoch [117/300] Training [59/62] Loss: 0.12299 
Epoch [117/300] Training [60/62] Loss: 0.24852 
Epoch [117/300] Training [61/62] Loss: 0.18502 
Epoch [117/300] Training [62/62] Loss: 0.27167 
Epoch [117/300] Training metric {'Train/mean dice_metric': 0.8947964310646057, 'Train/mean miou_metric': 0.8256676197052002, 'Train/mean f1': 0.911086916923523, 'Train/mean precision': 0.9057822823524475, 'Train/mean recall': 0.9164540767669678, 'Train/mean hd95_metric': 20.259361267089844}
Epoch [117/300] Validation [1/16] Loss: 0.27933  focal_loss 0.10064  dice_loss 0.17869 
Epoch [117/300] Validation [2/16] Loss: 0.37574  focal_loss 0.11790  dice_loss 0.25784 
Epoch [117/300] Validation [3/16] Loss: 0.32982  focal_loss 0.08876  dice_loss 0.24106 
Epoch [117/300] Validation [4/16] Loss: 0.27772  focal_loss 0.11634  dice_loss 0.16139 
Epoch [117/300] Validation [5/16] Loss: 0.43319  focal_loss 0.13986  dice_loss 0.29333 
Epoch [117/300] Validation [6/16] Loss: 0.24474  focal_loss 0.03981  dice_loss 0.20493 
Epoch [117/300] Validation [7/16] Loss: 0.25944  focal_loss 0.07505  dice_loss 0.18439 
Epoch [117/300] Validation [8/16] Loss: 0.38638  focal_loss 0.06337  dice_loss 0.32301 
Epoch [117/300] Validation [9/16] Loss: 0.21026  focal_loss 0.05663  dice_loss 0.15363 
Epoch [117/300] Validation [10/16] Loss: 0.41187  focal_loss 0.13446  dice_loss 0.27741 
Epoch [117/300] Validation [11/16] Loss: 0.15903  focal_loss 0.03408  dice_loss 0.12494 
Epoch [117/300] Validation [12/16] Loss: 0.33389  focal_loss 0.05422  dice_loss 0.27967 
Epoch [117/300] Validation [13/16] Loss: 0.23591  focal_loss 0.04982  dice_loss 0.18608 
Epoch [117/300] Validation [14/16] Loss: 0.63396  focal_loss 0.24675  dice_loss 0.38721 
Epoch [117/300] Validation [15/16] Loss: 0.12639  focal_loss 0.02980  dice_loss 0.09659 
Epoch [117/300] Validation [16/16] Loss: 0.06123  focal_loss 0.01088  dice_loss 0.05034 
Epoch [117/300] Validation metric {'Val/mean dice_metric': 0.8745813369750977, 'Val/mean miou_metric': 0.8018896579742432, 'Val/mean f1': 0.8873381018638611, 'Val/mean precision': 0.870275616645813, 'Val/mean recall': 0.9050828814506531, 'Val/mean hd95_metric': 26.35108184814453}
Cheakpoint...
Epoch [117/300] best acc:tensor([0.8817], device='cuda:0'), Now : mean acc: tensor([0.8746], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8745813369750977, 'Val/mean miou_metric': 0.8018896579742432, 'Val/mean f1': 0.8873381018638611, 'Val/mean precision': 0.870275616645813, 'Val/mean recall': 0.9050828814506531, 'Val/mean hd95_metric': 26.35108184814453}
Epoch [118/300] Training [1/62] Loss: 0.14144 
Epoch [118/300] Training [2/62] Loss: 0.10614 
Epoch [118/300] Training [3/62] Loss: 0.13554 
Epoch [118/300] Training [4/62] Loss: 0.08247 
Epoch [118/300] Training [5/62] Loss: 0.08687 
Epoch [118/300] Training [6/62] Loss: 0.15746 
Epoch [118/300] Training [7/62] Loss: 0.12524 
Epoch [118/300] Training [8/62] Loss: 0.09107 
Epoch [118/300] Training [9/62] Loss: 0.10959 
Epoch [118/300] Training [10/62] Loss: 0.14143 
Epoch [118/300] Training [11/62] Loss: 0.15166 
Epoch [118/300] Training [12/62] Loss: 0.10872 
Epoch [118/300] Training [13/62] Loss: 0.10672 
Epoch [118/300] Training [14/62] Loss: 0.12100 
Epoch [118/300] Training [15/62] Loss: 0.12103 
Epoch [118/300] Training [16/62] Loss: 0.11645 
Epoch [118/300] Training [17/62] Loss: 0.11777 
Epoch [118/300] Training [18/62] Loss: 0.14914 
Epoch [118/300] Training [19/62] Loss: 0.11119 
Epoch [118/300] Training [20/62] Loss: 0.10932 
Epoch [118/300] Training [21/62] Loss: 0.07524 
Epoch [118/300] Training [22/62] Loss: 0.12348 
Epoch [118/300] Training [23/62] Loss: 0.09132 
Epoch [118/300] Training [24/62] Loss: 0.11124 
Epoch [118/300] Training [25/62] Loss: 0.07207 
Epoch [118/300] Training [26/62] Loss: 0.17115 
Epoch [118/300] Training [27/62] Loss: 0.27480 
Epoch [118/300] Training [28/62] Loss: 0.11415 
Epoch [118/300] Training [29/62] Loss: 0.19150 
Epoch [118/300] Training [30/62] Loss: 0.12285 
Epoch [118/300] Training [31/62] Loss: 0.11047 
Epoch [118/300] Training [32/62] Loss: 0.08203 
Epoch [118/300] Training [33/62] Loss: 0.07228 
Epoch [118/300] Training [34/62] Loss: 0.11494 
Epoch [118/300] Training [35/62] Loss: 0.11481 
Epoch [118/300] Training [36/62] Loss: 0.10926 
Epoch [118/300] Training [37/62] Loss: 0.07989 
Epoch [118/300] Training [38/62] Loss: 0.16411 
Epoch [118/300] Training [39/62] Loss: 0.19950 
Epoch [118/300] Training [40/62] Loss: 0.16681 
Epoch [118/300] Training [41/62] Loss: 0.16914 
Epoch [118/300] Training [42/62] Loss: 0.18528 
Epoch [118/300] Training [43/62] Loss: 0.12667 
Epoch [118/300] Training [44/62] Loss: 0.25701 
Epoch [118/300] Training [45/62] Loss: 0.21186 
Epoch [118/300] Training [46/62] Loss: 0.12954 
Epoch [118/300] Training [47/62] Loss: 0.09745 
Epoch [118/300] Training [48/62] Loss: 0.15235 
Epoch [118/300] Training [49/62] Loss: 0.10264 
Epoch [118/300] Training [50/62] Loss: 0.14456 
Epoch [118/300] Training [51/62] Loss: 0.09353 
Epoch [118/300] Training [52/62] Loss: 0.18334 
Epoch [118/300] Training [53/62] Loss: 0.09836 
Epoch [118/300] Training [54/62] Loss: 0.13807 
Epoch [118/300] Training [55/62] Loss: 0.12789 
Epoch [118/300] Training [56/62] Loss: 0.19313 
Epoch [118/300] Training [57/62] Loss: 0.16803 
Epoch [118/300] Training [58/62] Loss: 0.15092 
Epoch [118/300] Training [59/62] Loss: 0.14432 
Epoch [118/300] Training [60/62] Loss: 0.16106 
Epoch [118/300] Training [61/62] Loss: 0.09879 
Epoch [118/300] Training [62/62] Loss: 0.07611 
Epoch [118/300] Training metric {'Train/mean dice_metric': 0.9091387391090393, 'Train/mean miou_metric': 0.8445535898208618, 'Train/mean f1': 0.9226004481315613, 'Train/mean precision': 0.9210109710693359, 'Train/mean recall': 0.9241955280303955, 'Train/mean hd95_metric': 17.676971435546875}
Epoch [118/300] Validation [1/16] Loss: 0.09967  focal_loss 0.03098  dice_loss 0.06870 
Epoch [118/300] Validation [2/16] Loss: 0.47801  focal_loss 0.14648  dice_loss 0.33153 
Epoch [118/300] Validation [3/16] Loss: 0.81747  focal_loss 0.46746  dice_loss 0.35001 
Epoch [118/300] Validation [4/16] Loss: 0.22372  focal_loss 0.07127  dice_loss 0.15245 
Epoch [118/300] Validation [5/16] Loss: 0.51908  focal_loss 0.20221  dice_loss 0.31687 
Epoch [118/300] Validation [6/16] Loss: 0.24738  focal_loss 0.07733  dice_loss 0.17004 
Epoch [118/300] Validation [7/16] Loss: 0.28862  focal_loss 0.08660  dice_loss 0.20202 
Epoch [118/300] Validation [8/16] Loss: 0.30681  focal_loss 0.08003  dice_loss 0.22678 
Epoch [118/300] Validation [9/16] Loss: 0.36362  focal_loss 0.12435  dice_loss 0.23927 
Epoch [118/300] Validation [10/16] Loss: 0.41174  focal_loss 0.11610  dice_loss 0.29564 
Epoch [118/300] Validation [11/16] Loss: 0.15703  focal_loss 0.05136  dice_loss 0.10567 
Epoch [118/300] Validation [12/16] Loss: 0.33176  focal_loss 0.10539  dice_loss 0.22637 
Epoch [118/300] Validation [13/16] Loss: 0.27407  focal_loss 0.09316  dice_loss 0.18091 
Epoch [118/300] Validation [14/16] Loss: 0.32827  focal_loss 0.07437  dice_loss 0.25389 
Epoch [118/300] Validation [15/16] Loss: 0.11252  focal_loss 0.03042  dice_loss 0.08210 
Epoch [118/300] Validation [16/16] Loss: 0.06073  focal_loss 0.01025  dice_loss 0.05048 
Epoch [118/300] Validation metric {'Val/mean dice_metric': 0.8875901103019714, 'Val/mean miou_metric': 0.8180872201919556, 'Val/mean f1': 0.8961851596832275, 'Val/mean precision': 0.8832710981369019, 'Val/mean recall': 0.9094823002815247, 'Val/mean hd95_metric': 23.12091827392578}
Cheakpoint...
Epoch [118/300] best acc:tensor([0.8876], device='cuda:0'), Now : mean acc: tensor([0.8876], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8875901103019714, 'Val/mean miou_metric': 0.8180872201919556, 'Val/mean f1': 0.8961851596832275, 'Val/mean precision': 0.8832710981369019, 'Val/mean recall': 0.9094823002815247, 'Val/mean hd95_metric': 23.12091827392578}
Epoch [119/300] Training [1/62] Loss: 0.18369 
Epoch [119/300] Training [2/62] Loss: 0.17110 
Epoch [119/300] Training [3/62] Loss: 0.17266 
Epoch [119/300] Training [4/62] Loss: 0.16559 
Epoch [119/300] Training [5/62] Loss: 0.13563 
Epoch [119/300] Training [6/62] Loss: 0.14664 
Epoch [119/300] Training [7/62] Loss: 0.08970 
Epoch [119/300] Training [8/62] Loss: 0.07655 
Epoch [119/300] Training [9/62] Loss: 0.20079 
Epoch [119/300] Training [10/62] Loss: 0.15223 
Epoch [119/300] Training [11/62] Loss: 0.17725 
Epoch [119/300] Training [12/62] Loss: 0.28796 
Epoch [119/300] Training [13/62] Loss: 0.18728 
Epoch [119/300] Training [14/62] Loss: 0.07831 
Epoch [119/300] Training [15/62] Loss: 0.10961 
Epoch [119/300] Training [16/62] Loss: 0.20754 
Epoch [119/300] Training [17/62] Loss: 0.09263 
Epoch [119/300] Training [18/62] Loss: 0.12638 
Epoch [119/300] Training [19/62] Loss: 0.21573 
Epoch [119/300] Training [20/62] Loss: 0.16932 
Epoch [119/300] Training [21/62] Loss: 0.15845 
Epoch [119/300] Training [22/62] Loss: 0.06440 
Epoch [119/300] Training [23/62] Loss: 0.31564 
Epoch [119/300] Training [24/62] Loss: 0.07575 
Epoch [119/300] Training [25/62] Loss: 0.14924 
Epoch [119/300] Training [26/62] Loss: 0.16227 
Epoch [119/300] Training [27/62] Loss: 0.11130 
Epoch [119/300] Training [28/62] Loss: 0.15198 
Epoch [119/300] Training [29/62] Loss: 0.10217 
Epoch [119/300] Training [30/62] Loss: 0.19573 
Epoch [119/300] Training [31/62] Loss: 0.05723 
Epoch [119/300] Training [32/62] Loss: 0.10393 
Epoch [119/300] Training [33/62] Loss: 0.10646 
Epoch [119/300] Training [34/62] Loss: 0.11714 
Epoch [119/300] Training [35/62] Loss: 0.21312 
Epoch [119/300] Training [36/62] Loss: 0.14427 
Epoch [119/300] Training [37/62] Loss: 0.24130 
Epoch [119/300] Training [38/62] Loss: 0.30579 
Epoch [119/300] Training [39/62] Loss: 0.15085 
Epoch [119/300] Training [40/62] Loss: 0.20675 
Epoch [119/300] Training [41/62] Loss: 0.11225 
Epoch [119/300] Training [42/62] Loss: 0.08833 
Epoch [119/300] Training [43/62] Loss: 0.28105 
Epoch [119/300] Training [44/62] Loss: 0.17372 
Epoch [119/300] Training [45/62] Loss: 0.20656 
Epoch [119/300] Training [46/62] Loss: 0.14730 
Epoch [119/300] Training [47/62] Loss: 0.24663 
Epoch [119/300] Training [48/62] Loss: 0.09897 
Epoch [119/300] Training [49/62] Loss: 0.11695 
Epoch [119/300] Training [50/62] Loss: 0.17043 
Epoch [119/300] Training [51/62] Loss: 0.12332 
Epoch [119/300] Training [52/62] Loss: 0.13815 
Epoch [119/300] Training [53/62] Loss: 0.12769 
Epoch [119/300] Training [54/62] Loss: 0.07644 
Epoch [119/300] Training [55/62] Loss: 0.15921 
Epoch [119/300] Training [56/62] Loss: 0.16742 
Epoch [119/300] Training [57/62] Loss: 0.15304 
Epoch [119/300] Training [58/62] Loss: 0.22764 
Epoch [119/300] Training [59/62] Loss: 0.17800 
Epoch [119/300] Training [60/62] Loss: 0.16086 
Epoch [119/300] Training [61/62] Loss: 0.11606 
Epoch [119/300] Training [62/62] Loss: 0.05576 
Epoch [119/300] Training metric {'Train/mean dice_metric': 0.8915814757347107, 'Train/mean miou_metric': 0.8218880891799927, 'Train/mean f1': 0.9071113467216492, 'Train/mean precision': 0.8970866799354553, 'Train/mean recall': 0.9173625111579895, 'Train/mean hd95_metric': 22.874069213867188}
Epoch [119/300] Validation [1/16] Loss: 0.16228  focal_loss 0.05761  dice_loss 0.10467 
Epoch [119/300] Validation [2/16] Loss: 0.45802  focal_loss 0.20988  dice_loss 0.24813 
Epoch [119/300] Validation [3/16] Loss: 0.35193  focal_loss 0.11995  dice_loss 0.23198 
Epoch [119/300] Validation [4/16] Loss: 0.31196  focal_loss 0.14411  dice_loss 0.16785 
Epoch [119/300] Validation [5/16] Loss: 0.25590  focal_loss 0.06302  dice_loss 0.19288 
Epoch [119/300] Validation [6/16] Loss: 0.26395  focal_loss 0.07396  dice_loss 0.18999 
Epoch [119/300] Validation [7/16] Loss: 0.41304  focal_loss 0.18036  dice_loss 0.23268 
Epoch [119/300] Validation [8/16] Loss: 0.44493  focal_loss 0.15331  dice_loss 0.29162 
Epoch [119/300] Validation [9/16] Loss: 0.19090  focal_loss 0.06829  dice_loss 0.12261 
Epoch [119/300] Validation [10/16] Loss: 0.34120  focal_loss 0.13264  dice_loss 0.20855 
Epoch [119/300] Validation [11/16] Loss: 0.19519  focal_loss 0.05835  dice_loss 0.13685 
Epoch [119/300] Validation [12/16] Loss: 0.39792  focal_loss 0.12269  dice_loss 0.27523 
Epoch [119/300] Validation [13/16] Loss: 0.32222  focal_loss 0.10708  dice_loss 0.21514 
Epoch [119/300] Validation [14/16] Loss: 0.75864  focal_loss 0.33592  dice_loss 0.42272 
Epoch [119/300] Validation [15/16] Loss: 0.13360  focal_loss 0.03759  dice_loss 0.09601 
Epoch [119/300] Validation [16/16] Loss: 0.07462  focal_loss 0.01879  dice_loss 0.05583 
Epoch [119/300] Validation metric {'Val/mean dice_metric': 0.8736178278923035, 'Val/mean miou_metric': 0.7999937534332275, 'Val/mean f1': 0.88516765832901, 'Val/mean precision': 0.8798909783363342, 'Val/mean recall': 0.8905079364776611, 'Val/mean hd95_metric': 27.6806583404541}
Cheakpoint...
Epoch [119/300] best acc:tensor([0.8876], device='cuda:0'), Now : mean acc: tensor([0.8736], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8736178278923035, 'Val/mean miou_metric': 0.7999937534332275, 'Val/mean f1': 0.88516765832901, 'Val/mean precision': 0.8798909783363342, 'Val/mean recall': 0.8905079364776611, 'Val/mean hd95_metric': 27.6806583404541}
Epoch [120/300] Training [1/62] Loss: 0.07017 
Epoch [120/300] Training [2/62] Loss: 0.09427 
Epoch [120/300] Training [3/62] Loss: 0.08397 
Epoch [120/300] Training [4/62] Loss: 0.07569 
Epoch [120/300] Training [5/62] Loss: 0.18789 
Epoch [120/300] Training [6/62] Loss: 0.16167 
Epoch [120/300] Training [7/62] Loss: 0.10810 
Epoch [120/300] Training [8/62] Loss: 0.21185 
Epoch [120/300] Training [9/62] Loss: 0.07996 
Epoch [120/300] Training [10/62] Loss: 0.08470 
Epoch [120/300] Training [11/62] Loss: 0.25273 
Epoch [120/300] Training [12/62] Loss: 0.17893 
Epoch [120/300] Training [13/62] Loss: 0.25611 
Epoch [120/300] Training [14/62] Loss: 0.10792 
Epoch [120/300] Training [15/62] Loss: 0.11747 
Epoch [120/300] Training [16/62] Loss: 0.14409 
Epoch [120/300] Training [17/62] Loss: 0.13892 
Epoch [120/300] Training [18/62] Loss: 0.14134 
Epoch [120/300] Training [19/62] Loss: 0.17041 
Epoch [120/300] Training [20/62] Loss: 0.11267 
Epoch [120/300] Training [21/62] Loss: 0.16590 
Epoch [120/300] Training [22/62] Loss: 0.18465 
Epoch [120/300] Training [23/62] Loss: 0.18376 
Epoch [120/300] Training [24/62] Loss: 0.06577 
Epoch [120/300] Training [25/62] Loss: 0.15100 
Epoch [120/300] Training [26/62] Loss: 0.16764 
Epoch [120/300] Training [27/62] Loss: 0.10898 
Epoch [120/300] Training [28/62] Loss: 0.19739 
Epoch [120/300] Training [29/62] Loss: 0.09588 
Epoch [120/300] Training [30/62] Loss: 0.30278 
Epoch [120/300] Training [31/62] Loss: 0.08915 
Epoch [120/300] Training [32/62] Loss: 0.09197 
Epoch [120/300] Training [33/62] Loss: 0.18365 
Epoch [120/300] Training [34/62] Loss: 0.20430 
Epoch [120/300] Training [35/62] Loss: 0.18565 
Epoch [120/300] Training [36/62] Loss: 0.14983 
Epoch [120/300] Training [37/62] Loss: 0.13470 
Epoch [120/300] Training [38/62] Loss: 0.10608 
Epoch [120/300] Training [39/62] Loss: 0.10309 
Epoch [120/300] Training [40/62] Loss: 0.16219 
Epoch [120/300] Training [41/62] Loss: 0.16687 
Epoch [120/300] Training [42/62] Loss: 0.08364 
Epoch [120/300] Training [43/62] Loss: 0.17847 
Epoch [120/300] Training [44/62] Loss: 0.15843 
Epoch [120/300] Training [45/62] Loss: 0.22728 
Epoch [120/300] Training [46/62] Loss: 0.08804 
Epoch [120/300] Training [47/62] Loss: 0.13388 
Epoch [120/300] Training [48/62] Loss: 0.12834 
Epoch [120/300] Training [49/62] Loss: 0.10560 
Epoch [120/300] Training [50/62] Loss: 0.12765 
Epoch [120/300] Training [51/62] Loss: 0.13225 
Epoch [120/300] Training [52/62] Loss: 0.09851 
Epoch [120/300] Training [53/62] Loss: 0.24724 
Epoch [120/300] Training [54/62] Loss: 0.14487 
Epoch [120/300] Training [55/62] Loss: 0.15049 
Epoch [120/300] Training [56/62] Loss: 0.14104 
Epoch [120/300] Training [57/62] Loss: 0.10496 
Epoch [120/300] Training [58/62] Loss: 0.28289 
Epoch [120/300] Training [59/62] Loss: 0.07801 
Epoch [120/300] Training [60/62] Loss: 0.09813 
Epoch [120/300] Training [61/62] Loss: 0.15183 
Epoch [120/300] Training [62/62] Loss: 0.04934 
Epoch [120/300] Training metric {'Train/mean dice_metric': 0.9006143808364868, 'Train/mean miou_metric': 0.833431601524353, 'Train/mean f1': 0.9138973951339722, 'Train/mean precision': 0.9059166312217712, 'Train/mean recall': 0.922019898891449, 'Train/mean hd95_metric': 20.808155059814453}
Epoch [120/300] Validation [1/16] Loss: 0.17112  focal_loss 0.05780  dice_loss 0.11332 
Epoch [120/300] Validation [2/16] Loss: 0.32860  focal_loss 0.10389  dice_loss 0.22471 
Epoch [120/300] Validation [3/16] Loss: 0.29458  focal_loss 0.07516  dice_loss 0.21941 
Epoch [120/300] Validation [4/16] Loss: 0.28864  focal_loss 0.10906  dice_loss 0.17958 
Epoch [120/300] Validation [5/16] Loss: 0.22952  focal_loss 0.07429  dice_loss 0.15523 
Epoch [120/300] Validation [6/16] Loss: 0.26097  focal_loss 0.07285  dice_loss 0.18812 
Epoch [120/300] Validation [7/16] Loss: 0.23884  focal_loss 0.09171  dice_loss 0.14713 
Epoch [120/300] Validation [8/16] Loss: 0.46584  focal_loss 0.13867  dice_loss 0.32717 
Epoch [120/300] Validation [9/16] Loss: 0.21109  focal_loss 0.05460  dice_loss 0.15648 
Epoch [120/300] Validation [10/16] Loss: 0.43377  focal_loss 0.18329  dice_loss 0.25047 
Epoch [120/300] Validation [11/16] Loss: 0.15117  focal_loss 0.03269  dice_loss 0.11848 
Epoch [120/300] Validation [12/16] Loss: 0.28844  focal_loss 0.05919  dice_loss 0.22925 
Epoch [120/300] Validation [13/16] Loss: 0.37509  focal_loss 0.12136  dice_loss 0.25373 
Epoch [120/300] Validation [14/16] Loss: 0.65980  focal_loss 0.21601  dice_loss 0.44378 
Epoch [120/300] Validation [15/16] Loss: 0.09882  focal_loss 0.02669  dice_loss 0.07213 
Epoch [120/300] Validation [16/16] Loss: 0.10564  focal_loss 0.02569  dice_loss 0.07995 
Epoch [120/300] Validation metric {'Val/mean dice_metric': 0.8825932741165161, 'Val/mean miou_metric': 0.8119297623634338, 'Val/mean f1': 0.8954021334648132, 'Val/mean precision': 0.8919591903686523, 'Val/mean recall': 0.898871898651123, 'Val/mean hd95_metric': 25.65204429626465}
Cheakpoint...
Epoch [120/300] best acc:tensor([0.8876], device='cuda:0'), Now : mean acc: tensor([0.8826], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8825932741165161, 'Val/mean miou_metric': 0.8119297623634338, 'Val/mean f1': 0.8954021334648132, 'Val/mean precision': 0.8919591903686523, 'Val/mean recall': 0.898871898651123, 'Val/mean hd95_metric': 25.65204429626465}
Epoch [121/300] Training [1/62] Loss: 0.33088 
Epoch [121/300] Training [2/62] Loss: 0.05589 
Epoch [121/300] Training [3/62] Loss: 0.13638 
Epoch [121/300] Training [4/62] Loss: 0.07625 
Epoch [121/300] Training [5/62] Loss: 0.11419 
Epoch [121/300] Training [6/62] Loss: 0.20744 
Epoch [121/300] Training [7/62] Loss: 0.28413 
Epoch [121/300] Training [8/62] Loss: 0.09851 
Epoch [121/300] Training [9/62] Loss: 0.09345 
Epoch [121/300] Training [10/62] Loss: 0.14049 
Epoch [121/300] Training [11/62] Loss: 0.12238 
Epoch [121/300] Training [12/62] Loss: 0.07162 
Epoch [121/300] Training [13/62] Loss: 0.20694 
Epoch [121/300] Training [14/62] Loss: 0.23507 
Epoch [121/300] Training [15/62] Loss: 0.12077 
Epoch [121/300] Training [16/62] Loss: 0.11421 
Epoch [121/300] Training [17/62] Loss: 0.08816 
Epoch [121/300] Training [18/62] Loss: 0.14082 
Epoch [121/300] Training [19/62] Loss: 0.13120 
Epoch [121/300] Training [20/62] Loss: 0.15449 
Epoch [121/300] Training [21/62] Loss: 0.09297 
Epoch [121/300] Training [22/62] Loss: 0.21200 
Epoch [121/300] Training [23/62] Loss: 0.19180 
Epoch [121/300] Training [24/62] Loss: 0.09682 
Epoch [121/300] Training [25/62] Loss: 0.26640 
Epoch [121/300] Training [26/62] Loss: 0.17776 
Epoch [121/300] Training [27/62] Loss: 0.07295 
Epoch [121/300] Training [28/62] Loss: 0.11632 
Epoch [121/300] Training [29/62] Loss: 0.16099 
Epoch [121/300] Training [30/62] Loss: 0.31063 
Epoch [121/300] Training [31/62] Loss: 0.12309 
Epoch [121/300] Training [32/62] Loss: 0.13450 
Epoch [121/300] Training [33/62] Loss: 0.13198 
Epoch [121/300] Training [34/62] Loss: 0.30498 
Epoch [121/300] Training [35/62] Loss: 0.19591 
Epoch [121/300] Training [36/62] Loss: 0.39880 
Epoch [121/300] Training [37/62] Loss: 0.20935 
Epoch [121/300] Training [38/62] Loss: 0.23246 
Epoch [121/300] Training [39/62] Loss: 0.10806 
Epoch [121/300] Training [40/62] Loss: 0.13243 
Epoch [121/300] Training [41/62] Loss: 0.14308 
Epoch [121/300] Training [42/62] Loss: 0.14530 
Epoch [121/300] Training [43/62] Loss: 0.13304 
Epoch [121/300] Training [44/62] Loss: 0.14314 
Epoch [121/300] Training [45/62] Loss: 0.17119 
Epoch [121/300] Training [46/62] Loss: 0.21811 
Epoch [121/300] Training [47/62] Loss: 0.13224 
Epoch [121/300] Training [48/62] Loss: 0.10052 
Epoch [121/300] Training [49/62] Loss: 0.13779 
Epoch [121/300] Training [50/62] Loss: 0.22829 
Epoch [121/300] Training [51/62] Loss: 0.17352 
Epoch [121/300] Training [52/62] Loss: 0.09060 
Epoch [121/300] Training [53/62] Loss: 0.09743 
Epoch [121/300] Training [54/62] Loss: 0.15616 
Epoch [121/300] Training [55/62] Loss: 0.18050 
Epoch [121/300] Training [56/62] Loss: 0.09211 
Epoch [121/300] Training [57/62] Loss: 0.15452 
Epoch [121/300] Training [58/62] Loss: 0.17918 
Epoch [121/300] Training [59/62] Loss: 0.11193 
Epoch [121/300] Training [60/62] Loss: 0.08318 
Epoch [121/300] Training [61/62] Loss: 0.21263 
Epoch [121/300] Training [62/62] Loss: 1.04465 
Epoch [121/300] Training metric {'Train/mean dice_metric': 0.8904137015342712, 'Train/mean miou_metric': 0.8204012513160706, 'Train/mean f1': 0.9045702815055847, 'Train/mean precision': 0.8995397686958313, 'Train/mean recall': 0.9096574783325195, 'Train/mean hd95_metric': 22.31875228881836}
Epoch [121/300] Validation [1/16] Loss: 0.24932  focal_loss 0.07649  dice_loss 0.17283 
Epoch [121/300] Validation [2/16] Loss: 0.41806  focal_loss 0.11475  dice_loss 0.30331 
Epoch [121/300] Validation [3/16] Loss: 0.26773  focal_loss 0.04826  dice_loss 0.21948 
Epoch [121/300] Validation [4/16] Loss: 0.27374  focal_loss 0.06414  dice_loss 0.20960 
Epoch [121/300] Validation [5/16] Loss: 0.41268  focal_loss 0.09400  dice_loss 0.31867 
Epoch [121/300] Validation [6/16] Loss: 0.30108  focal_loss 0.10244  dice_loss 0.19864 
Epoch [121/300] Validation [7/16] Loss: 0.36989  focal_loss 0.14154  dice_loss 0.22835 
Epoch [121/300] Validation [8/16] Loss: 0.34571  focal_loss 0.08968  dice_loss 0.25603 
Epoch [121/300] Validation [9/16] Loss: 0.36524  focal_loss 0.14798  dice_loss 0.21726 
Epoch [121/300] Validation [10/16] Loss: 0.78645  focal_loss 0.37037  dice_loss 0.41608 
Epoch [121/300] Validation [11/16] Loss: 0.28349  focal_loss 0.10257  dice_loss 0.18093 
Epoch [121/300] Validation [12/16] Loss: 0.40906  focal_loss 0.11364  dice_loss 0.29543 
Epoch [121/300] Validation [13/16] Loss: 0.37158  focal_loss 0.12011  dice_loss 0.25148 
Epoch [121/300] Validation [14/16] Loss: 0.60862  focal_loss 0.23565  dice_loss 0.37297 
Epoch [121/300] Validation [15/16] Loss: 0.14732  focal_loss 0.03970  dice_loss 0.10762 
Epoch [121/300] Validation [16/16] Loss: 0.08820  focal_loss 0.02502  dice_loss 0.06318 
Epoch [121/300] Validation metric {'Val/mean dice_metric': 0.8661718368530273, 'Val/mean miou_metric': 0.7927372455596924, 'Val/mean f1': 0.8735696077346802, 'Val/mean precision': 0.8518798351287842, 'Val/mean recall': 0.896392822265625, 'Val/mean hd95_metric': 29.955141067504883}
Cheakpoint...
Epoch [121/300] best acc:tensor([0.8876], device='cuda:0'), Now : mean acc: tensor([0.8662], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8661718368530273, 'Val/mean miou_metric': 0.7927372455596924, 'Val/mean f1': 0.8735696077346802, 'Val/mean precision': 0.8518798351287842, 'Val/mean recall': 0.896392822265625, 'Val/mean hd95_metric': 29.955141067504883}
Epoch [122/300] Training [1/62] Loss: 0.26280 
Epoch [122/300] Training [2/62] Loss: 0.25933 
Epoch [122/300] Training [3/62] Loss: 0.16483 
Epoch [122/300] Training [4/62] Loss: 0.15363 
Epoch [122/300] Training [5/62] Loss: 0.20368 
Epoch [122/300] Training [6/62] Loss: 0.17405 
Epoch [122/300] Training [7/62] Loss: 0.18067 
Epoch [122/300] Training [8/62] Loss: 0.17473 
Epoch [122/300] Training [9/62] Loss: 0.15229 
Epoch [122/300] Training [10/62] Loss: 0.13160 
Epoch [122/300] Training [11/62] Loss: 0.13680 
Epoch [122/300] Training [12/62] Loss: 0.31689 
Epoch [122/300] Training [13/62] Loss: 0.19662 
Epoch [122/300] Training [14/62] Loss: 0.14200 
Epoch [122/300] Training [15/62] Loss: 0.14918 
Epoch [122/300] Training [16/62] Loss: 0.23545 
Epoch [122/300] Training [17/62] Loss: 0.13411 
Epoch [122/300] Training [18/62] Loss: 0.16194 
Epoch [122/300] Training [19/62] Loss: 0.19665 
Epoch [122/300] Training [20/62] Loss: 0.17785 
Epoch [122/300] Training [21/62] Loss: 0.15377 
Epoch [122/300] Training [22/62] Loss: 0.08639 
Epoch [122/300] Training [23/62] Loss: 0.13308 
Epoch [122/300] Training [24/62] Loss: 0.13473 
Epoch [122/300] Training [25/62] Loss: 0.17035 
Epoch [122/300] Training [26/62] Loss: 0.16952 
Epoch [122/300] Training [27/62] Loss: 0.08654 
Epoch [122/300] Training [28/62] Loss: 0.12797 
Epoch [122/300] Training [29/62] Loss: 0.09320 
Epoch [122/300] Training [30/62] Loss: 0.21262 
Epoch [122/300] Training [31/62] Loss: 0.12040 
Epoch [122/300] Training [32/62] Loss: 0.11054 
Epoch [122/300] Training [33/62] Loss: 0.13188 
Epoch [122/300] Training [34/62] Loss: 0.09894 
Epoch [122/300] Training [35/62] Loss: 0.10259 
Epoch [122/300] Training [36/62] Loss: 0.21505 
Epoch [122/300] Training [37/62] Loss: 0.08029 
Epoch [122/300] Training [38/62] Loss: 0.15762 
Epoch [122/300] Training [39/62] Loss: 0.09646 
Epoch [122/300] Training [40/62] Loss: 0.28448 
Epoch [122/300] Training [41/62] Loss: 0.11972 
Epoch [122/300] Training [42/62] Loss: 0.09282 
Epoch [122/300] Training [43/62] Loss: 0.15476 
Epoch [122/300] Training [44/62] Loss: 0.16711 
Epoch [122/300] Training [45/62] Loss: 0.11105 
Epoch [122/300] Training [46/62] Loss: 0.08911 
Epoch [122/300] Training [47/62] Loss: 0.07857 
Epoch [122/300] Training [48/62] Loss: 0.21293 
Epoch [122/300] Training [49/62] Loss: 0.16490 
Epoch [122/300] Training [50/62] Loss: 0.17689 
Epoch [122/300] Training [51/62] Loss: 0.12729 
Epoch [122/300] Training [52/62] Loss: 0.07097 
Epoch [122/300] Training [53/62] Loss: 0.10230 
Epoch [122/300] Training [54/62] Loss: 0.21417 
Epoch [122/300] Training [55/62] Loss: 0.19209 
Epoch [122/300] Training [56/62] Loss: 0.28704 
Epoch [122/300] Training [57/62] Loss: 0.08640 
Epoch [122/300] Training [58/62] Loss: 0.11207 
Epoch [122/300] Training [59/62] Loss: 0.10958 
Epoch [122/300] Training [60/62] Loss: 0.20096 
Epoch [122/300] Training [61/62] Loss: 0.28677 
Epoch [122/300] Training [62/62] Loss: 0.06898 
Epoch [122/300] Training metric {'Train/mean dice_metric': 0.8923393487930298, 'Train/mean miou_metric': 0.8218861818313599, 'Train/mean f1': 0.9036121964454651, 'Train/mean precision': 0.893129289150238, 'Train/mean recall': 0.9143441319465637, 'Train/mean hd95_metric': 23.020736694335938}
Epoch [122/300] Validation [1/16] Loss: 0.21035  focal_loss 0.05569  dice_loss 0.15466 
Epoch [122/300] Validation [2/16] Loss: 0.32669  focal_loss 0.09656  dice_loss 0.23013 
Epoch [122/300] Validation [3/16] Loss: 0.61703  focal_loss 0.21954  dice_loss 0.39750 
Epoch [122/300] Validation [4/16] Loss: 0.28463  focal_loss 0.08862  dice_loss 0.19601 
Epoch [122/300] Validation [5/16] Loss: 0.24707  focal_loss 0.05342  dice_loss 0.19365 
Epoch [122/300] Validation [6/16] Loss: 0.20254  focal_loss 0.03780  dice_loss 0.16475 
Epoch [122/300] Validation [7/16] Loss: 0.25763  focal_loss 0.10363  dice_loss 0.15401 
Epoch [122/300] Validation [8/16] Loss: 0.36356  focal_loss 0.09855  dice_loss 0.26500 
Epoch [122/300] Validation [9/16] Loss: 0.24699  focal_loss 0.06993  dice_loss 0.17706 
Epoch [122/300] Validation [10/16] Loss: 0.39762  focal_loss 0.13070  dice_loss 0.26691 
Epoch [122/300] Validation [11/16] Loss: 0.15497  focal_loss 0.03812  dice_loss 0.11685 
Epoch [122/300] Validation [12/16] Loss: 0.30383  focal_loss 0.06731  dice_loss 0.23652 
Epoch [122/300] Validation [13/16] Loss: 0.19782  focal_loss 0.05052  dice_loss 0.14731 
Epoch [122/300] Validation [14/16] Loss: 0.48982  focal_loss 0.15112  dice_loss 0.33870 
Epoch [122/300] Validation [15/16] Loss: 0.22858  focal_loss 0.06394  dice_loss 0.16464 
Epoch [122/300] Validation [16/16] Loss: 0.04950  focal_loss 0.00900  dice_loss 0.04051 
Epoch [122/300] Validation metric {'Val/mean dice_metric': 0.8751769065856934, 'Val/mean miou_metric': 0.8008719682693481, 'Val/mean f1': 0.8847568035125732, 'Val/mean precision': 0.8767694234848022, 'Val/mean recall': 0.8928910493850708, 'Val/mean hd95_metric': 26.5111083984375}
Cheakpoint...
Epoch [122/300] best acc:tensor([0.8876], device='cuda:0'), Now : mean acc: tensor([0.8752], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8751769065856934, 'Val/mean miou_metric': 0.8008719682693481, 'Val/mean f1': 0.8847568035125732, 'Val/mean precision': 0.8767694234848022, 'Val/mean recall': 0.8928910493850708, 'Val/mean hd95_metric': 26.5111083984375}
Epoch [123/300] Training [1/62] Loss: 0.16142 
Epoch [123/300] Training [2/62] Loss: 0.13605 
Epoch [123/300] Training [3/62] Loss: 0.15218 
Epoch [123/300] Training [4/62] Loss: 0.27201 
Epoch [123/300] Training [5/62] Loss: 0.14699 
Epoch [123/300] Training [6/62] Loss: 0.13539 
Epoch [123/300] Training [7/62] Loss: 0.11910 
Epoch [123/300] Training [8/62] Loss: 0.24564 
Epoch [123/300] Training [9/62] Loss: 0.12592 
Epoch [123/300] Training [10/62] Loss: 0.07211 
Epoch [123/300] Training [11/62] Loss: 0.15066 
Epoch [123/300] Training [12/62] Loss: 0.12747 
Epoch [123/300] Training [13/62] Loss: 0.12440 
Epoch [123/300] Training [14/62] Loss: 0.16226 
Epoch [123/300] Training [15/62] Loss: 0.18933 
Epoch [123/300] Training [16/62] Loss: 0.15731 
Epoch [123/300] Training [17/62] Loss: 0.24217 
Epoch [123/300] Training [18/62] Loss: 0.23204 
Epoch [123/300] Training [19/62] Loss: 0.11951 
Epoch [123/300] Training [20/62] Loss: 0.15228 
Epoch [123/300] Training [21/62] Loss: 0.24076 
Epoch [123/300] Training [22/62] Loss: 0.14389 
Epoch [123/300] Training [23/62] Loss: 0.18569 
Epoch [123/300] Training [24/62] Loss: 0.09233 
Epoch [123/300] Training [25/62] Loss: 0.08530 
Epoch [123/300] Training [26/62] Loss: 0.08675 
Epoch [123/300] Training [27/62] Loss: 0.09218 
Epoch [123/300] Training [28/62] Loss: 0.19487 
Epoch [123/300] Training [29/62] Loss: 0.19905 
Epoch [123/300] Training [30/62] Loss: 0.19881 
Epoch [123/300] Training [31/62] Loss: 0.11519 
Epoch [123/300] Training [32/62] Loss: 0.09698 
Epoch [123/300] Training [33/62] Loss: 0.18141 
Epoch [123/300] Training [34/62] Loss: 0.17084 
Epoch [123/300] Training [35/62] Loss: 0.14347 
Epoch [123/300] Training [36/62] Loss: 0.29661 
Epoch [123/300] Training [37/62] Loss: 0.10728 
Epoch [123/300] Training [38/62] Loss: 0.15196 
Epoch [123/300] Training [39/62] Loss: 0.10173 
Epoch [123/300] Training [40/62] Loss: 0.14652 
Epoch [123/300] Training [41/62] Loss: 0.20396 
Epoch [123/300] Training [42/62] Loss: 0.07877 
Epoch [123/300] Training [43/62] Loss: 0.08446 
Epoch [123/300] Training [44/62] Loss: 0.10588 
Epoch [123/300] Training [45/62] Loss: 0.14364 
Epoch [123/300] Training [46/62] Loss: 0.19067 
Epoch [123/300] Training [47/62] Loss: 0.24410 
Epoch [123/300] Training [48/62] Loss: 0.17254 
Epoch [123/300] Training [49/62] Loss: 0.14601 
Epoch [123/300] Training [50/62] Loss: 0.22807 
Epoch [123/300] Training [51/62] Loss: 0.11907 
Epoch [123/300] Training [52/62] Loss: 0.15571 
Epoch [123/300] Training [53/62] Loss: 0.08282 
Epoch [123/300] Training [54/62] Loss: 0.11710 
Epoch [123/300] Training [55/62] Loss: 0.13178 
Epoch [123/300] Training [56/62] Loss: 0.15091 
Epoch [123/300] Training [57/62] Loss: 0.14216 
Epoch [123/300] Training [58/62] Loss: 0.12948 
Epoch [123/300] Training [59/62] Loss: 0.13617 
Epoch [123/300] Training [60/62] Loss: 0.22648 
Epoch [123/300] Training [61/62] Loss: 0.16108 
Epoch [123/300] Training [62/62] Loss: 0.06981 
Epoch [123/300] Training metric {'Train/mean dice_metric': 0.8938171863555908, 'Train/mean miou_metric': 0.8264595866203308, 'Train/mean f1': 0.9103528261184692, 'Train/mean precision': 0.9011971950531006, 'Train/mean recall': 0.9196963906288147, 'Train/mean hd95_metric': 19.317485809326172}
Epoch [123/300] Validation [1/16] Loss: 0.38412  focal_loss 0.24337  dice_loss 0.14075 
Epoch [123/300] Validation [2/16] Loss: 0.42116  focal_loss 0.13575  dice_loss 0.28541 
Epoch [123/300] Validation [3/16] Loss: 0.92239  focal_loss 0.50716  dice_loss 0.41523 
Epoch [123/300] Validation [4/16] Loss: 0.21775  focal_loss 0.08686  dice_loss 0.13089 
Epoch [123/300] Validation [5/16] Loss: 0.45819  focal_loss 0.18118  dice_loss 0.27701 
Epoch [123/300] Validation [6/16] Loss: 0.31325  focal_loss 0.09061  dice_loss 0.22264 
Epoch [123/300] Validation [7/16] Loss: 0.23192  focal_loss 0.09470  dice_loss 0.13722 
Epoch [123/300] Validation [8/16] Loss: 0.47508  focal_loss 0.12254  dice_loss 0.35255 
Epoch [123/300] Validation [9/16] Loss: 0.27893  focal_loss 0.10461  dice_loss 0.17432 
Epoch [123/300] Validation [10/16] Loss: 0.38733  focal_loss 0.14291  dice_loss 0.24443 
Epoch [123/300] Validation [11/16] Loss: 0.21330  focal_loss 0.04836  dice_loss 0.16494 
Epoch [123/300] Validation [12/16] Loss: 0.36305  focal_loss 0.10401  dice_loss 0.25903 
Epoch [123/300] Validation [13/16] Loss: 0.23959  focal_loss 0.07347  dice_loss 0.16613 
Epoch [123/300] Validation [14/16] Loss: 0.34645  focal_loss 0.12314  dice_loss 0.22331 
Epoch [123/300] Validation [15/16] Loss: 0.10850  focal_loss 0.03070  dice_loss 0.07779 
Epoch [123/300] Validation [16/16] Loss: 0.09089  focal_loss 0.02624  dice_loss 0.06465 
Epoch [123/300] Validation metric {'Val/mean dice_metric': 0.8739454746246338, 'Val/mean miou_metric': 0.802629828453064, 'Val/mean f1': 0.888809859752655, 'Val/mean precision': 0.873174250125885, 'Val/mean recall': 0.9050155878067017, 'Val/mean hd95_metric': 24.7721004486084}
Cheakpoint...
Epoch [123/300] best acc:tensor([0.8876], device='cuda:0'), Now : mean acc: tensor([0.8739], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8739454746246338, 'Val/mean miou_metric': 0.802629828453064, 'Val/mean f1': 0.888809859752655, 'Val/mean precision': 0.873174250125885, 'Val/mean recall': 0.9050155878067017, 'Val/mean hd95_metric': 24.7721004486084}
Epoch [124/300] Training [1/62] Loss: 0.08592 
Epoch [124/300] Training [2/62] Loss: 0.15666 
Epoch [124/300] Training [3/62] Loss: 0.19776 
Epoch [124/300] Training [4/62] Loss: 0.08834 
Epoch [124/300] Training [5/62] Loss: 0.18361 
Epoch [124/300] Training [6/62] Loss: 0.14422 
Epoch [124/300] Training [7/62] Loss: 0.20098 
Epoch [124/300] Training [8/62] Loss: 0.23002 
Epoch [124/300] Training [9/62] Loss: 0.16766 
Epoch [124/300] Training [10/62] Loss: 0.10936 
Epoch [124/300] Training [11/62] Loss: 0.16953 
Epoch [124/300] Training [12/62] Loss: 0.17231 
Epoch [124/300] Training [13/62] Loss: 0.12358 
Epoch [124/300] Training [14/62] Loss: 0.14983 
Epoch [124/300] Training [15/62] Loss: 0.06351 
Epoch [124/300] Training [16/62] Loss: 0.13117 
Epoch [124/300] Training [17/62] Loss: 0.13403 
Epoch [124/300] Training [18/62] Loss: 0.11363 
Epoch [124/300] Training [19/62] Loss: 0.16187 
Epoch [124/300] Training [20/62] Loss: 0.15052 
Epoch [124/300] Training [21/62] Loss: 0.12648 
Epoch [124/300] Training [22/62] Loss: 0.10563 
Epoch [124/300] Training [23/62] Loss: 0.11900 
Epoch [124/300] Training [24/62] Loss: 0.18453 
Epoch [124/300] Training [25/62] Loss: 0.08697 
Epoch [124/300] Training [26/62] Loss: 0.10863 
Epoch [124/300] Training [27/62] Loss: 0.15323 
Epoch [124/300] Training [28/62] Loss: 0.17439 
Epoch [124/300] Training [29/62] Loss: 0.08102 
Epoch [124/300] Training [30/62] Loss: 0.16106 
Epoch [124/300] Training [31/62] Loss: 0.14894 
Epoch [124/300] Training [32/62] Loss: 0.09639 
Epoch [124/300] Training [33/62] Loss: 0.08996 
Epoch [124/300] Training [34/62] Loss: 0.17341 
Epoch [124/300] Training [35/62] Loss: 0.22754 
Epoch [124/300] Training [36/62] Loss: 0.15572 
Epoch [124/300] Training [37/62] Loss: 0.10837 
Epoch [124/300] Training [38/62] Loss: 0.09577 
Epoch [124/300] Training [39/62] Loss: 0.13854 
Epoch [124/300] Training [40/62] Loss: 0.11256 
Epoch [124/300] Training [41/62] Loss: 0.08918 
Epoch [124/300] Training [42/62] Loss: 0.10378 
Epoch [124/300] Training [43/62] Loss: 0.17344 
Epoch [124/300] Training [44/62] Loss: 0.10574 
Epoch [124/300] Training [45/62] Loss: 0.23596 
Epoch [124/300] Training [46/62] Loss: 0.18676 
Epoch [124/300] Training [47/62] Loss: 0.15725 
Epoch [124/300] Training [48/62] Loss: 0.16909 
Epoch [124/300] Training [49/62] Loss: 0.10224 
Epoch [124/300] Training [50/62] Loss: 0.12489 
Epoch [124/300] Training [51/62] Loss: 0.27713 
Epoch [124/300] Training [52/62] Loss: 0.13360 
Epoch [124/300] Training [53/62] Loss: 0.12647 
Epoch [124/300] Training [54/62] Loss: 0.08793 
Epoch [124/300] Training [55/62] Loss: 0.13615 
Epoch [124/300] Training [56/62] Loss: 0.09142 
Epoch [124/300] Training [57/62] Loss: 0.08332 
Epoch [124/300] Training [58/62] Loss: 0.09807 
Epoch [124/300] Training [59/62] Loss: 0.08432 
Epoch [124/300] Training [60/62] Loss: 0.11093 
Epoch [124/300] Training [61/62] Loss: 0.11679 
Epoch [124/300] Training [62/62] Loss: 0.03724 
Epoch [124/300] Training metric {'Train/mean dice_metric': 0.9057244062423706, 'Train/mean miou_metric': 0.8400505781173706, 'Train/mean f1': 0.9205030202865601, 'Train/mean precision': 0.9152624607086182, 'Train/mean recall': 0.9258038997650146, 'Train/mean hd95_metric': 18.60915184020996}
Epoch [124/300] Validation [1/16] Loss: 0.29875  focal_loss 0.14553  dice_loss 0.15322 
Epoch [124/300] Validation [2/16] Loss: 0.37131  focal_loss 0.13355  dice_loss 0.23776 
Epoch [124/300] Validation [3/16] Loss: 0.83049  focal_loss 0.42755  dice_loss 0.40294 
Epoch [124/300] Validation [4/16] Loss: 0.43682  focal_loss 0.20506  dice_loss 0.23175 
Epoch [124/300] Validation [5/16] Loss: 0.36269  focal_loss 0.13046  dice_loss 0.23223 
Epoch [124/300] Validation [6/16] Loss: 0.36050  focal_loss 0.12356  dice_loss 0.23694 
Epoch [124/300] Validation [7/16] Loss: 0.25990  focal_loss 0.07488  dice_loss 0.18502 
Epoch [124/300] Validation [8/16] Loss: 0.38375  focal_loss 0.11590  dice_loss 0.26785 
Epoch [124/300] Validation [9/16] Loss: 0.30992  focal_loss 0.12187  dice_loss 0.18805 
Epoch [124/300] Validation [10/16] Loss: 0.36678  focal_loss 0.10067  dice_loss 0.26611 
Epoch [124/300] Validation [11/16] Loss: 0.11584  focal_loss 0.02444  dice_loss 0.09140 
Epoch [124/300] Validation [12/16] Loss: 0.41308  focal_loss 0.08718  dice_loss 0.32591 
Epoch [124/300] Validation [13/16] Loss: 0.28153  focal_loss 0.07531  dice_loss 0.20622 
Epoch [124/300] Validation [14/16] Loss: 0.61232  focal_loss 0.20130  dice_loss 0.41101 
Epoch [124/300] Validation [15/16] Loss: 0.13287  focal_loss 0.03751  dice_loss 0.09537 
Epoch [124/300] Validation [16/16] Loss: 0.12520  focal_loss 0.05059  dice_loss 0.07461 
Epoch [124/300] Validation metric {'Val/mean dice_metric': 0.8800348043441772, 'Val/mean miou_metric': 0.809857964515686, 'Val/mean f1': 0.8943920135498047, 'Val/mean precision': 0.8894115090370178, 'Val/mean recall': 0.8994286060333252, 'Val/mean hd95_metric': 24.65846824645996}
Cheakpoint...
Epoch [124/300] best acc:tensor([0.8876], device='cuda:0'), Now : mean acc: tensor([0.8800], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8800348043441772, 'Val/mean miou_metric': 0.809857964515686, 'Val/mean f1': 0.8943920135498047, 'Val/mean precision': 0.8894115090370178, 'Val/mean recall': 0.8994286060333252, 'Val/mean hd95_metric': 24.65846824645996}
Epoch [125/300] Training [1/62] Loss: 0.08964 
Epoch [125/300] Training [2/62] Loss: 0.08028 
Epoch [125/300] Training [3/62] Loss: 0.11238 
Epoch [125/300] Training [4/62] Loss: 0.13311 
Epoch [125/300] Training [5/62] Loss: 0.13334 
Epoch [125/300] Training [6/62] Loss: 0.19384 
Epoch [125/300] Training [7/62] Loss: 0.11791 
Epoch [125/300] Training [8/62] Loss: 0.10141 
Epoch [125/300] Training [9/62] Loss: 0.09570 
Epoch [125/300] Training [10/62] Loss: 0.06872 
Epoch [125/300] Training [11/62] Loss: 0.10097 
Epoch [125/300] Training [12/62] Loss: 0.12197 
Epoch [125/300] Training [13/62] Loss: 0.09989 
Epoch [125/300] Training [14/62] Loss: 0.07845 
Epoch [125/300] Training [15/62] Loss: 0.06279 
Epoch [125/300] Training [16/62] Loss: 0.13234 
Epoch [125/300] Training [17/62] Loss: 0.20811 
Epoch [125/300] Training [18/62] Loss: 0.14651 
Epoch [125/300] Training [19/62] Loss: 0.14491 
Epoch [125/300] Training [20/62] Loss: 0.13936 
Epoch [125/300] Training [21/62] Loss: 0.09708 
Epoch [125/300] Training [22/62] Loss: 0.15467 
Epoch [125/300] Training [23/62] Loss: 0.09744 
Epoch [125/300] Training [24/62] Loss: 0.09109 
Epoch [125/300] Training [25/62] Loss: 0.09907 
Epoch [125/300] Training [26/62] Loss: 0.12175 
Epoch [125/300] Training [27/62] Loss: 0.24026 
Epoch [125/300] Training [28/62] Loss: 0.20280 
Epoch [125/300] Training [29/62] Loss: 0.09749 
Epoch [125/300] Training [30/62] Loss: 0.09975 
Epoch [125/300] Training [31/62] Loss: 0.10847 
Epoch [125/300] Training [32/62] Loss: 0.24332 
Epoch [125/300] Training [33/62] Loss: 0.14255 
Epoch [125/300] Training [34/62] Loss: 0.12616 
Epoch [125/300] Training [35/62] Loss: 0.08700 
Epoch [125/300] Training [36/62] Loss: 0.09045 
Epoch [125/300] Training [37/62] Loss: 0.06972 
Epoch [125/300] Training [38/62] Loss: 0.13865 
Epoch [125/300] Training [39/62] Loss: 0.07272 
Epoch [125/300] Training [40/62] Loss: 0.20358 
Epoch [125/300] Training [41/62] Loss: 0.12510 
Epoch [125/300] Training [42/62] Loss: 0.10344 
Epoch [125/300] Training [43/62] Loss: 0.12569 
Epoch [125/300] Training [44/62] Loss: 0.10004 
Epoch [125/300] Training [45/62] Loss: 0.11602 
Epoch [125/300] Training [46/62] Loss: 0.18986 
Epoch [125/300] Training [47/62] Loss: 0.11596 
Epoch [125/300] Training [48/62] Loss: 0.13608 
Epoch [125/300] Training [49/62] Loss: 0.16162 
Epoch [125/300] Training [50/62] Loss: 0.15294 
Epoch [125/300] Training [51/62] Loss: 0.20533 
Epoch [125/300] Training [52/62] Loss: 0.11465 
Epoch [125/300] Training [53/62] Loss: 0.13387 
Epoch [125/300] Training [54/62] Loss: 0.14017 
Epoch [125/300] Training [55/62] Loss: 0.18718 
Epoch [125/300] Training [56/62] Loss: 0.08629 
Epoch [125/300] Training [57/62] Loss: 0.23665 
Epoch [125/300] Training [58/62] Loss: 0.10760 
Epoch [125/300] Training [59/62] Loss: 0.13887 
Epoch [125/300] Training [60/62] Loss: 0.16736 
Epoch [125/300] Training [61/62] Loss: 0.15097 
Epoch [125/300] Training [62/62] Loss: 0.03518 
Epoch [125/300] Training metric {'Train/mean dice_metric': 0.9087515473365784, 'Train/mean miou_metric': 0.8462390899658203, 'Train/mean f1': 0.9247763156890869, 'Train/mean precision': 0.9186449646949768, 'Train/mean recall': 0.9309901595115662, 'Train/mean hd95_metric': 17.57955551147461}
Epoch [125/300] Validation [1/16] Loss: 0.27893  focal_loss 0.11141  dice_loss 0.16751 
Epoch [125/300] Validation [2/16] Loss: 0.37731  focal_loss 0.13306  dice_loss 0.24425 
Epoch [125/300] Validation [3/16] Loss: 0.61968  focal_loss 0.31200  dice_loss 0.30768 
Epoch [125/300] Validation [4/16] Loss: 0.29049  focal_loss 0.12641  dice_loss 0.16408 
Epoch [125/300] Validation [5/16] Loss: 0.49600  focal_loss 0.17361  dice_loss 0.32239 
Epoch [125/300] Validation [6/16] Loss: 0.21640  focal_loss 0.04770  dice_loss 0.16871 
Epoch [125/300] Validation [7/16] Loss: 0.22369  focal_loss 0.08453  dice_loss 0.13916 
Epoch [125/300] Validation [8/16] Loss: 0.34846  focal_loss 0.07019  dice_loss 0.27827 
Epoch [125/300] Validation [9/16] Loss: 0.24659  focal_loss 0.09379  dice_loss 0.15280 
Epoch [125/300] Validation [10/16] Loss: 0.44072  focal_loss 0.17521  dice_loss 0.26550 
Epoch [125/300] Validation [11/16] Loss: 0.19503  focal_loss 0.06312  dice_loss 0.13191 
Epoch [125/300] Validation [12/16] Loss: 0.36158  focal_loss 0.12553  dice_loss 0.23605 
Epoch [125/300] Validation [13/16] Loss: 0.22885  focal_loss 0.06090  dice_loss 0.16795 
Epoch [125/300] Validation [14/16] Loss: 0.53578  focal_loss 0.17481  dice_loss 0.36096 
Epoch [125/300] Validation [15/16] Loss: 0.08837  focal_loss 0.01782  dice_loss 0.07055 
Epoch [125/300] Validation [16/16] Loss: 0.06946  focal_loss 0.01154  dice_loss 0.05792 
Epoch [125/300] Validation metric {'Val/mean dice_metric': 0.8874125480651855, 'Val/mean miou_metric': 0.8197682499885559, 'Val/mean f1': 0.8995221853256226, 'Val/mean precision': 0.8863162398338318, 'Val/mean recall': 0.9131276607513428, 'Val/mean hd95_metric': 23.55594253540039}
Cheakpoint...
Epoch [125/300] best acc:tensor([0.8876], device='cuda:0'), Now : mean acc: tensor([0.8874], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8874125480651855, 'Val/mean miou_metric': 0.8197682499885559, 'Val/mean f1': 0.8995221853256226, 'Val/mean precision': 0.8863162398338318, 'Val/mean recall': 0.9131276607513428, 'Val/mean hd95_metric': 23.55594253540039}
Epoch [126/300] Training [1/62] Loss: 0.13708 
Epoch [126/300] Training [2/62] Loss: 0.07325 
Epoch [126/300] Training [3/62] Loss: 0.15122 
Epoch [126/300] Training [4/62] Loss: 0.07236 
Epoch [126/300] Training [5/62] Loss: 0.14358 
Epoch [126/300] Training [6/62] Loss: 0.35552 
Epoch [126/300] Training [7/62] Loss: 0.16208 
Epoch [126/300] Training [8/62] Loss: 0.14169 
Epoch [126/300] Training [9/62] Loss: 0.15234 
Epoch [126/300] Training [10/62] Loss: 0.14725 
Epoch [126/300] Training [11/62] Loss: 0.09136 
Epoch [126/300] Training [12/62] Loss: 0.11070 
Epoch [126/300] Training [13/62] Loss: 0.09789 
Epoch [126/300] Training [14/62] Loss: 0.15125 
Epoch [126/300] Training [15/62] Loss: 0.14795 
Epoch [126/300] Training [16/62] Loss: 0.17451 
Epoch [126/300] Training [17/62] Loss: 0.11742 
Epoch [126/300] Training [18/62] Loss: 0.09355 
Epoch [126/300] Training [19/62] Loss: 0.15741 
Epoch [126/300] Training [20/62] Loss: 0.14049 
Epoch [126/300] Training [21/62] Loss: 0.18862 
Epoch [126/300] Training [22/62] Loss: 0.08576 
Epoch [126/300] Training [23/62] Loss: 0.14822 
Epoch [126/300] Training [24/62] Loss: 0.07674 
Epoch [126/300] Training [25/62] Loss: 0.12521 
Epoch [126/300] Training [26/62] Loss: 0.10377 
Epoch [126/300] Training [27/62] Loss: 0.15607 
Epoch [126/300] Training [28/62] Loss: 0.09281 
Epoch [126/300] Training [29/62] Loss: 0.20813 
Epoch [126/300] Training [30/62] Loss: 0.14404 
Epoch [126/300] Training [31/62] Loss: 0.15687 
Epoch [126/300] Training [32/62] Loss: 0.15269 
Epoch [126/300] Training [33/62] Loss: 0.18591 
Epoch [126/300] Training [34/62] Loss: 0.15811 
Epoch [126/300] Training [35/62] Loss: 0.13913 
Epoch [126/300] Training [36/62] Loss: 0.12450 
Epoch [126/300] Training [37/62] Loss: 0.13119 
Epoch [126/300] Training [38/62] Loss: 0.20017 
Epoch [126/300] Training [39/62] Loss: 0.22548 
Epoch [126/300] Training [40/62] Loss: 0.10181 
Epoch [126/300] Training [41/62] Loss: 0.11195 
Epoch [126/300] Training [42/62] Loss: 0.11302 
Epoch [126/300] Training [43/62] Loss: 0.12988 
Epoch [126/300] Training [44/62] Loss: 0.06918 
Epoch [126/300] Training [45/62] Loss: 0.11474 
Epoch [126/300] Training [46/62] Loss: 0.12895 
Epoch [126/300] Training [47/62] Loss: 0.17142 
Epoch [126/300] Training [48/62] Loss: 0.14374 
Epoch [126/300] Training [49/62] Loss: 0.08325 
Epoch [126/300] Training [50/62] Loss: 0.21506 
Epoch [126/300] Training [51/62] Loss: 0.09872 
Epoch [126/300] Training [52/62] Loss: 0.18840 
Epoch [126/300] Training [53/62] Loss: 0.13198 
Epoch [126/300] Training [54/62] Loss: 0.09175 
Epoch [126/300] Training [55/62] Loss: 0.17448 
Epoch [126/300] Training [56/62] Loss: 0.12083 
Epoch [126/300] Training [57/62] Loss: 0.18927 
Epoch [126/300] Training [58/62] Loss: 0.10028 
Epoch [126/300] Training [59/62] Loss: 0.12136 
Epoch [126/300] Training [60/62] Loss: 0.08627 
Epoch [126/300] Training [61/62] Loss: 0.10712 
Epoch [126/300] Training [62/62] Loss: 0.09207 
Epoch [126/300] Training metric {'Train/mean dice_metric': 0.9046158790588379, 'Train/mean miou_metric': 0.8409401178359985, 'Train/mean f1': 0.9198870658874512, 'Train/mean precision': 0.9078293442726135, 'Train/mean recall': 0.9322693943977356, 'Train/mean hd95_metric': 17.608312606811523}
Epoch [126/300] Validation [1/16] Loss: 0.18381  focal_loss 0.05928  dice_loss 0.12453 
Epoch [126/300] Validation [2/16] Loss: 0.37822  focal_loss 0.13093  dice_loss 0.24729 
Epoch [126/300] Validation [3/16] Loss: 0.36763  focal_loss 0.09383  dice_loss 0.27379 
Epoch [126/300] Validation [4/16] Loss: 0.29194  focal_loss 0.12662  dice_loss 0.16532 
Epoch [126/300] Validation [5/16] Loss: 0.51446  focal_loss 0.13762  dice_loss 0.37684 
Epoch [126/300] Validation [6/16] Loss: 0.24757  focal_loss 0.05261  dice_loss 0.19496 
Epoch [126/300] Validation [7/16] Loss: 0.19095  focal_loss 0.05715  dice_loss 0.13380 
Epoch [126/300] Validation [8/16] Loss: 0.31463  focal_loss 0.09142  dice_loss 0.22320 
Epoch [126/300] Validation [9/16] Loss: 0.22804  focal_loss 0.08125  dice_loss 0.14679 
Epoch [126/300] Validation [10/16] Loss: 0.25356  focal_loss 0.06341  dice_loss 0.19015 
Epoch [126/300] Validation [11/16] Loss: 0.10493  focal_loss 0.02007  dice_loss 0.08486 
Epoch [126/300] Validation [12/16] Loss: 0.32595  focal_loss 0.06541  dice_loss 0.26054 
Epoch [126/300] Validation [13/16] Loss: 0.29428  focal_loss 0.08382  dice_loss 0.21046 
Epoch [126/300] Validation [14/16] Loss: 0.46908  focal_loss 0.14412  dice_loss 0.32496 
Epoch [126/300] Validation [15/16] Loss: 0.17707  focal_loss 0.04782  dice_loss 0.12925 
Epoch [126/300] Validation [16/16] Loss: 0.09239  focal_loss 0.01953  dice_loss 0.07286 
Epoch [126/300] Validation metric {'Val/mean dice_metric': 0.8853306770324707, 'Val/mean miou_metric': 0.8186748027801514, 'Val/mean f1': 0.8992485404014587, 'Val/mean precision': 0.892998218536377, 'Val/mean recall': 0.9055871963500977, 'Val/mean hd95_metric': 22.749231338500977}
Cheakpoint...
Epoch [126/300] best acc:tensor([0.8876], device='cuda:0'), Now : mean acc: tensor([0.8853], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8853306770324707, 'Val/mean miou_metric': 0.8186748027801514, 'Val/mean f1': 0.8992485404014587, 'Val/mean precision': 0.892998218536377, 'Val/mean recall': 0.9055871963500977, 'Val/mean hd95_metric': 22.749231338500977}
Epoch [127/300] Training [1/62] Loss: 0.10968 
Epoch [127/300] Training [2/62] Loss: 0.07818 
Epoch [127/300] Training [3/62] Loss: 0.37220 
Epoch [127/300] Training [4/62] Loss: 0.11601 
Epoch [127/300] Training [5/62] Loss: 0.16521 
Epoch [127/300] Training [6/62] Loss: 0.12153 
Epoch [127/300] Training [7/62] Loss: 0.11221 
Epoch [127/300] Training [8/62] Loss: 0.14270 
Epoch [127/300] Training [9/62] Loss: 0.27744 
Epoch [127/300] Training [10/62] Loss: 0.10230 
Epoch [127/300] Training [11/62] Loss: 0.09420 
Epoch [127/300] Training [12/62] Loss: 0.10038 
Epoch [127/300] Training [13/62] Loss: 0.10827 
Epoch [127/300] Training [14/62] Loss: 0.16807 
Epoch [127/300] Training [15/62] Loss: 0.07634 
Epoch [127/300] Training [16/62] Loss: 0.13247 
Epoch [127/300] Training [17/62] Loss: 0.10196 
Epoch [127/300] Training [18/62] Loss: 0.22348 
Epoch [127/300] Training [19/62] Loss: 0.08101 
Epoch [127/300] Training [20/62] Loss: 0.17012 
Epoch [127/300] Training [21/62] Loss: 0.14793 
Epoch [127/300] Training [22/62] Loss: 0.21979 
Epoch [127/300] Training [23/62] Loss: 0.08096 
Epoch [127/300] Training [24/62] Loss: 0.15018 
Epoch [127/300] Training [25/62] Loss: 0.14580 
Epoch [127/300] Training [26/62] Loss: 0.13502 
Epoch [127/300] Training [27/62] Loss: 0.10347 
Epoch [127/300] Training [28/62] Loss: 0.25860 
Epoch [127/300] Training [29/62] Loss: 0.15972 
Epoch [127/300] Training [30/62] Loss: 0.29841 
Epoch [127/300] Training [31/62] Loss: 0.09641 
Epoch [127/300] Training [32/62] Loss: 0.16938 
Epoch [127/300] Training [33/62] Loss: 0.21917 
Epoch [127/300] Training [34/62] Loss: 0.08172 
Epoch [127/300] Training [35/62] Loss: 0.24445 
Epoch [127/300] Training [36/62] Loss: 0.17328 
Epoch [127/300] Training [37/62] Loss: 0.14127 
Epoch [127/300] Training [38/62] Loss: 0.12808 
Epoch [127/300] Training [39/62] Loss: 0.09423 
Epoch [127/300] Training [40/62] Loss: 0.11470 
Epoch [127/300] Training [41/62] Loss: 0.07872 
Epoch [127/300] Training [42/62] Loss: 0.10541 
Epoch [127/300] Training [43/62] Loss: 0.12998 
Epoch [127/300] Training [44/62] Loss: 0.16263 
Epoch [127/300] Training [45/62] Loss: 0.13547 
Epoch [127/300] Training [46/62] Loss: 0.14789 
Epoch [127/300] Training [47/62] Loss: 0.12187 
Epoch [127/300] Training [48/62] Loss: 0.11634 
Epoch [127/300] Training [49/62] Loss: 0.08053 
Epoch [127/300] Training [50/62] Loss: 0.15505 
Epoch [127/300] Training [51/62] Loss: 0.12221 
Epoch [127/300] Training [52/62] Loss: 0.28929 
Epoch [127/300] Training [53/62] Loss: 0.09806 
Epoch [127/300] Training [54/62] Loss: 0.09568 
Epoch [127/300] Training [55/62] Loss: 0.11876 
Epoch [127/300] Training [56/62] Loss: 0.13607 
Epoch [127/300] Training [57/62] Loss: 0.11149 
Epoch [127/300] Training [58/62] Loss: 0.13553 
Epoch [127/300] Training [59/62] Loss: 0.29167 
Epoch [127/300] Training [60/62] Loss: 0.15575 
Epoch [127/300] Training [61/62] Loss: 0.12172 
Epoch [127/300] Training [62/62] Loss: 0.12027 
Epoch [127/300] Training metric {'Train/mean dice_metric': 0.8999760150909424, 'Train/mean miou_metric': 0.834100067615509, 'Train/mean f1': 0.9150395393371582, 'Train/mean precision': 0.9071558117866516, 'Train/mean recall': 0.9230614304542542, 'Train/mean hd95_metric': 19.060155868530273}
Epoch [127/300] Validation [1/16] Loss: 0.15581  focal_loss 0.04910  dice_loss 0.10671 
Epoch [127/300] Validation [2/16] Loss: 0.28063  focal_loss 0.08329  dice_loss 0.19734 
Epoch [127/300] Validation [3/16] Loss: 0.35453  focal_loss 0.09919  dice_loss 0.25534 
Epoch [127/300] Validation [4/16] Loss: 0.36358  focal_loss 0.16071  dice_loss 0.20287 
Epoch [127/300] Validation [5/16] Loss: 0.43225  focal_loss 0.14930  dice_loss 0.28294 
Epoch [127/300] Validation [6/16] Loss: 0.34740  focal_loss 0.13321  dice_loss 0.21419 
Epoch [127/300] Validation [7/16] Loss: 0.22604  focal_loss 0.08022  dice_loss 0.14582 
Epoch [127/300] Validation [8/16] Loss: 0.48042  focal_loss 0.20658  dice_loss 0.27384 
Epoch [127/300] Validation [9/16] Loss: 0.15925  focal_loss 0.04396  dice_loss 0.11529 
Epoch [127/300] Validation [10/16] Loss: 0.28174  focal_loss 0.10312  dice_loss 0.17862 
Epoch [127/300] Validation [11/16] Loss: 0.12997  focal_loss 0.02781  dice_loss 0.10216 
Epoch [127/300] Validation [12/16] Loss: 0.28321  focal_loss 0.05328  dice_loss 0.22994 
Epoch [127/300] Validation [13/16] Loss: 0.25602  focal_loss 0.06288  dice_loss 0.19314 
Epoch [127/300] Validation [14/16] Loss: 0.50756  focal_loss 0.15602  dice_loss 0.35154 
Epoch [127/300] Validation [15/16] Loss: 0.14078  focal_loss 0.03387  dice_loss 0.10691 
Epoch [127/300] Validation [16/16] Loss: 0.05612  focal_loss 0.00966  dice_loss 0.04646 
Epoch [127/300] Validation metric {'Val/mean dice_metric': 0.8833991289138794, 'Val/mean miou_metric': 0.8133569955825806, 'Val/mean f1': 0.8947625756263733, 'Val/mean precision': 0.8890898823738098, 'Val/mean recall': 0.9005080461502075, 'Val/mean hd95_metric': 24.1070556640625}
Cheakpoint...
Epoch [127/300] best acc:tensor([0.8876], device='cuda:0'), Now : mean acc: tensor([0.8834], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8833991289138794, 'Val/mean miou_metric': 0.8133569955825806, 'Val/mean f1': 0.8947625756263733, 'Val/mean precision': 0.8890898823738098, 'Val/mean recall': 0.9005080461502075, 'Val/mean hd95_metric': 24.1070556640625}
Epoch [128/300] Training [1/62] Loss: 0.10232 
Epoch [128/300] Training [2/62] Loss: 0.12702 
Epoch [128/300] Training [3/62] Loss: 0.12424 
Epoch [128/300] Training [4/62] Loss: 0.12760 
Epoch [128/300] Training [5/62] Loss: 0.12936 
Epoch [128/300] Training [6/62] Loss: 0.07843 
Epoch [128/300] Training [7/62] Loss: 0.09370 
Epoch [128/300] Training [8/62] Loss: 0.07190 
Epoch [128/300] Training [9/62] Loss: 0.12072 
Epoch [128/300] Training [10/62] Loss: 0.09169 
Epoch [128/300] Training [11/62] Loss: 0.12466 
Epoch [128/300] Training [12/62] Loss: 0.10099 
Epoch [128/300] Training [13/62] Loss: 0.09521 
Epoch [128/300] Training [14/62] Loss: 0.15679 
Epoch [128/300] Training [15/62] Loss: 0.11385 
Epoch [128/300] Training [16/62] Loss: 0.13393 
Epoch [128/300] Training [17/62] Loss: 0.15284 
Epoch [128/300] Training [18/62] Loss: 0.09451 
Epoch [128/300] Training [19/62] Loss: 0.24376 
Epoch [128/300] Training [20/62] Loss: 0.11557 
Epoch [128/300] Training [21/62] Loss: 0.16050 
Epoch [128/300] Training [22/62] Loss: 0.12515 
Epoch [128/300] Training [23/62] Loss: 0.16803 
Epoch [128/300] Training [24/62] Loss: 0.08699 
Epoch [128/300] Training [25/62] Loss: 0.10529 
Epoch [128/300] Training [26/62] Loss: 0.08699 
Epoch [128/300] Training [27/62] Loss: 0.13983 
Epoch [128/300] Training [28/62] Loss: 0.22365 
Epoch [128/300] Training [29/62] Loss: 0.10252 
Epoch [128/300] Training [30/62] Loss: 0.13280 
Epoch [128/300] Training [31/62] Loss: 0.18596 
Epoch [128/300] Training [32/62] Loss: 0.09646 
Epoch [128/300] Training [33/62] Loss: 0.20207 
Epoch [128/300] Training [34/62] Loss: 0.26146 
Epoch [128/300] Training [35/62] Loss: 0.15010 
Epoch [128/300] Training [36/62] Loss: 0.19255 
Epoch [128/300] Training [37/62] Loss: 0.28701 
Epoch [128/300] Training [38/62] Loss: 0.16781 
Epoch [128/300] Training [39/62] Loss: 0.06546 
Epoch [128/300] Training [40/62] Loss: 0.17998 
Epoch [128/300] Training [41/62] Loss: 0.10236 
Epoch [128/300] Training [42/62] Loss: 0.08409 
Epoch [128/300] Training [43/62] Loss: 0.10899 
Epoch [128/300] Training [44/62] Loss: 0.11028 
Epoch [128/300] Training [45/62] Loss: 0.08917 
Epoch [128/300] Training [46/62] Loss: 0.16726 
Epoch [128/300] Training [47/62] Loss: 0.09058 
Epoch [128/300] Training [48/62] Loss: 0.10100 
Epoch [128/300] Training [49/62] Loss: 0.15039 
Epoch [128/300] Training [50/62] Loss: 0.11021 
Epoch [128/300] Training [51/62] Loss: 0.09425 
Epoch [128/300] Training [52/62] Loss: 0.12383 
Epoch [128/300] Training [53/62] Loss: 0.09964 
Epoch [128/300] Training [54/62] Loss: 0.12327 
Epoch [128/300] Training [55/62] Loss: 0.10260 
Epoch [128/300] Training [56/62] Loss: 0.10766 
Epoch [128/300] Training [57/62] Loss: 0.10591 
Epoch [128/300] Training [58/62] Loss: 0.08595 
Epoch [128/300] Training [59/62] Loss: 0.27392 
Epoch [128/300] Training [60/62] Loss: 0.07897 
Epoch [128/300] Training [61/62] Loss: 0.13007 
Epoch [128/300] Training [62/62] Loss: 0.23200 
Epoch [128/300] Training metric {'Train/mean dice_metric': 0.9090405106544495, 'Train/mean miou_metric': 0.8467555642127991, 'Train/mean f1': 0.9251497387886047, 'Train/mean precision': 0.9202929735183716, 'Train/mean recall': 0.9300581812858582, 'Train/mean hd95_metric': 17.817678451538086}
Epoch [128/300] Validation [1/16] Loss: 0.23519  focal_loss 0.07749  dice_loss 0.15770 
Epoch [128/300] Validation [2/16] Loss: 0.38134  focal_loss 0.12994  dice_loss 0.25140 
Epoch [128/300] Validation [3/16] Loss: 0.24586  focal_loss 0.04269  dice_loss 0.20317 
Epoch [128/300] Validation [4/16] Loss: 0.24759  focal_loss 0.10104  dice_loss 0.14655 
Epoch [128/300] Validation [5/16] Loss: 0.44309  focal_loss 0.12229  dice_loss 0.32080 
Epoch [128/300] Validation [6/16] Loss: 0.22641  focal_loss 0.04166  dice_loss 0.18475 
Epoch [128/300] Validation [7/16] Loss: 0.25028  focal_loss 0.07980  dice_loss 0.17048 
Epoch [128/300] Validation [8/16] Loss: 0.25691  focal_loss 0.05834  dice_loss 0.19857 
Epoch [128/300] Validation [9/16] Loss: 0.20284  focal_loss 0.04638  dice_loss 0.15646 
Epoch [128/300] Validation [10/16] Loss: 0.25041  focal_loss 0.06019  dice_loss 0.19022 
Epoch [128/300] Validation [11/16] Loss: 0.10446  focal_loss 0.02146  dice_loss 0.08300 
Epoch [128/300] Validation [12/16] Loss: 0.47981  focal_loss 0.12266  dice_loss 0.35715 
Epoch [128/300] Validation [13/16] Loss: 0.29497  focal_loss 0.11643  dice_loss 0.17853 
Epoch [128/300] Validation [14/16] Loss: 0.39299  focal_loss 0.11860  dice_loss 0.27439 
Epoch [128/300] Validation [15/16] Loss: 0.12755  focal_loss 0.03243  dice_loss 0.09512 
Epoch [128/300] Validation [16/16] Loss: 0.06526  focal_loss 0.01485  dice_loss 0.05040 
Epoch [128/300] Validation metric {'Val/mean dice_metric': 0.8913606405258179, 'Val/mean miou_metric': 0.8244808316230774, 'Val/mean f1': 0.9068877696990967, 'Val/mean precision': 0.8993022441864014, 'Val/mean recall': 0.9146024584770203, 'Val/mean hd95_metric': 23.428531646728516}
Cheakpoint...
Epoch [128/300] best acc:tensor([0.8914], device='cuda:0'), Now : mean acc: tensor([0.8914], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8913606405258179, 'Val/mean miou_metric': 0.8244808316230774, 'Val/mean f1': 0.9068877696990967, 'Val/mean precision': 0.8993022441864014, 'Val/mean recall': 0.9146024584770203, 'Val/mean hd95_metric': 23.428531646728516}
Epoch [129/300] Training [1/62] Loss: 0.13895 
Epoch [129/300] Training [2/62] Loss: 0.09022 
Epoch [129/300] Training [3/62] Loss: 0.08713 
Epoch [129/300] Training [4/62] Loss: 0.12850 
Epoch [129/300] Training [5/62] Loss: 0.17229 
Epoch [129/300] Training [6/62] Loss: 0.06965 
Epoch [129/300] Training [7/62] Loss: 0.18005 
Epoch [129/300] Training [8/62] Loss: 0.13154 
Epoch [129/300] Training [9/62] Loss: 0.22839 
Epoch [129/300] Training [10/62] Loss: 0.06755 
Epoch [129/300] Training [11/62] Loss: 0.09208 
Epoch [129/300] Training [12/62] Loss: 0.13816 
Epoch [129/300] Training [13/62] Loss: 0.18401 
Epoch [129/300] Training [14/62] Loss: 0.11348 
Epoch [129/300] Training [15/62] Loss: 0.14454 
Epoch [129/300] Training [16/62] Loss: 0.11080 
Epoch [129/300] Training [17/62] Loss: 0.16942 
Epoch [129/300] Training [18/62] Loss: 0.10521 
Epoch [129/300] Training [19/62] Loss: 0.15072 
Epoch [129/300] Training [20/62] Loss: 0.11825 
Epoch [129/300] Training [21/62] Loss: 0.24143 
Epoch [129/300] Training [22/62] Loss: 0.08766 
Epoch [129/300] Training [23/62] Loss: 0.16211 
Epoch [129/300] Training [24/62] Loss: 0.20436 
Epoch [129/300] Training [25/62] Loss: 0.13703 
Epoch [129/300] Training [26/62] Loss: 0.08173 
Epoch [129/300] Training [27/62] Loss: 0.14355 
Epoch [129/300] Training [28/62] Loss: 0.25810 
Epoch [129/300] Training [29/62] Loss: 0.08389 
Epoch [129/300] Training [30/62] Loss: 0.17158 
Epoch [129/300] Training [31/62] Loss: 0.25064 
Epoch [129/300] Training [32/62] Loss: 0.10613 
Epoch [129/300] Training [33/62] Loss: 0.16437 
Epoch [129/300] Training [34/62] Loss: 0.09355 
Epoch [129/300] Training [35/62] Loss: 0.16551 
Epoch [129/300] Training [36/62] Loss: 0.13666 
Epoch [129/300] Training [37/62] Loss: 0.17868 
Epoch [129/300] Training [38/62] Loss: 0.18831 
Epoch [129/300] Training [39/62] Loss: 0.23538 
Epoch [129/300] Training [40/62] Loss: 0.17704 
Epoch [129/300] Training [41/62] Loss: 0.42738 
Epoch [129/300] Training [42/62] Loss: 0.08513 
Epoch [129/300] Training [43/62] Loss: 0.07844 
Epoch [129/300] Training [44/62] Loss: 0.10796 
Epoch [129/300] Training [45/62] Loss: 0.20043 
Epoch [129/300] Training [46/62] Loss: 0.10372 
Epoch [129/300] Training [47/62] Loss: 0.13853 
Epoch [129/300] Training [48/62] Loss: 0.07445 
Epoch [129/300] Training [49/62] Loss: 0.06677 
Epoch [129/300] Training [50/62] Loss: 0.10037 
Epoch [129/300] Training [51/62] Loss: 0.13011 
Epoch [129/300] Training [52/62] Loss: 0.22270 
Epoch [129/300] Training [53/62] Loss: 0.06407 
Epoch [129/300] Training [54/62] Loss: 0.11566 
Epoch [129/300] Training [55/62] Loss: 0.23674 
Epoch [129/300] Training [56/62] Loss: 0.10195 
Epoch [129/300] Training [57/62] Loss: 0.14572 
Epoch [129/300] Training [58/62] Loss: 0.15507 
Epoch [129/300] Training [59/62] Loss: 0.10163 
Epoch [129/300] Training [60/62] Loss: 0.18084 
Epoch [129/300] Training [61/62] Loss: 0.20131 
Epoch [129/300] Training [62/62] Loss: 0.08021 
Epoch [129/300] Training metric {'Train/mean dice_metric': 0.8985671997070312, 'Train/mean miou_metric': 0.832736074924469, 'Train/mean f1': 0.914260745048523, 'Train/mean precision': 0.9089457392692566, 'Train/mean recall': 0.9196383357048035, 'Train/mean hd95_metric': 21.214693069458008}
Epoch [129/300] Validation [1/16] Loss: 0.14809  focal_loss 0.04449  dice_loss 0.10359 
Epoch [129/300] Validation [2/16] Loss: 0.31180  focal_loss 0.07833  dice_loss 0.23347 
Epoch [129/300] Validation [3/16] Loss: 0.68443  focal_loss 0.38498  dice_loss 0.29945 
Epoch [129/300] Validation [4/16] Loss: 0.26912  focal_loss 0.10030  dice_loss 0.16882 
Epoch [129/300] Validation [5/16] Loss: 0.32920  focal_loss 0.09747  dice_loss 0.23174 
Epoch [129/300] Validation [6/16] Loss: 0.18497  focal_loss 0.03660  dice_loss 0.14837 
Epoch [129/300] Validation [7/16] Loss: 0.15758  focal_loss 0.04239  dice_loss 0.11519 
Epoch [129/300] Validation [8/16] Loss: 0.32562  focal_loss 0.08668  dice_loss 0.23894 
Epoch [129/300] Validation [9/16] Loss: 0.21701  focal_loss 0.06221  dice_loss 0.15480 
Epoch [129/300] Validation [10/16] Loss: 0.22280  focal_loss 0.04491  dice_loss 0.17789 
Epoch [129/300] Validation [11/16] Loss: 0.16171  focal_loss 0.03210  dice_loss 0.12961 
Epoch [129/300] Validation [12/16] Loss: 0.30736  focal_loss 0.05995  dice_loss 0.24741 
Epoch [129/300] Validation [13/16] Loss: 0.21622  focal_loss 0.04985  dice_loss 0.16637 
Epoch [129/300] Validation [14/16] Loss: 0.45131  focal_loss 0.13685  dice_loss 0.31446 
Epoch [129/300] Validation [15/16] Loss: 0.20632  focal_loss 0.05914  dice_loss 0.14719 
Epoch [129/300] Validation [16/16] Loss: 0.06915  focal_loss 0.01460  dice_loss 0.05454 
Epoch [129/300] Validation metric {'Val/mean dice_metric': 0.8843032717704773, 'Val/mean miou_metric': 0.8147251009941101, 'Val/mean f1': 0.8983253836631775, 'Val/mean precision': 0.8893065452575684, 'Val/mean recall': 0.9075290560722351, 'Val/mean hd95_metric': 25.952661514282227}
Cheakpoint...
Epoch [129/300] best acc:tensor([0.8914], device='cuda:0'), Now : mean acc: tensor([0.8843], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8843032717704773, 'Val/mean miou_metric': 0.8147251009941101, 'Val/mean f1': 0.8983253836631775, 'Val/mean precision': 0.8893065452575684, 'Val/mean recall': 0.9075290560722351, 'Val/mean hd95_metric': 25.952661514282227}
Epoch [130/300] Training [1/62] Loss: 0.11176 
Epoch [130/300] Training [2/62] Loss: 0.11524 
Epoch [130/300] Training [3/62] Loss: 0.19326 
Epoch [130/300] Training [4/62] Loss: 0.08635 
Epoch [130/300] Training [5/62] Loss: 0.18325 
Epoch [130/300] Training [6/62] Loss: 0.12432 
Epoch [130/300] Training [7/62] Loss: 0.07653 
Epoch [130/300] Training [8/62] Loss: 0.08390 
Epoch [130/300] Training [9/62] Loss: 0.14339 
Epoch [130/300] Training [10/62] Loss: 0.10522 
Epoch [130/300] Training [11/62] Loss: 0.08673 
Epoch [130/300] Training [12/62] Loss: 0.08662 
Epoch [130/300] Training [13/62] Loss: 0.11387 
Epoch [130/300] Training [14/62] Loss: 0.06581 
Epoch [130/300] Training [15/62] Loss: 0.18258 
Epoch [130/300] Training [16/62] Loss: 0.19118 
Epoch [130/300] Training [17/62] Loss: 0.12790 
Epoch [130/300] Training [18/62] Loss: 0.10821 
Epoch [130/300] Training [19/62] Loss: 0.19447 
Epoch [130/300] Training [20/62] Loss: 0.10081 
Epoch [130/300] Training [21/62] Loss: 0.12760 
Epoch [130/300] Training [22/62] Loss: 0.16407 
Epoch [130/300] Training [23/62] Loss: 0.14083 
Epoch [130/300] Training [24/62] Loss: 0.14203 
Epoch [130/300] Training [25/62] Loss: 0.17196 
Epoch [130/300] Training [26/62] Loss: 0.08890 
Epoch [130/300] Training [27/62] Loss: 0.20466 
Epoch [130/300] Training [28/62] Loss: 0.16407 
Epoch [130/300] Training [29/62] Loss: 0.19125 
Epoch [130/300] Training [30/62] Loss: 0.13983 
Epoch [130/300] Training [31/62] Loss: 0.14511 
Epoch [130/300] Training [32/62] Loss: 0.08452 
Epoch [130/300] Training [33/62] Loss: 0.14471 
Epoch [130/300] Training [34/62] Loss: 0.16813 
Epoch [130/300] Training [35/62] Loss: 0.08052 
Epoch [130/300] Training [36/62] Loss: 0.10066 
Epoch [130/300] Training [37/62] Loss: 0.07080 
Epoch [130/300] Training [38/62] Loss: 0.12195 
Epoch [130/300] Training [39/62] Loss: 0.09078 
Epoch [130/300] Training [40/62] Loss: 0.09850 
Epoch [130/300] Training [41/62] Loss: 0.09293 
Epoch [130/300] Training [42/62] Loss: 0.11106 
Epoch [130/300] Training [43/62] Loss: 0.08582 
Epoch [130/300] Training [44/62] Loss: 0.08479 
Epoch [130/300] Training [45/62] Loss: 0.07645 
Epoch [130/300] Training [46/62] Loss: 0.15323 
Epoch [130/300] Training [47/62] Loss: 0.10030 
Epoch [130/300] Training [48/62] Loss: 0.10728 
Epoch [130/300] Training [49/62] Loss: 0.09883 
Epoch [130/300] Training [50/62] Loss: 0.11560 
Epoch [130/300] Training [51/62] Loss: 0.09340 
Epoch [130/300] Training [52/62] Loss: 0.10421 
Epoch [130/300] Training [53/62] Loss: 0.23164 
Epoch [130/300] Training [54/62] Loss: 0.13019 
Epoch [130/300] Training [55/62] Loss: 0.11911 
Epoch [130/300] Training [56/62] Loss: 0.14544 
Epoch [130/300] Training [57/62] Loss: 0.16259 
Epoch [130/300] Training [58/62] Loss: 0.09337 
Epoch [130/300] Training [59/62] Loss: 0.10529 
Epoch [130/300] Training [60/62] Loss: 0.08018 
Epoch [130/300] Training [61/62] Loss: 0.10913 
Epoch [130/300] Training [62/62] Loss: 0.05847 
Epoch [130/300] Training metric {'Train/mean dice_metric': 0.9131750464439392, 'Train/mean miou_metric': 0.8524757623672485, 'Train/mean f1': 0.9302157163619995, 'Train/mean precision': 0.9207327365875244, 'Train/mean recall': 0.9398961067199707, 'Train/mean hd95_metric': 15.237991333007812}
Epoch [130/300] Validation [1/16] Loss: 0.52318  focal_loss 0.28541  dice_loss 0.23777 
Epoch [130/300] Validation [2/16] Loss: 0.32102  focal_loss 0.13513  dice_loss 0.18589 
Epoch [130/300] Validation [3/16] Loss: 0.34990  focal_loss 0.10079  dice_loss 0.24911 
Epoch [130/300] Validation [4/16] Loss: 0.29515  focal_loss 0.11337  dice_loss 0.18178 
Epoch [130/300] Validation [5/16] Loss: 0.24938  focal_loss 0.07376  dice_loss 0.17562 
Epoch [130/300] Validation [6/16] Loss: 0.26149  focal_loss 0.07347  dice_loss 0.18802 
Epoch [130/300] Validation [7/16] Loss: 0.32382  focal_loss 0.15269  dice_loss 0.17113 
Epoch [130/300] Validation [8/16] Loss: 0.52095  focal_loss 0.20158  dice_loss 0.31937 
Epoch [130/300] Validation [9/16] Loss: 0.26469  focal_loss 0.07343  dice_loss 0.19126 
Epoch [130/300] Validation [10/16] Loss: 0.56349  focal_loss 0.23774  dice_loss 0.32575 
Epoch [130/300] Validation [11/16] Loss: 0.12552  focal_loss 0.03055  dice_loss 0.09497 
Epoch [130/300] Validation [12/16] Loss: 0.31905  focal_loss 0.07014  dice_loss 0.24891 
Epoch [130/300] Validation [13/16] Loss: 0.35421  focal_loss 0.11839  dice_loss 0.23583 
Epoch [130/300] Validation [14/16] Loss: 0.50007  focal_loss 0.16938  dice_loss 0.33068 
Epoch [130/300] Validation [15/16] Loss: 0.22101  focal_loss 0.07330  dice_loss 0.14771 
Epoch [130/300] Validation [16/16] Loss: 0.06508  focal_loss 0.01455  dice_loss 0.05053 
Epoch [130/300] Validation metric {'Val/mean dice_metric': 0.8889839053153992, 'Val/mean miou_metric': 0.8226231932640076, 'Val/mean f1': 0.9030066728591919, 'Val/mean precision': 0.9089431166648865, 'Val/mean recall': 0.8971471786499023, 'Val/mean hd95_metric': 20.970096588134766}
Cheakpoint...
Epoch [130/300] best acc:tensor([0.8914], device='cuda:0'), Now : mean acc: tensor([0.8890], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8889839053153992, 'Val/mean miou_metric': 0.8226231932640076, 'Val/mean f1': 0.9030066728591919, 'Val/mean precision': 0.9089431166648865, 'Val/mean recall': 0.8971471786499023, 'Val/mean hd95_metric': 20.970096588134766}
Epoch [131/300] Training [1/62] Loss: 0.16959 
Epoch [131/300] Training [2/62] Loss: 0.08951 
Epoch [131/300] Training [3/62] Loss: 0.15672 
Epoch [131/300] Training [4/62] Loss: 0.23062 
Epoch [131/300] Training [5/62] Loss: 0.13500 
Epoch [131/300] Training [6/62] Loss: 0.13909 
Epoch [131/300] Training [7/62] Loss: 0.09149 
Epoch [131/300] Training [8/62] Loss: 0.09452 
Epoch [131/300] Training [9/62] Loss: 0.13710 
Epoch [131/300] Training [10/62] Loss: 0.10879 
Epoch [131/300] Training [11/62] Loss: 0.07523 
Epoch [131/300] Training [12/62] Loss: 0.20454 
Epoch [131/300] Training [13/62] Loss: 0.10932 
Epoch [131/300] Training [14/62] Loss: 0.10288 
Epoch [131/300] Training [15/62] Loss: 0.23967 
Epoch [131/300] Training [16/62] Loss: 0.23414 
Epoch [131/300] Training [17/62] Loss: 0.18108 
Epoch [131/300] Training [18/62] Loss: 0.09453 
Epoch [131/300] Training [19/62] Loss: 0.08901 
Epoch [131/300] Training [20/62] Loss: 0.11559 
Epoch [131/300] Training [21/62] Loss: 0.12021 
Epoch [131/300] Training [22/62] Loss: 0.10203 
Epoch [131/300] Training [23/62] Loss: 0.13045 
Epoch [131/300] Training [24/62] Loss: 0.09445 
Epoch [131/300] Training [25/62] Loss: 0.18123 
Epoch [131/300] Training [26/62] Loss: 0.07896 
Epoch [131/300] Training [27/62] Loss: 0.06440 
Epoch [131/300] Training [28/62] Loss: 0.15181 
Epoch [131/300] Training [29/62] Loss: 0.10134 
Epoch [131/300] Training [30/62] Loss: 0.10448 
Epoch [131/300] Training [31/62] Loss: 0.14573 
Epoch [131/300] Training [32/62] Loss: 0.11002 
Epoch [131/300] Training [33/62] Loss: 0.09324 
Epoch [131/300] Training [34/62] Loss: 0.07435 
Epoch [131/300] Training [35/62] Loss: 0.19021 
Epoch [131/300] Training [36/62] Loss: 0.10092 
Epoch [131/300] Training [37/62] Loss: 0.11207 
Epoch [131/300] Training [38/62] Loss: 0.08436 
Epoch [131/300] Training [39/62] Loss: 0.13240 
Epoch [131/300] Training [40/62] Loss: 0.07450 
Epoch [131/300] Training [41/62] Loss: 0.11508 
Epoch [131/300] Training [42/62] Loss: 0.14932 
Epoch [131/300] Training [43/62] Loss: 0.18088 
Epoch [131/300] Training [44/62] Loss: 0.07949 
Epoch [131/300] Training [45/62] Loss: 0.12858 
Epoch [131/300] Training [46/62] Loss: 0.10615 
Epoch [131/300] Training [47/62] Loss: 0.08351 
Epoch [131/300] Training [48/62] Loss: 0.10110 
Epoch [131/300] Training [49/62] Loss: 0.22081 
Epoch [131/300] Training [50/62] Loss: 0.17163 
Epoch [131/300] Training [51/62] Loss: 0.15963 
Epoch [131/300] Training [52/62] Loss: 0.17169 
Epoch [131/300] Training [53/62] Loss: 0.10681 
Epoch [131/300] Training [54/62] Loss: 0.10104 
Epoch [131/300] Training [55/62] Loss: 0.06037 
Epoch [131/300] Training [56/62] Loss: 0.09366 
Epoch [131/300] Training [57/62] Loss: 0.13902 
Epoch [131/300] Training [58/62] Loss: 0.13997 
Epoch [131/300] Training [59/62] Loss: 0.22132 
Epoch [131/300] Training [60/62] Loss: 0.11626 
Epoch [131/300] Training [61/62] Loss: 0.10673 
Epoch [131/300] Training [62/62] Loss: 0.24497 
Epoch [131/300] Training metric {'Train/mean dice_metric': 0.9112548828125, 'Train/mean miou_metric': 0.8490718007087708, 'Train/mean f1': 0.9266039729118347, 'Train/mean precision': 0.9226470589637756, 'Train/mean recall': 0.9305949807167053, 'Train/mean hd95_metric': 16.77106475830078}
Epoch [131/300] Validation [1/16] Loss: 0.15318  focal_loss 0.04720  dice_loss 0.10598 
Epoch [131/300] Validation [2/16] Loss: 0.34203  focal_loss 0.11022  dice_loss 0.23181 
Epoch [131/300] Validation [3/16] Loss: 0.70489  focal_loss 0.37390  dice_loss 0.33099 
Epoch [131/300] Validation [4/16] Loss: 0.29185  focal_loss 0.12100  dice_loss 0.17085 
Epoch [131/300] Validation [5/16] Loss: 0.36580  focal_loss 0.10249  dice_loss 0.26331 
Epoch [131/300] Validation [6/16] Loss: 0.21782  focal_loss 0.03135  dice_loss 0.18647 
Epoch [131/300] Validation [7/16] Loss: 0.35189  focal_loss 0.12264  dice_loss 0.22925 
Epoch [131/300] Validation [8/16] Loss: 0.38348  focal_loss 0.12861  dice_loss 0.25488 
Epoch [131/300] Validation [9/16] Loss: 0.24598  focal_loss 0.07587  dice_loss 0.17011 
Epoch [131/300] Validation [10/16] Loss: 0.31558  focal_loss 0.06218  dice_loss 0.25339 
Epoch [131/300] Validation [11/16] Loss: 0.15985  focal_loss 0.02982  dice_loss 0.13003 
Epoch [131/300] Validation [12/16] Loss: 0.32154  focal_loss 0.06643  dice_loss 0.25511 
Epoch [131/300] Validation [13/16] Loss: 0.22681  focal_loss 0.05772  dice_loss 0.16909 
Epoch [131/300] Validation [14/16] Loss: 0.46263  focal_loss 0.14327  dice_loss 0.31936 
Epoch [131/300] Validation [15/16] Loss: 0.18936  focal_loss 0.06025  dice_loss 0.12911 
Epoch [131/300] Validation [16/16] Loss: 0.05141  focal_loss 0.00806  dice_loss 0.04335 
Epoch [131/300] Validation metric {'Val/mean dice_metric': 0.8898411393165588, 'Val/mean miou_metric': 0.8224448561668396, 'Val/mean f1': 0.9003540277481079, 'Val/mean precision': 0.8908737301826477, 'Val/mean recall': 0.9100382328033447, 'Val/mean hd95_metric': 23.46096420288086}
Cheakpoint...
Epoch [131/300] best acc:tensor([0.8914], device='cuda:0'), Now : mean acc: tensor([0.8898], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8898411393165588, 'Val/mean miou_metric': 0.8224448561668396, 'Val/mean f1': 0.9003540277481079, 'Val/mean precision': 0.8908737301826477, 'Val/mean recall': 0.9100382328033447, 'Val/mean hd95_metric': 23.46096420288086}
Epoch [132/300] Training [1/62] Loss: 0.11089 
Epoch [132/300] Training [2/62] Loss: 0.12130 
Epoch [132/300] Training [3/62] Loss: 0.06624 
Epoch [132/300] Training [4/62] Loss: 0.10283 
Epoch [132/300] Training [5/62] Loss: 0.13919 
Epoch [132/300] Training [6/62] Loss: 0.14380 
Epoch [132/300] Training [7/62] Loss: 0.16062 
Epoch [132/300] Training [8/62] Loss: 0.09274 
Epoch [132/300] Training [9/62] Loss: 0.07099 
Epoch [132/300] Training [10/62] Loss: 0.14182 
Epoch [132/300] Training [11/62] Loss: 0.26083 
Epoch [132/300] Training [12/62] Loss: 0.15878 
Epoch [132/300] Training [13/62] Loss: 0.12999 
Epoch [132/300] Training [14/62] Loss: 0.24381 
Epoch [132/300] Training [15/62] Loss: 0.11148 
Epoch [132/300] Training [16/62] Loss: 0.27871 
Epoch [132/300] Training [17/62] Loss: 0.08458 
Epoch [132/300] Training [18/62] Loss: 0.21089 
Epoch [132/300] Training [19/62] Loss: 0.24538 
Epoch [132/300] Training [20/62] Loss: 0.19289 
Epoch [132/300] Training [21/62] Loss: 0.09813 
Epoch [132/300] Training [22/62] Loss: 0.11749 
Epoch [132/300] Training [23/62] Loss: 0.10484 
Epoch [132/300] Training [24/62] Loss: 0.28906 
Epoch [132/300] Training [25/62] Loss: 0.09775 
Epoch [132/300] Training [26/62] Loss: 0.11790 
Epoch [132/300] Training [27/62] Loss: 0.13002 
Epoch [132/300] Training [28/62] Loss: 0.14469 
Epoch [132/300] Training [29/62] Loss: 0.14996 
Epoch [132/300] Training [30/62] Loss: 0.09966 
Epoch [132/300] Training [31/62] Loss: 0.08320 
Epoch [132/300] Training [32/62] Loss: 0.07642 
Epoch [132/300] Training [33/62] Loss: 0.11415 
Epoch [132/300] Training [34/62] Loss: 0.16937 
Epoch [132/300] Training [35/62] Loss: 0.07000 
Epoch [132/300] Training [36/62] Loss: 0.14235 
Epoch [132/300] Training [37/62] Loss: 0.10567 
Epoch [132/300] Training [38/62] Loss: 0.09881 
Epoch [132/300] Training [39/62] Loss: 0.17819 
Epoch [132/300] Training [40/62] Loss: 0.11642 
Epoch [132/300] Training [41/62] Loss: 0.09588 
Epoch [132/300] Training [42/62] Loss: 0.09170 
Epoch [132/300] Training [43/62] Loss: 0.15400 
Epoch [132/300] Training [44/62] Loss: 0.06727 
Epoch [132/300] Training [45/62] Loss: 0.09705 
Epoch [132/300] Training [46/62] Loss: 0.21727 
Epoch [132/300] Training [47/62] Loss: 0.09270 
Epoch [132/300] Training [48/62] Loss: 0.08549 
Epoch [132/300] Training [49/62] Loss: 0.16744 
Epoch [132/300] Training [50/62] Loss: 0.24884 
Epoch [132/300] Training [51/62] Loss: 0.12738 
Epoch [132/300] Training [52/62] Loss: 0.23677 
Epoch [132/300] Training [53/62] Loss: 0.05365 
Epoch [132/300] Training [54/62] Loss: 0.11653 
Epoch [132/300] Training [55/62] Loss: 0.07849 
Epoch [132/300] Training [56/62] Loss: 0.15847 
Epoch [132/300] Training [57/62] Loss: 0.09315 
Epoch [132/300] Training [58/62] Loss: 0.08643 
Epoch [132/300] Training [59/62] Loss: 0.14765 
Epoch [132/300] Training [60/62] Loss: 0.18226 
Epoch [132/300] Training [61/62] Loss: 0.16922 
Epoch [132/300] Training [62/62] Loss: 0.13601 
Epoch [132/300] Training metric {'Train/mean dice_metric': 0.9061961770057678, 'Train/mean miou_metric': 0.8425636291503906, 'Train/mean f1': 0.9198972582817078, 'Train/mean precision': 0.911561906337738, 'Train/mean recall': 0.9283865690231323, 'Train/mean hd95_metric': 18.02540397644043}
Epoch [132/300] Validation [1/16] Loss: 0.15846  focal_loss 0.04581  dice_loss 0.11264 
Epoch [132/300] Validation [2/16] Loss: 0.35007  focal_loss 0.12742  dice_loss 0.22265 
Epoch [132/300] Validation [3/16] Loss: 0.76568  focal_loss 0.42075  dice_loss 0.34493 
Epoch [132/300] Validation [4/16] Loss: 0.30182  focal_loss 0.12443  dice_loss 0.17739 
Epoch [132/300] Validation [5/16] Loss: 0.34788  focal_loss 0.13157  dice_loss 0.21631 
Epoch [132/300] Validation [6/16] Loss: 0.19631  focal_loss 0.04635  dice_loss 0.14995 
Epoch [132/300] Validation [7/16] Loss: 0.17699  focal_loss 0.04568  dice_loss 0.13131 
Epoch [132/300] Validation [8/16] Loss: 0.34927  focal_loss 0.12908  dice_loss 0.22020 
Epoch [132/300] Validation [9/16] Loss: 0.25179  focal_loss 0.07732  dice_loss 0.17447 
Epoch [132/300] Validation [10/16] Loss: 0.43432  focal_loss 0.14293  dice_loss 0.29139 
Epoch [132/300] Validation [11/16] Loss: 0.13526  focal_loss 0.03181  dice_loss 0.10345 
Epoch [132/300] Validation [12/16] Loss: 0.31831  focal_loss 0.08779  dice_loss 0.23052 
Epoch [132/300] Validation [13/16] Loss: 0.29267  focal_loss 0.11927  dice_loss 0.17340 
Epoch [132/300] Validation [14/16] Loss: 0.55881  focal_loss 0.18622  dice_loss 0.37258 
Epoch [132/300] Validation [15/16] Loss: 0.20814  focal_loss 0.07590  dice_loss 0.13224 
Epoch [132/300] Validation [16/16] Loss: 0.07698  focal_loss 0.01163  dice_loss 0.06535 
Epoch [132/300] Validation metric {'Val/mean dice_metric': 0.8867161273956299, 'Val/mean miou_metric': 0.8179472088813782, 'Val/mean f1': 0.8975239992141724, 'Val/mean precision': 0.8924031853675842, 'Val/mean recall': 0.9027038812637329, 'Val/mean hd95_metric': 23.285676956176758}
Cheakpoint...
Epoch [132/300] best acc:tensor([0.8914], device='cuda:0'), Now : mean acc: tensor([0.8867], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8867161273956299, 'Val/mean miou_metric': 0.8179472088813782, 'Val/mean f1': 0.8975239992141724, 'Val/mean precision': 0.8924031853675842, 'Val/mean recall': 0.9027038812637329, 'Val/mean hd95_metric': 23.285676956176758}
Epoch [133/300] Training [1/62] Loss: 0.10906 
Epoch [133/300] Training [2/62] Loss: 0.11918 
Epoch [133/300] Training [3/62] Loss: 0.13079 
Epoch [133/300] Training [4/62] Loss: 0.46323 
Epoch [133/300] Training [5/62] Loss: 0.08066 
Epoch [133/300] Training [6/62] Loss: 0.27997 
Epoch [133/300] Training [7/62] Loss: 0.12286 
Epoch [133/300] Training [8/62] Loss: 0.11076 
Epoch [133/300] Training [9/62] Loss: 0.20438 
Epoch [133/300] Training [10/62] Loss: 0.08421 
Epoch [133/300] Training [11/62] Loss: 0.07338 
Epoch [133/300] Training [12/62] Loss: 0.16048 
Epoch [133/300] Training [13/62] Loss: 0.07719 
Epoch [133/300] Training [14/62] Loss: 0.21796 
Epoch [133/300] Training [15/62] Loss: 0.20021 
Epoch [133/300] Training [16/62] Loss: 0.13916 
Epoch [133/300] Training [17/62] Loss: 0.15517 
Epoch [133/300] Training [18/62] Loss: 0.07816 
Epoch [133/300] Training [19/62] Loss: 0.12599 
Epoch [133/300] Training [20/62] Loss: 0.18498 
Epoch [133/300] Training [21/62] Loss: 0.15492 
Epoch [133/300] Training [22/62] Loss: 0.17044 
Epoch [133/300] Training [23/62] Loss: 0.13718 
Epoch [133/300] Training [24/62] Loss: 0.06600 
Epoch [133/300] Training [25/62] Loss: 0.08641 
Epoch [133/300] Training [26/62] Loss: 0.07885 
Epoch [133/300] Training [27/62] Loss: 0.08104 
Epoch [133/300] Training [28/62] Loss: 0.23427 
Epoch [133/300] Training [29/62] Loss: 0.08145 
Epoch [133/300] Training [30/62] Loss: 0.13913 
Epoch [133/300] Training [31/62] Loss: 0.06568 
Epoch [133/300] Training [32/62] Loss: 0.16784 
Epoch [133/300] Training [33/62] Loss: 0.12458 
Epoch [133/300] Training [34/62] Loss: 0.15606 
Epoch [133/300] Training [35/62] Loss: 0.10609 
Epoch [133/300] Training [36/62] Loss: 0.11517 
Epoch [133/300] Training [37/62] Loss: 0.08260 
Epoch [133/300] Training [38/62] Loss: 0.06930 
Epoch [133/300] Training [39/62] Loss: 0.18334 
Epoch [133/300] Training [40/62] Loss: 0.11432 
Epoch [133/300] Training [41/62] Loss: 0.27593 
Epoch [133/300] Training [42/62] Loss: 0.24070 
Epoch [133/300] Training [43/62] Loss: 0.11623 
Epoch [133/300] Training [44/62] Loss: 0.18510 
Epoch [133/300] Training [45/62] Loss: 0.08738 
Epoch [133/300] Training [46/62] Loss: 0.09689 
Epoch [133/300] Training [47/62] Loss: 0.16868 
Epoch [133/300] Training [48/62] Loss: 0.15812 
Epoch [133/300] Training [49/62] Loss: 0.07129 
Epoch [133/300] Training [50/62] Loss: 0.09494 
Epoch [133/300] Training [51/62] Loss: 0.09593 
Epoch [133/300] Training [52/62] Loss: 0.15370 
Epoch [133/300] Training [53/62] Loss: 0.14250 
Epoch [133/300] Training [54/62] Loss: 0.10644 
Epoch [133/300] Training [55/62] Loss: 0.13394 
Epoch [133/300] Training [56/62] Loss: 0.11792 
Epoch [133/300] Training [57/62] Loss: 0.24622 
Epoch [133/300] Training [58/62] Loss: 0.11348 
Epoch [133/300] Training [59/62] Loss: 0.21904 
Epoch [133/300] Training [60/62] Loss: 0.11381 
Epoch [133/300] Training [61/62] Loss: 0.05957 
Epoch [133/300] Training [62/62] Loss: 0.08359 
Epoch [133/300] Training metric {'Train/mean dice_metric': 0.905856728553772, 'Train/mean miou_metric': 0.8446264266967773, 'Train/mean f1': 0.9186187982559204, 'Train/mean precision': 0.9154786467552185, 'Train/mean recall': 0.9217805862426758, 'Train/mean hd95_metric': 18.080089569091797}
Epoch [133/300] Validation [1/16] Loss: 0.14584  focal_loss 0.04246  dice_loss 0.10338 
Epoch [133/300] Validation [2/16] Loss: 0.33021  focal_loss 0.09635  dice_loss 0.23386 
Epoch [133/300] Validation [3/16] Loss: 0.44193  focal_loss 0.13842  dice_loss 0.30351 
Epoch [133/300] Validation [4/16] Loss: 0.30241  focal_loss 0.12791  dice_loss 0.17451 
Epoch [133/300] Validation [5/16] Loss: 0.34434  focal_loss 0.11811  dice_loss 0.22623 
Epoch [133/300] Validation [6/16] Loss: 0.17522  focal_loss 0.03099  dice_loss 0.14423 
Epoch [133/300] Validation [7/16] Loss: 0.24650  focal_loss 0.08865  dice_loss 0.15784 
Epoch [133/300] Validation [8/16] Loss: 0.38039  focal_loss 0.10932  dice_loss 0.27107 
Epoch [133/300] Validation [9/16] Loss: 0.27087  focal_loss 0.08473  dice_loss 0.18614 
Epoch [133/300] Validation [10/16] Loss: 0.40243  focal_loss 0.14853  dice_loss 0.25390 
Epoch [133/300] Validation [11/16] Loss: 0.13677  focal_loss 0.03211  dice_loss 0.10466 
Epoch [133/300] Validation [12/16] Loss: 0.33015  focal_loss 0.07896  dice_loss 0.25119 
Epoch [133/300] Validation [13/16] Loss: 0.25958  focal_loss 0.07191  dice_loss 0.18766 
Epoch [133/300] Validation [14/16] Loss: 0.40803  focal_loss 0.10719  dice_loss 0.30083 
Epoch [133/300] Validation [15/16] Loss: 0.18814  focal_loss 0.05362  dice_loss 0.13453 
Epoch [133/300] Validation [16/16] Loss: 0.05352  focal_loss 0.00868  dice_loss 0.04484 
Epoch [133/300] Validation metric {'Val/mean dice_metric': 0.8870171308517456, 'Val/mean miou_metric': 0.8217465281486511, 'Val/mean f1': 0.8997431397438049, 'Val/mean precision': 0.8976777195930481, 'Val/mean recall': 0.9018182158470154, 'Val/mean hd95_metric': 22.506715774536133}
Cheakpoint...
Epoch [133/300] best acc:tensor([0.8914], device='cuda:0'), Now : mean acc: tensor([0.8870], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8870171308517456, 'Val/mean miou_metric': 0.8217465281486511, 'Val/mean f1': 0.8997431397438049, 'Val/mean precision': 0.8976777195930481, 'Val/mean recall': 0.9018182158470154, 'Val/mean hd95_metric': 22.506715774536133}
Epoch [134/300] Training [1/62] Loss: 0.12734 
Epoch [134/300] Training [2/62] Loss: 0.09633 
Epoch [134/300] Training [3/62] Loss: 0.15547 
Epoch [134/300] Training [4/62] Loss: 0.13717 
Epoch [134/300] Training [5/62] Loss: 0.08602 
Epoch [134/300] Training [6/62] Loss: 0.12789 
Epoch [134/300] Training [7/62] Loss: 0.14874 
Epoch [134/300] Training [8/62] Loss: 0.34878 
Epoch [134/300] Training [9/62] Loss: 0.19391 
Epoch [134/300] Training [10/62] Loss: 0.10354 
Epoch [134/300] Training [11/62] Loss: 0.12208 
Epoch [134/300] Training [12/62] Loss: 0.08284 
Epoch [134/300] Training [13/62] Loss: 0.08045 
Epoch [134/300] Training [14/62] Loss: 0.12582 
Epoch [134/300] Training [15/62] Loss: 0.10332 
Epoch [134/300] Training [16/62] Loss: 0.09779 
Epoch [134/300] Training [17/62] Loss: 0.19727 
Epoch [134/300] Training [18/62] Loss: 0.15210 
Epoch [134/300] Training [19/62] Loss: 0.09018 
Epoch [134/300] Training [20/62] Loss: 0.09032 
Epoch [134/300] Training [21/62] Loss: 0.14412 
Epoch [134/300] Training [22/62] Loss: 0.19370 
Epoch [134/300] Training [23/62] Loss: 0.12077 
Epoch [134/300] Training [24/62] Loss: 0.09665 
Epoch [134/300] Training [25/62] Loss: 0.09925 
Epoch [134/300] Training [26/62] Loss: 0.08735 
Epoch [134/300] Training [27/62] Loss: 0.06470 
Epoch [134/300] Training [28/62] Loss: 0.18381 
Epoch [134/300] Training [29/62] Loss: 0.11263 
Epoch [134/300] Training [30/62] Loss: 0.23257 
Epoch [134/300] Training [31/62] Loss: 0.14784 
Epoch [134/300] Training [32/62] Loss: 0.26709 
Epoch [134/300] Training [33/62] Loss: 0.07547 
Epoch [134/300] Training [34/62] Loss: 0.32457 
Epoch [134/300] Training [35/62] Loss: 0.15585 
Epoch [134/300] Training [36/62] Loss: 0.11975 
Epoch [134/300] Training [37/62] Loss: 0.14822 
Epoch [134/300] Training [38/62] Loss: 0.06192 
Epoch [134/300] Training [39/62] Loss: 0.13346 
Epoch [134/300] Training [40/62] Loss: 0.09273 
Epoch [134/300] Training [41/62] Loss: 0.15391 
Epoch [134/300] Training [42/62] Loss: 0.12071 
Epoch [134/300] Training [43/62] Loss: 0.07215 
Epoch [134/300] Training [44/62] Loss: 0.10146 
Epoch [134/300] Training [45/62] Loss: 0.06682 
Epoch [134/300] Training [46/62] Loss: 0.12395 
Epoch [134/300] Training [47/62] Loss: 0.11055 
Epoch [134/300] Training [48/62] Loss: 0.16673 
Epoch [134/300] Training [49/62] Loss: 0.10026 
Epoch [134/300] Training [50/62] Loss: 0.14844 
Epoch [134/300] Training [51/62] Loss: 0.15765 
Epoch [134/300] Training [52/62] Loss: 0.16398 
Epoch [134/300] Training [53/62] Loss: 0.07409 
Epoch [134/300] Training [54/62] Loss: 0.08779 
Epoch [134/300] Training [55/62] Loss: 0.21550 
Epoch [134/300] Training [56/62] Loss: 0.12384 
Epoch [134/300] Training [57/62] Loss: 0.09213 
Epoch [134/300] Training [58/62] Loss: 0.13336 
Epoch [134/300] Training [59/62] Loss: 0.12348 
Epoch [134/300] Training [60/62] Loss: 0.08173 
Epoch [134/300] Training [61/62] Loss: 0.14424 
Epoch [134/300] Training [62/62] Loss: 0.32655 
Epoch [134/300] Training metric {'Train/mean dice_metric': 0.9080971479415894, 'Train/mean miou_metric': 0.8459622859954834, 'Train/mean f1': 0.9225438237190247, 'Train/mean precision': 0.9139320254325867, 'Train/mean recall': 0.9313192963600159, 'Train/mean hd95_metric': 19.530073165893555}
Epoch [134/300] Validation [1/16] Loss: 0.28181  focal_loss 0.14520  dice_loss 0.13661 
Epoch [134/300] Validation [2/16] Loss: 0.33800  focal_loss 0.08487  dice_loss 0.25313 
Epoch [134/300] Validation [3/16] Loss: 0.31570  focal_loss 0.09666  dice_loss 0.21904 
Epoch [134/300] Validation [4/16] Loss: 0.22266  focal_loss 0.07257  dice_loss 0.15009 
Epoch [134/300] Validation [5/16] Loss: 0.31773  focal_loss 0.07259  dice_loss 0.24514 
Epoch [134/300] Validation [6/16] Loss: 0.23826  focal_loss 0.04309  dice_loss 0.19517 
Epoch [134/300] Validation [7/16] Loss: 0.21636  focal_loss 0.07604  dice_loss 0.14032 
Epoch [134/300] Validation [8/16] Loss: 0.28464  focal_loss 0.07418  dice_loss 0.21045 
Epoch [134/300] Validation [9/16] Loss: 0.18138  focal_loss 0.05413  dice_loss 0.12725 
Epoch [134/300] Validation [10/16] Loss: 0.20701  focal_loss 0.04594  dice_loss 0.16107 
Epoch [134/300] Validation [11/16] Loss: 0.22137  focal_loss 0.07189  dice_loss 0.14948 
Epoch [134/300] Validation [12/16] Loss: 0.38333  focal_loss 0.08994  dice_loss 0.29339 
Epoch [134/300] Validation [13/16] Loss: 0.25306  focal_loss 0.06040  dice_loss 0.19266 
Epoch [134/300] Validation [14/16] Loss: 0.66192  focal_loss 0.24423  dice_loss 0.41769 
Epoch [134/300] Validation [15/16] Loss: 0.12874  focal_loss 0.03339  dice_loss 0.09535 
Epoch [134/300] Validation [16/16] Loss: 0.08112  focal_loss 0.01164  dice_loss 0.06948 
Epoch [134/300] Validation metric {'Val/mean dice_metric': 0.8900992274284363, 'Val/mean miou_metric': 0.8234937191009521, 'Val/mean f1': 0.9033508896827698, 'Val/mean precision': 0.8897609114646912, 'Val/mean recall': 0.9173622131347656, 'Val/mean hd95_metric': 24.229604721069336}
Cheakpoint...
Epoch [134/300] best acc:tensor([0.8914], device='cuda:0'), Now : mean acc: tensor([0.8901], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8900992274284363, 'Val/mean miou_metric': 0.8234937191009521, 'Val/mean f1': 0.9033508896827698, 'Val/mean precision': 0.8897609114646912, 'Val/mean recall': 0.9173622131347656, 'Val/mean hd95_metric': 24.229604721069336}
Epoch [135/300] Training [1/62] Loss: 0.08364 
Epoch [135/300] Training [2/62] Loss: 0.09480 
Epoch [135/300] Training [3/62] Loss: 0.11799 
Epoch [135/300] Training [4/62] Loss: 0.10733 
Epoch [135/300] Training [5/62] Loss: 0.10356 
Epoch [135/300] Training [6/62] Loss: 0.13558 
Epoch [135/300] Training [7/62] Loss: 0.10532 
Epoch [135/300] Training [8/62] Loss: 0.15796 
Epoch [135/300] Training [9/62] Loss: 0.11730 
Epoch [135/300] Training [10/62] Loss: 0.24247 
Epoch [135/300] Training [11/62] Loss: 0.07865 
Epoch [135/300] Training [12/62] Loss: 0.13292 
Epoch [135/300] Training [13/62] Loss: 0.08607 
Epoch [135/300] Training [14/62] Loss: 0.13245 
Epoch [135/300] Training [15/62] Loss: 0.14546 
Epoch [135/300] Training [16/62] Loss: 0.13487 
Epoch [135/300] Training [17/62] Loss: 0.11124 
Epoch [135/300] Training [18/62] Loss: 0.15419 
Epoch [135/300] Training [19/62] Loss: 0.14161 
Epoch [135/300] Training [20/62] Loss: 0.11646 
Epoch [135/300] Training [21/62] Loss: 0.12843 
Epoch [135/300] Training [22/62] Loss: 0.28534 
Epoch [135/300] Training [23/62] Loss: 0.11653 
Epoch [135/300] Training [24/62] Loss: 0.13517 
Epoch [135/300] Training [25/62] Loss: 0.14772 
Epoch [135/300] Training [26/62] Loss: 0.06871 
Epoch [135/300] Training [27/62] Loss: 0.10334 
Epoch [135/300] Training [28/62] Loss: 0.19639 
Epoch [135/300] Training [29/62] Loss: 0.05972 
Epoch [135/300] Training [30/62] Loss: 0.13349 
Epoch [135/300] Training [31/62] Loss: 0.10056 
Epoch [135/300] Training [32/62] Loss: 0.11564 
Epoch [135/300] Training [33/62] Loss: 0.09196 
Epoch [135/300] Training [34/62] Loss: 0.11841 
Epoch [135/300] Training [35/62] Loss: 0.09297 
Epoch [135/300] Training [36/62] Loss: 0.08623 
Epoch [135/300] Training [37/62] Loss: 0.13071 
Epoch [135/300] Training [38/62] Loss: 0.18609 
Epoch [135/300] Training [39/62] Loss: 0.15638 
Epoch [135/300] Training [40/62] Loss: 0.16761 
Epoch [135/300] Training [41/62] Loss: 0.17013 
Epoch [135/300] Training [42/62] Loss: 0.14735 
Epoch [135/300] Training [43/62] Loss: 0.08147 
Epoch [135/300] Training [44/62] Loss: 0.10564 
Epoch [135/300] Training [45/62] Loss: 0.21594 
Epoch [135/300] Training [46/62] Loss: 0.19205 
Epoch [135/300] Training [47/62] Loss: 0.13522 
Epoch [135/300] Training [48/62] Loss: 0.18432 
Epoch [135/300] Training [49/62] Loss: 0.11172 
Epoch [135/300] Training [50/62] Loss: 0.09073 
Epoch [135/300] Training [51/62] Loss: 0.13658 
Epoch [135/300] Training [52/62] Loss: 0.10287 
Epoch [135/300] Training [53/62] Loss: 0.09879 
Epoch [135/300] Training [54/62] Loss: 0.08125 
Epoch [135/300] Training [55/62] Loss: 0.23807 
Epoch [135/300] Training [56/62] Loss: 0.25460 
Epoch [135/300] Training [57/62] Loss: 0.13578 
Epoch [135/300] Training [58/62] Loss: 0.14705 
Epoch [135/300] Training [59/62] Loss: 0.12928 
Epoch [135/300] Training [60/62] Loss: 0.11408 
Epoch [135/300] Training [61/62] Loss: 0.11700 
Epoch [135/300] Training [62/62] Loss: 0.05922 
Epoch [135/300] Training metric {'Train/mean dice_metric': 0.9077788591384888, 'Train/mean miou_metric': 0.8434841632843018, 'Train/mean f1': 0.9224593043327332, 'Train/mean precision': 0.917519211769104, 'Train/mean recall': 0.9274529814720154, 'Train/mean hd95_metric': 17.61768341064453}
Epoch [135/300] Validation [1/16] Loss: 0.45153  focal_loss 0.23424  dice_loss 0.21729 
Epoch [135/300] Validation [2/16] Loss: 0.28235  focal_loss 0.10436  dice_loss 0.17799 
Epoch [135/300] Validation [3/16] Loss: 0.68224  focal_loss 0.31687  dice_loss 0.36537 
Epoch [135/300] Validation [4/16] Loss: 0.36902  focal_loss 0.16534  dice_loss 0.20368 
Epoch [135/300] Validation [5/16] Loss: 0.43417  focal_loss 0.12889  dice_loss 0.30528 
Epoch [135/300] Validation [6/16] Loss: 0.19474  focal_loss 0.04777  dice_loss 0.14697 
Epoch [135/300] Validation [7/16] Loss: 0.28750  focal_loss 0.10747  dice_loss 0.18003 
Epoch [135/300] Validation [8/16] Loss: 0.23889  focal_loss 0.05416  dice_loss 0.18472 
Epoch [135/300] Validation [9/16] Loss: 0.22792  focal_loss 0.05084  dice_loss 0.17708 
Epoch [135/300] Validation [10/16] Loss: 0.41547  focal_loss 0.14224  dice_loss 0.27324 
Epoch [135/300] Validation [11/16] Loss: 0.12961  focal_loss 0.01987  dice_loss 0.10974 
Epoch [135/300] Validation [12/16] Loss: 0.35360  focal_loss 0.07906  dice_loss 0.27454 
Epoch [135/300] Validation [13/16] Loss: 0.21438  focal_loss 0.06279  dice_loss 0.15159 
Epoch [135/300] Validation [14/16] Loss: 0.55386  focal_loss 0.20336  dice_loss 0.35050 
Epoch [135/300] Validation [15/16] Loss: 0.19510  focal_loss 0.05252  dice_loss 0.14257 
Epoch [135/300] Validation [16/16] Loss: 0.05342  focal_loss 0.01007  dice_loss 0.04335 
Epoch [135/300] Validation metric {'Val/mean dice_metric': 0.885367214679718, 'Val/mean miou_metric': 0.816728949546814, 'Val/mean f1': 0.8993688821792603, 'Val/mean precision': 0.903960108757019, 'Val/mean recall': 0.894824206829071, 'Val/mean hd95_metric': 22.437681198120117}
Cheakpoint...
Epoch [135/300] best acc:tensor([0.8914], device='cuda:0'), Now : mean acc: tensor([0.8854], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.885367214679718, 'Val/mean miou_metric': 0.816728949546814, 'Val/mean f1': 0.8993688821792603, 'Val/mean precision': 0.903960108757019, 'Val/mean recall': 0.894824206829071, 'Val/mean hd95_metric': 22.437681198120117}
Epoch [136/300] Training [1/62] Loss: 0.10311 
Epoch [136/300] Training [2/62] Loss: 0.08639 
Epoch [136/300] Training [3/62] Loss: 0.19815 
Epoch [136/300] Training [4/62] Loss: 0.14144 
Epoch [136/300] Training [5/62] Loss: 0.09883 
Epoch [136/300] Training [6/62] Loss: 0.11264 
Epoch [136/300] Training [7/62] Loss: 0.14178 
Epoch [136/300] Training [8/62] Loss: 0.07983 
Epoch [136/300] Training [9/62] Loss: 0.14377 
Epoch [136/300] Training [10/62] Loss: 0.07740 
Epoch [136/300] Training [11/62] Loss: 0.26142 
Epoch [136/300] Training [12/62] Loss: 0.20122 
Epoch [136/300] Training [13/62] Loss: 0.09213 
Epoch [136/300] Training [14/62] Loss: 0.08471 
Epoch [136/300] Training [15/62] Loss: 0.11574 
Epoch [136/300] Training [16/62] Loss: 0.17290 
Epoch [136/300] Training [17/62] Loss: 0.12812 
Epoch [136/300] Training [18/62] Loss: 0.12628 
Epoch [136/300] Training [19/62] Loss: 0.09719 
Epoch [136/300] Training [20/62] Loss: 0.11482 
Epoch [136/300] Training [21/62] Loss: 0.09989 
Epoch [136/300] Training [22/62] Loss: 0.22176 
Epoch [136/300] Training [23/62] Loss: 0.09389 
Epoch [136/300] Training [24/62] Loss: 0.12322 
Epoch [136/300] Training [25/62] Loss: 0.13517 
Epoch [136/300] Training [26/62] Loss: 0.13350 
Epoch [136/300] Training [27/62] Loss: 0.24598 
Epoch [136/300] Training [28/62] Loss: 0.12822 
Epoch [136/300] Training [29/62] Loss: 0.08684 
Epoch [136/300] Training [30/62] Loss: 0.13403 
Epoch [136/300] Training [31/62] Loss: 0.06845 
Epoch [136/300] Training [32/62] Loss: 0.16807 
Epoch [136/300] Training [33/62] Loss: 0.09703 
Epoch [136/300] Training [34/62] Loss: 0.05744 
Epoch [136/300] Training [35/62] Loss: 0.15005 
Epoch [136/300] Training [36/62] Loss: 0.09568 
Epoch [136/300] Training [37/62] Loss: 0.11395 
Epoch [136/300] Training [38/62] Loss: 0.12638 
Epoch [136/300] Training [39/62] Loss: 0.06943 
Epoch [136/300] Training [40/62] Loss: 0.09946 
Epoch [136/300] Training [41/62] Loss: 0.11993 
Epoch [136/300] Training [42/62] Loss: 0.06687 
Epoch [136/300] Training [43/62] Loss: 0.17889 
Epoch [136/300] Training [44/62] Loss: 0.14345 
Epoch [136/300] Training [45/62] Loss: 0.07945 
Epoch [136/300] Training [46/62] Loss: 0.08779 
Epoch [136/300] Training [47/62] Loss: 0.08359 
Epoch [136/300] Training [48/62] Loss: 0.11441 
Epoch [136/300] Training [49/62] Loss: 0.24883 
Epoch [136/300] Training [50/62] Loss: 0.23140 
Epoch [136/300] Training [51/62] Loss: 0.14374 
Epoch [136/300] Training [52/62] Loss: 0.07641 
Epoch [136/300] Training [53/62] Loss: 0.08625 
Epoch [136/300] Training [54/62] Loss: 0.15270 
Epoch [136/300] Training [55/62] Loss: 0.15636 
Epoch [136/300] Training [56/62] Loss: 0.08051 
Epoch [136/300] Training [57/62] Loss: 0.14602 
Epoch [136/300] Training [58/62] Loss: 0.07167 
Epoch [136/300] Training [59/62] Loss: 0.08918 
Epoch [136/300] Training [60/62] Loss: 0.15719 
Epoch [136/300] Training [61/62] Loss: 0.08665 
Epoch [136/300] Training [62/62] Loss: 0.10113 
Epoch [136/300] Training metric {'Train/mean dice_metric': 0.9151998162269592, 'Train/mean miou_metric': 0.854631245136261, 'Train/mean f1': 0.9253885746002197, 'Train/mean precision': 0.9166998863220215, 'Train/mean recall': 0.9342435598373413, 'Train/mean hd95_metric': 16.361539840698242}
Epoch [136/300] Validation [1/16] Loss: 0.18202  focal_loss 0.04664  dice_loss 0.13538 
Epoch [136/300] Validation [2/16] Loss: 0.36924  focal_loss 0.12647  dice_loss 0.24277 
Epoch [136/300] Validation [3/16] Loss: 0.25702  focal_loss 0.05572  dice_loss 0.20130 
Epoch [136/300] Validation [4/16] Loss: 0.16200  focal_loss 0.03109  dice_loss 0.13091 
Epoch [136/300] Validation [5/16] Loss: 0.36217  focal_loss 0.08367  dice_loss 0.27850 
Epoch [136/300] Validation [6/16] Loss: 0.22540  focal_loss 0.04423  dice_loss 0.18116 
Epoch [136/300] Validation [7/16] Loss: 0.22449  focal_loss 0.06334  dice_loss 0.16115 
Epoch [136/300] Validation [8/16] Loss: 0.23162  focal_loss 0.04899  dice_loss 0.18263 
Epoch [136/300] Validation [9/16] Loss: 0.27759  focal_loss 0.06416  dice_loss 0.21342 
Epoch [136/300] Validation [10/16] Loss: 0.33767  focal_loss 0.10667  dice_loss 0.23100 
Epoch [136/300] Validation [11/16] Loss: 0.16205  focal_loss 0.02732  dice_loss 0.13473 
Epoch [136/300] Validation [12/16] Loss: 0.28006  focal_loss 0.03657  dice_loss 0.24349 
Epoch [136/300] Validation [13/16] Loss: 0.26329  focal_loss 0.08244  dice_loss 0.18085 
Epoch [136/300] Validation [14/16] Loss: 0.32208  focal_loss 0.05378  dice_loss 0.26830 
Epoch [136/300] Validation [15/16] Loss: 0.10089  focal_loss 0.01897  dice_loss 0.08192 
Epoch [136/300] Validation [16/16] Loss: 0.04889  focal_loss 0.00831  dice_loss 0.04059 
Epoch [136/300] Validation metric {'Val/mean dice_metric': 0.8981465101242065, 'Val/mean miou_metric': 0.832374632358551, 'Val/mean f1': 0.9070454835891724, 'Val/mean precision': 0.8971436023712158, 'Val/mean recall': 0.9171683192253113, 'Val/mean hd95_metric': 21.65784454345703}
Cheakpoint...
Epoch [136/300] best acc:tensor([0.8981], device='cuda:0'), Now : mean acc: tensor([0.8981], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8981465101242065, 'Val/mean miou_metric': 0.832374632358551, 'Val/mean f1': 0.9070454835891724, 'Val/mean precision': 0.8971436023712158, 'Val/mean recall': 0.9171683192253113, 'Val/mean hd95_metric': 21.65784454345703}
Epoch [137/300] Training [1/62] Loss: 0.10619 
Epoch [137/300] Training [2/62] Loss: 0.15712 
Epoch [137/300] Training [3/62] Loss: 0.14611 
Epoch [137/300] Training [4/62] Loss: 0.10073 
Epoch [137/300] Training [5/62] Loss: 0.15446 
Epoch [137/300] Training [6/62] Loss: 0.21889 
Epoch [137/300] Training [7/62] Loss: 0.07750 
Epoch [137/300] Training [8/62] Loss: 0.11755 
Epoch [137/300] Training [9/62] Loss: 0.08503 
Epoch [137/300] Training [10/62] Loss: 0.23362 
Epoch [137/300] Training [11/62] Loss: 0.16342 
Epoch [137/300] Training [12/62] Loss: 0.11157 
Epoch [137/300] Training [13/62] Loss: 0.10380 
Epoch [137/300] Training [14/62] Loss: 0.21245 
Epoch [137/300] Training [15/62] Loss: 0.25635 
Epoch [137/300] Training [16/62] Loss: 0.07937 
Epoch [137/300] Training [17/62] Loss: 0.06958 
Epoch [137/300] Training [18/62] Loss: 0.12542 
Epoch [137/300] Training [19/62] Loss: 0.12239 
Epoch [137/300] Training [20/62] Loss: 0.12343 
Epoch [137/300] Training [21/62] Loss: 0.18252 
Epoch [137/300] Training [22/62] Loss: 0.14200 
Epoch [137/300] Training [23/62] Loss: 0.16032 
Epoch [137/300] Training [24/62] Loss: 0.07906 
Epoch [137/300] Training [25/62] Loss: 0.12515 
Epoch [137/300] Training [26/62] Loss: 0.17033 
Epoch [137/300] Training [27/62] Loss: 0.15754 
Epoch [137/300] Training [28/62] Loss: 0.10986 
Epoch [137/300] Training [29/62] Loss: 0.10373 
Epoch [137/300] Training [30/62] Loss: 0.14498 
Epoch [137/300] Training [31/62] Loss: 0.10455 
Epoch [137/300] Training [32/62] Loss: 0.16475 
Epoch [137/300] Training [33/62] Loss: 0.07909 
Epoch [137/300] Training [34/62] Loss: 0.10998 
Epoch [137/300] Training [35/62] Loss: 0.05954 
Epoch [137/300] Training [36/62] Loss: 0.08077 
Epoch [137/300] Training [37/62] Loss: 0.11457 
Epoch [137/300] Training [38/62] Loss: 0.07457 
Epoch [137/300] Training [39/62] Loss: 0.08897 
Epoch [137/300] Training [40/62] Loss: 0.08113 
Epoch [137/300] Training [41/62] Loss: 0.12589 
Epoch [137/300] Training [42/62] Loss: 0.14552 
Epoch [137/300] Training [43/62] Loss: 0.08887 
Epoch [137/300] Training [44/62] Loss: 0.11526 
Epoch [137/300] Training [45/62] Loss: 0.18005 
Epoch [137/300] Training [46/62] Loss: 0.14042 
Epoch [137/300] Training [47/62] Loss: 0.07445 
Epoch [137/300] Training [48/62] Loss: 0.09962 
Epoch [137/300] Training [49/62] Loss: 0.09652 
Epoch [137/300] Training [50/62] Loss: 0.09563 
Epoch [137/300] Training [51/62] Loss: 0.10116 
Epoch [137/300] Training [52/62] Loss: 0.17946 
Epoch [137/300] Training [53/62] Loss: 0.12894 
Epoch [137/300] Training [54/62] Loss: 0.08257 
Epoch [137/300] Training [55/62] Loss: 0.06022 
Epoch [137/300] Training [56/62] Loss: 0.29576 
Epoch [137/300] Training [57/62] Loss: 0.08382 
Epoch [137/300] Training [58/62] Loss: 0.10130 
Epoch [137/300] Training [59/62] Loss: 0.09234 
Epoch [137/300] Training [60/62] Loss: 0.09528 
Epoch [137/300] Training [61/62] Loss: 0.08159 
Epoch [137/300] Training [62/62] Loss: 0.10944 
Epoch [137/300] Training metric {'Train/mean dice_metric': 0.9152922034263611, 'Train/mean miou_metric': 0.8548393845558167, 'Train/mean f1': 0.9238601922988892, 'Train/mean precision': 0.9218171238899231, 'Train/mean recall': 0.9259123206138611, 'Train/mean hd95_metric': 17.82274055480957}
Epoch [137/300] Validation [1/16] Loss: 0.52717  focal_loss 0.30163  dice_loss 0.22555 
Epoch [137/300] Validation [2/16] Loss: 0.40660  focal_loss 0.11685  dice_loss 0.28975 
Epoch [137/300] Validation [3/16] Loss: 0.29555  focal_loss 0.07344  dice_loss 0.22211 
Epoch [137/300] Validation [4/16] Loss: 0.24693  focal_loss 0.08872  dice_loss 0.15821 
Epoch [137/300] Validation [5/16] Loss: 0.31855  focal_loss 0.09447  dice_loss 0.22408 
Epoch [137/300] Validation [6/16] Loss: 0.21901  focal_loss 0.04552  dice_loss 0.17349 
Epoch [137/300] Validation [7/16] Loss: 0.28304  focal_loss 0.09621  dice_loss 0.18682 
Epoch [137/300] Validation [8/16] Loss: 0.30641  focal_loss 0.08215  dice_loss 0.22426 
Epoch [137/300] Validation [9/16] Loss: 0.20657  focal_loss 0.06005  dice_loss 0.14652 
Epoch [137/300] Validation [10/16] Loss: 0.28942  focal_loss 0.09434  dice_loss 0.19508 
Epoch [137/300] Validation [11/16] Loss: 0.12343  focal_loss 0.02261  dice_loss 0.10082 
Epoch [137/300] Validation [12/16] Loss: 0.32608  focal_loss 0.06232  dice_loss 0.26375 
Epoch [137/300] Validation [13/16] Loss: 0.30873  focal_loss 0.09752  dice_loss 0.21121 
Epoch [137/300] Validation [14/16] Loss: 0.34765  focal_loss 0.07656  dice_loss 0.27110 
Epoch [137/300] Validation [15/16] Loss: 0.12260  focal_loss 0.03544  dice_loss 0.08716 
Epoch [137/300] Validation [16/16] Loss: 0.06847  focal_loss 0.01339  dice_loss 0.05508 
Epoch [137/300] Validation metric {'Val/mean dice_metric': 0.8950111269950867, 'Val/mean miou_metric': 0.8292463421821594, 'Val/mean f1': 0.9042050838470459, 'Val/mean precision': 0.9046430587768555, 'Val/mean recall': 0.903767466545105, 'Val/mean hd95_metric': 22.5047664642334}
Cheakpoint...
Epoch [137/300] best acc:tensor([0.8981], device='cuda:0'), Now : mean acc: tensor([0.8950], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8950111269950867, 'Val/mean miou_metric': 0.8292463421821594, 'Val/mean f1': 0.9042050838470459, 'Val/mean precision': 0.9046430587768555, 'Val/mean recall': 0.903767466545105, 'Val/mean hd95_metric': 22.5047664642334}
Epoch [138/300] Training [1/62] Loss: 0.09313 
Epoch [138/300] Training [2/62] Loss: 0.16133 
Epoch [138/300] Training [3/62] Loss: 0.08218 
Epoch [138/300] Training [4/62] Loss: 0.08241 
Epoch [138/300] Training [5/62] Loss: 0.08879 
Epoch [138/300] Training [6/62] Loss: 0.14676 
Epoch [138/300] Training [7/62] Loss: 0.11740 
Epoch [138/300] Training [8/62] Loss: 0.09193 
Epoch [138/300] Training [9/62] Loss: 0.06476 
Epoch [138/300] Training [10/62] Loss: 0.07101 
Epoch [138/300] Training [11/62] Loss: 0.09170 
Epoch [138/300] Training [12/62] Loss: 0.21895 
Epoch [138/300] Training [13/62] Loss: 0.08919 
Epoch [138/300] Training [14/62] Loss: 0.16436 
Epoch [138/300] Training [15/62] Loss: 0.10305 
Epoch [138/300] Training [16/62] Loss: 0.09945 
Epoch [138/300] Training [17/62] Loss: 0.14010 
Epoch [138/300] Training [18/62] Loss: 0.12056 
Epoch [138/300] Training [19/62] Loss: 0.07906 
Epoch [138/300] Training [20/62] Loss: 0.22595 
Epoch [138/300] Training [21/62] Loss: 0.14312 
Epoch [138/300] Training [22/62] Loss: 0.10718 
Epoch [138/300] Training [23/62] Loss: 0.08923 
Epoch [138/300] Training [24/62] Loss: 0.08924 
Epoch [138/300] Training [25/62] Loss: 0.17276 
Epoch [138/300] Training [26/62] Loss: 0.11439 
Epoch [138/300] Training [27/62] Loss: 0.19423 
Epoch [138/300] Training [28/62] Loss: 0.14866 
Epoch [138/300] Training [29/62] Loss: 0.10446 
Epoch [138/300] Training [30/62] Loss: 0.23556 
Epoch [138/300] Training [31/62] Loss: 0.11893 
Epoch [138/300] Training [32/62] Loss: 0.22942 
Epoch [138/300] Training [33/62] Loss: 0.11136 
Epoch [138/300] Training [34/62] Loss: 0.06767 
Epoch [138/300] Training [35/62] Loss: 0.09638 
Epoch [138/300] Training [36/62] Loss: 0.09581 
Epoch [138/300] Training [37/62] Loss: 0.15768 
Epoch [138/300] Training [38/62] Loss: 0.10652 
Epoch [138/300] Training [39/62] Loss: 0.11638 
Epoch [138/300] Training [40/62] Loss: 0.10260 
Epoch [138/300] Training [41/62] Loss: 0.14845 
Epoch [138/300] Training [42/62] Loss: 0.15818 
Epoch [138/300] Training [43/62] Loss: 0.15303 
Epoch [138/300] Training [44/62] Loss: 0.08415 
Epoch [138/300] Training [45/62] Loss: 0.08299 
Epoch [138/300] Training [46/62] Loss: 0.08075 
Epoch [138/300] Training [47/62] Loss: 0.12978 
Epoch [138/300] Training [48/62] Loss: 0.10880 
Epoch [138/300] Training [49/62] Loss: 0.07870 
Epoch [138/300] Training [50/62] Loss: 0.39505 
Epoch [138/300] Training [51/62] Loss: 0.11642 
Epoch [138/300] Training [52/62] Loss: 0.13004 
Epoch [138/300] Training [53/62] Loss: 0.08672 
Epoch [138/300] Training [54/62] Loss: 0.14668 
Epoch [138/300] Training [55/62] Loss: 0.10219 
Epoch [138/300] Training [56/62] Loss: 0.14165 
Epoch [138/300] Training [57/62] Loss: 0.10966 
Epoch [138/300] Training [58/62] Loss: 0.08770 
Epoch [138/300] Training [59/62] Loss: 0.32738 
Epoch [138/300] Training [60/62] Loss: 0.12402 
Epoch [138/300] Training [61/62] Loss: 0.10287 
Epoch [138/300] Training [62/62] Loss: 0.06925 
Epoch [138/300] Training metric {'Train/mean dice_metric': 0.9127078652381897, 'Train/mean miou_metric': 0.853747546672821, 'Train/mean f1': 0.9251095056533813, 'Train/mean precision': 0.9202893972396851, 'Train/mean recall': 0.9299802780151367, 'Train/mean hd95_metric': 17.776676177978516}
Epoch [138/300] Validation [1/16] Loss: 0.51837  focal_loss 0.29716  dice_loss 0.22121 
Epoch [138/300] Validation [2/16] Loss: 0.48157  focal_loss 0.12434  dice_loss 0.35723 
Epoch [138/300] Validation [3/16] Loss: 0.63937  focal_loss 0.34039  dice_loss 0.29897 
Epoch [138/300] Validation [4/16] Loss: 0.31075  focal_loss 0.08872  dice_loss 0.22202 
Epoch [138/300] Validation [5/16] Loss: 0.36886  focal_loss 0.11573  dice_loss 0.25314 
Epoch [138/300] Validation [6/16] Loss: 0.21459  focal_loss 0.05087  dice_loss 0.16372 
Epoch [138/300] Validation [7/16] Loss: 0.24813  focal_loss 0.07781  dice_loss 0.17032 
Epoch [138/300] Validation [8/16] Loss: 0.30135  focal_loss 0.08208  dice_loss 0.21927 
Epoch [138/300] Validation [9/16] Loss: 0.23954  focal_loss 0.07787  dice_loss 0.16167 
Epoch [138/300] Validation [10/16] Loss: 0.53819  focal_loss 0.18538  dice_loss 0.35282 
Epoch [138/300] Validation [11/16] Loss: 0.13682  focal_loss 0.02615  dice_loss 0.11067 
Epoch [138/300] Validation [12/16] Loss: 0.30946  focal_loss 0.05761  dice_loss 0.25185 
Epoch [138/300] Validation [13/16] Loss: 0.34026  focal_loss 0.11446  dice_loss 0.22580 
Epoch [138/300] Validation [14/16] Loss: 0.47029  focal_loss 0.10972  dice_loss 0.36057 
Epoch [138/300] Validation [15/16] Loss: 0.19709  focal_loss 0.04379  dice_loss 0.15330 
Epoch [138/300] Validation [16/16] Loss: 0.08296  focal_loss 0.01842  dice_loss 0.06454 
Epoch [138/300] Validation metric {'Val/mean dice_metric': 0.8861066102981567, 'Val/mean miou_metric': 0.8215059041976929, 'Val/mean f1': 0.8989023566246033, 'Val/mean precision': 0.8993722796440125, 'Val/mean recall': 0.898432731628418, 'Val/mean hd95_metric': 23.861618041992188}
Cheakpoint...
Epoch [138/300] best acc:tensor([0.8981], device='cuda:0'), Now : mean acc: tensor([0.8861], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8861066102981567, 'Val/mean miou_metric': 0.8215059041976929, 'Val/mean f1': 0.8989023566246033, 'Val/mean precision': 0.8993722796440125, 'Val/mean recall': 0.898432731628418, 'Val/mean hd95_metric': 23.861618041992188}
Epoch [139/300] Training [1/62] Loss: 0.16732 
Epoch [139/300] Training [2/62] Loss: 0.06215 
Epoch [139/300] Training [3/62] Loss: 0.10306 
Epoch [139/300] Training [4/62] Loss: 0.09295 
Epoch [139/300] Training [5/62] Loss: 0.14897 
Epoch [139/300] Training [6/62] Loss: 0.13165 
Epoch [139/300] Training [7/62] Loss: 0.08004 
Epoch [139/300] Training [8/62] Loss: 0.10849 
Epoch [139/300] Training [9/62] Loss: 0.10219 
Epoch [139/300] Training [10/62] Loss: 0.15522 
Epoch [139/300] Training [11/62] Loss: 0.13565 
Epoch [139/300] Training [12/62] Loss: 0.12654 
Epoch [139/300] Training [13/62] Loss: 0.13871 
Epoch [139/300] Training [14/62] Loss: 0.17691 
Epoch [139/300] Training [15/62] Loss: 0.07031 
Epoch [139/300] Training [16/62] Loss: 0.09960 
Epoch [139/300] Training [17/62] Loss: 0.08448 
Epoch [139/300] Training [18/62] Loss: 0.07790 
Epoch [139/300] Training [19/62] Loss: 0.12355 
Epoch [139/300] Training [20/62] Loss: 0.11620 
Epoch [139/300] Training [21/62] Loss: 0.09597 
Epoch [139/300] Training [22/62] Loss: 0.12435 
Epoch [139/300] Training [23/62] Loss: 0.10444 
Epoch [139/300] Training [24/62] Loss: 0.07804 
Epoch [139/300] Training [25/62] Loss: 0.13718 
Epoch [139/300] Training [26/62] Loss: 0.15496 
Epoch [139/300] Training [27/62] Loss: 0.08198 
Epoch [139/300] Training [28/62] Loss: 0.11958 
Epoch [139/300] Training [29/62] Loss: 0.06718 
Epoch [139/300] Training [30/62] Loss: 0.23331 
Epoch [139/300] Training [31/62] Loss: 0.07341 
Epoch [139/300] Training [32/62] Loss: 0.08648 
Epoch [139/300] Training [33/62] Loss: 0.08890 
Epoch [139/300] Training [34/62] Loss: 0.13525 
Epoch [139/300] Training [35/62] Loss: 0.21660 
Epoch [139/300] Training [36/62] Loss: 0.14780 
Epoch [139/300] Training [37/62] Loss: 0.16107 
Epoch [139/300] Training [38/62] Loss: 0.08232 
Epoch [139/300] Training [39/62] Loss: 0.09078 
Epoch [139/300] Training [40/62] Loss: 0.09312 
Epoch [139/300] Training [41/62] Loss: 0.09232 
Epoch [139/300] Training [42/62] Loss: 0.20194 
Epoch [139/300] Training [43/62] Loss: 0.08546 
Epoch [139/300] Training [44/62] Loss: 0.08383 
Epoch [139/300] Training [45/62] Loss: 0.15156 
Epoch [139/300] Training [46/62] Loss: 0.08326 
Epoch [139/300] Training [47/62] Loss: 0.07489 
Epoch [139/300] Training [48/62] Loss: 0.09420 
Epoch [139/300] Training [49/62] Loss: 0.09115 
Epoch [139/300] Training [50/62] Loss: 0.27461 
Epoch [139/300] Training [51/62] Loss: 0.08332 
Epoch [139/300] Training [52/62] Loss: 0.31509 
Epoch [139/300] Training [53/62] Loss: 0.11261 
Epoch [139/300] Training [54/62] Loss: 0.18851 
Epoch [139/300] Training [55/62] Loss: 0.13260 
Epoch [139/300] Training [56/62] Loss: 0.14098 
Epoch [139/300] Training [57/62] Loss: 0.14920 
Epoch [139/300] Training [58/62] Loss: 0.10315 
Epoch [139/300] Training [59/62] Loss: 0.11227 
Epoch [139/300] Training [60/62] Loss: 0.16289 
Epoch [139/300] Training [61/62] Loss: 0.14178 
Epoch [139/300] Training [62/62] Loss: 0.08808 
Epoch [139/300] Training metric {'Train/mean dice_metric': 0.9154995083808899, 'Train/mean miou_metric': 0.8556089997291565, 'Train/mean f1': 0.9272648692131042, 'Train/mean precision': 0.922297477722168, 'Train/mean recall': 0.9322860836982727, 'Train/mean hd95_metric': 16.716541290283203}
Epoch [139/300] Validation [1/16] Loss: 0.24874  focal_loss 0.09741  dice_loss 0.15132 
Epoch [139/300] Validation [2/16] Loss: 0.38823  focal_loss 0.12487  dice_loss 0.26337 
Epoch [139/300] Validation [3/16] Loss: 0.34874  focal_loss 0.10944  dice_loss 0.23930 
Epoch [139/300] Validation [4/16] Loss: 0.24312  focal_loss 0.09858  dice_loss 0.14454 
Epoch [139/300] Validation [5/16] Loss: 0.37439  focal_loss 0.09780  dice_loss 0.27659 
Epoch [139/300] Validation [6/16] Loss: 0.25664  focal_loss 0.06012  dice_loss 0.19652 
Epoch [139/300] Validation [7/16] Loss: 0.19902  focal_loss 0.05908  dice_loss 0.13995 
Epoch [139/300] Validation [8/16] Loss: 0.37465  focal_loss 0.11011  dice_loss 0.26454 
Epoch [139/300] Validation [9/16] Loss: 0.20193  focal_loss 0.06888  dice_loss 0.13306 
Epoch [139/300] Validation [10/16] Loss: 0.25970  focal_loss 0.06861  dice_loss 0.19110 
Epoch [139/300] Validation [11/16] Loss: 0.19455  focal_loss 0.04922  dice_loss 0.14533 
Epoch [139/300] Validation [12/16] Loss: 0.37294  focal_loss 0.06548  dice_loss 0.30746 
Epoch [139/300] Validation [13/16] Loss: 0.30461  focal_loss 0.08581  dice_loss 0.21880 
Epoch [139/300] Validation [14/16] Loss: 0.65375  focal_loss 0.21465  dice_loss 0.43909 
Epoch [139/300] Validation [15/16] Loss: 0.15092  focal_loss 0.04365  dice_loss 0.10727 
Epoch [139/300] Validation [16/16] Loss: 0.05340  focal_loss 0.00935  dice_loss 0.04405 
Epoch [139/300] Validation metric {'Val/mean dice_metric': 0.8919036388397217, 'Val/mean miou_metric': 0.8274874091148376, 'Val/mean f1': 0.903834342956543, 'Val/mean precision': 0.9019532799720764, 'Val/mean recall': 0.9057232737541199, 'Val/mean hd95_metric': 22.326379776000977}
Cheakpoint...
Epoch [139/300] best acc:tensor([0.8981], device='cuda:0'), Now : mean acc: tensor([0.8919], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8919036388397217, 'Val/mean miou_metric': 0.8274874091148376, 'Val/mean f1': 0.903834342956543, 'Val/mean precision': 0.9019532799720764, 'Val/mean recall': 0.9057232737541199, 'Val/mean hd95_metric': 22.326379776000977}
Epoch [140/300] Training [1/62] Loss: 0.08914 
Epoch [140/300] Training [2/62] Loss: 0.06495 
Epoch [140/300] Training [3/62] Loss: 0.14645 
Epoch [140/300] Training [4/62] Loss: 0.07322 
Epoch [140/300] Training [5/62] Loss: 0.12760 
Epoch [140/300] Training [6/62] Loss: 0.18094 
Epoch [140/300] Training [7/62] Loss: 0.10690 
Epoch [140/300] Training [8/62] Loss: 0.06574 
Epoch [140/300] Training [9/62] Loss: 0.11052 
Epoch [140/300] Training [10/62] Loss: 0.11150 
Epoch [140/300] Training [11/62] Loss: 0.08662 
Epoch [140/300] Training [12/62] Loss: 0.27805 
Epoch [140/300] Training [13/62] Loss: 0.11456 
Epoch [140/300] Training [14/62] Loss: 0.15595 
Epoch [140/300] Training [15/62] Loss: 0.12646 
Epoch [140/300] Training [16/62] Loss: 0.08263 
Epoch [140/300] Training [17/62] Loss: 0.23982 
Epoch [140/300] Training [18/62] Loss: 0.10508 
Epoch [140/300] Training [19/62] Loss: 0.07130 
Epoch [140/300] Training [20/62] Loss: 0.08622 
Epoch [140/300] Training [21/62] Loss: 0.06921 
Epoch [140/300] Training [22/62] Loss: 0.07287 
Epoch [140/300] Training [23/62] Loss: 0.12679 
Epoch [140/300] Training [24/62] Loss: 0.10739 
Epoch [140/300] Training [25/62] Loss: 0.08697 
Epoch [140/300] Training [26/62] Loss: 0.13713 
Epoch [140/300] Training [27/62] Loss: 0.14486 
Epoch [140/300] Training [28/62] Loss: 0.04956 
Epoch [140/300] Training [29/62] Loss: 0.09863 
Epoch [140/300] Training [30/62] Loss: 0.06407 
Epoch [140/300] Training [31/62] Loss: 0.16025 
Epoch [140/300] Training [32/62] Loss: 0.21890 
Epoch [140/300] Training [33/62] Loss: 0.08259 
Epoch [140/300] Training [34/62] Loss: 0.14230 
Epoch [140/300] Training [35/62] Loss: 0.11992 
Epoch [140/300] Training [36/62] Loss: 0.14611 
Epoch [140/300] Training [37/62] Loss: 0.19245 
Epoch [140/300] Training [38/62] Loss: 0.15511 
Epoch [140/300] Training [39/62] Loss: 0.13507 
Epoch [140/300] Training [40/62] Loss: 0.06509 
Epoch [140/300] Training [41/62] Loss: 0.06003 
Epoch [140/300] Training [42/62] Loss: 0.12581 
Epoch [140/300] Training [43/62] Loss: 0.15094 
Epoch [140/300] Training [44/62] Loss: 0.13817 
Epoch [140/300] Training [45/62] Loss: 0.22205 
Epoch [140/300] Training [46/62] Loss: 0.08766 
Epoch [140/300] Training [47/62] Loss: 0.19908 
Epoch [140/300] Training [48/62] Loss: 0.06633 
Epoch [140/300] Training [49/62] Loss: 0.08428 
Epoch [140/300] Training [50/62] Loss: 0.10479 
Epoch [140/300] Training [51/62] Loss: 0.10733 
Epoch [140/300] Training [52/62] Loss: 0.06745 
Epoch [140/300] Training [53/62] Loss: 0.06429 
Epoch [140/300] Training [54/62] Loss: 0.08950 
Epoch [140/300] Training [55/62] Loss: 0.41920 
Epoch [140/300] Training [56/62] Loss: 0.10076 
Epoch [140/300] Training [57/62] Loss: 0.11428 
Epoch [140/300] Training [58/62] Loss: 0.12808 
Epoch [140/300] Training [59/62] Loss: 0.06340 
Epoch [140/300] Training [60/62] Loss: 0.13165 
Epoch [140/300] Training [61/62] Loss: 0.16314 
Epoch [140/300] Training [62/62] Loss: 0.04547 
Epoch [140/300] Training metric {'Train/mean dice_metric': 0.9150450825691223, 'Train/mean miou_metric': 0.8571054935455322, 'Train/mean f1': 0.9279462695121765, 'Train/mean precision': 0.9198991656303406, 'Train/mean recall': 0.936135470867157, 'Train/mean hd95_metric': 16.93639373779297}
Epoch [140/300] Validation [1/16] Loss: 0.13006  focal_loss 0.03466  dice_loss 0.09540 
Epoch [140/300] Validation [2/16] Loss: 0.34358  focal_loss 0.10831  dice_loss 0.23528 
Epoch [140/300] Validation [3/16] Loss: 0.35900  focal_loss 0.12990  dice_loss 0.22910 
Epoch [140/300] Validation [4/16] Loss: 0.24600  focal_loss 0.11228  dice_loss 0.13372 
Epoch [140/300] Validation [5/16] Loss: 0.42077  focal_loss 0.12269  dice_loss 0.29808 
Epoch [140/300] Validation [6/16] Loss: 0.22035  focal_loss 0.04390  dice_loss 0.17645 
Epoch [140/300] Validation [7/16] Loss: 0.15172  focal_loss 0.03825  dice_loss 0.11348 
Epoch [140/300] Validation [8/16] Loss: 0.44977  focal_loss 0.17074  dice_loss 0.27903 
Epoch [140/300] Validation [9/16] Loss: 0.22695  focal_loss 0.08474  dice_loss 0.14221 
Epoch [140/300] Validation [10/16] Loss: 0.29832  focal_loss 0.11829  dice_loss 0.18003 
Epoch [140/300] Validation [11/16] Loss: 0.24362  focal_loss 0.07946  dice_loss 0.16416 
Epoch [140/300] Validation [12/16] Loss: 0.31862  focal_loss 0.06707  dice_loss 0.25155 
Epoch [140/300] Validation [13/16] Loss: 0.25255  focal_loss 0.06262  dice_loss 0.18994 
Epoch [140/300] Validation [14/16] Loss: 0.36342  focal_loss 0.11897  dice_loss 0.24445 
Epoch [140/300] Validation [15/16] Loss: 0.22833  focal_loss 0.06785  dice_loss 0.16048 
Epoch [140/300] Validation [16/16] Loss: 0.06321  focal_loss 0.01046  dice_loss 0.05275 
Epoch [140/300] Validation metric {'Val/mean dice_metric': 0.8968907594680786, 'Val/mean miou_metric': 0.8343738317489624, 'Val/mean f1': 0.9082024097442627, 'Val/mean precision': 0.8961023688316345, 'Val/mean recall': 0.9206337332725525, 'Val/mean hd95_metric': 21.745494842529297}
Cheakpoint...
Epoch [140/300] best acc:tensor([0.8981], device='cuda:0'), Now : mean acc: tensor([0.8969], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8968907594680786, 'Val/mean miou_metric': 0.8343738317489624, 'Val/mean f1': 0.9082024097442627, 'Val/mean precision': 0.8961023688316345, 'Val/mean recall': 0.9206337332725525, 'Val/mean hd95_metric': 21.745494842529297}
Epoch [141/300] Training [1/62] Loss: 0.09971 
Epoch [141/300] Training [2/62] Loss: 0.05148 
Epoch [141/300] Training [3/62] Loss: 0.16893 
Epoch [141/300] Training [4/62] Loss: 0.17822 
Epoch [141/300] Training [5/62] Loss: 0.08833 
Epoch [141/300] Training [6/62] Loss: 0.19556 
Epoch [141/300] Training [7/62] Loss: 0.11669 
Epoch [141/300] Training [8/62] Loss: 0.11651 
Epoch [141/300] Training [9/62] Loss: 0.07443 
Epoch [141/300] Training [10/62] Loss: 0.11373 
Epoch [141/300] Training [11/62] Loss: 0.07709 
Epoch [141/300] Training [12/62] Loss: 0.23115 
Epoch [141/300] Training [13/62] Loss: 0.08628 
Epoch [141/300] Training [14/62] Loss: 0.09800 
Epoch [141/300] Training [15/62] Loss: 0.10857 
Epoch [141/300] Training [16/62] Loss: 0.18195 
Epoch [141/300] Training [17/62] Loss: 0.12700 
Epoch [141/300] Training [18/62] Loss: 0.09248 
Epoch [141/300] Training [19/62] Loss: 0.09686 
Epoch [141/300] Training [20/62] Loss: 0.11190 
Epoch [141/300] Training [21/62] Loss: 0.08231 
Epoch [141/300] Training [22/62] Loss: 0.07521 
Epoch [141/300] Training [23/62] Loss: 0.09870 
Epoch [141/300] Training [24/62] Loss: 0.17750 
Epoch [141/300] Training [25/62] Loss: 0.09061 
Epoch [141/300] Training [26/62] Loss: 0.14450 
Epoch [141/300] Training [27/62] Loss: 0.12089 
Epoch [141/300] Training [28/62] Loss: 0.06505 
Epoch [141/300] Training [29/62] Loss: 0.14837 
Epoch [141/300] Training [30/62] Loss: 0.06369 
Epoch [141/300] Training [31/62] Loss: 0.14705 
Epoch [141/300] Training [32/62] Loss: 0.07578 
Epoch [141/300] Training [33/62] Loss: 0.15212 
Epoch [141/300] Training [34/62] Loss: 0.08600 
Epoch [141/300] Training [35/62] Loss: 0.08831 
Epoch [141/300] Training [36/62] Loss: 0.07218 
Epoch [141/300] Training [37/62] Loss: 0.07473 
Epoch [141/300] Training [38/62] Loss: 0.12181 
Epoch [141/300] Training [39/62] Loss: 0.10745 
Epoch [141/300] Training [40/62] Loss: 0.07643 
Epoch [141/300] Training [41/62] Loss: 0.30218 
Epoch [141/300] Training [42/62] Loss: 0.07863 
Epoch [141/300] Training [43/62] Loss: 0.19075 
Epoch [141/300] Training [44/62] Loss: 0.14960 
Epoch [141/300] Training [45/62] Loss: 0.16927 
Epoch [141/300] Training [46/62] Loss: 0.17423 
Epoch [141/300] Training [47/62] Loss: 0.15281 
Epoch [141/300] Training [48/62] Loss: 0.06951 
Epoch [141/300] Training [49/62] Loss: 0.09375 
Epoch [141/300] Training [50/62] Loss: 0.07219 
Epoch [141/300] Training [51/62] Loss: 0.14980 
Epoch [141/300] Training [52/62] Loss: 0.14932 
Epoch [141/300] Training [53/62] Loss: 0.15320 
Epoch [141/300] Training [54/62] Loss: 0.07572 
Epoch [141/300] Training [55/62] Loss: 0.08152 
Epoch [141/300] Training [56/62] Loss: 0.12524 
Epoch [141/300] Training [57/62] Loss: 0.15967 
Epoch [141/300] Training [58/62] Loss: 0.08225 
Epoch [141/300] Training [59/62] Loss: 0.08455 
Epoch [141/300] Training [60/62] Loss: 0.18700 
Epoch [141/300] Training [61/62] Loss: 0.09197 
Epoch [141/300] Training [62/62] Loss: 0.09291 
Epoch [141/300] Training metric {'Train/mean dice_metric': 0.9166016578674316, 'Train/mean miou_metric': 0.857724666595459, 'Train/mean f1': 0.9312587976455688, 'Train/mean precision': 0.9278346300125122, 'Train/mean recall': 0.9347084164619446, 'Train/mean hd95_metric': 16.144569396972656}
Epoch [141/300] Validation [1/16] Loss: 0.11901  focal_loss 0.03027  dice_loss 0.08874 
Epoch [141/300] Validation [2/16] Loss: 0.26766  focal_loss 0.05728  dice_loss 0.21038 
Epoch [141/300] Validation [3/16] Loss: 0.33663  focal_loss 0.11109  dice_loss 0.22554 
Epoch [141/300] Validation [4/16] Loss: 0.19626  focal_loss 0.05236  dice_loss 0.14390 
Epoch [141/300] Validation [5/16] Loss: 0.22406  focal_loss 0.05456  dice_loss 0.16949 
Epoch [141/300] Validation [6/16] Loss: 0.17736  focal_loss 0.03120  dice_loss 0.14616 
Epoch [141/300] Validation [7/16] Loss: 0.16257  focal_loss 0.03671  dice_loss 0.12586 
Epoch [141/300] Validation [8/16] Loss: 0.32784  focal_loss 0.11141  dice_loss 0.21643 
Epoch [141/300] Validation [9/16] Loss: 0.15774  focal_loss 0.05497  dice_loss 0.10277 
Epoch [141/300] Validation [10/16] Loss: 0.28982  focal_loss 0.09200  dice_loss 0.19782 
Epoch [141/300] Validation [11/16] Loss: 0.17302  focal_loss 0.03857  dice_loss 0.13445 
Epoch [141/300] Validation [12/16] Loss: 0.35254  focal_loss 0.09621  dice_loss 0.25633 
Epoch [141/300] Validation [13/16] Loss: 0.28105  focal_loss 0.07798  dice_loss 0.20307 
Epoch [141/300] Validation [14/16] Loss: 0.41352  focal_loss 0.13425  dice_loss 0.27926 
Epoch [141/300] Validation [15/16] Loss: 0.12553  focal_loss 0.03345  dice_loss 0.09208 
Epoch [141/300] Validation [16/16] Loss: 0.08241  focal_loss 0.01351  dice_loss 0.06891 
Epoch [141/300] Validation metric {'Val/mean dice_metric': 0.9016750454902649, 'Val/mean miou_metric': 0.8381528258323669, 'Val/mean f1': 0.9143256545066833, 'Val/mean precision': 0.9038001298904419, 'Val/mean recall': 0.9250993132591248, 'Val/mean hd95_metric': 21.735858917236328}
Cheakpoint...
Epoch [141/300] best acc:tensor([0.9017], device='cuda:0'), Now : mean acc: tensor([0.9017], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9016750454902649, 'Val/mean miou_metric': 0.8381528258323669, 'Val/mean f1': 0.9143256545066833, 'Val/mean precision': 0.9038001298904419, 'Val/mean recall': 0.9250993132591248, 'Val/mean hd95_metric': 21.735858917236328}
Epoch [142/300] Training [1/62] Loss: 0.09390 
Epoch [142/300] Training [2/62] Loss: 0.10339 
Epoch [142/300] Training [3/62] Loss: 0.11015 
Epoch [142/300] Training [4/62] Loss: 0.09851 
Epoch [142/300] Training [5/62] Loss: 0.11599 
Epoch [142/300] Training [6/62] Loss: 0.08139 
Epoch [142/300] Training [7/62] Loss: 0.10811 
Epoch [142/300] Training [8/62] Loss: 0.14114 
Epoch [142/300] Training [9/62] Loss: 0.08297 
Epoch [142/300] Training [10/62] Loss: 0.13227 
Epoch [142/300] Training [11/62] Loss: 0.10459 
Epoch [142/300] Training [12/62] Loss: 0.10508 
Epoch [142/300] Training [13/62] Loss: 0.13446 
Epoch [142/300] Training [14/62] Loss: 0.21032 
Epoch [142/300] Training [15/62] Loss: 0.11985 
Epoch [142/300] Training [16/62] Loss: 0.19151 
Epoch [142/300] Training [17/62] Loss: 0.17463 
Epoch [142/300] Training [18/62] Loss: 0.12119 
Epoch [142/300] Training [19/62] Loss: 0.24917 
Epoch [142/300] Training [20/62] Loss: 0.10151 
Epoch [142/300] Training [21/62] Loss: 0.11413 
Epoch [142/300] Training [22/62] Loss: 0.14177 
Epoch [142/300] Training [23/62] Loss: 0.07139 
Epoch [142/300] Training [24/62] Loss: 0.10137 
Epoch [142/300] Training [25/62] Loss: 0.07988 
Epoch [142/300] Training [26/62] Loss: 0.11474 
Epoch [142/300] Training [27/62] Loss: 0.21476 
Epoch [142/300] Training [28/62] Loss: 0.14397 
Epoch [142/300] Training [29/62] Loss: 0.34368 
Epoch [142/300] Training [30/62] Loss: 0.39055 
Epoch [142/300] Training [31/62] Loss: 0.10056 
Epoch [142/300] Training [32/62] Loss: 0.12574 
Epoch [142/300] Training [33/62] Loss: 0.13278 
Epoch [142/300] Training [34/62] Loss: 0.09520 
Epoch [142/300] Training [35/62] Loss: 0.19530 
Epoch [142/300] Training [36/62] Loss: 0.14686 
Epoch [142/300] Training [37/62] Loss: 0.11961 
Epoch [142/300] Training [38/62] Loss: 0.10778 
Epoch [142/300] Training [39/62] Loss: 0.07702 
Epoch [142/300] Training [40/62] Loss: 0.13521 
Epoch [142/300] Training [41/62] Loss: 0.13996 
Epoch [142/300] Training [42/62] Loss: 0.06359 
Epoch [142/300] Training [43/62] Loss: 0.15371 
Epoch [142/300] Training [44/62] Loss: 0.08718 
Epoch [142/300] Training [45/62] Loss: 0.20879 
Epoch [142/300] Training [46/62] Loss: 0.20958 
Epoch [142/300] Training [47/62] Loss: 0.06059 
Epoch [142/300] Training [48/62] Loss: 0.11055 
Epoch [142/300] Training [49/62] Loss: 0.07097 
Epoch [142/300] Training [50/62] Loss: 0.09934 
Epoch [142/300] Training [51/62] Loss: 0.08506 
Epoch [142/300] Training [52/62] Loss: 0.06112 
Epoch [142/300] Training [53/62] Loss: 0.05566 
Epoch [142/300] Training [54/62] Loss: 0.09704 
Epoch [142/300] Training [55/62] Loss: 0.08233 
Epoch [142/300] Training [56/62] Loss: 0.15661 
Epoch [142/300] Training [57/62] Loss: 0.07233 
Epoch [142/300] Training [58/62] Loss: 0.10786 
Epoch [142/300] Training [59/62] Loss: 0.11614 
Epoch [142/300] Training [60/62] Loss: 0.08930 
Epoch [142/300] Training [61/62] Loss: 0.09790 
Epoch [142/300] Training [62/62] Loss: 0.08387 
Epoch [142/300] Training metric {'Train/mean dice_metric': 0.910967230796814, 'Train/mean miou_metric': 0.8498725891113281, 'Train/mean f1': 0.9281557202339172, 'Train/mean precision': 0.9219143986701965, 'Train/mean recall': 0.9344822764396667, 'Train/mean hd95_metric': 17.216312408447266}
Epoch [142/300] Validation [1/16] Loss: 0.10485  focal_loss 0.02754  dice_loss 0.07732 
Epoch [142/300] Validation [2/16] Loss: 0.27666  focal_loss 0.07063  dice_loss 0.20603 
Epoch [142/300] Validation [3/16] Loss: 0.34097  focal_loss 0.10486  dice_loss 0.23611 
Epoch [142/300] Validation [4/16] Loss: 0.35387  focal_loss 0.10873  dice_loss 0.24514 
Epoch [142/300] Validation [5/16] Loss: 0.36424  focal_loss 0.11261  dice_loss 0.25163 
Epoch [142/300] Validation [6/16] Loss: 0.22193  focal_loss 0.04668  dice_loss 0.17525 
Epoch [142/300] Validation [7/16] Loss: 0.12994  focal_loss 0.02858  dice_loss 0.10136 
Epoch [142/300] Validation [8/16] Loss: 0.36516  focal_loss 0.14079  dice_loss 0.22437 
Epoch [142/300] Validation [9/16] Loss: 0.23596  focal_loss 0.09775  dice_loss 0.13821 
Epoch [142/300] Validation [10/16] Loss: 0.20271  focal_loss 0.04523  dice_loss 0.15749 
Epoch [142/300] Validation [11/16] Loss: 0.16255  focal_loss 0.03639  dice_loss 0.12616 
Epoch [142/300] Validation [12/16] Loss: 0.29741  focal_loss 0.07627  dice_loss 0.22114 
Epoch [142/300] Validation [13/16] Loss: 0.36913  focal_loss 0.14712  dice_loss 0.22201 
Epoch [142/300] Validation [14/16] Loss: 0.37806  focal_loss 0.10390  dice_loss 0.27415 
Epoch [142/300] Validation [15/16] Loss: 0.13011  focal_loss 0.03627  dice_loss 0.09384 
Epoch [142/300] Validation [16/16] Loss: 0.06498  focal_loss 0.01404  dice_loss 0.05093 
Epoch [142/300] Validation metric {'Val/mean dice_metric': 0.8950724005699158, 'Val/mean miou_metric': 0.8303388953208923, 'Val/mean f1': 0.9105148315429688, 'Val/mean precision': 0.9001632928848267, 'Val/mean recall': 0.9211072325706482, 'Val/mean hd95_metric': 21.899076461791992}
Cheakpoint...
Epoch [142/300] best acc:tensor([0.9017], device='cuda:0'), Now : mean acc: tensor([0.8951], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8950724005699158, 'Val/mean miou_metric': 0.8303388953208923, 'Val/mean f1': 0.9105148315429688, 'Val/mean precision': 0.9001632928848267, 'Val/mean recall': 0.9211072325706482, 'Val/mean hd95_metric': 21.899076461791992}
Epoch [143/300] Training [1/62] Loss: 0.11379 
Epoch [143/300] Training [2/62] Loss: 0.07112 
Epoch [143/300] Training [3/62] Loss: 0.06380 
Epoch [143/300] Training [4/62] Loss: 0.14698 
Epoch [143/300] Training [5/62] Loss: 0.17921 
Epoch [143/300] Training [6/62] Loss: 0.06277 
Epoch [143/300] Training [7/62] Loss: 0.08704 
Epoch [143/300] Training [8/62] Loss: 0.17084 
Epoch [143/300] Training [9/62] Loss: 0.08925 
Epoch [143/300] Training [10/62] Loss: 0.21913 
Epoch [143/300] Training [11/62] Loss: 0.12006 
Epoch [143/300] Training [12/62] Loss: 0.09284 
Epoch [143/300] Training [13/62] Loss: 0.11325 
Epoch [143/300] Training [14/62] Loss: 0.14763 
Epoch [143/300] Training [15/62] Loss: 0.13826 
Epoch [143/300] Training [16/62] Loss: 0.09658 
Epoch [143/300] Training [17/62] Loss: 0.08564 
Epoch [143/300] Training [18/62] Loss: 0.10305 
Epoch [143/300] Training [19/62] Loss: 0.09928 
Epoch [143/300] Training [20/62] Loss: 0.24125 
Epoch [143/300] Training [21/62] Loss: 0.10823 
Epoch [143/300] Training [22/62] Loss: 0.12356 
Epoch [143/300] Training [23/62] Loss: 0.10688 
Epoch [143/300] Training [24/62] Loss: 0.18192 
Epoch [143/300] Training [25/62] Loss: 0.12735 
Epoch [143/300] Training [26/62] Loss: 0.08203 
Epoch [143/300] Training [27/62] Loss: 0.18066 
Epoch [143/300] Training [28/62] Loss: 0.12511 
Epoch [143/300] Training [29/62] Loss: 0.07532 
Epoch [143/300] Training [30/62] Loss: 0.12271 
Epoch [143/300] Training [31/62] Loss: 0.11363 
Epoch [143/300] Training [32/62] Loss: 0.16660 
Epoch [143/300] Training [33/62] Loss: 0.10082 
Epoch [143/300] Training [34/62] Loss: 0.07593 
Epoch [143/300] Training [35/62] Loss: 0.21524 
Epoch [143/300] Training [36/62] Loss: 0.08217 
Epoch [143/300] Training [37/62] Loss: 0.06802 
Epoch [143/300] Training [38/62] Loss: 0.11019 
Epoch [143/300] Training [39/62] Loss: 0.14181 
Epoch [143/300] Training [40/62] Loss: 0.07226 
Epoch [143/300] Training [41/62] Loss: 0.09369 
Epoch [143/300] Training [42/62] Loss: 0.16054 
Epoch [143/300] Training [43/62] Loss: 0.08455 
Epoch [143/300] Training [44/62] Loss: 0.10433 
Epoch [143/300] Training [45/62] Loss: 0.08142 
Epoch [143/300] Training [46/62] Loss: 0.15928 
Epoch [143/300] Training [47/62] Loss: 0.15921 
Epoch [143/300] Training [48/62] Loss: 0.18857 
Epoch [143/300] Training [49/62] Loss: 0.08084 
Epoch [143/300] Training [50/62] Loss: 0.11061 
Epoch [143/300] Training [51/62] Loss: 0.09082 
Epoch [143/300] Training [52/62] Loss: 0.10086 
Epoch [143/300] Training [53/62] Loss: 0.10431 
Epoch [143/300] Training [54/62] Loss: 0.11957 
Epoch [143/300] Training [55/62] Loss: 0.24501 
Epoch [143/300] Training [56/62] Loss: 0.08490 
Epoch [143/300] Training [57/62] Loss: 0.08888 
Epoch [143/300] Training [58/62] Loss: 0.13984 
Epoch [143/300] Training [59/62] Loss: 0.07150 
Epoch [143/300] Training [60/62] Loss: 0.27317 
Epoch [143/300] Training [61/62] Loss: 0.08687 
Epoch [143/300] Training [62/62] Loss: 0.16545 
Epoch [143/300] Training metric {'Train/mean dice_metric': 0.9142884612083435, 'Train/mean miou_metric': 0.8564730286598206, 'Train/mean f1': 0.9304394721984863, 'Train/mean precision': 0.9256856441497803, 'Train/mean recall': 0.9352424144744873, 'Train/mean hd95_metric': 16.567140579223633}
Epoch [143/300] Validation [1/16] Loss: 0.25919  focal_loss 0.09427  dice_loss 0.16493 
Epoch [143/300] Validation [2/16] Loss: 0.29597  focal_loss 0.07995  dice_loss 0.21602 
Epoch [143/300] Validation [3/16] Loss: 0.45667  focal_loss 0.18050  dice_loss 0.27617 
Epoch [143/300] Validation [4/16] Loss: 0.32365  focal_loss 0.16109  dice_loss 0.16257 
Epoch [143/300] Validation [5/16] Loss: 0.37369  focal_loss 0.13478  dice_loss 0.23892 
Epoch [143/300] Validation [6/16] Loss: 0.22456  focal_loss 0.05324  dice_loss 0.17133 
Epoch [143/300] Validation [7/16] Loss: 0.27187  focal_loss 0.07206  dice_loss 0.19981 
Epoch [143/300] Validation [8/16] Loss: 0.38365  focal_loss 0.13984  dice_loss 0.24381 
Epoch [143/300] Validation [9/16] Loss: 0.20841  focal_loss 0.06174  dice_loss 0.14667 
Epoch [143/300] Validation [10/16] Loss: 0.33146  focal_loss 0.15069  dice_loss 0.18077 
Epoch [143/300] Validation [11/16] Loss: 0.15270  focal_loss 0.03272  dice_loss 0.11998 
Epoch [143/300] Validation [12/16] Loss: 0.34874  focal_loss 0.10832  dice_loss 0.24042 
Epoch [143/300] Validation [13/16] Loss: 0.28046  focal_loss 0.08073  dice_loss 0.19973 
Epoch [143/300] Validation [14/16] Loss: 0.42371  focal_loss 0.12010  dice_loss 0.30362 
Epoch [143/300] Validation [15/16] Loss: 0.17285  focal_loss 0.05077  dice_loss 0.12208 
Epoch [143/300] Validation [16/16] Loss: 0.06810  focal_loss 0.01239  dice_loss 0.05572 
Epoch [143/300] Validation metric {'Val/mean dice_metric': 0.8942531943321228, 'Val/mean miou_metric': 0.8309242129325867, 'Val/mean f1': 0.9074186086654663, 'Val/mean precision': 0.9043272733688354, 'Val/mean recall': 0.9105312824249268, 'Val/mean hd95_metric': 21.8848876953125}
Cheakpoint...
Epoch [143/300] best acc:tensor([0.9017], device='cuda:0'), Now : mean acc: tensor([0.8943], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8942531943321228, 'Val/mean miou_metric': 0.8309242129325867, 'Val/mean f1': 0.9074186086654663, 'Val/mean precision': 0.9043272733688354, 'Val/mean recall': 0.9105312824249268, 'Val/mean hd95_metric': 21.8848876953125}
Epoch [144/300] Training [1/62] Loss: 0.12324 
Epoch [144/300] Training [2/62] Loss: 0.14010 
Epoch [144/300] Training [3/62] Loss: 0.11701 
Epoch [144/300] Training [4/62] Loss: 0.06379 
Epoch [144/300] Training [5/62] Loss: 0.08999 
Epoch [144/300] Training [6/62] Loss: 0.15928 
Epoch [144/300] Training [7/62] Loss: 0.10289 
Epoch [144/300] Training [8/62] Loss: 0.20003 
Epoch [144/300] Training [9/62] Loss: 0.09634 
Epoch [144/300] Training [10/62] Loss: 0.08025 
Epoch [144/300] Training [11/62] Loss: 0.13383 
Epoch [144/300] Training [12/62] Loss: 0.18006 
Epoch [144/300] Training [13/62] Loss: 0.11263 
Epoch [144/300] Training [14/62] Loss: 0.09082 
Epoch [144/300] Training [15/62] Loss: 0.12933 
Epoch [144/300] Training [16/62] Loss: 0.11351 
Epoch [144/300] Training [17/62] Loss: 0.07512 
Epoch [144/300] Training [18/62] Loss: 0.09351 
Epoch [144/300] Training [19/62] Loss: 0.10026 
Epoch [144/300] Training [20/62] Loss: 0.06174 
Epoch [144/300] Training [21/62] Loss: 0.05311 
Epoch [144/300] Training [22/62] Loss: 0.11964 
Epoch [144/300] Training [23/62] Loss: 0.24073 
Epoch [144/300] Training [24/62] Loss: 0.07985 
Epoch [144/300] Training [25/62] Loss: 0.09937 
Epoch [144/300] Training [26/62] Loss: 0.10955 
Epoch [144/300] Training [27/62] Loss: 0.12001 
Epoch [144/300] Training [28/62] Loss: 0.06892 
Epoch [144/300] Training [29/62] Loss: 0.08857 
Epoch [144/300] Training [30/62] Loss: 0.19476 
Epoch [144/300] Training [31/62] Loss: 0.13352 
Epoch [144/300] Training [32/62] Loss: 0.08273 
Epoch [144/300] Training [33/62] Loss: 0.15841 
Epoch [144/300] Training [34/62] Loss: 0.22917 
Epoch [144/300] Training [35/62] Loss: 0.06174 
Epoch [144/300] Training [36/62] Loss: 0.06954 
Epoch [144/300] Training [37/62] Loss: 0.12788 
Epoch [144/300] Training [38/62] Loss: 0.11240 
Epoch [144/300] Training [39/62] Loss: 0.06251 
Epoch [144/300] Training [40/62] Loss: 0.07718 
Epoch [144/300] Training [41/62] Loss: 0.10532 
Epoch [144/300] Training [42/62] Loss: 0.11311 
Epoch [144/300] Training [43/62] Loss: 0.07375 
Epoch [144/300] Training [44/62] Loss: 0.07584 
Epoch [144/300] Training [45/62] Loss: 0.11376 
Epoch [144/300] Training [46/62] Loss: 0.19488 
Epoch [144/300] Training [47/62] Loss: 0.10241 
Epoch [144/300] Training [48/62] Loss: 0.08933 
Epoch [144/300] Training [49/62] Loss: 0.14163 
Epoch [144/300] Training [50/62] Loss: 0.21880 
Epoch [144/300] Training [51/62] Loss: 0.06496 
Epoch [144/300] Training [52/62] Loss: 0.11621 
Epoch [144/300] Training [53/62] Loss: 0.07535 
Epoch [144/300] Training [54/62] Loss: 0.12795 
Epoch [144/300] Training [55/62] Loss: 0.09394 
Epoch [144/300] Training [56/62] Loss: 0.11828 
Epoch [144/300] Training [57/62] Loss: 0.07078 
Epoch [144/300] Training [58/62] Loss: 0.09145 
Epoch [144/300] Training [59/62] Loss: 0.09072 
Epoch [144/300] Training [60/62] Loss: 0.10012 
Epoch [144/300] Training [61/62] Loss: 0.08325 
Epoch [144/300] Training [62/62] Loss: 0.20145 
Epoch [144/300] Training metric {'Train/mean dice_metric': 0.9238737225532532, 'Train/mean miou_metric': 0.8683022260665894, 'Train/mean f1': 0.9342798590660095, 'Train/mean precision': 0.9286195039749146, 'Train/mean recall': 0.9400097727775574, 'Train/mean hd95_metric': 14.953598022460938}
Epoch [144/300] Validation [1/16] Loss: 0.47472  focal_loss 0.25290  dice_loss 0.22182 
Epoch [144/300] Validation [2/16] Loss: 0.33002  focal_loss 0.10535  dice_loss 0.22467 
Epoch [144/300] Validation [3/16] Loss: 0.68530  focal_loss 0.37759  dice_loss 0.30772 
Epoch [144/300] Validation [4/16] Loss: 0.28330  focal_loss 0.09831  dice_loss 0.18499 
Epoch [144/300] Validation [5/16] Loss: 0.35224  focal_loss 0.10476  dice_loss 0.24748 
Epoch [144/300] Validation [6/16] Loss: 0.27078  focal_loss 0.07081  dice_loss 0.19998 
Epoch [144/300] Validation [7/16] Loss: 0.18892  focal_loss 0.05434  dice_loss 0.13458 
Epoch [144/300] Validation [8/16] Loss: 0.51837  focal_loss 0.19576  dice_loss 0.32261 
Epoch [144/300] Validation [9/16] Loss: 0.25650  focal_loss 0.09024  dice_loss 0.16625 
Epoch [144/300] Validation [10/16] Loss: 0.30827  focal_loss 0.09159  dice_loss 0.21668 
Epoch [144/300] Validation [11/16] Loss: 0.14855  focal_loss 0.03472  dice_loss 0.11383 
Epoch [144/300] Validation [12/16] Loss: 0.31171  focal_loss 0.07150  dice_loss 0.24021 
Epoch [144/300] Validation [13/16] Loss: 0.39021  focal_loss 0.14759  dice_loss 0.24262 
Epoch [144/300] Validation [14/16] Loss: 0.46310  focal_loss 0.12548  dice_loss 0.33763 
Epoch [144/300] Validation [15/16] Loss: 0.23330  focal_loss 0.08770  dice_loss 0.14560 
Epoch [144/300] Validation [16/16] Loss: 0.05734  focal_loss 0.01241  dice_loss 0.04493 
Epoch [144/300] Validation metric {'Val/mean dice_metric': 0.8973378539085388, 'Val/mean miou_metric': 0.8357822895050049, 'Val/mean f1': 0.9081372618675232, 'Val/mean precision': 0.9090125560760498, 'Val/mean recall': 0.9072636961936951, 'Val/mean hd95_metric': 21.37420082092285}
Cheakpoint...
Epoch [144/300] best acc:tensor([0.9017], device='cuda:0'), Now : mean acc: tensor([0.8973], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8973378539085388, 'Val/mean miou_metric': 0.8357822895050049, 'Val/mean f1': 0.9081372618675232, 'Val/mean precision': 0.9090125560760498, 'Val/mean recall': 0.9072636961936951, 'Val/mean hd95_metric': 21.37420082092285}
Epoch [145/300] Training [1/62] Loss: 0.09119 
Epoch [145/300] Training [2/62] Loss: 0.15133 
Epoch [145/300] Training [3/62] Loss: 0.11095 
Epoch [145/300] Training [4/62] Loss: 0.23496 
Epoch [145/300] Training [5/62] Loss: 0.17266 
Epoch [145/300] Training [6/62] Loss: 0.08248 
Epoch [145/300] Training [7/62] Loss: 0.14712 
Epoch [145/300] Training [8/62] Loss: 0.06462 
Epoch [145/300] Training [9/62] Loss: 0.12799 
Epoch [145/300] Training [10/62] Loss: 0.12896 
Epoch [145/300] Training [11/62] Loss: 0.08144 
Epoch [145/300] Training [12/62] Loss: 0.16869 
Epoch [145/300] Training [13/62] Loss: 0.12275 
Epoch [145/300] Training [14/62] Loss: 0.13279 
Epoch [145/300] Training [15/62] Loss: 0.10909 
Epoch [145/300] Training [16/62] Loss: 0.12740 
Epoch [145/300] Training [17/62] Loss: 0.09192 
Epoch [145/300] Training [18/62] Loss: 0.08022 
Epoch [145/300] Training [19/62] Loss: 0.21876 
Epoch [145/300] Training [20/62] Loss: 0.08521 
Epoch [145/300] Training [21/62] Loss: 0.12001 
Epoch [145/300] Training [22/62] Loss: 0.07767 
Epoch [145/300] Training [23/62] Loss: 0.11176 
Epoch [145/300] Training [24/62] Loss: 0.08098 
Epoch [145/300] Training [25/62] Loss: 0.15141 
Epoch [145/300] Training [26/62] Loss: 0.20079 
Epoch [145/300] Training [27/62] Loss: 0.10978 
Epoch [145/300] Training [28/62] Loss: 0.11653 
Epoch [145/300] Training [29/62] Loss: 0.08678 
Epoch [145/300] Training [30/62] Loss: 0.06859 
Epoch [145/300] Training [31/62] Loss: 0.09079 
Epoch [145/300] Training [32/62] Loss: 0.09979 
Epoch [145/300] Training [33/62] Loss: 0.13204 
Epoch [145/300] Training [34/62] Loss: 0.08853 
Epoch [145/300] Training [35/62] Loss: 0.07160 
Epoch [145/300] Training [36/62] Loss: 0.11654 
Epoch [145/300] Training [37/62] Loss: 0.13449 
Epoch [145/300] Training [38/62] Loss: 0.11380 
Epoch [145/300] Training [39/62] Loss: 0.06694 
Epoch [145/300] Training [40/62] Loss: 0.15218 
Epoch [145/300] Training [41/62] Loss: 0.07717 
Epoch [145/300] Training [42/62] Loss: 0.25554 
Epoch [145/300] Training [43/62] Loss: 0.12138 
Epoch [145/300] Training [44/62] Loss: 0.08731 
Epoch [145/300] Training [45/62] Loss: 0.09384 
Epoch [145/300] Training [46/62] Loss: 0.09316 
Epoch [145/300] Training [47/62] Loss: 0.08269 
Epoch [145/300] Training [48/62] Loss: 0.17363 
Epoch [145/300] Training [49/62] Loss: 0.16651 
Epoch [145/300] Training [50/62] Loss: 0.12456 
Epoch [145/300] Training [51/62] Loss: 0.08927 
Epoch [145/300] Training [52/62] Loss: 0.11118 
Epoch [145/300] Training [53/62] Loss: 0.07277 
Epoch [145/300] Training [54/62] Loss: 0.11164 
Epoch [145/300] Training [55/62] Loss: 0.10264 
Epoch [145/300] Training [56/62] Loss: 0.12289 
Epoch [145/300] Training [57/62] Loss: 0.13449 
Epoch [145/300] Training [58/62] Loss: 0.09504 
Epoch [145/300] Training [59/62] Loss: 0.08466 
Epoch [145/300] Training [60/62] Loss: 0.08152 
Epoch [145/300] Training [61/62] Loss: 0.13902 
Epoch [145/300] Training [62/62] Loss: 0.12498 
Epoch [145/300] Training metric {'Train/mean dice_metric': 0.91963130235672, 'Train/mean miou_metric': 0.8615775108337402, 'Train/mean f1': 0.9300875067710876, 'Train/mean precision': 0.9283776879310608, 'Train/mean recall': 0.9318036437034607, 'Train/mean hd95_metric': 15.448657989501953}
Epoch [145/300] Validation [1/16] Loss: 0.16135  focal_loss 0.04428  dice_loss 0.11707 
Epoch [145/300] Validation [2/16] Loss: 0.27238  focal_loss 0.09543  dice_loss 0.17695 
Epoch [145/300] Validation [3/16] Loss: 0.26202  focal_loss 0.03698  dice_loss 0.22504 
Epoch [145/300] Validation [4/16] Loss: 0.23409  focal_loss 0.07637  dice_loss 0.15772 
Epoch [145/300] Validation [5/16] Loss: 0.29526  focal_loss 0.07617  dice_loss 0.21909 
Epoch [145/300] Validation [6/16] Loss: 0.17853  focal_loss 0.02623  dice_loss 0.15231 
Epoch [145/300] Validation [7/16] Loss: 0.23643  focal_loss 0.06126  dice_loss 0.17518 
Epoch [145/300] Validation [8/16] Loss: 0.44917  focal_loss 0.14120  dice_loss 0.30796 
Epoch [145/300] Validation [9/16] Loss: 0.23811  focal_loss 0.07424  dice_loss 0.16387 
Epoch [145/300] Validation [10/16] Loss: 0.16816  focal_loss 0.03613  dice_loss 0.13203 
Epoch [145/300] Validation [11/16] Loss: 0.13635  focal_loss 0.03048  dice_loss 0.10586 
Epoch [145/300] Validation [12/16] Loss: 0.31640  focal_loss 0.06069  dice_loss 0.25571 
Epoch [145/300] Validation [13/16] Loss: 0.32255  focal_loss 0.13437  dice_loss 0.18818 
Epoch [145/300] Validation [14/16] Loss: 0.50902  focal_loss 0.17125  dice_loss 0.33777 
Epoch [145/300] Validation [15/16] Loss: 0.18911  focal_loss 0.05073  dice_loss 0.13838 
Epoch [145/300] Validation [16/16] Loss: 0.07775  focal_loss 0.01789  dice_loss 0.05986 
Epoch [145/300] Validation metric {'Val/mean dice_metric': 0.9010615348815918, 'Val/mean miou_metric': 0.8374438285827637, 'Val/mean f1': 0.9095993638038635, 'Val/mean precision': 0.8987770080566406, 'Val/mean recall': 0.9206854104995728, 'Val/mean hd95_metric': 20.688060760498047}
Cheakpoint...
Epoch [145/300] best acc:tensor([0.9017], device='cuda:0'), Now : mean acc: tensor([0.9011], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9010615348815918, 'Val/mean miou_metric': 0.8374438285827637, 'Val/mean f1': 0.9095993638038635, 'Val/mean precision': 0.8987770080566406, 'Val/mean recall': 0.9206854104995728, 'Val/mean hd95_metric': 20.688060760498047}
Epoch [146/300] Training [1/62] Loss: 0.09342 
Epoch [146/300] Training [2/62] Loss: 0.09751 
Epoch [146/300] Training [3/62] Loss: 0.08593 
Epoch [146/300] Training [4/62] Loss: 0.11157 
Epoch [146/300] Training [5/62] Loss: 0.07554 
Epoch [146/300] Training [6/62] Loss: 0.17845 
Epoch [146/300] Training [7/62] Loss: 0.08941 
Epoch [146/300] Training [8/62] Loss: 0.08240 
Epoch [146/300] Training [9/62] Loss: 0.16584 
Epoch [146/300] Training [10/62] Loss: 0.14865 
Epoch [146/300] Training [11/62] Loss: 0.11930 
Epoch [146/300] Training [12/62] Loss: 0.11673 
Epoch [146/300] Training [13/62] Loss: 0.13624 
Epoch [146/300] Training [14/62] Loss: 0.09759 
Epoch [146/300] Training [15/62] Loss: 0.07884 
Epoch [146/300] Training [16/62] Loss: 0.11950 
Epoch [146/300] Training [17/62] Loss: 0.07891 
Epoch [146/300] Training [18/62] Loss: 0.08618 
Epoch [146/300] Training [19/62] Loss: 0.13606 
Epoch [146/300] Training [20/62] Loss: 0.15660 
Epoch [146/300] Training [21/62] Loss: 0.07990 
Epoch [146/300] Training [22/62] Loss: 0.13129 
Epoch [146/300] Training [23/62] Loss: 0.13378 
Epoch [146/300] Training [24/62] Loss: 0.13627 
Epoch [146/300] Training [25/62] Loss: 0.07876 
Epoch [146/300] Training [26/62] Loss: 0.06096 
Epoch [146/300] Training [27/62] Loss: 0.08656 
Epoch [146/300] Training [28/62] Loss: 0.11448 
Epoch [146/300] Training [29/62] Loss: 0.07367 
Epoch [146/300] Training [30/62] Loss: 0.06760 
Epoch [146/300] Training [31/62] Loss: 0.05403 
Epoch [146/300] Training [32/62] Loss: 0.06841 
Epoch [146/300] Training [33/62] Loss: 0.09624 
Epoch [146/300] Training [34/62] Loss: 0.09423 
Epoch [146/300] Training [35/62] Loss: 0.09024 
Epoch [146/300] Training [36/62] Loss: 0.08137 
Epoch [146/300] Training [37/62] Loss: 0.22541 
Epoch [146/300] Training [38/62] Loss: 0.07754 
Epoch [146/300] Training [39/62] Loss: 0.20780 
Epoch [146/300] Training [40/62] Loss: 0.12324 
Epoch [146/300] Training [41/62] Loss: 0.09480 
Epoch [146/300] Training [42/62] Loss: 0.05918 
Epoch [146/300] Training [43/62] Loss: 0.11483 
Epoch [146/300] Training [44/62] Loss: 0.13363 
Epoch [146/300] Training [45/62] Loss: 0.09320 
Epoch [146/300] Training [46/62] Loss: 0.15788 
Epoch [146/300] Training [47/62] Loss: 0.11880 
Epoch [146/300] Training [48/62] Loss: 0.10123 
Epoch [146/300] Training [49/62] Loss: 0.07363 
Epoch [146/300] Training [50/62] Loss: 0.11745 
Epoch [146/300] Training [51/62] Loss: 0.22874 
Epoch [146/300] Training [52/62] Loss: 0.10990 
Epoch [146/300] Training [53/62] Loss: 0.24342 
Epoch [146/300] Training [54/62] Loss: 0.12430 
Epoch [146/300] Training [55/62] Loss: 0.07936 
Epoch [146/300] Training [56/62] Loss: 0.10493 
Epoch [146/300] Training [57/62] Loss: 0.11436 
Epoch [146/300] Training [58/62] Loss: 0.09672 
Epoch [146/300] Training [59/62] Loss: 0.08571 
Epoch [146/300] Training [60/62] Loss: 0.19587 
Epoch [146/300] Training [61/62] Loss: 0.15912 
Epoch [146/300] Training [62/62] Loss: 0.08569 
Epoch [146/300] Training metric {'Train/mean dice_metric': 0.9208263158798218, 'Train/mean miou_metric': 0.8633854985237122, 'Train/mean f1': 0.9345436096191406, 'Train/mean precision': 0.9278054237365723, 'Train/mean recall': 0.9413803815841675, 'Train/mean hd95_metric': 14.537710189819336}
Epoch [146/300] Validation [1/16] Loss: 0.24130  focal_loss 0.10927  dice_loss 0.13203 
Epoch [146/300] Validation [2/16] Loss: 0.31303  focal_loss 0.09044  dice_loss 0.22259 
Epoch [146/300] Validation [3/16] Loss: 0.89399  focal_loss 0.51866  dice_loss 0.37533 
Epoch [146/300] Validation [4/16] Loss: 0.28613  focal_loss 0.10407  dice_loss 0.18206 
Epoch [146/300] Validation [5/16] Loss: 0.29581  focal_loss 0.07049  dice_loss 0.22532 
Epoch [146/300] Validation [6/16] Loss: 0.17799  focal_loss 0.03116  dice_loss 0.14683 
Epoch [146/300] Validation [7/16] Loss: 0.22324  focal_loss 0.08048  dice_loss 0.14277 
Epoch [146/300] Validation [8/16] Loss: 0.23942  focal_loss 0.04962  dice_loss 0.18981 
Epoch [146/300] Validation [9/16] Loss: 0.24858  focal_loss 0.07546  dice_loss 0.17312 
Epoch [146/300] Validation [10/16] Loss: 0.24044  focal_loss 0.04204  dice_loss 0.19840 
Epoch [146/300] Validation [11/16] Loss: 0.28689  focal_loss 0.08776  dice_loss 0.19913 
Epoch [146/300] Validation [12/16] Loss: 0.29468  focal_loss 0.04619  dice_loss 0.24849 
Epoch [146/300] Validation [13/16] Loss: 0.34577  focal_loss 0.12542  dice_loss 0.22035 
Epoch [146/300] Validation [14/16] Loss: 0.55351  focal_loss 0.20044  dice_loss 0.35307 
Epoch [146/300] Validation [15/16] Loss: 0.13425  focal_loss 0.03858  dice_loss 0.09567 
Epoch [146/300] Validation [16/16] Loss: 0.05743  focal_loss 0.01144  dice_loss 0.04599 
Epoch [146/300] Validation metric {'Val/mean dice_metric': 0.8983025550842285, 'Val/mean miou_metric': 0.8360254764556885, 'Val/mean f1': 0.9090674519538879, 'Val/mean precision': 0.8977882862091064, 'Val/mean recall': 0.9206337332725525, 'Val/mean hd95_metric': 20.375886917114258}
Cheakpoint...
Epoch [146/300] best acc:tensor([0.9017], device='cuda:0'), Now : mean acc: tensor([0.8983], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8983025550842285, 'Val/mean miou_metric': 0.8360254764556885, 'Val/mean f1': 0.9090674519538879, 'Val/mean precision': 0.8977882862091064, 'Val/mean recall': 0.9206337332725525, 'Val/mean hd95_metric': 20.375886917114258}
Epoch [147/300] Training [1/62] Loss: 0.13529 
Epoch [147/300] Training [2/62] Loss: 0.09029 
Epoch [147/300] Training [3/62] Loss: 0.13566 
Epoch [147/300] Training [4/62] Loss: 0.10368 
Epoch [147/300] Training [5/62] Loss: 0.10509 
Epoch [147/300] Training [6/62] Loss: 0.17636 
Epoch [147/300] Training [7/62] Loss: 0.08704 
Epoch [147/300] Training [8/62] Loss: 0.10905 
Epoch [147/300] Training [9/62] Loss: 0.06853 
Epoch [147/300] Training [10/62] Loss: 0.18356 
Epoch [147/300] Training [11/62] Loss: 0.11736 
Epoch [147/300] Training [12/62] Loss: 0.07443 
Epoch [147/300] Training [13/62] Loss: 0.11260 
Epoch [147/300] Training [14/62] Loss: 0.09627 
Epoch [147/300] Training [15/62] Loss: 0.12787 
Epoch [147/300] Training [16/62] Loss: 0.08093 
Epoch [147/300] Training [17/62] Loss: 0.08219 
Epoch [147/300] Training [18/62] Loss: 0.14777 
Epoch [147/300] Training [19/62] Loss: 0.08850 
Epoch [147/300] Training [20/62] Loss: 0.13049 
Epoch [147/300] Training [21/62] Loss: 0.08509 
Epoch [147/300] Training [22/62] Loss: 0.11658 
Epoch [147/300] Training [23/62] Loss: 0.13238 
Epoch [147/300] Training [24/62] Loss: 0.08083 
Epoch [147/300] Training [25/62] Loss: 0.22608 
Epoch [147/300] Training [26/62] Loss: 0.14078 
Epoch [147/300] Training [27/62] Loss: 0.11702 
Epoch [147/300] Training [28/62] Loss: 0.14943 
Epoch [147/300] Training [29/62] Loss: 0.09939 
Epoch [147/300] Training [30/62] Loss: 0.08363 
Epoch [147/300] Training [31/62] Loss: 0.08659 
Epoch [147/300] Training [32/62] Loss: 0.16577 
Epoch [147/300] Training [33/62] Loss: 0.09428 
Epoch [147/300] Training [34/62] Loss: 0.14033 
Epoch [147/300] Training [35/62] Loss: 0.08626 
Epoch [147/300] Training [36/62] Loss: 0.09188 
Epoch [147/300] Training [37/62] Loss: 0.11963 
Epoch [147/300] Training [38/62] Loss: 0.08482 
Epoch [147/300] Training [39/62] Loss: 0.09259 
Epoch [147/300] Training [40/62] Loss: 0.12259 
Epoch [147/300] Training [41/62] Loss: 0.05844 
Epoch [147/300] Training [42/62] Loss: 0.08776 
Epoch [147/300] Training [43/62] Loss: 0.07716 
Epoch [147/300] Training [44/62] Loss: 0.12190 
Epoch [147/300] Training [45/62] Loss: 0.05735 
Epoch [147/300] Training [46/62] Loss: 0.13829 
Epoch [147/300] Training [47/62] Loss: 0.19453 
Epoch [147/300] Training [48/62] Loss: 0.10273 
Epoch [147/300] Training [49/62] Loss: 0.10692 
Epoch [147/300] Training [50/62] Loss: 0.10104 
Epoch [147/300] Training [51/62] Loss: 0.11859 
Epoch [147/300] Training [52/62] Loss: 0.09023 
Epoch [147/300] Training [53/62] Loss: 0.11416 
Epoch [147/300] Training [54/62] Loss: 0.07658 
Epoch [147/300] Training [55/62] Loss: 0.08120 
Epoch [147/300] Training [56/62] Loss: 0.07459 
Epoch [147/300] Training [57/62] Loss: 0.11329 
Epoch [147/300] Training [58/62] Loss: 0.05982 
Epoch [147/300] Training [59/62] Loss: 0.08481 
Epoch [147/300] Training [60/62] Loss: 0.10696 
Epoch [147/300] Training [61/62] Loss: 0.11203 
Epoch [147/300] Training [62/62] Loss: 0.08427 
Epoch [147/300] Training metric {'Train/mean dice_metric': 0.9244284629821777, 'Train/mean miou_metric': 0.8680083155632019, 'Train/mean f1': 0.935966432094574, 'Train/mean precision': 0.9317602515220642, 'Train/mean recall': 0.9402107000350952, 'Train/mean hd95_metric': 14.258869171142578}
Epoch [147/300] Validation [1/16] Loss: 0.21213  focal_loss 0.08634  dice_loss 0.12579 
Epoch [147/300] Validation [2/16] Loss: 0.22020  focal_loss 0.08601  dice_loss 0.13419 
Epoch [147/300] Validation [3/16] Loss: 0.28548  focal_loss 0.10518  dice_loss 0.18030 
Epoch [147/300] Validation [4/16] Loss: 0.28209  focal_loss 0.13310  dice_loss 0.14899 
Epoch [147/300] Validation [5/16] Loss: 0.34530  focal_loss 0.10010  dice_loss 0.24520 
Epoch [147/300] Validation [6/16] Loss: 0.19710  focal_loss 0.03772  dice_loss 0.15938 
Epoch [147/300] Validation [7/16] Loss: 0.25612  focal_loss 0.09677  dice_loss 0.15935 
Epoch [147/300] Validation [8/16] Loss: 0.35570  focal_loss 0.11374  dice_loss 0.24195 
Epoch [147/300] Validation [9/16] Loss: 0.23832  focal_loss 0.09517  dice_loss 0.14314 
Epoch [147/300] Validation [10/16] Loss: 0.14492  focal_loss 0.03121  dice_loss 0.11371 
Epoch [147/300] Validation [11/16] Loss: 0.17471  focal_loss 0.06130  dice_loss 0.11341 
Epoch [147/300] Validation [12/16] Loss: 0.36917  focal_loss 0.09534  dice_loss 0.27383 
Epoch [147/300] Validation [13/16] Loss: 0.16691  focal_loss 0.03900  dice_loss 0.12792 
Epoch [147/300] Validation [14/16] Loss: 0.65135  focal_loss 0.24002  dice_loss 0.41134 
Epoch [147/300] Validation [15/16] Loss: 0.10693  focal_loss 0.02414  dice_loss 0.08279 
Epoch [147/300] Validation [16/16] Loss: 0.06747  focal_loss 0.01727  dice_loss 0.05020 
Epoch [147/300] Validation metric {'Val/mean dice_metric': 0.9061615467071533, 'Val/mean miou_metric': 0.844781219959259, 'Val/mean f1': 0.9159626960754395, 'Val/mean precision': 0.9085631370544434, 'Val/mean recall': 0.9234838485717773, 'Val/mean hd95_metric': 18.973892211914062}
Cheakpoint...
Epoch [147/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.9062], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9061615467071533, 'Val/mean miou_metric': 0.844781219959259, 'Val/mean f1': 0.9159626960754395, 'Val/mean precision': 0.9085631370544434, 'Val/mean recall': 0.9234838485717773, 'Val/mean hd95_metric': 18.973892211914062}
Epoch [148/300] Training [1/62] Loss: 0.20181 
Epoch [148/300] Training [2/62] Loss: 0.06523 
Epoch [148/300] Training [3/62] Loss: 0.07392 
Epoch [148/300] Training [4/62] Loss: 0.09393 
Epoch [148/300] Training [5/62] Loss: 0.08980 
Epoch [148/300] Training [6/62] Loss: 0.10652 
Epoch [148/300] Training [7/62] Loss: 0.11652 
Epoch [148/300] Training [8/62] Loss: 0.07960 
Epoch [148/300] Training [9/62] Loss: 0.09413 
Epoch [148/300] Training [10/62] Loss: 0.13691 
Epoch [148/300] Training [11/62] Loss: 0.09851 
Epoch [148/300] Training [12/62] Loss: 0.10035 
Epoch [148/300] Training [13/62] Loss: 0.11182 
Epoch [148/300] Training [14/62] Loss: 0.10132 
Epoch [148/300] Training [15/62] Loss: 0.16128 
Epoch [148/300] Training [16/62] Loss: 0.16941 
Epoch [148/300] Training [17/62] Loss: 0.10965 
Epoch [148/300] Training [18/62] Loss: 0.05060 
Epoch [148/300] Training [19/62] Loss: 0.09481 
Epoch [148/300] Training [20/62] Loss: 0.10265 
Epoch [148/300] Training [21/62] Loss: 0.14905 
Epoch [148/300] Training [22/62] Loss: 0.07160 
Epoch [148/300] Training [23/62] Loss: 0.07600 
Epoch [148/300] Training [24/62] Loss: 0.07152 
Epoch [148/300] Training [25/62] Loss: 0.09319 
Epoch [148/300] Training [26/62] Loss: 0.20529 
Epoch [148/300] Training [27/62] Loss: 0.08529 
Epoch [148/300] Training [28/62] Loss: 0.13431 
Epoch [148/300] Training [29/62] Loss: 0.13556 
Epoch [148/300] Training [30/62] Loss: 0.07340 
Epoch [148/300] Training [31/62] Loss: 0.13495 
Epoch [148/300] Training [32/62] Loss: 0.12287 
Epoch [148/300] Training [33/62] Loss: 0.13297 
Epoch [148/300] Training [34/62] Loss: 0.11490 
Epoch [148/300] Training [35/62] Loss: 0.13477 
Epoch [148/300] Training [36/62] Loss: 0.08844 
Epoch [148/300] Training [37/62] Loss: 0.09998 
Epoch [148/300] Training [38/62] Loss: 0.08243 
Epoch [148/300] Training [39/62] Loss: 0.08296 
Epoch [148/300] Training [40/62] Loss: 0.07810 
Epoch [148/300] Training [41/62] Loss: 0.08772 
Epoch [148/300] Training [42/62] Loss: 0.10251 
Epoch [148/300] Training [43/62] Loss: 0.10582 
Epoch [148/300] Training [44/62] Loss: 0.12519 
Epoch [148/300] Training [45/62] Loss: 0.06248 
Epoch [148/300] Training [46/62] Loss: 0.07419 
Epoch [148/300] Training [47/62] Loss: 0.12430 
Epoch [148/300] Training [48/62] Loss: 0.16234 
Epoch [148/300] Training [49/62] Loss: 0.13402 
Epoch [148/300] Training [50/62] Loss: 0.11770 
Epoch [148/300] Training [51/62] Loss: 0.07206 
Epoch [148/300] Training [52/62] Loss: 0.21150 
Epoch [148/300] Training [53/62] Loss: 0.09225 
Epoch [148/300] Training [54/62] Loss: 0.08167 
Epoch [148/300] Training [55/62] Loss: 0.09125 
Epoch [148/300] Training [56/62] Loss: 0.16196 
Epoch [148/300] Training [57/62] Loss: 0.08935 
Epoch [148/300] Training [58/62] Loss: 0.07189 
Epoch [148/300] Training [59/62] Loss: 0.06869 
Epoch [148/300] Training [60/62] Loss: 0.30392 
Epoch [148/300] Training [61/62] Loss: 0.11325 
Epoch [148/300] Training [62/62] Loss: 0.04691 
Epoch [148/300] Training metric {'Train/mean dice_metric': 0.9223501682281494, 'Train/mean miou_metric': 0.8652641773223877, 'Train/mean f1': 0.9347736239433289, 'Train/mean precision': 0.9273828864097595, 'Train/mean recall': 0.9422831535339355, 'Train/mean hd95_metric': 14.421483993530273}
Epoch [148/300] Validation [1/16] Loss: 0.17804  focal_loss 0.05133  dice_loss 0.12671 
Epoch [148/300] Validation [2/16] Loss: 0.27427  focal_loss 0.09956  dice_loss 0.17471 
Epoch [148/300] Validation [3/16] Loss: 0.54775  focal_loss 0.19721  dice_loss 0.35054 
Epoch [148/300] Validation [4/16] Loss: 0.38832  focal_loss 0.17790  dice_loss 0.21042 
Epoch [148/300] Validation [5/16] Loss: 0.40958  focal_loss 0.17914  dice_loss 0.23044 
Epoch [148/300] Validation [6/16] Loss: 0.26773  focal_loss 0.06788  dice_loss 0.19985 
Epoch [148/300] Validation [7/16] Loss: 0.33679  focal_loss 0.15033  dice_loss 0.18646 
Epoch [148/300] Validation [8/16] Loss: 0.42491  focal_loss 0.13331  dice_loss 0.29159 
Epoch [148/300] Validation [9/16] Loss: 0.14793  focal_loss 0.04974  dice_loss 0.09819 
Epoch [148/300] Validation [10/16] Loss: 0.37433  focal_loss 0.13308  dice_loss 0.24125 
Epoch [148/300] Validation [11/16] Loss: 0.15745  focal_loss 0.04078  dice_loss 0.11667 
Epoch [148/300] Validation [12/16] Loss: 0.38051  focal_loss 0.08300  dice_loss 0.29751 
Epoch [148/300] Validation [13/16] Loss: 0.38931  focal_loss 0.13733  dice_loss 0.25198 
Epoch [148/300] Validation [14/16] Loss: 0.53270  focal_loss 0.17257  dice_loss 0.36014 
Epoch [148/300] Validation [15/16] Loss: 0.21410  focal_loss 0.07996  dice_loss 0.13414 
Epoch [148/300] Validation [16/16] Loss: 0.10073  focal_loss 0.04107  dice_loss 0.05966 
Epoch [148/300] Validation metric {'Val/mean dice_metric': 0.8970193266868591, 'Val/mean miou_metric': 0.8339595198631287, 'Val/mean f1': 0.908791184425354, 'Val/mean precision': 0.903039813041687, 'Val/mean recall': 0.9146163463592529, 'Val/mean hd95_metric': 19.786277770996094}
Cheakpoint...
Epoch [148/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.8970], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8970193266868591, 'Val/mean miou_metric': 0.8339595198631287, 'Val/mean f1': 0.908791184425354, 'Val/mean precision': 0.903039813041687, 'Val/mean recall': 0.9146163463592529, 'Val/mean hd95_metric': 19.786277770996094}
Epoch [149/300] Training [1/62] Loss: 0.07469 
Epoch [149/300] Training [2/62] Loss: 0.20379 
Epoch [149/300] Training [3/62] Loss: 0.08026 
Epoch [149/300] Training [4/62] Loss: 0.10657 
Epoch [149/300] Training [5/62] Loss: 0.07624 
Epoch [149/300] Training [6/62] Loss: 0.18272 
Epoch [149/300] Training [7/62] Loss: 0.08248 
Epoch [149/300] Training [8/62] Loss: 0.07813 
Epoch [149/300] Training [9/62] Loss: 0.16071 
Epoch [149/300] Training [10/62] Loss: 0.25309 
Epoch [149/300] Training [11/62] Loss: 0.11617 
Epoch [149/300] Training [12/62] Loss: 0.10290 
Epoch [149/300] Training [13/62] Loss: 0.08535 
Epoch [149/300] Training [14/62] Loss: 0.16813 
Epoch [149/300] Training [15/62] Loss: 0.09211 
Epoch [149/300] Training [16/62] Loss: 0.10795 
Epoch [149/300] Training [17/62] Loss: 0.07496 
Epoch [149/300] Training [18/62] Loss: 0.11463 
Epoch [149/300] Training [19/62] Loss: 0.07710 
Epoch [149/300] Training [20/62] Loss: 0.06400 
Epoch [149/300] Training [21/62] Loss: 0.29030 
Epoch [149/300] Training [22/62] Loss: 0.12479 
Epoch [149/300] Training [23/62] Loss: 0.07591 
Epoch [149/300] Training [24/62] Loss: 0.18044 
Epoch [149/300] Training [25/62] Loss: 0.12392 
Epoch [149/300] Training [26/62] Loss: 0.16580 
Epoch [149/300] Training [27/62] Loss: 0.08623 
Epoch [149/300] Training [28/62] Loss: 0.08861 
Epoch [149/300] Training [29/62] Loss: 0.24628 
Epoch [149/300] Training [30/62] Loss: 0.08907 
Epoch [149/300] Training [31/62] Loss: 0.08844 
Epoch [149/300] Training [32/62] Loss: 0.12908 
Epoch [149/300] Training [33/62] Loss: 0.11232 
Epoch [149/300] Training [34/62] Loss: 0.06609 
Epoch [149/300] Training [35/62] Loss: 0.24321 
Epoch [149/300] Training [36/62] Loss: 0.10186 
Epoch [149/300] Training [37/62] Loss: 0.11712 
Epoch [149/300] Training [38/62] Loss: 0.13759 
Epoch [149/300] Training [39/62] Loss: 0.14023 
Epoch [149/300] Training [40/62] Loss: 0.07099 
Epoch [149/300] Training [41/62] Loss: 0.08407 
Epoch [149/300] Training [42/62] Loss: 0.14515 
Epoch [149/300] Training [43/62] Loss: 0.10726 
Epoch [149/300] Training [44/62] Loss: 0.07737 
Epoch [149/300] Training [45/62] Loss: 0.13891 
Epoch [149/300] Training [46/62] Loss: 0.08193 
Epoch [149/300] Training [47/62] Loss: 0.11911 
Epoch [149/300] Training [48/62] Loss: 0.13989 
Epoch [149/300] Training [49/62] Loss: 0.10314 
Epoch [149/300] Training [50/62] Loss: 0.16501 
Epoch [149/300] Training [51/62] Loss: 0.05457 
Epoch [149/300] Training [52/62] Loss: 0.07742 
Epoch [149/300] Training [53/62] Loss: 0.09672 
Epoch [149/300] Training [54/62] Loss: 0.06958 
Epoch [149/300] Training [55/62] Loss: 0.08172 
Epoch [149/300] Training [56/62] Loss: 0.09997 
Epoch [149/300] Training [57/62] Loss: 0.07647 
Epoch [149/300] Training [58/62] Loss: 0.09232 
Epoch [149/300] Training [59/62] Loss: 0.13530 
Epoch [149/300] Training [60/62] Loss: 0.13391 
Epoch [149/300] Training [61/62] Loss: 0.08902 
Epoch [149/300] Training [62/62] Loss: 0.04010 
Epoch [149/300] Training metric {'Train/mean dice_metric': 0.9172959923744202, 'Train/mean miou_metric': 0.8617151975631714, 'Train/mean f1': 0.9324468970298767, 'Train/mean precision': 0.9269816875457764, 'Train/mean recall': 0.9379769563674927, 'Train/mean hd95_metric': 15.624137878417969}
Epoch [149/300] Validation [1/16] Loss: 0.10148  focal_loss 0.03495  dice_loss 0.06653 
Epoch [149/300] Validation [2/16] Loss: 0.38493  focal_loss 0.14772  dice_loss 0.23721 
Epoch [149/300] Validation [3/16] Loss: 0.82007  focal_loss 0.47551  dice_loss 0.34456 
Epoch [149/300] Validation [4/16] Loss: 0.22661  focal_loss 0.07336  dice_loss 0.15326 
Epoch [149/300] Validation [5/16] Loss: 0.24636  focal_loss 0.05729  dice_loss 0.18907 
Epoch [149/300] Validation [6/16] Loss: 0.19650  focal_loss 0.04619  dice_loss 0.15030 
Epoch [149/300] Validation [7/16] Loss: 0.28467  focal_loss 0.11873  dice_loss 0.16594 
Epoch [149/300] Validation [8/16] Loss: 0.32991  focal_loss 0.11446  dice_loss 0.21544 
Epoch [149/300] Validation [9/16] Loss: 0.14152  focal_loss 0.04303  dice_loss 0.09849 
Epoch [149/300] Validation [10/16] Loss: 0.22225  focal_loss 0.06470  dice_loss 0.15755 
Epoch [149/300] Validation [11/16] Loss: 0.14410  focal_loss 0.04538  dice_loss 0.09872 
Epoch [149/300] Validation [12/16] Loss: 0.38438  focal_loss 0.11386  dice_loss 0.27052 
Epoch [149/300] Validation [13/16] Loss: 0.23958  focal_loss 0.06690  dice_loss 0.17268 
Epoch [149/300] Validation [14/16] Loss: 0.44414  focal_loss 0.13929  dice_loss 0.30485 
Epoch [149/300] Validation [15/16] Loss: 0.12978  focal_loss 0.04012  dice_loss 0.08966 
Epoch [149/300] Validation [16/16] Loss: 0.04095  focal_loss 0.00916  dice_loss 0.03180 
Epoch [149/300] Validation metric {'Val/mean dice_metric': 0.8997458815574646, 'Val/mean miou_metric': 0.8388412594795227, 'Val/mean f1': 0.9138344526290894, 'Val/mean precision': 0.9103075861930847, 'Val/mean recall': 0.9173888564109802, 'Val/mean hd95_metric': 20.678251266479492}
Cheakpoint...
Epoch [149/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.8997], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8997458815574646, 'Val/mean miou_metric': 0.8388412594795227, 'Val/mean f1': 0.9138344526290894, 'Val/mean precision': 0.9103075861930847, 'Val/mean recall': 0.9173888564109802, 'Val/mean hd95_metric': 20.678251266479492}
Epoch [150/300] Training [1/62] Loss: 0.08560 
Epoch [150/300] Training [2/62] Loss: 0.13552 
Epoch [150/300] Training [3/62] Loss: 0.06644 
Epoch [150/300] Training [4/62] Loss: 0.09041 
Epoch [150/300] Training [5/62] Loss: 0.09853 
Epoch [150/300] Training [6/62] Loss: 0.11987 
Epoch [150/300] Training [7/62] Loss: 0.14618 
Epoch [150/300] Training [8/62] Loss: 0.11450 
Epoch [150/300] Training [9/62] Loss: 0.05117 
Epoch [150/300] Training [10/62] Loss: 0.08066 
Epoch [150/300] Training [11/62] Loss: 0.18761 
Epoch [150/300] Training [12/62] Loss: 0.07049 
Epoch [150/300] Training [13/62] Loss: 0.14712 
Epoch [150/300] Training [14/62] Loss: 0.11028 
Epoch [150/300] Training [15/62] Loss: 0.11784 
Epoch [150/300] Training [16/62] Loss: 0.06932 
Epoch [150/300] Training [17/62] Loss: 0.07175 
Epoch [150/300] Training [18/62] Loss: 0.13905 
Epoch [150/300] Training [19/62] Loss: 0.11057 
Epoch [150/300] Training [20/62] Loss: 0.10593 
Epoch [150/300] Training [21/62] Loss: 0.06179 
Epoch [150/300] Training [22/62] Loss: 0.17426 
Epoch [150/300] Training [23/62] Loss: 0.06848 
Epoch [150/300] Training [24/62] Loss: 0.18945 
Epoch [150/300] Training [25/62] Loss: 0.24852 
Epoch [150/300] Training [26/62] Loss: 0.09970 
Epoch [150/300] Training [27/62] Loss: 0.07647 
Epoch [150/300] Training [28/62] Loss: 0.10228 
Epoch [150/300] Training [29/62] Loss: 0.13202 
Epoch [150/300] Training [30/62] Loss: 0.21477 
Epoch [150/300] Training [31/62] Loss: 0.07982 
Epoch [150/300] Training [32/62] Loss: 0.07318 
Epoch [150/300] Training [33/62] Loss: 0.06409 
Epoch [150/300] Training [34/62] Loss: 0.12216 
Epoch [150/300] Training [35/62] Loss: 0.06121 
Epoch [150/300] Training [36/62] Loss: 0.14381 
Epoch [150/300] Training [37/62] Loss: 0.07771 
Epoch [150/300] Training [38/62] Loss: 0.12208 
Epoch [150/300] Training [39/62] Loss: 0.08297 
Epoch [150/300] Training [40/62] Loss: 0.24161 
Epoch [150/300] Training [41/62] Loss: 0.10613 
Epoch [150/300] Training [42/62] Loss: 0.07940 
Epoch [150/300] Training [43/62] Loss: 0.15356 
Epoch [150/300] Training [44/62] Loss: 0.13581 
Epoch [150/300] Training [45/62] Loss: 0.10420 
Epoch [150/300] Training [46/62] Loss: 0.11345 
Epoch [150/300] Training [47/62] Loss: 0.09465 
Epoch [150/300] Training [48/62] Loss: 0.09294 
Epoch [150/300] Training [49/62] Loss: 0.18325 
Epoch [150/300] Training [50/62] Loss: 0.22155 
Epoch [150/300] Training [51/62] Loss: 0.09933 
Epoch [150/300] Training [52/62] Loss: 0.12701 
Epoch [150/300] Training [53/62] Loss: 0.15259 
Epoch [150/300] Training [54/62] Loss: 0.06516 
Epoch [150/300] Training [55/62] Loss: 0.13400 
Epoch [150/300] Training [56/62] Loss: 0.06335 
Epoch [150/300] Training [57/62] Loss: 0.06107 
Epoch [150/300] Training [58/62] Loss: 0.07061 
Epoch [150/300] Training [59/62] Loss: 0.10136 
Epoch [150/300] Training [60/62] Loss: 0.18002 
Epoch [150/300] Training [61/62] Loss: 0.15251 
Epoch [150/300] Training [62/62] Loss: 0.04825 
Epoch [150/300] Training metric {'Train/mean dice_metric': 0.9192811250686646, 'Train/mean miou_metric': 0.8632930517196655, 'Train/mean f1': 0.934584379196167, 'Train/mean precision': 0.9293332695960999, 'Train/mean recall': 0.9398952126502991, 'Train/mean hd95_metric': 14.282358169555664}
Epoch [150/300] Validation [1/16] Loss: 0.19332  focal_loss 0.06965  dice_loss 0.12367 
Epoch [150/300] Validation [2/16] Loss: 0.34067  focal_loss 0.11135  dice_loss 0.22932 
Epoch [150/300] Validation [3/16] Loss: 0.29437  focal_loss 0.08378  dice_loss 0.21059 
Epoch [150/300] Validation [4/16] Loss: 0.33639  focal_loss 0.13786  dice_loss 0.19853 
Epoch [150/300] Validation [5/16] Loss: 0.26875  focal_loss 0.06834  dice_loss 0.20040 
Epoch [150/300] Validation [6/16] Loss: 0.23565  focal_loss 0.06033  dice_loss 0.17532 
Epoch [150/300] Validation [7/16] Loss: 0.35793  focal_loss 0.11309  dice_loss 0.24484 
Epoch [150/300] Validation [8/16] Loss: 0.49610  focal_loss 0.15538  dice_loss 0.34073 
Epoch [150/300] Validation [9/16] Loss: 0.29829  focal_loss 0.11835  dice_loss 0.17994 
Epoch [150/300] Validation [10/16] Loss: 0.40285  focal_loss 0.11119  dice_loss 0.29166 
Epoch [150/300] Validation [11/16] Loss: 0.19802  focal_loss 0.05662  dice_loss 0.14140 
Epoch [150/300] Validation [12/16] Loss: 0.47701  focal_loss 0.13530  dice_loss 0.34171 
Epoch [150/300] Validation [13/16] Loss: 0.22567  focal_loss 0.06018  dice_loss 0.16548 
Epoch [150/300] Validation [14/16] Loss: 0.61462  focal_loss 0.21932  dice_loss 0.39530 
Epoch [150/300] Validation [15/16] Loss: 0.12398  focal_loss 0.03629  dice_loss 0.08769 
Epoch [150/300] Validation [16/16] Loss: 0.05164  focal_loss 0.01336  dice_loss 0.03828 
Epoch [150/300] Validation metric {'Val/mean dice_metric': 0.8938249349594116, 'Val/mean miou_metric': 0.8318169116973877, 'Val/mean f1': 0.9088212847709656, 'Val/mean precision': 0.8969500064849854, 'Val/mean recall': 0.9210109710693359, 'Val/mean hd95_metric': 21.13712501525879}
Cheakpoint...
Epoch [150/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.8938], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8938249349594116, 'Val/mean miou_metric': 0.8318169116973877, 'Val/mean f1': 0.9088212847709656, 'Val/mean precision': 0.8969500064849854, 'Val/mean recall': 0.9210109710693359, 'Val/mean hd95_metric': 21.13712501525879}
Epoch [151/300] Training [1/62] Loss: 0.10405 
Epoch [151/300] Training [2/62] Loss: 0.10649 
Epoch [151/300] Training [3/62] Loss: 0.09135 
Epoch [151/300] Training [4/62] Loss: 0.12581 
Epoch [151/300] Training [5/62] Loss: 0.08011 
Epoch [151/300] Training [6/62] Loss: 0.16450 
Epoch [151/300] Training [7/62] Loss: 0.15107 
Epoch [151/300] Training [8/62] Loss: 0.11742 
Epoch [151/300] Training [9/62] Loss: 0.08541 
Epoch [151/300] Training [10/62] Loss: 0.15101 
Epoch [151/300] Training [11/62] Loss: 0.10955 
Epoch [151/300] Training [12/62] Loss: 0.08339 
Epoch [151/300] Training [13/62] Loss: 0.06851 
Epoch [151/300] Training [14/62] Loss: 0.09521 
Epoch [151/300] Training [15/62] Loss: 0.17515 
Epoch [151/300] Training [16/62] Loss: 0.08591 
Epoch [151/300] Training [17/62] Loss: 0.07853 
Epoch [151/300] Training [18/62] Loss: 0.17716 
Epoch [151/300] Training [19/62] Loss: 0.07364 
Epoch [151/300] Training [20/62] Loss: 0.08943 
Epoch [151/300] Training [21/62] Loss: 0.08427 
Epoch [151/300] Training [22/62] Loss: 0.10180 
Epoch [151/300] Training [23/62] Loss: 0.18375 
Epoch [151/300] Training [24/62] Loss: 0.08732 
Epoch [151/300] Training [25/62] Loss: 0.07593 
Epoch [151/300] Training [26/62] Loss: 0.23028 
Epoch [151/300] Training [27/62] Loss: 0.09523 
Epoch [151/300] Training [28/62] Loss: 0.07640 
Epoch [151/300] Training [29/62] Loss: 0.08016 
Epoch [151/300] Training [30/62] Loss: 0.07371 
Epoch [151/300] Training [31/62] Loss: 0.07495 
Epoch [151/300] Training [32/62] Loss: 0.09373 
Epoch [151/300] Training [33/62] Loss: 0.10900 
Epoch [151/300] Training [34/62] Loss: 0.06434 
Epoch [151/300] Training [35/62] Loss: 0.12981 
Epoch [151/300] Training [36/62] Loss: 0.19838 
Epoch [151/300] Training [37/62] Loss: 0.10588 
Epoch [151/300] Training [38/62] Loss: 0.07192 
Epoch [151/300] Training [39/62] Loss: 0.08262 
Epoch [151/300] Training [40/62] Loss: 0.07394 
Epoch [151/300] Training [41/62] Loss: 0.27245 
Epoch [151/300] Training [42/62] Loss: 0.07561 
Epoch [151/300] Training [43/62] Loss: 0.10749 
Epoch [151/300] Training [44/62] Loss: 0.08081 
Epoch [151/300] Training [45/62] Loss: 0.06775 
Epoch [151/300] Training [46/62] Loss: 0.07517 
Epoch [151/300] Training [47/62] Loss: 0.05072 
Epoch [151/300] Training [48/62] Loss: 0.05422 
Epoch [151/300] Training [49/62] Loss: 0.26659 
Epoch [151/300] Training [50/62] Loss: 0.11292 
Epoch [151/300] Training [51/62] Loss: 0.09867 
Epoch [151/300] Training [52/62] Loss: 0.07468 
Epoch [151/300] Training [53/62] Loss: 0.12759 
Epoch [151/300] Training [54/62] Loss: 0.11093 
Epoch [151/300] Training [55/62] Loss: 0.07715 
Epoch [151/300] Training [56/62] Loss: 0.08293 
Epoch [151/300] Training [57/62] Loss: 0.12429 
Epoch [151/300] Training [58/62] Loss: 0.10043 
Epoch [151/300] Training [59/62] Loss: 0.08882 
Epoch [151/300] Training [60/62] Loss: 0.06112 
Epoch [151/300] Training [61/62] Loss: 0.12280 
Epoch [151/300] Training [62/62] Loss: 0.04908 
Epoch [151/300] Training metric {'Train/mean dice_metric': 0.9251510500907898, 'Train/mean miou_metric': 0.8716463446617126, 'Train/mean f1': 0.9370599985122681, 'Train/mean precision': 0.9309978485107422, 'Train/mean recall': 0.9432016611099243, 'Train/mean hd95_metric': 13.721981048583984}
Epoch [151/300] Validation [1/16] Loss: 0.42066  focal_loss 0.24312  dice_loss 0.17754 
Epoch [151/300] Validation [2/16] Loss: 0.25565  focal_loss 0.10733  dice_loss 0.14833 
Epoch [151/300] Validation [3/16] Loss: 0.39310  focal_loss 0.14225  dice_loss 0.25085 
Epoch [151/300] Validation [4/16] Loss: 0.33671  focal_loss 0.13274  dice_loss 0.20397 
Epoch [151/300] Validation [5/16] Loss: 0.35354  focal_loss 0.11768  dice_loss 0.23586 
Epoch [151/300] Validation [6/16] Loss: 0.26003  focal_loss 0.07145  dice_loss 0.18858 
Epoch [151/300] Validation [7/16] Loss: 0.33006  focal_loss 0.16126  dice_loss 0.16880 
Epoch [151/300] Validation [8/16] Loss: 0.34132  focal_loss 0.11847  dice_loss 0.22286 
Epoch [151/300] Validation [9/16] Loss: 0.20966  focal_loss 0.06086  dice_loss 0.14880 
Epoch [151/300] Validation [10/16] Loss: 0.27353  focal_loss 0.07160  dice_loss 0.20193 
Epoch [151/300] Validation [11/16] Loss: 0.15720  focal_loss 0.04770  dice_loss 0.10949 
Epoch [151/300] Validation [12/16] Loss: 0.36621  focal_loss 0.08352  dice_loss 0.28269 
Epoch [151/300] Validation [13/16] Loss: 0.23885  focal_loss 0.09404  dice_loss 0.14481 
Epoch [151/300] Validation [14/16] Loss: 0.49357  focal_loss 0.16927  dice_loss 0.32430 
Epoch [151/300] Validation [15/16] Loss: 0.23922  focal_loss 0.08660  dice_loss 0.15262 
Epoch [151/300] Validation [16/16] Loss: 0.04710  focal_loss 0.00867  dice_loss 0.03843 
Epoch [151/300] Validation metric {'Val/mean dice_metric': 0.9030669927597046, 'Val/mean miou_metric': 0.8426564335823059, 'Val/mean f1': 0.9146565198898315, 'Val/mean precision': 0.9176579713821411, 'Val/mean recall': 0.9116745591163635, 'Val/mean hd95_metric': 18.431930541992188}
Cheakpoint...
Epoch [151/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.9031], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9030669927597046, 'Val/mean miou_metric': 0.8426564335823059, 'Val/mean f1': 0.9146565198898315, 'Val/mean precision': 0.9176579713821411, 'Val/mean recall': 0.9116745591163635, 'Val/mean hd95_metric': 18.431930541992188}
Epoch [152/300] Training [1/62] Loss: 0.16226 
Epoch [152/300] Training [2/62] Loss: 0.07851 
Epoch [152/300] Training [3/62] Loss: 0.09880 
Epoch [152/300] Training [4/62] Loss: 0.07144 
Epoch [152/300] Training [5/62] Loss: 0.08378 
Epoch [152/300] Training [6/62] Loss: 0.18927 
Epoch [152/300] Training [7/62] Loss: 0.04623 
Epoch [152/300] Training [8/62] Loss: 0.05988 
Epoch [152/300] Training [9/62] Loss: 0.11082 
Epoch [152/300] Training [10/62] Loss: 0.06869 
Epoch [152/300] Training [11/62] Loss: 0.05989 
Epoch [152/300] Training [12/62] Loss: 0.05979 
Epoch [152/300] Training [13/62] Loss: 0.14206 
Epoch [152/300] Training [14/62] Loss: 0.07487 
Epoch [152/300] Training [15/62] Loss: 0.28091 
Epoch [152/300] Training [16/62] Loss: 0.05838 
Epoch [152/300] Training [17/62] Loss: 0.09686 
Epoch [152/300] Training [18/62] Loss: 0.21787 
Epoch [152/300] Training [19/62] Loss: 0.08196 
Epoch [152/300] Training [20/62] Loss: 0.08249 
Epoch [152/300] Training [21/62] Loss: 0.09071 
Epoch [152/300] Training [22/62] Loss: 0.07117 
Epoch [152/300] Training [23/62] Loss: 0.10284 
Epoch [152/300] Training [24/62] Loss: 0.08573 
Epoch [152/300] Training [25/62] Loss: 0.11895 
Epoch [152/300] Training [26/62] Loss: 0.18412 
Epoch [152/300] Training [27/62] Loss: 0.07358 
Epoch [152/300] Training [28/62] Loss: 0.07347 
Epoch [152/300] Training [29/62] Loss: 0.24977 
Epoch [152/300] Training [30/62] Loss: 0.09693 
Epoch [152/300] Training [31/62] Loss: 0.16206 
Epoch [152/300] Training [32/62] Loss: 0.11624 
Epoch [152/300] Training [33/62] Loss: 0.09916 
Epoch [152/300] Training [34/62] Loss: 0.10296 
Epoch [152/300] Training [35/62] Loss: 0.07324 
Epoch [152/300] Training [36/62] Loss: 0.09980 
Epoch [152/300] Training [37/62] Loss: 0.07056 
Epoch [152/300] Training [38/62] Loss: 0.07364 
Epoch [152/300] Training [39/62] Loss: 0.16756 
Epoch [152/300] Training [40/62] Loss: 0.14455 
Epoch [152/300] Training [41/62] Loss: 0.08394 
Epoch [152/300] Training [42/62] Loss: 0.07942 
Epoch [152/300] Training [43/62] Loss: 0.13647 
Epoch [152/300] Training [44/62] Loss: 0.11602 
Epoch [152/300] Training [45/62] Loss: 0.11260 
Epoch [152/300] Training [46/62] Loss: 0.10632 
Epoch [152/300] Training [47/62] Loss: 0.07377 
Epoch [152/300] Training [48/62] Loss: 0.12476 
Epoch [152/300] Training [49/62] Loss: 0.06158 
Epoch [152/300] Training [50/62] Loss: 0.07807 
Epoch [152/300] Training [51/62] Loss: 0.11083 
Epoch [152/300] Training [52/62] Loss: 0.10212 
Epoch [152/300] Training [53/62] Loss: 0.20507 
Epoch [152/300] Training [54/62] Loss: 0.08462 
Epoch [152/300] Training [55/62] Loss: 0.21006 
Epoch [152/300] Training [56/62] Loss: 0.11528 
Epoch [152/300] Training [57/62] Loss: 0.09709 
Epoch [152/300] Training [58/62] Loss: 0.10835 
Epoch [152/300] Training [59/62] Loss: 0.08375 
Epoch [152/300] Training [60/62] Loss: 0.08065 
Epoch [152/300] Training [61/62] Loss: 0.06498 
Epoch [152/300] Training [62/62] Loss: 0.13264 
Epoch [152/300] Training metric {'Train/mean dice_metric': 0.9243572354316711, 'Train/mean miou_metric': 0.8716756701469421, 'Train/mean f1': 0.9407551288604736, 'Train/mean precision': 0.9365903735160828, 'Train/mean recall': 0.9449571371078491, 'Train/mean hd95_metric': 13.424223899841309}
Epoch [152/300] Validation [1/16] Loss: 0.22497  focal_loss 0.06513  dice_loss 0.15984 
Epoch [152/300] Validation [2/16] Loss: 0.39684  focal_loss 0.14557  dice_loss 0.25127 
Epoch [152/300] Validation [3/16] Loss: 0.28479  focal_loss 0.09770  dice_loss 0.18709 
Epoch [152/300] Validation [4/16] Loss: 0.18312  focal_loss 0.05966  dice_loss 0.12345 
Epoch [152/300] Validation [5/16] Loss: 0.32211  focal_loss 0.06272  dice_loss 0.25939 
Epoch [152/300] Validation [6/16] Loss: 0.23284  focal_loss 0.03478  dice_loss 0.19806 
Epoch [152/300] Validation [7/16] Loss: 0.13043  focal_loss 0.03646  dice_loss 0.09396 
Epoch [152/300] Validation [8/16] Loss: 0.36027  focal_loss 0.10472  dice_loss 0.25554 
Epoch [152/300] Validation [9/16] Loss: 0.27930  focal_loss 0.09097  dice_loss 0.18834 
Epoch [152/300] Validation [10/16] Loss: 0.22402  focal_loss 0.07256  dice_loss 0.15146 
Epoch [152/300] Validation [11/16] Loss: 0.15555  focal_loss 0.02944  dice_loss 0.12612 
Epoch [152/300] Validation [12/16] Loss: 0.39547  focal_loss 0.07813  dice_loss 0.31734 
Epoch [152/300] Validation [13/16] Loss: 0.41169  focal_loss 0.16847  dice_loss 0.24322 
Epoch [152/300] Validation [14/16] Loss: 0.49677  focal_loss 0.14148  dice_loss 0.35529 
Epoch [152/300] Validation [15/16] Loss: 0.18805  focal_loss 0.05138  dice_loss 0.13667 
Epoch [152/300] Validation [16/16] Loss: 0.05105  focal_loss 0.00890  dice_loss 0.04216 
Epoch [152/300] Validation metric {'Val/mean dice_metric': 0.9015058279037476, 'Val/mean miou_metric': 0.8432076573371887, 'Val/mean f1': 0.9207403659820557, 'Val/mean precision': 0.9200097918510437, 'Val/mean recall': 0.9214720726013184, 'Val/mean hd95_metric': 19.95159339904785}
Cheakpoint...
Epoch [152/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.9015], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9015058279037476, 'Val/mean miou_metric': 0.8432076573371887, 'Val/mean f1': 0.9207403659820557, 'Val/mean precision': 0.9200097918510437, 'Val/mean recall': 0.9214720726013184, 'Val/mean hd95_metric': 19.95159339904785}
Epoch [153/300] Training [1/62] Loss: 0.06134 
Epoch [153/300] Training [2/62] Loss: 0.11204 
Epoch [153/300] Training [3/62] Loss: 0.14157 
Epoch [153/300] Training [4/62] Loss: 0.05094 
Epoch [153/300] Training [5/62] Loss: 0.08334 
Epoch [153/300] Training [6/62] Loss: 0.09304 
Epoch [153/300] Training [7/62] Loss: 0.08015 
Epoch [153/300] Training [8/62] Loss: 0.12377 
Epoch [153/300] Training [9/62] Loss: 0.05594 
Epoch [153/300] Training [10/62] Loss: 0.10476 
Epoch [153/300] Training [11/62] Loss: 0.07332 
Epoch [153/300] Training [12/62] Loss: 0.09840 
Epoch [153/300] Training [13/62] Loss: 0.06668 
Epoch [153/300] Training [14/62] Loss: 0.07626 
Epoch [153/300] Training [15/62] Loss: 0.14326 
Epoch [153/300] Training [16/62] Loss: 0.09660 
Epoch [153/300] Training [17/62] Loss: 0.10176 
Epoch [153/300] Training [18/62] Loss: 0.10383 
Epoch [153/300] Training [19/62] Loss: 0.11570 
Epoch [153/300] Training [20/62] Loss: 0.08074 
Epoch [153/300] Training [21/62] Loss: 0.07184 
Epoch [153/300] Training [22/62] Loss: 0.20231 
Epoch [153/300] Training [23/62] Loss: 0.16128 
Epoch [153/300] Training [24/62] Loss: 0.12438 
Epoch [153/300] Training [25/62] Loss: 0.08471 
Epoch [153/300] Training [26/62] Loss: 0.10245 
Epoch [153/300] Training [27/62] Loss: 0.11343 
Epoch [153/300] Training [28/62] Loss: 0.08501 
Epoch [153/300] Training [29/62] Loss: 0.13017 
Epoch [153/300] Training [30/62] Loss: 0.15851 
Epoch [153/300] Training [31/62] Loss: 0.13139 
Epoch [153/300] Training [32/62] Loss: 0.14008 
Epoch [153/300] Training [33/62] Loss: 0.07966 
Epoch [153/300] Training [34/62] Loss: 0.18807 
Epoch [153/300] Training [35/62] Loss: 0.10007 
Epoch [153/300] Training [36/62] Loss: 0.13006 
Epoch [153/300] Training [37/62] Loss: 0.12344 
Epoch [153/300] Training [38/62] Loss: 0.07963 
Epoch [153/300] Training [39/62] Loss: 0.08936 
Epoch [153/300] Training [40/62] Loss: 0.11408 
Epoch [153/300] Training [41/62] Loss: 0.22572 
Epoch [153/300] Training [42/62] Loss: 0.10995 
Epoch [153/300] Training [43/62] Loss: 0.20106 
Epoch [153/300] Training [44/62] Loss: 0.14772 
Epoch [153/300] Training [45/62] Loss: 0.13404 
Epoch [153/300] Training [46/62] Loss: 0.13129 
Epoch [153/300] Training [47/62] Loss: 0.07461 
Epoch [153/300] Training [48/62] Loss: 0.07152 
Epoch [153/300] Training [49/62] Loss: 0.09260 
Epoch [153/300] Training [50/62] Loss: 0.10285 
Epoch [153/300] Training [51/62] Loss: 0.13628 
Epoch [153/300] Training [52/62] Loss: 0.11091 
Epoch [153/300] Training [53/62] Loss: 0.10047 
Epoch [153/300] Training [54/62] Loss: 0.16707 
Epoch [153/300] Training [55/62] Loss: 0.08642 
Epoch [153/300] Training [56/62] Loss: 0.06428 
Epoch [153/300] Training [57/62] Loss: 0.09518 
Epoch [153/300] Training [58/62] Loss: 0.08742 
Epoch [153/300] Training [59/62] Loss: 0.07089 
Epoch [153/300] Training [60/62] Loss: 0.12464 
Epoch [153/300] Training [61/62] Loss: 0.06196 
Epoch [153/300] Training [62/62] Loss: 0.03572 
Epoch [153/300] Training metric {'Train/mean dice_metric': 0.9238448143005371, 'Train/mean miou_metric': 0.8681480288505554, 'Train/mean f1': 0.9357587099075317, 'Train/mean precision': 0.9319584369659424, 'Train/mean recall': 0.9395899772644043, 'Train/mean hd95_metric': 14.987771034240723}
Epoch [153/300] Validation [1/16] Loss: 0.21367  focal_loss 0.10221  dice_loss 0.11147 
Epoch [153/300] Validation [2/16] Loss: 0.33530  focal_loss 0.10466  dice_loss 0.23064 
Epoch [153/300] Validation [3/16] Loss: 0.83070  focal_loss 0.45212  dice_loss 0.37858 
Epoch [153/300] Validation [4/16] Loss: 0.20707  focal_loss 0.07403  dice_loss 0.13304 
Epoch [153/300] Validation [5/16] Loss: 0.37568  focal_loss 0.11958  dice_loss 0.25609 
Epoch [153/300] Validation [6/16] Loss: 0.20974  focal_loss 0.04126  dice_loss 0.16848 
Epoch [153/300] Validation [7/16] Loss: 0.21619  focal_loss 0.07959  dice_loss 0.13660 
Epoch [153/300] Validation [8/16] Loss: 0.32340  focal_loss 0.10192  dice_loss 0.22149 
Epoch [153/300] Validation [9/16] Loss: 0.20889  focal_loss 0.06221  dice_loss 0.14668 
Epoch [153/300] Validation [10/16] Loss: 0.48782  focal_loss 0.21085  dice_loss 0.27697 
Epoch [153/300] Validation [11/16] Loss: 0.14028  focal_loss 0.03802  dice_loss 0.10226 
Epoch [153/300] Validation [12/16] Loss: 0.37298  focal_loss 0.13902  dice_loss 0.23396 
Epoch [153/300] Validation [13/16] Loss: 0.46362  focal_loss 0.20909  dice_loss 0.25453 
Epoch [153/300] Validation [14/16] Loss: 0.42106  focal_loss 0.13553  dice_loss 0.28552 
Epoch [153/300] Validation [15/16] Loss: 0.29582  focal_loss 0.11714  dice_loss 0.17868 
Epoch [153/300] Validation [16/16] Loss: 0.09004  focal_loss 0.02593  dice_loss 0.06410 
Epoch [153/300] Validation metric {'Val/mean dice_metric': 0.8998790979385376, 'Val/mean miou_metric': 0.8377424478530884, 'Val/mean f1': 0.913047730922699, 'Val/mean precision': 0.9131265878677368, 'Val/mean recall': 0.9129688143730164, 'Val/mean hd95_metric': 20.960283279418945}
Cheakpoint...
Epoch [153/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.8999], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.8998790979385376, 'Val/mean miou_metric': 0.8377424478530884, 'Val/mean f1': 0.913047730922699, 'Val/mean precision': 0.9131265878677368, 'Val/mean recall': 0.9129688143730164, 'Val/mean hd95_metric': 20.960283279418945}
Epoch [154/300] Training [1/62] Loss: 0.07871 
Epoch [154/300] Training [2/62] Loss: 0.11526 
Epoch [154/300] Training [3/62] Loss: 0.23798 
Epoch [154/300] Training [4/62] Loss: 0.12941 
Epoch [154/300] Training [5/62] Loss: 0.08126 
Epoch [154/300] Training [6/62] Loss: 0.07560 
Epoch [154/300] Training [7/62] Loss: 0.10114 
Epoch [154/300] Training [8/62] Loss: 0.09698 
Epoch [154/300] Training [9/62] Loss: 0.12266 
Epoch [154/300] Training [10/62] Loss: 0.05555 
Epoch [154/300] Training [11/62] Loss: 0.08618 
Epoch [154/300] Training [12/62] Loss: 0.12878 
Epoch [154/300] Training [13/62] Loss: 0.08593 
Epoch [154/300] Training [14/62] Loss: 0.05152 
Epoch [154/300] Training [15/62] Loss: 0.08517 
Epoch [154/300] Training [16/62] Loss: 0.14729 
Epoch [154/300] Training [17/62] Loss: 0.07323 
Epoch [154/300] Training [18/62] Loss: 0.09515 
Epoch [154/300] Training [19/62] Loss: 0.07285 
Epoch [154/300] Training [20/62] Loss: 0.11721 
Epoch [154/300] Training [21/62] Loss: 0.10010 
Epoch [154/300] Training [22/62] Loss: 0.09339 
Epoch [154/300] Training [23/62] Loss: 0.10368 
Epoch [154/300] Training [24/62] Loss: 0.06941 
Epoch [154/300] Training [25/62] Loss: 0.07455 
Epoch [154/300] Training [26/62] Loss: 0.14904 
Epoch [154/300] Training [27/62] Loss: 0.08230 
Epoch [154/300] Training [28/62] Loss: 0.12767 
Epoch [154/300] Training [29/62] Loss: 0.09028 
Epoch [154/300] Training [30/62] Loss: 0.06476 
Epoch [154/300] Training [31/62] Loss: 0.04767 
Epoch [154/300] Training [32/62] Loss: 0.07699 
Epoch [154/300] Training [33/62] Loss: 0.05927 
Epoch [154/300] Training [34/62] Loss: 0.10474 
Epoch [154/300] Training [35/62] Loss: 0.09356 
Epoch [154/300] Training [36/62] Loss: 0.08847 
Epoch [154/300] Training [37/62] Loss: 0.07281 
Epoch [154/300] Training [38/62] Loss: 0.07999 
Epoch [154/300] Training [39/62] Loss: 0.13404 
Epoch [154/300] Training [40/62] Loss: 0.08949 
Epoch [154/300] Training [41/62] Loss: 0.12982 
Epoch [154/300] Training [42/62] Loss: 0.11820 
Epoch [154/300] Training [43/62] Loss: 0.12333 
Epoch [154/300] Training [44/62] Loss: 0.19745 
Epoch [154/300] Training [45/62] Loss: 0.09286 
Epoch [154/300] Training [46/62] Loss: 0.05580 
Epoch [154/300] Training [47/62] Loss: 0.06211 
Epoch [154/300] Training [48/62] Loss: 0.05422 
Epoch [154/300] Training [49/62] Loss: 0.06966 
Epoch [154/300] Training [50/62] Loss: 0.15951 
Epoch [154/300] Training [51/62] Loss: 0.07173 
Epoch [154/300] Training [52/62] Loss: 0.09476 
Epoch [154/300] Training [53/62] Loss: 0.13035 
Epoch [154/300] Training [54/62] Loss: 0.07917 
Epoch [154/300] Training [55/62] Loss: 0.10862 
Epoch [154/300] Training [56/62] Loss: 0.25529 
Epoch [154/300] Training [57/62] Loss: 0.10091 
Epoch [154/300] Training [58/62] Loss: 0.09248 
Epoch [154/300] Training [59/62] Loss: 0.09338 
Epoch [154/300] Training [60/62] Loss: 0.11758 
Epoch [154/300] Training [61/62] Loss: 0.12016 
Epoch [154/300] Training [62/62] Loss: 0.08904 
Epoch [154/300] Training metric {'Train/mean dice_metric': 0.9298419952392578, 'Train/mean miou_metric': 0.8777170181274414, 'Train/mean f1': 0.9400258660316467, 'Train/mean precision': 0.9307442903518677, 'Train/mean recall': 0.9494943618774414, 'Train/mean hd95_metric': 12.95043659210205}
Epoch [154/300] Validation [1/16] Loss: 0.10548  focal_loss 0.02883  dice_loss 0.07665 
Epoch [154/300] Validation [2/16] Loss: 0.38424  focal_loss 0.14792  dice_loss 0.23631 
Epoch [154/300] Validation [3/16] Loss: 0.30954  focal_loss 0.07017  dice_loss 0.23937 
Epoch [154/300] Validation [4/16] Loss: 0.25840  focal_loss 0.07439  dice_loss 0.18400 
Epoch [154/300] Validation [5/16] Loss: 0.40862  focal_loss 0.14396  dice_loss 0.26466 
Epoch [154/300] Validation [6/16] Loss: 0.23019  focal_loss 0.03200  dice_loss 0.19819 
Epoch [154/300] Validation [7/16] Loss: 0.23704  focal_loss 0.07764  dice_loss 0.15940 
Epoch [154/300] Validation [8/16] Loss: 0.29734  focal_loss 0.05962  dice_loss 0.23772 
Epoch [154/300] Validation [9/16] Loss: 0.21912  focal_loss 0.06627  dice_loss 0.15285 
Epoch [154/300] Validation [10/16] Loss: 0.22478  focal_loss 0.04655  dice_loss 0.17823 
Epoch [154/300] Validation [11/16] Loss: 0.24907  focal_loss 0.06785  dice_loss 0.18121 
Epoch [154/300] Validation [12/16] Loss: 0.42831  focal_loss 0.11002  dice_loss 0.31829 
Epoch [154/300] Validation [13/16] Loss: 0.30332  focal_loss 0.07427  dice_loss 0.22905 
Epoch [154/300] Validation [14/16] Loss: 0.44385  focal_loss 0.14157  dice_loss 0.30228 
Epoch [154/300] Validation [15/16] Loss: 0.15583  focal_loss 0.03872  dice_loss 0.11711 
Epoch [154/300] Validation [16/16] Loss: 0.06027  focal_loss 0.01143  dice_loss 0.04884 
Epoch [154/300] Validation metric {'Val/mean dice_metric': 0.905984103679657, 'Val/mean miou_metric': 0.8467109203338623, 'Val/mean f1': 0.9155510067939758, 'Val/mean precision': 0.8989473581314087, 'Val/mean recall': 0.9327795505523682, 'Val/mean hd95_metric': 20.682065963745117}
Cheakpoint...
Epoch [154/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.9060], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.905984103679657, 'Val/mean miou_metric': 0.8467109203338623, 'Val/mean f1': 0.9155510067939758, 'Val/mean precision': 0.8989473581314087, 'Val/mean recall': 0.9327795505523682, 'Val/mean hd95_metric': 20.682065963745117}
Epoch [155/300] Training [1/62] Loss: 0.13463 
Epoch [155/300] Training [2/62] Loss: 0.10737 
Epoch [155/300] Training [3/62] Loss: 0.08251 
Epoch [155/300] Training [4/62] Loss: 0.07967 
Epoch [155/300] Training [5/62] Loss: 0.08546 
Epoch [155/300] Training [6/62] Loss: 0.13482 
Epoch [155/300] Training [7/62] Loss: 0.09593 
Epoch [155/300] Training [8/62] Loss: 0.10775 
Epoch [155/300] Training [9/62] Loss: 0.06309 
Epoch [155/300] Training [10/62] Loss: 0.05914 
Epoch [155/300] Training [11/62] Loss: 0.08803 
Epoch [155/300] Training [12/62] Loss: 0.08651 
Epoch [155/300] Training [13/62] Loss: 0.16930 
Epoch [155/300] Training [14/62] Loss: 0.08637 
Epoch [155/300] Training [15/62] Loss: 0.08797 
Epoch [155/300] Training [16/62] Loss: 0.19755 
Epoch [155/300] Training [17/62] Loss: 0.07541 
Epoch [155/300] Training [18/62] Loss: 0.08331 
Epoch [155/300] Training [19/62] Loss: 0.09927 
Epoch [155/300] Training [20/62] Loss: 0.06261 
Epoch [155/300] Training [21/62] Loss: 0.10178 
Epoch [155/300] Training [22/62] Loss: 0.10476 
Epoch [155/300] Training [23/62] Loss: 0.09183 
Epoch [155/300] Training [24/62] Loss: 0.11776 
Epoch [155/300] Training [25/62] Loss: 0.14223 
Epoch [155/300] Training [26/62] Loss: 0.05741 
Epoch [155/300] Training [27/62] Loss: 0.20056 
Epoch [155/300] Training [28/62] Loss: 0.13544 
Epoch [155/300] Training [29/62] Loss: 0.13468 
Epoch [155/300] Training [30/62] Loss: 0.09379 
Epoch [155/300] Training [31/62] Loss: 0.07453 
Epoch [155/300] Training [32/62] Loss: 0.08985 
Epoch [155/300] Training [33/62] Loss: 0.10923 
Epoch [155/300] Training [34/62] Loss: 0.08786 
Epoch [155/300] Training [35/62] Loss: 0.09176 
Epoch [155/300] Training [36/62] Loss: 0.06516 
Epoch [155/300] Training [37/62] Loss: 0.08814 
Epoch [155/300] Training [38/62] Loss: 0.16403 
Epoch [155/300] Training [39/62] Loss: 0.08877 
Epoch [155/300] Training [40/62] Loss: 0.12505 
Epoch [155/300] Training [41/62] Loss: 0.05186 
Epoch [155/300] Training [42/62] Loss: 0.13766 
Epoch [155/300] Training [43/62] Loss: 0.13139 
Epoch [155/300] Training [44/62] Loss: 0.12120 
Epoch [155/300] Training [45/62] Loss: 0.12188 
Epoch [155/300] Training [46/62] Loss: 0.12511 
Epoch [155/300] Training [47/62] Loss: 0.26255 
Epoch [155/300] Training [48/62] Loss: 0.07620 
Epoch [155/300] Training [49/62] Loss: 0.12185 
Epoch [155/300] Training [50/62] Loss: 0.13814 
Epoch [155/300] Training [51/62] Loss: 0.12363 
Epoch [155/300] Training [52/62] Loss: 0.06840 
Epoch [155/300] Training [53/62] Loss: 0.07915 
Epoch [155/300] Training [54/62] Loss: 0.07686 
Epoch [155/300] Training [55/62] Loss: 0.09100 
Epoch [155/300] Training [56/62] Loss: 0.08413 
Epoch [155/300] Training [57/62] Loss: 0.09568 
Epoch [155/300] Training [58/62] Loss: 0.07521 
Epoch [155/300] Training [59/62] Loss: 0.07559 
Epoch [155/300] Training [60/62] Loss: 0.06583 
Epoch [155/300] Training [61/62] Loss: 0.19589 
Epoch [155/300] Training [62/62] Loss: 0.04395 
Epoch [155/300] Training metric {'Train/mean dice_metric': 0.9262683987617493, 'Train/mean miou_metric': 0.8713594079017639, 'Train/mean f1': 0.9358797669410706, 'Train/mean precision': 0.9301010966300964, 'Train/mean recall': 0.9417306780815125, 'Train/mean hd95_metric': 14.869775772094727}
Epoch [155/300] Validation [1/16] Loss: 0.13100  focal_loss 0.04453  dice_loss 0.08646 
Epoch [155/300] Validation [2/16] Loss: 0.35358  focal_loss 0.13468  dice_loss 0.21890 
Epoch [155/300] Validation [3/16] Loss: 0.35428  focal_loss 0.14419  dice_loss 0.21009 
Epoch [155/300] Validation [4/16] Loss: 0.15049  focal_loss 0.05116  dice_loss 0.09933 
Epoch [155/300] Validation [5/16] Loss: 0.27212  focal_loss 0.05653  dice_loss 0.21559 
Epoch [155/300] Validation [6/16] Loss: 0.21201  focal_loss 0.04608  dice_loss 0.16593 
Epoch [155/300] Validation [7/16] Loss: 0.24981  focal_loss 0.09944  dice_loss 0.15037 
Epoch [155/300] Validation [8/16] Loss: 0.31300  focal_loss 0.08357  dice_loss 0.22944 
Epoch [155/300] Validation [9/16] Loss: 0.31250  focal_loss 0.13529  dice_loss 0.17721 
Epoch [155/300] Validation [10/16] Loss: 0.43021  focal_loss 0.17316  dice_loss 0.25705 
Epoch [155/300] Validation [11/16] Loss: 0.17329  focal_loss 0.05253  dice_loss 0.12076 
Epoch [155/300] Validation [12/16] Loss: 0.38497  focal_loss 0.13743  dice_loss 0.24754 
Epoch [155/300] Validation [13/16] Loss: 0.35656  focal_loss 0.14699  dice_loss 0.20957 
Epoch [155/300] Validation [14/16] Loss: 0.59730  focal_loss 0.21944  dice_loss 0.37785 
Epoch [155/300] Validation [15/16] Loss: 0.38354  focal_loss 0.18874  dice_loss 0.19480 
Epoch [155/300] Validation [16/16] Loss: 0.05711  focal_loss 0.01439  dice_loss 0.04272 
Epoch [155/300] Validation metric {'Val/mean dice_metric': 0.9038465619087219, 'Val/mean miou_metric': 0.8439261317253113, 'Val/mean f1': 0.9131460785865784, 'Val/mean precision': 0.9039477109909058, 'Val/mean recall': 0.9225335121154785, 'Val/mean hd95_metric': 20.195674896240234}
Cheakpoint...
Epoch [155/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.9038], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9038465619087219, 'Val/mean miou_metric': 0.8439261317253113, 'Val/mean f1': 0.9131460785865784, 'Val/mean precision': 0.9039477109909058, 'Val/mean recall': 0.9225335121154785, 'Val/mean hd95_metric': 20.195674896240234}
Epoch [156/300] Training [1/62] Loss: 0.05891 
Epoch [156/300] Training [2/62] Loss: 0.08438 
Epoch [156/300] Training [3/62] Loss: 0.08355 
Epoch [156/300] Training [4/62] Loss: 0.06451 
Epoch [156/300] Training [5/62] Loss: 0.38752 
Epoch [156/300] Training [6/62] Loss: 0.23979 
Epoch [156/300] Training [7/62] Loss: 0.20475 
Epoch [156/300] Training [8/62] Loss: 0.20309 
Epoch [156/300] Training [9/62] Loss: 0.07845 
Epoch [156/300] Training [10/62] Loss: 0.08650 
Epoch [156/300] Training [11/62] Loss: 0.10677 
Epoch [156/300] Training [12/62] Loss: 0.07172 
Epoch [156/300] Training [13/62] Loss: 0.07687 
Epoch [156/300] Training [14/62] Loss: 0.11398 
Epoch [156/300] Training [15/62] Loss: 0.19473 
Epoch [156/300] Training [16/62] Loss: 0.12766 
Epoch [156/300] Training [17/62] Loss: 0.06477 
Epoch [156/300] Training [18/62] Loss: 0.06725 
Epoch [156/300] Training [19/62] Loss: 0.09996 
Epoch [156/300] Training [20/62] Loss: 0.20116 
Epoch [156/300] Training [21/62] Loss: 0.06565 
Epoch [156/300] Training [22/62] Loss: 0.16335 
Epoch [156/300] Training [23/62] Loss: 0.07494 
Epoch [156/300] Training [24/62] Loss: 0.06358 
Epoch [156/300] Training [25/62] Loss: 0.09801 
Epoch [156/300] Training [26/62] Loss: 0.32092 
Epoch [156/300] Training [27/62] Loss: 0.10778 
Epoch [156/300] Training [28/62] Loss: 0.11846 
Epoch [156/300] Training [29/62] Loss: 0.07652 
Epoch [156/300] Training [30/62] Loss: 0.07644 
Epoch [156/300] Training [31/62] Loss: 0.09200 
Epoch [156/300] Training [32/62] Loss: 0.13729 
Epoch [156/300] Training [33/62] Loss: 0.08146 
Epoch [156/300] Training [34/62] Loss: 0.12227 
Epoch [156/300] Training [35/62] Loss: 0.08082 
Epoch [156/300] Training [36/62] Loss: 0.06721 
Epoch [156/300] Training [37/62] Loss: 0.08840 
Epoch [156/300] Training [38/62] Loss: 0.19389 
Epoch [156/300] Training [39/62] Loss: 0.12384 
Epoch [156/300] Training [40/62] Loss: 0.12623 
Epoch [156/300] Training [41/62] Loss: 0.09452 
Epoch [156/300] Training [42/62] Loss: 0.09844 
Epoch [156/300] Training [43/62] Loss: 0.16338 
Epoch [156/300] Training [44/62] Loss: 0.14399 
Epoch [156/300] Training [45/62] Loss: 0.13563 
Epoch [156/300] Training [46/62] Loss: 0.07164 
Epoch [156/300] Training [47/62] Loss: 0.11069 
Epoch [156/300] Training [48/62] Loss: 0.07105 
Epoch [156/300] Training [49/62] Loss: 0.09116 
Epoch [156/300] Training [50/62] Loss: 0.07576 
Epoch [156/300] Training [51/62] Loss: 0.08151 
Epoch [156/300] Training [52/62] Loss: 0.06574 
Epoch [156/300] Training [53/62] Loss: 0.06209 
Epoch [156/300] Training [54/62] Loss: 0.04910 
Epoch [156/300] Training [55/62] Loss: 0.10386 
Epoch [156/300] Training [56/62] Loss: 0.08242 
Epoch [156/300] Training [57/62] Loss: 0.08575 
Epoch [156/300] Training [58/62] Loss: 0.11353 
Epoch [156/300] Training [59/62] Loss: 0.07631 
Epoch [156/300] Training [60/62] Loss: 0.14364 
Epoch [156/300] Training [61/62] Loss: 0.10457 
Epoch [156/300] Training [62/62] Loss: 0.06124 
Epoch [156/300] Training metric {'Train/mean dice_metric': 0.9247029423713684, 'Train/mean miou_metric': 0.8714098334312439, 'Train/mean f1': 0.9303788542747498, 'Train/mean precision': 0.9250955581665039, 'Train/mean recall': 0.9357228875160217, 'Train/mean hd95_metric': 15.253588676452637}
Epoch [156/300] Validation [1/16] Loss: 0.11504  focal_loss 0.04215  dice_loss 0.07289 
Epoch [156/300] Validation [2/16] Loss: 0.36341  focal_loss 0.13160  dice_loss 0.23181 
Epoch [156/300] Validation [3/16] Loss: 0.33513  focal_loss 0.12262  dice_loss 0.21251 
Epoch [156/300] Validation [4/16] Loss: 0.21972  focal_loss 0.08883  dice_loss 0.13089 
Epoch [156/300] Validation [5/16] Loss: 0.24685  focal_loss 0.07355  dice_loss 0.17329 
Epoch [156/300] Validation [6/16] Loss: 0.24618  focal_loss 0.07456  dice_loss 0.17162 
Epoch [156/300] Validation [7/16] Loss: 0.20082  focal_loss 0.06613  dice_loss 0.13469 
Epoch [156/300] Validation [8/16] Loss: 0.40338  focal_loss 0.15905  dice_loss 0.24433 
Epoch [156/300] Validation [9/16] Loss: 0.24796  focal_loss 0.11132  dice_loss 0.13664 
Epoch [156/300] Validation [10/16] Loss: 0.36314  focal_loss 0.15794  dice_loss 0.20520 
Epoch [156/300] Validation [11/16] Loss: 0.16504  focal_loss 0.04963  dice_loss 0.11541 
Epoch [156/300] Validation [12/16] Loss: 0.42277  focal_loss 0.12060  dice_loss 0.30217 
Epoch [156/300] Validation [13/16] Loss: 0.45198  focal_loss 0.19026  dice_loss 0.26171 
Epoch [156/300] Validation [14/16] Loss: 0.35588  focal_loss 0.12284  dice_loss 0.23305 
Epoch [156/300] Validation [15/16] Loss: 0.19363  focal_loss 0.05619  dice_loss 0.13743 
Epoch [156/300] Validation [16/16] Loss: 0.06314  focal_loss 0.02015  dice_loss 0.04299 
Epoch [156/300] Validation metric {'Val/mean dice_metric': 0.9048808217048645, 'Val/mean miou_metric': 0.8446710109710693, 'Val/mean f1': 0.9101163148880005, 'Val/mean precision': 0.9064922332763672, 'Val/mean recall': 0.9137693643569946, 'Val/mean hd95_metric': 20.771835327148438}
Cheakpoint...
Epoch [156/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.9049], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9048808217048645, 'Val/mean miou_metric': 0.8446710109710693, 'Val/mean f1': 0.9101163148880005, 'Val/mean precision': 0.9064922332763672, 'Val/mean recall': 0.9137693643569946, 'Val/mean hd95_metric': 20.771835327148438}
Epoch [157/300] Training [1/62] Loss: 0.09478 
Epoch [157/300] Training [2/62] Loss: 0.10024 
Epoch [157/300] Training [3/62] Loss: 0.13180 
Epoch [157/300] Training [4/62] Loss: 0.11881 
Epoch [157/300] Training [5/62] Loss: 0.13031 
Epoch [157/300] Training [6/62] Loss: 0.14480 
Epoch [157/300] Training [7/62] Loss: 0.10798 
Epoch [157/300] Training [8/62] Loss: 0.07092 
Epoch [157/300] Training [9/62] Loss: 0.10522 
Epoch [157/300] Training [10/62] Loss: 0.09498 
Epoch [157/300] Training [11/62] Loss: 0.08620 
Epoch [157/300] Training [12/62] Loss: 0.12573 
Epoch [157/300] Training [13/62] Loss: 0.06734 
Epoch [157/300] Training [14/62] Loss: 0.10222 
Epoch [157/300] Training [15/62] Loss: 0.05245 
Epoch [157/300] Training [16/62] Loss: 0.06689 
Epoch [157/300] Training [17/62] Loss: 0.12820 
Epoch [157/300] Training [18/62] Loss: 0.08818 
Epoch [157/300] Training [19/62] Loss: 0.12027 
Epoch [157/300] Training [20/62] Loss: 0.08353 
Epoch [157/300] Training [21/62] Loss: 0.05570 
Epoch [157/300] Training [22/62] Loss: 0.07274 
Epoch [157/300] Training [23/62] Loss: 0.25922 
Epoch [157/300] Training [24/62] Loss: 0.11878 
Epoch [157/300] Training [25/62] Loss: 0.09661 
Epoch [157/300] Training [26/62] Loss: 0.08734 
Epoch [157/300] Training [27/62] Loss: 0.11686 
Epoch [157/300] Training [28/62] Loss: 0.09871 
Epoch [157/300] Training [29/62] Loss: 0.03745 
Epoch [157/300] Training [30/62] Loss: 0.15675 
Epoch [157/300] Training [31/62] Loss: 0.20692 
Epoch [157/300] Training [32/62] Loss: 0.13027 
Epoch [157/300] Training [33/62] Loss: 0.09890 
Epoch [157/300] Training [34/62] Loss: 0.08012 
Epoch [157/300] Training [35/62] Loss: 0.07625 
Epoch [157/300] Training [36/62] Loss: 0.07901 
Epoch [157/300] Training [37/62] Loss: 0.20498 
Epoch [157/300] Training [38/62] Loss: 0.07615 
Epoch [157/300] Training [39/62] Loss: 0.06494 
Epoch [157/300] Training [40/62] Loss: 0.15395 
Epoch [157/300] Training [41/62] Loss: 0.08177 
Epoch [157/300] Training [42/62] Loss: 0.09204 
Epoch [157/300] Training [43/62] Loss: 0.12601 
Epoch [157/300] Training [44/62] Loss: 0.07379 
Epoch [157/300] Training [45/62] Loss: 0.10600 
Epoch [157/300] Training [46/62] Loss: 0.08134 
Epoch [157/300] Training [47/62] Loss: 0.20729 
Epoch [157/300] Training [48/62] Loss: 0.14507 
Epoch [157/300] Training [49/62] Loss: 0.08735 
Epoch [157/300] Training [50/62] Loss: 0.07596 
Epoch [157/300] Training [51/62] Loss: 0.06423 
Epoch [157/300] Training [52/62] Loss: 0.13484 
Epoch [157/300] Training [53/62] Loss: 0.05524 
Epoch [157/300] Training [54/62] Loss: 0.07910 
Epoch [157/300] Training [55/62] Loss: 0.07772 
Epoch [157/300] Training [56/62] Loss: 0.11978 
Epoch [157/300] Training [57/62] Loss: 0.09942 
Epoch [157/300] Training [58/62] Loss: 0.13857 
Epoch [157/300] Training [59/62] Loss: 0.05506 
Epoch [157/300] Training [60/62] Loss: 0.07797 
Epoch [157/300] Training [61/62] Loss: 0.12273 
Epoch [157/300] Training [62/62] Loss: 0.41450 
Epoch [157/300] Training metric {'Train/mean dice_metric': 0.9274836182594299, 'Train/mean miou_metric': 0.8734750151634216, 'Train/mean f1': 0.9366438984870911, 'Train/mean precision': 0.9293156862258911, 'Train/mean recall': 0.9440885782241821, 'Train/mean hd95_metric': 14.135234832763672}
Epoch [157/300] Validation [1/16] Loss: 0.36456  focal_loss 0.21075  dice_loss 0.15381 
Epoch [157/300] Validation [2/16] Loss: 0.37208  focal_loss 0.13662  dice_loss 0.23546 
Epoch [157/300] Validation [3/16] Loss: 0.55520  focal_loss 0.26211  dice_loss 0.29309 
Epoch [157/300] Validation [4/16] Loss: 0.20581  focal_loss 0.07823  dice_loss 0.12758 
Epoch [157/300] Validation [5/16] Loss: 0.26053  focal_loss 0.05905  dice_loss 0.20148 
Epoch [157/300] Validation [6/16] Loss: 0.18745  focal_loss 0.04585  dice_loss 0.14160 
Epoch [157/300] Validation [7/16] Loss: 0.34697  focal_loss 0.14852  dice_loss 0.19845 
Epoch [157/300] Validation [8/16] Loss: 0.37453  focal_loss 0.12644  dice_loss 0.24809 
Epoch [157/300] Validation [9/16] Loss: 0.23662  focal_loss 0.09974  dice_loss 0.13688 
Epoch [157/300] Validation [10/16] Loss: 0.51195  focal_loss 0.19013  dice_loss 0.32181 
Epoch [157/300] Validation [11/16] Loss: 0.16228  focal_loss 0.04321  dice_loss 0.11907 
Epoch [157/300] Validation [12/16] Loss: 0.31919  focal_loss 0.07791  dice_loss 0.24128 
Epoch [157/300] Validation [13/16] Loss: 0.34786  focal_loss 0.13813  dice_loss 0.20973 
Epoch [157/300] Validation [14/16] Loss: 0.40869  focal_loss 0.10892  dice_loss 0.29977 
Epoch [157/300] Validation [15/16] Loss: 0.16053  focal_loss 0.05255  dice_loss 0.10798 
Epoch [157/300] Validation [16/16] Loss: 0.05219  focal_loss 0.01046  dice_loss 0.04173 
Epoch [157/300] Validation metric {'Val/mean dice_metric': 0.9032905697822571, 'Val/mean miou_metric': 0.8432012796401978, 'Val/mean f1': 0.9134976863861084, 'Val/mean precision': 0.91131192445755, 'Val/mean recall': 0.9156940579414368, 'Val/mean hd95_metric': 19.84812355041504}
Cheakpoint...
Epoch [157/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.9033], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9032905697822571, 'Val/mean miou_metric': 0.8432012796401978, 'Val/mean f1': 0.9134976863861084, 'Val/mean precision': 0.91131192445755, 'Val/mean recall': 0.9156940579414368, 'Val/mean hd95_metric': 19.84812355041504}
Epoch [158/300] Training [1/62] Loss: 0.06730 
Epoch [158/300] Training [2/62] Loss: 0.06796 
Epoch [158/300] Training [3/62] Loss: 0.08162 
Epoch [158/300] Training [4/62] Loss: 0.07449 
Epoch [158/300] Training [5/62] Loss: 0.11481 
Epoch [158/300] Training [6/62] Loss: 0.18133 
Epoch [158/300] Training [7/62] Loss: 0.07201 
Epoch [158/300] Training [8/62] Loss: 0.06089 
Epoch [158/300] Training [9/62] Loss: 0.07078 
Epoch [158/300] Training [10/62] Loss: 0.25654 
Epoch [158/300] Training [11/62] Loss: 0.08102 
Epoch [158/300] Training [12/62] Loss: 0.09244 
Epoch [158/300] Training [13/62] Loss: 0.09575 
Epoch [158/300] Training [14/62] Loss: 0.08048 
Epoch [158/300] Training [15/62] Loss: 0.16636 
Epoch [158/300] Training [16/62] Loss: 0.10529 
Epoch [158/300] Training [17/62] Loss: 0.09062 
Epoch [158/300] Training [18/62] Loss: 0.09426 
Epoch [158/300] Training [19/62] Loss: 0.11264 
Epoch [158/300] Training [20/62] Loss: 0.07709 
Epoch [158/300] Training [21/62] Loss: 0.29435 
Epoch [158/300] Training [22/62] Loss: 0.09311 
Epoch [158/300] Training [23/62] Loss: 0.13133 
Epoch [158/300] Training [24/62] Loss: 0.06025 
Epoch [158/300] Training [25/62] Loss: 0.29889 
Epoch [158/300] Training [26/62] Loss: 0.08087 
Epoch [158/300] Training [27/62] Loss: 0.05487 
Epoch [158/300] Training [28/62] Loss: 0.08407 
Epoch [158/300] Training [29/62] Loss: 0.08943 
Epoch [158/300] Training [30/62] Loss: 0.08977 
Epoch [158/300] Training [31/62] Loss: 0.13293 
Epoch [158/300] Training [32/62] Loss: 0.10900 
Epoch [158/300] Training [33/62] Loss: 0.10919 
Epoch [158/300] Training [34/62] Loss: 0.09870 
Epoch [158/300] Training [35/62] Loss: 0.04744 
Epoch [158/300] Training [36/62] Loss: 0.13659 
Epoch [158/300] Training [37/62] Loss: 0.12295 
Epoch [158/300] Training [38/62] Loss: 0.12793 
Epoch [158/300] Training [39/62] Loss: 0.15045 
Epoch [158/300] Training [40/62] Loss: 0.06590 
Epoch [158/300] Training [41/62] Loss: 0.07001 
Epoch [158/300] Training [42/62] Loss: 0.07393 
Epoch [158/300] Training [43/62] Loss: 0.10845 
Epoch [158/300] Training [44/62] Loss: 0.14009 
Epoch [158/300] Training [45/62] Loss: 0.14402 
Epoch [158/300] Training [46/62] Loss: 0.08962 
Epoch [158/300] Training [47/62] Loss: 0.10767 
Epoch [158/300] Training [48/62] Loss: 0.05884 
Epoch [158/300] Training [49/62] Loss: 0.10773 
Epoch [158/300] Training [50/62] Loss: 0.07349 
Epoch [158/300] Training [51/62] Loss: 0.06556 
Epoch [158/300] Training [52/62] Loss: 0.09651 
Epoch [158/300] Training [53/62] Loss: 0.12985 
Epoch [158/300] Training [54/62] Loss: 0.12013 
Epoch [158/300] Training [55/62] Loss: 0.06265 
Epoch [158/300] Training [56/62] Loss: 0.05330 
Epoch [158/300] Training [57/62] Loss: 0.06656 
Epoch [158/300] Training [58/62] Loss: 0.08808 
Epoch [158/300] Training [59/62] Loss: 0.13234 
Epoch [158/300] Training [60/62] Loss: 0.16293 
Epoch [158/300] Training [61/62] Loss: 0.14211 
Epoch [158/300] Training [62/62] Loss: 0.05923 
Epoch [158/300] Training metric {'Train/mean dice_metric': 0.9259634613990784, 'Train/mean miou_metric': 0.8732380270957947, 'Train/mean f1': 0.9375253915786743, 'Train/mean precision': 0.9349616765975952, 'Train/mean recall': 0.9401031732559204, 'Train/mean hd95_metric': 13.60593032836914}
Epoch [158/300] Validation [1/16] Loss: 0.13443  focal_loss 0.05067  dice_loss 0.08376 
Epoch [158/300] Validation [2/16] Loss: 0.31103  focal_loss 0.07937  dice_loss 0.23166 
Epoch [158/300] Validation [3/16] Loss: 0.27310  focal_loss 0.08232  dice_loss 0.19078 
Epoch [158/300] Validation [4/16] Loss: 0.18737  focal_loss 0.04772  dice_loss 0.13964 
Epoch [158/300] Validation [5/16] Loss: 0.38169  focal_loss 0.11850  dice_loss 0.26319 
Epoch [158/300] Validation [6/16] Loss: 0.21909  focal_loss 0.05174  dice_loss 0.16735 
Epoch [158/300] Validation [7/16] Loss: 0.25014  focal_loss 0.06393  dice_loss 0.18621 
Epoch [158/300] Validation [8/16] Loss: 0.27077  focal_loss 0.07322  dice_loss 0.19756 
Epoch [158/300] Validation [9/16] Loss: 0.20568  focal_loss 0.07817  dice_loss 0.12751 
Epoch [158/300] Validation [10/16] Loss: 0.33850  focal_loss 0.09099  dice_loss 0.24751 
Epoch [158/300] Validation [11/16] Loss: 0.14687  focal_loss 0.03019  dice_loss 0.11668 
Epoch [158/300] Validation [12/16] Loss: 0.43325  focal_loss 0.11447  dice_loss 0.31879 
Epoch [158/300] Validation [13/16] Loss: 0.34672  focal_loss 0.10922  dice_loss 0.23751 
Epoch [158/300] Validation [14/16] Loss: 0.47656  focal_loss 0.13663  dice_loss 0.33993 
Epoch [158/300] Validation [15/16] Loss: 0.12370  focal_loss 0.02723  dice_loss 0.09646 
Epoch [158/300] Validation [16/16] Loss: 0.06231  focal_loss 0.01454  dice_loss 0.04777 
Epoch [158/300] Validation metric {'Val/mean dice_metric': 0.9050281047821045, 'Val/mean miou_metric': 0.8465700745582581, 'Val/mean f1': 0.9159488081932068, 'Val/mean precision': 0.902779757976532, 'Val/mean recall': 0.9295077919960022, 'Val/mean hd95_metric': 19.210424423217773}
Cheakpoint...
Epoch [158/300] best acc:tensor([0.9062], device='cuda:0'), Now : mean acc: tensor([0.9050], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9050281047821045, 'Val/mean miou_metric': 0.8465700745582581, 'Val/mean f1': 0.9159488081932068, 'Val/mean precision': 0.902779757976532, 'Val/mean recall': 0.9295077919960022, 'Val/mean hd95_metric': 19.210424423217773}
Epoch [159/300] Training [1/62] Loss: 0.05840 
Epoch [159/300] Training [2/62] Loss: 0.07461 
Epoch [159/300] Training [3/62] Loss: 0.21053 
Epoch [159/300] Training [4/62] Loss: 0.09560 
Epoch [159/300] Training [5/62] Loss: 0.09401 
Epoch [159/300] Training [6/62] Loss: 0.16834 
Epoch [159/300] Training [7/62] Loss: 0.09344 
Epoch [159/300] Training [8/62] Loss: 0.07344 
Epoch [159/300] Training [9/62] Loss: 0.10616 
Epoch [159/300] Training [10/62] Loss: 0.09127 
Epoch [159/300] Training [11/62] Loss: 0.18553 
Epoch [159/300] Training [12/62] Loss: 0.21094 
Epoch [159/300] Training [13/62] Loss: 0.05453 
Epoch [159/300] Training [14/62] Loss: 0.07244 
Epoch [159/300] Training [15/62] Loss: 0.06791 
Epoch [159/300] Training [16/62] Loss: 0.11045 
Epoch [159/300] Training [17/62] Loss: 0.09658 
Epoch [159/300] Training [18/62] Loss: 0.13289 
Epoch [159/300] Training [19/62] Loss: 0.09451 
Epoch [159/300] Training [20/62] Loss: 0.12536 
Epoch [159/300] Training [21/62] Loss: 0.11110 
Epoch [159/300] Training [22/62] Loss: 0.08122 
Epoch [159/300] Training [23/62] Loss: 0.09904 
Epoch [159/300] Training [24/62] Loss: 0.09104 
Epoch [159/300] Training [25/62] Loss: 0.09092 
Epoch [159/300] Training [26/62] Loss: 0.06745 
Epoch [159/300] Training [27/62] Loss: 0.20008 
Epoch [159/300] Training [28/62] Loss: 0.06392 
Epoch [159/300] Training [29/62] Loss: 0.10835 
Epoch [159/300] Training [30/62] Loss: 0.13547 
Epoch [159/300] Training [31/62] Loss: 0.18704 
Epoch [159/300] Training [32/62] Loss: 0.08082 
Epoch [159/300] Training [33/62] Loss: 0.07601 
Epoch [159/300] Training [34/62] Loss: 0.11167 
Epoch [159/300] Training [35/62] Loss: 0.08413 
Epoch [159/300] Training [36/62] Loss: 0.07732 
Epoch [159/300] Training [37/62] Loss: 0.27958 
Epoch [159/300] Training [38/62] Loss: 0.12732 
Epoch [159/300] Training [39/62] Loss: 0.07167 
Epoch [159/300] Training [40/62] Loss: 0.06142 
Epoch [159/300] Training [41/62] Loss: 0.09882 
Epoch [159/300] Training [42/62] Loss: 0.07502 
Epoch [159/300] Training [43/62] Loss: 0.08463 
Epoch [159/300] Training [44/62] Loss: 0.08372 
Epoch [159/300] Training [45/62] Loss: 0.11510 
Epoch [159/300] Training [46/62] Loss: 0.08742 
Epoch [159/300] Training [47/62] Loss: 0.06739 
Epoch [159/300] Training [48/62] Loss: 0.06812 
Epoch [159/300] Training [49/62] Loss: 0.12490 
Epoch [159/300] Training [50/62] Loss: 0.06712 
Epoch [159/300] Training [51/62] Loss: 0.05749 
Epoch [159/300] Training [52/62] Loss: 0.06009 
Epoch [159/300] Training [53/62] Loss: 0.06781 
Epoch [159/300] Training [54/62] Loss: 0.15063 
Epoch [159/300] Training [55/62] Loss: 0.06548 
Epoch [159/300] Training [56/62] Loss: 0.14020 
Epoch [159/300] Training [57/62] Loss: 0.10423 
Epoch [159/300] Training [58/62] Loss: 0.07428 
Epoch [159/300] Training [59/62] Loss: 0.07210 
Epoch [159/300] Training [60/62] Loss: 0.06000 
Epoch [159/300] Training [61/62] Loss: 0.11409 
Epoch [159/300] Training [62/62] Loss: 0.06850 
Epoch [159/300] Training metric {'Train/mean dice_metric': 0.9287055730819702, 'Train/mean miou_metric': 0.8776566982269287, 'Train/mean f1': 0.9419745802879333, 'Train/mean precision': 0.9370321035385132, 'Train/mean recall': 0.9469695091247559, 'Train/mean hd95_metric': 12.509801864624023}
Epoch [159/300] Validation [1/16] Loss: 0.14032  focal_loss 0.04670  dice_loss 0.09361 
Epoch [159/300] Validation [2/16] Loss: 0.31347  focal_loss 0.11725  dice_loss 0.19623 
Epoch [159/300] Validation [3/16] Loss: 0.35648  focal_loss 0.13194  dice_loss 0.22453 
Epoch [159/300] Validation [4/16] Loss: 0.27901  focal_loss 0.12633  dice_loss 0.15267 
Epoch [159/300] Validation [5/16] Loss: 0.35047  focal_loss 0.11722  dice_loss 0.23325 
Epoch [159/300] Validation [6/16] Loss: 0.19777  focal_loss 0.02694  dice_loss 0.17083 
Epoch [159/300] Validation [7/16] Loss: 0.33563  focal_loss 0.15268  dice_loss 0.18296 
Epoch [159/300] Validation [8/16] Loss: 0.41431  focal_loss 0.16280  dice_loss 0.25151 
Epoch [159/300] Validation [9/16] Loss: 0.14445  focal_loss 0.04978  dice_loss 0.09467 
Epoch [159/300] Validation [10/16] Loss: 0.35092  focal_loss 0.14017  dice_loss 0.21075 
Epoch [159/300] Validation [11/16] Loss: 0.15755  focal_loss 0.03989  dice_loss 0.11766 
Epoch [159/300] Validation [12/16] Loss: 0.35839  focal_loss 0.08418  dice_loss 0.27420 
Epoch [159/300] Validation [13/16] Loss: 0.31228  focal_loss 0.09649  dice_loss 0.21579 
Epoch [159/300] Validation [14/16] Loss: 0.52387  focal_loss 0.18451  dice_loss 0.33936 
Epoch [159/300] Validation [15/16] Loss: 0.21360  focal_loss 0.07069  dice_loss 0.14291 
Epoch [159/300] Validation [16/16] Loss: 0.04641  focal_loss 0.00904  dice_loss 0.03736 
Epoch [159/300] Validation metric {'Val/mean dice_metric': 0.9065579771995544, 'Val/mean miou_metric': 0.8490970730781555, 'Val/mean f1': 0.9215817451477051, 'Val/mean precision': 0.9240139126777649, 'Val/mean recall': 0.9191624522209167, 'Val/mean hd95_metric': 18.26972007751465}
Cheakpoint...
Epoch [159/300] best acc:tensor([0.9066], device='cuda:0'), Now : mean acc: tensor([0.9066], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9065579771995544, 'Val/mean miou_metric': 0.8490970730781555, 'Val/mean f1': 0.9215817451477051, 'Val/mean precision': 0.9240139126777649, 'Val/mean recall': 0.9191624522209167, 'Val/mean hd95_metric': 18.26972007751465}
Epoch [160/300] Training [1/62] Loss: 0.07747 
Epoch [160/300] Training [2/62] Loss: 0.14242 
Epoch [160/300] Training [3/62] Loss: 0.17290 
Epoch [160/300] Training [4/62] Loss: 0.15153 
Epoch [160/300] Training [5/62] Loss: 0.06061 
Epoch [160/300] Training [6/62] Loss: 0.08641 
Epoch [160/300] Training [7/62] Loss: 0.12130 
Epoch [160/300] Training [8/62] Loss: 0.08493 
Epoch [160/300] Training [9/62] Loss: 0.08664 
Epoch [160/300] Training [10/62] Loss: 0.09208 
Epoch [160/300] Training [11/62] Loss: 0.09473 
Epoch [160/300] Training [12/62] Loss: 0.06123 
Epoch [160/300] Training [13/62] Loss: 0.07424 
Epoch [160/300] Training [14/62] Loss: 0.07407 
Epoch [160/300] Training [15/62] Loss: 0.09050 
Epoch [160/300] Training [16/62] Loss: 0.06822 
Epoch [160/300] Training [17/62] Loss: 0.07857 
Epoch [160/300] Training [18/62] Loss: 0.11391 
Epoch [160/300] Training [19/62] Loss: 0.14414 
Epoch [160/300] Training [20/62] Loss: 0.12276 
Epoch [160/300] Training [21/62] Loss: 0.06477 
Epoch [160/300] Training [22/62] Loss: 0.07839 
Epoch [160/300] Training [23/62] Loss: 0.09159 
Epoch [160/300] Training [24/62] Loss: 0.13100 
Epoch [160/300] Training [25/62] Loss: 0.06561 
Epoch [160/300] Training [26/62] Loss: 0.07413 
Epoch [160/300] Training [27/62] Loss: 0.07843 
Epoch [160/300] Training [28/62] Loss: 0.10390 
Epoch [160/300] Training [29/62] Loss: 0.05600 
Epoch [160/300] Training [30/62] Loss: 0.06981 
Epoch [160/300] Training [31/62] Loss: 0.06777 
Epoch [160/300] Training [32/62] Loss: 0.08301 
Epoch [160/300] Training [33/62] Loss: 0.06440 
Epoch [160/300] Training [34/62] Loss: 0.07993 
Epoch [160/300] Training [35/62] Loss: 0.07808 
Epoch [160/300] Training [36/62] Loss: 0.09932 
Epoch [160/300] Training [37/62] Loss: 0.10844 
Epoch [160/300] Training [38/62] Loss: 0.07357 
Epoch [160/300] Training [39/62] Loss: 0.05695 
Epoch [160/300] Training [40/62] Loss: 0.06344 
Epoch [160/300] Training [41/62] Loss: 0.11292 
Epoch [160/300] Training [42/62] Loss: 0.07960 
Epoch [160/300] Training [43/62] Loss: 0.08235 
Epoch [160/300] Training [44/62] Loss: 0.07031 
Epoch [160/300] Training [45/62] Loss: 0.05534 
Epoch [160/300] Training [46/62] Loss: 0.08426 
Epoch [160/300] Training [47/62] Loss: 0.19458 
Epoch [160/300] Training [48/62] Loss: 0.04683 
Epoch [160/300] Training [49/62] Loss: 0.09126 
Epoch [160/300] Training [50/62] Loss: 0.11317 
Epoch [160/300] Training [51/62] Loss: 0.20451 
Epoch [160/300] Training [52/62] Loss: 0.07503 
Epoch [160/300] Training [53/62] Loss: 0.06930 
Epoch [160/300] Training [54/62] Loss: 0.15204 
Epoch [160/300] Training [55/62] Loss: 0.12971 
Epoch [160/300] Training [56/62] Loss: 0.23653 
Epoch [160/300] Training [57/62] Loss: 0.12834 
Epoch [160/300] Training [58/62] Loss: 0.08788 
Epoch [160/300] Training [59/62] Loss: 0.17438 
Epoch [160/300] Training [60/62] Loss: 0.07903 
Epoch [160/300] Training [61/62] Loss: 0.11530 
Epoch [160/300] Training [62/62] Loss: 0.07379 
Epoch [160/300] Training metric {'Train/mean dice_metric': 0.9307419061660767, 'Train/mean miou_metric': 0.8806273937225342, 'Train/mean f1': 0.9440864324569702, 'Train/mean precision': 0.9378288388252258, 'Train/mean recall': 0.9504281878471375, 'Train/mean hd95_metric': 11.740653991699219}
Epoch [160/300] Validation [1/16] Loss: 0.12399  focal_loss 0.03805  dice_loss 0.08594 
Epoch [160/300] Validation [2/16] Loss: 0.37122  focal_loss 0.12889  dice_loss 0.24232 
Epoch [160/300] Validation [3/16] Loss: 0.38478  focal_loss 0.14566  dice_loss 0.23912 
Epoch [160/300] Validation [4/16] Loss: 0.24262  focal_loss 0.08648  dice_loss 0.15614 
Epoch [160/300] Validation [5/16] Loss: 0.29895  focal_loss 0.07771  dice_loss 0.22124 
Epoch [160/300] Validation [6/16] Loss: 0.24178  focal_loss 0.03884  dice_loss 0.20294 
Epoch [160/300] Validation [7/16] Loss: 0.30202  focal_loss 0.10646  dice_loss 0.19556 
Epoch [160/300] Validation [8/16] Loss: 0.60332  focal_loss 0.22056  dice_loss 0.38276 
Epoch [160/300] Validation [9/16] Loss: 0.18202  focal_loss 0.07166  dice_loss 0.11036 
Epoch [160/300] Validation [10/16] Loss: 0.15155  focal_loss 0.03421  dice_loss 0.11733 
Epoch [160/300] Validation [11/16] Loss: 0.16119  focal_loss 0.03946  dice_loss 0.12173 
Epoch [160/300] Validation [12/16] Loss: 0.33696  focal_loss 0.08382  dice_loss 0.25314 
Epoch [160/300] Validation [13/16] Loss: 0.40688  focal_loss 0.15246  dice_loss 0.25442 
Epoch [160/300] Validation [14/16] Loss: 0.35247  focal_loss 0.13066  dice_loss 0.22180 
Epoch [160/300] Validation [15/16] Loss: 0.12803  focal_loss 0.03268  dice_loss 0.09535 
Epoch [160/300] Validation [16/16] Loss: 0.04768  focal_loss 0.00892  dice_loss 0.03875 
Epoch [160/300] Validation metric {'Val/mean dice_metric': 0.9085948467254639, 'Val/mean miou_metric': 0.8522816300392151, 'Val/mean f1': 0.9211410880088806, 'Val/mean precision': 0.9165858626365662, 'Val/mean recall': 0.9257417321205139, 'Val/mean hd95_metric': 18.428665161132812}
Cheakpoint...
Epoch [160/300] best acc:tensor([0.9086], device='cuda:0'), Now : mean acc: tensor([0.9086], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9085948467254639, 'Val/mean miou_metric': 0.8522816300392151, 'Val/mean f1': 0.9211410880088806, 'Val/mean precision': 0.9165858626365662, 'Val/mean recall': 0.9257417321205139, 'Val/mean hd95_metric': 18.428665161132812}
Epoch [161/300] Training [1/62] Loss: 0.15803 
Epoch [161/300] Training [2/62] Loss: 0.20868 
Epoch [161/300] Training [3/62] Loss: 0.07462 
Epoch [161/300] Training [4/62] Loss: 0.10366 
Epoch [161/300] Training [5/62] Loss: 0.26044 
Epoch [161/300] Training [6/62] Loss: 0.06913 
Epoch [161/300] Training [7/62] Loss: 0.05632 
Epoch [161/300] Training [8/62] Loss: 0.11362 
Epoch [161/300] Training [9/62] Loss: 0.08705 
Epoch [161/300] Training [10/62] Loss: 0.09955 
Epoch [161/300] Training [11/62] Loss: 0.05010 
Epoch [161/300] Training [12/62] Loss: 0.08996 
Epoch [161/300] Training [13/62] Loss: 0.13821 
Epoch [161/300] Training [14/62] Loss: 0.06952 
Epoch [161/300] Training [15/62] Loss: 0.12318 
Epoch [161/300] Training [16/62] Loss: 0.08515 
Epoch [161/300] Training [17/62] Loss: 0.08389 
Epoch [161/300] Training [18/62] Loss: 0.08556 
Epoch [161/300] Training [19/62] Loss: 0.05206 
Epoch [161/300] Training [20/62] Loss: 0.09514 
Epoch [161/300] Training [21/62] Loss: 0.14461 
Epoch [161/300] Training [22/62] Loss: 0.10561 
Epoch [161/300] Training [23/62] Loss: 0.08734 
Epoch [161/300] Training [24/62] Loss: 0.06813 
Epoch [161/300] Training [25/62] Loss: 0.08975 
Epoch [161/300] Training [26/62] Loss: 0.07881 
Epoch [161/300] Training [27/62] Loss: 0.05610 
Epoch [161/300] Training [28/62] Loss: 0.06222 
Epoch [161/300] Training [29/62] Loss: 0.08294 
Epoch [161/300] Training [30/62] Loss: 0.07869 
Epoch [161/300] Training [31/62] Loss: 0.11731 
Epoch [161/300] Training [32/62] Loss: 0.11665 
Epoch [161/300] Training [33/62] Loss: 0.08192 
Epoch [161/300] Training [34/62] Loss: 0.05129 
Epoch [161/300] Training [35/62] Loss: 0.08160 
Epoch [161/300] Training [36/62] Loss: 0.05966 
Epoch [161/300] Training [37/62] Loss: 0.05886 
Epoch [161/300] Training [38/62] Loss: 0.11722 
Epoch [161/300] Training [39/62] Loss: 0.20209 
Epoch [161/300] Training [40/62] Loss: 0.12168 
Epoch [161/300] Training [41/62] Loss: 0.09082 
Epoch [161/300] Training [42/62] Loss: 0.05592 
Epoch [161/300] Training [43/62] Loss: 0.12891 
Epoch [161/300] Training [44/62] Loss: 0.09502 
Epoch [161/300] Training [45/62] Loss: 0.07296 
Epoch [161/300] Training [46/62] Loss: 0.06466 
Epoch [161/300] Training [47/62] Loss: 0.10287 
Epoch [161/300] Training [48/62] Loss: 0.21135 
Epoch [161/300] Training [49/62] Loss: 0.07637 
Epoch [161/300] Training [50/62] Loss: 0.13336 
Epoch [161/300] Training [51/62] Loss: 0.06197 
Epoch [161/300] Training [52/62] Loss: 0.09877 
Epoch [161/300] Training [53/62] Loss: 0.09087 
Epoch [161/300] Training [54/62] Loss: 0.06280 
Epoch [161/300] Training [55/62] Loss: 0.04883 
Epoch [161/300] Training [56/62] Loss: 0.11970 
Epoch [161/300] Training [57/62] Loss: 0.10380 
Epoch [161/300] Training [58/62] Loss: 0.08662 
Epoch [161/300] Training [59/62] Loss: 0.06956 
Epoch [161/300] Training [60/62] Loss: 0.06817 
Epoch [161/300] Training [61/62] Loss: 0.11587 
Epoch [161/300] Training [62/62] Loss: 0.14381 
Epoch [161/300] Training metric {'Train/mean dice_metric': 0.9328569769859314, 'Train/mean miou_metric': 0.8833728432655334, 'Train/mean f1': 0.9449556469917297, 'Train/mean precision': 0.9414095282554626, 'Train/mean recall': 0.948528528213501, 'Train/mean hd95_metric': 12.58900260925293}
Epoch [161/300] Validation [1/16] Loss: 0.21757  focal_loss 0.08732  dice_loss 0.13025 
Epoch [161/300] Validation [2/16] Loss: 0.35789  focal_loss 0.12770  dice_loss 0.23019 
Epoch [161/300] Validation [3/16] Loss: 0.44671  focal_loss 0.21851  dice_loss 0.22820 
Epoch [161/300] Validation [4/16] Loss: 0.30198  focal_loss 0.12795  dice_loss 0.17403 
Epoch [161/300] Validation [5/16] Loss: 0.32705  focal_loss 0.09107  dice_loss 0.23598 
Epoch [161/300] Validation [6/16] Loss: 0.18862  focal_loss 0.02702  dice_loss 0.16160 
Epoch [161/300] Validation [7/16] Loss: 0.20052  focal_loss 0.08989  dice_loss 0.11063 
Epoch [161/300] Validation [8/16] Loss: 0.35257  focal_loss 0.12317  dice_loss 0.22940 
Epoch [161/300] Validation [9/16] Loss: 0.14005  focal_loss 0.04581  dice_loss 0.09424 
Epoch [161/300] Validation [10/16] Loss: 0.14252  focal_loss 0.03579  dice_loss 0.10672 
Epoch [161/300] Validation [11/16] Loss: 0.14980  focal_loss 0.03745  dice_loss 0.11235 
Epoch [161/300] Validation [12/16] Loss: 0.33165  focal_loss 0.09678  dice_loss 0.23487 
Epoch [161/300] Validation [13/16] Loss: 0.38831  focal_loss 0.17117  dice_loss 0.21713 
Epoch [161/300] Validation [14/16] Loss: 0.42745  focal_loss 0.13967  dice_loss 0.28777 
Epoch [161/300] Validation [15/16] Loss: 0.09272  focal_loss 0.02661  dice_loss 0.06610 
Epoch [161/300] Validation [16/16] Loss: 0.05332  focal_loss 0.01220  dice_loss 0.04111 
Epoch [161/300] Validation metric {'Val/mean dice_metric': 0.9132034182548523, 'Val/mean miou_metric': 0.8575883507728577, 'Val/mean f1': 0.9267914295196533, 'Val/mean precision': 0.9283028841018677, 'Val/mean recall': 0.9252848625183105, 'Val/mean hd95_metric': 16.91672706604004}
Cheakpoint...
Epoch [161/300] best acc:tensor([0.9132], device='cuda:0'), Now : mean acc: tensor([0.9132], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9132034182548523, 'Val/mean miou_metric': 0.8575883507728577, 'Val/mean f1': 0.9267914295196533, 'Val/mean precision': 0.9283028841018677, 'Val/mean recall': 0.9252848625183105, 'Val/mean hd95_metric': 16.91672706604004}
Epoch [162/300] Training [1/62] Loss: 0.07362 
Epoch [162/300] Training [2/62] Loss: 0.04692 
Epoch [162/300] Training [3/62] Loss: 0.19357 
Epoch [162/300] Training [4/62] Loss: 0.06228 
Epoch [162/300] Training [5/62] Loss: 0.10876 
Epoch [162/300] Training [6/62] Loss: 0.06066 
Epoch [162/300] Training [7/62] Loss: 0.07278 
Epoch [162/300] Training [8/62] Loss: 0.08984 
Epoch [162/300] Training [9/62] Loss: 0.05806 
Epoch [162/300] Training [10/62] Loss: 0.20653 
Epoch [162/300] Training [11/62] Loss: 0.05727 
Epoch [162/300] Training [12/62] Loss: 0.06677 
Epoch [162/300] Training [13/62] Loss: 0.05402 
Epoch [162/300] Training [14/62] Loss: 0.15724 
Epoch [162/300] Training [15/62] Loss: 0.11994 
Epoch [162/300] Training [16/62] Loss: 0.07565 
Epoch [162/300] Training [17/62] Loss: 0.17285 
Epoch [162/300] Training [18/62] Loss: 0.06334 
Epoch [162/300] Training [19/62] Loss: 0.05290 
Epoch [162/300] Training [20/62] Loss: 0.05387 
Epoch [162/300] Training [21/62] Loss: 0.10229 
Epoch [162/300] Training [22/62] Loss: 0.08608 
Epoch [162/300] Training [23/62] Loss: 0.09740 
Epoch [162/300] Training [24/62] Loss: 0.06047 
Epoch [162/300] Training [25/62] Loss: 0.20685 
Epoch [162/300] Training [26/62] Loss: 0.05779 
Epoch [162/300] Training [27/62] Loss: 0.05526 
Epoch [162/300] Training [28/62] Loss: 0.08909 
Epoch [162/300] Training [29/62] Loss: 0.09369 
Epoch [162/300] Training [30/62] Loss: 0.08100 
Epoch [162/300] Training [31/62] Loss: 0.06238 
Epoch [162/300] Training [32/62] Loss: 0.11079 
Epoch [162/300] Training [33/62] Loss: 0.08516 
Epoch [162/300] Training [34/62] Loss: 0.08087 
Epoch [162/300] Training [35/62] Loss: 0.12080 
Epoch [162/300] Training [36/62] Loss: 0.12777 
Epoch [162/300] Training [37/62] Loss: 0.06089 
Epoch [162/300] Training [38/62] Loss: 0.09843 
Epoch [162/300] Training [39/62] Loss: 0.05279 
Epoch [162/300] Training [40/62] Loss: 0.06317 
Epoch [162/300] Training [41/62] Loss: 0.06566 
Epoch [162/300] Training [42/62] Loss: 0.09997 
Epoch [162/300] Training [43/62] Loss: 0.06820 
Epoch [162/300] Training [44/62] Loss: 0.07224 
Epoch [162/300] Training [45/62] Loss: 0.06974 
Epoch [162/300] Training [46/62] Loss: 0.07629 
Epoch [162/300] Training [47/62] Loss: 0.22662 
Epoch [162/300] Training [48/62] Loss: 0.08258 
Epoch [162/300] Training [49/62] Loss: 0.16766 
Epoch [162/300] Training [50/62] Loss: 0.09418 
Epoch [162/300] Training [51/62] Loss: 0.11683 
Epoch [162/300] Training [52/62] Loss: 0.09072 
Epoch [162/300] Training [53/62] Loss: 0.06930 
Epoch [162/300] Training [54/62] Loss: 0.06006 
Epoch [162/300] Training [55/62] Loss: 0.07413 
Epoch [162/300] Training [56/62] Loss: 0.15756 
Epoch [162/300] Training [57/62] Loss: 0.11568 
Epoch [162/300] Training [58/62] Loss: 0.10496 
Epoch [162/300] Training [59/62] Loss: 0.10256 
Epoch [162/300] Training [60/62] Loss: 0.08983 
Epoch [162/300] Training [61/62] Loss: 0.08604 
Epoch [162/300] Training [62/62] Loss: 0.15475 
Epoch [162/300] Training metric {'Train/mean dice_metric': 0.9335082173347473, 'Train/mean miou_metric': 0.8845146298408508, 'Train/mean f1': 0.9456919431686401, 'Train/mean precision': 0.9419847130775452, 'Train/mean recall': 0.9494286179542542, 'Train/mean hd95_metric': 11.508947372436523}
Epoch [162/300] Validation [1/16] Loss: 0.11217  focal_loss 0.04012  dice_loss 0.07205 
Epoch [162/300] Validation [2/16] Loss: 0.33018  focal_loss 0.09401  dice_loss 0.23617 
Epoch [162/300] Validation [3/16] Loss: 0.61376  focal_loss 0.33380  dice_loss 0.27996 
Epoch [162/300] Validation [4/16] Loss: 0.23395  focal_loss 0.07401  dice_loss 0.15994 
Epoch [162/300] Validation [5/16] Loss: 0.36611  focal_loss 0.09931  dice_loss 0.26680 
Epoch [162/300] Validation [6/16] Loss: 0.23294  focal_loss 0.04705  dice_loss 0.18589 
Epoch [162/300] Validation [7/16] Loss: 0.21338  focal_loss 0.05913  dice_loss 0.15425 
Epoch [162/300] Validation [8/16] Loss: 0.47380  focal_loss 0.17168  dice_loss 0.30211 
Epoch [162/300] Validation [9/16] Loss: 0.20902  focal_loss 0.06314  dice_loss 0.14587 
Epoch [162/300] Validation [10/16] Loss: 0.28615  focal_loss 0.06130  dice_loss 0.22484 
Epoch [162/300] Validation [11/16] Loss: 0.16746  focal_loss 0.04351  dice_loss 0.12395 
Epoch [162/300] Validation [12/16] Loss: 0.32399  focal_loss 0.06738  dice_loss 0.25662 
Epoch [162/300] Validation [13/16] Loss: 0.31323  focal_loss 0.10922  dice_loss 0.20401 
Epoch [162/300] Validation [14/16] Loss: 0.34454  focal_loss 0.10227  dice_loss 0.24227 
Epoch [162/300] Validation [15/16] Loss: 0.11956  focal_loss 0.03270  dice_loss 0.08686 
Epoch [162/300] Validation [16/16] Loss: 0.04533  focal_loss 0.00768  dice_loss 0.03765 
Epoch [162/300] Validation metric {'Val/mean dice_metric': 0.910283625125885, 'Val/mean miou_metric': 0.855158805847168, 'Val/mean f1': 0.9239034056663513, 'Val/mean precision': 0.9219771027565002, 'Val/mean recall': 0.9258376955986023, 'Val/mean hd95_metric': 18.33171272277832}
Cheakpoint...
Epoch [162/300] best acc:tensor([0.9132], device='cuda:0'), Now : mean acc: tensor([0.9103], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.910283625125885, 'Val/mean miou_metric': 0.855158805847168, 'Val/mean f1': 0.9239034056663513, 'Val/mean precision': 0.9219771027565002, 'Val/mean recall': 0.9258376955986023, 'Val/mean hd95_metric': 18.33171272277832}
Epoch [163/300] Training [1/62] Loss: 0.06304 
Epoch [163/300] Training [2/62] Loss: 0.09176 
Epoch [163/300] Training [3/62] Loss: 0.05848 
Epoch [163/300] Training [4/62] Loss: 0.11577 
Epoch [163/300] Training [5/62] Loss: 0.05826 
Epoch [163/300] Training [6/62] Loss: 0.06035 
Epoch [163/300] Training [7/62] Loss: 0.05190 
Epoch [163/300] Training [8/62] Loss: 0.12471 
Epoch [163/300] Training [9/62] Loss: 0.06922 
Epoch [163/300] Training [10/62] Loss: 0.12234 
Epoch [163/300] Training [11/62] Loss: 0.08487 
Epoch [163/300] Training [12/62] Loss: 0.12408 
Epoch [163/300] Training [13/62] Loss: 0.15877 
Epoch [163/300] Training [14/62] Loss: 0.18225 
Epoch [163/300] Training [15/62] Loss: 0.06813 
Epoch [163/300] Training [16/62] Loss: 0.19326 
Epoch [163/300] Training [17/62] Loss: 0.07409 
Epoch [163/300] Training [18/62] Loss: 0.08701 
Epoch [163/300] Training [19/62] Loss: 0.07826 
Epoch [163/300] Training [20/62] Loss: 0.08556 
Epoch [163/300] Training [21/62] Loss: 0.08949 
Epoch [163/300] Training [22/62] Loss: 0.06080 
Epoch [163/300] Training [23/62] Loss: 0.05977 
Epoch [163/300] Training [24/62] Loss: 0.16722 
Epoch [163/300] Training [25/62] Loss: 0.12800 
Epoch [163/300] Training [26/62] Loss: 0.07282 
Epoch [163/300] Training [27/62] Loss: 0.16797 
Epoch [163/300] Training [28/62] Loss: 0.14813 
Epoch [163/300] Training [29/62] Loss: 0.06781 
Epoch [163/300] Training [30/62] Loss: 0.11267 
Epoch [163/300] Training [31/62] Loss: 0.07402 
Epoch [163/300] Training [32/62] Loss: 0.08462 
Epoch [163/300] Training [33/62] Loss: 0.09428 
Epoch [163/300] Training [34/62] Loss: 0.08852 
Epoch [163/300] Training [35/62] Loss: 0.23472 
Epoch [163/300] Training [36/62] Loss: 0.13753 
Epoch [163/300] Training [37/62] Loss: 0.06529 
Epoch [163/300] Training [38/62] Loss: 0.05665 
Epoch [163/300] Training [39/62] Loss: 0.09246 
Epoch [163/300] Training [40/62] Loss: 0.10756 
Epoch [163/300] Training [41/62] Loss: 0.12876 
Epoch [163/300] Training [42/62] Loss: 0.09411 
Epoch [163/300] Training [43/62] Loss: 0.07448 
Epoch [163/300] Training [44/62] Loss: 0.06321 
Epoch [163/300] Training [45/62] Loss: 0.06160 
Epoch [163/300] Training [46/62] Loss: 0.10269 
Epoch [163/300] Training [47/62] Loss: 0.07138 
Epoch [163/300] Training [48/62] Loss: 0.08243 
Epoch [163/300] Training [49/62] Loss: 0.05361 
Epoch [163/300] Training [50/62] Loss: 0.07635 
Epoch [163/300] Training [51/62] Loss: 0.07586 
Epoch [163/300] Training [52/62] Loss: 0.08218 
Epoch [163/300] Training [53/62] Loss: 0.06059 
Epoch [163/300] Training [54/62] Loss: 0.06504 
Epoch [163/300] Training [55/62] Loss: 0.09480 
Epoch [163/300] Training [56/62] Loss: 0.04978 
Epoch [163/300] Training [57/62] Loss: 0.06088 
Epoch [163/300] Training [58/62] Loss: 0.24597 
Epoch [163/300] Training [59/62] Loss: 0.08251 
Epoch [163/300] Training [60/62] Loss: 0.10327 
Epoch [163/300] Training [61/62] Loss: 0.08287 
Epoch [163/300] Training [62/62] Loss: 0.05323 
Epoch [163/300] Training metric {'Train/mean dice_metric': 0.9322689771652222, 'Train/mean miou_metric': 0.8822479844093323, 'Train/mean f1': 0.9439690709114075, 'Train/mean precision': 0.9394107460975647, 'Train/mean recall': 0.9485718011856079, 'Train/mean hd95_metric': 12.058097839355469}
Epoch [163/300] Validation [1/16] Loss: 0.39091  focal_loss 0.24311  dice_loss 0.14780 
Epoch [163/300] Validation [2/16] Loss: 0.38139  focal_loss 0.15327  dice_loss 0.22811 
Epoch [163/300] Validation [3/16] Loss: 0.49231  focal_loss 0.25138  dice_loss 0.24093 
Epoch [163/300] Validation [4/16] Loss: 0.40529  focal_loss 0.17628  dice_loss 0.22902 
Epoch [163/300] Validation [5/16] Loss: 0.42573  focal_loss 0.16468  dice_loss 0.26105 
Epoch [163/300] Validation [6/16] Loss: 0.26136  focal_loss 0.05926  dice_loss 0.20210 
Epoch [163/300] Validation [7/16] Loss: 0.34820  focal_loss 0.15285  dice_loss 0.19536 
Epoch [163/300] Validation [8/16] Loss: 0.34963  focal_loss 0.12170  dice_loss 0.22792 
Epoch [163/300] Validation [9/16] Loss: 0.30069  focal_loss 0.11330  dice_loss 0.18740 
Epoch [163/300] Validation [10/16] Loss: 0.20867  focal_loss 0.04876  dice_loss 0.15991 
Epoch [163/300] Validation [11/16] Loss: 0.17244  focal_loss 0.06094  dice_loss 0.11149 
Epoch [163/300] Validation [12/16] Loss: 0.35629  focal_loss 0.08946  dice_loss 0.26684 
Epoch [163/300] Validation [13/16] Loss: 0.32627  focal_loss 0.11020  dice_loss 0.21607 
Epoch [163/300] Validation [14/16] Loss: 0.48257  focal_loss 0.15832  dice_loss 0.32425 
Epoch [163/300] Validation [15/16] Loss: 0.13797  focal_loss 0.04413  dice_loss 0.09384 
Epoch [163/300] Validation [16/16] Loss: 0.04575  focal_loss 0.01023  dice_loss 0.03552 
Epoch [163/300] Validation metric {'Val/mean dice_metric': 0.9065079092979431, 'Val/mean miou_metric': 0.8494585752487183, 'Val/mean f1': 0.9183494448661804, 'Val/mean precision': 0.917302668094635, 'Val/mean recall': 0.9193986058235168, 'Val/mean hd95_metric': 18.697887420654297}
Cheakpoint...
Epoch [163/300] best acc:tensor([0.9132], device='cuda:0'), Now : mean acc: tensor([0.9065], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9065079092979431, 'Val/mean miou_metric': 0.8494585752487183, 'Val/mean f1': 0.9183494448661804, 'Val/mean precision': 0.917302668094635, 'Val/mean recall': 0.9193986058235168, 'Val/mean hd95_metric': 18.697887420654297}
Epoch [164/300] Training [1/62] Loss: 0.05764 
Epoch [164/300] Training [2/62] Loss: 0.12121 
Epoch [164/300] Training [3/62] Loss: 0.09640 
Epoch [164/300] Training [4/62] Loss: 0.08752 
Epoch [164/300] Training [5/62] Loss: 0.07340 
Epoch [164/300] Training [6/62] Loss: 0.07846 
Epoch [164/300] Training [7/62] Loss: 0.07355 
Epoch [164/300] Training [8/62] Loss: 0.11169 
Epoch [164/300] Training [9/62] Loss: 0.11338 
Epoch [164/300] Training [10/62] Loss: 0.08214 
Epoch [164/300] Training [11/62] Loss: 0.09001 
Epoch [164/300] Training [12/62] Loss: 0.08253 
Epoch [164/300] Training [13/62] Loss: 0.05333 
Epoch [164/300] Training [14/62] Loss: 0.06230 
Epoch [164/300] Training [15/62] Loss: 0.08816 
Epoch [164/300] Training [16/62] Loss: 0.05350 
Epoch [164/300] Training [17/62] Loss: 0.07224 
Epoch [164/300] Training [18/62] Loss: 0.08357 
Epoch [164/300] Training [19/62] Loss: 0.05937 
Epoch [164/300] Training [20/62] Loss: 0.05989 
Epoch [164/300] Training [21/62] Loss: 0.06959 
Epoch [164/300] Training [22/62] Loss: 0.09537 
Epoch [164/300] Training [23/62] Loss: 0.04828 
Epoch [164/300] Training [24/62] Loss: 0.04670 
Epoch [164/300] Training [25/62] Loss: 0.05409 
Epoch [164/300] Training [26/62] Loss: 0.07350 
Epoch [164/300] Training [27/62] Loss: 0.11150 
Epoch [164/300] Training [28/62] Loss: 0.07103 
Epoch [164/300] Training [29/62] Loss: 0.08146 
Epoch [164/300] Training [30/62] Loss: 0.11939 
Epoch [164/300] Training [31/62] Loss: 0.15830 
Epoch [164/300] Training [32/62] Loss: 0.06763 
Epoch [164/300] Training [33/62] Loss: 0.12644 
Epoch [164/300] Training [34/62] Loss: 0.09647 
Epoch [164/300] Training [35/62] Loss: 0.11904 
Epoch [164/300] Training [36/62] Loss: 0.08563 
Epoch [164/300] Training [37/62] Loss: 0.11528 
Epoch [164/300] Training [38/62] Loss: 0.06254 
Epoch [164/300] Training [39/62] Loss: 0.06887 
Epoch [164/300] Training [40/62] Loss: 0.07451 
Epoch [164/300] Training [41/62] Loss: 0.04981 
Epoch [164/300] Training [42/62] Loss: 0.15408 
Epoch [164/300] Training [43/62] Loss: 0.07690 
Epoch [164/300] Training [44/62] Loss: 0.08717 
Epoch [164/300] Training [45/62] Loss: 0.14911 
Epoch [164/300] Training [46/62] Loss: 0.08521 
Epoch [164/300] Training [47/62] Loss: 0.12005 
Epoch [164/300] Training [48/62] Loss: 0.09253 
Epoch [164/300] Training [49/62] Loss: 0.06622 
Epoch [164/300] Training [50/62] Loss: 0.06714 
Epoch [164/300] Training [51/62] Loss: 0.08496 
Epoch [164/300] Training [52/62] Loss: 0.10412 
Epoch [164/300] Training [53/62] Loss: 0.18815 
Epoch [164/300] Training [54/62] Loss: 0.06588 
Epoch [164/300] Training [55/62] Loss: 0.09820 
Epoch [164/300] Training [56/62] Loss: 0.09458 
Epoch [164/300] Training [57/62] Loss: 0.08912 
Epoch [164/300] Training [58/62] Loss: 0.11793 
Epoch [164/300] Training [59/62] Loss: 0.15591 
Epoch [164/300] Training [60/62] Loss: 0.07842 
Epoch [164/300] Training [61/62] Loss: 0.16341 
Epoch [164/300] Training [62/62] Loss: 0.04814 
Epoch [164/300] Training metric {'Train/mean dice_metric': 0.9367029666900635, 'Train/mean miou_metric': 0.8865571022033691, 'Train/mean f1': 0.9460465312004089, 'Train/mean precision': 0.943210780620575, 'Train/mean recall': 0.9488993883132935, 'Train/mean hd95_metric': 11.50924015045166}
Epoch [164/300] Validation [1/16] Loss: 0.11271  focal_loss 0.03559  dice_loss 0.07712 
Epoch [164/300] Validation [2/16] Loss: 0.35835  focal_loss 0.12641  dice_loss 0.23194 
Epoch [164/300] Validation [3/16] Loss: 0.57174  focal_loss 0.26010  dice_loss 0.31164 
Epoch [164/300] Validation [4/16] Loss: 0.30413  focal_loss 0.07330  dice_loss 0.23083 
Epoch [164/300] Validation [5/16] Loss: 0.37496  focal_loss 0.12123  dice_loss 0.25373 
Epoch [164/300] Validation [6/16] Loss: 0.30967  focal_loss 0.11461  dice_loss 0.19506 
Epoch [164/300] Validation [7/16] Loss: 0.20228  focal_loss 0.05787  dice_loss 0.14440 
Epoch [164/300] Validation [8/16] Loss: 0.28927  focal_loss 0.05063  dice_loss 0.23864 
Epoch [164/300] Validation [9/16] Loss: 0.26212  focal_loss 0.11348  dice_loss 0.14864 
Epoch [164/300] Validation [10/16] Loss: 0.20156  focal_loss 0.06367  dice_loss 0.13789 
Epoch [164/300] Validation [11/16] Loss: 0.21276  focal_loss 0.03429  dice_loss 0.17847 
Epoch [164/300] Validation [12/16] Loss: 0.32462  focal_loss 0.06961  dice_loss 0.25501 
Epoch [164/300] Validation [13/16] Loss: 0.26686  focal_loss 0.08729  dice_loss 0.17956 
Epoch [164/300] Validation [14/16] Loss: 0.49225  focal_loss 0.14921  dice_loss 0.34304 
Epoch [164/300] Validation [15/16] Loss: 0.10762  focal_loss 0.02800  dice_loss 0.07962 
Epoch [164/300] Validation [16/16] Loss: 0.06058  focal_loss 0.01225  dice_loss 0.04833 
Epoch [164/300] Validation metric {'Val/mean dice_metric': 0.9126542210578918, 'Val/mean miou_metric': 0.8554525971412659, 'Val/mean f1': 0.9212057590484619, 'Val/mean precision': 0.9079979658126831, 'Val/mean recall': 0.9348035454750061, 'Val/mean hd95_metric': 17.9263916015625}
Cheakpoint...
Epoch [164/300] best acc:tensor([0.9132], device='cuda:0'), Now : mean acc: tensor([0.9127], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9126542210578918, 'Val/mean miou_metric': 0.8554525971412659, 'Val/mean f1': 0.9212057590484619, 'Val/mean precision': 0.9079979658126831, 'Val/mean recall': 0.9348035454750061, 'Val/mean hd95_metric': 17.9263916015625}
Epoch [165/300] Training [1/62] Loss: 0.08505 
Epoch [165/300] Training [2/62] Loss: 0.08956 
Epoch [165/300] Training [3/62] Loss: 0.12091 
Epoch [165/300] Training [4/62] Loss: 0.09622 
Epoch [165/300] Training [5/62] Loss: 0.08607 
Epoch [165/300] Training [6/62] Loss: 0.06478 
Epoch [165/300] Training [7/62] Loss: 0.07838 
Epoch [165/300] Training [8/62] Loss: 0.06713 
Epoch [165/300] Training [9/62] Loss: 0.08454 
Epoch [165/300] Training [10/62] Loss: 0.10607 
Epoch [165/300] Training [11/62] Loss: 0.09142 
Epoch [165/300] Training [12/62] Loss: 0.15535 
Epoch [165/300] Training [13/62] Loss: 0.06135 
Epoch [165/300] Training [14/62] Loss: 0.09059 
Epoch [165/300] Training [15/62] Loss: 0.06402 
Epoch [165/300] Training [16/62] Loss: 0.08344 
Epoch [165/300] Training [17/62] Loss: 0.08402 
Epoch [165/300] Training [18/62] Loss: 0.05144 
Epoch [165/300] Training [19/62] Loss: 0.06939 
Epoch [165/300] Training [20/62] Loss: 0.10185 
Epoch [165/300] Training [21/62] Loss: 0.08485 
Epoch [165/300] Training [22/62] Loss: 0.07388 
Epoch [165/300] Training [23/62] Loss: 0.06691 
Epoch [165/300] Training [24/62] Loss: 0.05475 
Epoch [165/300] Training [25/62] Loss: 0.05911 
Epoch [165/300] Training [26/62] Loss: 0.04742 
Epoch [165/300] Training [27/62] Loss: 0.15496 
Epoch [165/300] Training [28/62] Loss: 0.05551 
Epoch [165/300] Training [29/62] Loss: 0.08244 
Epoch [165/300] Training [30/62] Loss: 0.16533 
Epoch [165/300] Training [31/62] Loss: 0.07521 
Epoch [165/300] Training [32/62] Loss: 0.09478 
Epoch [165/300] Training [33/62] Loss: 0.19192 
Epoch [165/300] Training [34/62] Loss: 0.13109 
Epoch [165/300] Training [35/62] Loss: 0.08019 
Epoch [165/300] Training [36/62] Loss: 0.07096 
Epoch [165/300] Training [37/62] Loss: 0.06989 
Epoch [165/300] Training [38/62] Loss: 0.18276 
Epoch [165/300] Training [39/62] Loss: 0.08874 
Epoch [165/300] Training [40/62] Loss: 0.07413 
Epoch [165/300] Training [41/62] Loss: 0.08113 
Epoch [165/300] Training [42/62] Loss: 0.09074 
Epoch [165/300] Training [43/62] Loss: 0.06631 
Epoch [165/300] Training [44/62] Loss: 0.21439 
Epoch [165/300] Training [45/62] Loss: 0.14269 
Epoch [165/300] Training [46/62] Loss: 0.07049 
Epoch [165/300] Training [47/62] Loss: 0.05745 
Epoch [165/300] Training [48/62] Loss: 0.14221 
Epoch [165/300] Training [49/62] Loss: 0.08506 
Epoch [165/300] Training [50/62] Loss: 0.08451 
Epoch [165/300] Training [51/62] Loss: 0.05505 
Epoch [165/300] Training [52/62] Loss: 0.08559 
Epoch [165/300] Training [53/62] Loss: 0.10834 
Epoch [165/300] Training [54/62] Loss: 0.07328 
Epoch [165/300] Training [55/62] Loss: 0.05145 
Epoch [165/300] Training [56/62] Loss: 0.06395 
Epoch [165/300] Training [57/62] Loss: 0.10590 
Epoch [165/300] Training [58/62] Loss: 0.17839 
Epoch [165/300] Training [59/62] Loss: 0.12895 
Epoch [165/300] Training [60/62] Loss: 0.35666 
Epoch [165/300] Training [61/62] Loss: 0.05632 
Epoch [165/300] Training [62/62] Loss: 0.03818 
Epoch [165/300] Training metric {'Train/mean dice_metric': 0.93346107006073, 'Train/mean miou_metric': 0.8839058876037598, 'Train/mean f1': 0.941682755947113, 'Train/mean precision': 0.9376580119132996, 'Train/mean recall': 0.9457422494888306, 'Train/mean hd95_metric': 12.106230735778809}
Epoch [165/300] Validation [1/16] Loss: 0.16044  focal_loss 0.05051  dice_loss 0.10993 
Epoch [165/300] Validation [2/16] Loss: 0.32755  focal_loss 0.08897  dice_loss 0.23858 
Epoch [165/300] Validation [3/16] Loss: 0.49672  focal_loss 0.14784  dice_loss 0.34888 
Epoch [165/300] Validation [4/16] Loss: 0.21964  focal_loss 0.07511  dice_loss 0.14453 
Epoch [165/300] Validation [5/16] Loss: 0.34250  focal_loss 0.08936  dice_loss 0.25314 
Epoch [165/300] Validation [6/16] Loss: 0.18452  focal_loss 0.03426  dice_loss 0.15027 
Epoch [165/300] Validation [7/16] Loss: 0.31399  focal_loss 0.11385  dice_loss 0.20014 
Epoch [165/300] Validation [8/16] Loss: 0.36678  focal_loss 0.07719  dice_loss 0.28959 
Epoch [165/300] Validation [9/16] Loss: 0.23797  focal_loss 0.07664  dice_loss 0.16134 
Epoch [165/300] Validation [10/16] Loss: 0.42802  focal_loss 0.13309  dice_loss 0.29493 
Epoch [165/300] Validation [11/16] Loss: 0.13835  focal_loss 0.03083  dice_loss 0.10752 
Epoch [165/300] Validation [12/16] Loss: 0.36926  focal_loss 0.03943  dice_loss 0.32983 
Epoch [165/300] Validation [13/16] Loss: 0.24617  focal_loss 0.05333  dice_loss 0.19284 
Epoch [165/300] Validation [14/16] Loss: 0.51797  focal_loss 0.16624  dice_loss 0.35173 
Epoch [165/300] Validation [15/16] Loss: 0.14114  focal_loss 0.03579  dice_loss 0.10535 
Epoch [165/300] Validation [16/16] Loss: 0.04217  focal_loss 0.00672  dice_loss 0.03545 
Epoch [165/300] Validation metric {'Val/mean dice_metric': 0.9069883823394775, 'Val/mean miou_metric': 0.8507271409034729, 'Val/mean f1': 0.9136254787445068, 'Val/mean precision': 0.8977128863334656, 'Val/mean recall': 0.9301123023033142, 'Val/mean hd95_metric': 19.119915008544922}
Cheakpoint...
Epoch [165/300] best acc:tensor([0.9132], device='cuda:0'), Now : mean acc: tensor([0.9070], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9069883823394775, 'Val/mean miou_metric': 0.8507271409034729, 'Val/mean f1': 0.9136254787445068, 'Val/mean precision': 0.8977128863334656, 'Val/mean recall': 0.9301123023033142, 'Val/mean hd95_metric': 19.119915008544922}
Epoch [166/300] Training [1/62] Loss: 0.07544 
Epoch [166/300] Training [2/62] Loss: 0.17764 
Epoch [166/300] Training [3/62] Loss: 0.13924 
Epoch [166/300] Training [4/62] Loss: 0.13362 
Epoch [166/300] Training [5/62] Loss: 0.11634 
Epoch [166/300] Training [6/62] Loss: 0.07489 
Epoch [166/300] Training [7/62] Loss: 0.08444 
Epoch [166/300] Training [8/62] Loss: 0.07640 
Epoch [166/300] Training [9/62] Loss: 0.08535 
Epoch [166/300] Training [10/62] Loss: 0.06489 
Epoch [166/300] Training [11/62] Loss: 0.11585 
Epoch [166/300] Training [12/62] Loss: 0.09085 
Epoch [166/300] Training [13/62] Loss: 0.04054 
Epoch [166/300] Training [14/62] Loss: 0.08970 
Epoch [166/300] Training [15/62] Loss: 0.15434 
Epoch [166/300] Training [16/62] Loss: 0.07440 
Epoch [166/300] Training [17/62] Loss: 0.15329 
Epoch [166/300] Training [18/62] Loss: 0.20489 
Epoch [166/300] Training [19/62] Loss: 0.07618 
Epoch [166/300] Training [20/62] Loss: 0.07658 
Epoch [166/300] Training [21/62] Loss: 0.11442 
Epoch [166/300] Training [22/62] Loss: 0.05969 
Epoch [166/300] Training [23/62] Loss: 0.06982 
Epoch [166/300] Training [24/62] Loss: 0.04727 
Epoch [166/300] Training [25/62] Loss: 0.04849 
Epoch [166/300] Training [26/62] Loss: 0.15508 
Epoch [166/300] Training [27/62] Loss: 0.06000 
Epoch [166/300] Training [28/62] Loss: 0.13058 
Epoch [166/300] Training [29/62] Loss: 0.10755 
Epoch [166/300] Training [30/62] Loss: 0.07629 
Epoch [166/300] Training [31/62] Loss: 0.06199 
Epoch [166/300] Training [32/62] Loss: 0.05283 
Epoch [166/300] Training [33/62] Loss: 0.06732 
Epoch [166/300] Training [34/62] Loss: 0.05965 
Epoch [166/300] Training [35/62] Loss: 0.06632 
Epoch [166/300] Training [36/62] Loss: 0.10735 
Epoch [166/300] Training [37/62] Loss: 0.17521 
Epoch [166/300] Training [38/62] Loss: 0.06005 
Epoch [166/300] Training [39/62] Loss: 0.08575 
Epoch [166/300] Training [40/62] Loss: 0.05872 
Epoch [166/300] Training [41/62] Loss: 0.05702 
Epoch [166/300] Training [42/62] Loss: 0.06619 
Epoch [166/300] Training [43/62] Loss: 0.12998 
Epoch [166/300] Training [44/62] Loss: 0.05331 
Epoch [166/300] Training [45/62] Loss: 0.08691 
Epoch [166/300] Training [46/62] Loss: 0.11427 
Epoch [166/300] Training [47/62] Loss: 0.16130 
Epoch [166/300] Training [48/62] Loss: 0.09129 
Epoch [166/300] Training [49/62] Loss: 0.05445 
Epoch [166/300] Training [50/62] Loss: 0.07015 
Epoch [166/300] Training [51/62] Loss: 0.07468 
Epoch [166/300] Training [52/62] Loss: 0.06851 
Epoch [166/300] Training [53/62] Loss: 0.17243 
Epoch [166/300] Training [54/62] Loss: 0.20430 
Epoch [166/300] Training [55/62] Loss: 0.07616 
Epoch [166/300] Training [56/62] Loss: 0.08134 
Epoch [166/300] Training [57/62] Loss: 0.08806 
Epoch [166/300] Training [58/62] Loss: 0.09626 
Epoch [166/300] Training [59/62] Loss: 0.08522 
Epoch [166/300] Training [60/62] Loss: 0.07312 
Epoch [166/300] Training [61/62] Loss: 0.07860 
Epoch [166/300] Training [62/62] Loss: 0.07810 
Epoch [166/300] Training metric {'Train/mean dice_metric': 0.934741735458374, 'Train/mean miou_metric': 0.8864121437072754, 'Train/mean f1': 0.9440690875053406, 'Train/mean precision': 0.9364873170852661, 'Train/mean recall': 0.9517746567726135, 'Train/mean hd95_metric': 11.970052719116211}
Epoch [166/300] Validation [1/16] Loss: 0.23550  focal_loss 0.08992  dice_loss 0.14558 
Epoch [166/300] Validation [2/16] Loss: 0.32637  focal_loss 0.10233  dice_loss 0.22404 
Epoch [166/300] Validation [3/16] Loss: 0.29235  focal_loss 0.08387  dice_loss 0.20848 
Epoch [166/300] Validation [4/16] Loss: 0.32128  focal_loss 0.14241  dice_loss 0.17887 
Epoch [166/300] Validation [5/16] Loss: 0.39109  focal_loss 0.10042  dice_loss 0.29067 
Epoch [166/300] Validation [6/16] Loss: 0.25406  focal_loss 0.06954  dice_loss 0.18453 
Epoch [166/300] Validation [7/16] Loss: 0.24137  focal_loss 0.08317  dice_loss 0.15821 
Epoch [166/300] Validation [8/16] Loss: 0.37838  focal_loss 0.07611  dice_loss 0.30228 
Epoch [166/300] Validation [9/16] Loss: 0.21388  focal_loss 0.07115  dice_loss 0.14273 
Epoch [166/300] Validation [10/16] Loss: 0.38687  focal_loss 0.15609  dice_loss 0.23078 
Epoch [166/300] Validation [11/16] Loss: 0.14966  focal_loss 0.03291  dice_loss 0.11675 
Epoch [166/300] Validation [12/16] Loss: 0.34474  focal_loss 0.08897  dice_loss 0.25577 
Epoch [166/300] Validation [13/16] Loss: 0.23902  focal_loss 0.07329  dice_loss 0.16573 
Epoch [166/300] Validation [14/16] Loss: 0.66375  focal_loss 0.30282  dice_loss 0.36094 
Epoch [166/300] Validation [15/16] Loss: 0.16247  focal_loss 0.04106  dice_loss 0.12141 
Epoch [166/300] Validation [16/16] Loss: 0.07437  focal_loss 0.01466  dice_loss 0.05970 
Epoch [166/300] Validation metric {'Val/mean dice_metric': 0.9094531536102295, 'Val/mean miou_metric': 0.854601263999939, 'Val/mean f1': 0.9152743220329285, 'Val/mean precision': 0.8950347304344177, 'Val/mean recall': 0.9364505410194397, 'Val/mean hd95_metric': 18.32562255859375}
Cheakpoint...
Epoch [166/300] best acc:tensor([0.9132], device='cuda:0'), Now : mean acc: tensor([0.9095], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9094531536102295, 'Val/mean miou_metric': 0.854601263999939, 'Val/mean f1': 0.9152743220329285, 'Val/mean precision': 0.8950347304344177, 'Val/mean recall': 0.9364505410194397, 'Val/mean hd95_metric': 18.32562255859375}
Epoch [167/300] Training [1/62] Loss: 0.15935 
Epoch [167/300] Training [2/62] Loss: 0.06731 
Epoch [167/300] Training [3/62] Loss: 0.07710 
Epoch [167/300] Training [4/62] Loss: 0.14005 
Epoch [167/300] Training [5/62] Loss: 0.10093 
Epoch [167/300] Training [6/62] Loss: 0.15056 
Epoch [167/300] Training [7/62] Loss: 0.11898 
Epoch [167/300] Training [8/62] Loss: 0.06039 
Epoch [167/300] Training [9/62] Loss: 0.05153 
Epoch [167/300] Training [10/62] Loss: 0.06967 
Epoch [167/300] Training [11/62] Loss: 0.08637 
Epoch [167/300] Training [12/62] Loss: 0.05859 
Epoch [167/300] Training [13/62] Loss: 0.10399 
Epoch [167/300] Training [14/62] Loss: 0.08599 
Epoch [167/300] Training [15/62] Loss: 0.05397 
Epoch [167/300] Training [16/62] Loss: 0.10913 
Epoch [167/300] Training [17/62] Loss: 0.06114 
Epoch [167/300] Training [18/62] Loss: 0.09414 
Epoch [167/300] Training [19/62] Loss: 0.09097 
Epoch [167/300] Training [20/62] Loss: 0.07255 
Epoch [167/300] Training [21/62] Loss: 0.06549 
Epoch [167/300] Training [22/62] Loss: 0.08047 
Epoch [167/300] Training [23/62] Loss: 0.06437 
Epoch [167/300] Training [24/62] Loss: 0.08976 
Epoch [167/300] Training [25/62] Loss: 0.07649 
Epoch [167/300] Training [26/62] Loss: 0.07123 
Epoch [167/300] Training [27/62] Loss: 0.11936 
Epoch [167/300] Training [28/62] Loss: 0.08639 
Epoch [167/300] Training [29/62] Loss: 0.07161 
Epoch [167/300] Training [30/62] Loss: 0.06218 
Epoch [167/300] Training [31/62] Loss: 0.05566 
Epoch [167/300] Training [32/62] Loss: 0.06966 
Epoch [167/300] Training [33/62] Loss: 0.07685 
Epoch [167/300] Training [34/62] Loss: 0.10887 
Epoch [167/300] Training [35/62] Loss: 0.07477 
Epoch [167/300] Training [36/62] Loss: 0.12119 
Epoch [167/300] Training [37/62] Loss: 0.07923 
Epoch [167/300] Training [38/62] Loss: 0.11898 
Epoch [167/300] Training [39/62] Loss: 0.06844 
Epoch [167/300] Training [40/62] Loss: 0.06309 
Epoch [167/300] Training [41/62] Loss: 0.09676 
Epoch [167/300] Training [42/62] Loss: 0.06812 
Epoch [167/300] Training [43/62] Loss: 0.10584 
Epoch [167/300] Training [44/62] Loss: 0.06687 
Epoch [167/300] Training [45/62] Loss: 0.09746 
Epoch [167/300] Training [46/62] Loss: 0.06466 
Epoch [167/300] Training [47/62] Loss: 0.06117 
Epoch [167/300] Training [48/62] Loss: 0.06333 
Epoch [167/300] Training [49/62] Loss: 0.11050 
Epoch [167/300] Training [50/62] Loss: 0.19707 
Epoch [167/300] Training [51/62] Loss: 0.09753 
Epoch [167/300] Training [52/62] Loss: 0.06095 
Epoch [167/300] Training [53/62] Loss: 0.05274 
Epoch [167/300] Training [54/62] Loss: 0.15560 
Epoch [167/300] Training [55/62] Loss: 0.10388 
Epoch [167/300] Training [56/62] Loss: 0.20650 
Epoch [167/300] Training [57/62] Loss: 0.10368 
Epoch [167/300] Training [58/62] Loss: 0.07276 
Epoch [167/300] Training [59/62] Loss: 0.11317 
Epoch [167/300] Training [60/62] Loss: 0.07803 
Epoch [167/300] Training [61/62] Loss: 0.08119 
Epoch [167/300] Training [62/62] Loss: 0.05395 
Epoch [167/300] Training metric {'Train/mean dice_metric': 0.9372361898422241, 'Train/mean miou_metric': 0.8891083598136902, 'Train/mean f1': 0.9466208815574646, 'Train/mean precision': 0.943081259727478, 'Train/mean recall': 0.9501871466636658, 'Train/mean hd95_metric': 10.76887321472168}
Epoch [167/300] Validation [1/16] Loss: 0.11800  focal_loss 0.04425  dice_loss 0.07375 
Epoch [167/300] Validation [2/16] Loss: 0.22349  focal_loss 0.09625  dice_loss 0.12724 
Epoch [167/300] Validation [3/16] Loss: 0.23875  focal_loss 0.06315  dice_loss 0.17560 
Epoch [167/300] Validation [4/16] Loss: 0.29697  focal_loss 0.10203  dice_loss 0.19494 
Epoch [167/300] Validation [5/16] Loss: 0.23459  focal_loss 0.04287  dice_loss 0.19171 
Epoch [167/300] Validation [6/16] Loss: 0.21556  focal_loss 0.05236  dice_loss 0.16319 
Epoch [167/300] Validation [7/16] Loss: 0.21032  focal_loss 0.07667  dice_loss 0.13365 
Epoch [167/300] Validation [8/16] Loss: 0.47837  focal_loss 0.17616  dice_loss 0.30221 
Epoch [167/300] Validation [9/16] Loss: 0.31187  focal_loss 0.13656  dice_loss 0.17531 
Epoch [167/300] Validation [10/16] Loss: 0.13848  focal_loss 0.03422  dice_loss 0.10427 
Epoch [167/300] Validation [11/16] Loss: 0.25171  focal_loss 0.06980  dice_loss 0.18191 
Epoch [167/300] Validation [12/16] Loss: 0.30453  focal_loss 0.07695  dice_loss 0.22758 
Epoch [167/300] Validation [13/16] Loss: 0.28454  focal_loss 0.07796  dice_loss 0.20658 
Epoch [167/300] Validation [14/16] Loss: 0.56862  focal_loss 0.22007  dice_loss 0.34855 
Epoch [167/300] Validation [15/16] Loss: 0.13778  focal_loss 0.03516  dice_loss 0.10261 
Epoch [167/300] Validation [16/16] Loss: 0.04113  focal_loss 0.00778  dice_loss 0.03335 
Epoch [167/300] Validation metric {'Val/mean dice_metric': 0.9162607789039612, 'Val/mean miou_metric': 0.8623138666152954, 'Val/mean f1': 0.9227941036224365, 'Val/mean precision': 0.9077885150909424, 'Val/mean recall': 0.9383041858673096, 'Val/mean hd95_metric': 16.34939193725586}
Cheakpoint...
Epoch [167/300] best acc:tensor([0.9163], device='cuda:0'), Now : mean acc: tensor([0.9163], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9162607789039612, 'Val/mean miou_metric': 0.8623138666152954, 'Val/mean f1': 0.9227941036224365, 'Val/mean precision': 0.9077885150909424, 'Val/mean recall': 0.9383041858673096, 'Val/mean hd95_metric': 16.34939193725586}
Epoch [168/300] Training [1/62] Loss: 0.06450 
Epoch [168/300] Training [2/62] Loss: 0.12146 
Epoch [168/300] Training [3/62] Loss: 0.06079 
Epoch [168/300] Training [4/62] Loss: 0.06492 
Epoch [168/300] Training [5/62] Loss: 0.09814 
Epoch [168/300] Training [6/62] Loss: 0.14587 
Epoch [168/300] Training [7/62] Loss: 0.08609 
Epoch [168/300] Training [8/62] Loss: 0.23658 
Epoch [168/300] Training [9/62] Loss: 0.05539 
Epoch [168/300] Training [10/62] Loss: 0.06630 
Epoch [168/300] Training [11/62] Loss: 0.11677 
Epoch [168/300] Training [12/62] Loss: 0.11551 
Epoch [168/300] Training [13/62] Loss: 0.05467 
Epoch [168/300] Training [14/62] Loss: 0.05772 
Epoch [168/300] Training [15/62] Loss: 0.10151 
Epoch [168/300] Training [16/62] Loss: 0.06178 
Epoch [168/300] Training [17/62] Loss: 0.17268 
Epoch [168/300] Training [18/62] Loss: 0.07328 
Epoch [168/300] Training [19/62] Loss: 0.25366 
Epoch [168/300] Training [20/62] Loss: 0.07217 
Epoch [168/300] Training [21/62] Loss: 0.08723 
Epoch [168/300] Training [22/62] Loss: 0.11790 
Epoch [168/300] Training [23/62] Loss: 0.09553 
Epoch [168/300] Training [24/62] Loss: 0.15537 
Epoch [168/300] Training [25/62] Loss: 0.07215 
Epoch [168/300] Training [26/62] Loss: 0.06867 
Epoch [168/300] Training [27/62] Loss: 0.13137 
Epoch [168/300] Training [28/62] Loss: 0.07851 
Epoch [168/300] Training [29/62] Loss: 0.07886 
Epoch [168/300] Training [30/62] Loss: 0.06314 
Epoch [168/300] Training [31/62] Loss: 0.06343 
Epoch [168/300] Training [32/62] Loss: 0.07493 
Epoch [168/300] Training [33/62] Loss: 0.05999 
Epoch [168/300] Training [34/62] Loss: 0.05748 
Epoch [168/300] Training [35/62] Loss: 0.06285 
Epoch [168/300] Training [36/62] Loss: 0.11046 
Epoch [168/300] Training [37/62] Loss: 0.12958 
Epoch [168/300] Training [38/62] Loss: 0.14082 
Epoch [168/300] Training [39/62] Loss: 0.07047 
Epoch [168/300] Training [40/62] Loss: 0.07665 
Epoch [168/300] Training [41/62] Loss: 0.10564 
Epoch [168/300] Training [42/62] Loss: 0.08889 
Epoch [168/300] Training [43/62] Loss: 0.09432 
Epoch [168/300] Training [44/62] Loss: 0.10263 
Epoch [168/300] Training [45/62] Loss: 0.11753 
Epoch [168/300] Training [46/62] Loss: 0.06274 
Epoch [168/300] Training [47/62] Loss: 0.16269 
Epoch [168/300] Training [48/62] Loss: 0.06727 
Epoch [168/300] Training [49/62] Loss: 0.06318 
Epoch [168/300] Training [50/62] Loss: 0.06407 
Epoch [168/300] Training [51/62] Loss: 0.07664 
Epoch [168/300] Training [52/62] Loss: 0.06479 
Epoch [168/300] Training [53/62] Loss: 0.04594 
Epoch [168/300] Training [54/62] Loss: 0.10435 
Epoch [168/300] Training [55/62] Loss: 0.07621 
Epoch [168/300] Training [56/62] Loss: 0.09602 
Epoch [168/300] Training [57/62] Loss: 0.10578 
Epoch [168/300] Training [58/62] Loss: 0.06876 
Epoch [168/300] Training [59/62] Loss: 0.07506 
Epoch [168/300] Training [60/62] Loss: 0.08084 
Epoch [168/300] Training [61/62] Loss: 0.07761 
Epoch [168/300] Training [62/62] Loss: 0.16271 
Epoch [168/300] Training metric {'Train/mean dice_metric': 0.9344858527183533, 'Train/mean miou_metric': 0.8852853178977966, 'Train/mean f1': 0.9439340829849243, 'Train/mean precision': 0.9362837672233582, 'Train/mean recall': 0.9517104625701904, 'Train/mean hd95_metric': 11.099172592163086}
Epoch [168/300] Validation [1/16] Loss: 0.21255  focal_loss 0.09195  dice_loss 0.12060 
Epoch [168/300] Validation [2/16] Loss: 0.38609  focal_loss 0.17333  dice_loss 0.21275 
Epoch [168/300] Validation [3/16] Loss: 0.31404  focal_loss 0.06228  dice_loss 0.25177 
Epoch [168/300] Validation [4/16] Loss: 0.32395  focal_loss 0.13495  dice_loss 0.18899 
Epoch [168/300] Validation [5/16] Loss: 0.36535  focal_loss 0.13827  dice_loss 0.22708 
Epoch [168/300] Validation [6/16] Loss: 0.21060  focal_loss 0.03286  dice_loss 0.17774 
Epoch [168/300] Validation [7/16] Loss: 0.31084  focal_loss 0.13260  dice_loss 0.17824 
Epoch [168/300] Validation [8/16] Loss: 0.47266  focal_loss 0.17377  dice_loss 0.29888 
Epoch [168/300] Validation [9/16] Loss: 0.13205  focal_loss 0.03689  dice_loss 0.09516 
Epoch [168/300] Validation [10/16] Loss: 0.25935  focal_loss 0.08925  dice_loss 0.17010 
Epoch [168/300] Validation [11/16] Loss: 0.13077  focal_loss 0.03542  dice_loss 0.09535 
Epoch [168/300] Validation [12/16] Loss: 0.30335  focal_loss 0.07075  dice_loss 0.23259 
Epoch [168/300] Validation [13/16] Loss: 0.17556  focal_loss 0.03911  dice_loss 0.13645 
Epoch [168/300] Validation [14/16] Loss: 0.53065  focal_loss 0.17533  dice_loss 0.35533 
Epoch [168/300] Validation [15/16] Loss: 0.16416  focal_loss 0.04938  dice_loss 0.11478 
Epoch [168/300] Validation [16/16] Loss: 0.04388  focal_loss 0.00766  dice_loss 0.03622 
Epoch [168/300] Validation metric {'Val/mean dice_metric': 0.9114726781845093, 'Val/mean miou_metric': 0.855806827545166, 'Val/mean f1': 0.9231598973274231, 'Val/mean precision': 0.9230384230613708, 'Val/mean recall': 0.9232814311981201, 'Val/mean hd95_metric': 16.93433380126953}
Cheakpoint...
Epoch [168/300] best acc:tensor([0.9163], device='cuda:0'), Now : mean acc: tensor([0.9115], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9114726781845093, 'Val/mean miou_metric': 0.855806827545166, 'Val/mean f1': 0.9231598973274231, 'Val/mean precision': 0.9230384230613708, 'Val/mean recall': 0.9232814311981201, 'Val/mean hd95_metric': 16.93433380126953}
Epoch [169/300] Training [1/62] Loss: 0.06244 
Epoch [169/300] Training [2/62] Loss: 0.07809 
Epoch [169/300] Training [3/62] Loss: 0.09126 
Epoch [169/300] Training [4/62] Loss: 0.19213 
Epoch [169/300] Training [5/62] Loss: 0.10137 
Epoch [169/300] Training [6/62] Loss: 0.09393 
Epoch [169/300] Training [7/62] Loss: 0.06212 
Epoch [169/300] Training [8/62] Loss: 0.08959 
Epoch [169/300] Training [9/62] Loss: 0.13789 
Epoch [169/300] Training [10/62] Loss: 0.21881 
Epoch [169/300] Training [11/62] Loss: 0.16342 
Epoch [169/300] Training [12/62] Loss: 0.07503 
Epoch [169/300] Training [13/62] Loss: 0.07687 
Epoch [169/300] Training [14/62] Loss: 0.17534 
Epoch [169/300] Training [15/62] Loss: 0.11258 
Epoch [169/300] Training [16/62] Loss: 0.06761 
Epoch [169/300] Training [17/62] Loss: 0.07386 
Epoch [169/300] Training [18/62] Loss: 0.09451 
Epoch [169/300] Training [19/62] Loss: 0.05658 
Epoch [169/300] Training [20/62] Loss: 0.11188 
Epoch [169/300] Training [21/62] Loss: 0.06381 
Epoch [169/300] Training [22/62] Loss: 0.06240 
Epoch [169/300] Training [23/62] Loss: 0.12380 
Epoch [169/300] Training [24/62] Loss: 0.09330 
Epoch [169/300] Training [25/62] Loss: 0.15338 
Epoch [169/300] Training [26/62] Loss: 0.07453 
Epoch [169/300] Training [27/62] Loss: 0.10794 
Epoch [169/300] Training [28/62] Loss: 0.10468 
Epoch [169/300] Training [29/62] Loss: 0.05930 
Epoch [169/300] Training [30/62] Loss: 0.06211 
Epoch [169/300] Training [31/62] Loss: 0.05788 
Epoch [169/300] Training [32/62] Loss: 0.09230 
Epoch [169/300] Training [33/62] Loss: 0.07415 
Epoch [169/300] Training [34/62] Loss: 0.07630 
Epoch [169/300] Training [35/62] Loss: 0.07824 
Epoch [169/300] Training [36/62] Loss: 0.07201 
Epoch [169/300] Training [37/62] Loss: 0.12149 
Epoch [169/300] Training [38/62] Loss: 0.05308 
Epoch [169/300] Training [39/62] Loss: 0.17239 
Epoch [169/300] Training [40/62] Loss: 0.11373 
Epoch [169/300] Training [41/62] Loss: 0.05841 
Epoch [169/300] Training [42/62] Loss: 0.07113 
Epoch [169/300] Training [43/62] Loss: 0.08932 
Epoch [169/300] Training [44/62] Loss: 0.11543 
Epoch [169/300] Training [45/62] Loss: 0.09396 
Epoch [169/300] Training [46/62] Loss: 0.05444 
Epoch [169/300] Training [47/62] Loss: 0.05028 
Epoch [169/300] Training [48/62] Loss: 0.04862 
Epoch [169/300] Training [49/62] Loss: 0.07933 
Epoch [169/300] Training [50/62] Loss: 0.06706 
Epoch [169/300] Training [51/62] Loss: 0.05385 
Epoch [169/300] Training [52/62] Loss: 0.06608 
Epoch [169/300] Training [53/62] Loss: 0.11354 
Epoch [169/300] Training [54/62] Loss: 0.09582 
Epoch [169/300] Training [55/62] Loss: 0.06823 
Epoch [169/300] Training [56/62] Loss: 0.04954 
Epoch [169/300] Training [57/62] Loss: 0.08361 
Epoch [169/300] Training [58/62] Loss: 0.06483 
Epoch [169/300] Training [59/62] Loss: 0.05647 
Epoch [169/300] Training [60/62] Loss: 0.05929 
Epoch [169/300] Training [61/62] Loss: 0.10436 
Epoch [169/300] Training [62/62] Loss: 0.09454 
Epoch [169/300] Training metric {'Train/mean dice_metric': 0.9361585378646851, 'Train/mean miou_metric': 0.8882393836975098, 'Train/mean f1': 0.9476615786552429, 'Train/mean precision': 0.9423258900642395, 'Train/mean recall': 0.9530580043792725, 'Train/mean hd95_metric': 10.81137752532959}
Epoch [169/300] Validation [1/16] Loss: 0.34405  focal_loss 0.20120  dice_loss 0.14285 
Epoch [169/300] Validation [2/16] Loss: 0.34675  focal_loss 0.11396  dice_loss 0.23278 
Epoch [169/300] Validation [3/16] Loss: 0.33470  focal_loss 0.12772  dice_loss 0.20697 
Epoch [169/300] Validation [4/16] Loss: 0.26098  focal_loss 0.12685  dice_loss 0.13413 
Epoch [169/300] Validation [5/16] Loss: 0.28445  focal_loss 0.08063  dice_loss 0.20382 
Epoch [169/300] Validation [6/16] Loss: 0.19087  focal_loss 0.03831  dice_loss 0.15256 
Epoch [169/300] Validation [7/16] Loss: 0.38276  focal_loss 0.15772  dice_loss 0.22505 
Epoch [169/300] Validation [8/16] Loss: 0.52214  focal_loss 0.20846  dice_loss 0.31369 
Epoch [169/300] Validation [9/16] Loss: 0.13608  focal_loss 0.04392  dice_loss 0.09216 
Epoch [169/300] Validation [10/16] Loss: 0.42173  focal_loss 0.15185  dice_loss 0.26989 
Epoch [169/300] Validation [11/16] Loss: 0.13582  focal_loss 0.03657  dice_loss 0.09925 
Epoch [169/300] Validation [12/16] Loss: 0.32733  focal_loss 0.08456  dice_loss 0.24277 
Epoch [169/300] Validation [13/16] Loss: 0.17542  focal_loss 0.04463  dice_loss 0.13079 
Epoch [169/300] Validation [14/16] Loss: 0.53326  focal_loss 0.21662  dice_loss 0.31664 
Epoch [169/300] Validation [15/16] Loss: 0.14010  focal_loss 0.04504  dice_loss 0.09506 
Epoch [169/300] Validation [16/16] Loss: 0.03766  focal_loss 0.00783  dice_loss 0.02983 
Epoch [169/300] Validation metric {'Val/mean dice_metric': 0.9125990271568298, 'Val/mean miou_metric': 0.8584964871406555, 'Val/mean f1': 0.9252579212188721, 'Val/mean precision': 0.9246957898139954, 'Val/mean recall': 0.9258207678794861, 'Val/mean hd95_metric': 16.4231014251709}
Cheakpoint...
Epoch [169/300] best acc:tensor([0.9163], device='cuda:0'), Now : mean acc: tensor([0.9126], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9125990271568298, 'Val/mean miou_metric': 0.8584964871406555, 'Val/mean f1': 0.9252579212188721, 'Val/mean precision': 0.9246957898139954, 'Val/mean recall': 0.9258207678794861, 'Val/mean hd95_metric': 16.4231014251709}
Epoch [170/300] Training [1/62] Loss: 0.07805 
Epoch [170/300] Training [2/62] Loss: 0.08671 
Epoch [170/300] Training [3/62] Loss: 0.08409 
Epoch [170/300] Training [4/62] Loss: 0.08927 
Epoch [170/300] Training [5/62] Loss: 0.11736 
Epoch [170/300] Training [6/62] Loss: 0.09752 
Epoch [170/300] Training [7/62] Loss: 0.08696 
Epoch [170/300] Training [8/62] Loss: 0.08115 
Epoch [170/300] Training [9/62] Loss: 0.08438 
Epoch [170/300] Training [10/62] Loss: 0.19208 
Epoch [170/300] Training [11/62] Loss: 0.06586 
Epoch [170/300] Training [12/62] Loss: 0.09919 
Epoch [170/300] Training [13/62] Loss: 0.07553 
Epoch [170/300] Training [14/62] Loss: 0.07666 
Epoch [170/300] Training [15/62] Loss: 0.07293 
Epoch [170/300] Training [16/62] Loss: 0.07247 
Epoch [170/300] Training [17/62] Loss: 0.06454 
Epoch [170/300] Training [18/62] Loss: 0.08778 
Epoch [170/300] Training [19/62] Loss: 0.06098 
Epoch [170/300] Training [20/62] Loss: 0.19201 
Epoch [170/300] Training [21/62] Loss: 0.16205 
Epoch [170/300] Training [22/62] Loss: 0.06152 
Epoch [170/300] Training [23/62] Loss: 0.11398 
Epoch [170/300] Training [24/62] Loss: 0.05736 
Epoch [170/300] Training [25/62] Loss: 0.07082 
Epoch [170/300] Training [26/62] Loss: 0.08662 
Epoch [170/300] Training [27/62] Loss: 0.07932 
Epoch [170/300] Training [28/62] Loss: 0.06560 
Epoch [170/300] Training [29/62] Loss: 0.06469 
Epoch [170/300] Training [30/62] Loss: 0.09750 
Epoch [170/300] Training [31/62] Loss: 0.17038 
Epoch [170/300] Training [32/62] Loss: 0.06546 
Epoch [170/300] Training [33/62] Loss: 0.11005 
Epoch [170/300] Training [34/62] Loss: 0.11282 
Epoch [170/300] Training [35/62] Loss: 0.07674 
Epoch [170/300] Training [36/62] Loss: 0.06154 
Epoch [170/300] Training [37/62] Loss: 0.06917 
Epoch [170/300] Training [38/62] Loss: 0.07622 
Epoch [170/300] Training [39/62] Loss: 0.10405 
Epoch [170/300] Training [40/62] Loss: 0.06271 
Epoch [170/300] Training [41/62] Loss: 0.09829 
Epoch [170/300] Training [42/62] Loss: 0.09244 
Epoch [170/300] Training [43/62] Loss: 0.09545 
Epoch [170/300] Training [44/62] Loss: 0.07261 
Epoch [170/300] Training [45/62] Loss: 0.07413 
Epoch [170/300] Training [46/62] Loss: 0.10769 
Epoch [170/300] Training [47/62] Loss: 0.12243 
Epoch [170/300] Training [48/62] Loss: 0.09104 
Epoch [170/300] Training [49/62] Loss: 0.04950 
Epoch [170/300] Training [50/62] Loss: 0.07749 
Epoch [170/300] Training [51/62] Loss: 0.12020 
Epoch [170/300] Training [52/62] Loss: 0.14264 
Epoch [170/300] Training [53/62] Loss: 0.05899 
Epoch [170/300] Training [54/62] Loss: 0.09812 
Epoch [170/300] Training [55/62] Loss: 0.05705 
Epoch [170/300] Training [56/62] Loss: 0.05415 
Epoch [170/300] Training [57/62] Loss: 0.05977 
Epoch [170/300] Training [58/62] Loss: 0.16760 
Epoch [170/300] Training [59/62] Loss: 0.05646 
Epoch [170/300] Training [60/62] Loss: 0.15167 
Epoch [170/300] Training [61/62] Loss: 0.09052 
Epoch [170/300] Training [62/62] Loss: 0.29566 
Epoch [170/300] Training metric {'Train/mean dice_metric': 0.9360775351524353, 'Train/mean miou_metric': 0.8868741393089294, 'Train/mean f1': 0.9455184936523438, 'Train/mean precision': 0.9418078064918518, 'Train/mean recall': 0.9492585062980652, 'Train/mean hd95_metric': 11.95374870300293}
Epoch [170/300] Validation [1/16] Loss: 0.31849  focal_loss 0.16905  dice_loss 0.14944 
Epoch [170/300] Validation [2/16] Loss: 0.29531  focal_loss 0.11297  dice_loss 0.18234 
Epoch [170/300] Validation [3/16] Loss: 0.38256  focal_loss 0.13832  dice_loss 0.24424 
Epoch [170/300] Validation [4/16] Loss: 0.29227  focal_loss 0.10973  dice_loss 0.18254 
Epoch [170/300] Validation [5/16] Loss: 0.30509  focal_loss 0.08260  dice_loss 0.22249 
Epoch [170/300] Validation [6/16] Loss: 0.21497  focal_loss 0.04271  dice_loss 0.17226 
Epoch [170/300] Validation [7/16] Loss: 0.26418  focal_loss 0.10527  dice_loss 0.15891 
Epoch [170/300] Validation [8/16] Loss: 0.39516  focal_loss 0.12969  dice_loss 0.26547 
Epoch [170/300] Validation [9/16] Loss: 0.17723  focal_loss 0.05478  dice_loss 0.12245 
Epoch [170/300] Validation [10/16] Loss: 0.40125  focal_loss 0.13343  dice_loss 0.26782 
Epoch [170/300] Validation [11/16] Loss: 0.14730  focal_loss 0.04654  dice_loss 0.10075 
Epoch [170/300] Validation [12/16] Loss: 0.31261  focal_loss 0.08965  dice_loss 0.22297 
Epoch [170/300] Validation [13/16] Loss: 0.24041  focal_loss 0.08182  dice_loss 0.15859 
Epoch [170/300] Validation [14/16] Loss: 0.45154  focal_loss 0.18559  dice_loss 0.26596 
Epoch [170/300] Validation [15/16] Loss: 0.13992  focal_loss 0.03966  dice_loss 0.10026 
Epoch [170/300] Validation [16/16] Loss: 0.05138  focal_loss 0.01283  dice_loss 0.03855 
Epoch [170/300] Validation metric {'Val/mean dice_metric': 0.9129317402839661, 'Val/mean miou_metric': 0.8572196960449219, 'Val/mean f1': 0.9214462041854858, 'Val/mean precision': 0.9222294092178345, 'Val/mean recall': 0.9206643104553223, 'Val/mean hd95_metric': 17.327795028686523}
Cheakpoint...
Epoch [170/300] best acc:tensor([0.9163], device='cuda:0'), Now : mean acc: tensor([0.9129], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9129317402839661, 'Val/mean miou_metric': 0.8572196960449219, 'Val/mean f1': 0.9214462041854858, 'Val/mean precision': 0.9222294092178345, 'Val/mean recall': 0.9206643104553223, 'Val/mean hd95_metric': 17.327795028686523}
Epoch [171/300] Training [1/62] Loss: 0.10976 
Epoch [171/300] Training [2/62] Loss: 0.10101 
Epoch [171/300] Training [3/62] Loss: 0.07793 
Epoch [171/300] Training [4/62] Loss: 0.07774 
Epoch [171/300] Training [5/62] Loss: 0.06146 
Epoch [171/300] Training [6/62] Loss: 0.19286 
Epoch [171/300] Training [7/62] Loss: 0.16696 
Epoch [171/300] Training [8/62] Loss: 0.13075 
Epoch [171/300] Training [9/62] Loss: 0.09610 
Epoch [171/300] Training [10/62] Loss: 0.16394 
Epoch [171/300] Training [11/62] Loss: 0.09722 
Epoch [171/300] Training [12/62] Loss: 0.07558 
Epoch [171/300] Training [13/62] Loss: 0.14938 
Epoch [171/300] Training [14/62] Loss: 0.06208 
Epoch [171/300] Training [15/62] Loss: 0.16132 
Epoch [171/300] Training [16/62] Loss: 0.06026 
Epoch [171/300] Training [17/62] Loss: 0.07084 
Epoch [171/300] Training [18/62] Loss: 0.10887 
Epoch [171/300] Training [19/62] Loss: 0.07768 
Epoch [171/300] Training [20/62] Loss: 0.09016 
Epoch [171/300] Training [21/62] Loss: 0.08136 
Epoch [171/300] Training [22/62] Loss: 0.11608 
Epoch [171/300] Training [23/62] Loss: 0.07816 
Epoch [171/300] Training [24/62] Loss: 0.08018 
Epoch [171/300] Training [25/62] Loss: 0.10194 
Epoch [171/300] Training [26/62] Loss: 0.09146 
Epoch [171/300] Training [27/62] Loss: 0.05586 
Epoch [171/300] Training [28/62] Loss: 0.06400 
Epoch [171/300] Training [29/62] Loss: 0.05996 
Epoch [171/300] Training [30/62] Loss: 0.11070 
Epoch [171/300] Training [31/62] Loss: 0.11093 
Epoch [171/300] Training [32/62] Loss: 0.18603 
Epoch [171/300] Training [33/62] Loss: 0.06072 
Epoch [171/300] Training [34/62] Loss: 0.06315 
Epoch [171/300] Training [35/62] Loss: 0.07062 
Epoch [171/300] Training [36/62] Loss: 0.09364 
Epoch [171/300] Training [37/62] Loss: 0.06225 
Epoch [171/300] Training [38/62] Loss: 0.07026 
Epoch [171/300] Training [39/62] Loss: 0.06297 
Epoch [171/300] Training [40/62] Loss: 0.08932 
Epoch [171/300] Training [41/62] Loss: 0.07042 
Epoch [171/300] Training [42/62] Loss: 0.09831 
Epoch [171/300] Training [43/62] Loss: 0.06007 
Epoch [171/300] Training [44/62] Loss: 0.08275 
Epoch [171/300] Training [45/62] Loss: 0.05392 
Epoch [171/300] Training [46/62] Loss: 0.05267 
Epoch [171/300] Training [47/62] Loss: 0.05099 
Epoch [171/300] Training [48/62] Loss: 0.09413 
Epoch [171/300] Training [49/62] Loss: 0.05069 
Epoch [171/300] Training [50/62] Loss: 0.06444 
Epoch [171/300] Training [51/62] Loss: 0.07587 
Epoch [171/300] Training [52/62] Loss: 0.08338 
Epoch [171/300] Training [53/62] Loss: 0.11238 
Epoch [171/300] Training [54/62] Loss: 0.06596 
Epoch [171/300] Training [55/62] Loss: 0.05337 
Epoch [171/300] Training [56/62] Loss: 0.04647 
Epoch [171/300] Training [57/62] Loss: 0.13731 
Epoch [171/300] Training [58/62] Loss: 0.05708 
Epoch [171/300] Training [59/62] Loss: 0.06979 
Epoch [171/300] Training [60/62] Loss: 0.09620 
Epoch [171/300] Training [61/62] Loss: 0.08638 
Epoch [171/300] Training [62/62] Loss: 0.04366 
Epoch [171/300] Training metric {'Train/mean dice_metric': 0.9385930299758911, 'Train/mean miou_metric': 0.8903252482414246, 'Train/mean f1': 0.9460281729698181, 'Train/mean precision': 0.9391077160835266, 'Train/mean recall': 0.9530512690544128, 'Train/mean hd95_metric': 10.762346267700195}
Epoch [171/300] Validation [1/16] Loss: 0.34128  focal_loss 0.17057  dice_loss 0.17071 
Epoch [171/300] Validation [2/16] Loss: 0.34640  focal_loss 0.11849  dice_loss 0.22791 
Epoch [171/300] Validation [3/16] Loss: 0.75269  focal_loss 0.42501  dice_loss 0.32769 
Epoch [171/300] Validation [4/16] Loss: 0.30900  focal_loss 0.13174  dice_loss 0.17726 
Epoch [171/300] Validation [5/16] Loss: 0.38623  focal_loss 0.13526  dice_loss 0.25097 
Epoch [171/300] Validation [6/16] Loss: 0.22837  focal_loss 0.05433  dice_loss 0.17404 
Epoch [171/300] Validation [7/16] Loss: 0.20440  focal_loss 0.06616  dice_loss 0.13824 
Epoch [171/300] Validation [8/16] Loss: 0.38237  focal_loss 0.11685  dice_loss 0.26552 
Epoch [171/300] Validation [9/16] Loss: 0.13836  focal_loss 0.04942  dice_loss 0.08894 
Epoch [171/300] Validation [10/16] Loss: 0.25706  focal_loss 0.07875  dice_loss 0.17832 
Epoch [171/300] Validation [11/16] Loss: 0.11490  focal_loss 0.03407  dice_loss 0.08082 
Epoch [171/300] Validation [12/16] Loss: 0.34515  focal_loss 0.10753  dice_loss 0.23762 
Epoch [171/300] Validation [13/16] Loss: 0.27404  focal_loss 0.08928  dice_loss 0.18476 
Epoch [171/300] Validation [14/16] Loss: 0.45518  focal_loss 0.17808  dice_loss 0.27709 
Epoch [171/300] Validation [15/16] Loss: 0.12555  focal_loss 0.03774  dice_loss 0.08781 
Epoch [171/300] Validation [16/16] Loss: 0.04555  focal_loss 0.00986  dice_loss 0.03569 
Epoch [171/300] Validation metric {'Val/mean dice_metric': 0.9142867922782898, 'Val/mean miou_metric': 0.8598847985267639, 'Val/mean f1': 0.9201995134353638, 'Val/mean precision': 0.9155518412590027, 'Val/mean recall': 0.9248946309089661, 'Val/mean hd95_metric': 15.817482948303223}
Cheakpoint...
Epoch [171/300] best acc:tensor([0.9163], device='cuda:0'), Now : mean acc: tensor([0.9143], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9142867922782898, 'Val/mean miou_metric': 0.8598847985267639, 'Val/mean f1': 0.9201995134353638, 'Val/mean precision': 0.9155518412590027, 'Val/mean recall': 0.9248946309089661, 'Val/mean hd95_metric': 15.817482948303223}
Epoch [172/300] Training [1/62] Loss: 0.05884 
Epoch [172/300] Training [2/62] Loss: 0.12550 
Epoch [172/300] Training [3/62] Loss: 0.08355 
Epoch [172/300] Training [4/62] Loss: 0.05292 
Epoch [172/300] Training [5/62] Loss: 0.12265 
Epoch [172/300] Training [6/62] Loss: 0.07133 
Epoch [172/300] Training [7/62] Loss: 0.05439 
Epoch [172/300] Training [8/62] Loss: 0.06730 
Epoch [172/300] Training [9/62] Loss: 0.15445 
Epoch [172/300] Training [10/62] Loss: 0.17624 
Epoch [172/300] Training [11/62] Loss: 0.12857 
Epoch [172/300] Training [12/62] Loss: 0.06756 
Epoch [172/300] Training [13/62] Loss: 0.09210 
Epoch [172/300] Training [14/62] Loss: 0.07061 
Epoch [172/300] Training [15/62] Loss: 0.05484 
Epoch [172/300] Training [16/62] Loss: 0.15722 
Epoch [172/300] Training [17/62] Loss: 0.09188 
Epoch [172/300] Training [18/62] Loss: 0.05884 
Epoch [172/300] Training [19/62] Loss: 0.13626 
Epoch [172/300] Training [20/62] Loss: 0.10427 
Epoch [172/300] Training [21/62] Loss: 0.04978 
Epoch [172/300] Training [22/62] Loss: 0.10393 
Epoch [172/300] Training [23/62] Loss: 0.07289 
Epoch [172/300] Training [24/62] Loss: 0.15216 
Epoch [172/300] Training [25/62] Loss: 0.08239 
Epoch [172/300] Training [26/62] Loss: 0.05350 
Epoch [172/300] Training [27/62] Loss: 0.05732 
Epoch [172/300] Training [28/62] Loss: 0.05003 
Epoch [172/300] Training [29/62] Loss: 0.10646 
Epoch [172/300] Training [30/62] Loss: 0.07151 
Epoch [172/300] Training [31/62] Loss: 0.04328 
Epoch [172/300] Training [32/62] Loss: 0.05582 
Epoch [172/300] Training [33/62] Loss: 0.05117 
Epoch [172/300] Training [34/62] Loss: 0.14551 
Epoch [172/300] Training [35/62] Loss: 0.13864 
Epoch [172/300] Training [36/62] Loss: 0.15109 
Epoch [172/300] Training [37/62] Loss: 0.08013 
Epoch [172/300] Training [38/62] Loss: 0.11843 
Epoch [172/300] Training [39/62] Loss: 0.06800 
Epoch [172/300] Training [40/62] Loss: 0.16092 
Epoch [172/300] Training [41/62] Loss: 0.07328 
Epoch [172/300] Training [42/62] Loss: 0.06046 
Epoch [172/300] Training [43/62] Loss: 0.06294 
Epoch [172/300] Training [44/62] Loss: 0.06177 
Epoch [172/300] Training [45/62] Loss: 0.09477 
Epoch [172/300] Training [46/62] Loss: 0.06016 
Epoch [172/300] Training [47/62] Loss: 0.10107 
Epoch [172/300] Training [48/62] Loss: 0.27392 
Epoch [172/300] Training [49/62] Loss: 0.07055 
Epoch [172/300] Training [50/62] Loss: 0.06676 
Epoch [172/300] Training [51/62] Loss: 0.08619 
Epoch [172/300] Training [52/62] Loss: 0.10655 
Epoch [172/300] Training [53/62] Loss: 0.06246 
Epoch [172/300] Training [54/62] Loss: 0.14540 
Epoch [172/300] Training [55/62] Loss: 0.08999 
Epoch [172/300] Training [56/62] Loss: 0.08590 
Epoch [172/300] Training [57/62] Loss: 0.06433 
Epoch [172/300] Training [58/62] Loss: 0.09369 
Epoch [172/300] Training [59/62] Loss: 0.06916 
Epoch [172/300] Training [60/62] Loss: 0.07275 
Epoch [172/300] Training [61/62] Loss: 0.12997 
Epoch [172/300] Training [62/62] Loss: 0.03565 
Epoch [172/300] Training metric {'Train/mean dice_metric': 0.9342479109764099, 'Train/mean miou_metric': 0.8863211870193481, 'Train/mean f1': 0.9465537667274475, 'Train/mean precision': 0.9427672624588013, 'Train/mean recall': 0.9503706693649292, 'Train/mean hd95_metric': 11.84457778930664}
Epoch [172/300] Validation [1/16] Loss: 0.11174  focal_loss 0.03432  dice_loss 0.07741 
Epoch [172/300] Validation [2/16] Loss: 0.28944  focal_loss 0.08237  dice_loss 0.20707 
Epoch [172/300] Validation [3/16] Loss: 0.48731  focal_loss 0.24199  dice_loss 0.24532 
Epoch [172/300] Validation [4/16] Loss: 0.25893  focal_loss 0.09802  dice_loss 0.16091 
Epoch [172/300] Validation [5/16] Loss: 0.26376  focal_loss 0.06643  dice_loss 0.19733 
Epoch [172/300] Validation [6/16] Loss: 0.21653  focal_loss 0.05025  dice_loss 0.16628 
Epoch [172/300] Validation [7/16] Loss: 0.32955  focal_loss 0.13994  dice_loss 0.18961 
Epoch [172/300] Validation [8/16] Loss: 0.25724  focal_loss 0.05608  dice_loss 0.20116 
Epoch [172/300] Validation [9/16] Loss: 0.11524  focal_loss 0.03188  dice_loss 0.08336 
Epoch [172/300] Validation [10/16] Loss: 0.63309  focal_loss 0.32099  dice_loss 0.31210 
Epoch [172/300] Validation [11/16] Loss: 0.14489  focal_loss 0.03024  dice_loss 0.11465 
Epoch [172/300] Validation [12/16] Loss: 0.41732  focal_loss 0.10227  dice_loss 0.31505 
Epoch [172/300] Validation [13/16] Loss: 0.35627  focal_loss 0.11230  dice_loss 0.24397 
Epoch [172/300] Validation [14/16] Loss: 0.68165  focal_loss 0.26232  dice_loss 0.41933 
Epoch [172/300] Validation [15/16] Loss: 0.20278  focal_loss 0.05501  dice_loss 0.14776 
Epoch [172/300] Validation [16/16] Loss: 0.04846  focal_loss 0.00953  dice_loss 0.03893 
Epoch [172/300] Validation metric {'Val/mean dice_metric': 0.9091745018959045, 'Val/mean miou_metric': 0.8548130393028259, 'Val/mean f1': 0.919967770576477, 'Val/mean precision': 0.910214900970459, 'Val/mean recall': 0.9299318790435791, 'Val/mean hd95_metric': 17.883657455444336}
Cheakpoint...
Epoch [172/300] best acc:tensor([0.9163], device='cuda:0'), Now : mean acc: tensor([0.9092], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9091745018959045, 'Val/mean miou_metric': 0.8548130393028259, 'Val/mean f1': 0.919967770576477, 'Val/mean precision': 0.910214900970459, 'Val/mean recall': 0.9299318790435791, 'Val/mean hd95_metric': 17.883657455444336}
Epoch [173/300] Training [1/62] Loss: 0.07875 
Epoch [173/300] Training [2/62] Loss: 0.12508 
Epoch [173/300] Training [3/62] Loss: 0.07788 
Epoch [173/300] Training [4/62] Loss: 0.10634 
Epoch [173/300] Training [5/62] Loss: 0.09312 
Epoch [173/300] Training [6/62] Loss: 0.06014 
Epoch [173/300] Training [7/62] Loss: 0.12743 
Epoch [173/300] Training [8/62] Loss: 0.08157 
Epoch [173/300] Training [9/62] Loss: 0.07039 
Epoch [173/300] Training [10/62] Loss: 0.05458 
Epoch [173/300] Training [11/62] Loss: 0.04645 
Epoch [173/300] Training [12/62] Loss: 0.07808 
Epoch [173/300] Training [13/62] Loss: 0.08663 
Epoch [173/300] Training [14/62] Loss: 0.07892 
Epoch [173/300] Training [15/62] Loss: 0.08312 
Epoch [173/300] Training [16/62] Loss: 0.07041 
Epoch [173/300] Training [17/62] Loss: 0.05128 
Epoch [173/300] Training [18/62] Loss: 0.05781 
Epoch [173/300] Training [19/62] Loss: 0.04326 
Epoch [173/300] Training [20/62] Loss: 0.08045 
Epoch [173/300] Training [21/62] Loss: 0.07728 
Epoch [173/300] Training [22/62] Loss: 0.04987 
Epoch [173/300] Training [23/62] Loss: 0.06472 
Epoch [173/300] Training [24/62] Loss: 0.09808 
Epoch [173/300] Training [25/62] Loss: 0.05245 
Epoch [173/300] Training [26/62] Loss: 0.08356 
Epoch [173/300] Training [27/62] Loss: 0.13252 
Epoch [173/300] Training [28/62] Loss: 0.08405 
Epoch [173/300] Training [29/62] Loss: 0.08367 
Epoch [173/300] Training [30/62] Loss: 0.06877 
Epoch [173/300] Training [31/62] Loss: 0.07921 
Epoch [173/300] Training [32/62] Loss: 0.04875 
Epoch [173/300] Training [33/62] Loss: 0.04865 
Epoch [173/300] Training [34/62] Loss: 0.06687 
Epoch [173/300] Training [35/62] Loss: 0.07815 
Epoch [173/300] Training [36/62] Loss: 0.06381 
Epoch [173/300] Training [37/62] Loss: 0.06984 
Epoch [173/300] Training [38/62] Loss: 0.19426 
Epoch [173/300] Training [39/62] Loss: 0.09292 
Epoch [173/300] Training [40/62] Loss: 0.08930 
Epoch [173/300] Training [41/62] Loss: 0.08765 
Epoch [173/300] Training [42/62] Loss: 0.08888 
Epoch [173/300] Training [43/62] Loss: 0.05938 
Epoch [173/300] Training [44/62] Loss: 0.10199 
Epoch [173/300] Training [45/62] Loss: 0.11632 
Epoch [173/300] Training [46/62] Loss: 0.10919 
Epoch [173/300] Training [47/62] Loss: 0.07806 
Epoch [173/300] Training [48/62] Loss: 0.13468 
Epoch [173/300] Training [49/62] Loss: 0.10910 
Epoch [173/300] Training [50/62] Loss: 0.05791 
Epoch [173/300] Training [51/62] Loss: 0.05582 
Epoch [173/300] Training [52/62] Loss: 0.06967 
Epoch [173/300] Training [53/62] Loss: 0.05959 
Epoch [173/300] Training [54/62] Loss: 0.11879 
Epoch [173/300] Training [55/62] Loss: 0.14036 
Epoch [173/300] Training [56/62] Loss: 0.19890 
Epoch [173/300] Training [57/62] Loss: 0.06667 
Epoch [173/300] Training [58/62] Loss: 0.13649 
Epoch [173/300] Training [59/62] Loss: 0.09929 
Epoch [173/300] Training [60/62] Loss: 0.25296 
Epoch [173/300] Training [61/62] Loss: 0.06704 
Epoch [173/300] Training [62/62] Loss: 0.08263 
Epoch [173/300] Training metric {'Train/mean dice_metric': 0.9393035769462585, 'Train/mean miou_metric': 0.8925846219062805, 'Train/mean f1': 0.9485012292861938, 'Train/mean precision': 0.9448252320289612, 'Train/mean recall': 0.952206015586853, 'Train/mean hd95_metric': 11.375513076782227}
Epoch [173/300] Validation [1/16] Loss: 0.36921  focal_loss 0.21582  dice_loss 0.15339 
Epoch [173/300] Validation [2/16] Loss: 0.38386  focal_loss 0.14074  dice_loss 0.24312 
Epoch [173/300] Validation [3/16] Loss: 0.71164  focal_loss 0.39194  dice_loss 0.31970 
Epoch [173/300] Validation [4/16] Loss: 0.23046  focal_loss 0.10414  dice_loss 0.12632 
Epoch [173/300] Validation [5/16] Loss: 0.20191  focal_loss 0.05973  dice_loss 0.14218 
Epoch [173/300] Validation [6/16] Loss: 0.24361  focal_loss 0.03666  dice_loss 0.20695 
Epoch [173/300] Validation [7/16] Loss: 0.20121  focal_loss 0.06796  dice_loss 0.13325 
Epoch [173/300] Validation [8/16] Loss: 0.48951  focal_loss 0.18788  dice_loss 0.30163 
Epoch [173/300] Validation [9/16] Loss: 0.14088  focal_loss 0.04771  dice_loss 0.09317 
Epoch [173/300] Validation [10/16] Loss: 0.34451  focal_loss 0.13590  dice_loss 0.20861 
Epoch [173/300] Validation [11/16] Loss: 0.11853  focal_loss 0.02462  dice_loss 0.09392 
Epoch [173/300] Validation [12/16] Loss: 0.24862  focal_loss 0.05267  dice_loss 0.19595 
Epoch [173/300] Validation [13/16] Loss: 0.27762  focal_loss 0.09305  dice_loss 0.18457 
Epoch [173/300] Validation [14/16] Loss: 0.49582  focal_loss 0.18413  dice_loss 0.31169 
Epoch [173/300] Validation [15/16] Loss: 0.31133  focal_loss 0.12308  dice_loss 0.18825 
Epoch [173/300] Validation [16/16] Loss: 0.04830  focal_loss 0.00968  dice_loss 0.03862 
Epoch [173/300] Validation metric {'Val/mean dice_metric': 0.9151328206062317, 'Val/mean miou_metric': 0.862362802028656, 'Val/mean f1': 0.9235179424285889, 'Val/mean precision': 0.9255309700965881, 'Val/mean recall': 0.9215136170387268, 'Val/mean hd95_metric': 16.79264259338379}
Cheakpoint...
Epoch [173/300] best acc:tensor([0.9163], device='cuda:0'), Now : mean acc: tensor([0.9151], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9151328206062317, 'Val/mean miou_metric': 0.862362802028656, 'Val/mean f1': 0.9235179424285889, 'Val/mean precision': 0.9255309700965881, 'Val/mean recall': 0.9215136170387268, 'Val/mean hd95_metric': 16.79264259338379}
Epoch [174/300] Training [1/62] Loss: 0.05389 
Epoch [174/300] Training [2/62] Loss: 0.04736 
Epoch [174/300] Training [3/62] Loss: 0.08986 
Epoch [174/300] Training [4/62] Loss: 0.08377 
Epoch [174/300] Training [5/62] Loss: 0.07321 
Epoch [174/300] Training [6/62] Loss: 0.06696 
Epoch [174/300] Training [7/62] Loss: 0.08009 
Epoch [174/300] Training [8/62] Loss: 0.10333 
Epoch [174/300] Training [9/62] Loss: 0.07177 
Epoch [174/300] Training [10/62] Loss: 0.14190 
Epoch [174/300] Training [11/62] Loss: 0.08971 
Epoch [174/300] Training [12/62] Loss: 0.14241 
Epoch [174/300] Training [13/62] Loss: 0.05666 
Epoch [174/300] Training [14/62] Loss: 0.10137 
Epoch [174/300] Training [15/62] Loss: 0.20810 
Epoch [174/300] Training [16/62] Loss: 0.04819 
Epoch [174/300] Training [17/62] Loss: 0.11850 
Epoch [174/300] Training [18/62] Loss: 0.06889 
Epoch [174/300] Training [19/62] Loss: 0.06562 
Epoch [174/300] Training [20/62] Loss: 0.06724 
Epoch [174/300] Training [21/62] Loss: 0.05669 
Epoch [174/300] Training [22/62] Loss: 0.09833 
Epoch [174/300] Training [23/62] Loss: 0.12183 
Epoch [174/300] Training [24/62] Loss: 0.11743 
Epoch [174/300] Training [25/62] Loss: 0.06656 
Epoch [174/300] Training [26/62] Loss: 0.07388 
Epoch [174/300] Training [27/62] Loss: 0.14897 
Epoch [174/300] Training [28/62] Loss: 0.08269 
Epoch [174/300] Training [29/62] Loss: 0.05273 
Epoch [174/300] Training [30/62] Loss: 0.05448 
Epoch [174/300] Training [31/62] Loss: 0.06545 
Epoch [174/300] Training [32/62] Loss: 0.08856 
Epoch [174/300] Training [33/62] Loss: 0.05761 
Epoch [174/300] Training [34/62] Loss: 0.06416 
Epoch [174/300] Training [35/62] Loss: 0.07186 
Epoch [174/300] Training [36/62] Loss: 0.09740 
Epoch [174/300] Training [37/62] Loss: 0.06011 
Epoch [174/300] Training [38/62] Loss: 0.05190 
Epoch [174/300] Training [39/62] Loss: 0.16498 
Epoch [174/300] Training [40/62] Loss: 0.05874 
Epoch [174/300] Training [41/62] Loss: 0.07735 
Epoch [174/300] Training [42/62] Loss: 0.06090 
Epoch [174/300] Training [43/62] Loss: 0.11983 
Epoch [174/300] Training [44/62] Loss: 0.19100 
Epoch [174/300] Training [45/62] Loss: 0.07656 
Epoch [174/300] Training [46/62] Loss: 0.22417 
Epoch [174/300] Training [47/62] Loss: 0.16262 
Epoch [174/300] Training [48/62] Loss: 0.09768 
Epoch [174/300] Training [49/62] Loss: 0.04419 
Epoch [174/300] Training [50/62] Loss: 0.10065 
Epoch [174/300] Training [51/62] Loss: 0.08512 
Epoch [174/300] Training [52/62] Loss: 0.07392 
Epoch [174/300] Training [53/62] Loss: 0.16523 
Epoch [174/300] Training [54/62] Loss: 0.14409 
Epoch [174/300] Training [55/62] Loss: 0.14689 
Epoch [174/300] Training [56/62] Loss: 0.09059 
Epoch [174/300] Training [57/62] Loss: 0.10619 
Epoch [174/300] Training [58/62] Loss: 0.09543 
Epoch [174/300] Training [59/62] Loss: 0.05018 
Epoch [174/300] Training [60/62] Loss: 0.04748 
Epoch [174/300] Training [61/62] Loss: 0.16248 
Epoch [174/300] Training [62/62] Loss: 0.03850 
Epoch [174/300] Training metric {'Train/mean dice_metric': 0.9339216351509094, 'Train/mean miou_metric': 0.8856909275054932, 'Train/mean f1': 0.9468249678611755, 'Train/mean precision': 0.9413130283355713, 'Train/mean recall': 0.9524018168449402, 'Train/mean hd95_metric': 12.474535942077637}
Epoch [174/300] Validation [1/16] Loss: 0.13034  focal_loss 0.04489  dice_loss 0.08544 
Epoch [174/300] Validation [2/16] Loss: 0.39367  focal_loss 0.12724  dice_loss 0.26643 
Epoch [174/300] Validation [3/16] Loss: 0.50277  focal_loss 0.23280  dice_loss 0.26997 
Epoch [174/300] Validation [4/16] Loss: 0.16680  focal_loss 0.05987  dice_loss 0.10693 
Epoch [174/300] Validation [5/16] Loss: 0.38739  focal_loss 0.10010  dice_loss 0.28729 
Epoch [174/300] Validation [6/16] Loss: 0.18596  focal_loss 0.03911  dice_loss 0.14684 
Epoch [174/300] Validation [7/16] Loss: 0.21655  focal_loss 0.07523  dice_loss 0.14132 
Epoch [174/300] Validation [8/16] Loss: 0.29749  focal_loss 0.07473  dice_loss 0.22276 
Epoch [174/300] Validation [9/16] Loss: 0.21935  focal_loss 0.06977  dice_loss 0.14958 
Epoch [174/300] Validation [10/16] Loss: 0.50750  focal_loss 0.15556  dice_loss 0.35194 
Epoch [174/300] Validation [11/16] Loss: 0.12836  focal_loss 0.02880  dice_loss 0.09956 
Epoch [174/300] Validation [12/16] Loss: 0.34174  focal_loss 0.07892  dice_loss 0.26282 
Epoch [174/300] Validation [13/16] Loss: 0.30589  focal_loss 0.09415  dice_loss 0.21174 
Epoch [174/300] Validation [14/16] Loss: 0.39128  focal_loss 0.14212  dice_loss 0.24916 
Epoch [174/300] Validation [15/16] Loss: 0.09834  focal_loss 0.01985  dice_loss 0.07850 
Epoch [174/300] Validation [16/16] Loss: 0.05862  focal_loss 0.01428  dice_loss 0.04434 
Epoch [174/300] Validation metric {'Val/mean dice_metric': 0.9105443954467773, 'Val/mean miou_metric': 0.8564590811729431, 'Val/mean f1': 0.9253231883049011, 'Val/mean precision': 0.9245694279670715, 'Val/mean recall': 0.9260782599449158, 'Val/mean hd95_metric': 17.7075138092041}
Cheakpoint...
Epoch [174/300] best acc:tensor([0.9163], device='cuda:0'), Now : mean acc: tensor([0.9105], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9105443954467773, 'Val/mean miou_metric': 0.8564590811729431, 'Val/mean f1': 0.9253231883049011, 'Val/mean precision': 0.9245694279670715, 'Val/mean recall': 0.9260782599449158, 'Val/mean hd95_metric': 17.7075138092041}
Epoch [175/300] Training [1/62] Loss: 0.06715 
Epoch [175/300] Training [2/62] Loss: 0.08526 
Epoch [175/300] Training [3/62] Loss: 0.08375 
Epoch [175/300] Training [4/62] Loss: 0.07542 
Epoch [175/300] Training [5/62] Loss: 0.04689 
Epoch [175/300] Training [6/62] Loss: 0.08457 
Epoch [175/300] Training [7/62] Loss: 0.05717 
Epoch [175/300] Training [8/62] Loss: 0.05567 
Epoch [175/300] Training [9/62] Loss: 0.05558 
Epoch [175/300] Training [10/62] Loss: 0.08482 
Epoch [175/300] Training [11/62] Loss: 0.08765 
Epoch [175/300] Training [12/62] Loss: 0.07687 
Epoch [175/300] Training [13/62] Loss: 0.08715 
Epoch [175/300] Training [14/62] Loss: 0.18191 
Epoch [175/300] Training [15/62] Loss: 0.06965 
Epoch [175/300] Training [16/62] Loss: 0.07025 
Epoch [175/300] Training [17/62] Loss: 0.06395 
Epoch [175/300] Training [18/62] Loss: 0.09117 
Epoch [175/300] Training [19/62] Loss: 0.06087 
Epoch [175/300] Training [20/62] Loss: 0.06541 
Epoch [175/300] Training [21/62] Loss: 0.10694 
Epoch [175/300] Training [22/62] Loss: 0.05496 
Epoch [175/300] Training [23/62] Loss: 0.07464 
Epoch [175/300] Training [24/62] Loss: 0.16487 
Epoch [175/300] Training [25/62] Loss: 0.16485 
Epoch [175/300] Training [26/62] Loss: 0.06460 
Epoch [175/300] Training [27/62] Loss: 0.05851 
Epoch [175/300] Training [28/62] Loss: 0.05712 
Epoch [175/300] Training [29/62] Loss: 0.06157 
Epoch [175/300] Training [30/62] Loss: 0.13393 
Epoch [175/300] Training [31/62] Loss: 0.07873 
Epoch [175/300] Training [32/62] Loss: 0.08040 
Epoch [175/300] Training [33/62] Loss: 0.06587 
Epoch [175/300] Training [34/62] Loss: 0.09129 
Epoch [175/300] Training [35/62] Loss: 0.25743 
Epoch [175/300] Training [36/62] Loss: 0.11746 
Epoch [175/300] Training [37/62] Loss: 0.11130 
Epoch [175/300] Training [38/62] Loss: 0.12372 
Epoch [175/300] Training [39/62] Loss: 0.06228 
Epoch [175/300] Training [40/62] Loss: 0.05601 
Epoch [175/300] Training [41/62] Loss: 0.06126 
Epoch [175/300] Training [42/62] Loss: 0.06149 
Epoch [175/300] Training [43/62] Loss: 0.11606 
Epoch [175/300] Training [44/62] Loss: 0.06373 
Epoch [175/300] Training [45/62] Loss: 0.09737 
Epoch [175/300] Training [46/62] Loss: 0.09475 
Epoch [175/300] Training [47/62] Loss: 0.07488 
Epoch [175/300] Training [48/62] Loss: 0.06981 
Epoch [175/300] Training [49/62] Loss: 0.13270 
Epoch [175/300] Training [50/62] Loss: 0.07351 
Epoch [175/300] Training [51/62] Loss: 0.05908 
Epoch [175/300] Training [52/62] Loss: 0.08316 
Epoch [175/300] Training [53/62] Loss: 0.06125 
Epoch [175/300] Training [54/62] Loss: 0.09406 
Epoch [175/300] Training [55/62] Loss: 0.06219 
Epoch [175/300] Training [56/62] Loss: 0.07063 
Epoch [175/300] Training [57/62] Loss: 0.08176 
Epoch [175/300] Training [58/62] Loss: 0.10955 
Epoch [175/300] Training [59/62] Loss: 0.05232 
Epoch [175/300] Training [60/62] Loss: 0.10080 
Epoch [175/300] Training [61/62] Loss: 0.06958 
Epoch [175/300] Training [62/62] Loss: 0.05665 
Epoch [175/300] Training metric {'Train/mean dice_metric': 0.9407878518104553, 'Train/mean miou_metric': 0.8947461247444153, 'Train/mean f1': 0.9484983086585999, 'Train/mean precision': 0.9424052238464355, 'Train/mean recall': 0.9546707272529602, 'Train/mean hd95_metric': 10.515640258789062}
Epoch [175/300] Validation [1/16] Loss: 0.29100  focal_loss 0.14204  dice_loss 0.14896 
Epoch [175/300] Validation [2/16] Loss: 0.34131  focal_loss 0.11697  dice_loss 0.22434 
Epoch [175/300] Validation [3/16] Loss: 0.29700  focal_loss 0.09088  dice_loss 0.20613 
Epoch [175/300] Validation [4/16] Loss: 0.45492  focal_loss 0.23264  dice_loss 0.22228 
Epoch [175/300] Validation [5/16] Loss: 0.26747  focal_loss 0.07581  dice_loss 0.19166 
Epoch [175/300] Validation [6/16] Loss: 0.21916  focal_loss 0.03378  dice_loss 0.18538 
Epoch [175/300] Validation [7/16] Loss: 0.16783  focal_loss 0.05331  dice_loss 0.11452 
Epoch [175/300] Validation [8/16] Loss: 0.29981  focal_loss 0.06827  dice_loss 0.23154 
Epoch [175/300] Validation [9/16] Loss: 0.22900  focal_loss 0.09510  dice_loss 0.13390 
Epoch [175/300] Validation [10/16] Loss: 0.39532  focal_loss 0.12351  dice_loss 0.27181 
Epoch [175/300] Validation [11/16] Loss: 0.15281  focal_loss 0.04036  dice_loss 0.11245 
Epoch [175/300] Validation [12/16] Loss: 0.29338  focal_loss 0.06456  dice_loss 0.22881 
Epoch [175/300] Validation [13/16] Loss: 0.33788  focal_loss 0.13041  dice_loss 0.20746 
Epoch [175/300] Validation [14/16] Loss: 0.42164  focal_loss 0.13158  dice_loss 0.29006 
Epoch [175/300] Validation [15/16] Loss: 0.33768  focal_loss 0.12804  dice_loss 0.20964 
Epoch [175/300] Validation [16/16] Loss: 0.04996  focal_loss 0.01197  dice_loss 0.03799 
Epoch [175/300] Validation metric {'Val/mean dice_metric': 0.9148362278938293, 'Val/mean miou_metric': 0.8613678216934204, 'Val/mean f1': 0.9254972338676453, 'Val/mean precision': 0.9302299618721008, 'Val/mean recall': 0.9208124279975891, 'Val/mean hd95_metric': 16.547149658203125}
Cheakpoint...
Epoch [175/300] best acc:tensor([0.9163], device='cuda:0'), Now : mean acc: tensor([0.9148], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9148362278938293, 'Val/mean miou_metric': 0.8613678216934204, 'Val/mean f1': 0.9254972338676453, 'Val/mean precision': 0.9302299618721008, 'Val/mean recall': 0.9208124279975891, 'Val/mean hd95_metric': 16.547149658203125}
Epoch [176/300] Training [1/62] Loss: 0.05741 
Epoch [176/300] Training [2/62] Loss: 0.07644 
Epoch [176/300] Training [3/62] Loss: 0.07465 
Epoch [176/300] Training [4/62] Loss: 0.09818 
Epoch [176/300] Training [5/62] Loss: 0.10160 
Epoch [176/300] Training [6/62] Loss: 0.09104 
Epoch [176/300] Training [7/62] Loss: 0.07512 
Epoch [176/300] Training [8/62] Loss: 0.07883 
Epoch [176/300] Training [9/62] Loss: 0.09807 
Epoch [176/300] Training [10/62] Loss: 0.06325 
Epoch [176/300] Training [11/62] Loss: 0.14096 
Epoch [176/300] Training [12/62] Loss: 0.06121 
Epoch [176/300] Training [13/62] Loss: 0.07597 
Epoch [176/300] Training [14/62] Loss: 0.05203 
Epoch [176/300] Training [15/62] Loss: 0.07930 
Epoch [176/300] Training [16/62] Loss: 0.13200 
Epoch [176/300] Training [17/62] Loss: 0.20181 
Epoch [176/300] Training [18/62] Loss: 0.16183 
Epoch [176/300] Training [19/62] Loss: 0.12506 
Epoch [176/300] Training [20/62] Loss: 0.05875 
Epoch [176/300] Training [21/62] Loss: 0.10437 
Epoch [176/300] Training [22/62] Loss: 0.06746 
Epoch [176/300] Training [23/62] Loss: 0.16257 
Epoch [176/300] Training [24/62] Loss: 0.12216 
Epoch [176/300] Training [25/62] Loss: 0.06606 
Epoch [176/300] Training [26/62] Loss: 0.08426 
Epoch [176/300] Training [27/62] Loss: 0.04053 
Epoch [176/300] Training [28/62] Loss: 0.11192 
Epoch [176/300] Training [29/62] Loss: 0.06136 
Epoch [176/300] Training [30/62] Loss: 0.19893 
Epoch [176/300] Training [31/62] Loss: 0.08376 
Epoch [176/300] Training [32/62] Loss: 0.15786 
Epoch [176/300] Training [33/62] Loss: 0.06891 
Epoch [176/300] Training [34/62] Loss: 0.09899 
Epoch [176/300] Training [35/62] Loss: 0.08923 
Epoch [176/300] Training [36/62] Loss: 0.07865 
Epoch [176/300] Training [37/62] Loss: 0.05625 
Epoch [176/300] Training [38/62] Loss: 0.05786 
Epoch [176/300] Training [39/62] Loss: 0.08061 
Epoch [176/300] Training [40/62] Loss: 0.06679 
Epoch [176/300] Training [41/62] Loss: 0.11544 
Epoch [176/300] Training [42/62] Loss: 0.07982 
Epoch [176/300] Training [43/62] Loss: 0.10513 
Epoch [176/300] Training [44/62] Loss: 0.13552 
Epoch [176/300] Training [45/62] Loss: 0.11088 
Epoch [176/300] Training [46/62] Loss: 0.07666 
Epoch [176/300] Training [47/62] Loss: 0.13531 
Epoch [176/300] Training [48/62] Loss: 0.23514 
Epoch [176/300] Training [49/62] Loss: 0.19455 
Epoch [176/300] Training [50/62] Loss: 0.10504 
Epoch [176/300] Training [51/62] Loss: 0.09984 
Epoch [176/300] Training [52/62] Loss: 0.06737 
Epoch [176/300] Training [53/62] Loss: 0.09904 
Epoch [176/300] Training [54/62] Loss: 0.24314 
Epoch [176/300] Training [55/62] Loss: 0.06919 
Epoch [176/300] Training [56/62] Loss: 0.06383 
Epoch [176/300] Training [57/62] Loss: 0.07873 
Epoch [176/300] Training [58/62] Loss: 0.08448 
Epoch [176/300] Training [59/62] Loss: 0.08616 
Epoch [176/300] Training [60/62] Loss: 0.15535 
Epoch [176/300] Training [61/62] Loss: 0.07953 
Epoch [176/300] Training [62/62] Loss: 0.07465 
Epoch [176/300] Training metric {'Train/mean dice_metric': 0.92906653881073, 'Train/mean miou_metric': 0.8797417283058167, 'Train/mean f1': 0.9406827092170715, 'Train/mean precision': 0.9351316690444946, 'Train/mean recall': 0.9462998509407043, 'Train/mean hd95_metric': 12.19771957397461}
Epoch [176/300] Validation [1/16] Loss: 0.29964  focal_loss 0.15967  dice_loss 0.13997 
Epoch [176/300] Validation [2/16] Loss: 0.40225  focal_loss 0.14453  dice_loss 0.25772 
Epoch [176/300] Validation [3/16] Loss: 0.32803  focal_loss 0.08847  dice_loss 0.23957 
Epoch [176/300] Validation [4/16] Loss: 0.28955  focal_loss 0.11274  dice_loss 0.17681 
Epoch [176/300] Validation [5/16] Loss: 0.30748  focal_loss 0.07885  dice_loss 0.22863 
Epoch [176/300] Validation [6/16] Loss: 0.22126  focal_loss 0.03894  dice_loss 0.18232 
Epoch [176/300] Validation [7/16] Loss: 0.14298  focal_loss 0.03237  dice_loss 0.11061 
Epoch [176/300] Validation [8/16] Loss: 0.30576  focal_loss 0.09833  dice_loss 0.20744 
Epoch [176/300] Validation [9/16] Loss: 0.14905  focal_loss 0.05713  dice_loss 0.09192 
Epoch [176/300] Validation [10/16] Loss: 0.24007  focal_loss 0.07214  dice_loss 0.16792 
Epoch [176/300] Validation [11/16] Loss: 0.16029  focal_loss 0.05202  dice_loss 0.10827 
Epoch [176/300] Validation [12/16] Loss: 0.32467  focal_loss 0.06644  dice_loss 0.25824 
Epoch [176/300] Validation [13/16] Loss: 0.31429  focal_loss 0.12285  dice_loss 0.19144 
Epoch [176/300] Validation [14/16] Loss: 0.47159  focal_loss 0.14719  dice_loss 0.32439 
Epoch [176/300] Validation [15/16] Loss: 0.11391  focal_loss 0.03332  dice_loss 0.08059 
Epoch [176/300] Validation [16/16] Loss: 0.07500  focal_loss 0.02636  dice_loss 0.04864 
Epoch [176/300] Validation metric {'Val/mean dice_metric': 0.9090791344642639, 'Val/mean miou_metric': 0.8545618057250977, 'Val/mean f1': 0.9203124046325684, 'Val/mean precision': 0.9132330417633057, 'Val/mean recall': 0.9275023341178894, 'Val/mean hd95_metric': 17.98850440979004}
Cheakpoint...
Epoch [176/300] best acc:tensor([0.9163], device='cuda:0'), Now : mean acc: tensor([0.9091], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9090791344642639, 'Val/mean miou_metric': 0.8545618057250977, 'Val/mean f1': 0.9203124046325684, 'Val/mean precision': 0.9132330417633057, 'Val/mean recall': 0.9275023341178894, 'Val/mean hd95_metric': 17.98850440979004}
Epoch [177/300] Training [1/62] Loss: 0.09938 
Epoch [177/300] Training [2/62] Loss: 0.09649 
Epoch [177/300] Training [3/62] Loss: 0.04955 
Epoch [177/300] Training [4/62] Loss: 0.07681 
Epoch [177/300] Training [5/62] Loss: 0.15913 
Epoch [177/300] Training [6/62] Loss: 0.06526 
Epoch [177/300] Training [7/62] Loss: 0.09107 
Epoch [177/300] Training [8/62] Loss: 0.05528 
Epoch [177/300] Training [9/62] Loss: 0.05494 
Epoch [177/300] Training [10/62] Loss: 0.06670 
Epoch [177/300] Training [11/62] Loss: 0.06814 
Epoch [177/300] Training [12/62] Loss: 0.05151 
Epoch [177/300] Training [13/62] Loss: 0.08476 
Epoch [177/300] Training [14/62] Loss: 0.14217 
Epoch [177/300] Training [15/62] Loss: 0.05270 
Epoch [177/300] Training [16/62] Loss: 0.08261 
Epoch [177/300] Training [17/62] Loss: 0.06432 
Epoch [177/300] Training [18/62] Loss: 0.12858 
Epoch [177/300] Training [19/62] Loss: 0.04165 
Epoch [177/300] Training [20/62] Loss: 0.05090 
Epoch [177/300] Training [21/62] Loss: 0.13977 
Epoch [177/300] Training [22/62] Loss: 0.17055 
Epoch [177/300] Training [23/62] Loss: 0.05768 
Epoch [177/300] Training [24/62] Loss: 0.07137 
Epoch [177/300] Training [25/62] Loss: 0.07727 
Epoch [177/300] Training [26/62] Loss: 0.10478 
Epoch [177/300] Training [27/62] Loss: 0.10868 
Epoch [177/300] Training [28/62] Loss: 0.04967 
Epoch [177/300] Training [29/62] Loss: 0.04876 
Epoch [177/300] Training [30/62] Loss: 0.06753 
Epoch [177/300] Training [31/62] Loss: 0.10251 
Epoch [177/300] Training [32/62] Loss: 0.06205 
Epoch [177/300] Training [33/62] Loss: 0.06454 
Epoch [177/300] Training [34/62] Loss: 0.11123 
Epoch [177/300] Training [35/62] Loss: 0.07126 
Epoch [177/300] Training [36/62] Loss: 0.11374 
Epoch [177/300] Training [37/62] Loss: 0.08587 
Epoch [177/300] Training [38/62] Loss: 0.08198 
Epoch [177/300] Training [39/62] Loss: 0.05913 
Epoch [177/300] Training [40/62] Loss: 0.08437 
Epoch [177/300] Training [41/62] Loss: 0.07532 
Epoch [177/300] Training [42/62] Loss: 0.05313 
Epoch [177/300] Training [43/62] Loss: 0.07406 
Epoch [177/300] Training [44/62] Loss: 0.08960 
Epoch [177/300] Training [45/62] Loss: 0.05883 
Epoch [177/300] Training [46/62] Loss: 0.08456 
Epoch [177/300] Training [47/62] Loss: 0.05639 
Epoch [177/300] Training [48/62] Loss: 0.06285 
Epoch [177/300] Training [49/62] Loss: 0.08240 
Epoch [177/300] Training [50/62] Loss: 0.05127 
Epoch [177/300] Training [51/62] Loss: 0.05677 
Epoch [177/300] Training [52/62] Loss: 0.04482 
Epoch [177/300] Training [53/62] Loss: 0.07771 
Epoch [177/300] Training [54/62] Loss: 0.06683 
Epoch [177/300] Training [55/62] Loss: 0.05743 
Epoch [177/300] Training [56/62] Loss: 0.10438 
Epoch [177/300] Training [57/62] Loss: 0.05601 
Epoch [177/300] Training [58/62] Loss: 0.07321 
Epoch [177/300] Training [59/62] Loss: 0.13952 
Epoch [177/300] Training [60/62] Loss: 0.05878 
Epoch [177/300] Training [61/62] Loss: 0.06496 
Epoch [177/300] Training [62/62] Loss: 0.03050 
Epoch [177/300] Training metric {'Train/mean dice_metric': 0.9463847875595093, 'Train/mean miou_metric': 0.9026890993118286, 'Train/mean f1': 0.9531346559524536, 'Train/mean precision': 0.9502490758895874, 'Train/mean recall': 0.9560377597808838, 'Train/mean hd95_metric': 9.978056907653809}
Epoch [177/300] Validation [1/16] Loss: 0.13877  focal_loss 0.04618  dice_loss 0.09259 
Epoch [177/300] Validation [2/16] Loss: 0.40849  focal_loss 0.16593  dice_loss 0.24256 
Epoch [177/300] Validation [3/16] Loss: 0.21306  focal_loss 0.05230  dice_loss 0.16076 
Epoch [177/300] Validation [4/16] Loss: 0.20110  focal_loss 0.05272  dice_loss 0.14838 
Epoch [177/300] Validation [5/16] Loss: 0.20062  focal_loss 0.04894  dice_loss 0.15168 
Epoch [177/300] Validation [6/16] Loss: 0.20507  focal_loss 0.03257  dice_loss 0.17251 
Epoch [177/300] Validation [7/16] Loss: 0.23718  focal_loss 0.08171  dice_loss 0.15547 
Epoch [177/300] Validation [8/16] Loss: 0.45814  focal_loss 0.16428  dice_loss 0.29386 
Epoch [177/300] Validation [9/16] Loss: 0.14402  focal_loss 0.04564  dice_loss 0.09838 
Epoch [177/300] Validation [10/16] Loss: 0.36069  focal_loss 0.11944  dice_loss 0.24125 
Epoch [177/300] Validation [11/16] Loss: 0.17651  focal_loss 0.05057  dice_loss 0.12593 
Epoch [177/300] Validation [12/16] Loss: 0.26075  focal_loss 0.04537  dice_loss 0.21539 
Epoch [177/300] Validation [13/16] Loss: 0.23517  focal_loss 0.06364  dice_loss 0.17154 
Epoch [177/300] Validation [14/16] Loss: 0.47799  focal_loss 0.15262  dice_loss 0.32538 
Epoch [177/300] Validation [15/16] Loss: 0.09153  focal_loss 0.02081  dice_loss 0.07072 
Epoch [177/300] Validation [16/16] Loss: 0.08196  focal_loss 0.02913  dice_loss 0.05283 
Epoch [177/300] Validation metric {'Val/mean dice_metric': 0.9239336252212524, 'Val/mean miou_metric': 0.8728419542312622, 'Val/mean f1': 0.9310562610626221, 'Val/mean precision': 0.92447429895401, 'Val/mean recall': 0.9377325773239136, 'Val/mean hd95_metric': 15.709918022155762}
Cheakpoint...
Epoch [177/300] best acc:tensor([0.9239], device='cuda:0'), Now : mean acc: tensor([0.9239], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9239336252212524, 'Val/mean miou_metric': 0.8728419542312622, 'Val/mean f1': 0.9310562610626221, 'Val/mean precision': 0.92447429895401, 'Val/mean recall': 0.9377325773239136, 'Val/mean hd95_metric': 15.709918022155762}
Epoch [178/300] Training [1/62] Loss: 0.06180 
Epoch [178/300] Training [2/62] Loss: 0.05622 
Epoch [178/300] Training [3/62] Loss: 0.04845 
Epoch [178/300] Training [4/62] Loss: 0.05094 
Epoch [178/300] Training [5/62] Loss: 0.14237 
Epoch [178/300] Training [6/62] Loss: 0.05390 
Epoch [178/300] Training [7/62] Loss: 0.06331 
Epoch [178/300] Training [8/62] Loss: 0.06617 
Epoch [178/300] Training [9/62] Loss: 0.05680 
Epoch [178/300] Training [10/62] Loss: 0.05747 
Epoch [178/300] Training [11/62] Loss: 0.05148 
Epoch [178/300] Training [12/62] Loss: 0.09013 
Epoch [178/300] Training [13/62] Loss: 0.08748 
Epoch [178/300] Training [14/62] Loss: 0.23159 
Epoch [178/300] Training [15/62] Loss: 0.05648 
Epoch [178/300] Training [16/62] Loss: 0.10388 
Epoch [178/300] Training [17/62] Loss: 0.06115 
Epoch [178/300] Training [18/62] Loss: 0.05188 
Epoch [178/300] Training [19/62] Loss: 0.08454 
Epoch [178/300] Training [20/62] Loss: 0.05320 
Epoch [178/300] Training [21/62] Loss: 0.07474 
Epoch [178/300] Training [22/62] Loss: 0.11705 
Epoch [178/300] Training [23/62] Loss: 0.09789 
Epoch [178/300] Training [24/62] Loss: 0.10030 
Epoch [178/300] Training [25/62] Loss: 0.06994 
Epoch [178/300] Training [26/62] Loss: 0.05979 
Epoch [178/300] Training [27/62] Loss: 0.10944 
Epoch [178/300] Training [28/62] Loss: 0.10079 
Epoch [178/300] Training [29/62] Loss: 0.07439 
Epoch [178/300] Training [30/62] Loss: 0.12569 
Epoch [178/300] Training [31/62] Loss: 0.13739 
Epoch [178/300] Training [32/62] Loss: 0.07067 
Epoch [178/300] Training [33/62] Loss: 0.08600 
Epoch [178/300] Training [34/62] Loss: 0.07647 
Epoch [178/300] Training [35/62] Loss: 0.07037 
Epoch [178/300] Training [36/62] Loss: 0.06221 
Epoch [178/300] Training [37/62] Loss: 0.09163 
Epoch [178/300] Training [38/62] Loss: 0.10661 
Epoch [178/300] Training [39/62] Loss: 0.14442 
Epoch [178/300] Training [40/62] Loss: 0.06781 
Epoch [178/300] Training [41/62] Loss: 0.07076 
Epoch [178/300] Training [42/62] Loss: 0.07491 
Epoch [178/300] Training [43/62] Loss: 0.07538 
Epoch [178/300] Training [44/62] Loss: 0.11226 
Epoch [178/300] Training [45/62] Loss: 0.05827 
Epoch [178/300] Training [46/62] Loss: 0.06241 
Epoch [178/300] Training [47/62] Loss: 0.05924 
Epoch [178/300] Training [48/62] Loss: 0.07028 
Epoch [178/300] Training [49/62] Loss: 0.18665 
Epoch [178/300] Training [50/62] Loss: 0.20970 
Epoch [178/300] Training [51/62] Loss: 0.05856 
Epoch [178/300] Training [52/62] Loss: 0.07150 
Epoch [178/300] Training [53/62] Loss: 0.08424 
Epoch [178/300] Training [54/62] Loss: 0.06271 
Epoch [178/300] Training [55/62] Loss: 0.12335 
Epoch [178/300] Training [56/62] Loss: 0.07137 
Epoch [178/300] Training [57/62] Loss: 0.10212 
Epoch [178/300] Training [58/62] Loss: 0.04447 
Epoch [178/300] Training [59/62] Loss: 0.10043 
Epoch [178/300] Training [60/62] Loss: 0.06735 
Epoch [178/300] Training [61/62] Loss: 0.05799 
Epoch [178/300] Training [62/62] Loss: 0.06417 
Epoch [178/300] Training metric {'Train/mean dice_metric': 0.9391322731971741, 'Train/mean miou_metric': 0.8945853114128113, 'Train/mean f1': 0.9513826966285706, 'Train/mean precision': 0.9447149634361267, 'Train/mean recall': 0.958145260810852, 'Train/mean hd95_metric': 11.47171401977539}
Epoch [178/300] Validation [1/16] Loss: 0.19266  focal_loss 0.07232  dice_loss 0.12034 
Epoch [178/300] Validation [2/16] Loss: 0.37892  focal_loss 0.16041  dice_loss 0.21852 
Epoch [178/300] Validation [3/16] Loss: 0.26718  focal_loss 0.08107  dice_loss 0.18611 
Epoch [178/300] Validation [4/16] Loss: 0.27870  focal_loss 0.14369  dice_loss 0.13501 
Epoch [178/300] Validation [5/16] Loss: 0.39554  focal_loss 0.14489  dice_loss 0.25065 
Epoch [178/300] Validation [6/16] Loss: 0.23254  focal_loss 0.04728  dice_loss 0.18526 
Epoch [178/300] Validation [7/16] Loss: 0.18208  focal_loss 0.06690  dice_loss 0.11518 
Epoch [178/300] Validation [8/16] Loss: 0.35631  focal_loss 0.11158  dice_loss 0.24473 
Epoch [178/300] Validation [9/16] Loss: 0.20729  focal_loss 0.07319  dice_loss 0.13410 
Epoch [178/300] Validation [10/16] Loss: 0.33644  focal_loss 0.12584  dice_loss 0.21061 
Epoch [178/300] Validation [11/16] Loss: 0.10972  focal_loss 0.02569  dice_loss 0.08403 
Epoch [178/300] Validation [12/16] Loss: 0.35195  focal_loss 0.09973  dice_loss 0.25223 
Epoch [178/300] Validation [13/16] Loss: 0.45726  focal_loss 0.22614  dice_loss 0.23112 
Epoch [178/300] Validation [14/16] Loss: 0.63950  focal_loss 0.24454  dice_loss 0.39496 
Epoch [178/300] Validation [15/16] Loss: 0.11761  focal_loss 0.04468  dice_loss 0.07292 
Epoch [178/300] Validation [16/16] Loss: 0.03985  focal_loss 0.00781  dice_loss 0.03204 
Epoch [178/300] Validation metric {'Val/mean dice_metric': 0.9152786135673523, 'Val/mean miou_metric': 0.8633376955986023, 'Val/mean f1': 0.9297430515289307, 'Val/mean precision': 0.9283604025840759, 'Val/mean recall': 0.9311297535896301, 'Val/mean hd95_metric': 18.152748107910156}
Cheakpoint...
Epoch [178/300] best acc:tensor([0.9239], device='cuda:0'), Now : mean acc: tensor([0.9153], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9152786135673523, 'Val/mean miou_metric': 0.8633376955986023, 'Val/mean f1': 0.9297430515289307, 'Val/mean precision': 0.9283604025840759, 'Val/mean recall': 0.9311297535896301, 'Val/mean hd95_metric': 18.152748107910156}
Epoch [179/300] Training [1/62] Loss: 0.08276 
Epoch [179/300] Training [2/62] Loss: 0.07465 
Epoch [179/300] Training [3/62] Loss: 0.05290 
Epoch [179/300] Training [4/62] Loss: 0.04324 
Epoch [179/300] Training [5/62] Loss: 0.08134 
Epoch [179/300] Training [6/62] Loss: 0.15960 
Epoch [179/300] Training [7/62] Loss: 0.06408 
Epoch [179/300] Training [8/62] Loss: 0.05964 
Epoch [179/300] Training [9/62] Loss: 0.06509 
Epoch [179/300] Training [10/62] Loss: 0.04591 
Epoch [179/300] Training [11/62] Loss: 0.08298 
Epoch [179/300] Training [12/62] Loss: 0.04788 
Epoch [179/300] Training [13/62] Loss: 0.12385 
Epoch [179/300] Training [14/62] Loss: 0.15279 
Epoch [179/300] Training [15/62] Loss: 0.06646 
Epoch [179/300] Training [16/62] Loss: 0.05603 
Epoch [179/300] Training [17/62] Loss: 0.08756 
Epoch [179/300] Training [18/62] Loss: 0.05403 
Epoch [179/300] Training [19/62] Loss: 0.05277 
Epoch [179/300] Training [20/62] Loss: 0.07739 
Epoch [179/300] Training [21/62] Loss: 0.06190 
Epoch [179/300] Training [22/62] Loss: 0.05230 
Epoch [179/300] Training [23/62] Loss: 0.05650 
Epoch [179/300] Training [24/62] Loss: 0.05863 
Epoch [179/300] Training [25/62] Loss: 0.06297 
Epoch [179/300] Training [26/62] Loss: 0.05904 
Epoch [179/300] Training [27/62] Loss: 0.07732 
Epoch [179/300] Training [28/62] Loss: 0.03810 
Epoch [179/300] Training [29/62] Loss: 0.10515 
Epoch [179/300] Training [30/62] Loss: 0.05096 
Epoch [179/300] Training [31/62] Loss: 0.06737 
Epoch [179/300] Training [32/62] Loss: 0.08547 
Epoch [179/300] Training [33/62] Loss: 0.07030 
Epoch [179/300] Training [34/62] Loss: 0.10172 
Epoch [179/300] Training [35/62] Loss: 0.10399 
Epoch [179/300] Training [36/62] Loss: 0.08551 
Epoch [179/300] Training [37/62] Loss: 0.12094 
Epoch [179/300] Training [38/62] Loss: 0.06056 
Epoch [179/300] Training [39/62] Loss: 0.09919 
Epoch [179/300] Training [40/62] Loss: 0.11462 
Epoch [179/300] Training [41/62] Loss: 0.07848 
Epoch [179/300] Training [42/62] Loss: 0.05228 
Epoch [179/300] Training [43/62] Loss: 0.05754 
Epoch [179/300] Training [44/62] Loss: 0.06015 
Epoch [179/300] Training [45/62] Loss: 0.11550 
Epoch [179/300] Training [46/62] Loss: 0.07671 
Epoch [179/300] Training [47/62] Loss: 0.06041 
Epoch [179/300] Training [48/62] Loss: 0.06903 
Epoch [179/300] Training [49/62] Loss: 0.05612 
Epoch [179/300] Training [50/62] Loss: 0.08115 
Epoch [179/300] Training [51/62] Loss: 0.07272 
Epoch [179/300] Training [52/62] Loss: 0.05745 
Epoch [179/300] Training [53/62] Loss: 0.06534 
Epoch [179/300] Training [54/62] Loss: 0.04831 
Epoch [179/300] Training [55/62] Loss: 0.06504 
Epoch [179/300] Training [56/62] Loss: 0.05178 
Epoch [179/300] Training [57/62] Loss: 0.03777 
Epoch [179/300] Training [58/62] Loss: 0.04954 
Epoch [179/300] Training [59/62] Loss: 0.15031 
Epoch [179/300] Training [60/62] Loss: 0.07068 
Epoch [179/300] Training [61/62] Loss: 0.07893 
Epoch [179/300] Training [62/62] Loss: 0.05712 
Epoch [179/300] Training metric {'Train/mean dice_metric': 0.9483811259269714, 'Train/mean miou_metric': 0.9068718552589417, 'Train/mean f1': 0.9554999470710754, 'Train/mean precision': 0.950775682926178, 'Train/mean recall': 0.960271418094635, 'Train/mean hd95_metric': 8.549833297729492}
Epoch [179/300] Validation [1/16] Loss: 0.17247  focal_loss 0.08325  dice_loss 0.08922 
Epoch [179/300] Validation [2/16] Loss: 0.34049  focal_loss 0.10267  dice_loss 0.23782 
Epoch [179/300] Validation [3/16] Loss: 0.57848  focal_loss 0.30361  dice_loss 0.27487 
Epoch [179/300] Validation [4/16] Loss: 0.24546  focal_loss 0.11989  dice_loss 0.12558 
Epoch [179/300] Validation [5/16] Loss: 0.32517  focal_loss 0.11035  dice_loss 0.21481 
Epoch [179/300] Validation [6/16] Loss: 0.21177  focal_loss 0.04375  dice_loss 0.16802 
Epoch [179/300] Validation [7/16] Loss: 0.38246  focal_loss 0.14126  dice_loss 0.24119 
Epoch [179/300] Validation [8/16] Loss: 0.24689  focal_loss 0.06746  dice_loss 0.17944 
Epoch [179/300] Validation [9/16] Loss: 0.23805  focal_loss 0.07946  dice_loss 0.15859 
Epoch [179/300] Validation [10/16] Loss: 0.44019  focal_loss 0.17130  dice_loss 0.26889 
Epoch [179/300] Validation [11/16] Loss: 0.21462  focal_loss 0.07622  dice_loss 0.13840 
Epoch [179/300] Validation [12/16] Loss: 0.32983  focal_loss 0.09556  dice_loss 0.23427 
Epoch [179/300] Validation [13/16] Loss: 0.42820  focal_loss 0.18985  dice_loss 0.23835 
Epoch [179/300] Validation [14/16] Loss: 0.45087  focal_loss 0.16393  dice_loss 0.28694 
Epoch [179/300] Validation [15/16] Loss: 0.11630  focal_loss 0.04100  dice_loss 0.07530 
Epoch [179/300] Validation [16/16] Loss: 0.05931  focal_loss 0.01520  dice_loss 0.04412 
Epoch [179/300] Validation metric {'Val/mean dice_metric': 0.9212692379951477, 'Val/mean miou_metric': 0.8714902997016907, 'Val/mean f1': 0.930837869644165, 'Val/mean precision': 0.9277053475379944, 'Val/mean recall': 0.9339916706085205, 'Val/mean hd95_metric': 15.292932510375977}
Cheakpoint...
Epoch [179/300] best acc:tensor([0.9239], device='cuda:0'), Now : mean acc: tensor([0.9213], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9212692379951477, 'Val/mean miou_metric': 0.8714902997016907, 'Val/mean f1': 0.930837869644165, 'Val/mean precision': 0.9277053475379944, 'Val/mean recall': 0.9339916706085205, 'Val/mean hd95_metric': 15.292932510375977}
Epoch [180/300] Training [1/62] Loss: 0.06670 
Epoch [180/300] Training [2/62] Loss: 0.06259 
Epoch [180/300] Training [3/62] Loss: 0.07417 
Epoch [180/300] Training [4/62] Loss: 0.07245 
Epoch [180/300] Training [5/62] Loss: 0.06541 
Epoch [180/300] Training [6/62] Loss: 0.07845 
Epoch [180/300] Training [7/62] Loss: 0.12607 
Epoch [180/300] Training [8/62] Loss: 0.04788 
Epoch [180/300] Training [9/62] Loss: 0.07561 
Epoch [180/300] Training [10/62] Loss: 0.10591 
Epoch [180/300] Training [11/62] Loss: 0.10560 
Epoch [180/300] Training [12/62] Loss: 0.06219 
Epoch [180/300] Training [13/62] Loss: 0.04301 
Epoch [180/300] Training [14/62] Loss: 0.07806 
Epoch [180/300] Training [15/62] Loss: 0.13677 
Epoch [180/300] Training [16/62] Loss: 0.04867 
Epoch [180/300] Training [17/62] Loss: 0.05457 
Epoch [180/300] Training [18/62] Loss: 0.06318 
Epoch [180/300] Training [19/62] Loss: 0.07426 
Epoch [180/300] Training [20/62] Loss: 0.04930 
Epoch [180/300] Training [21/62] Loss: 0.05788 
Epoch [180/300] Training [22/62] Loss: 0.05999 
Epoch [180/300] Training [23/62] Loss: 0.09438 
Epoch [180/300] Training [24/62] Loss: 0.06334 
Epoch [180/300] Training [25/62] Loss: 0.15258 
Epoch [180/300] Training [26/62] Loss: 0.05762 
Epoch [180/300] Training [27/62] Loss: 0.05114 
Epoch [180/300] Training [28/62] Loss: 0.06785 
Epoch [180/300] Training [29/62] Loss: 0.05033 
Epoch [180/300] Training [30/62] Loss: 0.06209 
Epoch [180/300] Training [31/62] Loss: 0.09132 
Epoch [180/300] Training [32/62] Loss: 0.06217 
Epoch [180/300] Training [33/62] Loss: 0.07572 
Epoch [180/300] Training [34/62] Loss: 0.11957 
Epoch [180/300] Training [35/62] Loss: 0.14497 
Epoch [180/300] Training [36/62] Loss: 0.06174 
Epoch [180/300] Training [37/62] Loss: 0.09596 
Epoch [180/300] Training [38/62] Loss: 0.10320 
Epoch [180/300] Training [39/62] Loss: 0.05269 
Epoch [180/300] Training [40/62] Loss: 0.08268 
Epoch [180/300] Training [41/62] Loss: 0.06020 
Epoch [180/300] Training [42/62] Loss: 0.06160 
Epoch [180/300] Training [43/62] Loss: 0.06983 
Epoch [180/300] Training [44/62] Loss: 0.10578 
Epoch [180/300] Training [45/62] Loss: 0.06090 
Epoch [180/300] Training [46/62] Loss: 0.05933 
Epoch [180/300] Training [47/62] Loss: 0.05531 
Epoch [180/300] Training [48/62] Loss: 0.15419 
Epoch [180/300] Training [49/62] Loss: 0.07742 
Epoch [180/300] Training [50/62] Loss: 0.08136 
Epoch [180/300] Training [51/62] Loss: 0.08106 
Epoch [180/300] Training [52/62] Loss: 0.07200 
Epoch [180/300] Training [53/62] Loss: 0.06819 
Epoch [180/300] Training [54/62] Loss: 0.06134 
Epoch [180/300] Training [55/62] Loss: 0.05353 
Epoch [180/300] Training [56/62] Loss: 0.06475 
Epoch [180/300] Training [57/62] Loss: 0.09577 
Epoch [180/300] Training [58/62] Loss: 0.05344 
Epoch [180/300] Training [59/62] Loss: 0.04965 
Epoch [180/300] Training [60/62] Loss: 0.13041 
Epoch [180/300] Training [61/62] Loss: 0.05095 
Epoch [180/300] Training [62/62] Loss: 0.08538 
Epoch [180/300] Training metric {'Train/mean dice_metric': 0.9467778205871582, 'Train/mean miou_metric': 0.9030719995498657, 'Train/mean f1': 0.9526444673538208, 'Train/mean precision': 0.9479079842567444, 'Train/mean recall': 0.9574283957481384, 'Train/mean hd95_metric': 8.549490928649902}
Epoch [180/300] Validation [1/16] Loss: 0.11918  focal_loss 0.04475  dice_loss 0.07443 
Epoch [180/300] Validation [2/16] Loss: 0.42532  focal_loss 0.19557  dice_loss 0.22975 
Epoch [180/300] Validation [3/16] Loss: 0.26925  focal_loss 0.08781  dice_loss 0.18144 
Epoch [180/300] Validation [4/16] Loss: 0.16918  focal_loss 0.06611  dice_loss 0.10306 
Epoch [180/300] Validation [5/16] Loss: 0.38560  focal_loss 0.14542  dice_loss 0.24018 
Epoch [180/300] Validation [6/16] Loss: 0.22605  focal_loss 0.06453  dice_loss 0.16152 
Epoch [180/300] Validation [7/16] Loss: 0.20869  focal_loss 0.06909  dice_loss 0.13960 
Epoch [180/300] Validation [8/16] Loss: 0.32826  focal_loss 0.10811  dice_loss 0.22015 
Epoch [180/300] Validation [9/16] Loss: 0.19136  focal_loss 0.07114  dice_loss 0.12022 
Epoch [180/300] Validation [10/16] Loss: 0.68641  focal_loss 0.31556  dice_loss 0.37085 
Epoch [180/300] Validation [11/16] Loss: 0.21411  focal_loss 0.04573  dice_loss 0.16839 
Epoch [180/300] Validation [12/16] Loss: 0.32277  focal_loss 0.09952  dice_loss 0.22325 
Epoch [180/300] Validation [13/16] Loss: 0.17062  focal_loss 0.03984  dice_loss 0.13078 
Epoch [180/300] Validation [14/16] Loss: 0.67426  focal_loss 0.27054  dice_loss 0.40372 
Epoch [180/300] Validation [15/16] Loss: 0.12423  focal_loss 0.03405  dice_loss 0.09018 
Epoch [180/300] Validation [16/16] Loss: 0.06486  focal_loss 0.01748  dice_loss 0.04738 
Epoch [180/300] Validation metric {'Val/mean dice_metric': 0.9210899472236633, 'Val/mean miou_metric': 0.8710552453994751, 'Val/mean f1': 0.9288628697395325, 'Val/mean precision': 0.9184199571609497, 'Val/mean recall': 0.9395459890365601, 'Val/mean hd95_metric': 15.424667358398438}
Cheakpoint...
Epoch [180/300] best acc:tensor([0.9239], device='cuda:0'), Now : mean acc: tensor([0.9211], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9210899472236633, 'Val/mean miou_metric': 0.8710552453994751, 'Val/mean f1': 0.9288628697395325, 'Val/mean precision': 0.9184199571609497, 'Val/mean recall': 0.9395459890365601, 'Val/mean hd95_metric': 15.424667358398438}
Epoch [181/300] Training [1/62] Loss: 0.11310 
Epoch [181/300] Training [2/62] Loss: 0.14708 
Epoch [181/300] Training [3/62] Loss: 0.06812 
Epoch [181/300] Training [4/62] Loss: 0.05636 
Epoch [181/300] Training [5/62] Loss: 0.05843 
Epoch [181/300] Training [6/62] Loss: 0.05681 
Epoch [181/300] Training [7/62] Loss: 0.08194 
Epoch [181/300] Training [8/62] Loss: 0.08789 
Epoch [181/300] Training [9/62] Loss: 0.08676 
Epoch [181/300] Training [10/62] Loss: 0.06793 
Epoch [181/300] Training [11/62] Loss: 0.04681 
Epoch [181/300] Training [12/62] Loss: 0.08156 
Epoch [181/300] Training [13/62] Loss: 0.08050 
Epoch [181/300] Training [14/62] Loss: 0.13845 
Epoch [181/300] Training [15/62] Loss: 0.05986 
Epoch [181/300] Training [16/62] Loss: 0.04863 
Epoch [181/300] Training [17/62] Loss: 0.08569 
Epoch [181/300] Training [18/62] Loss: 0.04929 
Epoch [181/300] Training [19/62] Loss: 0.07456 
Epoch [181/300] Training [20/62] Loss: 0.18820 
Epoch [181/300] Training [21/62] Loss: 0.04699 
Epoch [181/300] Training [22/62] Loss: 0.06578 
Epoch [181/300] Training [23/62] Loss: 0.06352 
Epoch [181/300] Training [24/62] Loss: 0.11232 
Epoch [181/300] Training [25/62] Loss: 0.15580 
Epoch [181/300] Training [26/62] Loss: 0.07124 
Epoch [181/300] Training [27/62] Loss: 0.07922 
Epoch [181/300] Training [28/62] Loss: 0.16474 
Epoch [181/300] Training [29/62] Loss: 0.06284 
Epoch [181/300] Training [30/62] Loss: 0.06209 
Epoch [181/300] Training [31/62] Loss: 0.13088 
Epoch [181/300] Training [32/62] Loss: 0.13335 
Epoch [181/300] Training [33/62] Loss: 0.06845 
Epoch [181/300] Training [34/62] Loss: 0.04883 
Epoch [181/300] Training [35/62] Loss: 0.06494 
Epoch [181/300] Training [36/62] Loss: 0.05293 
Epoch [181/300] Training [37/62] Loss: 0.05617 
Epoch [181/300] Training [38/62] Loss: 0.12849 
Epoch [181/300] Training [39/62] Loss: 0.13807 
Epoch [181/300] Training [40/62] Loss: 0.07906 
Epoch [181/300] Training [41/62] Loss: 0.04910 
Epoch [181/300] Training [42/62] Loss: 0.07017 
Epoch [181/300] Training [43/62] Loss: 0.04330 
Epoch [181/300] Training [44/62] Loss: 0.11091 
Epoch [181/300] Training [45/62] Loss: 0.05315 
Epoch [181/300] Training [46/62] Loss: 0.05909 
Epoch [181/300] Training [47/62] Loss: 0.09437 
Epoch [181/300] Training [48/62] Loss: 0.07853 
Epoch [181/300] Training [49/62] Loss: 0.06609 
Epoch [181/300] Training [50/62] Loss: 0.09104 
Epoch [181/300] Training [51/62] Loss: 0.04704 
Epoch [181/300] Training [52/62] Loss: 0.12408 
Epoch [181/300] Training [53/62] Loss: 0.05493 
Epoch [181/300] Training [54/62] Loss: 0.06945 
Epoch [181/300] Training [55/62] Loss: 0.15834 
Epoch [181/300] Training [56/62] Loss: 0.07874 
Epoch [181/300] Training [57/62] Loss: 0.08469 
Epoch [181/300] Training [58/62] Loss: 0.19201 
Epoch [181/300] Training [59/62] Loss: 0.06343 
Epoch [181/300] Training [60/62] Loss: 0.10715 
Epoch [181/300] Training [61/62] Loss: 0.09326 
Epoch [181/300] Training [62/62] Loss: 0.05461 
Epoch [181/300] Training metric {'Train/mean dice_metric': 0.9391575455665588, 'Train/mean miou_metric': 0.8946988582611084, 'Train/mean f1': 0.950076162815094, 'Train/mean precision': 0.9436814188957214, 'Train/mean recall': 0.956558108329773, 'Train/mean hd95_metric': 11.451976776123047}
Epoch [181/300] Validation [1/16] Loss: 0.15018  focal_loss 0.04702  dice_loss 0.10316 
Epoch [181/300] Validation [2/16] Loss: 0.47016  focal_loss 0.17462  dice_loss 0.29554 
Epoch [181/300] Validation [3/16] Loss: 0.38008  focal_loss 0.12963  dice_loss 0.25045 
Epoch [181/300] Validation [4/16] Loss: 0.24054  focal_loss 0.10248  dice_loss 0.13806 
Epoch [181/300] Validation [5/16] Loss: 0.30951  focal_loss 0.08929  dice_loss 0.22021 
Epoch [181/300] Validation [6/16] Loss: 0.22446  focal_loss 0.05070  dice_loss 0.17376 
Epoch [181/300] Validation [7/16] Loss: 0.20391  focal_loss 0.07830  dice_loss 0.12561 
Epoch [181/300] Validation [8/16] Loss: 0.56447  focal_loss 0.21744  dice_loss 0.34703 
Epoch [181/300] Validation [9/16] Loss: 0.13614  focal_loss 0.04700  dice_loss 0.08914 
Epoch [181/300] Validation [10/16] Loss: 0.35909  focal_loss 0.14834  dice_loss 0.21075 
Epoch [181/300] Validation [11/16] Loss: 0.17603  focal_loss 0.05999  dice_loss 0.11604 
Epoch [181/300] Validation [12/16] Loss: 0.28171  focal_loss 0.05593  dice_loss 0.22578 
Epoch [181/300] Validation [13/16] Loss: 0.35432  focal_loss 0.13249  dice_loss 0.22183 
Epoch [181/300] Validation [14/16] Loss: 0.61872  focal_loss 0.23951  dice_loss 0.37921 
Epoch [181/300] Validation [15/16] Loss: 0.12713  focal_loss 0.04859  dice_loss 0.07854 
Epoch [181/300] Validation [16/16] Loss: 0.04646  focal_loss 0.00987  dice_loss 0.03660 
Epoch [181/300] Validation metric {'Val/mean dice_metric': 0.9137580990791321, 'Val/mean miou_metric': 0.8621919751167297, 'Val/mean f1': 0.928676187992096, 'Val/mean precision': 0.92845219373703, 'Val/mean recall': 0.9289003014564514, 'Val/mean hd95_metric': 17.248130798339844}
Cheakpoint...
Epoch [181/300] best acc:tensor([0.9239], device='cuda:0'), Now : mean acc: tensor([0.9138], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9137580990791321, 'Val/mean miou_metric': 0.8621919751167297, 'Val/mean f1': 0.928676187992096, 'Val/mean precision': 0.92845219373703, 'Val/mean recall': 0.9289003014564514, 'Val/mean hd95_metric': 17.248130798339844}
Epoch [182/300] Training [1/62] Loss: 0.05469 
Epoch [182/300] Training [2/62] Loss: 0.06512 
Epoch [182/300] Training [3/62] Loss: 0.06522 
Epoch [182/300] Training [4/62] Loss: 0.08046 
Epoch [182/300] Training [5/62] Loss: 0.06972 
Epoch [182/300] Training [6/62] Loss: 0.04467 
Epoch [182/300] Training [7/62] Loss: 0.07458 
Epoch [182/300] Training [8/62] Loss: 0.06213 
Epoch [182/300] Training [9/62] Loss: 0.06612 
Epoch [182/300] Training [10/62] Loss: 0.10406 
Epoch [182/300] Training [11/62] Loss: 0.05175 
Epoch [182/300] Training [12/62] Loss: 0.10389 
Epoch [182/300] Training [13/62] Loss: 0.06714 
Epoch [182/300] Training [14/62] Loss: 0.05236 
Epoch [182/300] Training [15/62] Loss: 0.04855 
Epoch [182/300] Training [16/62] Loss: 0.05965 
Epoch [182/300] Training [17/62] Loss: 0.04713 
Epoch [182/300] Training [18/62] Loss: 0.12022 
Epoch [182/300] Training [19/62] Loss: 0.06409 
Epoch [182/300] Training [20/62] Loss: 0.08786 
Epoch [182/300] Training [21/62] Loss: 0.07169 
Epoch [182/300] Training [22/62] Loss: 0.05013 
Epoch [182/300] Training [23/62] Loss: 0.06134 
Epoch [182/300] Training [24/62] Loss: 0.11256 
Epoch [182/300] Training [25/62] Loss: 0.07449 
Epoch [182/300] Training [26/62] Loss: 0.06074 
Epoch [182/300] Training [27/62] Loss: 0.09975 
Epoch [182/300] Training [28/62] Loss: 0.05097 
Epoch [182/300] Training [29/62] Loss: 0.07491 
Epoch [182/300] Training [30/62] Loss: 0.09793 
Epoch [182/300] Training [31/62] Loss: 0.13282 
Epoch [182/300] Training [32/62] Loss: 0.05752 
Epoch [182/300] Training [33/62] Loss: 0.07179 
Epoch [182/300] Training [34/62] Loss: 0.07157 
Epoch [182/300] Training [35/62] Loss: 0.04169 
Epoch [182/300] Training [36/62] Loss: 0.05238 
Epoch [182/300] Training [37/62] Loss: 0.05303 
Epoch [182/300] Training [38/62] Loss: 0.10546 
Epoch [182/300] Training [39/62] Loss: 0.09481 
Epoch [182/300] Training [40/62] Loss: 0.06113 
Epoch [182/300] Training [41/62] Loss: 0.08423 
Epoch [182/300] Training [42/62] Loss: 0.14558 
Epoch [182/300] Training [43/62] Loss: 0.08186 
Epoch [182/300] Training [44/62] Loss: 0.06127 
Epoch [182/300] Training [45/62] Loss: 0.07974 
Epoch [182/300] Training [46/62] Loss: 0.08511 
Epoch [182/300] Training [47/62] Loss: 0.07193 
Epoch [182/300] Training [48/62] Loss: 0.08950 
Epoch [182/300] Training [49/62] Loss: 0.25144 
Epoch [182/300] Training [50/62] Loss: 0.06792 
Epoch [182/300] Training [51/62] Loss: 0.11473 
Epoch [182/300] Training [52/62] Loss: 0.06648 
Epoch [182/300] Training [53/62] Loss: 0.07222 
Epoch [182/300] Training [54/62] Loss: 0.05173 
Epoch [182/300] Training [55/62] Loss: 0.08619 
Epoch [182/300] Training [56/62] Loss: 0.06240 
Epoch [182/300] Training [57/62] Loss: 0.04106 
Epoch [182/300] Training [58/62] Loss: 0.06680 
Epoch [182/300] Training [59/62] Loss: 0.09673 
Epoch [182/300] Training [60/62] Loss: 0.06921 
Epoch [182/300] Training [61/62] Loss: 0.06502 
Epoch [182/300] Training [62/62] Loss: 0.04396 
Epoch [182/300] Training metric {'Train/mean dice_metric': 0.9459373950958252, 'Train/mean miou_metric': 0.9030812382698059, 'Train/mean f1': 0.953558623790741, 'Train/mean precision': 0.9477757215499878, 'Train/mean recall': 0.9594124555587769, 'Train/mean hd95_metric': 9.287015914916992}
Epoch [182/300] Validation [1/16] Loss: 0.11149  focal_loss 0.04174  dice_loss 0.06976 
Epoch [182/300] Validation [2/16] Loss: 0.32002  focal_loss 0.15944  dice_loss 0.16058 
Epoch [182/300] Validation [3/16] Loss: 0.68287  focal_loss 0.40663  dice_loss 0.27624 
Epoch [182/300] Validation [4/16] Loss: 0.11630  focal_loss 0.03298  dice_loss 0.08332 
Epoch [182/300] Validation [5/16] Loss: 0.39611  focal_loss 0.14823  dice_loss 0.24787 
Epoch [182/300] Validation [6/16] Loss: 0.21268  focal_loss 0.04620  dice_loss 0.16648 
Epoch [182/300] Validation [7/16] Loss: 0.37922  focal_loss 0.17535  dice_loss 0.20387 
Epoch [182/300] Validation [8/16] Loss: 0.30065  focal_loss 0.09420  dice_loss 0.20645 
Epoch [182/300] Validation [9/16] Loss: 0.17956  focal_loss 0.07810  dice_loss 0.10146 
Epoch [182/300] Validation [10/16] Loss: 0.60800  focal_loss 0.27783  dice_loss 0.33017 
Epoch [182/300] Validation [11/16] Loss: 0.13465  focal_loss 0.04048  dice_loss 0.09417 
Epoch [182/300] Validation [12/16] Loss: 0.34235  focal_loss 0.12152  dice_loss 0.22084 
Epoch [182/300] Validation [13/16] Loss: 0.40717  focal_loss 0.16541  dice_loss 0.24176 
Epoch [182/300] Validation [14/16] Loss: 0.56707  focal_loss 0.19716  dice_loss 0.36991 
Epoch [182/300] Validation [15/16] Loss: 0.11047  focal_loss 0.03492  dice_loss 0.07556 
Epoch [182/300] Validation [16/16] Loss: 0.07496  focal_loss 0.02846  dice_loss 0.04649 
Epoch [182/300] Validation metric {'Val/mean dice_metric': 0.9206332564353943, 'Val/mean miou_metric': 0.8707371354103088, 'Val/mean f1': 0.9289822578430176, 'Val/mean precision': 0.9225844144821167, 'Val/mean recall': 0.9354695677757263, 'Val/mean hd95_metric': 16.114465713500977}
Cheakpoint...
Epoch [182/300] best acc:tensor([0.9239], device='cuda:0'), Now : mean acc: tensor([0.9206], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9206332564353943, 'Val/mean miou_metric': 0.8707371354103088, 'Val/mean f1': 0.9289822578430176, 'Val/mean precision': 0.9225844144821167, 'Val/mean recall': 0.9354695677757263, 'Val/mean hd95_metric': 16.114465713500977}
Epoch [183/300] Training [1/62] Loss: 0.09346 
Epoch [183/300] Training [2/62] Loss: 0.06054 
Epoch [183/300] Training [3/62] Loss: 0.05794 
Epoch [183/300] Training [4/62] Loss: 0.05282 
Epoch [183/300] Training [5/62] Loss: 0.07220 
Epoch [183/300] Training [6/62] Loss: 0.06244 
Epoch [183/300] Training [7/62] Loss: 0.07777 
Epoch [183/300] Training [8/62] Loss: 0.05779 
Epoch [183/300] Training [9/62] Loss: 0.05631 
Epoch [183/300] Training [10/62] Loss: 0.05834 
Epoch [183/300] Training [11/62] Loss: 0.16009 
Epoch [183/300] Training [12/62] Loss: 0.05949 
Epoch [183/300] Training [13/62] Loss: 0.05629 
Epoch [183/300] Training [14/62] Loss: 0.22535 
Epoch [183/300] Training [15/62] Loss: 0.07853 
Epoch [183/300] Training [16/62] Loss: 0.06302 
Epoch [183/300] Training [17/62] Loss: 0.06187 
Epoch [183/300] Training [18/62] Loss: 0.06984 
Epoch [183/300] Training [19/62] Loss: 0.08835 
Epoch [183/300] Training [20/62] Loss: 0.05699 
Epoch [183/300] Training [21/62] Loss: 0.04805 
Epoch [183/300] Training [22/62] Loss: 0.09624 
Epoch [183/300] Training [23/62] Loss: 0.06802 
Epoch [183/300] Training [24/62] Loss: 0.04809 
Epoch [183/300] Training [25/62] Loss: 0.06889 
Epoch [183/300] Training [26/62] Loss: 0.05418 
Epoch [183/300] Training [27/62] Loss: 0.06036 
Epoch [183/300] Training [28/62] Loss: 0.08076 
Epoch [183/300] Training [29/62] Loss: 0.09282 
Epoch [183/300] Training [30/62] Loss: 0.09113 
Epoch [183/300] Training [31/62] Loss: 0.04512 
Epoch [183/300] Training [32/62] Loss: 0.06878 
Epoch [183/300] Training [33/62] Loss: 0.05642 
Epoch [183/300] Training [34/62] Loss: 0.06230 
Epoch [183/300] Training [35/62] Loss: 0.06983 
Epoch [183/300] Training [36/62] Loss: 0.10516 
Epoch [183/300] Training [37/62] Loss: 0.07480 
Epoch [183/300] Training [38/62] Loss: 0.08619 
Epoch [183/300] Training [39/62] Loss: 0.05985 
Epoch [183/300] Training [40/62] Loss: 0.05359 
Epoch [183/300] Training [41/62] Loss: 0.05149 
Epoch [183/300] Training [42/62] Loss: 0.05371 
Epoch [183/300] Training [43/62] Loss: 0.04844 
Epoch [183/300] Training [44/62] Loss: 0.14185 
Epoch [183/300] Training [45/62] Loss: 0.11639 
Epoch [183/300] Training [46/62] Loss: 0.05675 
Epoch [183/300] Training [47/62] Loss: 0.08753 
Epoch [183/300] Training [48/62] Loss: 0.05719 
Epoch [183/300] Training [49/62] Loss: 0.10274 
Epoch [183/300] Training [50/62] Loss: 0.06648 
Epoch [183/300] Training [51/62] Loss: 0.04465 
Epoch [183/300] Training [52/62] Loss: 0.09221 
Epoch [183/300] Training [53/62] Loss: 0.06511 
Epoch [183/300] Training [54/62] Loss: 0.05951 
Epoch [183/300] Training [55/62] Loss: 0.08518 
Epoch [183/300] Training [56/62] Loss: 0.08085 
Epoch [183/300] Training [57/62] Loss: 0.06280 
Epoch [183/300] Training [58/62] Loss: 0.06570 
Epoch [183/300] Training [59/62] Loss: 0.05643 
Epoch [183/300] Training [60/62] Loss: 0.07043 
Epoch [183/300] Training [61/62] Loss: 0.08271 
Epoch [183/300] Training [62/62] Loss: 0.04335 
Epoch [183/300] Training metric {'Train/mean dice_metric': 0.948832094669342, 'Train/mean miou_metric': 0.9065759181976318, 'Train/mean f1': 0.9559077024459839, 'Train/mean precision': 0.9531279802322388, 'Train/mean recall': 0.9587037563323975, 'Train/mean hd95_metric': 9.379354476928711}
Epoch [183/300] Validation [1/16] Loss: 0.21016  focal_loss 0.08999  dice_loss 0.12017 
Epoch [183/300] Validation [2/16] Loss: 0.35841  focal_loss 0.14549  dice_loss 0.21292 
Epoch [183/300] Validation [3/16] Loss: 0.44308  focal_loss 0.17727  dice_loss 0.26581 
Epoch [183/300] Validation [4/16] Loss: 0.36902  focal_loss 0.16114  dice_loss 0.20788 
Epoch [183/300] Validation [5/16] Loss: 0.21210  focal_loss 0.04517  dice_loss 0.16693 
Epoch [183/300] Validation [6/16] Loss: 0.17130  focal_loss 0.03159  dice_loss 0.13971 
Epoch [183/300] Validation [7/16] Loss: 0.22497  focal_loss 0.08095  dice_loss 0.14401 
Epoch [183/300] Validation [8/16] Loss: 0.50667  focal_loss 0.17080  dice_loss 0.33586 
Epoch [183/300] Validation [9/16] Loss: 0.19726  focal_loss 0.07519  dice_loss 0.12207 
Epoch [183/300] Validation [10/16] Loss: 0.54956  focal_loss 0.22362  dice_loss 0.32594 
Epoch [183/300] Validation [11/16] Loss: 0.10950  focal_loss 0.02536  dice_loss 0.08413 
Epoch [183/300] Validation [12/16] Loss: 0.23516  focal_loss 0.04712  dice_loss 0.18804 
Epoch [183/300] Validation [13/16] Loss: 0.22160  focal_loss 0.06039  dice_loss 0.16121 
Epoch [183/300] Validation [14/16] Loss: 0.34416  focal_loss 0.11965  dice_loss 0.22451 
Epoch [183/300] Validation [15/16] Loss: 0.14968  focal_loss 0.04905  dice_loss 0.10063 
Epoch [183/300] Validation [16/16] Loss: 0.04642  focal_loss 0.01048  dice_loss 0.03594 
Epoch [183/300] Validation metric {'Val/mean dice_metric': 0.9241771697998047, 'Val/mean miou_metric': 0.8735647797584534, 'Val/mean f1': 0.9325230717658997, 'Val/mean precision': 0.9315836429595947, 'Val/mean recall': 0.933464527130127, 'Val/mean hd95_metric': 14.990862846374512}
Cheakpoint...
Epoch [183/300] best acc:tensor([0.9242], device='cuda:0'), Now : mean acc: tensor([0.9242], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9241771697998047, 'Val/mean miou_metric': 0.8735647797584534, 'Val/mean f1': 0.9325230717658997, 'Val/mean precision': 0.9315836429595947, 'Val/mean recall': 0.933464527130127, 'Val/mean hd95_metric': 14.990862846374512}
Epoch [184/300] Training [1/62] Loss: 0.10015 
Epoch [184/300] Training [2/62] Loss: 0.06785 
Epoch [184/300] Training [3/62] Loss: 0.07507 
Epoch [184/300] Training [4/62] Loss: 0.08410 
Epoch [184/300] Training [5/62] Loss: 0.06394 
Epoch [184/300] Training [6/62] Loss: 0.18330 
Epoch [184/300] Training [7/62] Loss: 0.09832 
Epoch [184/300] Training [8/62] Loss: 0.05898 
Epoch [184/300] Training [9/62] Loss: 0.05306 
Epoch [184/300] Training [10/62] Loss: 0.14145 
Epoch [184/300] Training [11/62] Loss: 0.06809 
Epoch [184/300] Training [12/62] Loss: 0.07502 
Epoch [184/300] Training [13/62] Loss: 0.04198 
Epoch [184/300] Training [14/62] Loss: 0.07996 
Epoch [184/300] Training [15/62] Loss: 0.06364 
Epoch [184/300] Training [16/62] Loss: 0.09029 
Epoch [184/300] Training [17/62] Loss: 0.05566 
Epoch [184/300] Training [18/62] Loss: 0.10007 
Epoch [184/300] Training [19/62] Loss: 0.06995 
Epoch [184/300] Training [20/62] Loss: 0.10651 
Epoch [184/300] Training [21/62] Loss: 0.14290 
Epoch [184/300] Training [22/62] Loss: 0.04978 
Epoch [184/300] Training [23/62] Loss: 0.07162 
Epoch [184/300] Training [24/62] Loss: 0.04999 
Epoch [184/300] Training [25/62] Loss: 0.04363 
Epoch [184/300] Training [26/62] Loss: 0.05343 
Epoch [184/300] Training [27/62] Loss: 0.10235 
Epoch [184/300] Training [28/62] Loss: 0.13493 
Epoch [184/300] Training [29/62] Loss: 0.10068 
Epoch [184/300] Training [30/62] Loss: 0.06468 
Epoch [184/300] Training [31/62] Loss: 0.10406 
Epoch [184/300] Training [32/62] Loss: 0.06126 
Epoch [184/300] Training [33/62] Loss: 0.05339 
Epoch [184/300] Training [34/62] Loss: 0.07521 
Epoch [184/300] Training [35/62] Loss: 0.03818 
Epoch [184/300] Training [36/62] Loss: 0.05764 
Epoch [184/300] Training [37/62] Loss: 0.05686 
Epoch [184/300] Training [38/62] Loss: 0.13201 
Epoch [184/300] Training [39/62] Loss: 0.05674 
Epoch [184/300] Training [40/62] Loss: 0.07992 
Epoch [184/300] Training [41/62] Loss: 0.07225 
Epoch [184/300] Training [42/62] Loss: 0.05735 
Epoch [184/300] Training [43/62] Loss: 0.03859 
Epoch [184/300] Training [44/62] Loss: 0.12582 
Epoch [184/300] Training [45/62] Loss: 0.05344 
Epoch [184/300] Training [46/62] Loss: 0.06100 
Epoch [184/300] Training [47/62] Loss: 0.05789 
Epoch [184/300] Training [48/62] Loss: 0.12863 
Epoch [184/300] Training [49/62] Loss: 0.05304 
Epoch [184/300] Training [50/62] Loss: 0.16330 
Epoch [184/300] Training [51/62] Loss: 0.06608 
Epoch [184/300] Training [52/62] Loss: 0.07775 
Epoch [184/300] Training [53/62] Loss: 0.08760 
Epoch [184/300] Training [54/62] Loss: 0.06569 
Epoch [184/300] Training [55/62] Loss: 0.11440 
Epoch [184/300] Training [56/62] Loss: 0.11352 
Epoch [184/300] Training [57/62] Loss: 0.08039 
Epoch [184/300] Training [58/62] Loss: 0.05520 
Epoch [184/300] Training [59/62] Loss: 0.07457 
Epoch [184/300] Training [60/62] Loss: 0.04589 
Epoch [184/300] Training [61/62] Loss: 0.07834 
Epoch [184/300] Training [62/62] Loss: 0.05346 
Epoch [184/300] Training metric {'Train/mean dice_metric': 0.9439732432365417, 'Train/mean miou_metric': 0.8998761773109436, 'Train/mean f1': 0.952217698097229, 'Train/mean precision': 0.946982741355896, 'Train/mean recall': 0.9575106501579285, 'Train/mean hd95_metric': 9.950089454650879}
Epoch [184/300] Validation [1/16] Loss: 0.11775  focal_loss 0.04447  dice_loss 0.07327 
Epoch [184/300] Validation [2/16] Loss: 0.31937  focal_loss 0.11096  dice_loss 0.20841 
Epoch [184/300] Validation [3/16] Loss: 0.46972  focal_loss 0.23575  dice_loss 0.23397 
Epoch [184/300] Validation [4/16] Loss: 0.17998  focal_loss 0.06398  dice_loss 0.11600 
Epoch [184/300] Validation [5/16] Loss: 0.46918  focal_loss 0.18596  dice_loss 0.28322 
Epoch [184/300] Validation [6/16] Loss: 0.23484  focal_loss 0.06654  dice_loss 0.16831 
Epoch [184/300] Validation [7/16] Loss: 0.21394  focal_loss 0.08153  dice_loss 0.13241 
Epoch [184/300] Validation [8/16] Loss: 0.33661  focal_loss 0.11504  dice_loss 0.22157 
Epoch [184/300] Validation [9/16] Loss: 0.17002  focal_loss 0.06526  dice_loss 0.10476 
Epoch [184/300] Validation [10/16] Loss: 0.18360  focal_loss 0.05243  dice_loss 0.13117 
Epoch [184/300] Validation [11/16] Loss: 0.21114  focal_loss 0.06533  dice_loss 0.14581 
Epoch [184/300] Validation [12/16] Loss: 0.41218  focal_loss 0.15680  dice_loss 0.25538 
Epoch [184/300] Validation [13/16] Loss: 0.22337  focal_loss 0.07187  dice_loss 0.15151 
Epoch [184/300] Validation [14/16] Loss: 0.43632  focal_loss 0.13199  dice_loss 0.30433 
Epoch [184/300] Validation [15/16] Loss: 0.06938  focal_loss 0.01535  dice_loss 0.05403 
Epoch [184/300] Validation [16/16] Loss: 0.03864  focal_loss 0.00813  dice_loss 0.03051 
Epoch [184/300] Validation metric {'Val/mean dice_metric': 0.9227872490882874, 'Val/mean miou_metric': 0.8721451163291931, 'Val/mean f1': 0.9302816390991211, 'Val/mean precision': 0.9201189875602722, 'Val/mean recall': 0.940671443939209, 'Val/mean hd95_metric': 15.177447319030762}
Cheakpoint...
Epoch [184/300] best acc:tensor([0.9242], device='cuda:0'), Now : mean acc: tensor([0.9228], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9227872490882874, 'Val/mean miou_metric': 0.8721451163291931, 'Val/mean f1': 0.9302816390991211, 'Val/mean precision': 0.9201189875602722, 'Val/mean recall': 0.940671443939209, 'Val/mean hd95_metric': 15.177447319030762}
Epoch [185/300] Training [1/62] Loss: 0.04757 
Epoch [185/300] Training [2/62] Loss: 0.04614 
Epoch [185/300] Training [3/62] Loss: 0.06859 
Epoch [185/300] Training [4/62] Loss: 0.05632 
Epoch [185/300] Training [5/62] Loss: 0.06050 
Epoch [185/300] Training [6/62] Loss: 0.06466 
Epoch [185/300] Training [7/62] Loss: 0.05766 
Epoch [185/300] Training [8/62] Loss: 0.07302 
Epoch [185/300] Training [9/62] Loss: 0.06178 
Epoch [185/300] Training [10/62] Loss: 0.10977 
Epoch [185/300] Training [11/62] Loss: 0.06216 
Epoch [185/300] Training [12/62] Loss: 0.07286 
Epoch [185/300] Training [13/62] Loss: 0.04949 
Epoch [185/300] Training [14/62] Loss: 0.08828 
Epoch [185/300] Training [15/62] Loss: 0.10844 
Epoch [185/300] Training [16/62] Loss: 0.08227 
Epoch [185/300] Training [17/62] Loss: 0.07778 
Epoch [185/300] Training [18/62] Loss: 0.10033 
Epoch [185/300] Training [19/62] Loss: 0.12901 
Epoch [185/300] Training [20/62] Loss: 0.05489 
Epoch [185/300] Training [21/62] Loss: 0.08790 
Epoch [185/300] Training [22/62] Loss: 0.12432 
Epoch [185/300] Training [23/62] Loss: 0.06256 
Epoch [185/300] Training [24/62] Loss: 0.07966 
Epoch [185/300] Training [25/62] Loss: 0.05477 
Epoch [185/300] Training [26/62] Loss: 0.15766 
Epoch [185/300] Training [27/62] Loss: 0.05403 
Epoch [185/300] Training [28/62] Loss: 0.07011 
Epoch [185/300] Training [29/62] Loss: 0.13918 
Epoch [185/300] Training [30/62] Loss: 0.09693 
Epoch [185/300] Training [31/62] Loss: 0.04655 
Epoch [185/300] Training [32/62] Loss: 0.05586 
Epoch [185/300] Training [33/62] Loss: 0.07244 
Epoch [185/300] Training [34/62] Loss: 0.08354 
Epoch [185/300] Training [35/62] Loss: 0.05481 
Epoch [185/300] Training [36/62] Loss: 0.06357 
Epoch [185/300] Training [37/62] Loss: 0.05222 
Epoch [185/300] Training [38/62] Loss: 0.06203 
Epoch [185/300] Training [39/62] Loss: 0.05454 
Epoch [185/300] Training [40/62] Loss: 0.05337 
Epoch [185/300] Training [41/62] Loss: 0.08067 
Epoch [185/300] Training [42/62] Loss: 0.12050 
Epoch [185/300] Training [43/62] Loss: 0.04840 
Epoch [185/300] Training [44/62] Loss: 0.11812 
Epoch [185/300] Training [45/62] Loss: 0.08793 
Epoch [185/300] Training [46/62] Loss: 0.04645 
Epoch [185/300] Training [47/62] Loss: 0.07308 
Epoch [185/300] Training [48/62] Loss: 0.07297 
Epoch [185/300] Training [49/62] Loss: 0.06651 
Epoch [185/300] Training [50/62] Loss: 0.07619 
Epoch [185/300] Training [51/62] Loss: 0.06746 
Epoch [185/300] Training [52/62] Loss: 0.08914 
Epoch [185/300] Training [53/62] Loss: 0.06337 
Epoch [185/300] Training [54/62] Loss: 0.06983 
Epoch [185/300] Training [55/62] Loss: 0.10194 
Epoch [185/300] Training [56/62] Loss: 0.06461 
Epoch [185/300] Training [57/62] Loss: 0.08116 
Epoch [185/300] Training [58/62] Loss: 0.06982 
Epoch [185/300] Training [59/62] Loss: 0.12239 
Epoch [185/300] Training [60/62] Loss: 0.04606 
Epoch [185/300] Training [61/62] Loss: 0.12605 
Epoch [185/300] Training [62/62] Loss: 0.03443 
Epoch [185/300] Training metric {'Train/mean dice_metric': 0.9466690421104431, 'Train/mean miou_metric': 0.9030544757843018, 'Train/mean f1': 0.9528543949127197, 'Train/mean precision': 0.9470714330673218, 'Train/mean recall': 0.9587085843086243, 'Train/mean hd95_metric': 8.781878471374512}
Epoch [185/300] Validation [1/16] Loss: 0.49464  focal_loss 0.32343  dice_loss 0.17121 
Epoch [185/300] Validation [2/16] Loss: 0.35411  focal_loss 0.13696  dice_loss 0.21715 
Epoch [185/300] Validation [3/16] Loss: 0.31857  focal_loss 0.12248  dice_loss 0.19609 
Epoch [185/300] Validation [4/16] Loss: 0.14675  focal_loss 0.05719  dice_loss 0.08956 
Epoch [185/300] Validation [5/16] Loss: 0.28651  focal_loss 0.09846  dice_loss 0.18805 
Epoch [185/300] Validation [6/16] Loss: 0.23526  focal_loss 0.05460  dice_loss 0.18066 
Epoch [185/300] Validation [7/16] Loss: 0.15899  focal_loss 0.03707  dice_loss 0.12191 
Epoch [185/300] Validation [8/16] Loss: 0.31881  focal_loss 0.08947  dice_loss 0.22934 
Epoch [185/300] Validation [9/16] Loss: 0.20941  focal_loss 0.07235  dice_loss 0.13706 
Epoch [185/300] Validation [10/16] Loss: 0.35643  focal_loss 0.11216  dice_loss 0.24427 
Epoch [185/300] Validation [11/16] Loss: 0.11666  focal_loss 0.02626  dice_loss 0.09040 
Epoch [185/300] Validation [12/16] Loss: 0.31848  focal_loss 0.07648  dice_loss 0.24199 
Epoch [185/300] Validation [13/16] Loss: 0.17862  focal_loss 0.04623  dice_loss 0.13238 
Epoch [185/300] Validation [14/16] Loss: 0.37750  focal_loss 0.09551  dice_loss 0.28199 
Epoch [185/300] Validation [15/16] Loss: 0.13066  focal_loss 0.03591  dice_loss 0.09475 
Epoch [185/300] Validation [16/16] Loss: 0.03959  focal_loss 0.00813  dice_loss 0.03146 
Epoch [185/300] Validation metric {'Val/mean dice_metric': 0.9244951009750366, 'Val/mean miou_metric': 0.8747917413711548, 'Val/mean f1': 0.9333880543708801, 'Val/mean precision': 0.931403398513794, 'Val/mean recall': 0.9353811740875244, 'Val/mean hd95_metric': 14.58474063873291}
Cheakpoint...
Epoch [185/300] best acc:tensor([0.9245], device='cuda:0'), Now : mean acc: tensor([0.9245], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9244951009750366, 'Val/mean miou_metric': 0.8747917413711548, 'Val/mean f1': 0.9333880543708801, 'Val/mean precision': 0.931403398513794, 'Val/mean recall': 0.9353811740875244, 'Val/mean hd95_metric': 14.58474063873291}
Epoch [186/300] Training [1/62] Loss: 0.06113 
Epoch [186/300] Training [2/62] Loss: 0.08103 
Epoch [186/300] Training [3/62] Loss: 0.05455 
Epoch [186/300] Training [4/62] Loss: 0.08737 
Epoch [186/300] Training [5/62] Loss: 0.13732 
Epoch [186/300] Training [6/62] Loss: 0.07508 
Epoch [186/300] Training [7/62] Loss: 0.11568 
Epoch [186/300] Training [8/62] Loss: 0.22866 
Epoch [186/300] Training [9/62] Loss: 0.05033 
Epoch [186/300] Training [10/62] Loss: 0.11840 
Epoch [186/300] Training [11/62] Loss: 0.08677 
Epoch [186/300] Training [12/62] Loss: 0.05230 
Epoch [186/300] Training [13/62] Loss: 0.05161 
Epoch [186/300] Training [14/62] Loss: 0.06399 
Epoch [186/300] Training [15/62] Loss: 0.04866 
Epoch [186/300] Training [16/62] Loss: 0.05922 
Epoch [186/300] Training [17/62] Loss: 0.06619 
Epoch [186/300] Training [18/62] Loss: 0.07262 
Epoch [186/300] Training [19/62] Loss: 0.15425 
Epoch [186/300] Training [20/62] Loss: 0.07250 
Epoch [186/300] Training [21/62] Loss: 0.04660 
Epoch [186/300] Training [22/62] Loss: 0.05856 
Epoch [186/300] Training [23/62] Loss: 0.05688 
Epoch [186/300] Training [24/62] Loss: 0.04751 
Epoch [186/300] Training [25/62] Loss: 0.04257 
Epoch [186/300] Training [26/62] Loss: 0.08423 
Epoch [186/300] Training [27/62] Loss: 0.08136 
Epoch [186/300] Training [28/62] Loss: 0.06660 
Epoch [186/300] Training [29/62] Loss: 0.11342 
Epoch [186/300] Training [30/62] Loss: 0.08522 
Epoch [186/300] Training [31/62] Loss: 0.05269 
Epoch [186/300] Training [32/62] Loss: 0.03994 
Epoch [186/300] Training [33/62] Loss: 0.07167 
Epoch [186/300] Training [34/62] Loss: 0.08513 
Epoch [186/300] Training [35/62] Loss: 0.12398 
Epoch [186/300] Training [36/62] Loss: 0.03861 
Epoch [186/300] Training [37/62] Loss: 0.05570 
Epoch [186/300] Training [38/62] Loss: 0.06322 
Epoch [186/300] Training [39/62] Loss: 0.04701 
Epoch [186/300] Training [40/62] Loss: 0.09752 
Epoch [186/300] Training [41/62] Loss: 0.06558 
Epoch [186/300] Training [42/62] Loss: 0.12037 
Epoch [186/300] Training [43/62] Loss: 0.05891 
Epoch [186/300] Training [44/62] Loss: 0.07747 
Epoch [186/300] Training [45/62] Loss: 0.07045 
Epoch [186/300] Training [46/62] Loss: 0.11838 
Epoch [186/300] Training [47/62] Loss: 0.05350 
Epoch [186/300] Training [48/62] Loss: 0.05500 
Epoch [186/300] Training [49/62] Loss: 0.06386 
Epoch [186/300] Training [50/62] Loss: 0.10202 
Epoch [186/300] Training [51/62] Loss: 0.05657 
Epoch [186/300] Training [52/62] Loss: 0.06059 
Epoch [186/300] Training [53/62] Loss: 0.07202 
Epoch [186/300] Training [54/62] Loss: 0.05350 
Epoch [186/300] Training [55/62] Loss: 0.15888 
Epoch [186/300] Training [56/62] Loss: 0.07707 
Epoch [186/300] Training [57/62] Loss: 0.04454 
Epoch [186/300] Training [58/62] Loss: 0.07021 
Epoch [186/300] Training [59/62] Loss: 0.05719 
Epoch [186/300] Training [60/62] Loss: 0.05824 
Epoch [186/300] Training [61/62] Loss: 0.04888 
Epoch [186/300] Training [62/62] Loss: 0.04248 
Epoch [186/300] Training metric {'Train/mean dice_metric': 0.9474891424179077, 'Train/mean miou_metric': 0.9047315120697021, 'Train/mean f1': 0.9548590183258057, 'Train/mean precision': 0.9514811635017395, 'Train/mean recall': 0.9582608938217163, 'Train/mean hd95_metric': 8.444305419921875}
Epoch [186/300] Validation [1/16] Loss: 0.22895  focal_loss 0.12066  dice_loss 0.10829 
Epoch [186/300] Validation [2/16] Loss: 0.28360  focal_loss 0.13813  dice_loss 0.14547 
Epoch [186/300] Validation [3/16] Loss: 0.36227  focal_loss 0.15733  dice_loss 0.20495 
Epoch [186/300] Validation [4/16] Loss: 0.15603  focal_loss 0.06210  dice_loss 0.09393 
Epoch [186/300] Validation [5/16] Loss: 0.27480  focal_loss 0.08427  dice_loss 0.19052 
Epoch [186/300] Validation [6/16] Loss: 0.18518  focal_loss 0.03397  dice_loss 0.15120 
Epoch [186/300] Validation [7/16] Loss: 0.32845  focal_loss 0.15416  dice_loss 0.17429 
Epoch [186/300] Validation [8/16] Loss: 0.43087  focal_loss 0.13977  dice_loss 0.29110 
Epoch [186/300] Validation [9/16] Loss: 0.14901  focal_loss 0.05790  dice_loss 0.09111 
Epoch [186/300] Validation [10/16] Loss: 0.23018  focal_loss 0.06162  dice_loss 0.16855 
Epoch [186/300] Validation [11/16] Loss: 0.10379  focal_loss 0.03097  dice_loss 0.07282 
Epoch [186/300] Validation [12/16] Loss: 0.32973  focal_loss 0.09058  dice_loss 0.23915 
Epoch [186/300] Validation [13/16] Loss: 0.20738  focal_loss 0.07347  dice_loss 0.13391 
Epoch [186/300] Validation [14/16] Loss: 0.37457  focal_loss 0.13486  dice_loss 0.23971 
Epoch [186/300] Validation [15/16] Loss: 0.10519  focal_loss 0.03678  dice_loss 0.06841 
Epoch [186/300] Validation [16/16] Loss: 0.06289  focal_loss 0.01815  dice_loss 0.04474 
Epoch [186/300] Validation metric {'Val/mean dice_metric': 0.9280112385749817, 'Val/mean miou_metric': 0.8782210946083069, 'Val/mean f1': 0.9358342885971069, 'Val/mean precision': 0.9348311424255371, 'Val/mean recall': 0.9368396401405334, 'Val/mean hd95_metric': 14.177244186401367}
Cheakpoint...
Epoch [186/300] best acc:tensor([0.9280], device='cuda:0'), Now : mean acc: tensor([0.9280], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9280112385749817, 'Val/mean miou_metric': 0.8782210946083069, 'Val/mean f1': 0.9358342885971069, 'Val/mean precision': 0.9348311424255371, 'Val/mean recall': 0.9368396401405334, 'Val/mean hd95_metric': 14.177244186401367}
Epoch [187/300] Training [1/62] Loss: 0.09638 
Epoch [187/300] Training [2/62] Loss: 0.08301 
Epoch [187/300] Training [3/62] Loss: 0.07051 
Epoch [187/300] Training [4/62] Loss: 0.11721 
Epoch [187/300] Training [5/62] Loss: 0.05394 
Epoch [187/300] Training [6/62] Loss: 0.06958 
Epoch [187/300] Training [7/62] Loss: 0.04263 
Epoch [187/300] Training [8/62] Loss: 0.07050 
Epoch [187/300] Training [9/62] Loss: 0.06899 
Epoch [187/300] Training [10/62] Loss: 0.14227 
Epoch [187/300] Training [11/62] Loss: 0.06080 
Epoch [187/300] Training [12/62] Loss: 0.05669 
Epoch [187/300] Training [13/62] Loss: 0.05195 
Epoch [187/300] Training [14/62] Loss: 0.05057 
Epoch [187/300] Training [15/62] Loss: 0.11238 
Epoch [187/300] Training [16/62] Loss: 0.06874 
Epoch [187/300] Training [17/62] Loss: 0.05063 
Epoch [187/300] Training [18/62] Loss: 0.10339 
Epoch [187/300] Training [19/62] Loss: 0.06021 
Epoch [187/300] Training [20/62] Loss: 0.14713 
Epoch [187/300] Training [21/62] Loss: 0.10203 
Epoch [187/300] Training [22/62] Loss: 0.06624 
Epoch [187/300] Training [23/62] Loss: 0.07331 
Epoch [187/300] Training [24/62] Loss: 0.22760 
Epoch [187/300] Training [25/62] Loss: 0.05793 
Epoch [187/300] Training [26/62] Loss: 0.05687 
Epoch [187/300] Training [27/62] Loss: 0.05964 
Epoch [187/300] Training [28/62] Loss: 0.04328 
Epoch [187/300] Training [29/62] Loss: 0.08828 
Epoch [187/300] Training [30/62] Loss: 0.06113 
Epoch [187/300] Training [31/62] Loss: 0.09155 
Epoch [187/300] Training [32/62] Loss: 0.08418 
Epoch [187/300] Training [33/62] Loss: 0.08465 
Epoch [187/300] Training [34/62] Loss: 0.05233 
Epoch [187/300] Training [35/62] Loss: 0.04981 
Epoch [187/300] Training [36/62] Loss: 0.05025 
Epoch [187/300] Training [37/62] Loss: 0.13689 
Epoch [187/300] Training [38/62] Loss: 0.05911 
Epoch [187/300] Training [39/62] Loss: 0.04512 
Epoch [187/300] Training [40/62] Loss: 0.11307 
Epoch [187/300] Training [41/62] Loss: 0.08754 
Epoch [187/300] Training [42/62] Loss: 0.06915 
Epoch [187/300] Training [43/62] Loss: 0.07111 
Epoch [187/300] Training [44/62] Loss: 0.10289 
Epoch [187/300] Training [45/62] Loss: 0.06420 
Epoch [187/300] Training [46/62] Loss: 0.06634 
Epoch [187/300] Training [47/62] Loss: 0.07013 
Epoch [187/300] Training [48/62] Loss: 0.05000 
Epoch [187/300] Training [49/62] Loss: 0.07258 
Epoch [187/300] Training [50/62] Loss: 0.06875 
Epoch [187/300] Training [51/62] Loss: 0.08357 
Epoch [187/300] Training [52/62] Loss: 0.08153 
Epoch [187/300] Training [53/62] Loss: 0.07407 
Epoch [187/300] Training [54/62] Loss: 0.04373 
Epoch [187/300] Training [55/62] Loss: 0.07084 
Epoch [187/300] Training [56/62] Loss: 0.07213 
Epoch [187/300] Training [57/62] Loss: 0.06426 
Epoch [187/300] Training [58/62] Loss: 0.06268 
Epoch [187/300] Training [59/62] Loss: 0.09483 
Epoch [187/300] Training [60/62] Loss: 0.03968 
Epoch [187/300] Training [61/62] Loss: 0.10745 
Epoch [187/300] Training [62/62] Loss: 0.03835 
Epoch [187/300] Training metric {'Train/mean dice_metric': 0.946283757686615, 'Train/mean miou_metric': 0.9032432436943054, 'Train/mean f1': 0.9532937407493591, 'Train/mean precision': 0.9494783878326416, 'Train/mean recall': 0.9571398496627808, 'Train/mean hd95_metric': 9.254951477050781}
Epoch [187/300] Validation [1/16] Loss: 0.26307  focal_loss 0.13281  dice_loss 0.13027 
Epoch [187/300] Validation [2/16] Loss: 0.27723  focal_loss 0.13156  dice_loss 0.14567 
Epoch [187/300] Validation [3/16] Loss: 0.32036  focal_loss 0.14370  dice_loss 0.17666 
Epoch [187/300] Validation [4/16] Loss: 0.25608  focal_loss 0.09758  dice_loss 0.15849 
Epoch [187/300] Validation [5/16] Loss: 0.28925  focal_loss 0.10489  dice_loss 0.18436 
Epoch [187/300] Validation [6/16] Loss: 0.33840  focal_loss 0.14047  dice_loss 0.19793 
Epoch [187/300] Validation [7/16] Loss: 0.19905  focal_loss 0.08543  dice_loss 0.11362 
Epoch [187/300] Validation [8/16] Loss: 0.37238  focal_loss 0.13308  dice_loss 0.23930 
Epoch [187/300] Validation [9/16] Loss: 0.24026  focal_loss 0.09554  dice_loss 0.14473 
Epoch [187/300] Validation [10/16] Loss: 0.40736  focal_loss 0.18192  dice_loss 0.22543 
Epoch [187/300] Validation [11/16] Loss: 0.14298  focal_loss 0.03895  dice_loss 0.10403 
Epoch [187/300] Validation [12/16] Loss: 0.33871  focal_loss 0.07898  dice_loss 0.25974 
Epoch [187/300] Validation [13/16] Loss: 0.32483  focal_loss 0.13166  dice_loss 0.19317 
Epoch [187/300] Validation [14/16] Loss: 0.53255  focal_loss 0.16854  dice_loss 0.36402 
Epoch [187/300] Validation [15/16] Loss: 0.12943  focal_loss 0.03349  dice_loss 0.09594 
Epoch [187/300] Validation [16/16] Loss: 0.07450  focal_loss 0.02988  dice_loss 0.04462 
Epoch [187/300] Validation metric {'Val/mean dice_metric': 0.9220305681228638, 'Val/mean miou_metric': 0.8720448613166809, 'Val/mean f1': 0.9289628863334656, 'Val/mean precision': 0.9285296201705933, 'Val/mean recall': 0.9293967485427856, 'Val/mean hd95_metric': 15.623992919921875}
Cheakpoint...
Epoch [187/300] best acc:tensor([0.9280], device='cuda:0'), Now : mean acc: tensor([0.9220], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9220305681228638, 'Val/mean miou_metric': 0.8720448613166809, 'Val/mean f1': 0.9289628863334656, 'Val/mean precision': 0.9285296201705933, 'Val/mean recall': 0.9293967485427856, 'Val/mean hd95_metric': 15.623992919921875}
Epoch [188/300] Training [1/62] Loss: 0.06251 
Epoch [188/300] Training [2/62] Loss: 0.09028 
Epoch [188/300] Training [3/62] Loss: 0.07874 
Epoch [188/300] Training [4/62] Loss: 0.05881 
Epoch [188/300] Training [5/62] Loss: 0.04753 
Epoch [188/300] Training [6/62] Loss: 0.05630 
Epoch [188/300] Training [7/62] Loss: 0.05355 
Epoch [188/300] Training [8/62] Loss: 0.04771 
Epoch [188/300] Training [9/62] Loss: 0.07448 
Epoch [188/300] Training [10/62] Loss: 0.12507 
Epoch [188/300] Training [11/62] Loss: 0.05053 
Epoch [188/300] Training [12/62] Loss: 0.08783 
Epoch [188/300] Training [13/62] Loss: 0.05169 
Epoch [188/300] Training [14/62] Loss: 0.05073 
Epoch [188/300] Training [15/62] Loss: 0.04393 
Epoch [188/300] Training [16/62] Loss: 0.05532 
Epoch [188/300] Training [17/62] Loss: 0.05416 
Epoch [188/300] Training [18/62] Loss: 0.04953 
Epoch [188/300] Training [19/62] Loss: 0.04734 
Epoch [188/300] Training [20/62] Loss: 0.06940 
Epoch [188/300] Training [21/62] Loss: 0.08841 
Epoch [188/300] Training [22/62] Loss: 0.14555 
Epoch [188/300] Training [23/62] Loss: 0.07650 
Epoch [188/300] Training [24/62] Loss: 0.10795 
Epoch [188/300] Training [25/62] Loss: 0.06215 
Epoch [188/300] Training [26/62] Loss: 0.05389 
Epoch [188/300] Training [27/62] Loss: 0.05726 
Epoch [188/300] Training [28/62] Loss: 0.06038 
Epoch [188/300] Training [29/62] Loss: 0.06567 
Epoch [188/300] Training [30/62] Loss: 0.05518 
Epoch [188/300] Training [31/62] Loss: 0.05866 
Epoch [188/300] Training [32/62] Loss: 0.05316 
Epoch [188/300] Training [33/62] Loss: 0.06440 
Epoch [188/300] Training [34/62] Loss: 0.08122 
Epoch [188/300] Training [35/62] Loss: 0.12874 
Epoch [188/300] Training [36/62] Loss: 0.07924 
Epoch [188/300] Training [37/62] Loss: 0.05330 
Epoch [188/300] Training [38/62] Loss: 0.06746 
Epoch [188/300] Training [39/62] Loss: 0.08239 
Epoch [188/300] Training [40/62] Loss: 0.04901 
Epoch [188/300] Training [41/62] Loss: 0.06751 
Epoch [188/300] Training [42/62] Loss: 0.13464 
Epoch [188/300] Training [43/62] Loss: 0.04921 
Epoch [188/300] Training [44/62] Loss: 0.07101 
Epoch [188/300] Training [45/62] Loss: 0.05136 
Epoch [188/300] Training [46/62] Loss: 0.05295 
Epoch [188/300] Training [47/62] Loss: 0.08821 
Epoch [188/300] Training [48/62] Loss: 0.06698 
Epoch [188/300] Training [49/62] Loss: 0.05029 
Epoch [188/300] Training [50/62] Loss: 0.06710 
Epoch [188/300] Training [51/62] Loss: 0.04574 
Epoch [188/300] Training [52/62] Loss: 0.06443 
Epoch [188/300] Training [53/62] Loss: 0.03954 
Epoch [188/300] Training [54/62] Loss: 0.06646 
Epoch [188/300] Training [55/62] Loss: 0.07349 
Epoch [188/300] Training [56/62] Loss: 0.05150 
Epoch [188/300] Training [57/62] Loss: 0.04677 
Epoch [188/300] Training [58/62] Loss: 0.06390 
Epoch [188/300] Training [59/62] Loss: 0.05916 
Epoch [188/300] Training [60/62] Loss: 0.09892 
Epoch [188/300] Training [61/62] Loss: 0.08915 
Epoch [188/300] Training [62/62] Loss: 0.06018 
Epoch [188/300] Training metric {'Train/mean dice_metric': 0.9526886343955994, 'Train/mean miou_metric': 0.9130393862724304, 'Train/mean f1': 0.9576602578163147, 'Train/mean precision': 0.952987790107727, 'Train/mean recall': 0.9623785614967346, 'Train/mean hd95_metric': 8.739029884338379}
Epoch [188/300] Validation [1/16] Loss: 0.47992  focal_loss 0.31708  dice_loss 0.16285 
Epoch [188/300] Validation [2/16] Loss: 0.31450  focal_loss 0.12284  dice_loss 0.19165 
Epoch [188/300] Validation [3/16] Loss: 0.68367  focal_loss 0.42791  dice_loss 0.25576 
Epoch [188/300] Validation [4/16] Loss: 0.27203  focal_loss 0.11735  dice_loss 0.15468 
Epoch [188/300] Validation [5/16] Loss: 0.27714  focal_loss 0.08818  dice_loss 0.18896 
Epoch [188/300] Validation [6/16] Loss: 0.20852  focal_loss 0.05166  dice_loss 0.15686 
Epoch [188/300] Validation [7/16] Loss: 0.25971  focal_loss 0.12318  dice_loss 0.13653 
Epoch [188/300] Validation [8/16] Loss: 0.35548  focal_loss 0.09691  dice_loss 0.25858 
Epoch [188/300] Validation [9/16] Loss: 0.14258  focal_loss 0.04667  dice_loss 0.09590 
Epoch [188/300] Validation [10/16] Loss: 0.19429  focal_loss 0.04946  dice_loss 0.14483 
Epoch [188/300] Validation [11/16] Loss: 0.13273  focal_loss 0.04120  dice_loss 0.09153 
Epoch [188/300] Validation [12/16] Loss: 0.28453  focal_loss 0.07205  dice_loss 0.21248 
Epoch [188/300] Validation [13/16] Loss: 0.38276  focal_loss 0.13369  dice_loss 0.24907 
Epoch [188/300] Validation [14/16] Loss: 0.37160  focal_loss 0.12321  dice_loss 0.24839 
Epoch [188/300] Validation [15/16] Loss: 0.11097  focal_loss 0.03193  dice_loss 0.07904 
Epoch [188/300] Validation [16/16] Loss: 0.05580  focal_loss 0.01603  dice_loss 0.03977 
Epoch [188/300] Validation metric {'Val/mean dice_metric': 0.929120659828186, 'Val/mean miou_metric': 0.8820618391036987, 'Val/mean f1': 0.9340932965278625, 'Val/mean precision': 0.9315242171287537, 'Val/mean recall': 0.9366766214370728, 'Val/mean hd95_metric': 14.45529556274414}
Cheakpoint...
Epoch [188/300] best acc:tensor([0.9291], device='cuda:0'), Now : mean acc: tensor([0.9291], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.929120659828186, 'Val/mean miou_metric': 0.8820618391036987, 'Val/mean f1': 0.9340932965278625, 'Val/mean precision': 0.9315242171287537, 'Val/mean recall': 0.9366766214370728, 'Val/mean hd95_metric': 14.45529556274414}
Epoch [189/300] Training [1/62] Loss: 0.04559 
Epoch [189/300] Training [2/62] Loss: 0.05547 
Epoch [189/300] Training [3/62] Loss: 0.07741 
Epoch [189/300] Training [4/62] Loss: 0.05877 
Epoch [189/300] Training [5/62] Loss: 0.04373 
Epoch [189/300] Training [6/62] Loss: 0.13092 
Epoch [189/300] Training [7/62] Loss: 0.08034 
Epoch [189/300] Training [8/62] Loss: 0.10245 
Epoch [189/300] Training [9/62] Loss: 0.05720 
Epoch [189/300] Training [10/62] Loss: 0.04555 
Epoch [189/300] Training [11/62] Loss: 0.07947 
Epoch [189/300] Training [12/62] Loss: 0.05338 
Epoch [189/300] Training [13/62] Loss: 0.07139 
Epoch [189/300] Training [14/62] Loss: 0.06074 
Epoch [189/300] Training [15/62] Loss: 0.10631 
Epoch [189/300] Training [16/62] Loss: 0.05363 
Epoch [189/300] Training [17/62] Loss: 0.06358 
Epoch [189/300] Training [18/62] Loss: 0.08209 
Epoch [189/300] Training [19/62] Loss: 0.15692 
Epoch [189/300] Training [20/62] Loss: 0.06941 
Epoch [189/300] Training [21/62] Loss: 0.04941 
Epoch [189/300] Training [22/62] Loss: 0.10441 
Epoch [189/300] Training [23/62] Loss: 0.06297 
Epoch [189/300] Training [24/62] Loss: 0.07174 
Epoch [189/300] Training [25/62] Loss: 0.13604 
Epoch [189/300] Training [26/62] Loss: 0.06406 
Epoch [189/300] Training [27/62] Loss: 0.04603 
Epoch [189/300] Training [28/62] Loss: 0.16562 
Epoch [189/300] Training [29/62] Loss: 0.07346 
Epoch [189/300] Training [30/62] Loss: 0.09627 
Epoch [189/300] Training [31/62] Loss: 0.05778 
Epoch [189/300] Training [32/62] Loss: 0.08380 
Epoch [189/300] Training [33/62] Loss: 0.05704 
Epoch [189/300] Training [34/62] Loss: 0.08143 
Epoch [189/300] Training [35/62] Loss: 0.06801 
Epoch [189/300] Training [36/62] Loss: 0.09622 
Epoch [189/300] Training [37/62] Loss: 0.04399 
Epoch [189/300] Training [38/62] Loss: 0.07323 
Epoch [189/300] Training [39/62] Loss: 0.07600 
Epoch [189/300] Training [40/62] Loss: 0.05285 
Epoch [189/300] Training [41/62] Loss: 0.06047 
Epoch [189/300] Training [42/62] Loss: 0.09112 
Epoch [189/300] Training [43/62] Loss: 0.07678 
Epoch [189/300] Training [44/62] Loss: 0.07231 
Epoch [189/300] Training [45/62] Loss: 0.08459 
Epoch [189/300] Training [46/62] Loss: 0.04908 
Epoch [189/300] Training [47/62] Loss: 0.10123 
Epoch [189/300] Training [48/62] Loss: 0.09061 
Epoch [189/300] Training [49/62] Loss: 0.06608 
Epoch [189/300] Training [50/62] Loss: 0.07178 
Epoch [189/300] Training [51/62] Loss: 0.04576 
Epoch [189/300] Training [52/62] Loss: 0.08703 
Epoch [189/300] Training [53/62] Loss: 0.13009 
Epoch [189/300] Training [54/62] Loss: 0.05064 
Epoch [189/300] Training [55/62] Loss: 0.04999 
Epoch [189/300] Training [56/62] Loss: 0.05951 
Epoch [189/300] Training [57/62] Loss: 0.12623 
Epoch [189/300] Training [58/62] Loss: 0.06337 
Epoch [189/300] Training [59/62] Loss: 0.18478 
Epoch [189/300] Training [60/62] Loss: 0.07334 
Epoch [189/300] Training [61/62] Loss: 0.06113 
Epoch [189/300] Training [62/62] Loss: 0.02575 
Epoch [189/300] Training metric {'Train/mean dice_metric': 0.9473667144775391, 'Train/mean miou_metric': 0.9049831628799438, 'Train/mean f1': 0.950103759765625, 'Train/mean precision': 0.9472221732139587, 'Train/mean recall': 0.9530030488967896, 'Train/mean hd95_metric': 9.389102935791016}
Epoch [189/300] Validation [1/16] Loss: 0.16337  focal_loss 0.05668  dice_loss 0.10669 
Epoch [189/300] Validation [2/16] Loss: 0.33953  focal_loss 0.12454  dice_loss 0.21499 
Epoch [189/300] Validation [3/16] Loss: 0.27221  focal_loss 0.07789  dice_loss 0.19432 
Epoch [189/300] Validation [4/16] Loss: 0.35426  focal_loss 0.15367  dice_loss 0.20059 
Epoch [189/300] Validation [5/16] Loss: 0.32761  focal_loss 0.08210  dice_loss 0.24552 
Epoch [189/300] Validation [6/16] Loss: 0.20747  focal_loss 0.04469  dice_loss 0.16277 
Epoch [189/300] Validation [7/16] Loss: 0.20506  focal_loss 0.06735  dice_loss 0.13771 
Epoch [189/300] Validation [8/16] Loss: 0.41658  focal_loss 0.13954  dice_loss 0.27704 
Epoch [189/300] Validation [9/16] Loss: 0.22767  focal_loss 0.07879  dice_loss 0.14887 
Epoch [189/300] Validation [10/16] Loss: 0.25634  focal_loss 0.05197  dice_loss 0.20437 
Epoch [189/300] Validation [11/16] Loss: 0.20648  focal_loss 0.05419  dice_loss 0.15229 
Epoch [189/300] Validation [12/16] Loss: 0.31145  focal_loss 0.06844  dice_loss 0.24302 
Epoch [189/300] Validation [13/16] Loss: 0.20823  focal_loss 0.06785  dice_loss 0.14039 
Epoch [189/300] Validation [14/16] Loss: 0.43899  focal_loss 0.14971  dice_loss 0.28928 
Epoch [189/300] Validation [15/16] Loss: 0.08461  focal_loss 0.01870  dice_loss 0.06592 
Epoch [189/300] Validation [16/16] Loss: 0.04664  focal_loss 0.00806  dice_loss 0.03858 
Epoch [189/300] Validation metric {'Val/mean dice_metric': 0.9231787919998169, 'Val/mean miou_metric': 0.8727290630340576, 'Val/mean f1': 0.9289644956588745, 'Val/mean precision': 0.9255076050758362, 'Val/mean recall': 0.9324474930763245, 'Val/mean hd95_metric': 16.132312774658203}
Cheakpoint...
Epoch [189/300] best acc:tensor([0.9291], device='cuda:0'), Now : mean acc: tensor([0.9232], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9231787919998169, 'Val/mean miou_metric': 0.8727290630340576, 'Val/mean f1': 0.9289644956588745, 'Val/mean precision': 0.9255076050758362, 'Val/mean recall': 0.9324474930763245, 'Val/mean hd95_metric': 16.132312774658203}
Epoch [190/300] Training [1/62] Loss: 0.09260 
Epoch [190/300] Training [2/62] Loss: 0.07489 
Epoch [190/300] Training [3/62] Loss: 0.16476 
Epoch [190/300] Training [4/62] Loss: 0.04969 
Epoch [190/300] Training [5/62] Loss: 0.06556 
Epoch [190/300] Training [6/62] Loss: 0.08188 
Epoch [190/300] Training [7/62] Loss: 0.04782 
Epoch [190/300] Training [8/62] Loss: 0.06390 
Epoch [190/300] Training [9/62] Loss: 0.05648 
Epoch [190/300] Training [10/62] Loss: 0.05348 
Epoch [190/300] Training [11/62] Loss: 0.06448 
Epoch [190/300] Training [12/62] Loss: 0.06236 
Epoch [190/300] Training [13/62] Loss: 0.06016 
Epoch [190/300] Training [14/62] Loss: 0.16608 
Epoch [190/300] Training [15/62] Loss: 0.09539 
Epoch [190/300] Training [16/62] Loss: 0.19669 
Epoch [190/300] Training [17/62] Loss: 0.06042 
Epoch [190/300] Training [18/62] Loss: 0.05339 
Epoch [190/300] Training [19/62] Loss: 0.05679 
Epoch [190/300] Training [20/62] Loss: 0.10741 
Epoch [190/300] Training [21/62] Loss: 0.07735 
Epoch [190/300] Training [22/62] Loss: 0.06840 
Epoch [190/300] Training [23/62] Loss: 0.04046 
Epoch [190/300] Training [24/62] Loss: 0.05976 
Epoch [190/300] Training [25/62] Loss: 0.06057 
Epoch [190/300] Training [26/62] Loss: 0.08155 
Epoch [190/300] Training [27/62] Loss: 0.06021 
Epoch [190/300] Training [28/62] Loss: 0.08878 
Epoch [190/300] Training [29/62] Loss: 0.09187 
Epoch [190/300] Training [30/62] Loss: 0.03855 
Epoch [190/300] Training [31/62] Loss: 0.04885 
Epoch [190/300] Training [32/62] Loss: 0.13086 
Epoch [190/300] Training [33/62] Loss: 0.05970 
Epoch [190/300] Training [34/62] Loss: 0.05791 
Epoch [190/300] Training [35/62] Loss: 0.18570 
Epoch [190/300] Training [36/62] Loss: 0.05152 
Epoch [190/300] Training [37/62] Loss: 0.04628 
Epoch [190/300] Training [38/62] Loss: 0.06126 
Epoch [190/300] Training [39/62] Loss: 0.04381 
Epoch [190/300] Training [40/62] Loss: 0.04382 
Epoch [190/300] Training [41/62] Loss: 0.05154 
Epoch [190/300] Training [42/62] Loss: 0.15708 
Epoch [190/300] Training [43/62] Loss: 0.05037 
Epoch [190/300] Training [44/62] Loss: 0.07310 
Epoch [190/300] Training [45/62] Loss: 0.04512 
Epoch [190/300] Training [46/62] Loss: 0.05148 
Epoch [190/300] Training [47/62] Loss: 0.08127 
Epoch [190/300] Training [48/62] Loss: 0.05550 
Epoch [190/300] Training [49/62] Loss: 0.13819 
Epoch [190/300] Training [50/62] Loss: 0.04541 
Epoch [190/300] Training [51/62] Loss: 0.06079 
Epoch [190/300] Training [52/62] Loss: 0.05158 
Epoch [190/300] Training [53/62] Loss: 0.05173 
Epoch [190/300] Training [54/62] Loss: 0.11522 
Epoch [190/300] Training [55/62] Loss: 0.05320 
Epoch [190/300] Training [56/62] Loss: 0.07922 
Epoch [190/300] Training [57/62] Loss: 0.04568 
Epoch [190/300] Training [58/62] Loss: 0.10030 
Epoch [190/300] Training [59/62] Loss: 0.04255 
Epoch [190/300] Training [60/62] Loss: 0.07065 
Epoch [190/300] Training [61/62] Loss: 0.08965 
Epoch [190/300] Training [62/62] Loss: 0.08646 
Epoch [190/300] Training metric {'Train/mean dice_metric': 0.9471645951271057, 'Train/mean miou_metric': 0.906932532787323, 'Train/mean f1': 0.9541873335838318, 'Train/mean precision': 0.9468802809715271, 'Train/mean recall': 0.9616079926490784, 'Train/mean hd95_metric': 9.146097183227539}
Epoch [190/300] Validation [1/16] Loss: 0.29384  focal_loss 0.12570  dice_loss 0.16814 
Epoch [190/300] Validation [2/16] Loss: 0.31838  focal_loss 0.09695  dice_loss 0.22142 
Epoch [190/300] Validation [3/16] Loss: 0.69643  focal_loss 0.40804  dice_loss 0.28839 
Epoch [190/300] Validation [4/16] Loss: 0.18387  focal_loss 0.04910  dice_loss 0.13477 
Epoch [190/300] Validation [5/16] Loss: 0.30475  focal_loss 0.09515  dice_loss 0.20961 
Epoch [190/300] Validation [6/16] Loss: 0.29830  focal_loss 0.06507  dice_loss 0.23323 
Epoch [190/300] Validation [7/16] Loss: 0.32741  focal_loss 0.11324  dice_loss 0.21417 
Epoch [190/300] Validation [8/16] Loss: 0.30838  focal_loss 0.08848  dice_loss 0.21990 
Epoch [190/300] Validation [9/16] Loss: 0.31188  focal_loss 0.10092  dice_loss 0.21097 
Epoch [190/300] Validation [10/16] Loss: 0.25444  focal_loss 0.06188  dice_loss 0.19256 
Epoch [190/300] Validation [11/16] Loss: 0.16027  focal_loss 0.04197  dice_loss 0.11830 
Epoch [190/300] Validation [12/16] Loss: 0.33785  focal_loss 0.07531  dice_loss 0.26253 
Epoch [190/300] Validation [13/16] Loss: 0.29500  focal_loss 0.09751  dice_loss 0.19749 
Epoch [190/300] Validation [14/16] Loss: 0.42212  focal_loss 0.12782  dice_loss 0.29431 
Epoch [190/300] Validation [15/16] Loss: 0.11833  focal_loss 0.02478  dice_loss 0.09354 
Epoch [190/300] Validation [16/16] Loss: 0.03682  focal_loss 0.00722  dice_loss 0.02959 
Epoch [190/300] Validation metric {'Val/mean dice_metric': 0.919218897819519, 'Val/mean miou_metric': 0.8706223368644714, 'Val/mean f1': 0.9301226139068604, 'Val/mean precision': 0.9231535196304321, 'Val/mean recall': 0.9371976852416992, 'Val/mean hd95_metric': 16.434398651123047}
Cheakpoint...
Epoch [190/300] best acc:tensor([0.9291], device='cuda:0'), Now : mean acc: tensor([0.9192], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.919218897819519, 'Val/mean miou_metric': 0.8706223368644714, 'Val/mean f1': 0.9301226139068604, 'Val/mean precision': 0.9231535196304321, 'Val/mean recall': 0.9371976852416992, 'Val/mean hd95_metric': 16.434398651123047}
Epoch [191/300] Training [1/62] Loss: 0.09004 
Epoch [191/300] Training [2/62] Loss: 0.05687 
Epoch [191/300] Training [3/62] Loss: 0.07505 
Epoch [191/300] Training [4/62] Loss: 0.05488 
Epoch [191/300] Training [5/62] Loss: 0.05943 
Epoch [191/300] Training [6/62] Loss: 0.05879 
Epoch [191/300] Training [7/62] Loss: 0.06284 
Epoch [191/300] Training [8/62] Loss: 0.04954 
Epoch [191/300] Training [9/62] Loss: 0.06210 
Epoch [191/300] Training [10/62] Loss: 0.04696 
Epoch [191/300] Training [11/62] Loss: 0.09167 
Epoch [191/300] Training [12/62] Loss: 0.07280 
Epoch [191/300] Training [13/62] Loss: 0.04875 
Epoch [191/300] Training [14/62] Loss: 0.06863 
Epoch [191/300] Training [15/62] Loss: 0.07893 
Epoch [191/300] Training [16/62] Loss: 0.04671 
Epoch [191/300] Training [17/62] Loss: 0.11517 
Epoch [191/300] Training [18/62] Loss: 0.04446 
Epoch [191/300] Training [19/62] Loss: 0.05141 
Epoch [191/300] Training [20/62] Loss: 0.05737 
Epoch [191/300] Training [21/62] Loss: 0.06433 
Epoch [191/300] Training [22/62] Loss: 0.09146 
Epoch [191/300] Training [23/62] Loss: 0.04482 
Epoch [191/300] Training [24/62] Loss: 0.04859 
Epoch [191/300] Training [25/62] Loss: 0.10097 
Epoch [191/300] Training [26/62] Loss: 0.07204 
Epoch [191/300] Training [27/62] Loss: 0.07840 
Epoch [191/300] Training [28/62] Loss: 0.05737 
Epoch [191/300] Training [29/62] Loss: 0.08488 
Epoch [191/300] Training [30/62] Loss: 0.08203 
Epoch [191/300] Training [31/62] Loss: 0.06586 
Epoch [191/300] Training [32/62] Loss: 0.04978 
Epoch [191/300] Training [33/62] Loss: 0.05959 
Epoch [191/300] Training [34/62] Loss: 0.06200 
Epoch [191/300] Training [35/62] Loss: 0.06423 
Epoch [191/300] Training [36/62] Loss: 0.08170 
Epoch [191/300] Training [37/62] Loss: 0.10979 
Epoch [191/300] Training [38/62] Loss: 0.08054 
Epoch [191/300] Training [39/62] Loss: 0.06843 
Epoch [191/300] Training [40/62] Loss: 0.10847 
Epoch [191/300] Training [41/62] Loss: 0.09103 
Epoch [191/300] Training [42/62] Loss: 0.04770 
Epoch [191/300] Training [43/62] Loss: 0.06649 
Epoch [191/300] Training [44/62] Loss: 0.08944 
Epoch [191/300] Training [45/62] Loss: 0.06145 
Epoch [191/300] Training [46/62] Loss: 0.06147 
Epoch [191/300] Training [47/62] Loss: 0.05478 
Epoch [191/300] Training [48/62] Loss: 0.08645 
Epoch [191/300] Training [49/62] Loss: 0.10265 
Epoch [191/300] Training [50/62] Loss: 0.03857 
Epoch [191/300] Training [51/62] Loss: 0.08945 
Epoch [191/300] Training [52/62] Loss: 0.05563 
Epoch [191/300] Training [53/62] Loss: 0.07600 
Epoch [191/300] Training [54/62] Loss: 0.10194 
Epoch [191/300] Training [55/62] Loss: 0.12991 
Epoch [191/300] Training [56/62] Loss: 0.06732 
Epoch [191/300] Training [57/62] Loss: 0.06328 
Epoch [191/300] Training [58/62] Loss: 0.09083 
Epoch [191/300] Training [59/62] Loss: 0.17888 
Epoch [191/300] Training [60/62] Loss: 0.06286 
Epoch [191/300] Training [61/62] Loss: 0.05657 
Epoch [191/300] Training [62/62] Loss: 0.05063 
Epoch [191/300] Training metric {'Train/mean dice_metric': 0.9494163393974304, 'Train/mean miou_metric': 0.9077498912811279, 'Train/mean f1': 0.9557186365127563, 'Train/mean precision': 0.9511594176292419, 'Train/mean recall': 0.9603217244148254, 'Train/mean hd95_metric': 8.877787590026855}
Epoch [191/300] Validation [1/16] Loss: 0.19615  focal_loss 0.07144  dice_loss 0.12471 
Epoch [191/300] Validation [2/16] Loss: 0.34193  focal_loss 0.11813  dice_loss 0.22381 
Epoch [191/300] Validation [3/16] Loss: 0.66575  focal_loss 0.40309  dice_loss 0.26266 
Epoch [191/300] Validation [4/16] Loss: 0.19306  focal_loss 0.07334  dice_loss 0.11972 
Epoch [191/300] Validation [5/16] Loss: 0.26408  focal_loss 0.07998  dice_loss 0.18410 
Epoch [191/300] Validation [6/16] Loss: 0.15733  focal_loss 0.02303  dice_loss 0.13429 
Epoch [191/300] Validation [7/16] Loss: 0.28123  focal_loss 0.12668  dice_loss 0.15455 
Epoch [191/300] Validation [8/16] Loss: 0.52058  focal_loss 0.18169  dice_loss 0.33889 
Epoch [191/300] Validation [9/16] Loss: 0.15269  focal_loss 0.04699  dice_loss 0.10570 
Epoch [191/300] Validation [10/16] Loss: 0.42953  focal_loss 0.17487  dice_loss 0.25466 
Epoch [191/300] Validation [11/16] Loss: 0.15746  focal_loss 0.04220  dice_loss 0.11525 
Epoch [191/300] Validation [12/16] Loss: 0.27164  focal_loss 0.05747  dice_loss 0.21417 
Epoch [191/300] Validation [13/16] Loss: 0.30290  focal_loss 0.10398  dice_loss 0.19893 
Epoch [191/300] Validation [14/16] Loss: 0.45650  focal_loss 0.12623  dice_loss 0.33027 
Epoch [191/300] Validation [15/16] Loss: 0.10449  focal_loss 0.02745  dice_loss 0.07704 
Epoch [191/300] Validation [16/16] Loss: 0.04074  focal_loss 0.00804  dice_loss 0.03270 
Epoch [191/300] Validation metric {'Val/mean dice_metric': 0.923874020576477, 'Val/mean miou_metric': 0.8744832873344421, 'Val/mean f1': 0.9310184121131897, 'Val/mean precision': 0.9290456771850586, 'Val/mean recall': 0.9329994916915894, 'Val/mean hd95_metric': 14.406086921691895}
Cheakpoint...
Epoch [191/300] best acc:tensor([0.9291], device='cuda:0'), Now : mean acc: tensor([0.9239], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.923874020576477, 'Val/mean miou_metric': 0.8744832873344421, 'Val/mean f1': 0.9310184121131897, 'Val/mean precision': 0.9290456771850586, 'Val/mean recall': 0.9329994916915894, 'Val/mean hd95_metric': 14.406086921691895}
Epoch [192/300] Training [1/62] Loss: 0.07509 
Epoch [192/300] Training [2/62] Loss: 0.10594 
Epoch [192/300] Training [3/62] Loss: 0.11814 
Epoch [192/300] Training [4/62] Loss: 0.07161 
Epoch [192/300] Training [5/62] Loss: 0.07590 
Epoch [192/300] Training [6/62] Loss: 0.06041 
Epoch [192/300] Training [7/62] Loss: 0.05138 
Epoch [192/300] Training [8/62] Loss: 0.05315 
Epoch [192/300] Training [9/62] Loss: 0.08254 
Epoch [192/300] Training [10/62] Loss: 0.06009 
Epoch [192/300] Training [11/62] Loss: 0.04231 
Epoch [192/300] Training [12/62] Loss: 0.10685 
Epoch [192/300] Training [13/62] Loss: 0.10989 
Epoch [192/300] Training [14/62] Loss: 0.05337 
Epoch [192/300] Training [15/62] Loss: 0.05880 
Epoch [192/300] Training [16/62] Loss: 0.08707 
Epoch [192/300] Training [17/62] Loss: 0.06677 
Epoch [192/300] Training [18/62] Loss: 0.04960 
Epoch [192/300] Training [19/62] Loss: 0.06704 
Epoch [192/300] Training [20/62] Loss: 0.07362 
Epoch [192/300] Training [21/62] Loss: 0.08947 
Epoch [192/300] Training [22/62] Loss: 0.04830 
Epoch [192/300] Training [23/62] Loss: 0.06413 
Epoch [192/300] Training [24/62] Loss: 0.13682 
Epoch [192/300] Training [25/62] Loss: 0.04374 
Epoch [192/300] Training [26/62] Loss: 0.04967 
Epoch [192/300] Training [27/62] Loss: 0.05621 
Epoch [192/300] Training [28/62] Loss: 0.16835 
Epoch [192/300] Training [29/62] Loss: 0.04331 
Epoch [192/300] Training [30/62] Loss: 0.04094 
Epoch [192/300] Training [31/62] Loss: 0.07085 
Epoch [192/300] Training [32/62] Loss: 0.04706 
Epoch [192/300] Training [33/62] Loss: 0.04335 
Epoch [192/300] Training [34/62] Loss: 0.06567 
Epoch [192/300] Training [35/62] Loss: 0.05010 
Epoch [192/300] Training [36/62] Loss: 0.04170 
Epoch [192/300] Training [37/62] Loss: 0.06205 
Epoch [192/300] Training [38/62] Loss: 0.07897 
Epoch [192/300] Training [39/62] Loss: 0.06168 
Epoch [192/300] Training [40/62] Loss: 0.08842 
Epoch [192/300] Training [41/62] Loss: 0.05747 
Epoch [192/300] Training [42/62] Loss: 0.08583 
Epoch [192/300] Training [43/62] Loss: 0.11862 
Epoch [192/300] Training [44/62] Loss: 0.06360 
Epoch [192/300] Training [45/62] Loss: 0.04200 
Epoch [192/300] Training [46/62] Loss: 0.04718 
Epoch [192/300] Training [47/62] Loss: 0.05531 
Epoch [192/300] Training [48/62] Loss: 0.05467 
Epoch [192/300] Training [49/62] Loss: 0.13467 
Epoch [192/300] Training [50/62] Loss: 0.06933 
Epoch [192/300] Training [51/62] Loss: 0.13600 
Epoch [192/300] Training [52/62] Loss: 0.04990 
Epoch [192/300] Training [53/62] Loss: 0.06483 
Epoch [192/300] Training [54/62] Loss: 0.05202 
Epoch [192/300] Training [55/62] Loss: 0.04983 
Epoch [192/300] Training [56/62] Loss: 0.08678 
Epoch [192/300] Training [57/62] Loss: 0.12096 
Epoch [192/300] Training [58/62] Loss: 0.05383 
Epoch [192/300] Training [59/62] Loss: 0.09098 
Epoch [192/300] Training [60/62] Loss: 0.09845 
Epoch [192/300] Training [61/62] Loss: 0.05377 
Epoch [192/300] Training [62/62] Loss: 0.07810 
Epoch [192/300] Training metric {'Train/mean dice_metric': 0.9495114684104919, 'Train/mean miou_metric': 0.9098042845726013, 'Train/mean f1': 0.9557675123214722, 'Train/mean precision': 0.9500342011451721, 'Train/mean recall': 0.9615705609321594, 'Train/mean hd95_metric': 8.11101245880127}
Epoch [192/300] Validation [1/16] Loss: 0.31269  focal_loss 0.16374  dice_loss 0.14895 
Epoch [192/300] Validation [2/16] Loss: 0.23199  focal_loss 0.10677  dice_loss 0.12523 
Epoch [192/300] Validation [3/16] Loss: 0.26661  focal_loss 0.05767  dice_loss 0.20893 
Epoch [192/300] Validation [4/16] Loss: 0.23054  focal_loss 0.08255  dice_loss 0.14799 
Epoch [192/300] Validation [5/16] Loss: 0.23927  focal_loss 0.06743  dice_loss 0.17184 
Epoch [192/300] Validation [6/16] Loss: 0.17955  focal_loss 0.03629  dice_loss 0.14326 
Epoch [192/300] Validation [7/16] Loss: 0.23188  focal_loss 0.09959  dice_loss 0.13229 
Epoch [192/300] Validation [8/16] Loss: 0.41650  focal_loss 0.15113  dice_loss 0.26537 
Epoch [192/300] Validation [9/16] Loss: 0.13131  focal_loss 0.04092  dice_loss 0.09038 
Epoch [192/300] Validation [10/16] Loss: 0.20881  focal_loss 0.04223  dice_loss 0.16658 
Epoch [192/300] Validation [11/16] Loss: 0.14830  focal_loss 0.02401  dice_loss 0.12429 
Epoch [192/300] Validation [12/16] Loss: 0.28637  focal_loss 0.06516  dice_loss 0.22122 
Epoch [192/300] Validation [13/16] Loss: 0.17907  focal_loss 0.04426  dice_loss 0.13481 
Epoch [192/300] Validation [14/16] Loss: 0.40213  focal_loss 0.10198  dice_loss 0.30014 
Epoch [192/300] Validation [15/16] Loss: 0.07598  focal_loss 0.01635  dice_loss 0.05963 
Epoch [192/300] Validation [16/16] Loss: 0.04412  focal_loss 0.00850  dice_loss 0.03562 
Epoch [192/300] Validation metric {'Val/mean dice_metric': 0.9295466542243958, 'Val/mean miou_metric': 0.8822159171104431, 'Val/mean f1': 0.9376897811889648, 'Val/mean precision': 0.9363498091697693, 'Val/mean recall': 0.9390335083007812, 'Val/mean hd95_metric': 13.11483383178711}
Cheakpoint...
Epoch [192/300] best acc:tensor([0.9295], device='cuda:0'), Now : mean acc: tensor([0.9295], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9295466542243958, 'Val/mean miou_metric': 0.8822159171104431, 'Val/mean f1': 0.9376897811889648, 'Val/mean precision': 0.9363498091697693, 'Val/mean recall': 0.9390335083007812, 'Val/mean hd95_metric': 13.11483383178711}
Epoch [193/300] Training [1/62] Loss: 0.05516 
Epoch [193/300] Training [2/62] Loss: 0.06988 
Epoch [193/300] Training [3/62] Loss: 0.07269 
Epoch [193/300] Training [4/62] Loss: 0.04786 
Epoch [193/300] Training [5/62] Loss: 0.05098 
Epoch [193/300] Training [6/62] Loss: 0.04381 
Epoch [193/300] Training [7/62] Loss: 0.10283 
Epoch [193/300] Training [8/62] Loss: 0.08507 
Epoch [193/300] Training [9/62] Loss: 0.08122 
Epoch [193/300] Training [10/62] Loss: 0.06715 
Epoch [193/300] Training [11/62] Loss: 0.08621 
Epoch [193/300] Training [12/62] Loss: 0.05648 
Epoch [193/300] Training [13/62] Loss: 0.05894 
Epoch [193/300] Training [14/62] Loss: 0.06418 
Epoch [193/300] Training [15/62] Loss: 0.04284 
Epoch [193/300] Training [16/62] Loss: 0.05355 
Epoch [193/300] Training [17/62] Loss: 0.09728 
Epoch [193/300] Training [18/62] Loss: 0.08237 
Epoch [193/300] Training [19/62] Loss: 0.18756 
Epoch [193/300] Training [20/62] Loss: 0.17765 
Epoch [193/300] Training [21/62] Loss: 0.08512 
Epoch [193/300] Training [22/62] Loss: 0.05938 
Epoch [193/300] Training [23/62] Loss: 0.09899 
Epoch [193/300] Training [24/62] Loss: 0.08260 
Epoch [193/300] Training [25/62] Loss: 0.07742 
Epoch [193/300] Training [26/62] Loss: 0.08457 
Epoch [193/300] Training [27/62] Loss: 0.08994 
Epoch [193/300] Training [28/62] Loss: 0.10593 
Epoch [193/300] Training [29/62] Loss: 0.06435 
Epoch [193/300] Training [30/62] Loss: 0.07562 
Epoch [193/300] Training [31/62] Loss: 0.05440 
Epoch [193/300] Training [32/62] Loss: 0.06673 
Epoch [193/300] Training [33/62] Loss: 0.07357 
Epoch [193/300] Training [34/62] Loss: 0.09036 
Epoch [193/300] Training [35/62] Loss: 0.07466 
Epoch [193/300] Training [36/62] Loss: 0.09817 
Epoch [193/300] Training [37/62] Loss: 0.09069 
Epoch [193/300] Training [38/62] Loss: 0.06766 
Epoch [193/300] Training [39/62] Loss: 0.04533 
Epoch [193/300] Training [40/62] Loss: 0.06389 
Epoch [193/300] Training [41/62] Loss: 0.13004 
Epoch [193/300] Training [42/62] Loss: 0.06745 
Epoch [193/300] Training [43/62] Loss: 0.05577 
Epoch [193/300] Training [44/62] Loss: 0.08734 
Epoch [193/300] Training [45/62] Loss: 0.09693 
Epoch [193/300] Training [46/62] Loss: 0.05578 
Epoch [193/300] Training [47/62] Loss: 0.08788 
Epoch [193/300] Training [48/62] Loss: 0.05358 
Epoch [193/300] Training [49/62] Loss: 0.04351 
Epoch [193/300] Training [50/62] Loss: 0.11116 
Epoch [193/300] Training [51/62] Loss: 0.05667 
Epoch [193/300] Training [52/62] Loss: 0.05517 
Epoch [193/300] Training [53/62] Loss: 0.07506 
Epoch [193/300] Training [54/62] Loss: 0.08146 
Epoch [193/300] Training [55/62] Loss: 0.04616 
Epoch [193/300] Training [56/62] Loss: 0.04608 
Epoch [193/300] Training [57/62] Loss: 0.11235 
Epoch [193/300] Training [58/62] Loss: 0.06548 
Epoch [193/300] Training [59/62] Loss: 0.05812 
Epoch [193/300] Training [60/62] Loss: 0.04597 
Epoch [193/300] Training [61/62] Loss: 0.04773 
Epoch [193/300] Training [62/62] Loss: 0.04584 
Epoch [193/300] Training metric {'Train/mean dice_metric': 0.9468647241592407, 'Train/mean miou_metric': 0.9053228497505188, 'Train/mean f1': 0.9545875787734985, 'Train/mean precision': 0.9484741687774658, 'Train/mean recall': 0.9607802033424377, 'Train/mean hd95_metric': 8.295065879821777}
Epoch [193/300] Validation [1/16] Loss: 0.58811  focal_loss 0.40847  dice_loss 0.17964 
Epoch [193/300] Validation [2/16] Loss: 0.37311  focal_loss 0.14647  dice_loss 0.22664 
Epoch [193/300] Validation [3/16] Loss: 0.67265  focal_loss 0.40722  dice_loss 0.26543 
Epoch [193/300] Validation [4/16] Loss: 0.19170  focal_loss 0.07419  dice_loss 0.11751 
Epoch [193/300] Validation [5/16] Loss: 0.34367  focal_loss 0.12095  dice_loss 0.22272 
Epoch [193/300] Validation [6/16] Loss: 0.20353  focal_loss 0.03938  dice_loss 0.16415 
Epoch [193/300] Validation [7/16] Loss: 0.20500  focal_loss 0.08918  dice_loss 0.11582 
Epoch [193/300] Validation [8/16] Loss: 0.23634  focal_loss 0.06319  dice_loss 0.17315 
Epoch [193/300] Validation [9/16] Loss: 0.26135  focal_loss 0.12259  dice_loss 0.13875 
Epoch [193/300] Validation [10/16] Loss: 0.13457  focal_loss 0.02889  dice_loss 0.10568 
Epoch [193/300] Validation [11/16] Loss: 0.17330  focal_loss 0.05323  dice_loss 0.12007 
Epoch [193/300] Validation [12/16] Loss: 0.39447  focal_loss 0.10176  dice_loss 0.29271 
Epoch [193/300] Validation [13/16] Loss: 0.21731  focal_loss 0.06955  dice_loss 0.14776 
Epoch [193/300] Validation [14/16] Loss: 0.36660  focal_loss 0.12133  dice_loss 0.24527 
Epoch [193/300] Validation [15/16] Loss: 0.08107  focal_loss 0.02147  dice_loss 0.05961 
Epoch [193/300] Validation [16/16] Loss: 0.03769  focal_loss 0.00837  dice_loss 0.02933 
Epoch [193/300] Validation metric {'Val/mean dice_metric': 0.924956202507019, 'Val/mean miou_metric': 0.8763940334320068, 'Val/mean f1': 0.9340562224388123, 'Val/mean precision': 0.9326730370521545, 'Val/mean recall': 0.9354435205459595, 'Val/mean hd95_metric': 14.197932243347168}
Cheakpoint...
Epoch [193/300] best acc:tensor([0.9295], device='cuda:0'), Now : mean acc: tensor([0.9250], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.924956202507019, 'Val/mean miou_metric': 0.8763940334320068, 'Val/mean f1': 0.9340562224388123, 'Val/mean precision': 0.9326730370521545, 'Val/mean recall': 0.9354435205459595, 'Val/mean hd95_metric': 14.197932243347168}
Epoch [194/300] Training [1/62] Loss: 0.06990 
Epoch [194/300] Training [2/62] Loss: 0.05434 
Epoch [194/300] Training [3/62] Loss: 0.04050 
Epoch [194/300] Training [4/62] Loss: 0.06181 
Epoch [194/300] Training [5/62] Loss: 0.09474 
Epoch [194/300] Training [6/62] Loss: 0.04420 
Epoch [194/300] Training [7/62] Loss: 0.05161 
Epoch [194/300] Training [8/62] Loss: 0.04978 
Epoch [194/300] Training [9/62] Loss: 0.06401 
Epoch [194/300] Training [10/62] Loss: 0.05339 
Epoch [194/300] Training [11/62] Loss: 0.07836 
Epoch [194/300] Training [12/62] Loss: 0.07129 
Epoch [194/300] Training [13/62] Loss: 0.07671 
Epoch [194/300] Training [14/62] Loss: 0.11583 
Epoch [194/300] Training [15/62] Loss: 0.05005 
Epoch [194/300] Training [16/62] Loss: 0.04182 
Epoch [194/300] Training [17/62] Loss: 0.05058 
Epoch [194/300] Training [18/62] Loss: 0.05211 
Epoch [194/300] Training [19/62] Loss: 0.06332 
Epoch [194/300] Training [20/62] Loss: 0.09592 
Epoch [194/300] Training [21/62] Loss: 0.06458 
Epoch [194/300] Training [22/62] Loss: 0.05979 
Epoch [194/300] Training [23/62] Loss: 0.06565 
Epoch [194/300] Training [24/62] Loss: 0.10013 
Epoch [194/300] Training [25/62] Loss: 0.08510 
Epoch [194/300] Training [26/62] Loss: 0.04720 
Epoch [194/300] Training [27/62] Loss: 0.04317 
Epoch [194/300] Training [28/62] Loss: 0.11590 
Epoch [194/300] Training [29/62] Loss: 0.05916 
Epoch [194/300] Training [30/62] Loss: 0.06453 
Epoch [194/300] Training [31/62] Loss: 0.05333 
Epoch [194/300] Training [32/62] Loss: 0.09071 
Epoch [194/300] Training [33/62] Loss: 0.06638 
Epoch [194/300] Training [34/62] Loss: 0.06273 
Epoch [194/300] Training [35/62] Loss: 0.08136 
Epoch [194/300] Training [36/62] Loss: 0.06390 
Epoch [194/300] Training [37/62] Loss: 0.04189 
Epoch [194/300] Training [38/62] Loss: 0.05857 
Epoch [194/300] Training [39/62] Loss: 0.05245 
Epoch [194/300] Training [40/62] Loss: 0.05714 
Epoch [194/300] Training [41/62] Loss: 0.04447 
Epoch [194/300] Training [42/62] Loss: 0.05640 
Epoch [194/300] Training [43/62] Loss: 0.14651 
Epoch [194/300] Training [44/62] Loss: 0.06068 
Epoch [194/300] Training [45/62] Loss: 0.04178 
Epoch [194/300] Training [46/62] Loss: 0.12791 
Epoch [194/300] Training [47/62] Loss: 0.06365 
Epoch [194/300] Training [48/62] Loss: 0.09394 
Epoch [194/300] Training [49/62] Loss: 0.04687 
Epoch [194/300] Training [50/62] Loss: 0.04629 
Epoch [194/300] Training [51/62] Loss: 0.06902 
Epoch [194/300] Training [52/62] Loss: 0.05683 
Epoch [194/300] Training [53/62] Loss: 0.06713 
Epoch [194/300] Training [54/62] Loss: 0.05055 
Epoch [194/300] Training [55/62] Loss: 0.03950 
Epoch [194/300] Training [56/62] Loss: 0.07349 
Epoch [194/300] Training [57/62] Loss: 0.13518 
Epoch [194/300] Training [58/62] Loss: 0.16386 
Epoch [194/300] Training [59/62] Loss: 0.05715 
Epoch [194/300] Training [60/62] Loss: 0.05542 
Epoch [194/300] Training [61/62] Loss: 0.05481 
Epoch [194/300] Training [62/62] Loss: 0.39005 
Epoch [194/300] Training metric {'Train/mean dice_metric': 0.9521433115005493, 'Train/mean miou_metric': 0.9132382273674011, 'Train/mean f1': 0.9587892889976501, 'Train/mean precision': 0.9538654685020447, 'Train/mean recall': 0.9637642502784729, 'Train/mean hd95_metric': 7.303885459899902}
Epoch [194/300] Validation [1/16] Loss: 0.52309  focal_loss 0.34140  dice_loss 0.18169 
Epoch [194/300] Validation [2/16] Loss: 0.25707  focal_loss 0.12899  dice_loss 0.12807 
Epoch [194/300] Validation [3/16] Loss: 0.63237  focal_loss 0.35089  dice_loss 0.28147 
Epoch [194/300] Validation [4/16] Loss: 0.29722  focal_loss 0.14344  dice_loss 0.15378 
Epoch [194/300] Validation [5/16] Loss: 0.31360  focal_loss 0.07892  dice_loss 0.23468 
Epoch [194/300] Validation [6/16] Loss: 0.20482  focal_loss 0.04968  dice_loss 0.15514 
Epoch [194/300] Validation [7/16] Loss: 0.18404  focal_loss 0.06092  dice_loss 0.12312 
Epoch [194/300] Validation [8/16] Loss: 0.31581  focal_loss 0.09102  dice_loss 0.22479 
Epoch [194/300] Validation [9/16] Loss: 0.19397  focal_loss 0.07255  dice_loss 0.12142 
Epoch [194/300] Validation [10/16] Loss: 0.29273  focal_loss 0.08657  dice_loss 0.20616 
Epoch [194/300] Validation [11/16] Loss: 0.19740  focal_loss 0.06910  dice_loss 0.12830 
Epoch [194/300] Validation [12/16] Loss: 0.34768  focal_loss 0.07952  dice_loss 0.26816 
Epoch [194/300] Validation [13/16] Loss: 0.22989  focal_loss 0.07169  dice_loss 0.15820 
Epoch [194/300] Validation [14/16] Loss: 0.55765  focal_loss 0.18086  dice_loss 0.37679 
Epoch [194/300] Validation [15/16] Loss: 0.10440  focal_loss 0.03059  dice_loss 0.07381 
Epoch [194/300] Validation [16/16] Loss: 0.04728  focal_loss 0.01003  dice_loss 0.03725 
Epoch [194/300] Validation metric {'Val/mean dice_metric': 0.9258177280426025, 'Val/mean miou_metric': 0.8789527416229248, 'Val/mean f1': 0.9347732067108154, 'Val/mean precision': 0.9363760948181152, 'Val/mean recall': 0.9331756830215454, 'Val/mean hd95_metric': 12.684731483459473}
Cheakpoint...
Epoch [194/300] best acc:tensor([0.9295], device='cuda:0'), Now : mean acc: tensor([0.9258], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9258177280426025, 'Val/mean miou_metric': 0.8789527416229248, 'Val/mean f1': 0.9347732067108154, 'Val/mean precision': 0.9363760948181152, 'Val/mean recall': 0.9331756830215454, 'Val/mean hd95_metric': 12.684731483459473}
Epoch [195/300] Training [1/62] Loss: 0.10705 
Epoch [195/300] Training [2/62] Loss: 0.09578 
Epoch [195/300] Training [3/62] Loss: 0.06259 
Epoch [195/300] Training [4/62] Loss: 0.09515 
Epoch [195/300] Training [5/62] Loss: 0.05444 
Epoch [195/300] Training [6/62] Loss: 0.10213 
Epoch [195/300] Training [7/62] Loss: 0.16026 
Epoch [195/300] Training [8/62] Loss: 0.16644 
Epoch [195/300] Training [9/62] Loss: 0.06276 
Epoch [195/300] Training [10/62] Loss: 0.06071 
Epoch [195/300] Training [11/62] Loss: 0.05111 
Epoch [195/300] Training [12/62] Loss: 0.04836 
Epoch [195/300] Training [13/62] Loss: 0.06084 
Epoch [195/300] Training [14/62] Loss: 0.06042 
Epoch [195/300] Training [15/62] Loss: 0.09523 
Epoch [195/300] Training [16/62] Loss: 0.03478 
Epoch [195/300] Training [17/62] Loss: 0.14566 
Epoch [195/300] Training [18/62] Loss: 0.04714 
Epoch [195/300] Training [19/62] Loss: 0.05128 
Epoch [195/300] Training [20/62] Loss: 0.07262 
Epoch [195/300] Training [21/62] Loss: 0.03707 
Epoch [195/300] Training [22/62] Loss: 0.05825 
Epoch [195/300] Training [23/62] Loss: 0.06572 
Epoch [195/300] Training [24/62] Loss: 0.05288 
Epoch [195/300] Training [25/62] Loss: 0.05264 
Epoch [195/300] Training [26/62] Loss: 0.04547 
Epoch [195/300] Training [27/62] Loss: 0.07580 
Epoch [195/300] Training [28/62] Loss: 0.04377 
Epoch [195/300] Training [29/62] Loss: 0.06606 
Epoch [195/300] Training [30/62] Loss: 0.08618 
Epoch [195/300] Training [31/62] Loss: 0.04708 
Epoch [195/300] Training [32/62] Loss: 0.05004 
Epoch [195/300] Training [33/62] Loss: 0.05453 
Epoch [195/300] Training [34/62] Loss: 0.11155 
Epoch [195/300] Training [35/62] Loss: 0.07965 
Epoch [195/300] Training [36/62] Loss: 0.06387 
Epoch [195/300] Training [37/62] Loss: 0.08607 
Epoch [195/300] Training [38/62] Loss: 0.04465 
Epoch [195/300] Training [39/62] Loss: 0.05805 
Epoch [195/300] Training [40/62] Loss: 0.06475 
Epoch [195/300] Training [41/62] Loss: 0.08322 
Epoch [195/300] Training [42/62] Loss: 0.04798 
Epoch [195/300] Training [43/62] Loss: 0.11814 
Epoch [195/300] Training [44/62] Loss: 0.06279 
Epoch [195/300] Training [45/62] Loss: 0.08022 
Epoch [195/300] Training [46/62] Loss: 0.05952 
Epoch [195/300] Training [47/62] Loss: 0.08232 
Epoch [195/300] Training [48/62] Loss: 0.05017 
Epoch [195/300] Training [49/62] Loss: 0.10771 
Epoch [195/300] Training [50/62] Loss: 0.05862 
Epoch [195/300] Training [51/62] Loss: 0.06470 
Epoch [195/300] Training [52/62] Loss: 0.05647 
Epoch [195/300] Training [53/62] Loss: 0.05891 
Epoch [195/300] Training [54/62] Loss: 0.06633 
Epoch [195/300] Training [55/62] Loss: 0.08216 
Epoch [195/300] Training [56/62] Loss: 0.06816 
Epoch [195/300] Training [57/62] Loss: 0.07831 
Epoch [195/300] Training [58/62] Loss: 0.07026 
Epoch [195/300] Training [59/62] Loss: 0.07258 
Epoch [195/300] Training [60/62] Loss: 0.05023 
Epoch [195/300] Training [61/62] Loss: 0.08889 
Epoch [195/300] Training [62/62] Loss: 0.02997 
Epoch [195/300] Training metric {'Train/mean dice_metric': 0.9490938186645508, 'Train/mean miou_metric': 0.9084770679473877, 'Train/mean f1': 0.9578122496604919, 'Train/mean precision': 0.9534448385238647, 'Train/mean recall': 0.9622198343276978, 'Train/mean hd95_metric': 8.098576545715332}
Epoch [195/300] Validation [1/16] Loss: 0.38765  focal_loss 0.23772  dice_loss 0.14994 
Epoch [195/300] Validation [2/16] Loss: 0.33977  focal_loss 0.11678  dice_loss 0.22299 
Epoch [195/300] Validation [3/16] Loss: 0.37426  focal_loss 0.13652  dice_loss 0.23774 
Epoch [195/300] Validation [4/16] Loss: 0.29911  focal_loss 0.14069  dice_loss 0.15842 
Epoch [195/300] Validation [5/16] Loss: 0.24270  focal_loss 0.05869  dice_loss 0.18401 
Epoch [195/300] Validation [6/16] Loss: 0.24953  focal_loss 0.05313  dice_loss 0.19640 
Epoch [195/300] Validation [7/16] Loss: 0.19914  focal_loss 0.07258  dice_loss 0.12656 
Epoch [195/300] Validation [8/16] Loss: 0.32829  focal_loss 0.09804  dice_loss 0.23024 
Epoch [195/300] Validation [9/16] Loss: 0.14503  focal_loss 0.05138  dice_loss 0.09365 
Epoch [195/300] Validation [10/16] Loss: 0.20500  focal_loss 0.06214  dice_loss 0.14285 
Epoch [195/300] Validation [11/16] Loss: 0.15581  focal_loss 0.04883  dice_loss 0.10697 
Epoch [195/300] Validation [12/16] Loss: 0.33053  focal_loss 0.08165  dice_loss 0.24887 
Epoch [195/300] Validation [13/16] Loss: 0.24256  focal_loss 0.07375  dice_loss 0.16881 
Epoch [195/300] Validation [14/16] Loss: 0.44967  focal_loss 0.15737  dice_loss 0.29230 
Epoch [195/300] Validation [15/16] Loss: 0.10228  focal_loss 0.02964  dice_loss 0.07263 
Epoch [195/300] Validation [16/16] Loss: 0.04478  focal_loss 0.01059  dice_loss 0.03420 
Epoch [195/300] Validation metric {'Val/mean dice_metric': 0.9256975054740906, 'Val/mean miou_metric': 0.8779745697975159, 'Val/mean f1': 0.9367649555206299, 'Val/mean precision': 0.9361611008644104, 'Val/mean recall': 0.9373697638511658, 'Val/mean hd95_metric': 13.1669282913208}
Cheakpoint...
Epoch [195/300] best acc:tensor([0.9295], device='cuda:0'), Now : mean acc: tensor([0.9257], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9256975054740906, 'Val/mean miou_metric': 0.8779745697975159, 'Val/mean f1': 0.9367649555206299, 'Val/mean precision': 0.9361611008644104, 'Val/mean recall': 0.9373697638511658, 'Val/mean hd95_metric': 13.1669282913208}
Epoch [196/300] Training [1/62] Loss: 0.08216 
Epoch [196/300] Training [2/62] Loss: 0.08302 
Epoch [196/300] Training [3/62] Loss: 0.04983 
Epoch [196/300] Training [4/62] Loss: 0.04159 
Epoch [196/300] Training [5/62] Loss: 0.07379 
Epoch [196/300] Training [6/62] Loss: 0.05117 
Epoch [196/300] Training [7/62] Loss: 0.03835 
Epoch [196/300] Training [8/62] Loss: 0.04594 
Epoch [196/300] Training [9/62] Loss: 0.05584 
Epoch [196/300] Training [10/62] Loss: 0.06998 
Epoch [196/300] Training [11/62] Loss: 0.07514 
Epoch [196/300] Training [12/62] Loss: 0.04827 
Epoch [196/300] Training [13/62] Loss: 0.09039 
Epoch [196/300] Training [14/62] Loss: 0.04703 
Epoch [196/300] Training [15/62] Loss: 0.04685 
Epoch [196/300] Training [16/62] Loss: 0.05473 
Epoch [196/300] Training [17/62] Loss: 0.07504 
Epoch [196/300] Training [18/62] Loss: 0.13750 
Epoch [196/300] Training [19/62] Loss: 0.07088 
Epoch [196/300] Training [20/62] Loss: 0.04381 
Epoch [196/300] Training [21/62] Loss: 0.06707 
Epoch [196/300] Training [22/62] Loss: 0.07029 
Epoch [196/300] Training [23/62] Loss: 0.17962 
Epoch [196/300] Training [24/62] Loss: 0.04831 
Epoch [196/300] Training [25/62] Loss: 0.07318 
Epoch [196/300] Training [26/62] Loss: 0.04901 
Epoch [196/300] Training [27/62] Loss: 0.08965 
Epoch [196/300] Training [28/62] Loss: 0.09218 
Epoch [196/300] Training [29/62] Loss: 0.08033 
Epoch [196/300] Training [30/62] Loss: 0.07723 
Epoch [196/300] Training [31/62] Loss: 0.04612 
Epoch [196/300] Training [32/62] Loss: 0.05479 
Epoch [196/300] Training [33/62] Loss: 0.03510 
Epoch [196/300] Training [34/62] Loss: 0.08692 
Epoch [196/300] Training [35/62] Loss: 0.04558 
Epoch [196/300] Training [36/62] Loss: 0.04080 
Epoch [196/300] Training [37/62] Loss: 0.04575 
Epoch [196/300] Training [38/62] Loss: 0.05534 
Epoch [196/300] Training [39/62] Loss: 0.04224 
Epoch [196/300] Training [40/62] Loss: 0.04125 
Epoch [196/300] Training [41/62] Loss: 0.06719 
Epoch [196/300] Training [42/62] Loss: 0.04894 
Epoch [196/300] Training [43/62] Loss: 0.05144 
Epoch [196/300] Training [44/62] Loss: 0.06068 
Epoch [196/300] Training [45/62] Loss: 0.10400 
Epoch [196/300] Training [46/62] Loss: 0.06402 
Epoch [196/300] Training [47/62] Loss: 0.05588 
Epoch [196/300] Training [48/62] Loss: 0.06406 
Epoch [196/300] Training [49/62] Loss: 0.06005 
Epoch [196/300] Training [50/62] Loss: 0.06136 
Epoch [196/300] Training [51/62] Loss: 0.04379 
Epoch [196/300] Training [52/62] Loss: 0.06020 
Epoch [196/300] Training [53/62] Loss: 0.05652 
Epoch [196/300] Training [54/62] Loss: 0.06181 
Epoch [196/300] Training [55/62] Loss: 0.09665 
Epoch [196/300] Training [56/62] Loss: 0.04261 
Epoch [196/300] Training [57/62] Loss: 0.04745 
Epoch [196/300] Training [58/62] Loss: 0.05917 
Epoch [196/300] Training [59/62] Loss: 0.06455 
Epoch [196/300] Training [60/62] Loss: 0.11226 
Epoch [196/300] Training [61/62] Loss: 0.10419 
Epoch [196/300] Training [62/62] Loss: 0.06190 
Epoch [196/300] Training metric {'Train/mean dice_metric': 0.9534896016120911, 'Train/mean miou_metric': 0.9156853556632996, 'Train/mean f1': 0.9606844186782837, 'Train/mean precision': 0.9558861255645752, 'Train/mean recall': 0.965531051158905, 'Train/mean hd95_metric': 8.426593780517578}
Epoch [196/300] Validation [1/16] Loss: 0.09270  focal_loss 0.03218  dice_loss 0.06052 
Epoch [196/300] Validation [2/16] Loss: 0.27743  focal_loss 0.14871  dice_loss 0.12872 
Epoch [196/300] Validation [3/16] Loss: 0.23745  focal_loss 0.07925  dice_loss 0.15820 
Epoch [196/300] Validation [4/16] Loss: 0.24016  focal_loss 0.12089  dice_loss 0.11927 
Epoch [196/300] Validation [5/16] Loss: 0.28791  focal_loss 0.08110  dice_loss 0.20681 
Epoch [196/300] Validation [6/16] Loss: 0.21039  focal_loss 0.04471  dice_loss 0.16568 
Epoch [196/300] Validation [7/16] Loss: 0.15196  focal_loss 0.05450  dice_loss 0.09747 
Epoch [196/300] Validation [8/16] Loss: 0.24801  focal_loss 0.05879  dice_loss 0.18922 
Epoch [196/300] Validation [9/16] Loss: 0.15146  focal_loss 0.05868  dice_loss 0.09279 
Epoch [196/300] Validation [10/16] Loss: 0.21794  focal_loss 0.06586  dice_loss 0.15209 
Epoch [196/300] Validation [11/16] Loss: 0.11947  focal_loss 0.03145  dice_loss 0.08803 
Epoch [196/300] Validation [12/16] Loss: 0.28755  focal_loss 0.05461  dice_loss 0.23293 
Epoch [196/300] Validation [13/16] Loss: 0.18494  focal_loss 0.05699  dice_loss 0.12795 
Epoch [196/300] Validation [14/16] Loss: 0.50822  focal_loss 0.16749  dice_loss 0.34073 
Epoch [196/300] Validation [15/16] Loss: 0.17842  focal_loss 0.06220  dice_loss 0.11622 
Epoch [196/300] Validation [16/16] Loss: 0.05435  focal_loss 0.01365  dice_loss 0.04071 
Epoch [196/300] Validation metric {'Val/mean dice_metric': 0.9341612458229065, 'Val/mean miou_metric': 0.8883259892463684, 'Val/mean f1': 0.943432092666626, 'Val/mean precision': 0.9378440976142883, 'Val/mean recall': 0.9490869045257568, 'Val/mean hd95_metric': 13.398408889770508}
Cheakpoint...
Epoch [196/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9342], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9341612458229065, 'Val/mean miou_metric': 0.8883259892463684, 'Val/mean f1': 0.943432092666626, 'Val/mean precision': 0.9378440976142883, 'Val/mean recall': 0.9490869045257568, 'Val/mean hd95_metric': 13.398408889770508}
Epoch [197/300] Training [1/62] Loss: 0.10439 
Epoch [197/300] Training [2/62] Loss: 0.06576 
Epoch [197/300] Training [3/62] Loss: 0.06529 
Epoch [197/300] Training [4/62] Loss: 0.09141 
Epoch [197/300] Training [5/62] Loss: 0.07926 
Epoch [197/300] Training [6/62] Loss: 0.05685 
Epoch [197/300] Training [7/62] Loss: 0.10410 
Epoch [197/300] Training [8/62] Loss: 0.07758 
Epoch [197/300] Training [9/62] Loss: 0.04736 
Epoch [197/300] Training [10/62] Loss: 0.05420 
Epoch [197/300] Training [11/62] Loss: 0.05030 
Epoch [197/300] Training [12/62] Loss: 0.04528 
Epoch [197/300] Training [13/62] Loss: 0.03865 
Epoch [197/300] Training [14/62] Loss: 0.04837 
Epoch [197/300] Training [15/62] Loss: 0.10259 
Epoch [197/300] Training [16/62] Loss: 0.09060 
Epoch [197/300] Training [17/62] Loss: 0.07285 
Epoch [197/300] Training [18/62] Loss: 0.06468 
Epoch [197/300] Training [19/62] Loss: 0.04081 
Epoch [197/300] Training [20/62] Loss: 0.08685 
Epoch [197/300] Training [21/62] Loss: 0.04899 
Epoch [197/300] Training [22/62] Loss: 0.06389 
Epoch [197/300] Training [23/62] Loss: 0.05661 
Epoch [197/300] Training [24/62] Loss: 0.08518 
Epoch [197/300] Training [25/62] Loss: 0.05475 
Epoch [197/300] Training [26/62] Loss: 0.07899 
Epoch [197/300] Training [27/62] Loss: 0.07936 
Epoch [197/300] Training [28/62] Loss: 0.04968 
Epoch [197/300] Training [29/62] Loss: 0.04164 
Epoch [197/300] Training [30/62] Loss: 0.06143 
Epoch [197/300] Training [31/62] Loss: 0.04640 
Epoch [197/300] Training [32/62] Loss: 0.05943 
Epoch [197/300] Training [33/62] Loss: 0.09117 
Epoch [197/300] Training [34/62] Loss: 0.05601 
Epoch [197/300] Training [35/62] Loss: 0.05701 
Epoch [197/300] Training [36/62] Loss: 0.05742 
Epoch [197/300] Training [37/62] Loss: 0.05488 
Epoch [197/300] Training [38/62] Loss: 0.07163 
Epoch [197/300] Training [39/62] Loss: 0.08988 
Epoch [197/300] Training [40/62] Loss: 0.04628 
Epoch [197/300] Training [41/62] Loss: 0.05980 
Epoch [197/300] Training [42/62] Loss: 0.08258 
Epoch [197/300] Training [43/62] Loss: 0.17420 
Epoch [197/300] Training [44/62] Loss: 0.05108 
Epoch [197/300] Training [45/62] Loss: 0.06227 
Epoch [197/300] Training [46/62] Loss: 0.06015 
Epoch [197/300] Training [47/62] Loss: 0.06453 
Epoch [197/300] Training [48/62] Loss: 0.06251 
Epoch [197/300] Training [49/62] Loss: 0.07126 
Epoch [197/300] Training [50/62] Loss: 0.04957 
Epoch [197/300] Training [51/62] Loss: 0.04394 
Epoch [197/300] Training [52/62] Loss: 0.05619 
Epoch [197/300] Training [53/62] Loss: 0.10736 
Epoch [197/300] Training [54/62] Loss: 0.04976 
Epoch [197/300] Training [55/62] Loss: 0.08977 
Epoch [197/300] Training [56/62] Loss: 0.04689 
Epoch [197/300] Training [57/62] Loss: 0.05647 
Epoch [197/300] Training [58/62] Loss: 0.05543 
Epoch [197/300] Training [59/62] Loss: 0.06520 
Epoch [197/300] Training [60/62] Loss: 0.06396 
Epoch [197/300] Training [61/62] Loss: 0.05084 
Epoch [197/300] Training [62/62] Loss: 0.16508 
Epoch [197/300] Training metric {'Train/mean dice_metric': 0.9532612562179565, 'Train/mean miou_metric': 0.9147595763206482, 'Train/mean f1': 0.9597375988960266, 'Train/mean precision': 0.9557616710662842, 'Train/mean recall': 0.9637468457221985, 'Train/mean hd95_metric': 8.253299713134766}
Epoch [197/300] Validation [1/16] Loss: 0.11320  focal_loss 0.04792  dice_loss 0.06527 
Epoch [197/300] Validation [2/16] Loss: 0.41418  focal_loss 0.19113  dice_loss 0.22304 
Epoch [197/300] Validation [3/16] Loss: 0.36328  focal_loss 0.15671  dice_loss 0.20657 
Epoch [197/300] Validation [4/16] Loss: 0.25824  focal_loss 0.13091  dice_loss 0.12733 
Epoch [197/300] Validation [5/16] Loss: 0.27404  focal_loss 0.10130  dice_loss 0.17274 
Epoch [197/300] Validation [6/16] Loss: 0.22491  focal_loss 0.04943  dice_loss 0.17548 
Epoch [197/300] Validation [7/16] Loss: 0.11860  focal_loss 0.03744  dice_loss 0.08116 
Epoch [197/300] Validation [8/16] Loss: 0.41752  focal_loss 0.14298  dice_loss 0.27454 
Epoch [197/300] Validation [9/16] Loss: 0.17629  focal_loss 0.08005  dice_loss 0.09624 
Epoch [197/300] Validation [10/16] Loss: 0.14460  focal_loss 0.04025  dice_loss 0.10435 
Epoch [197/300] Validation [11/16] Loss: 0.21078  focal_loss 0.07655  dice_loss 0.13423 
Epoch [197/300] Validation [12/16] Loss: 0.29895  focal_loss 0.07219  dice_loss 0.22676 
Epoch [197/300] Validation [13/16] Loss: 0.26883  focal_loss 0.11791  dice_loss 0.15092 
Epoch [197/300] Validation [14/16] Loss: 0.54959  focal_loss 0.19468  dice_loss 0.35491 
Epoch [197/300] Validation [15/16] Loss: 0.18347  focal_loss 0.06212  dice_loss 0.12134 
Epoch [197/300] Validation [16/16] Loss: 0.06865  focal_loss 0.02450  dice_loss 0.04416 
Epoch [197/300] Validation metric {'Val/mean dice_metric': 0.9308070540428162, 'Val/mean miou_metric': 0.8842795491218567, 'Val/mean f1': 0.9391862154006958, 'Val/mean precision': 0.9360013008117676, 'Val/mean recall': 0.9423929452896118, 'Val/mean hd95_metric': 14.047628402709961}
Cheakpoint...
Epoch [197/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9308], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9308070540428162, 'Val/mean miou_metric': 0.8842795491218567, 'Val/mean f1': 0.9391862154006958, 'Val/mean precision': 0.9360013008117676, 'Val/mean recall': 0.9423929452896118, 'Val/mean hd95_metric': 14.047628402709961}
Epoch [198/300] Training [1/62] Loss: 0.07437 
Epoch [198/300] Training [2/62] Loss: 0.06376 
Epoch [198/300] Training [3/62] Loss: 0.04358 
Epoch [198/300] Training [4/62] Loss: 0.13655 
Epoch [198/300] Training [5/62] Loss: 0.07091 
Epoch [198/300] Training [6/62] Loss: 0.04895 
Epoch [198/300] Training [7/62] Loss: 0.07822 
Epoch [198/300] Training [8/62] Loss: 0.04221 
Epoch [198/300] Training [9/62] Loss: 0.11288 
Epoch [198/300] Training [10/62] Loss: 0.03732 
Epoch [198/300] Training [11/62] Loss: 0.05882 
Epoch [198/300] Training [12/62] Loss: 0.04252 
Epoch [198/300] Training [13/62] Loss: 0.05243 
Epoch [198/300] Training [14/62] Loss: 0.06944 
Epoch [198/300] Training [15/62] Loss: 0.05735 
Epoch [198/300] Training [16/62] Loss: 0.06108 
Epoch [198/300] Training [17/62] Loss: 0.05558 
Epoch [198/300] Training [18/62] Loss: 0.04952 
Epoch [198/300] Training [19/62] Loss: 0.07709 
Epoch [198/300] Training [20/62] Loss: 0.16039 
Epoch [198/300] Training [21/62] Loss: 0.06804 
Epoch [198/300] Training [22/62] Loss: 0.05859 
Epoch [198/300] Training [23/62] Loss: 0.04133 
Epoch [198/300] Training [24/62] Loss: 0.08697 
Epoch [198/300] Training [25/62] Loss: 0.04894 
Epoch [198/300] Training [26/62] Loss: 0.08927 
Epoch [198/300] Training [27/62] Loss: 0.06431 
Epoch [198/300] Training [28/62] Loss: 0.09986 
Epoch [198/300] Training [29/62] Loss: 0.04808 
Epoch [198/300] Training [30/62] Loss: 0.04371 
Epoch [198/300] Training [31/62] Loss: 0.07007 
Epoch [198/300] Training [32/62] Loss: 0.04710 
Epoch [198/300] Training [33/62] Loss: 0.08757 
Epoch [198/300] Training [34/62] Loss: 0.11060 
Epoch [198/300] Training [35/62] Loss: 0.05660 
Epoch [198/300] Training [36/62] Loss: 0.06300 
Epoch [198/300] Training [37/62] Loss: 0.07202 
Epoch [198/300] Training [38/62] Loss: 0.05779 
Epoch [198/300] Training [39/62] Loss: 0.07201 
Epoch [198/300] Training [40/62] Loss: 0.04923 
Epoch [198/300] Training [41/62] Loss: 0.05419 
Epoch [198/300] Training [42/62] Loss: 0.09503 
Epoch [198/300] Training [43/62] Loss: 0.07008 
Epoch [198/300] Training [44/62] Loss: 0.06011 
Epoch [198/300] Training [45/62] Loss: 0.13441 
Epoch [198/300] Training [46/62] Loss: 0.07568 
Epoch [198/300] Training [47/62] Loss: 0.04105 
Epoch [198/300] Training [48/62] Loss: 0.04939 
Epoch [198/300] Training [49/62] Loss: 0.09036 
Epoch [198/300] Training [50/62] Loss: 0.05396 
Epoch [198/300] Training [51/62] Loss: 0.04370 
Epoch [198/300] Training [52/62] Loss: 0.10321 
Epoch [198/300] Training [53/62] Loss: 0.08788 
Epoch [198/300] Training [54/62] Loss: 0.06299 
Epoch [198/300] Training [55/62] Loss: 0.06065 
Epoch [198/300] Training [56/62] Loss: 0.08073 
Epoch [198/300] Training [57/62] Loss: 0.06037 
Epoch [198/300] Training [58/62] Loss: 0.03927 
Epoch [198/300] Training [59/62] Loss: 0.05756 
Epoch [198/300] Training [60/62] Loss: 0.05180 
Epoch [198/300] Training [61/62] Loss: 0.03793 
Epoch [198/300] Training [62/62] Loss: 0.03765 
Epoch [198/300] Training metric {'Train/mean dice_metric': 0.9537081122398376, 'Train/mean miou_metric': 0.9150446057319641, 'Train/mean f1': 0.9580317735671997, 'Train/mean precision': 0.9540977478027344, 'Train/mean recall': 0.9619983434677124, 'Train/mean hd95_metric': 8.171354293823242}
Epoch [198/300] Validation [1/16] Loss: 0.12858  focal_loss 0.03990  dice_loss 0.08869 
Epoch [198/300] Validation [2/16] Loss: 0.39411  focal_loss 0.15547  dice_loss 0.23865 
Epoch [198/300] Validation [3/16] Loss: 0.29904  focal_loss 0.08678  dice_loss 0.21225 
Epoch [198/300] Validation [4/16] Loss: 0.20973  focal_loss 0.09252  dice_loss 0.11721 
Epoch [198/300] Validation [5/16] Loss: 0.32056  focal_loss 0.11988  dice_loss 0.20068 
Epoch [198/300] Validation [6/16] Loss: 0.28351  focal_loss 0.10008  dice_loss 0.18343 
Epoch [198/300] Validation [7/16] Loss: 0.22349  focal_loss 0.10239  dice_loss 0.12109 
Epoch [198/300] Validation [8/16] Loss: 0.38316  focal_loss 0.13965  dice_loss 0.24351 
Epoch [198/300] Validation [9/16] Loss: 0.16590  focal_loss 0.06358  dice_loss 0.10233 
Epoch [198/300] Validation [10/16] Loss: 0.31858  focal_loss 0.10010  dice_loss 0.21848 
Epoch [198/300] Validation [11/16] Loss: 0.16215  focal_loss 0.05273  dice_loss 0.10943 
Epoch [198/300] Validation [12/16] Loss: 0.29496  focal_loss 0.07713  dice_loss 0.21783 
Epoch [198/300] Validation [13/16] Loss: 0.17213  focal_loss 0.04803  dice_loss 0.12411 
Epoch [198/300] Validation [14/16] Loss: 0.50463  focal_loss 0.15472  dice_loss 0.34990 
Epoch [198/300] Validation [15/16] Loss: 0.20958  focal_loss 0.08190  dice_loss 0.12768 
Epoch [198/300] Validation [16/16] Loss: 0.06682  focal_loss 0.01879  dice_loss 0.04803 
Epoch [198/300] Validation metric {'Val/mean dice_metric': 0.9293133020401001, 'Val/mean miou_metric': 0.8834270238876343, 'Val/mean f1': 0.9355548024177551, 'Val/mean precision': 0.9287711977958679, 'Val/mean recall': 0.9424382448196411, 'Val/mean hd95_metric': 14.310428619384766}
Cheakpoint...
Epoch [198/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9293], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9293133020401001, 'Val/mean miou_metric': 0.8834270238876343, 'Val/mean f1': 0.9355548024177551, 'Val/mean precision': 0.9287711977958679, 'Val/mean recall': 0.9424382448196411, 'Val/mean hd95_metric': 14.310428619384766}
Epoch [199/300] Training [1/62] Loss: 0.06753 
Epoch [199/300] Training [2/62] Loss: 0.08797 
Epoch [199/300] Training [3/62] Loss: 0.09225 
Epoch [199/300] Training [4/62] Loss: 0.10015 
Epoch [199/300] Training [5/62] Loss: 0.04477 
Epoch [199/300] Training [6/62] Loss: 0.05746 
Epoch [199/300] Training [7/62] Loss: 0.06585 
Epoch [199/300] Training [8/62] Loss: 0.06190 
Epoch [199/300] Training [9/62] Loss: 0.04121 
Epoch [199/300] Training [10/62] Loss: 0.04019 
Epoch [199/300] Training [11/62] Loss: 0.08207 
Epoch [199/300] Training [12/62] Loss: 0.09371 
Epoch [199/300] Training [13/62] Loss: 0.07924 
Epoch [199/300] Training [14/62] Loss: 0.04490 
Epoch [199/300] Training [15/62] Loss: 0.04817 
Epoch [199/300] Training [16/62] Loss: 0.05805 
Epoch [199/300] Training [17/62] Loss: 0.07305 
Epoch [199/300] Training [18/62] Loss: 0.06001 
Epoch [199/300] Training [19/62] Loss: 0.05676 
Epoch [199/300] Training [20/62] Loss: 0.07109 
Epoch [199/300] Training [21/62] Loss: 0.05683 
Epoch [199/300] Training [22/62] Loss: 0.04583 
Epoch [199/300] Training [23/62] Loss: 0.07432 
Epoch [199/300] Training [24/62] Loss: 0.05322 
Epoch [199/300] Training [25/62] Loss: 0.06188 
Epoch [199/300] Training [26/62] Loss: 0.06843 
Epoch [199/300] Training [27/62] Loss: 0.04536 
Epoch [199/300] Training [28/62] Loss: 0.05683 
Epoch [199/300] Training [29/62] Loss: 0.18951 
Epoch [199/300] Training [30/62] Loss: 0.07625 
Epoch [199/300] Training [31/62] Loss: 0.03967 
Epoch [199/300] Training [32/62] Loss: 0.09394 
Epoch [199/300] Training [33/62] Loss: 0.05102 
Epoch [199/300] Training [34/62] Loss: 0.07312 
Epoch [199/300] Training [35/62] Loss: 0.04284 
Epoch [199/300] Training [36/62] Loss: 0.08781 
Epoch [199/300] Training [37/62] Loss: 0.05191 
Epoch [199/300] Training [38/62] Loss: 0.03844 
Epoch [199/300] Training [39/62] Loss: 0.03956 
Epoch [199/300] Training [40/62] Loss: 0.05191 
Epoch [199/300] Training [41/62] Loss: 0.07499 
Epoch [199/300] Training [42/62] Loss: 0.06585 
Epoch [199/300] Training [43/62] Loss: 0.05523 
Epoch [199/300] Training [44/62] Loss: 0.05510 
Epoch [199/300] Training [45/62] Loss: 0.06062 
Epoch [199/300] Training [46/62] Loss: 0.09230 
Epoch [199/300] Training [47/62] Loss: 0.16089 
Epoch [199/300] Training [48/62] Loss: 0.09749 
Epoch [199/300] Training [49/62] Loss: 0.06210 
Epoch [199/300] Training [50/62] Loss: 0.07629 
Epoch [199/300] Training [51/62] Loss: 0.04505 
Epoch [199/300] Training [52/62] Loss: 0.05254 
Epoch [199/300] Training [53/62] Loss: 0.06218 
Epoch [199/300] Training [54/62] Loss: 0.05195 
Epoch [199/300] Training [55/62] Loss: 0.05219 
Epoch [199/300] Training [56/62] Loss: 0.06452 
Epoch [199/300] Training [57/62] Loss: 0.04992 
Epoch [199/300] Training [58/62] Loss: 0.09433 
Epoch [199/300] Training [59/62] Loss: 0.04480 
Epoch [199/300] Training [60/62] Loss: 0.04071 
Epoch [199/300] Training [61/62] Loss: 0.05063 
Epoch [199/300] Training [62/62] Loss: 0.05283 
Epoch [199/300] Training metric {'Train/mean dice_metric': 0.9539037942886353, 'Train/mean miou_metric': 0.9164164662361145, 'Train/mean f1': 0.9582931399345398, 'Train/mean precision': 0.9522367715835571, 'Train/mean recall': 0.9644270539283752, 'Train/mean hd95_metric': 7.801131248474121}
Epoch [199/300] Validation [1/16] Loss: 0.14044  focal_loss 0.05441  dice_loss 0.08603 
Epoch [199/300] Validation [2/16] Loss: 0.33592  focal_loss 0.10952  dice_loss 0.22639 
Epoch [199/300] Validation [3/16] Loss: 0.70142  focal_loss 0.41239  dice_loss 0.28903 
Epoch [199/300] Validation [4/16] Loss: 0.26050  focal_loss 0.12346  dice_loss 0.13704 
Epoch [199/300] Validation [5/16] Loss: 0.30222  focal_loss 0.10958  dice_loss 0.19264 
Epoch [199/300] Validation [6/16] Loss: 0.17470  focal_loss 0.03760  dice_loss 0.13710 
Epoch [199/300] Validation [7/16] Loss: 0.44968  focal_loss 0.22885  dice_loss 0.22083 
Epoch [199/300] Validation [8/16] Loss: 0.33453  focal_loss 0.10873  dice_loss 0.22580 
Epoch [199/300] Validation [9/16] Loss: 0.16666  focal_loss 0.06761  dice_loss 0.09905 
Epoch [199/300] Validation [10/16] Loss: 0.32448  focal_loss 0.10957  dice_loss 0.21491 
Epoch [199/300] Validation [11/16] Loss: 0.10350  focal_loss 0.02581  dice_loss 0.07769 
Epoch [199/300] Validation [12/16] Loss: 0.27597  focal_loss 0.05946  dice_loss 0.21651 
Epoch [199/300] Validation [13/16] Loss: 0.25320  focal_loss 0.09925  dice_loss 0.15395 
Epoch [199/300] Validation [14/16] Loss: 0.39474  focal_loss 0.15536  dice_loss 0.23937 
Epoch [199/300] Validation [15/16] Loss: 0.11834  focal_loss 0.03997  dice_loss 0.07837 
Epoch [199/300] Validation [16/16] Loss: 0.04232  focal_loss 0.01055  dice_loss 0.03177 
Epoch [199/300] Validation metric {'Val/mean dice_metric': 0.9300703406333923, 'Val/mean miou_metric': 0.8847053647041321, 'Val/mean f1': 0.9365360736846924, 'Val/mean precision': 0.9353946447372437, 'Val/mean recall': 0.9376803636550903, 'Val/mean hd95_metric': 13.30542278289795}
Cheakpoint...
Epoch [199/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9301], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9300703406333923, 'Val/mean miou_metric': 0.8847053647041321, 'Val/mean f1': 0.9365360736846924, 'Val/mean precision': 0.9353946447372437, 'Val/mean recall': 0.9376803636550903, 'Val/mean hd95_metric': 13.30542278289795}
Epoch [200/300] Training [1/62] Loss: 0.06064 
Epoch [200/300] Training [2/62] Loss: 0.04658 
Epoch [200/300] Training [3/62] Loss: 0.04240 
Epoch [200/300] Training [4/62] Loss: 0.08207 
Epoch [200/300] Training [5/62] Loss: 0.07683 
Epoch [200/300] Training [6/62] Loss: 0.04555 
Epoch [200/300] Training [7/62] Loss: 0.09923 
Epoch [200/300] Training [8/62] Loss: 0.08509 
Epoch [200/300] Training [9/62] Loss: 0.04186 
Epoch [200/300] Training [10/62] Loss: 0.06870 
Epoch [200/300] Training [11/62] Loss: 0.03828 
Epoch [200/300] Training [12/62] Loss: 0.05607 
Epoch [200/300] Training [13/62] Loss: 0.11581 
Epoch [200/300] Training [14/62] Loss: 0.06784 
Epoch [200/300] Training [15/62] Loss: 0.07496 
Epoch [200/300] Training [16/62] Loss: 0.09411 
Epoch [200/300] Training [17/62] Loss: 0.05792 
Epoch [200/300] Training [18/62] Loss: 0.08817 
Epoch [200/300] Training [19/62] Loss: 0.04790 
Epoch [200/300] Training [20/62] Loss: 0.06252 
Epoch [200/300] Training [21/62] Loss: 0.04595 
Epoch [200/300] Training [22/62] Loss: 0.04725 
Epoch [200/300] Training [23/62] Loss: 0.03902 
Epoch [200/300] Training [24/62] Loss: 0.04426 
Epoch [200/300] Training [25/62] Loss: 0.07135 
Epoch [200/300] Training [26/62] Loss: 0.05388 
Epoch [200/300] Training [27/62] Loss: 0.06553 
Epoch [200/300] Training [28/62] Loss: 0.09132 
Epoch [200/300] Training [29/62] Loss: 0.04600 
Epoch [200/300] Training [30/62] Loss: 0.08885 
Epoch [200/300] Training [31/62] Loss: 0.05176 
Epoch [200/300] Training [32/62] Loss: 0.10483 
Epoch [200/300] Training [33/62] Loss: 0.07244 
Epoch [200/300] Training [34/62] Loss: 0.04213 
Epoch [200/300] Training [35/62] Loss: 0.08613 
Epoch [200/300] Training [36/62] Loss: 0.10088 
Epoch [200/300] Training [37/62] Loss: 0.05582 
Epoch [200/300] Training [38/62] Loss: 0.08119 
Epoch [200/300] Training [39/62] Loss: 0.05143 
Epoch [200/300] Training [40/62] Loss: 0.07761 
Epoch [200/300] Training [41/62] Loss: 0.06432 
Epoch [200/300] Training [42/62] Loss: 0.03835 
Epoch [200/300] Training [43/62] Loss: 0.05736 
Epoch [200/300] Training [44/62] Loss: 0.04618 
Epoch [200/300] Training [45/62] Loss: 0.04485 
Epoch [200/300] Training [46/62] Loss: 0.14057 
Epoch [200/300] Training [47/62] Loss: 0.13193 
Epoch [200/300] Training [48/62] Loss: 0.06816 
Epoch [200/300] Training [49/62] Loss: 0.05955 
Epoch [200/300] Training [50/62] Loss: 0.06226 
Epoch [200/300] Training [51/62] Loss: 0.09132 
Epoch [200/300] Training [52/62] Loss: 0.06882 
Epoch [200/300] Training [53/62] Loss: 0.05321 
Epoch [200/300] Training [54/62] Loss: 0.05484 
Epoch [200/300] Training [55/62] Loss: 0.09117 
Epoch [200/300] Training [56/62] Loss: 0.03946 
Epoch [200/300] Training [57/62] Loss: 0.06305 
Epoch [200/300] Training [58/62] Loss: 0.07480 
Epoch [200/300] Training [59/62] Loss: 0.04920 
Epoch [200/300] Training [60/62] Loss: 0.05718 
Epoch [200/300] Training [61/62] Loss: 0.05434 
Epoch [200/300] Training [62/62] Loss: 0.02861 
Epoch [200/300] Training metric {'Train/mean dice_metric': 0.9529814720153809, 'Train/mean miou_metric': 0.9138995409011841, 'Train/mean f1': 0.9591852426528931, 'Train/mean precision': 0.9545467495918274, 'Train/mean recall': 0.9638690948486328, 'Train/mean hd95_metric': 7.724473476409912}
Epoch [200/300] Validation [1/16] Loss: 0.13089  focal_loss 0.04671  dice_loss 0.08418 
Epoch [200/300] Validation [2/16] Loss: 0.42616  focal_loss 0.16043  dice_loss 0.26573 
Epoch [200/300] Validation [3/16] Loss: 0.25538  focal_loss 0.07297  dice_loss 0.18241 
Epoch [200/300] Validation [4/16] Loss: 0.35371  focal_loss 0.17800  dice_loss 0.17571 
Epoch [200/300] Validation [5/16] Loss: 0.32593  focal_loss 0.11651  dice_loss 0.20941 
Epoch [200/300] Validation [6/16] Loss: 0.19376  focal_loss 0.04212  dice_loss 0.15165 
Epoch [200/300] Validation [7/16] Loss: 0.18713  focal_loss 0.07067  dice_loss 0.11646 
Epoch [200/300] Validation [8/16] Loss: 0.49212  focal_loss 0.19942  dice_loss 0.29271 
Epoch [200/300] Validation [9/16] Loss: 0.19808  focal_loss 0.07996  dice_loss 0.11812 
Epoch [200/300] Validation [10/16] Loss: 0.26532  focal_loss 0.08225  dice_loss 0.18307 
Epoch [200/300] Validation [11/16] Loss: 0.13082  focal_loss 0.03587  dice_loss 0.09494 
Epoch [200/300] Validation [12/16] Loss: 0.29424  focal_loss 0.06129  dice_loss 0.23295 
Epoch [200/300] Validation [13/16] Loss: 0.29032  focal_loss 0.12266  dice_loss 0.16766 
Epoch [200/300] Validation [14/16] Loss: 0.48401  focal_loss 0.17366  dice_loss 0.31035 
Epoch [200/300] Validation [15/16] Loss: 0.13884  focal_loss 0.05326  dice_loss 0.08558 
Epoch [200/300] Validation [16/16] Loss: 0.04122  focal_loss 0.00951  dice_loss 0.03170 
Epoch [200/300] Validation metric {'Val/mean dice_metric': 0.928441047668457, 'Val/mean miou_metric': 0.8811414241790771, 'Val/mean f1': 0.938633143901825, 'Val/mean precision': 0.9392675757408142, 'Val/mean recall': 0.9379997253417969, 'Val/mean hd95_metric': 13.174734115600586}
Cheakpoint...
Epoch [200/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9284], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.928441047668457, 'Val/mean miou_metric': 0.8811414241790771, 'Val/mean f1': 0.938633143901825, 'Val/mean precision': 0.9392675757408142, 'Val/mean recall': 0.9379997253417969, 'Val/mean hd95_metric': 13.174734115600586}
Epoch [201/300] Training [1/62] Loss: 0.08932 
Epoch [201/300] Training [2/62] Loss: 0.03707 
Epoch [201/300] Training [3/62] Loss: 0.04210 
Epoch [201/300] Training [4/62] Loss: 0.05544 
Epoch [201/300] Training [5/62] Loss: 0.05878 
Epoch [201/300] Training [6/62] Loss: 0.06121 
Epoch [201/300] Training [7/62] Loss: 0.16546 
Epoch [201/300] Training [8/62] Loss: 0.06328 
Epoch [201/300] Training [9/62] Loss: 0.04532 
Epoch [201/300] Training [10/62] Loss: 0.08494 
Epoch [201/300] Training [11/62] Loss: 0.08349 
Epoch [201/300] Training [12/62] Loss: 0.04074 
Epoch [201/300] Training [13/62] Loss: 0.05208 
Epoch [201/300] Training [14/62] Loss: 0.05493 
Epoch [201/300] Training [15/62] Loss: 0.03871 
Epoch [201/300] Training [16/62] Loss: 0.06391 
Epoch [201/300] Training [17/62] Loss: 0.04456 
Epoch [201/300] Training [18/62] Loss: 0.08901 
Epoch [201/300] Training [19/62] Loss: 0.04514 
Epoch [201/300] Training [20/62] Loss: 0.04848 
Epoch [201/300] Training [21/62] Loss: 0.04541 
Epoch [201/300] Training [22/62] Loss: 0.05882 
Epoch [201/300] Training [23/62] Loss: 0.03919 
Epoch [201/300] Training [24/62] Loss: 0.06008 
Epoch [201/300] Training [25/62] Loss: 0.06672 
Epoch [201/300] Training [26/62] Loss: 0.05127 
Epoch [201/300] Training [27/62] Loss: 0.06715 
Epoch [201/300] Training [28/62] Loss: 0.04568 
Epoch [201/300] Training [29/62] Loss: 0.05231 
Epoch [201/300] Training [30/62] Loss: 0.07268 
Epoch [201/300] Training [31/62] Loss: 0.10548 
Epoch [201/300] Training [32/62] Loss: 0.05173 
Epoch [201/300] Training [33/62] Loss: 0.03918 
Epoch [201/300] Training [34/62] Loss: 0.07258 
Epoch [201/300] Training [35/62] Loss: 0.05161 
Epoch [201/300] Training [36/62] Loss: 0.04564 
Epoch [201/300] Training [37/62] Loss: 0.10199 
Epoch [201/300] Training [38/62] Loss: 0.10111 
Epoch [201/300] Training [39/62] Loss: 0.06466 
Epoch [201/300] Training [40/62] Loss: 0.17915 
Epoch [201/300] Training [41/62] Loss: 0.05596 
Epoch [201/300] Training [42/62] Loss: 0.06225 
Epoch [201/300] Training [43/62] Loss: 0.07476 
Epoch [201/300] Training [44/62] Loss: 0.09318 
Epoch [201/300] Training [45/62] Loss: 0.04594 
Epoch [201/300] Training [46/62] Loss: 0.12899 
Epoch [201/300] Training [47/62] Loss: 0.09418 
Epoch [201/300] Training [48/62] Loss: 0.05071 
Epoch [201/300] Training [49/62] Loss: 0.12523 
Epoch [201/300] Training [50/62] Loss: 0.05254 
Epoch [201/300] Training [51/62] Loss: 0.03801 
Epoch [201/300] Training [52/62] Loss: 0.05014 
Epoch [201/300] Training [53/62] Loss: 0.05412 
Epoch [201/300] Training [54/62] Loss: 0.05723 
Epoch [201/300] Training [55/62] Loss: 0.05844 
Epoch [201/300] Training [56/62] Loss: 0.05590 
Epoch [201/300] Training [57/62] Loss: 0.05765 
Epoch [201/300] Training [58/62] Loss: 0.13894 
Epoch [201/300] Training [59/62] Loss: 0.08565 
Epoch [201/300] Training [60/62] Loss: 0.05644 
Epoch [201/300] Training [61/62] Loss: 0.05088 
Epoch [201/300] Training [62/62] Loss: 0.06108 
Epoch [201/300] Training metric {'Train/mean dice_metric': 0.9525817036628723, 'Train/mean miou_metric': 0.9150568842887878, 'Train/mean f1': 0.9599406719207764, 'Train/mean precision': 0.954133152961731, 'Train/mean recall': 0.9658194184303284, 'Train/mean hd95_metric': 7.7669830322265625}
Epoch [201/300] Validation [1/16] Loss: 0.29074  focal_loss 0.16653  dice_loss 0.12421 
Epoch [201/300] Validation [2/16] Loss: 0.34785  focal_loss 0.12358  dice_loss 0.22427 
Epoch [201/300] Validation [3/16] Loss: 0.76565  focal_loss 0.45659  dice_loss 0.30906 
Epoch [201/300] Validation [4/16] Loss: 0.47823  focal_loss 0.22132  dice_loss 0.25690 
Epoch [201/300] Validation [5/16] Loss: 0.35665  focal_loss 0.12199  dice_loss 0.23467 
Epoch [201/300] Validation [6/16] Loss: 0.27093  focal_loss 0.09669  dice_loss 0.17424 
Epoch [201/300] Validation [7/16] Loss: 0.22098  focal_loss 0.09476  dice_loss 0.12621 
Epoch [201/300] Validation [8/16] Loss: 0.29113  focal_loss 0.09733  dice_loss 0.19380 
Epoch [201/300] Validation [9/16] Loss: 0.17533  focal_loss 0.07128  dice_loss 0.10405 
Epoch [201/300] Validation [10/16] Loss: 0.43683  focal_loss 0.15872  dice_loss 0.27811 
Epoch [201/300] Validation [11/16] Loss: 0.15317  focal_loss 0.04065  dice_loss 0.11252 
Epoch [201/300] Validation [12/16] Loss: 0.28897  focal_loss 0.08114  dice_loss 0.20783 
Epoch [201/300] Validation [13/16] Loss: 0.29832  focal_loss 0.11950  dice_loss 0.17882 
Epoch [201/300] Validation [14/16] Loss: 0.45159  focal_loss 0.16556  dice_loss 0.28603 
Epoch [201/300] Validation [15/16] Loss: 0.10772  focal_loss 0.03208  dice_loss 0.07564 
Epoch [201/300] Validation [16/16] Loss: 0.05624  focal_loss 0.01527  dice_loss 0.04096 
Epoch [201/300] Validation metric {'Val/mean dice_metric': 0.9250809550285339, 'Val/mean miou_metric': 0.8796013593673706, 'Val/mean f1': 0.9335684180259705, 'Val/mean precision': 0.9327833652496338, 'Val/mean recall': 0.9343549609184265, 'Val/mean hd95_metric': 14.794583320617676}
Cheakpoint...
Epoch [201/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9251], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9250809550285339, 'Val/mean miou_metric': 0.8796013593673706, 'Val/mean f1': 0.9335684180259705, 'Val/mean precision': 0.9327833652496338, 'Val/mean recall': 0.9343549609184265, 'Val/mean hd95_metric': 14.794583320617676}
Epoch [202/300] Training [1/62] Loss: 0.13096 
Epoch [202/300] Training [2/62] Loss: 0.05016 
Epoch [202/300] Training [3/62] Loss: 0.04700 
Epoch [202/300] Training [4/62] Loss: 0.05908 
Epoch [202/300] Training [5/62] Loss: 0.06066 
Epoch [202/300] Training [6/62] Loss: 0.08764 
Epoch [202/300] Training [7/62] Loss: 0.08334 
Epoch [202/300] Training [8/62] Loss: 0.04025 
Epoch [202/300] Training [9/62] Loss: 0.11344 
Epoch [202/300] Training [10/62] Loss: 0.08533 
Epoch [202/300] Training [11/62] Loss: 0.04922 
Epoch [202/300] Training [12/62] Loss: 0.05649 
Epoch [202/300] Training [13/62] Loss: 0.06832 
Epoch [202/300] Training [14/62] Loss: 0.06793 
Epoch [202/300] Training [15/62] Loss: 0.05677 
Epoch [202/300] Training [16/62] Loss: 0.04809 
Epoch [202/300] Training [17/62] Loss: 0.05161 
Epoch [202/300] Training [18/62] Loss: 0.04162 
Epoch [202/300] Training [19/62] Loss: 0.11191 
Epoch [202/300] Training [20/62] Loss: 0.05108 
Epoch [202/300] Training [21/62] Loss: 0.06394 
Epoch [202/300] Training [22/62] Loss: 0.05638 
Epoch [202/300] Training [23/62] Loss: 0.08108 
Epoch [202/300] Training [24/62] Loss: 0.04537 
Epoch [202/300] Training [25/62] Loss: 0.07680 
Epoch [202/300] Training [26/62] Loss: 0.08875 
Epoch [202/300] Training [27/62] Loss: 0.05257 
Epoch [202/300] Training [28/62] Loss: 0.04269 
Epoch [202/300] Training [29/62] Loss: 0.04680 
Epoch [202/300] Training [30/62] Loss: 0.06426 
Epoch [202/300] Training [31/62] Loss: 0.05608 
Epoch [202/300] Training [32/62] Loss: 0.05359 
Epoch [202/300] Training [33/62] Loss: 0.04278 
Epoch [202/300] Training [34/62] Loss: 0.08134 
Epoch [202/300] Training [35/62] Loss: 0.03558 
Epoch [202/300] Training [36/62] Loss: 0.06634 
Epoch [202/300] Training [37/62] Loss: 0.04535 
Epoch [202/300] Training [38/62] Loss: 0.04012 
Epoch [202/300] Training [39/62] Loss: 0.06980 
Epoch [202/300] Training [40/62] Loss: 0.06639 
Epoch [202/300] Training [41/62] Loss: 0.05143 
Epoch [202/300] Training [42/62] Loss: 0.04788 
Epoch [202/300] Training [43/62] Loss: 0.05228 
Epoch [202/300] Training [44/62] Loss: 0.04841 
Epoch [202/300] Training [45/62] Loss: 0.03914 
Epoch [202/300] Training [46/62] Loss: 0.06168 
Epoch [202/300] Training [47/62] Loss: 0.06085 
Epoch [202/300] Training [48/62] Loss: 0.04357 
Epoch [202/300] Training [49/62] Loss: 0.04071 
Epoch [202/300] Training [50/62] Loss: 0.04136 
Epoch [202/300] Training [51/62] Loss: 0.06283 
Epoch [202/300] Training [52/62] Loss: 0.04305 
Epoch [202/300] Training [53/62] Loss: 0.05844 
Epoch [202/300] Training [54/62] Loss: 0.06240 
Epoch [202/300] Training [55/62] Loss: 0.05894 
Epoch [202/300] Training [56/62] Loss: 0.09099 
Epoch [202/300] Training [57/62] Loss: 0.08764 
Epoch [202/300] Training [58/62] Loss: 0.04704 
Epoch [202/300] Training [59/62] Loss: 0.05793 
Epoch [202/300] Training [60/62] Loss: 0.04004 
Epoch [202/300] Training [61/62] Loss: 0.09699 
Epoch [202/300] Training [62/62] Loss: 0.04800 
Epoch [202/300] Training metric {'Train/mean dice_metric': 0.9579958915710449, 'Train/mean miou_metric': 0.9215036630630493, 'Train/mean f1': 0.9605277180671692, 'Train/mean precision': 0.9565058350563049, 'Train/mean recall': 0.9645836353302002, 'Train/mean hd95_metric': 7.1841959953308105}
Epoch [202/300] Validation [1/16] Loss: 0.12701  focal_loss 0.04382  dice_loss 0.08318 
Epoch [202/300] Validation [2/16] Loss: 0.25790  focal_loss 0.11615  dice_loss 0.14174 
Epoch [202/300] Validation [3/16] Loss: 0.31470  focal_loss 0.10882  dice_loss 0.20588 
Epoch [202/300] Validation [4/16] Loss: 0.39576  focal_loss 0.17188  dice_loss 0.22388 
Epoch [202/300] Validation [5/16] Loss: 0.36487  focal_loss 0.13859  dice_loss 0.22628 
Epoch [202/300] Validation [6/16] Loss: 0.19256  focal_loss 0.03219  dice_loss 0.16037 
Epoch [202/300] Validation [7/16] Loss: 0.15043  focal_loss 0.04179  dice_loss 0.10864 
Epoch [202/300] Validation [8/16] Loss: 0.33005  focal_loss 0.09008  dice_loss 0.23998 
Epoch [202/300] Validation [9/16] Loss: 0.20124  focal_loss 0.07217  dice_loss 0.12906 
Epoch [202/300] Validation [10/16] Loss: 0.32566  focal_loss 0.09135  dice_loss 0.23430 
Epoch [202/300] Validation [11/16] Loss: 0.12462  focal_loss 0.03153  dice_loss 0.09308 
Epoch [202/300] Validation [12/16] Loss: 0.36589  focal_loss 0.11118  dice_loss 0.25471 
Epoch [202/300] Validation [13/16] Loss: 0.20507  focal_loss 0.05556  dice_loss 0.14951 
Epoch [202/300] Validation [14/16] Loss: 0.60286  focal_loss 0.19518  dice_loss 0.40768 
Epoch [202/300] Validation [15/16] Loss: 0.08246  focal_loss 0.01799  dice_loss 0.06447 
Epoch [202/300] Validation [16/16] Loss: 0.04370  focal_loss 0.00749  dice_loss 0.03621 
Epoch [202/300] Validation metric {'Val/mean dice_metric': 0.9314939975738525, 'Val/mean miou_metric': 0.8876123428344727, 'Val/mean f1': 0.9404470324516296, 'Val/mean precision': 0.9412162899971008, 'Val/mean recall': 0.939678966999054, 'Val/mean hd95_metric': 12.39260482788086}
Cheakpoint...
Epoch [202/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9315], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9314939975738525, 'Val/mean miou_metric': 0.8876123428344727, 'Val/mean f1': 0.9404470324516296, 'Val/mean precision': 0.9412162899971008, 'Val/mean recall': 0.939678966999054, 'Val/mean hd95_metric': 12.39260482788086}
Epoch [203/300] Training [1/62] Loss: 0.06135 
Epoch [203/300] Training [2/62] Loss: 0.16644 
Epoch [203/300] Training [3/62] Loss: 0.05857 
Epoch [203/300] Training [4/62] Loss: 0.03885 
Epoch [203/300] Training [5/62] Loss: 0.06635 
Epoch [203/300] Training [6/62] Loss: 0.07099 
Epoch [203/300] Training [7/62] Loss: 0.05135 
Epoch [203/300] Training [8/62] Loss: 0.07534 
Epoch [203/300] Training [9/62] Loss: 0.06132 
Epoch [203/300] Training [10/62] Loss: 0.04397 
Epoch [203/300] Training [11/62] Loss: 0.04797 
Epoch [203/300] Training [12/62] Loss: 0.07973 
Epoch [203/300] Training [13/62] Loss: 0.03725 
Epoch [203/300] Training [14/62] Loss: 0.04015 
Epoch [203/300] Training [15/62] Loss: 0.06974 
Epoch [203/300] Training [16/62] Loss: 0.07818 
Epoch [203/300] Training [17/62] Loss: 0.04772 
Epoch [203/300] Training [18/62] Loss: 0.04718 
Epoch [203/300] Training [19/62] Loss: 0.07183 
Epoch [203/300] Training [20/62] Loss: 0.04922 
Epoch [203/300] Training [21/62] Loss: 0.12210 
Epoch [203/300] Training [22/62] Loss: 0.04595 
Epoch [203/300] Training [23/62] Loss: 0.07203 
Epoch [203/300] Training [24/62] Loss: 0.04782 
Epoch [203/300] Training [25/62] Loss: 0.09628 
Epoch [203/300] Training [26/62] Loss: 0.07402 
Epoch [203/300] Training [27/62] Loss: 0.05730 
Epoch [203/300] Training [28/62] Loss: 0.05022 
Epoch [203/300] Training [29/62] Loss: 0.08538 
Epoch [203/300] Training [30/62] Loss: 0.04827 
Epoch [203/300] Training [31/62] Loss: 0.05122 
Epoch [203/300] Training [32/62] Loss: 0.06101 
Epoch [203/300] Training [33/62] Loss: 0.05126 
Epoch [203/300] Training [34/62] Loss: 0.08993 
Epoch [203/300] Training [35/62] Loss: 0.05579 
Epoch [203/300] Training [36/62] Loss: 0.07794 
Epoch [203/300] Training [37/62] Loss: 0.04989 
Epoch [203/300] Training [38/62] Loss: 0.04363 
Epoch [203/300] Training [39/62] Loss: 0.05898 
Epoch [203/300] Training [40/62] Loss: 0.05449 
Epoch [203/300] Training [41/62] Loss: 0.05064 
Epoch [203/300] Training [42/62] Loss: 0.03806 
Epoch [203/300] Training [43/62] Loss: 0.04127 
Epoch [203/300] Training [44/62] Loss: 0.07021 
Epoch [203/300] Training [45/62] Loss: 0.03750 
Epoch [203/300] Training [46/62] Loss: 0.07914 
Epoch [203/300] Training [47/62] Loss: 0.04832 
Epoch [203/300] Training [48/62] Loss: 0.04613 
Epoch [203/300] Training [49/62] Loss: 0.05125 
Epoch [203/300] Training [50/62] Loss: 0.08359 
Epoch [203/300] Training [51/62] Loss: 0.06175 
Epoch [203/300] Training [52/62] Loss: 0.09136 
Epoch [203/300] Training [53/62] Loss: 0.03546 
Epoch [203/300] Training [54/62] Loss: 0.04160 
Epoch [203/300] Training [55/62] Loss: 0.04255 
Epoch [203/300] Training [56/62] Loss: 0.04876 
Epoch [203/300] Training [57/62] Loss: 0.04788 
Epoch [203/300] Training [58/62] Loss: 0.06334 
Epoch [203/300] Training [59/62] Loss: 0.05108 
Epoch [203/300] Training [60/62] Loss: 0.07398 
Epoch [203/300] Training [61/62] Loss: 0.04223 
Epoch [203/300] Training [62/62] Loss: 0.14237 
Epoch [203/300] Training metric {'Train/mean dice_metric': 0.9576308727264404, 'Train/mean miou_metric': 0.9212854504585266, 'Train/mean f1': 0.9615247249603271, 'Train/mean precision': 0.9574410319328308, 'Train/mean recall': 0.9656435251235962, 'Train/mean hd95_metric': 7.722599506378174}
Epoch [203/300] Validation [1/16] Loss: 0.20396  focal_loss 0.09503  dice_loss 0.10893 
Epoch [203/300] Validation [2/16] Loss: 0.45881  focal_loss 0.20313  dice_loss 0.25568 
Epoch [203/300] Validation [3/16] Loss: 0.31432  focal_loss 0.12664  dice_loss 0.18768 
Epoch [203/300] Validation [4/16] Loss: 0.23944  focal_loss 0.08919  dice_loss 0.15025 
Epoch [203/300] Validation [5/16] Loss: 0.44158  focal_loss 0.15345  dice_loss 0.28813 
Epoch [203/300] Validation [6/16] Loss: 0.20745  focal_loss 0.04611  dice_loss 0.16134 
Epoch [203/300] Validation [7/16] Loss: 0.35790  focal_loss 0.17662  dice_loss 0.18128 
Epoch [203/300] Validation [8/16] Loss: 0.28487  focal_loss 0.07012  dice_loss 0.21475 
Epoch [203/300] Validation [9/16] Loss: 0.19709  focal_loss 0.06477  dice_loss 0.13231 
Epoch [203/300] Validation [10/16] Loss: 0.32387  focal_loss 0.10438  dice_loss 0.21949 
Epoch [203/300] Validation [11/16] Loss: 0.13090  focal_loss 0.03757  dice_loss 0.09332 
Epoch [203/300] Validation [12/16] Loss: 0.28136  focal_loss 0.06599  dice_loss 0.21537 
Epoch [203/300] Validation [13/16] Loss: 0.29815  focal_loss 0.09886  dice_loss 0.19928 
Epoch [203/300] Validation [14/16] Loss: 0.47812  focal_loss 0.16064  dice_loss 0.31748 
Epoch [203/300] Validation [15/16] Loss: 0.12760  focal_loss 0.04773  dice_loss 0.07987 
Epoch [203/300] Validation [16/16] Loss: 0.04146  focal_loss 0.00906  dice_loss 0.03240 
Epoch [203/300] Validation metric {'Val/mean dice_metric': 0.9305256605148315, 'Val/mean miou_metric': 0.8858169913291931, 'Val/mean f1': 0.9375542998313904, 'Val/mean precision': 0.9331490397453308, 'Val/mean recall': 0.9420013427734375, 'Val/mean hd95_metric': 13.606057167053223}
Cheakpoint...
Epoch [203/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9305], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9305256605148315, 'Val/mean miou_metric': 0.8858169913291931, 'Val/mean f1': 0.9375542998313904, 'Val/mean precision': 0.9331490397453308, 'Val/mean recall': 0.9420013427734375, 'Val/mean hd95_metric': 13.606057167053223}
Epoch [204/300] Training [1/62] Loss: 0.05899 
Epoch [204/300] Training [2/62] Loss: 0.06784 
Epoch [204/300] Training [3/62] Loss: 0.05503 
Epoch [204/300] Training [4/62] Loss: 0.07065 
Epoch [204/300] Training [5/62] Loss: 0.07549 
Epoch [204/300] Training [6/62] Loss: 0.09051 
Epoch [204/300] Training [7/62] Loss: 0.07761 
Epoch [204/300] Training [8/62] Loss: 0.04888 
Epoch [204/300] Training [9/62] Loss: 0.04473 
Epoch [204/300] Training [10/62] Loss: 0.07030 
Epoch [204/300] Training [11/62] Loss: 0.05156 
Epoch [204/300] Training [12/62] Loss: 0.06747 
Epoch [204/300] Training [13/62] Loss: 0.06366 
Epoch [204/300] Training [14/62] Loss: 0.04690 
Epoch [204/300] Training [15/62] Loss: 0.05162 
Epoch [204/300] Training [16/62] Loss: 0.07302 
Epoch [204/300] Training [17/62] Loss: 0.04026 
Epoch [204/300] Training [18/62] Loss: 0.06140 
Epoch [204/300] Training [19/62] Loss: 0.07534 
Epoch [204/300] Training [20/62] Loss: 0.21560 
Epoch [204/300] Training [21/62] Loss: 0.07035 
Epoch [204/300] Training [22/62] Loss: 0.04784 
Epoch [204/300] Training [23/62] Loss: 0.04907 
Epoch [204/300] Training [24/62] Loss: 0.10803 
Epoch [204/300] Training [25/62] Loss: 0.05322 
Epoch [204/300] Training [26/62] Loss: 0.06857 
Epoch [204/300] Training [27/62] Loss: 0.03819 
Epoch [204/300] Training [28/62] Loss: 0.05379 
Epoch [204/300] Training [29/62] Loss: 0.04877 
Epoch [204/300] Training [30/62] Loss: 0.04175 
Epoch [204/300] Training [31/62] Loss: 0.05454 
Epoch [204/300] Training [32/62] Loss: 0.04262 
Epoch [204/300] Training [33/62] Loss: 0.04626 
Epoch [204/300] Training [34/62] Loss: 0.03856 
Epoch [204/300] Training [35/62] Loss: 0.04861 
Epoch [204/300] Training [36/62] Loss: 0.04420 
Epoch [204/300] Training [37/62] Loss: 0.05618 
Epoch [204/300] Training [38/62] Loss: 0.06554 
Epoch [204/300] Training [39/62] Loss: 0.04655 
Epoch [204/300] Training [40/62] Loss: 0.05596 
Epoch [204/300] Training [41/62] Loss: 0.05404 
Epoch [204/300] Training [42/62] Loss: 0.04732 
Epoch [204/300] Training [43/62] Loss: 0.04336 
Epoch [204/300] Training [44/62] Loss: 0.06177 
Epoch [204/300] Training [45/62] Loss: 0.05727 
Epoch [204/300] Training [46/62] Loss: 0.04171 
Epoch [204/300] Training [47/62] Loss: 0.05645 
Epoch [204/300] Training [48/62] Loss: 0.05283 
Epoch [204/300] Training [49/62] Loss: 0.05131 
Epoch [204/300] Training [50/62] Loss: 0.09475 
Epoch [204/300] Training [51/62] Loss: 0.05118 
Epoch [204/300] Training [52/62] Loss: 0.04135 
Epoch [204/300] Training [53/62] Loss: 0.04733 
Epoch [204/300] Training [54/62] Loss: 0.05354 
Epoch [204/300] Training [55/62] Loss: 0.11895 
Epoch [204/300] Training [56/62] Loss: 0.03617 
Epoch [204/300] Training [57/62] Loss: 0.07703 
Epoch [204/300] Training [58/62] Loss: 0.09187 
Epoch [204/300] Training [59/62] Loss: 0.06419 
Epoch [204/300] Training [60/62] Loss: 0.08749 
Epoch [204/300] Training [61/62] Loss: 0.08533 
Epoch [204/300] Training [62/62] Loss: 0.04589 
Epoch [204/300] Training metric {'Train/mean dice_metric': 0.9564276337623596, 'Train/mean miou_metric': 0.9208098649978638, 'Train/mean f1': 0.9624078869819641, 'Train/mean precision': 0.9585573077201843, 'Train/mean recall': 0.9662894606590271, 'Train/mean hd95_metric': 7.084285736083984}
Epoch [204/300] Validation [1/16] Loss: 0.44881  focal_loss 0.29185  dice_loss 0.15696 
Epoch [204/300] Validation [2/16] Loss: 0.25903  focal_loss 0.11408  dice_loss 0.14495 
Epoch [204/300] Validation [3/16] Loss: 0.46628  focal_loss 0.21218  dice_loss 0.25410 
Epoch [204/300] Validation [4/16] Loss: 0.24999  focal_loss 0.10047  dice_loss 0.14952 
Epoch [204/300] Validation [5/16] Loss: 0.20604  focal_loss 0.04919  dice_loss 0.15684 
Epoch [204/300] Validation [6/16] Loss: 0.19653  focal_loss 0.04368  dice_loss 0.15285 
Epoch [204/300] Validation [7/16] Loss: 0.19845  focal_loss 0.07077  dice_loss 0.12768 
Epoch [204/300] Validation [8/16] Loss: 0.30857  focal_loss 0.09722  dice_loss 0.21135 
Epoch [204/300] Validation [9/16] Loss: 0.17900  focal_loss 0.06655  dice_loss 0.11246 
Epoch [204/300] Validation [10/16] Loss: 0.23858  focal_loss 0.05878  dice_loss 0.17980 
Epoch [204/300] Validation [11/16] Loss: 0.12289  focal_loss 0.02840  dice_loss 0.09450 
Epoch [204/300] Validation [12/16] Loss: 0.34393  focal_loss 0.07058  dice_loss 0.27336 
Epoch [204/300] Validation [13/16] Loss: 0.25989  focal_loss 0.08313  dice_loss 0.17676 
Epoch [204/300] Validation [14/16] Loss: 0.58766  focal_loss 0.22753  dice_loss 0.36013 
Epoch [204/300] Validation [15/16] Loss: 0.12746  focal_loss 0.03699  dice_loss 0.09046 
Epoch [204/300] Validation [16/16] Loss: 0.06870  focal_loss 0.02552  dice_loss 0.04318 
Epoch [204/300] Validation metric {'Val/mean dice_metric': 0.9318603277206421, 'Val/mean miou_metric': 0.8871484994888306, 'Val/mean f1': 0.9376153349876404, 'Val/mean precision': 0.933660089969635, 'Val/mean recall': 0.9416043758392334, 'Val/mean hd95_metric': 13.916520118713379}
Cheakpoint...
Epoch [204/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9319], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9318603277206421, 'Val/mean miou_metric': 0.8871484994888306, 'Val/mean f1': 0.9376153349876404, 'Val/mean precision': 0.933660089969635, 'Val/mean recall': 0.9416043758392334, 'Val/mean hd95_metric': 13.916520118713379}
Epoch [205/300] Training [1/62] Loss: 0.06132 
Epoch [205/300] Training [2/62] Loss: 0.03705 
Epoch [205/300] Training [3/62] Loss: 0.04855 
Epoch [205/300] Training [4/62] Loss: 0.04798 
Epoch [205/300] Training [5/62] Loss: 0.05886 
Epoch [205/300] Training [6/62] Loss: 0.05117 
Epoch [205/300] Training [7/62] Loss: 0.13344 
Epoch [205/300] Training [8/62] Loss: 0.06859 
Epoch [205/300] Training [9/62] Loss: 0.04097 
Epoch [205/300] Training [10/62] Loss: 0.06000 
Epoch [205/300] Training [11/62] Loss: 0.06472 
Epoch [205/300] Training [12/62] Loss: 0.04646 
Epoch [205/300] Training [13/62] Loss: 0.08201 
Epoch [205/300] Training [14/62] Loss: 0.05119 
Epoch [205/300] Training [15/62] Loss: 0.03675 
Epoch [205/300] Training [16/62] Loss: 0.12499 
Epoch [205/300] Training [17/62] Loss: 0.07440 
Epoch [205/300] Training [18/62] Loss: 0.04565 
Epoch [205/300] Training [19/62] Loss: 0.07408 
Epoch [205/300] Training [20/62] Loss: 0.03921 
Epoch [205/300] Training [21/62] Loss: 0.04764 
Epoch [205/300] Training [22/62] Loss: 0.06401 
Epoch [205/300] Training [23/62] Loss: 0.05537 
Epoch [205/300] Training [24/62] Loss: 0.04340 
Epoch [205/300] Training [25/62] Loss: 0.06454 
Epoch [205/300] Training [26/62] Loss: 0.04944 
Epoch [205/300] Training [27/62] Loss: 0.05267 
Epoch [205/300] Training [28/62] Loss: 0.05094 
Epoch [205/300] Training [29/62] Loss: 0.04449 
Epoch [205/300] Training [30/62] Loss: 0.03832 
Epoch [205/300] Training [31/62] Loss: 0.04975 
Epoch [205/300] Training [32/62] Loss: 0.05799 
Epoch [205/300] Training [33/62] Loss: 0.04907 
Epoch [205/300] Training [34/62] Loss: 0.03305 
Epoch [205/300] Training [35/62] Loss: 0.09849 
Epoch [205/300] Training [36/62] Loss: 0.06120 
Epoch [205/300] Training [37/62] Loss: 0.08593 
Epoch [205/300] Training [38/62] Loss: 0.03916 
Epoch [205/300] Training [39/62] Loss: 0.09525 
Epoch [205/300] Training [40/62] Loss: 0.07382 
Epoch [205/300] Training [41/62] Loss: 0.08733 
Epoch [205/300] Training [42/62] Loss: 0.06825 
Epoch [205/300] Training [43/62] Loss: 0.04255 
Epoch [205/300] Training [44/62] Loss: 0.05186 
Epoch [205/300] Training [45/62] Loss: 0.03640 
Epoch [205/300] Training [46/62] Loss: 0.04438 
Epoch [205/300] Training [47/62] Loss: 0.06619 
Epoch [205/300] Training [48/62] Loss: 0.05142 
Epoch [205/300] Training [49/62] Loss: 0.07969 
Epoch [205/300] Training [50/62] Loss: 0.04762 
Epoch [205/300] Training [51/62] Loss: 0.04344 
Epoch [205/300] Training [52/62] Loss: 0.08447 
Epoch [205/300] Training [53/62] Loss: 0.08505 
Epoch [205/300] Training [54/62] Loss: 0.06246 
Epoch [205/300] Training [55/62] Loss: 0.04936 
Epoch [205/300] Training [56/62] Loss: 0.03590 
Epoch [205/300] Training [57/62] Loss: 0.04195 
Epoch [205/300] Training [58/62] Loss: 0.08788 
Epoch [205/300] Training [59/62] Loss: 0.05498 
Epoch [205/300] Training [60/62] Loss: 0.04049 
Epoch [205/300] Training [61/62] Loss: 0.06821 
Epoch [205/300] Training [62/62] Loss: 0.03833 
Epoch [205/300] Training metric {'Train/mean dice_metric': 0.9583859443664551, 'Train/mean miou_metric': 0.9229931831359863, 'Train/mean f1': 0.9623845219612122, 'Train/mean precision': 0.9575635194778442, 'Train/mean recall': 0.9672542214393616, 'Train/mean hd95_metric': 6.824071884155273}
Epoch [205/300] Validation [1/16] Loss: 0.12389  focal_loss 0.04631  dice_loss 0.07758 
Epoch [205/300] Validation [2/16] Loss: 0.42765  focal_loss 0.17758  dice_loss 0.25007 
Epoch [205/300] Validation [3/16] Loss: 0.60328  focal_loss 0.32087  dice_loss 0.28241 
Epoch [205/300] Validation [4/16] Loss: 0.24658  focal_loss 0.11132  dice_loss 0.13526 
Epoch [205/300] Validation [5/16] Loss: 0.23528  focal_loss 0.07386  dice_loss 0.16142 
Epoch [205/300] Validation [6/16] Loss: 0.19539  focal_loss 0.05433  dice_loss 0.14106 
Epoch [205/300] Validation [7/16] Loss: 0.24765  focal_loss 0.11307  dice_loss 0.13458 
Epoch [205/300] Validation [8/16] Loss: 0.31991  focal_loss 0.09485  dice_loss 0.22506 
Epoch [205/300] Validation [9/16] Loss: 0.28628  focal_loss 0.12173  dice_loss 0.16455 
Epoch [205/300] Validation [10/16] Loss: 0.29067  focal_loss 0.09099  dice_loss 0.19968 
Epoch [205/300] Validation [11/16] Loss: 0.11971  focal_loss 0.03469  dice_loss 0.08502 
Epoch [205/300] Validation [12/16] Loss: 0.28528  focal_loss 0.06087  dice_loss 0.22441 
Epoch [205/300] Validation [13/16] Loss: 0.22310  focal_loss 0.07415  dice_loss 0.14895 
Epoch [205/300] Validation [14/16] Loss: 0.49304  focal_loss 0.16009  dice_loss 0.33295 
Epoch [205/300] Validation [15/16] Loss: 0.13944  focal_loss 0.04690  dice_loss 0.09253 
Epoch [205/300] Validation [16/16] Loss: 0.05349  focal_loss 0.01392  dice_loss 0.03957 
Epoch [205/300] Validation metric {'Val/mean dice_metric': 0.9332217574119568, 'Val/mean miou_metric': 0.8894151449203491, 'Val/mean f1': 0.9402839541435242, 'Val/mean precision': 0.9384366273880005, 'Val/mean recall': 0.9421385526657104, 'Val/mean hd95_metric': 12.52116870880127}
Cheakpoint...
Epoch [205/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9332], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9332217574119568, 'Val/mean miou_metric': 0.8894151449203491, 'Val/mean f1': 0.9402839541435242, 'Val/mean precision': 0.9384366273880005, 'Val/mean recall': 0.9421385526657104, 'Val/mean hd95_metric': 12.52116870880127}
Epoch [206/300] Training [1/62] Loss: 0.03507 
Epoch [206/300] Training [2/62] Loss: 0.04742 
Epoch [206/300] Training [3/62] Loss: 0.06994 
Epoch [206/300] Training [4/62] Loss: 0.04218 
Epoch [206/300] Training [5/62] Loss: 0.06091 
Epoch [206/300] Training [6/62] Loss: 0.05545 
Epoch [206/300] Training [7/62] Loss: 0.09093 
Epoch [206/300] Training [8/62] Loss: 0.03625 
Epoch [206/300] Training [9/62] Loss: 0.04126 
Epoch [206/300] Training [10/62] Loss: 0.05887 
Epoch [206/300] Training [11/62] Loss: 0.03754 
Epoch [206/300] Training [12/62] Loss: 0.04577 
Epoch [206/300] Training [13/62] Loss: 0.07680 
Epoch [206/300] Training [14/62] Loss: 0.06839 
Epoch [206/300] Training [15/62] Loss: 0.05868 
Epoch [206/300] Training [16/62] Loss: 0.06296 
Epoch [206/300] Training [17/62] Loss: 0.05232 
Epoch [206/300] Training [18/62] Loss: 0.05662 
Epoch [206/300] Training [19/62] Loss: 0.05240 
Epoch [206/300] Training [20/62] Loss: 0.05214 
Epoch [206/300] Training [21/62] Loss: 0.04507 
Epoch [206/300] Training [22/62] Loss: 0.07558 
Epoch [206/300] Training [23/62] Loss: 0.05190 
Epoch [206/300] Training [24/62] Loss: 0.04991 
Epoch [206/300] Training [25/62] Loss: 0.04832 
Epoch [206/300] Training [26/62] Loss: 0.05612 
Epoch [206/300] Training [27/62] Loss: 0.04042 
Epoch [206/300] Training [28/62] Loss: 0.10144 
Epoch [206/300] Training [29/62] Loss: 0.06667 
Epoch [206/300] Training [30/62] Loss: 0.10530 
Epoch [206/300] Training [31/62] Loss: 0.04817 
Epoch [206/300] Training [32/62] Loss: 0.15154 
Epoch [206/300] Training [33/62] Loss: 0.04441 
Epoch [206/300] Training [34/62] Loss: 0.05889 
Epoch [206/300] Training [35/62] Loss: 0.05344 
Epoch [206/300] Training [36/62] Loss: 0.06875 
Epoch [206/300] Training [37/62] Loss: 0.03733 
Epoch [206/300] Training [38/62] Loss: 0.09707 
Epoch [206/300] Training [39/62] Loss: 0.05528 
Epoch [206/300] Training [40/62] Loss: 0.06952 
Epoch [206/300] Training [41/62] Loss: 0.07700 
Epoch [206/300] Training [42/62] Loss: 0.07678 
Epoch [206/300] Training [43/62] Loss: 0.08390 
Epoch [206/300] Training [44/62] Loss: 0.06967 
Epoch [206/300] Training [45/62] Loss: 0.04990 
Epoch [206/300] Training [46/62] Loss: 0.08290 
Epoch [206/300] Training [47/62] Loss: 0.05888 
Epoch [206/300] Training [48/62] Loss: 0.05386 
Epoch [206/300] Training [49/62] Loss: 0.06531 
Epoch [206/300] Training [50/62] Loss: 0.05655 
Epoch [206/300] Training [51/62] Loss: 0.05893 
Epoch [206/300] Training [52/62] Loss: 0.05753 
Epoch [206/300] Training [53/62] Loss: 0.08386 
Epoch [206/300] Training [54/62] Loss: 0.06029 
Epoch [206/300] Training [55/62] Loss: 0.04835 
Epoch [206/300] Training [56/62] Loss: 0.04100 
Epoch [206/300] Training [57/62] Loss: 0.05003 
Epoch [206/300] Training [58/62] Loss: 0.06933 
Epoch [206/300] Training [59/62] Loss: 0.14752 
Epoch [206/300] Training [60/62] Loss: 0.04432 
Epoch [206/300] Training [61/62] Loss: 0.06390 
Epoch [206/300] Training [62/62] Loss: 0.05170 
Epoch [206/300] Training metric {'Train/mean dice_metric': 0.9559780359268188, 'Train/mean miou_metric': 0.9191108345985413, 'Train/mean f1': 0.9608657360076904, 'Train/mean precision': 0.956931471824646, 'Train/mean recall': 0.9648324847221375, 'Train/mean hd95_metric': 6.660792827606201}
Epoch [206/300] Validation [1/16] Loss: 0.29394  focal_loss 0.11635  dice_loss 0.17758 
Epoch [206/300] Validation [2/16] Loss: 0.32931  focal_loss 0.15241  dice_loss 0.17690 
Epoch [206/300] Validation [3/16] Loss: 0.63883  focal_loss 0.34184  dice_loss 0.29700 
Epoch [206/300] Validation [4/16] Loss: 0.40367  focal_loss 0.20959  dice_loss 0.19408 
Epoch [206/300] Validation [5/16] Loss: 0.26196  focal_loss 0.07112  dice_loss 0.19084 
Epoch [206/300] Validation [6/16] Loss: 0.20228  focal_loss 0.04930  dice_loss 0.15298 
Epoch [206/300] Validation [7/16] Loss: 0.25416  focal_loss 0.10922  dice_loss 0.14495 
Epoch [206/300] Validation [8/16] Loss: 0.39326  focal_loss 0.14482  dice_loss 0.24844 
Epoch [206/300] Validation [9/16] Loss: 0.17698  focal_loss 0.05526  dice_loss 0.12172 
Epoch [206/300] Validation [10/16] Loss: 0.14742  focal_loss 0.03547  dice_loss 0.11195 
Epoch [206/300] Validation [11/16] Loss: 0.12781  focal_loss 0.03167  dice_loss 0.09613 
Epoch [206/300] Validation [12/16] Loss: 0.32782  focal_loss 0.07813  dice_loss 0.24968 
Epoch [206/300] Validation [13/16] Loss: 0.27304  focal_loss 0.11058  dice_loss 0.16246 
Epoch [206/300] Validation [14/16] Loss: 0.43477  focal_loss 0.14845  dice_loss 0.28631 
Epoch [206/300] Validation [15/16] Loss: 0.13572  focal_loss 0.04411  dice_loss 0.09161 
Epoch [206/300] Validation [16/16] Loss: 0.06122  focal_loss 0.01448  dice_loss 0.04674 
Epoch [206/300] Validation metric {'Val/mean dice_metric': 0.9303199648857117, 'Val/mean miou_metric': 0.8839631676673889, 'Val/mean f1': 0.9365846514701843, 'Val/mean precision': 0.9424776434898376, 'Val/mean recall': 0.93076491355896, 'Val/mean hd95_metric': 13.165942192077637}
Cheakpoint...
Epoch [206/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9303], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9303199648857117, 'Val/mean miou_metric': 0.8839631676673889, 'Val/mean f1': 0.9365846514701843, 'Val/mean precision': 0.9424776434898376, 'Val/mean recall': 0.93076491355896, 'Val/mean hd95_metric': 13.165942192077637}
Epoch [207/300] Training [1/62] Loss: 0.03806 
Epoch [207/300] Training [2/62] Loss: 0.05456 
Epoch [207/300] Training [3/62] Loss: 0.04464 
Epoch [207/300] Training [4/62] Loss: 0.05775 
Epoch [207/300] Training [5/62] Loss: 0.07540 
Epoch [207/300] Training [6/62] Loss: 0.05322 
Epoch [207/300] Training [7/62] Loss: 0.04674 
Epoch [207/300] Training [8/62] Loss: 0.10421 
Epoch [207/300] Training [9/62] Loss: 0.08041 
Epoch [207/300] Training [10/62] Loss: 0.03704 
Epoch [207/300] Training [11/62] Loss: 0.04685 
Epoch [207/300] Training [12/62] Loss: 0.03860 
Epoch [207/300] Training [13/62] Loss: 0.05345 
Epoch [207/300] Training [14/62] Loss: 0.12735 
Epoch [207/300] Training [15/62] Loss: 0.03514 
Epoch [207/300] Training [16/62] Loss: 0.08854 
Epoch [207/300] Training [17/62] Loss: 0.04421 
Epoch [207/300] Training [18/62] Loss: 0.04523 
Epoch [207/300] Training [19/62] Loss: 0.04510 
Epoch [207/300] Training [20/62] Loss: 0.04855 
Epoch [207/300] Training [21/62] Loss: 0.04522 
Epoch [207/300] Training [22/62] Loss: 0.04098 
Epoch [207/300] Training [23/62] Loss: 0.04568 
Epoch [207/300] Training [24/62] Loss: 0.03953 
Epoch [207/300] Training [25/62] Loss: 0.04982 
Epoch [207/300] Training [26/62] Loss: 0.04758 
Epoch [207/300] Training [27/62] Loss: 0.06185 
Epoch [207/300] Training [28/62] Loss: 0.10148 
Epoch [207/300] Training [29/62] Loss: 0.05181 
Epoch [207/300] Training [30/62] Loss: 0.04160 
Epoch [207/300] Training [31/62] Loss: 0.05594 
Epoch [207/300] Training [32/62] Loss: 0.04162 
Epoch [207/300] Training [33/62] Loss: 0.04279 
Epoch [207/300] Training [34/62] Loss: 0.05127 
Epoch [207/300] Training [35/62] Loss: 0.12787 
Epoch [207/300] Training [36/62] Loss: 0.05222 
Epoch [207/300] Training [37/62] Loss: 0.05888 
Epoch [207/300] Training [38/62] Loss: 0.04906 
Epoch [207/300] Training [39/62] Loss: 0.08472 
Epoch [207/300] Training [40/62] Loss: 0.07086 
Epoch [207/300] Training [41/62] Loss: 0.06633 
Epoch [207/300] Training [42/62] Loss: 0.05853 
Epoch [207/300] Training [43/62] Loss: 0.05064 
Epoch [207/300] Training [44/62] Loss: 0.06586 
Epoch [207/300] Training [45/62] Loss: 0.05631 
Epoch [207/300] Training [46/62] Loss: 0.04487 
Epoch [207/300] Training [47/62] Loss: 0.12703 
Epoch [207/300] Training [48/62] Loss: 0.03375 
Epoch [207/300] Training [49/62] Loss: 0.04710 
Epoch [207/300] Training [50/62] Loss: 0.05833 
Epoch [207/300] Training [51/62] Loss: 0.05893 
Epoch [207/300] Training [52/62] Loss: 0.06248 
Epoch [207/300] Training [53/62] Loss: 0.08216 
Epoch [207/300] Training [54/62] Loss: 0.05054 
Epoch [207/300] Training [55/62] Loss: 0.05976 
Epoch [207/300] Training [56/62] Loss: 0.04779 
Epoch [207/300] Training [57/62] Loss: 0.05746 
Epoch [207/300] Training [58/62] Loss: 0.06696 
Epoch [207/300] Training [59/62] Loss: 0.06803 
Epoch [207/300] Training [60/62] Loss: 0.03579 
Epoch [207/300] Training [61/62] Loss: 0.05729 
Epoch [207/300] Training [62/62] Loss: 0.04895 
Epoch [207/300] Training metric {'Train/mean dice_metric': 0.95916348695755, 'Train/mean miou_metric': 0.9241915941238403, 'Train/mean f1': 0.9636077284812927, 'Train/mean precision': 0.9594678282737732, 'Train/mean recall': 0.967783510684967, 'Train/mean hd95_metric': 7.039775371551514}
Epoch [207/300] Validation [1/16] Loss: 0.20329  focal_loss 0.07922  dice_loss 0.12407 
Epoch [207/300] Validation [2/16] Loss: 0.38656  focal_loss 0.15199  dice_loss 0.23457 
Epoch [207/300] Validation [3/16] Loss: 0.74699  focal_loss 0.45775  dice_loss 0.28924 
Epoch [207/300] Validation [4/16] Loss: 0.33114  focal_loss 0.15193  dice_loss 0.17922 
Epoch [207/300] Validation [5/16] Loss: 0.35776  focal_loss 0.14967  dice_loss 0.20809 
Epoch [207/300] Validation [6/16] Loss: 0.17814  focal_loss 0.04134  dice_loss 0.13681 
Epoch [207/300] Validation [7/16] Loss: 0.27813  focal_loss 0.13516  dice_loss 0.14297 
Epoch [207/300] Validation [8/16] Loss: 0.31041  focal_loss 0.10895  dice_loss 0.20146 
Epoch [207/300] Validation [9/16] Loss: 0.20491  focal_loss 0.07770  dice_loss 0.12721 
Epoch [207/300] Validation [10/16] Loss: 0.26670  focal_loss 0.07662  dice_loss 0.19008 
Epoch [207/300] Validation [11/16] Loss: 0.13539  focal_loss 0.03487  dice_loss 0.10051 
Epoch [207/300] Validation [12/16] Loss: 0.33055  focal_loss 0.07641  dice_loss 0.25413 
Epoch [207/300] Validation [13/16] Loss: 0.26736  focal_loss 0.10413  dice_loss 0.16323 
Epoch [207/300] Validation [14/16] Loss: 0.38463  focal_loss 0.12355  dice_loss 0.26108 
Epoch [207/300] Validation [15/16] Loss: 0.11896  focal_loss 0.03348  dice_loss 0.08548 
Epoch [207/300] Validation [16/16] Loss: 0.05266  focal_loss 0.01602  dice_loss 0.03663 
Epoch [207/300] Validation metric {'Val/mean dice_metric': 0.9333740472793579, 'Val/mean miou_metric': 0.8894398212432861, 'Val/mean f1': 0.9401941895484924, 'Val/mean precision': 0.9426897168159485, 'Val/mean recall': 0.9377118945121765, 'Val/mean hd95_metric': 13.411579132080078}
Cheakpoint...
Epoch [207/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9334], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9333740472793579, 'Val/mean miou_metric': 0.8894398212432861, 'Val/mean f1': 0.9401941895484924, 'Val/mean precision': 0.9426897168159485, 'Val/mean recall': 0.9377118945121765, 'Val/mean hd95_metric': 13.411579132080078}
Epoch [208/300] Training [1/62] Loss: 0.03880 
Epoch [208/300] Training [2/62] Loss: 0.05290 
Epoch [208/300] Training [3/62] Loss: 0.06362 
Epoch [208/300] Training [4/62] Loss: 0.07701 
Epoch [208/300] Training [5/62] Loss: 0.04515 
Epoch [208/300] Training [6/62] Loss: 0.05076 
Epoch [208/300] Training [7/62] Loss: 0.10541 
Epoch [208/300] Training [8/62] Loss: 0.04326 
Epoch [208/300] Training [9/62] Loss: 0.07959 
Epoch [208/300] Training [10/62] Loss: 0.07451 
Epoch [208/300] Training [11/62] Loss: 0.05125 
Epoch [208/300] Training [12/62] Loss: 0.11059 
Epoch [208/300] Training [13/62] Loss: 0.07401 
Epoch [208/300] Training [14/62] Loss: 0.09375 
Epoch [208/300] Training [15/62] Loss: 0.04511 
Epoch [208/300] Training [16/62] Loss: 0.07254 
Epoch [208/300] Training [17/62] Loss: 0.05728 
Epoch [208/300] Training [18/62] Loss: 0.13153 
Epoch [208/300] Training [19/62] Loss: 0.05194 
Epoch [208/300] Training [20/62] Loss: 0.04048 
Epoch [208/300] Training [21/62] Loss: 0.03835 
Epoch [208/300] Training [22/62] Loss: 0.06422 
Epoch [208/300] Training [23/62] Loss: 0.06548 
Epoch [208/300] Training [24/62] Loss: 0.05771 
Epoch [208/300] Training [25/62] Loss: 0.04989 
Epoch [208/300] Training [26/62] Loss: 0.03938 
Epoch [208/300] Training [27/62] Loss: 0.05813 
Epoch [208/300] Training [28/62] Loss: 0.05094 
Epoch [208/300] Training [29/62] Loss: 0.05267 
Epoch [208/300] Training [30/62] Loss: 0.08051 
Epoch [208/300] Training [31/62] Loss: 0.04671 
Epoch [208/300] Training [32/62] Loss: 0.14646 
Epoch [208/300] Training [33/62] Loss: 0.11130 
Epoch [208/300] Training [34/62] Loss: 0.04598 
Epoch [208/300] Training [35/62] Loss: 0.04069 
Epoch [208/300] Training [36/62] Loss: 0.05496 
Epoch [208/300] Training [37/62] Loss: 0.09011 
Epoch [208/300] Training [38/62] Loss: 0.04075 
Epoch [208/300] Training [39/62] Loss: 0.07254 
Epoch [208/300] Training [40/62] Loss: 0.08355 
Epoch [208/300] Training [41/62] Loss: 0.04955 
Epoch [208/300] Training [42/62] Loss: 0.04228 
Epoch [208/300] Training [43/62] Loss: 0.05207 
Epoch [208/300] Training [44/62] Loss: 0.06613 
Epoch [208/300] Training [45/62] Loss: 0.08961 
Epoch [208/300] Training [46/62] Loss: 0.05396 
Epoch [208/300] Training [47/62] Loss: 0.06083 
Epoch [208/300] Training [48/62] Loss: 0.04436 
Epoch [208/300] Training [49/62] Loss: 0.04814 
Epoch [208/300] Training [50/62] Loss: 0.07202 
Epoch [208/300] Training [51/62] Loss: 0.06941 
Epoch [208/300] Training [52/62] Loss: 0.03994 
Epoch [208/300] Training [53/62] Loss: 0.06568 
Epoch [208/300] Training [54/62] Loss: 0.08128 
Epoch [208/300] Training [55/62] Loss: 0.04828 
Epoch [208/300] Training [56/62] Loss: 0.16784 
Epoch [208/300] Training [57/62] Loss: 0.05543 
Epoch [208/300] Training [58/62] Loss: 0.05712 
Epoch [208/300] Training [59/62] Loss: 0.06434 
Epoch [208/300] Training [60/62] Loss: 0.08130 
Epoch [208/300] Training [61/62] Loss: 0.04099 
Epoch [208/300] Training [62/62] Loss: 0.03301 
Epoch [208/300] Training metric {'Train/mean dice_metric': 0.9535285830497742, 'Train/mean miou_metric': 0.9163840413093567, 'Train/mean f1': 0.9595804810523987, 'Train/mean precision': 0.9531844258308411, 'Train/mean recall': 0.9660629034042358, 'Train/mean hd95_metric': 7.495636463165283}
Epoch [208/300] Validation [1/16] Loss: 0.15433  focal_loss 0.05810  dice_loss 0.09623 
Epoch [208/300] Validation [2/16] Loss: 0.38185  focal_loss 0.15312  dice_loss 0.22873 
Epoch [208/300] Validation [3/16] Loss: 0.37408  focal_loss 0.13364  dice_loss 0.24044 
Epoch [208/300] Validation [4/16] Loss: 0.24044  focal_loss 0.10419  dice_loss 0.13624 
Epoch [208/300] Validation [5/16] Loss: 0.37156  focal_loss 0.14854  dice_loss 0.22301 
Epoch [208/300] Validation [6/16] Loss: 0.15467  focal_loss 0.03607  dice_loss 0.11861 
Epoch [208/300] Validation [7/16] Loss: 0.19365  focal_loss 0.05701  dice_loss 0.13665 
Epoch [208/300] Validation [8/16] Loss: 0.33413  focal_loss 0.09660  dice_loss 0.23754 
Epoch [208/300] Validation [9/16] Loss: 0.18512  focal_loss 0.07487  dice_loss 0.11025 
Epoch [208/300] Validation [10/16] Loss: 0.44892  focal_loss 0.18186  dice_loss 0.26706 
Epoch [208/300] Validation [11/16] Loss: 0.10275  focal_loss 0.02069  dice_loss 0.08205 
Epoch [208/300] Validation [12/16] Loss: 0.34125  focal_loss 0.09756  dice_loss 0.24369 
Epoch [208/300] Validation [13/16] Loss: 0.17991  focal_loss 0.05061  dice_loss 0.12930 
Epoch [208/300] Validation [14/16] Loss: 0.43745  focal_loss 0.15734  dice_loss 0.28011 
Epoch [208/300] Validation [15/16] Loss: 0.20849  focal_loss 0.08741  dice_loss 0.12109 
Epoch [208/300] Validation [16/16] Loss: 0.06118  focal_loss 0.01599  dice_loss 0.04519 
Epoch [208/300] Validation metric {'Val/mean dice_metric': 0.9292411208152771, 'Val/mean miou_metric': 0.8841074109077454, 'Val/mean f1': 0.9364620447158813, 'Val/mean precision': 0.927471935749054, 'Val/mean recall': 0.9456280469894409, 'Val/mean hd95_metric': 13.663010597229004}
Cheakpoint...
Epoch [208/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9292], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9292411208152771, 'Val/mean miou_metric': 0.8841074109077454, 'Val/mean f1': 0.9364620447158813, 'Val/mean precision': 0.927471935749054, 'Val/mean recall': 0.9456280469894409, 'Val/mean hd95_metric': 13.663010597229004}
Epoch [209/300] Training [1/62] Loss: 0.07092 
Epoch [209/300] Training [2/62] Loss: 0.04754 
Epoch [209/300] Training [3/62] Loss: 0.05076 
Epoch [209/300] Training [4/62] Loss: 0.05980 
Epoch [209/300] Training [5/62] Loss: 0.04660 
Epoch [209/300] Training [6/62] Loss: 0.03972 
Epoch [209/300] Training [7/62] Loss: 0.04883 
Epoch [209/300] Training [8/62] Loss: 0.03604 
Epoch [209/300] Training [9/62] Loss: 0.05271 
Epoch [209/300] Training [10/62] Loss: 0.06709 
Epoch [209/300] Training [11/62] Loss: 0.03961 
Epoch [209/300] Training [12/62] Loss: 0.05376 
Epoch [209/300] Training [13/62] Loss: 0.05524 
Epoch [209/300] Training [14/62] Loss: 0.05286 
Epoch [209/300] Training [15/62] Loss: 0.06129 
Epoch [209/300] Training [16/62] Loss: 0.05002 
Epoch [209/300] Training [17/62] Loss: 0.09295 
Epoch [209/300] Training [18/62] Loss: 0.05248 
Epoch [209/300] Training [19/62] Loss: 0.05509 
Epoch [209/300] Training [20/62] Loss: 0.03555 
Epoch [209/300] Training [21/62] Loss: 0.05687 
Epoch [209/300] Training [22/62] Loss: 0.04150 
Epoch [209/300] Training [23/62] Loss: 0.05718 
Epoch [209/300] Training [24/62] Loss: 0.06521 
Epoch [209/300] Training [25/62] Loss: 0.03296 
Epoch [209/300] Training [26/62] Loss: 0.04787 
Epoch [209/300] Training [27/62] Loss: 0.07599 
Epoch [209/300] Training [28/62] Loss: 0.03783 
Epoch [209/300] Training [29/62] Loss: 0.11798 
Epoch [209/300] Training [30/62] Loss: 0.04039 
Epoch [209/300] Training [31/62] Loss: 0.03610 
Epoch [209/300] Training [32/62] Loss: 0.04560 
Epoch [209/300] Training [33/62] Loss: 0.04670 
Epoch [209/300] Training [34/62] Loss: 0.04031 
Epoch [209/300] Training [35/62] Loss: 0.05661 
Epoch [209/300] Training [36/62] Loss: 0.08735 
Epoch [209/300] Training [37/62] Loss: 0.04311 
Epoch [209/300] Training [38/62] Loss: 0.05492 
Epoch [209/300] Training [39/62] Loss: 0.05728 
Epoch [209/300] Training [40/62] Loss: 0.05702 
Epoch [209/300] Training [41/62] Loss: 0.07930 
Epoch [209/300] Training [42/62] Loss: 0.04431 
Epoch [209/300] Training [43/62] Loss: 0.04831 
Epoch [209/300] Training [44/62] Loss: 0.04140 
Epoch [209/300] Training [45/62] Loss: 0.06508 
Epoch [209/300] Training [46/62] Loss: 0.05950 
Epoch [209/300] Training [47/62] Loss: 0.10653 
Epoch [209/300] Training [48/62] Loss: 0.07630 
Epoch [209/300] Training [49/62] Loss: 0.08326 
Epoch [209/300] Training [50/62] Loss: 0.04421 
Epoch [209/300] Training [51/62] Loss: 0.05799 
Epoch [209/300] Training [52/62] Loss: 0.04306 
Epoch [209/300] Training [53/62] Loss: 0.08081 
Epoch [209/300] Training [54/62] Loss: 0.04996 
Epoch [209/300] Training [55/62] Loss: 0.05570 
Epoch [209/300] Training [56/62] Loss: 0.06974 
Epoch [209/300] Training [57/62] Loss: 0.06474 
Epoch [209/300] Training [58/62] Loss: 0.06143 
Epoch [209/300] Training [59/62] Loss: 0.08010 
Epoch [209/300] Training [60/62] Loss: 0.04466 
Epoch [209/300] Training [61/62] Loss: 0.04956 
Epoch [209/300] Training [62/62] Loss: 0.14917 
Epoch [209/300] Training metric {'Train/mean dice_metric': 0.960066556930542, 'Train/mean miou_metric': 0.9255426526069641, 'Train/mean f1': 0.9643797278404236, 'Train/mean precision': 0.9597886204719543, 'Train/mean recall': 0.9690148830413818, 'Train/mean hd95_metric': 6.2754974365234375}
Epoch [209/300] Validation [1/16] Loss: 0.24583  focal_loss 0.11332  dice_loss 0.13250 
Epoch [209/300] Validation [2/16] Loss: 0.37386  focal_loss 0.15952  dice_loss 0.21434 
Epoch [209/300] Validation [3/16] Loss: 0.63422  focal_loss 0.37605  dice_loss 0.25817 
Epoch [209/300] Validation [4/16] Loss: 0.25597  focal_loss 0.11598  dice_loss 0.13999 
Epoch [209/300] Validation [5/16] Loss: 0.33300  focal_loss 0.13390  dice_loss 0.19909 
Epoch [209/300] Validation [6/16] Loss: 0.18117  focal_loss 0.04153  dice_loss 0.13965 
Epoch [209/300] Validation [7/16] Loss: 0.37248  focal_loss 0.16710  dice_loss 0.20538 
Epoch [209/300] Validation [8/16] Loss: 0.46898  focal_loss 0.17960  dice_loss 0.28938 
Epoch [209/300] Validation [9/16] Loss: 0.23567  focal_loss 0.08578  dice_loss 0.14989 
Epoch [209/300] Validation [10/16] Loss: 0.35880  focal_loss 0.11673  dice_loss 0.24207 
Epoch [209/300] Validation [11/16] Loss: 0.15589  focal_loss 0.04298  dice_loss 0.11291 
Epoch [209/300] Validation [12/16] Loss: 0.35809  focal_loss 0.11586  dice_loss 0.24223 
Epoch [209/300] Validation [13/16] Loss: 0.29425  focal_loss 0.11309  dice_loss 0.18116 
Epoch [209/300] Validation [14/16] Loss: 0.45130  focal_loss 0.15619  dice_loss 0.29512 
Epoch [209/300] Validation [15/16] Loss: 0.09710  focal_loss 0.02838  dice_loss 0.06871 
Epoch [209/300] Validation [16/16] Loss: 0.04991  focal_loss 0.01090  dice_loss 0.03901 
Epoch [209/300] Validation metric {'Val/mean dice_metric': 0.9314046502113342, 'Val/mean miou_metric': 0.887993335723877, 'Val/mean f1': 0.9388949275016785, 'Val/mean precision': 0.9369500279426575, 'Val/mean recall': 0.9408479928970337, 'Val/mean hd95_metric': 13.207262992858887}
Cheakpoint...
Epoch [209/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9314], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9314046502113342, 'Val/mean miou_metric': 0.887993335723877, 'Val/mean f1': 0.9388949275016785, 'Val/mean precision': 0.9369500279426575, 'Val/mean recall': 0.9408479928970337, 'Val/mean hd95_metric': 13.207262992858887}
Epoch [210/300] Training [1/62] Loss: 0.04084 
Epoch [210/300] Training [2/62] Loss: 0.05446 
Epoch [210/300] Training [3/62] Loss: 0.08329 
Epoch [210/300] Training [4/62] Loss: 0.12177 
Epoch [210/300] Training [5/62] Loss: 0.04302 
Epoch [210/300] Training [6/62] Loss: 0.04244 
Epoch [210/300] Training [7/62] Loss: 0.04997 
Epoch [210/300] Training [8/62] Loss: 0.05403 
Epoch [210/300] Training [9/62] Loss: 0.04842 
Epoch [210/300] Training [10/62] Loss: 0.05076 
Epoch [210/300] Training [11/62] Loss: 0.05530 
Epoch [210/300] Training [12/62] Loss: 0.05875 
Epoch [210/300] Training [13/62] Loss: 0.10978 
Epoch [210/300] Training [14/62] Loss: 0.18207 
Epoch [210/300] Training [15/62] Loss: 0.04850 
Epoch [210/300] Training [16/62] Loss: 0.06081 
Epoch [210/300] Training [17/62] Loss: 0.04027 
Epoch [210/300] Training [18/62] Loss: 0.04289 
Epoch [210/300] Training [19/62] Loss: 0.05808 
Epoch [210/300] Training [20/62] Loss: 0.05002 
Epoch [210/300] Training [21/62] Loss: 0.04508 
Epoch [210/300] Training [22/62] Loss: 0.07187 
Epoch [210/300] Training [23/62] Loss: 0.05642 
Epoch [210/300] Training [24/62] Loss: 0.06309 
Epoch [210/300] Training [25/62] Loss: 0.04642 
Epoch [210/300] Training [26/62] Loss: 0.05208 
Epoch [210/300] Training [27/62] Loss: 0.11296 
Epoch [210/300] Training [28/62] Loss: 0.05931 
Epoch [210/300] Training [29/62] Loss: 0.03864 
Epoch [210/300] Training [30/62] Loss: 0.04664 
Epoch [210/300] Training [31/62] Loss: 0.10660 
Epoch [210/300] Training [32/62] Loss: 0.07686 
Epoch [210/300] Training [33/62] Loss: 0.06324 
Epoch [210/300] Training [34/62] Loss: 0.04249 
Epoch [210/300] Training [35/62] Loss: 0.03861 
Epoch [210/300] Training [36/62] Loss: 0.05293 
Epoch [210/300] Training [37/62] Loss: 0.05295 
Epoch [210/300] Training [38/62] Loss: 0.05409 
Epoch [210/300] Training [39/62] Loss: 0.03844 
Epoch [210/300] Training [40/62] Loss: 0.06341 
Epoch [210/300] Training [41/62] Loss: 0.08017 
Epoch [210/300] Training [42/62] Loss: 0.04864 
Epoch [210/300] Training [43/62] Loss: 0.04302 
Epoch [210/300] Training [44/62] Loss: 0.05386 
Epoch [210/300] Training [45/62] Loss: 0.04327 
Epoch [210/300] Training [46/62] Loss: 0.04735 
Epoch [210/300] Training [47/62] Loss: 0.05009 
Epoch [210/300] Training [48/62] Loss: 0.04545 
Epoch [210/300] Training [49/62] Loss: 0.06128 
Epoch [210/300] Training [50/62] Loss: 0.05412 
Epoch [210/300] Training [51/62] Loss: 0.05620 
Epoch [210/300] Training [52/62] Loss: 0.05748 
Epoch [210/300] Training [53/62] Loss: 0.03770 
Epoch [210/300] Training [54/62] Loss: 0.06830 
Epoch [210/300] Training [55/62] Loss: 0.05185 
Epoch [210/300] Training [56/62] Loss: 0.04180 
Epoch [210/300] Training [57/62] Loss: 0.05413 
Epoch [210/300] Training [58/62] Loss: 0.05667 
Epoch [210/300] Training [59/62] Loss: 0.05868 
Epoch [210/300] Training [60/62] Loss: 0.07824 
Epoch [210/300] Training [61/62] Loss: 0.04519 
Epoch [210/300] Training [62/62] Loss: 0.02762 
Epoch [210/300] Training metric {'Train/mean dice_metric': 0.9587867856025696, 'Train/mean miou_metric': 0.9243476390838623, 'Train/mean f1': 0.962961733341217, 'Train/mean precision': 0.9574828147888184, 'Train/mean recall': 0.9685037136077881, 'Train/mean hd95_metric': 6.363194465637207}
Epoch [210/300] Validation [1/16] Loss: 0.36436  focal_loss 0.21448  dice_loss 0.14988 
Epoch [210/300] Validation [2/16] Loss: 0.38086  focal_loss 0.15418  dice_loss 0.22668 
Epoch [210/300] Validation [3/16] Loss: 0.30769  focal_loss 0.11428  dice_loss 0.19341 
Epoch [210/300] Validation [4/16] Loss: 0.29547  focal_loss 0.14013  dice_loss 0.15534 
Epoch [210/300] Validation [5/16] Loss: 0.32667  focal_loss 0.13492  dice_loss 0.19175 
Epoch [210/300] Validation [6/16] Loss: 0.16987  focal_loss 0.04744  dice_loss 0.12243 
Epoch [210/300] Validation [7/16] Loss: 0.34842  focal_loss 0.18207  dice_loss 0.16635 
Epoch [210/300] Validation [8/16] Loss: 0.35108  focal_loss 0.11164  dice_loss 0.23944 
Epoch [210/300] Validation [9/16] Loss: 0.22807  focal_loss 0.08277  dice_loss 0.14530 
Epoch [210/300] Validation [10/16] Loss: 0.30783  focal_loss 0.12093  dice_loss 0.18690 
Epoch [210/300] Validation [11/16] Loss: 0.13089  focal_loss 0.03958  dice_loss 0.09131 
Epoch [210/300] Validation [12/16] Loss: 0.41454  focal_loss 0.11441  dice_loss 0.30013 
Epoch [210/300] Validation [13/16] Loss: 0.31079  focal_loss 0.12872  dice_loss 0.18207 
Epoch [210/300] Validation [14/16] Loss: 0.43360  focal_loss 0.14631  dice_loss 0.28729 
Epoch [210/300] Validation [15/16] Loss: 0.10012  focal_loss 0.02909  dice_loss 0.07103 
Epoch [210/300] Validation [16/16] Loss: 0.05191  focal_loss 0.01396  dice_loss 0.03795 
Epoch [210/300] Validation metric {'Val/mean dice_metric': 0.932426929473877, 'Val/mean miou_metric': 0.8888723254203796, 'Val/mean f1': 0.9401740431785583, 'Val/mean precision': 0.9396874904632568, 'Val/mean recall': 0.9406611919403076, 'Val/mean hd95_metric': 12.63210678100586}
Cheakpoint...
Epoch [210/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9324], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.932426929473877, 'Val/mean miou_metric': 0.8888723254203796, 'Val/mean f1': 0.9401740431785583, 'Val/mean precision': 0.9396874904632568, 'Val/mean recall': 0.9406611919403076, 'Val/mean hd95_metric': 12.63210678100586}
Epoch [211/300] Training [1/62] Loss: 0.05527 
Epoch [211/300] Training [2/62] Loss: 0.08783 
Epoch [211/300] Training [3/62] Loss: 0.08119 
Epoch [211/300] Training [4/62] Loss: 0.04364 
Epoch [211/300] Training [5/62] Loss: 0.04803 
Epoch [211/300] Training [6/62] Loss: 0.04588 
Epoch [211/300] Training [7/62] Loss: 0.05007 
Epoch [211/300] Training [8/62] Loss: 0.05070 
Epoch [211/300] Training [9/62] Loss: 0.06893 
Epoch [211/300] Training [10/62] Loss: 0.03905 
Epoch [211/300] Training [11/62] Loss: 0.05467 
Epoch [211/300] Training [12/62] Loss: 0.03728 
Epoch [211/300] Training [13/62] Loss: 0.09699 
Epoch [211/300] Training [14/62] Loss: 0.04685 
Epoch [211/300] Training [15/62] Loss: 0.05081 
Epoch [211/300] Training [16/62] Loss: 0.06101 
Epoch [211/300] Training [17/62] Loss: 0.04853 
Epoch [211/300] Training [18/62] Loss: 0.04187 
Epoch [211/300] Training [19/62] Loss: 0.04288 
Epoch [211/300] Training [20/62] Loss: 0.03382 
Epoch [211/300] Training [21/62] Loss: 0.08837 
Epoch [211/300] Training [22/62] Loss: 0.05388 
Epoch [211/300] Training [23/62] Loss: 0.13025 
Epoch [211/300] Training [24/62] Loss: 0.06203 
Epoch [211/300] Training [25/62] Loss: 0.05247 
Epoch [211/300] Training [26/62] Loss: 0.06454 
Epoch [211/300] Training [27/62] Loss: 0.04498 
Epoch [211/300] Training [28/62] Loss: 0.04828 
Epoch [211/300] Training [29/62] Loss: 0.04038 
Epoch [211/300] Training [30/62] Loss: 0.04061 
Epoch [211/300] Training [31/62] Loss: 0.03432 
Epoch [211/300] Training [32/62] Loss: 0.04928 
Epoch [211/300] Training [33/62] Loss: 0.05835 
Epoch [211/300] Training [34/62] Loss: 0.04711 
Epoch [211/300] Training [35/62] Loss: 0.05427 
Epoch [211/300] Training [36/62] Loss: 0.08973 
Epoch [211/300] Training [37/62] Loss: 0.08815 
Epoch [211/300] Training [38/62] Loss: 0.07438 
Epoch [211/300] Training [39/62] Loss: 0.04192 
Epoch [211/300] Training [40/62] Loss: 0.05874 
Epoch [211/300] Training [41/62] Loss: 0.10162 
Epoch [211/300] Training [42/62] Loss: 0.03660 
Epoch [211/300] Training [43/62] Loss: 0.04336 
Epoch [211/300] Training [44/62] Loss: 0.04782 
Epoch [211/300] Training [45/62] Loss: 0.05920 
Epoch [211/300] Training [46/62] Loss: 0.04301 
Epoch [211/300] Training [47/62] Loss: 0.03609 
Epoch [211/300] Training [48/62] Loss: 0.04611 
Epoch [211/300] Training [49/62] Loss: 0.04764 
Epoch [211/300] Training [50/62] Loss: 0.11903 
Epoch [211/300] Training [51/62] Loss: 0.03963 
Epoch [211/300] Training [52/62] Loss: 0.05180 
Epoch [211/300] Training [53/62] Loss: 0.03972 
Epoch [211/300] Training [54/62] Loss: 0.04988 
Epoch [211/300] Training [55/62] Loss: 0.05611 
Epoch [211/300] Training [56/62] Loss: 0.04719 
Epoch [211/300] Training [57/62] Loss: 0.04350 
Epoch [211/300] Training [58/62] Loss: 0.06002 
Epoch [211/300] Training [59/62] Loss: 0.03219 
Epoch [211/300] Training [60/62] Loss: 0.04147 
Epoch [211/300] Training [61/62] Loss: 0.05448 
Epoch [211/300] Training [62/62] Loss: 0.04191 
Epoch [211/300] Training metric {'Train/mean dice_metric': 0.9612345695495605, 'Train/mean miou_metric': 0.9275763630867004, 'Train/mean f1': 0.9639931321144104, 'Train/mean precision': 0.9593629240989685, 'Train/mean recall': 0.9686681032180786, 'Train/mean hd95_metric': 6.192323684692383}
Epoch [211/300] Validation [1/16] Loss: 0.33838  focal_loss 0.18702  dice_loss 0.15136 
Epoch [211/300] Validation [2/16] Loss: 0.40962  focal_loss 0.17305  dice_loss 0.23657 
Epoch [211/300] Validation [3/16] Loss: 0.23942  focal_loss 0.06199  dice_loss 0.17743 
Epoch [211/300] Validation [4/16] Loss: 0.46052  focal_loss 0.22845  dice_loss 0.23207 
Epoch [211/300] Validation [5/16] Loss: 0.31300  focal_loss 0.08678  dice_loss 0.22622 
Epoch [211/300] Validation [6/16] Loss: 0.13966  focal_loss 0.03173  dice_loss 0.10792 
Epoch [211/300] Validation [7/16] Loss: 0.20377  focal_loss 0.07754  dice_loss 0.12623 
Epoch [211/300] Validation [8/16] Loss: 0.43340  focal_loss 0.15766  dice_loss 0.27573 
Epoch [211/300] Validation [9/16] Loss: 0.16684  focal_loss 0.07096  dice_loss 0.09588 
Epoch [211/300] Validation [10/16] Loss: 0.23812  focal_loss 0.06003  dice_loss 0.17809 
Epoch [211/300] Validation [11/16] Loss: 0.12082  focal_loss 0.03243  dice_loss 0.08840 
Epoch [211/300] Validation [12/16] Loss: 0.33320  focal_loss 0.09363  dice_loss 0.23957 
Epoch [211/300] Validation [13/16] Loss: 0.24035  focal_loss 0.08778  dice_loss 0.15257 
Epoch [211/300] Validation [14/16] Loss: 0.64651  focal_loss 0.23952  dice_loss 0.40699 
Epoch [211/300] Validation [15/16] Loss: 0.09727  focal_loss 0.03037  dice_loss 0.06690 
Epoch [211/300] Validation [16/16] Loss: 0.06015  focal_loss 0.01515  dice_loss 0.04501 
Epoch [211/300] Validation metric {'Val/mean dice_metric': 0.9338039755821228, 'Val/mean miou_metric': 0.8909898400306702, 'Val/mean f1': 0.9413305521011353, 'Val/mean precision': 0.9431177973747253, 'Val/mean recall': 0.93954998254776, 'Val/mean hd95_metric': 12.454249382019043}
Cheakpoint...
Epoch [211/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9338], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9338039755821228, 'Val/mean miou_metric': 0.8909898400306702, 'Val/mean f1': 0.9413305521011353, 'Val/mean precision': 0.9431177973747253, 'Val/mean recall': 0.93954998254776, 'Val/mean hd95_metric': 12.454249382019043}
Epoch [212/300] Training [1/62] Loss: 0.05464 
Epoch [212/300] Training [2/62] Loss: 0.04195 
Epoch [212/300] Training [3/62] Loss: 0.07011 
Epoch [212/300] Training [4/62] Loss: 0.05247 
Epoch [212/300] Training [5/62] Loss: 0.05211 
Epoch [212/300] Training [6/62] Loss: 0.03641 
Epoch [212/300] Training [7/62] Loss: 0.04113 
Epoch [212/300] Training [8/62] Loss: 0.04430 
Epoch [212/300] Training [9/62] Loss: 0.07710 
Epoch [212/300] Training [10/62] Loss: 0.03624 
Epoch [212/300] Training [11/62] Loss: 0.04609 
Epoch [212/300] Training [12/62] Loss: 0.04612 
Epoch [212/300] Training [13/62] Loss: 0.06248 
Epoch [212/300] Training [14/62] Loss: 0.05965 
Epoch [212/300] Training [15/62] Loss: 0.03797 
Epoch [212/300] Training [16/62] Loss: 0.05797 
Epoch [212/300] Training [17/62] Loss: 0.07130 
Epoch [212/300] Training [18/62] Loss: 0.06385 
Epoch [212/300] Training [19/62] Loss: 0.04006 
Epoch [212/300] Training [20/62] Loss: 0.05315 
Epoch [212/300] Training [21/62] Loss: 0.04720 
Epoch [212/300] Training [22/62] Loss: 0.06275 
Epoch [212/300] Training [23/62] Loss: 0.08827 
Epoch [212/300] Training [24/62] Loss: 0.04334 
Epoch [212/300] Training [25/62] Loss: 0.09116 
Epoch [212/300] Training [26/62] Loss: 0.07024 
Epoch [212/300] Training [27/62] Loss: 0.06148 
Epoch [212/300] Training [28/62] Loss: 0.03981 
Epoch [212/300] Training [29/62] Loss: 0.03626 
Epoch [212/300] Training [30/62] Loss: 0.03738 
Epoch [212/300] Training [31/62] Loss: 0.06136 
Epoch [212/300] Training [32/62] Loss: 0.05686 
Epoch [212/300] Training [33/62] Loss: 0.07534 
Epoch [212/300] Training [34/62] Loss: 0.06000 
Epoch [212/300] Training [35/62] Loss: 0.06139 
Epoch [212/300] Training [36/62] Loss: 0.06077 
Epoch [212/300] Training [37/62] Loss: 0.05550 
Epoch [212/300] Training [38/62] Loss: 0.03797 
Epoch [212/300] Training [39/62] Loss: 0.06440 
Epoch [212/300] Training [40/62] Loss: 0.08529 
Epoch [212/300] Training [41/62] Loss: 0.05440 
Epoch [212/300] Training [42/62] Loss: 0.05629 
Epoch [212/300] Training [43/62] Loss: 0.11489 
Epoch [212/300] Training [44/62] Loss: 0.09471 
Epoch [212/300] Training [45/62] Loss: 0.03752 
Epoch [212/300] Training [46/62] Loss: 0.07890 
Epoch [212/300] Training [47/62] Loss: 0.04762 
Epoch [212/300] Training [48/62] Loss: 0.03795 
Epoch [212/300] Training [49/62] Loss: 0.04151 
Epoch [212/300] Training [50/62] Loss: 0.04817 
Epoch [212/300] Training [51/62] Loss: 0.07853 
Epoch [212/300] Training [52/62] Loss: 0.08076 
Epoch [212/300] Training [53/62] Loss: 0.04159 
Epoch [212/300] Training [54/62] Loss: 0.03902 
Epoch [212/300] Training [55/62] Loss: 0.05721 
Epoch [212/300] Training [56/62] Loss: 0.04544 
Epoch [212/300] Training [57/62] Loss: 0.05360 
Epoch [212/300] Training [58/62] Loss: 0.06844 
Epoch [212/300] Training [59/62] Loss: 0.04480 
Epoch [212/300] Training [60/62] Loss: 0.04784 
Epoch [212/300] Training [61/62] Loss: 0.05482 
Epoch [212/300] Training [62/62] Loss: 0.03509 
Epoch [212/300] Training metric {'Train/mean dice_metric': 0.9605110287666321, 'Train/mean miou_metric': 0.9261286854743958, 'Train/mean f1': 0.9635877013206482, 'Train/mean precision': 0.9580698013305664, 'Train/mean recall': 0.9691694974899292, 'Train/mean hd95_metric': 6.8315348625183105}
Epoch [212/300] Validation [1/16] Loss: 0.19083  focal_loss 0.08126  dice_loss 0.10957 
Epoch [212/300] Validation [2/16] Loss: 0.40963  focal_loss 0.16263  dice_loss 0.24699 
Epoch [212/300] Validation [3/16] Loss: 0.82254  focal_loss 0.52629  dice_loss 0.29626 
Epoch [212/300] Validation [4/16] Loss: 0.42052  focal_loss 0.20567  dice_loss 0.21485 
Epoch [212/300] Validation [5/16] Loss: 0.35610  focal_loss 0.14767  dice_loss 0.20843 
Epoch [212/300] Validation [6/16] Loss: 0.31146  focal_loss 0.06460  dice_loss 0.24686 
Epoch [212/300] Validation [7/16] Loss: 0.35038  focal_loss 0.16447  dice_loss 0.18591 
Epoch [212/300] Validation [8/16] Loss: 0.34429  focal_loss 0.11333  dice_loss 0.23097 
Epoch [212/300] Validation [9/16] Loss: 0.12438  focal_loss 0.04070  dice_loss 0.08368 
Epoch [212/300] Validation [10/16] Loss: 0.31385  focal_loss 0.09630  dice_loss 0.21755 
Epoch [212/300] Validation [11/16] Loss: 0.18013  focal_loss 0.05745  dice_loss 0.12268 
Epoch [212/300] Validation [12/16] Loss: 0.27852  focal_loss 0.06758  dice_loss 0.21093 
Epoch [212/300] Validation [13/16] Loss: 0.27559  focal_loss 0.09566  dice_loss 0.17994 
Epoch [212/300] Validation [14/16] Loss: 0.56946  focal_loss 0.19839  dice_loss 0.37107 
Epoch [212/300] Validation [15/16] Loss: 0.14773  focal_loss 0.05074  dice_loss 0.09699 
Epoch [212/300] Validation [16/16] Loss: 0.06683  focal_loss 0.01911  dice_loss 0.04772 
Epoch [212/300] Validation metric {'Val/mean dice_metric': 0.9293660521507263, 'Val/mean miou_metric': 0.886347770690918, 'Val/mean f1': 0.9394790530204773, 'Val/mean precision': 0.9459079504013062, 'Val/mean recall': 0.9331369400024414, 'Val/mean hd95_metric': 13.45280933380127}
Cheakpoint...
Epoch [212/300] best acc:tensor([0.9342], device='cuda:0'), Now : mean acc: tensor([0.9294], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9293660521507263, 'Val/mean miou_metric': 0.886347770690918, 'Val/mean f1': 0.9394790530204773, 'Val/mean precision': 0.9459079504013062, 'Val/mean recall': 0.9331369400024414, 'Val/mean hd95_metric': 13.45280933380127}
Epoch [213/300] Training [1/62] Loss: 0.08385 
Epoch [213/300] Training [2/62] Loss: 0.03314 
Epoch [213/300] Training [3/62] Loss: 0.06889 
Epoch [213/300] Training [4/62] Loss: 0.03659 
Epoch [213/300] Training [5/62] Loss: 0.06767 
Epoch [213/300] Training [6/62] Loss: 0.03713 
Epoch [213/300] Training [7/62] Loss: 0.05995 
Epoch [213/300] Training [8/62] Loss: 0.05689 
Epoch [213/300] Training [9/62] Loss: 0.03927 
Epoch [213/300] Training [10/62] Loss: 0.03455 
Epoch [213/300] Training [11/62] Loss: 0.08967 
Epoch [213/300] Training [12/62] Loss: 0.05019 
Epoch [213/300] Training [13/62] Loss: 0.04480 
Epoch [213/300] Training [14/62] Loss: 0.05171 
Epoch [213/300] Training [15/62] Loss: 0.08309 
Epoch [213/300] Training [16/62] Loss: 0.07586 
Epoch [213/300] Training [17/62] Loss: 0.03840 
Epoch [213/300] Training [18/62] Loss: 0.03721 
Epoch [213/300] Training [19/62] Loss: 0.04665 
Epoch [213/300] Training [20/62] Loss: 0.03737 
Epoch [213/300] Training [21/62] Loss: 0.09036 
Epoch [213/300] Training [22/62] Loss: 0.03292 
Epoch [213/300] Training [23/62] Loss: 0.04034 
Epoch [213/300] Training [24/62] Loss: 0.03496 
Epoch [213/300] Training [25/62] Loss: 0.06078 
Epoch [213/300] Training [26/62] Loss: 0.03934 
Epoch [213/300] Training [27/62] Loss: 0.05120 
Epoch [213/300] Training [28/62] Loss: 0.07502 
Epoch [213/300] Training [29/62] Loss: 0.03960 
Epoch [213/300] Training [30/62] Loss: 0.04076 
Epoch [213/300] Training [31/62] Loss: 0.05629 
Epoch [213/300] Training [32/62] Loss: 0.05426 
Epoch [213/300] Training [33/62] Loss: 0.04826 
Epoch [213/300] Training [34/62] Loss: 0.04332 
Epoch [213/300] Training [35/62] Loss: 0.05160 
Epoch [213/300] Training [36/62] Loss: 0.04273 
Epoch [213/300] Training [37/62] Loss: 0.04459 
Epoch [213/300] Training [38/62] Loss: 0.03770 
Epoch [213/300] Training [39/62] Loss: 0.06478 
Epoch [213/300] Training [40/62] Loss: 0.04237 
Epoch [213/300] Training [41/62] Loss: 0.03650 
Epoch [213/300] Training [42/62] Loss: 0.04141 
Epoch [213/300] Training [43/62] Loss: 0.04741 
Epoch [213/300] Training [44/62] Loss: 0.05849 
Epoch [213/300] Training [45/62] Loss: 0.06797 
Epoch [213/300] Training [46/62] Loss: 0.04007 
Epoch [213/300] Training [47/62] Loss: 0.04736 
Epoch [213/300] Training [48/62] Loss: 0.03800 
Epoch [213/300] Training [49/62] Loss: 0.09474 
Epoch [213/300] Training [50/62] Loss: 0.07366 
Epoch [213/300] Training [51/62] Loss: 0.05157 
Epoch [213/300] Training [52/62] Loss: 0.09713 
Epoch [213/300] Training [53/62] Loss: 0.08188 
Epoch [213/300] Training [54/62] Loss: 0.04142 
Epoch [213/300] Training [55/62] Loss: 0.06311 
Epoch [213/300] Training [56/62] Loss: 0.13368 
Epoch [213/300] Training [57/62] Loss: 0.10079 
Epoch [213/300] Training [58/62] Loss: 0.07402 
Epoch [213/300] Training [59/62] Loss: 0.10641 
Epoch [213/300] Training [60/62] Loss: 0.05899 
Epoch [213/300] Training [61/62] Loss: 0.05325 
Epoch [213/300] Training [62/62] Loss: 0.03905 
Epoch [213/300] Training metric {'Train/mean dice_metric': 0.9604137539863586, 'Train/mean miou_metric': 0.9267392158508301, 'Train/mean f1': 0.9641575813293457, 'Train/mean precision': 0.9609457850456238, 'Train/mean recall': 0.9673910140991211, 'Train/mean hd95_metric': 6.459484577178955}
Epoch [213/300] Validation [1/16] Loss: 0.15698  focal_loss 0.06319  dice_loss 0.09379 
Epoch [213/300] Validation [2/16] Loss: 0.38761  focal_loss 0.15598  dice_loss 0.23162 
Epoch [213/300] Validation [3/16] Loss: 0.31038  focal_loss 0.10252  dice_loss 0.20787 
Epoch [213/300] Validation [4/16] Loss: 0.26767  focal_loss 0.11362  dice_loss 0.15405 
Epoch [213/300] Validation [5/16] Loss: 0.34122  focal_loss 0.09671  dice_loss 0.24451 
Epoch [213/300] Validation [6/16] Loss: 0.16771  focal_loss 0.03239  dice_loss 0.13533 
Epoch [213/300] Validation [7/16] Loss: 0.17992  focal_loss 0.05994  dice_loss 0.11998 
Epoch [213/300] Validation [8/16] Loss: 0.32097  focal_loss 0.08150  dice_loss 0.23948 
Epoch [213/300] Validation [9/16] Loss: 0.13529  focal_loss 0.04973  dice_loss 0.08556 
Epoch [213/300] Validation [10/16] Loss: 0.41732  focal_loss 0.12505  dice_loss 0.29227 
Epoch [213/300] Validation [11/16] Loss: 0.15831  focal_loss 0.04658  dice_loss 0.11173 
Epoch [213/300] Validation [12/16] Loss: 0.27054  focal_loss 0.06180  dice_loss 0.20874 
Epoch [213/300] Validation [13/16] Loss: 0.22135  focal_loss 0.07439  dice_loss 0.14696 
Epoch [213/300] Validation [14/16] Loss: 0.45504  focal_loss 0.14496  dice_loss 0.31008 
Epoch [213/300] Validation [15/16] Loss: 0.10081  focal_loss 0.03282  dice_loss 0.06798 
Epoch [213/300] Validation [16/16] Loss: 0.04060  focal_loss 0.00909  dice_loss 0.03151 
Epoch [213/300] Validation metric {'Val/mean dice_metric': 0.9348508715629578, 'Val/mean miou_metric': 0.8927573561668396, 'Val/mean f1': 0.9423666000366211, 'Val/mean precision': 0.9396399855613708, 'Val/mean recall': 0.9451090693473816, 'Val/mean hd95_metric': 12.690632820129395}
Cheakpoint...
Epoch [213/300] best acc:tensor([0.9349], device='cuda:0'), Now : mean acc: tensor([0.9349], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9348508715629578, 'Val/mean miou_metric': 0.8927573561668396, 'Val/mean f1': 0.9423666000366211, 'Val/mean precision': 0.9396399855613708, 'Val/mean recall': 0.9451090693473816, 'Val/mean hd95_metric': 12.690632820129395}
Epoch [214/300] Training [1/62] Loss: 0.12446 
Epoch [214/300] Training [2/62] Loss: 0.03898 
Epoch [214/300] Training [3/62] Loss: 0.04877 
Epoch [214/300] Training [4/62] Loss: 0.03978 
Epoch [214/300] Training [5/62] Loss: 0.04348 
Epoch [214/300] Training [6/62] Loss: 0.05820 
Epoch [214/300] Training [7/62] Loss: 0.04095 
Epoch [214/300] Training [8/62] Loss: 0.10158 
Epoch [214/300] Training [9/62] Loss: 0.04800 
Epoch [214/300] Training [10/62] Loss: 0.08183 
Epoch [214/300] Training [11/62] Loss: 0.05403 
Epoch [214/300] Training [12/62] Loss: 0.04685 
Epoch [214/300] Training [13/62] Loss: 0.03718 
Epoch [214/300] Training [14/62] Loss: 0.05379 
Epoch [214/300] Training [15/62] Loss: 0.06744 
Epoch [214/300] Training [16/62] Loss: 0.04456 
Epoch [214/300] Training [17/62] Loss: 0.04346 
Epoch [214/300] Training [18/62] Loss: 0.05340 
Epoch [214/300] Training [19/62] Loss: 0.03154 
Epoch [214/300] Training [20/62] Loss: 0.04223 
Epoch [214/300] Training [21/62] Loss: 0.03596 
Epoch [214/300] Training [22/62] Loss: 0.05784 
Epoch [214/300] Training [23/62] Loss: 0.03418 
Epoch [214/300] Training [24/62] Loss: 0.04504 
Epoch [214/300] Training [25/62] Loss: 0.04338 
Epoch [214/300] Training [26/62] Loss: 0.08877 
Epoch [214/300] Training [27/62] Loss: 0.03784 
Epoch [214/300] Training [28/62] Loss: 0.04423 
Epoch [214/300] Training [29/62] Loss: 0.04308 
Epoch [214/300] Training [30/62] Loss: 0.04918 
Epoch [214/300] Training [31/62] Loss: 0.05008 
Epoch [214/300] Training [32/62] Loss: 0.06925 
Epoch [214/300] Training [33/62] Loss: 0.21393 
Epoch [214/300] Training [34/62] Loss: 0.08971 
Epoch [214/300] Training [35/62] Loss: 0.04190 
Epoch [214/300] Training [36/62] Loss: 0.06699 
Epoch [214/300] Training [37/62] Loss: 0.07752 
Epoch [214/300] Training [38/62] Loss: 0.05178 
Epoch [214/300] Training [39/62] Loss: 0.03934 
Epoch [214/300] Training [40/62] Loss: 0.03667 
Epoch [214/300] Training [41/62] Loss: 0.05441 
Epoch [214/300] Training [42/62] Loss: 0.05780 
Epoch [214/300] Training [43/62] Loss: 0.03651 
Epoch [214/300] Training [44/62] Loss: 0.04627 
Epoch [214/300] Training [45/62] Loss: 0.04189 
Epoch [214/300] Training [46/62] Loss: 0.04088 
Epoch [214/300] Training [47/62] Loss: 0.06087 
Epoch [214/300] Training [48/62] Loss: 0.06933 
Epoch [214/300] Training [49/62] Loss: 0.05335 
Epoch [214/300] Training [50/62] Loss: 0.07985 
Epoch [214/300] Training [51/62] Loss: 0.11712 
Epoch [214/300] Training [52/62] Loss: 0.03452 
Epoch [214/300] Training [53/62] Loss: 0.04412 
Epoch [214/300] Training [54/62] Loss: 0.05727 
Epoch [214/300] Training [55/62] Loss: 0.03694 
Epoch [214/300] Training [56/62] Loss: 0.06089 
Epoch [214/300] Training [57/62] Loss: 0.05333 
Epoch [214/300] Training [58/62] Loss: 0.04873 
Epoch [214/300] Training [59/62] Loss: 0.06191 
Epoch [214/300] Training [60/62] Loss: 0.04197 
Epoch [214/300] Training [61/62] Loss: 0.02972 
Epoch [214/300] Training [62/62] Loss: 0.07217 
Epoch [214/300] Training metric {'Train/mean dice_metric': 0.96075439453125, 'Train/mean miou_metric': 0.9278087019920349, 'Train/mean f1': 0.9638888239860535, 'Train/mean precision': 0.958753764629364, 'Train/mean recall': 0.9690790772438049, 'Train/mean hd95_metric': 6.414847373962402}
Epoch [214/300] Validation [1/16] Loss: 0.15155  focal_loss 0.06524  dice_loss 0.08630 
Epoch [214/300] Validation [2/16] Loss: 0.40705  focal_loss 0.17635  dice_loss 0.23070 
Epoch [214/300] Validation [3/16] Loss: 0.55415  focal_loss 0.28266  dice_loss 0.27149 
Epoch [214/300] Validation [4/16] Loss: 0.37901  focal_loss 0.16773  dice_loss 0.21127 
Epoch [214/300] Validation [5/16] Loss: 0.30893  focal_loss 0.06702  dice_loss 0.24191 
Epoch [214/300] Validation [6/16] Loss: 0.19805  focal_loss 0.04903  dice_loss 0.14903 
Epoch [214/300] Validation [7/16] Loss: 0.27185  focal_loss 0.12648  dice_loss 0.14538 
Epoch [214/300] Validation [8/16] Loss: 0.30270  focal_loss 0.08127  dice_loss 0.22143 
Epoch [214/300] Validation [9/16] Loss: 0.26157  focal_loss 0.10038  dice_loss 0.16120 
Epoch [214/300] Validation [10/16] Loss: 0.36539  focal_loss 0.14138  dice_loss 0.22401 
Epoch [214/300] Validation [11/16] Loss: 0.15481  focal_loss 0.05319  dice_loss 0.10163 
Epoch [214/300] Validation [12/16] Loss: 0.29977  focal_loss 0.06572  dice_loss 0.23405 
Epoch [214/300] Validation [13/16] Loss: 0.22220  focal_loss 0.07300  dice_loss 0.14920 
Epoch [214/300] Validation [14/16] Loss: 0.39096  focal_loss 0.13223  dice_loss 0.25873 
Epoch [214/300] Validation [15/16] Loss: 0.09436  focal_loss 0.02708  dice_loss 0.06729 
Epoch [214/300] Validation [16/16] Loss: 0.06016  focal_loss 0.01938  dice_loss 0.04078 
Epoch [214/300] Validation metric {'Val/mean dice_metric': 0.9337804317474365, 'Val/mean miou_metric': 0.8916820287704468, 'Val/mean f1': 0.9400228261947632, 'Val/mean precision': 0.9358876347541809, 'Val/mean recall': 0.9441948533058167, 'Val/mean hd95_metric': 12.644680976867676}
Cheakpoint...
Epoch [214/300] best acc:tensor([0.9349], device='cuda:0'), Now : mean acc: tensor([0.9338], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9337804317474365, 'Val/mean miou_metric': 0.8916820287704468, 'Val/mean f1': 0.9400228261947632, 'Val/mean precision': 0.9358876347541809, 'Val/mean recall': 0.9441948533058167, 'Val/mean hd95_metric': 12.644680976867676}
Epoch [215/300] Training [1/62] Loss: 0.04820 
Epoch [215/300] Training [2/62] Loss: 0.05985 
Epoch [215/300] Training [3/62] Loss: 0.04313 
Epoch [215/300] Training [4/62] Loss: 0.04754 
Epoch [215/300] Training [5/62] Loss: 0.08420 
Epoch [215/300] Training [6/62] Loss: 0.03349 
Epoch [215/300] Training [7/62] Loss: 0.04739 
Epoch [215/300] Training [8/62] Loss: 0.05050 
Epoch [215/300] Training [9/62] Loss: 0.03828 
Epoch [215/300] Training [10/62] Loss: 0.06025 
Epoch [215/300] Training [11/62] Loss: 0.06644 
Epoch [215/300] Training [12/62] Loss: 0.03984 
Epoch [215/300] Training [13/62] Loss: 0.04718 
Epoch [215/300] Training [14/62] Loss: 0.03732 
Epoch [215/300] Training [15/62] Loss: 0.08050 
Epoch [215/300] Training [16/62] Loss: 0.04745 
Epoch [215/300] Training [17/62] Loss: 0.09344 
Epoch [215/300] Training [18/62] Loss: 0.03758 
Epoch [215/300] Training [19/62] Loss: 0.05332 
Epoch [215/300] Training [20/62] Loss: 0.06588 
Epoch [215/300] Training [21/62] Loss: 0.04431 
Epoch [215/300] Training [22/62] Loss: 0.18347 
Epoch [215/300] Training [23/62] Loss: 0.04483 
Epoch [215/300] Training [24/62] Loss: 0.04122 
Epoch [215/300] Training [25/62] Loss: 0.04778 
Epoch [215/300] Training [26/62] Loss: 0.04380 
Epoch [215/300] Training [27/62] Loss: 0.04704 
Epoch [215/300] Training [28/62] Loss: 0.05114 
Epoch [215/300] Training [29/62] Loss: 0.06256 
Epoch [215/300] Training [30/62] Loss: 0.05388 
Epoch [215/300] Training [31/62] Loss: 0.03930 
Epoch [215/300] Training [32/62] Loss: 0.04297 
Epoch [215/300] Training [33/62] Loss: 0.05073 
Epoch [215/300] Training [34/62] Loss: 0.09494 
Epoch [215/300] Training [35/62] Loss: 0.07436 
Epoch [215/300] Training [36/62] Loss: 0.09603 
Epoch [215/300] Training [37/62] Loss: 0.04397 
Epoch [215/300] Training [38/62] Loss: 0.03038 
Epoch [215/300] Training [39/62] Loss: 0.03813 
Epoch [215/300] Training [40/62] Loss: 0.04708 
Epoch [215/300] Training [41/62] Loss: 0.05018 
Epoch [215/300] Training [42/62] Loss: 0.07466 
Epoch [215/300] Training [43/62] Loss: 0.06700 
Epoch [215/300] Training [44/62] Loss: 0.04293 
Epoch [215/300] Training [45/62] Loss: 0.04161 
Epoch [215/300] Training [46/62] Loss: 0.04821 
Epoch [215/300] Training [47/62] Loss: 0.04800 
Epoch [215/300] Training [48/62] Loss: 0.07318 
Epoch [215/300] Training [49/62] Loss: 0.04105 
Epoch [215/300] Training [50/62] Loss: 0.04846 
Epoch [215/300] Training [51/62] Loss: 0.05495 
Epoch [215/300] Training [52/62] Loss: 0.05240 
Epoch [215/300] Training [53/62] Loss: 0.04184 
Epoch [215/300] Training [54/62] Loss: 0.06075 
Epoch [215/300] Training [55/62] Loss: 0.04325 
Epoch [215/300] Training [56/62] Loss: 0.03563 
Epoch [215/300] Training [57/62] Loss: 0.07062 
Epoch [215/300] Training [58/62] Loss: 0.04693 
Epoch [215/300] Training [59/62] Loss: 0.04231 
Epoch [215/300] Training [60/62] Loss: 0.05186 
Epoch [215/300] Training [61/62] Loss: 0.18184 
Epoch [215/300] Training [62/62] Loss: 0.05150 
Epoch [215/300] Training metric {'Train/mean dice_metric': 0.9595854878425598, 'Train/mean miou_metric': 0.9269480109214783, 'Train/mean f1': 0.9648398756980896, 'Train/mean precision': 0.9592542052268982, 'Train/mean recall': 0.9704909920692444, 'Train/mean hd95_metric': 6.880022048950195}
Epoch [215/300] Validation [1/16] Loss: 0.18109  focal_loss 0.08065  dice_loss 0.10045 
Epoch [215/300] Validation [2/16] Loss: 0.48404  focal_loss 0.22716  dice_loss 0.25688 
Epoch [215/300] Validation [3/16] Loss: 0.26946  focal_loss 0.07968  dice_loss 0.18978 
Epoch [215/300] Validation [4/16] Loss: 0.44106  focal_loss 0.21908  dice_loss 0.22198 
Epoch [215/300] Validation [5/16] Loss: 0.36758  focal_loss 0.11601  dice_loss 0.25156 
Epoch [215/300] Validation [6/16] Loss: 0.19552  focal_loss 0.03883  dice_loss 0.15669 
Epoch [215/300] Validation [7/16] Loss: 0.22439  focal_loss 0.09794  dice_loss 0.12645 
Epoch [215/300] Validation [8/16] Loss: 0.36588  focal_loss 0.12899  dice_loss 0.23688 
Epoch [215/300] Validation [9/16] Loss: 0.18338  focal_loss 0.09157  dice_loss 0.09181 
Epoch [215/300] Validation [10/16] Loss: 0.43027  focal_loss 0.19488  dice_loss 0.23540 
Epoch [215/300] Validation [11/16] Loss: 0.17260  focal_loss 0.07296  dice_loss 0.09965 
Epoch [215/300] Validation [12/16] Loss: 0.29878  focal_loss 0.07669  dice_loss 0.22209 
Epoch [215/300] Validation [13/16] Loss: 0.23953  focal_loss 0.09118  dice_loss 0.14835 
Epoch [215/300] Validation [14/16] Loss: 0.44998  focal_loss 0.16784  dice_loss 0.28215 
Epoch [215/300] Validation [15/16] Loss: 0.18566  focal_loss 0.05929  dice_loss 0.12637 
Epoch [215/300] Validation [16/16] Loss: 0.12771  focal_loss 0.06591  dice_loss 0.06180 
Epoch [215/300] Validation metric {'Val/mean dice_metric': 0.932431697845459, 'Val/mean miou_metric': 0.8903751969337463, 'Val/mean f1': 0.9404842853546143, 'Val/mean precision': 0.9355781674385071, 'Val/mean recall': 0.9454423189163208, 'Val/mean hd95_metric': 12.907882690429688}
Cheakpoint...
Epoch [215/300] best acc:tensor([0.9349], device='cuda:0'), Now : mean acc: tensor([0.9324], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.932431697845459, 'Val/mean miou_metric': 0.8903751969337463, 'Val/mean f1': 0.9404842853546143, 'Val/mean precision': 0.9355781674385071, 'Val/mean recall': 0.9454423189163208, 'Val/mean hd95_metric': 12.907882690429688}
Epoch [216/300] Training [1/62] Loss: 0.06134 
Epoch [216/300] Training [2/62] Loss: 0.03758 
Epoch [216/300] Training [3/62] Loss: 0.04975 
Epoch [216/300] Training [4/62] Loss: 0.04052 
Epoch [216/300] Training [5/62] Loss: 0.08618 
Epoch [216/300] Training [6/62] Loss: 0.05070 
Epoch [216/300] Training [7/62] Loss: 0.03312 
Epoch [216/300] Training [8/62] Loss: 0.03605 
Epoch [216/300] Training [9/62] Loss: 0.04808 
Epoch [216/300] Training [10/62] Loss: 0.03861 
Epoch [216/300] Training [11/62] Loss: 0.04102 
Epoch [216/300] Training [12/62] Loss: 0.05752 
Epoch [216/300] Training [13/62] Loss: 0.04707 
Epoch [216/300] Training [14/62] Loss: 0.05295 
Epoch [216/300] Training [15/62] Loss: 0.05610 
Epoch [216/300] Training [16/62] Loss: 0.06873 
Epoch [216/300] Training [17/62] Loss: 0.06175 
Epoch [216/300] Training [18/62] Loss: 0.04406 
Epoch [216/300] Training [19/62] Loss: 0.04302 
Epoch [216/300] Training [20/62] Loss: 0.04110 
Epoch [216/300] Training [21/62] Loss: 0.04472 
Epoch [216/300] Training [22/62] Loss: 0.04522 
Epoch [216/300] Training [23/62] Loss: 0.04494 
Epoch [216/300] Training [24/62] Loss: 0.06147 
Epoch [216/300] Training [25/62] Loss: 0.07683 
Epoch [216/300] Training [26/62] Loss: 0.06098 
Epoch [216/300] Training [27/62] Loss: 0.05125 
Epoch [216/300] Training [28/62] Loss: 0.04822 
Epoch [216/300] Training [29/62] Loss: 0.05603 
Epoch [216/300] Training [30/62] Loss: 0.06049 
Epoch [216/300] Training [31/62] Loss: 0.04532 
Epoch [216/300] Training [32/62] Loss: 0.04557 
Epoch [216/300] Training [33/62] Loss: 0.03576 
Epoch [216/300] Training [34/62] Loss: 0.04542 
Epoch [216/300] Training [35/62] Loss: 0.04099 
Epoch [216/300] Training [36/62] Loss: 0.04248 
Epoch [216/300] Training [37/62] Loss: 0.04667 
Epoch [216/300] Training [38/62] Loss: 0.05592 
Epoch [216/300] Training [39/62] Loss: 0.04124 
Epoch [216/300] Training [40/62] Loss: 0.04762 
Epoch [216/300] Training [41/62] Loss: 0.06596 
Epoch [216/300] Training [42/62] Loss: 0.06378 
Epoch [216/300] Training [43/62] Loss: 0.03886 
Epoch [216/300] Training [44/62] Loss: 0.06137 
Epoch [216/300] Training [45/62] Loss: 0.04442 
Epoch [216/300] Training [46/62] Loss: 0.07075 
Epoch [216/300] Training [47/62] Loss: 0.07181 
Epoch [216/300] Training [48/62] Loss: 0.10324 
Epoch [216/300] Training [49/62] Loss: 0.04588 
Epoch [216/300] Training [50/62] Loss: 0.04278 
Epoch [216/300] Training [51/62] Loss: 0.04885 
Epoch [216/300] Training [52/62] Loss: 0.03643 
Epoch [216/300] Training [53/62] Loss: 0.04523 
Epoch [216/300] Training [54/62] Loss: 0.05536 
Epoch [216/300] Training [55/62] Loss: 0.07613 
Epoch [216/300] Training [56/62] Loss: 0.07732 
Epoch [216/300] Training [57/62] Loss: 0.07102 
Epoch [216/300] Training [58/62] Loss: 0.04836 
Epoch [216/300] Training [59/62] Loss: 0.04722 
Epoch [216/300] Training [60/62] Loss: 0.12384 
Epoch [216/300] Training [61/62] Loss: 0.05579 
Epoch [216/300] Training [62/62] Loss: 0.04215 
Epoch [216/300] Training metric {'Train/mean dice_metric': 0.9627005457878113, 'Train/mean miou_metric': 0.9301373958587646, 'Train/mean f1': 0.9648330211639404, 'Train/mean precision': 0.9604050517082214, 'Train/mean recall': 0.9693019986152649, 'Train/mean hd95_metric': 6.608168601989746}
Epoch [216/300] Validation [1/16] Loss: 0.15400  focal_loss 0.06599  dice_loss 0.08802 
Epoch [216/300] Validation [2/16] Loss: 0.41227  focal_loss 0.17665  dice_loss 0.23562 
Epoch [216/300] Validation [3/16] Loss: 0.32095  focal_loss 0.10591  dice_loss 0.21504 
Epoch [216/300] Validation [4/16] Loss: 0.46115  focal_loss 0.22930  dice_loss 0.23186 
Epoch [216/300] Validation [5/16] Loss: 0.32180  focal_loss 0.08804  dice_loss 0.23376 
Epoch [216/300] Validation [6/16] Loss: 0.25749  focal_loss 0.07899  dice_loss 0.17851 
Epoch [216/300] Validation [7/16] Loss: 0.11862  focal_loss 0.03010  dice_loss 0.08852 
Epoch [216/300] Validation [8/16] Loss: 0.46682  focal_loss 0.16011  dice_loss 0.30671 
Epoch [216/300] Validation [9/16] Loss: 0.14251  focal_loss 0.05831  dice_loss 0.08419 
Epoch [216/300] Validation [10/16] Loss: 0.24570  focal_loss 0.08714  dice_loss 0.15856 
Epoch [216/300] Validation [11/16] Loss: 0.09447  focal_loss 0.02464  dice_loss 0.06983 
Epoch [216/300] Validation [12/16] Loss: 0.30789  focal_loss 0.09516  dice_loss 0.21273 
Epoch [216/300] Validation [13/16] Loss: 0.20466  focal_loss 0.06003  dice_loss 0.14463 
Epoch [216/300] Validation [14/16] Loss: 0.51412  focal_loss 0.18323  dice_loss 0.33089 
Epoch [216/300] Validation [15/16] Loss: 0.08690  focal_loss 0.02430  dice_loss 0.06259 
Epoch [216/300] Validation [16/16] Loss: 0.04677  focal_loss 0.01153  dice_loss 0.03523 
Epoch [216/300] Validation metric {'Val/mean dice_metric': 0.936546802520752, 'Val/mean miou_metric': 0.8957371711730957, 'Val/mean f1': 0.9423208236694336, 'Val/mean precision': 0.9388015866279602, 'Val/mean recall': 0.9458664655685425, 'Val/mean hd95_metric': 12.885388374328613}
Cheakpoint...
Epoch [216/300] best acc:tensor([0.9365], device='cuda:0'), Now : mean acc: tensor([0.9365], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.936546802520752, 'Val/mean miou_metric': 0.8957371711730957, 'Val/mean f1': 0.9423208236694336, 'Val/mean precision': 0.9388015866279602, 'Val/mean recall': 0.9458664655685425, 'Val/mean hd95_metric': 12.885388374328613}
Epoch [217/300] Training [1/62] Loss: 0.03958 
Epoch [217/300] Training [2/62] Loss: 0.08528 
Epoch [217/300] Training [3/62] Loss: 0.04403 
Epoch [217/300] Training [4/62] Loss: 0.04708 
Epoch [217/300] Training [5/62] Loss: 0.05502 
Epoch [217/300] Training [6/62] Loss: 0.07051 
Epoch [217/300] Training [7/62] Loss: 0.08307 
Epoch [217/300] Training [8/62] Loss: 0.07774 
Epoch [217/300] Training [9/62] Loss: 0.03510 
Epoch [217/300] Training [10/62] Loss: 0.03800 
Epoch [217/300] Training [11/62] Loss: 0.07251 
Epoch [217/300] Training [12/62] Loss: 0.05113 
Epoch [217/300] Training [13/62] Loss: 0.03374 
Epoch [217/300] Training [14/62] Loss: 0.05618 
Epoch [217/300] Training [15/62] Loss: 0.03940 
Epoch [217/300] Training [16/62] Loss: 0.03578 
Epoch [217/300] Training [17/62] Loss: 0.05326 
Epoch [217/300] Training [18/62] Loss: 0.05139 
Epoch [217/300] Training [19/62] Loss: 0.03455 
Epoch [217/300] Training [20/62] Loss: 0.05042 
Epoch [217/300] Training [21/62] Loss: 0.06271 
Epoch [217/300] Training [22/62] Loss: 0.04550 
Epoch [217/300] Training [23/62] Loss: 0.03394 
Epoch [217/300] Training [24/62] Loss: 0.03739 
Epoch [217/300] Training [25/62] Loss: 0.07391 
Epoch [217/300] Training [26/62] Loss: 0.04554 
Epoch [217/300] Training [27/62] Loss: 0.04065 
Epoch [217/300] Training [28/62] Loss: 0.04096 
Epoch [217/300] Training [29/62] Loss: 0.05891 
Epoch [217/300] Training [30/62] Loss: 0.05380 
Epoch [217/300] Training [31/62] Loss: 0.07010 
Epoch [217/300] Training [32/62] Loss: 0.04121 
Epoch [217/300] Training [33/62] Loss: 0.07341 
Epoch [217/300] Training [34/62] Loss: 0.05840 
Epoch [217/300] Training [35/62] Loss: 0.04784 
Epoch [217/300] Training [36/62] Loss: 0.03541 
Epoch [217/300] Training [37/62] Loss: 0.04685 
Epoch [217/300] Training [38/62] Loss: 0.09919 
Epoch [217/300] Training [39/62] Loss: 0.04850 
Epoch [217/300] Training [40/62] Loss: 0.04742 
Epoch [217/300] Training [41/62] Loss: 0.03322 
Epoch [217/300] Training [42/62] Loss: 0.05011 
Epoch [217/300] Training [43/62] Loss: 0.03634 
Epoch [217/300] Training [44/62] Loss: 0.04208 
Epoch [217/300] Training [45/62] Loss: 0.04222 
Epoch [217/300] Training [46/62] Loss: 0.03741 
Epoch [217/300] Training [47/62] Loss: 0.06181 
Epoch [217/300] Training [48/62] Loss: 0.04265 
Epoch [217/300] Training [49/62] Loss: 0.04907 
Epoch [217/300] Training [50/62] Loss: 0.08903 
Epoch [217/300] Training [51/62] Loss: 0.05301 
Epoch [217/300] Training [52/62] Loss: 0.04134 
Epoch [217/300] Training [53/62] Loss: 0.04596 
Epoch [217/300] Training [54/62] Loss: 0.03800 
Epoch [217/300] Training [55/62] Loss: 0.03850 
Epoch [217/300] Training [56/62] Loss: 0.06261 
Epoch [217/300] Training [57/62] Loss: 0.06892 
Epoch [217/300] Training [58/62] Loss: 0.03768 
Epoch [217/300] Training [59/62] Loss: 0.05550 
Epoch [217/300] Training [60/62] Loss: 0.03431 
Epoch [217/300] Training [61/62] Loss: 0.06211 
Epoch [217/300] Training [62/62] Loss: 0.08018 
Epoch [217/300] Training metric {'Train/mean dice_metric': 0.9641969799995422, 'Train/mean miou_metric': 0.9324287176132202, 'Train/mean f1': 0.9666042923927307, 'Train/mean precision': 0.9619742035865784, 'Train/mean recall': 0.9712791442871094, 'Train/mean hd95_metric': 5.553069114685059}
Epoch [217/300] Validation [1/16] Loss: 0.18394  focal_loss 0.07690  dice_loss 0.10704 
Epoch [217/300] Validation [2/16] Loss: 0.30464  focal_loss 0.16917  dice_loss 0.13547 
Epoch [217/300] Validation [3/16] Loss: 0.56518  focal_loss 0.32358  dice_loss 0.24161 
Epoch [217/300] Validation [4/16] Loss: 0.36207  focal_loss 0.17748  dice_loss 0.18458 
Epoch [217/300] Validation [5/16] Loss: 0.38275  focal_loss 0.13117  dice_loss 0.25157 
Epoch [217/300] Validation [6/16] Loss: 0.21138  focal_loss 0.04149  dice_loss 0.16989 
Epoch [217/300] Validation [7/16] Loss: 0.25027  focal_loss 0.12033  dice_loss 0.12994 
Epoch [217/300] Validation [8/16] Loss: 0.38705  focal_loss 0.14755  dice_loss 0.23950 
Epoch [217/300] Validation [9/16] Loss: 0.15138  focal_loss 0.06783  dice_loss 0.08355 
Epoch [217/300] Validation [10/16] Loss: 0.32447  focal_loss 0.11103  dice_loss 0.21344 
Epoch [217/300] Validation [11/16] Loss: 0.12949  focal_loss 0.03711  dice_loss 0.09238 
Epoch [217/300] Validation [12/16] Loss: 0.31048  focal_loss 0.07059  dice_loss 0.23989 
Epoch [217/300] Validation [13/16] Loss: 0.28635  focal_loss 0.09753  dice_loss 0.18882 
Epoch [217/300] Validation [14/16] Loss: 0.47522  focal_loss 0.17093  dice_loss 0.30429 
Epoch [217/300] Validation [15/16] Loss: 0.12078  focal_loss 0.03457  dice_loss 0.08622 
Epoch [217/300] Validation [16/16] Loss: 0.06655  focal_loss 0.02458  dice_loss 0.04197 
Epoch [217/300] Validation metric {'Val/mean dice_metric': 0.9370917081832886, 'Val/mean miou_metric': 0.8971750140190125, 'Val/mean f1': 0.9434972405433655, 'Val/mean precision': 0.9462910890579224, 'Val/mean recall': 0.9407199025154114, 'Val/mean hd95_metric': 11.681255340576172}
Cheakpoint...
Epoch [217/300] best acc:tensor([0.9371], device='cuda:0'), Now : mean acc: tensor([0.9371], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9370917081832886, 'Val/mean miou_metric': 0.8971750140190125, 'Val/mean f1': 0.9434972405433655, 'Val/mean precision': 0.9462910890579224, 'Val/mean recall': 0.9407199025154114, 'Val/mean hd95_metric': 11.681255340576172}
Epoch [218/300] Training [1/62] Loss: 0.05160 
Epoch [218/300] Training [2/62] Loss: 0.03230 
Epoch [218/300] Training [3/62] Loss: 0.05293 
Epoch [218/300] Training [4/62] Loss: 0.12321 
Epoch [218/300] Training [5/62] Loss: 0.05205 
Epoch [218/300] Training [6/62] Loss: 0.05064 
Epoch [218/300] Training [7/62] Loss: 0.19362 
Epoch [218/300] Training [8/62] Loss: 0.04667 
Epoch [218/300] Training [9/62] Loss: 0.06354 
Epoch [218/300] Training [10/62] Loss: 0.03453 
Epoch [218/300] Training [11/62] Loss: 0.06252 
Epoch [218/300] Training [12/62] Loss: 0.04039 
Epoch [218/300] Training [13/62] Loss: 0.03594 
Epoch [218/300] Training [14/62] Loss: 0.05017 
Epoch [218/300] Training [15/62] Loss: 0.04527 
Epoch [218/300] Training [16/62] Loss: 0.05379 
Epoch [218/300] Training [17/62] Loss: 0.07136 
Epoch [218/300] Training [18/62] Loss: 0.04896 
Epoch [218/300] Training [19/62] Loss: 0.04193 
Epoch [218/300] Training [20/62] Loss: 0.03920 
Epoch [218/300] Training [21/62] Loss: 0.04319 
Epoch [218/300] Training [22/62] Loss: 0.05063 
Epoch [218/300] Training [23/62] Loss: 0.07198 
Epoch [218/300] Training [24/62] Loss: 0.03841 
Epoch [218/300] Training [25/62] Loss: 0.03733 
Epoch [218/300] Training [26/62] Loss: 0.04518 
Epoch [218/300] Training [27/62] Loss: 0.08076 
Epoch [218/300] Training [28/62] Loss: 0.05061 
Epoch [218/300] Training [29/62] Loss: 0.04741 
Epoch [218/300] Training [30/62] Loss: 0.07685 
Epoch [218/300] Training [31/62] Loss: 0.04275 
Epoch [218/300] Training [32/62] Loss: 0.04838 
Epoch [218/300] Training [33/62] Loss: 0.11236 
Epoch [218/300] Training [34/62] Loss: 0.04950 
Epoch [218/300] Training [35/62] Loss: 0.07221 
Epoch [218/300] Training [36/62] Loss: 0.08808 
Epoch [218/300] Training [37/62] Loss: 0.12848 
Epoch [218/300] Training [38/62] Loss: 0.05198 
Epoch [218/300] Training [39/62] Loss: 0.07465 
Epoch [218/300] Training [40/62] Loss: 0.07391 
Epoch [218/300] Training [41/62] Loss: 0.04938 
Epoch [218/300] Training [42/62] Loss: 0.04958 
Epoch [218/300] Training [43/62] Loss: 0.05851 
Epoch [218/300] Training [44/62] Loss: 0.09493 
Epoch [218/300] Training [45/62] Loss: 0.06258 
Epoch [218/300] Training [46/62] Loss: 0.04260 
Epoch [218/300] Training [47/62] Loss: 0.07761 
Epoch [218/300] Training [48/62] Loss: 0.06586 
Epoch [218/300] Training [49/62] Loss: 0.04175 
Epoch [218/300] Training [50/62] Loss: 0.04225 
Epoch [218/300] Training [51/62] Loss: 0.06575 
Epoch [218/300] Training [52/62] Loss: 0.04844 
Epoch [218/300] Training [53/62] Loss: 0.07571 
Epoch [218/300] Training [54/62] Loss: 0.04835 
Epoch [218/300] Training [55/62] Loss: 0.10814 
Epoch [218/300] Training [56/62] Loss: 0.04546 
Epoch [218/300] Training [57/62] Loss: 0.04468 
Epoch [218/300] Training [58/62] Loss: 0.04382 
Epoch [218/300] Training [59/62] Loss: 0.05025 
Epoch [218/300] Training [60/62] Loss: 0.06751 
Epoch [218/300] Training [61/62] Loss: 0.07754 
Epoch [218/300] Training [62/62] Loss: 0.09475 
Epoch [218/300] Training metric {'Train/mean dice_metric': 0.9567208290100098, 'Train/mean miou_metric': 0.9225590825080872, 'Train/mean f1': 0.9636285901069641, 'Train/mean precision': 0.9597805142402649, 'Train/mean recall': 0.9675077199935913, 'Train/mean hd95_metric': 7.038265705108643}
Epoch [218/300] Validation [1/16] Loss: 0.27830  focal_loss 0.13666  dice_loss 0.14164 
Epoch [218/300] Validation [2/16] Loss: 0.36091  focal_loss 0.12649  dice_loss 0.23442 
Epoch [218/300] Validation [3/16] Loss: 0.19721  focal_loss 0.04183  dice_loss 0.15537 
Epoch [218/300] Validation [4/16] Loss: 0.28253  focal_loss 0.12469  dice_loss 0.15785 
Epoch [218/300] Validation [5/16] Loss: 0.38921  focal_loss 0.15159  dice_loss 0.23762 
Epoch [218/300] Validation [6/16] Loss: 0.21850  focal_loss 0.05174  dice_loss 0.16675 
Epoch [218/300] Validation [7/16] Loss: 0.30163  focal_loss 0.14908  dice_loss 0.15255 
Epoch [218/300] Validation [8/16] Loss: 0.32152  focal_loss 0.08832  dice_loss 0.23320 
Epoch [218/300] Validation [9/16] Loss: 0.16659  focal_loss 0.07416  dice_loss 0.09243 
Epoch [218/300] Validation [10/16] Loss: 0.24478  focal_loss 0.08216  dice_loss 0.16262 
Epoch [218/300] Validation [11/16] Loss: 0.16350  focal_loss 0.05600  dice_loss 0.10750 
Epoch [218/300] Validation [12/16] Loss: 0.32406  focal_loss 0.08334  dice_loss 0.24072 
Epoch [218/300] Validation [13/16] Loss: 0.21634  focal_loss 0.07395  dice_loss 0.14239 
Epoch [218/300] Validation [14/16] Loss: 0.46786  focal_loss 0.14966  dice_loss 0.31820 
Epoch [218/300] Validation [15/16] Loss: 0.08538  focal_loss 0.02260  dice_loss 0.06278 
Epoch [218/300] Validation [16/16] Loss: 0.04113  focal_loss 0.00852  dice_loss 0.03261 
Epoch [218/300] Validation metric {'Val/mean dice_metric': 0.9322786927223206, 'Val/mean miou_metric': 0.8898470997810364, 'Val/mean f1': 0.9415891170501709, 'Val/mean precision': 0.9356975555419922, 'Val/mean recall': 0.9475552439689636, 'Val/mean hd95_metric': 12.753813743591309}
Cheakpoint...
Epoch [218/300] best acc:tensor([0.9371], device='cuda:0'), Now : mean acc: tensor([0.9323], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9322786927223206, 'Val/mean miou_metric': 0.8898470997810364, 'Val/mean f1': 0.9415891170501709, 'Val/mean precision': 0.9356975555419922, 'Val/mean recall': 0.9475552439689636, 'Val/mean hd95_metric': 12.753813743591309}
Epoch [219/300] Training [1/62] Loss: 0.03305 
Epoch [219/300] Training [2/62] Loss: 0.05598 
Epoch [219/300] Training [3/62] Loss: 0.03768 
Epoch [219/300] Training [4/62] Loss: 0.04101 
Epoch [219/300] Training [5/62] Loss: 0.04564 
Epoch [219/300] Training [6/62] Loss: 0.04536 
Epoch [219/300] Training [7/62] Loss: 0.06634 
Epoch [219/300] Training [8/62] Loss: 0.03986 
Epoch [219/300] Training [9/62] Loss: 0.04350 
Epoch [219/300] Training [10/62] Loss: 0.05919 
Epoch [219/300] Training [11/62] Loss: 0.05252 
Epoch [219/300] Training [12/62] Loss: 0.03654 
Epoch [219/300] Training [13/62] Loss: 0.03481 
Epoch [219/300] Training [14/62] Loss: 0.09739 
Epoch [219/300] Training [15/62] Loss: 0.04562 
Epoch [219/300] Training [16/62] Loss: 0.03386 
Epoch [219/300] Training [17/62] Loss: 0.04834 
Epoch [219/300] Training [18/62] Loss: 0.04787 
Epoch [219/300] Training [19/62] Loss: 0.05860 
Epoch [219/300] Training [20/62] Loss: 0.03741 
Epoch [219/300] Training [21/62] Loss: 0.05172 
Epoch [219/300] Training [22/62] Loss: 0.03433 
Epoch [219/300] Training [23/62] Loss: 0.03736 
Epoch [219/300] Training [24/62] Loss: 0.05583 
Epoch [219/300] Training [25/62] Loss: 0.03716 
Epoch [219/300] Training [26/62] Loss: 0.04374 
Epoch [219/300] Training [27/62] Loss: 0.03548 
Epoch [219/300] Training [28/62] Loss: 0.06534 
Epoch [219/300] Training [29/62] Loss: 0.04425 
Epoch [219/300] Training [30/62] Loss: 0.03601 
Epoch [219/300] Training [31/62] Loss: 0.04922 
Epoch [219/300] Training [32/62] Loss: 0.07119 
Epoch [219/300] Training [33/62] Loss: 0.05554 
Epoch [219/300] Training [34/62] Loss: 0.03404 
Epoch [219/300] Training [35/62] Loss: 0.04615 
Epoch [219/300] Training [36/62] Loss: 0.04196 
Epoch [219/300] Training [37/62] Loss: 0.04487 
Epoch [219/300] Training [38/62] Loss: 0.04072 
Epoch [219/300] Training [39/62] Loss: 0.05081 
Epoch [219/300] Training [40/62] Loss: 0.03067 
Epoch [219/300] Training [41/62] Loss: 0.03213 
Epoch [219/300] Training [42/62] Loss: 0.03873 
Epoch [219/300] Training [43/62] Loss: 0.07145 
Epoch [219/300] Training [44/62] Loss: 0.08991 
Epoch [219/300] Training [45/62] Loss: 0.03887 
Epoch [219/300] Training [46/62] Loss: 0.07570 
Epoch [219/300] Training [47/62] Loss: 0.03134 
Epoch [219/300] Training [48/62] Loss: 0.05524 
Epoch [219/300] Training [49/62] Loss: 0.03301 
Epoch [219/300] Training [50/62] Loss: 0.08519 
Epoch [219/300] Training [51/62] Loss: 0.03726 
Epoch [219/300] Training [52/62] Loss: 0.08461 
Epoch [219/300] Training [53/62] Loss: 0.03190 
Epoch [219/300] Training [54/62] Loss: 0.03985 
Epoch [219/300] Training [55/62] Loss: 0.03679 
Epoch [219/300] Training [56/62] Loss: 0.03780 
Epoch [219/300] Training [57/62] Loss: 0.03608 
Epoch [219/300] Training [58/62] Loss: 0.04241 
Epoch [219/300] Training [59/62] Loss: 0.05596 
Epoch [219/300] Training [60/62] Loss: 0.02740 
Epoch [219/300] Training [61/62] Loss: 0.04808 
Epoch [219/300] Training [62/62] Loss: 0.03814 
Epoch [219/300] Training metric {'Train/mean dice_metric': 0.9670742154121399, 'Train/mean miou_metric': 0.9375284314155579, 'Train/mean f1': 0.9687702655792236, 'Train/mean precision': 0.9638543128967285, 'Train/mean recall': 0.9737366437911987, 'Train/mean hd95_metric': 5.099979877471924}
Epoch [219/300] Validation [1/16] Loss: 0.41086  focal_loss 0.23816  dice_loss 0.17269 
Epoch [219/300] Validation [2/16] Loss: 0.47928  focal_loss 0.23761  dice_loss 0.24168 
Epoch [219/300] Validation [3/16] Loss: 0.47154  focal_loss 0.21498  dice_loss 0.25656 
Epoch [219/300] Validation [4/16] Loss: 0.30327  focal_loss 0.14715  dice_loss 0.15612 
Epoch [219/300] Validation [5/16] Loss: 0.27097  focal_loss 0.08221  dice_loss 0.18876 
Epoch [219/300] Validation [6/16] Loss: 0.18591  focal_loss 0.04241  dice_loss 0.14350 
Epoch [219/300] Validation [7/16] Loss: 0.19333  focal_loss 0.07226  dice_loss 0.12107 
Epoch [219/300] Validation [8/16] Loss: 0.30946  focal_loss 0.09043  dice_loss 0.21903 
Epoch [219/300] Validation [9/16] Loss: 0.19482  focal_loss 0.08138  dice_loss 0.11344 
Epoch [219/300] Validation [10/16] Loss: 0.21460  focal_loss 0.06259  dice_loss 0.15201 
Epoch [219/300] Validation [11/16] Loss: 0.10565  focal_loss 0.03064  dice_loss 0.07501 
Epoch [219/300] Validation [12/16] Loss: 0.30496  focal_loss 0.09216  dice_loss 0.21281 
Epoch [219/300] Validation [13/16] Loss: 0.22435  focal_loss 0.07431  dice_loss 0.15005 
Epoch [219/300] Validation [14/16] Loss: 0.44160  focal_loss 0.15246  dice_loss 0.28914 
Epoch [219/300] Validation [15/16] Loss: 0.08316  focal_loss 0.02300  dice_loss 0.06016 
Epoch [219/300] Validation [16/16] Loss: 0.04153  focal_loss 0.01029  dice_loss 0.03125 
Epoch [219/300] Validation metric {'Val/mean dice_metric': 0.9410166144371033, 'Val/mean miou_metric': 0.9020787477493286, 'Val/mean f1': 0.9447653889656067, 'Val/mean precision': 0.9428673386573792, 'Val/mean recall': 0.9466712474822998, 'Val/mean hd95_metric': 11.508971214294434}
Cheakpoint...
Epoch [219/300] best acc:tensor([0.9410], device='cuda:0'), Now : mean acc: tensor([0.9410], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9410166144371033, 'Val/mean miou_metric': 0.9020787477493286, 'Val/mean f1': 0.9447653889656067, 'Val/mean precision': 0.9428673386573792, 'Val/mean recall': 0.9466712474822998, 'Val/mean hd95_metric': 11.508971214294434}
Epoch [220/300] Training [1/62] Loss: 0.03925 
Epoch [220/300] Training [2/62] Loss: 0.11180 
Epoch [220/300] Training [3/62] Loss: 0.04668 
Epoch [220/300] Training [4/62] Loss: 0.04390 
Epoch [220/300] Training [5/62] Loss: 0.05192 
Epoch [220/300] Training [6/62] Loss: 0.04078 
Epoch [220/300] Training [7/62] Loss: 0.05484 
Epoch [220/300] Training [8/62] Loss: 0.05402 
Epoch [220/300] Training [9/62] Loss: 0.03775 
Epoch [220/300] Training [10/62] Loss: 0.04668 
Epoch [220/300] Training [11/62] Loss: 0.05064 
Epoch [220/300] Training [12/62] Loss: 0.06912 
Epoch [220/300] Training [13/62] Loss: 0.09618 
Epoch [220/300] Training [14/62] Loss: 0.07542 
Epoch [220/300] Training [15/62] Loss: 0.03991 
Epoch [220/300] Training [16/62] Loss: 0.04535 
Epoch [220/300] Training [17/62] Loss: 0.05376 
Epoch [220/300] Training [18/62] Loss: 0.08663 
Epoch [220/300] Training [19/62] Loss: 0.04872 
Epoch [220/300] Training [20/62] Loss: 0.04181 
Epoch [220/300] Training [21/62] Loss: 0.04328 
Epoch [220/300] Training [22/62] Loss: 0.05710 
Epoch [220/300] Training [23/62] Loss: 0.05203 
Epoch [220/300] Training [24/62] Loss: 0.07845 
Epoch [220/300] Training [25/62] Loss: 0.03286 
Epoch [220/300] Training [26/62] Loss: 0.04653 
Epoch [220/300] Training [27/62] Loss: 0.04689 
Epoch [220/300] Training [28/62] Loss: 0.03967 
Epoch [220/300] Training [29/62] Loss: 0.03998 
Epoch [220/300] Training [30/62] Loss: 0.04217 
Epoch [220/300] Training [31/62] Loss: 0.04374 
Epoch [220/300] Training [32/62] Loss: 0.06256 
Epoch [220/300] Training [33/62] Loss: 0.05262 
Epoch [220/300] Training [34/62] Loss: 0.06237 
Epoch [220/300] Training [35/62] Loss: 0.05127 
Epoch [220/300] Training [36/62] Loss: 0.05763 
Epoch [220/300] Training [37/62] Loss: 0.07322 
Epoch [220/300] Training [38/62] Loss: 0.06474 
Epoch [220/300] Training [39/62] Loss: 0.05278 
Epoch [220/300] Training [40/62] Loss: 0.04576 
Epoch [220/300] Training [41/62] Loss: 0.05074 
Epoch [220/300] Training [42/62] Loss: 0.07135 
Epoch [220/300] Training [43/62] Loss: 0.03484 
Epoch [220/300] Training [44/62] Loss: 0.03864 
Epoch [220/300] Training [45/62] Loss: 0.02947 
Epoch [220/300] Training [46/62] Loss: 0.04543 
Epoch [220/300] Training [47/62] Loss: 0.03647 
Epoch [220/300] Training [48/62] Loss: 0.06191 
Epoch [220/300] Training [49/62] Loss: 0.05056 
Epoch [220/300] Training [50/62] Loss: 0.03839 
Epoch [220/300] Training [51/62] Loss: 0.05593 
Epoch [220/300] Training [52/62] Loss: 0.03557 
Epoch [220/300] Training [53/62] Loss: 0.04471 
Epoch [220/300] Training [54/62] Loss: 0.09172 
Epoch [220/300] Training [55/62] Loss: 0.04889 
Epoch [220/300] Training [56/62] Loss: 0.05098 
Epoch [220/300] Training [57/62] Loss: 0.04461 
Epoch [220/300] Training [58/62] Loss: 0.04518 
Epoch [220/300] Training [59/62] Loss: 0.06040 
Epoch [220/300] Training [60/62] Loss: 0.03630 
Epoch [220/300] Training [61/62] Loss: 0.04682 
Epoch [220/300] Training [62/62] Loss: 0.06856 
Epoch [220/300] Training metric {'Train/mean dice_metric': 0.9634345769882202, 'Train/mean miou_metric': 0.9313139915466309, 'Train/mean f1': 0.9669299721717834, 'Train/mean precision': 0.9620042443275452, 'Train/mean recall': 0.9719064831733704, 'Train/mean hd95_metric': 5.993924140930176}
Epoch [220/300] Validation [1/16] Loss: 0.13608  focal_loss 0.05120  dice_loss 0.08488 
Epoch [220/300] Validation [2/16] Loss: 0.42483  focal_loss 0.19005  dice_loss 0.23478 
Epoch [220/300] Validation [3/16] Loss: 0.20726  focal_loss 0.06079  dice_loss 0.14647 
Epoch [220/300] Validation [4/16] Loss: 0.35427  focal_loss 0.17471  dice_loss 0.17956 
Epoch [220/300] Validation [5/16] Loss: 0.31895  focal_loss 0.08776  dice_loss 0.23119 
Epoch [220/300] Validation [6/16] Loss: 0.22440  focal_loss 0.05676  dice_loss 0.16765 
Epoch [220/300] Validation [7/16] Loss: 0.22812  focal_loss 0.10529  dice_loss 0.12283 
Epoch [220/300] Validation [8/16] Loss: 0.35624  focal_loss 0.10969  dice_loss 0.24655 
Epoch [220/300] Validation [9/16] Loss: 0.13945  focal_loss 0.05423  dice_loss 0.08523 
Epoch [220/300] Validation [10/16] Loss: 0.15011  focal_loss 0.04623  dice_loss 0.10388 
Epoch [220/300] Validation [11/16] Loss: 0.14383  focal_loss 0.04127  dice_loss 0.10256 
Epoch [220/300] Validation [12/16] Loss: 0.25624  focal_loss 0.06100  dice_loss 0.19525 
Epoch [220/300] Validation [13/16] Loss: 0.22912  focal_loss 0.08185  dice_loss 0.14727 
Epoch [220/300] Validation [14/16] Loss: 0.54111  focal_loss 0.21920  dice_loss 0.32191 
Epoch [220/300] Validation [15/16] Loss: 0.31733  focal_loss 0.14549  dice_loss 0.17183 
Epoch [220/300] Validation [16/16] Loss: 0.04407  focal_loss 0.01092  dice_loss 0.03315 
Epoch [220/300] Validation metric {'Val/mean dice_metric': 0.9383131861686707, 'Val/mean miou_metric': 0.8974424600601196, 'Val/mean f1': 0.9457696080207825, 'Val/mean precision': 0.9436510801315308, 'Val/mean recall': 0.947897732257843, 'Val/mean hd95_metric': 12.283611297607422}
Cheakpoint...
Epoch [220/300] best acc:tensor([0.9410], device='cuda:0'), Now : mean acc: tensor([0.9383], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9383131861686707, 'Val/mean miou_metric': 0.8974424600601196, 'Val/mean f1': 0.9457696080207825, 'Val/mean precision': 0.9436510801315308, 'Val/mean recall': 0.947897732257843, 'Val/mean hd95_metric': 12.283611297607422}
Epoch [221/300] Training [1/62] Loss: 0.07247 
Epoch [221/300] Training [2/62] Loss: 0.04410 
Epoch [221/300] Training [3/62] Loss: 0.04417 
Epoch [221/300] Training [4/62] Loss: 0.05531 
Epoch [221/300] Training [5/62] Loss: 0.04282 
Epoch [221/300] Training [6/62] Loss: 0.04087 
Epoch [221/300] Training [7/62] Loss: 0.03840 
Epoch [221/300] Training [8/62] Loss: 0.05871 
Epoch [221/300] Training [9/62] Loss: 0.04448 
Epoch [221/300] Training [10/62] Loss: 0.05165 
Epoch [221/300] Training [11/62] Loss: 0.04224 
Epoch [221/300] Training [12/62] Loss: 0.03642 
Epoch [221/300] Training [13/62] Loss: 0.04042 
Epoch [221/300] Training [14/62] Loss: 0.05195 
Epoch [221/300] Training [15/62] Loss: 0.07765 
Epoch [221/300] Training [16/62] Loss: 0.04066 
Epoch [221/300] Training [17/62] Loss: 0.03818 
Epoch [221/300] Training [18/62] Loss: 0.04518 
Epoch [221/300] Training [19/62] Loss: 0.04675 
Epoch [221/300] Training [20/62] Loss: 0.03683 
Epoch [221/300] Training [21/62] Loss: 0.07062 
Epoch [221/300] Training [22/62] Loss: 0.04846 
Epoch [221/300] Training [23/62] Loss: 0.05694 
Epoch [221/300] Training [24/62] Loss: 0.03595 
Epoch [221/300] Training [25/62] Loss: 0.04345 
Epoch [221/300] Training [26/62] Loss: 0.03042 
Epoch [221/300] Training [27/62] Loss: 0.08707 
Epoch [221/300] Training [28/62] Loss: 0.04413 
Epoch [221/300] Training [29/62] Loss: 0.04111 
Epoch [221/300] Training [30/62] Loss: 0.05078 
Epoch [221/300] Training [31/62] Loss: 0.04294 
Epoch [221/300] Training [32/62] Loss: 0.03193 
Epoch [221/300] Training [33/62] Loss: 0.06094 
Epoch [221/300] Training [34/62] Loss: 0.04477 
Epoch [221/300] Training [35/62] Loss: 0.04761 
Epoch [221/300] Training [36/62] Loss: 0.03695 
Epoch [221/300] Training [37/62] Loss: 0.05699 
Epoch [221/300] Training [38/62] Loss: 0.04922 
Epoch [221/300] Training [39/62] Loss: 0.04415 
Epoch [221/300] Training [40/62] Loss: 0.03873 
Epoch [221/300] Training [41/62] Loss: 0.05115 
Epoch [221/300] Training [42/62] Loss: 0.05808 
Epoch [221/300] Training [43/62] Loss: 0.06552 
Epoch [221/300] Training [44/62] Loss: 0.04166 
Epoch [221/300] Training [45/62] Loss: 0.03704 
Epoch [221/300] Training [46/62] Loss: 0.04621 
Epoch [221/300] Training [47/62] Loss: 0.09091 
Epoch [221/300] Training [48/62] Loss: 0.04301 
Epoch [221/300] Training [49/62] Loss: 0.05108 
Epoch [221/300] Training [50/62] Loss: 0.04365 
Epoch [221/300] Training [51/62] Loss: 0.06444 
Epoch [221/300] Training [52/62] Loss: 0.04041 
Epoch [221/300] Training [53/62] Loss: 0.05821 
Epoch [221/300] Training [54/62] Loss: 0.05995 
Epoch [221/300] Training [55/62] Loss: 0.06077 
Epoch [221/300] Training [56/62] Loss: 0.03735 
Epoch [221/300] Training [57/62] Loss: 0.05468 
Epoch [221/300] Training [58/62] Loss: 0.04635 
Epoch [221/300] Training [59/62] Loss: 0.04832 
Epoch [221/300] Training [60/62] Loss: 0.05605 
Epoch [221/300] Training [61/62] Loss: 0.03866 
Epoch [221/300] Training [62/62] Loss: 0.03497 
Epoch [221/300] Training metric {'Train/mean dice_metric': 0.9656373262405396, 'Train/mean miou_metric': 0.9347637295722961, 'Train/mean f1': 0.9678224325180054, 'Train/mean precision': 0.9630163311958313, 'Train/mean recall': 0.9726765155792236, 'Train/mean hd95_metric': 5.460225582122803}
Epoch [221/300] Validation [1/16] Loss: 0.50996  focal_loss 0.33378  dice_loss 0.17618 
Epoch [221/300] Validation [2/16] Loss: 0.40007  focal_loss 0.17226  dice_loss 0.22781 
Epoch [221/300] Validation [3/16] Loss: 0.22955  focal_loss 0.07394  dice_loss 0.15561 
Epoch [221/300] Validation [4/16] Loss: 0.30097  focal_loss 0.14920  dice_loss 0.15178 
Epoch [221/300] Validation [5/16] Loss: 0.23486  focal_loss 0.07108  dice_loss 0.16378 
Epoch [221/300] Validation [6/16] Loss: 0.18269  focal_loss 0.04190  dice_loss 0.14079 
Epoch [221/300] Validation [7/16] Loss: 0.23222  focal_loss 0.09751  dice_loss 0.13471 
Epoch [221/300] Validation [8/16] Loss: 0.30589  focal_loss 0.08812  dice_loss 0.21777 
Epoch [221/300] Validation [9/16] Loss: 0.13451  focal_loss 0.04927  dice_loss 0.08524 
Epoch [221/300] Validation [10/16] Loss: 0.23437  focal_loss 0.08197  dice_loss 0.15239 
Epoch [221/300] Validation [11/16] Loss: 0.09685  focal_loss 0.02433  dice_loss 0.07252 
Epoch [221/300] Validation [12/16] Loss: 0.26927  focal_loss 0.06205  dice_loss 0.20721 
Epoch [221/300] Validation [13/16] Loss: 0.32718  focal_loss 0.12601  dice_loss 0.20117 
Epoch [221/300] Validation [14/16] Loss: 0.45029  focal_loss 0.14901  dice_loss 0.30129 
Epoch [221/300] Validation [15/16] Loss: 0.12538  focal_loss 0.04826  dice_loss 0.07712 
Epoch [221/300] Validation [16/16] Loss: 0.05018  focal_loss 0.01272  dice_loss 0.03746 
Epoch [221/300] Validation metric {'Val/mean dice_metric': 0.9412947297096252, 'Val/mean miou_metric': 0.9018111824989319, 'Val/mean f1': 0.9468779563903809, 'Val/mean precision': 0.9473315477371216, 'Val/mean recall': 0.946424663066864, 'Val/mean hd95_metric': 11.391980171203613}
Cheakpoint...
Epoch [221/300] best acc:tensor([0.9413], device='cuda:0'), Now : mean acc: tensor([0.9413], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9412947297096252, 'Val/mean miou_metric': 0.9018111824989319, 'Val/mean f1': 0.9468779563903809, 'Val/mean precision': 0.9473315477371216, 'Val/mean recall': 0.946424663066864, 'Val/mean hd95_metric': 11.391980171203613}
Epoch [222/300] Training [1/62] Loss: 0.03958 
Epoch [222/300] Training [2/62] Loss: 0.04923 
Epoch [222/300] Training [3/62] Loss: 0.04393 
Epoch [222/300] Training [4/62] Loss: 0.05546 
Epoch [222/300] Training [5/62] Loss: 0.04109 
Epoch [222/300] Training [6/62] Loss: 0.07039 
Epoch [222/300] Training [7/62] Loss: 0.04600 
Epoch [222/300] Training [8/62] Loss: 0.07246 
Epoch [222/300] Training [9/62] Loss: 0.03969 
Epoch [222/300] Training [10/62] Loss: 0.04373 
Epoch [222/300] Training [11/62] Loss: 0.05688 
Epoch [222/300] Training [12/62] Loss: 0.04124 
Epoch [222/300] Training [13/62] Loss: 0.04621 
Epoch [222/300] Training [14/62] Loss: 0.03278 
Epoch [222/300] Training [15/62] Loss: 0.03562 
Epoch [222/300] Training [16/62] Loss: 0.07627 
Epoch [222/300] Training [17/62] Loss: 0.03286 
Epoch [222/300] Training [18/62] Loss: 0.08354 
Epoch [222/300] Training [19/62] Loss: 0.07044 
Epoch [222/300] Training [20/62] Loss: 0.04746 
Epoch [222/300] Training [21/62] Loss: 0.04682 
Epoch [222/300] Training [22/62] Loss: 0.03213 
Epoch [222/300] Training [23/62] Loss: 0.04976 
Epoch [222/300] Training [24/62] Loss: 0.04134 
Epoch [222/300] Training [25/62] Loss: 0.03481 
Epoch [222/300] Training [26/62] Loss: 0.04929 
Epoch [222/300] Training [27/62] Loss: 0.07660 
Epoch [222/300] Training [28/62] Loss: 0.04282 
Epoch [222/300] Training [29/62] Loss: 0.03756 
Epoch [222/300] Training [30/62] Loss: 0.05055 
Epoch [222/300] Training [31/62] Loss: 0.06198 
Epoch [222/300] Training [32/62] Loss: 0.04244 
Epoch [222/300] Training [33/62] Loss: 0.03767 
Epoch [222/300] Training [34/62] Loss: 0.03640 
Epoch [222/300] Training [35/62] Loss: 0.03771 
Epoch [222/300] Training [36/62] Loss: 0.04140 
Epoch [222/300] Training [37/62] Loss: 0.03473 
Epoch [222/300] Training [38/62] Loss: 0.03478 
Epoch [222/300] Training [39/62] Loss: 0.04745 
Epoch [222/300] Training [40/62] Loss: 0.04329 
Epoch [222/300] Training [41/62] Loss: 0.05498 
Epoch [222/300] Training [42/62] Loss: 0.05269 
Epoch [222/300] Training [43/62] Loss: 0.04200 
Epoch [222/300] Training [44/62] Loss: 0.06479 
Epoch [222/300] Training [45/62] Loss: 0.04049 
Epoch [222/300] Training [46/62] Loss: 0.04243 
Epoch [222/300] Training [47/62] Loss: 0.04400 
Epoch [222/300] Training [48/62] Loss: 0.04988 
Epoch [222/300] Training [49/62] Loss: 0.04955 
Epoch [222/300] Training [50/62] Loss: 0.04222 
Epoch [222/300] Training [51/62] Loss: 0.03740 
Epoch [222/300] Training [52/62] Loss: 0.04298 
Epoch [222/300] Training [53/62] Loss: 0.04663 
Epoch [222/300] Training [54/62] Loss: 0.04166 
Epoch [222/300] Training [55/62] Loss: 0.04093 
Epoch [222/300] Training [56/62] Loss: 0.04555 
Epoch [222/300] Training [57/62] Loss: 0.03825 
Epoch [222/300] Training [58/62] Loss: 0.04631 
Epoch [222/300] Training [59/62] Loss: 0.04783 
Epoch [222/300] Training [60/62] Loss: 0.04307 
Epoch [222/300] Training [61/62] Loss: 0.04651 
Epoch [222/300] Training [62/62] Loss: 0.04040 
Epoch [222/300] Training metric {'Train/mean dice_metric': 0.9675843119621277, 'Train/mean miou_metric': 0.937989354133606, 'Train/mean f1': 0.9681434035301208, 'Train/mean precision': 0.9636088609695435, 'Train/mean recall': 0.9727209210395813, 'Train/mean hd95_metric': 5.2526702880859375}
Epoch [222/300] Validation [1/16] Loss: 0.53772  focal_loss 0.36499  dice_loss 0.17272 
Epoch [222/300] Validation [2/16] Loss: 0.43611  focal_loss 0.20131  dice_loss 0.23480 
Epoch [222/300] Validation [3/16] Loss: 0.39898  focal_loss 0.18450  dice_loss 0.21447 
Epoch [222/300] Validation [4/16] Loss: 0.28465  focal_loss 0.12677  dice_loss 0.15788 
Epoch [222/300] Validation [5/16] Loss: 0.41964  focal_loss 0.16102  dice_loss 0.25861 
Epoch [222/300] Validation [6/16] Loss: 0.20170  focal_loss 0.04248  dice_loss 0.15923 
Epoch [222/300] Validation [7/16] Loss: 0.24397  focal_loss 0.12425  dice_loss 0.11972 
Epoch [222/300] Validation [8/16] Loss: 0.32574  focal_loss 0.10733  dice_loss 0.21841 
Epoch [222/300] Validation [9/16] Loss: 0.13912  focal_loss 0.06028  dice_loss 0.07884 
Epoch [222/300] Validation [10/16] Loss: 0.55831  focal_loss 0.23443  dice_loss 0.32389 
Epoch [222/300] Validation [11/16] Loss: 0.13310  focal_loss 0.03446  dice_loss 0.09864 
Epoch [222/300] Validation [12/16] Loss: 0.26989  focal_loss 0.06885  dice_loss 0.20104 
Epoch [222/300] Validation [13/16] Loss: 0.28960  focal_loss 0.10548  dice_loss 0.18413 
Epoch [222/300] Validation [14/16] Loss: 0.41778  focal_loss 0.14053  dice_loss 0.27725 
Epoch [222/300] Validation [15/16] Loss: 0.36357  focal_loss 0.18884  dice_loss 0.17473 
Epoch [222/300] Validation [16/16] Loss: 0.05023  focal_loss 0.01576  dice_loss 0.03447 
Epoch [222/300] Validation metric {'Val/mean dice_metric': 0.9373677372932434, 'Val/mean miou_metric': 0.8987374901771545, 'Val/mean f1': 0.9425071477890015, 'Val/mean precision': 0.9455115795135498, 'Val/mean recall': 0.9395217299461365, 'Val/mean hd95_metric': 12.783721923828125}
Cheakpoint...
Epoch [222/300] best acc:tensor([0.9413], device='cuda:0'), Now : mean acc: tensor([0.9374], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9373677372932434, 'Val/mean miou_metric': 0.8987374901771545, 'Val/mean f1': 0.9425071477890015, 'Val/mean precision': 0.9455115795135498, 'Val/mean recall': 0.9395217299461365, 'Val/mean hd95_metric': 12.783721923828125}
Epoch [223/300] Training [1/62] Loss: 0.05334 
Epoch [223/300] Training [2/62] Loss: 0.05238 
Epoch [223/300] Training [3/62] Loss: 0.04212 
Epoch [223/300] Training [4/62] Loss: 0.04512 
Epoch [223/300] Training [5/62] Loss: 0.05832 
Epoch [223/300] Training [6/62] Loss: 0.04739 
Epoch [223/300] Training [7/62] Loss: 0.05846 
Epoch [223/300] Training [8/62] Loss: 0.03408 
Epoch [223/300] Training [9/62] Loss: 0.05171 
Epoch [223/300] Training [10/62] Loss: 0.02855 
Epoch [223/300] Training [11/62] Loss: 0.05335 
Epoch [223/300] Training [12/62] Loss: 0.04343 
Epoch [223/300] Training [13/62] Loss: 0.03150 
Epoch [223/300] Training [14/62] Loss: 0.04285 
Epoch [223/300] Training [15/62] Loss: 0.06285 
Epoch [223/300] Training [16/62] Loss: 0.03440 
Epoch [223/300] Training [17/62] Loss: 0.12145 
Epoch [223/300] Training [18/62] Loss: 0.10324 
Epoch [223/300] Training [19/62] Loss: 0.04346 
Epoch [223/300] Training [20/62] Loss: 0.04288 
Epoch [223/300] Training [21/62] Loss: 0.06314 
Epoch [223/300] Training [22/62] Loss: 0.08126 
Epoch [223/300] Training [23/62] Loss: 0.03935 
Epoch [223/300] Training [24/62] Loss: 0.09226 
Epoch [223/300] Training [25/62] Loss: 0.03073 
Epoch [223/300] Training [26/62] Loss: 0.04614 
Epoch [223/300] Training [27/62] Loss: 0.03730 
Epoch [223/300] Training [28/62] Loss: 0.09030 
Epoch [223/300] Training [29/62] Loss: 0.03804 
Epoch [223/300] Training [30/62] Loss: 0.04094 
Epoch [223/300] Training [31/62] Loss: 0.05014 
Epoch [223/300] Training [32/62] Loss: 0.05123 
Epoch [223/300] Training [33/62] Loss: 0.04152 
Epoch [223/300] Training [34/62] Loss: 0.07029 
Epoch [223/300] Training [35/62] Loss: 0.04103 
Epoch [223/300] Training [36/62] Loss: 0.06517 
Epoch [223/300] Training [37/62] Loss: 0.06609 
Epoch [223/300] Training [38/62] Loss: 0.04085 
Epoch [223/300] Training [39/62] Loss: 0.03579 
Epoch [223/300] Training [40/62] Loss: 0.05688 
Epoch [223/300] Training [41/62] Loss: 0.04844 
Epoch [223/300] Training [42/62] Loss: 0.04463 
Epoch [223/300] Training [43/62] Loss: 0.05528 
Epoch [223/300] Training [44/62] Loss: 0.06041 
Epoch [223/300] Training [45/62] Loss: 0.05483 
Epoch [223/300] Training [46/62] Loss: 0.04057 
Epoch [223/300] Training [47/62] Loss: 0.03482 
Epoch [223/300] Training [48/62] Loss: 0.04428 
Epoch [223/300] Training [49/62] Loss: 0.06037 
Epoch [223/300] Training [50/62] Loss: 0.04125 
Epoch [223/300] Training [51/62] Loss: 0.04305 
Epoch [223/300] Training [52/62] Loss: 0.05584 
Epoch [223/300] Training [53/62] Loss: 0.04923 
Epoch [223/300] Training [54/62] Loss: 0.03616 
Epoch [223/300] Training [55/62] Loss: 0.03784 
Epoch [223/300] Training [56/62] Loss: 0.04080 
Epoch [223/300] Training [57/62] Loss: 0.16375 
Epoch [223/300] Training [58/62] Loss: 0.04717 
Epoch [223/300] Training [59/62] Loss: 0.03521 
Epoch [223/300] Training [60/62] Loss: 0.03348 
Epoch [223/300] Training [61/62] Loss: 0.07175 
Epoch [223/300] Training [62/62] Loss: 0.03442 
Epoch [223/300] Training metric {'Train/mean dice_metric': 0.9631133079528809, 'Train/mean miou_metric': 0.931947648525238, 'Train/mean f1': 0.9669924378395081, 'Train/mean precision': 0.9625460505485535, 'Train/mean recall': 0.971480131149292, 'Train/mean hd95_metric': 5.521553039550781}
Epoch [223/300] Validation [1/16] Loss: 0.19610  focal_loss 0.09191  dice_loss 0.10419 
Epoch [223/300] Validation [2/16] Loss: 0.37136  focal_loss 0.14187  dice_loss 0.22949 
Epoch [223/300] Validation [3/16] Loss: 0.67820  focal_loss 0.42110  dice_loss 0.25710 
Epoch [223/300] Validation [4/16] Loss: 0.33255  focal_loss 0.15587  dice_loss 0.17668 
Epoch [223/300] Validation [5/16] Loss: 0.33055  focal_loss 0.12111  dice_loss 0.20945 
Epoch [223/300] Validation [6/16] Loss: 0.21510  focal_loss 0.04188  dice_loss 0.17322 
Epoch [223/300] Validation [7/16] Loss: 0.20126  focal_loss 0.07582  dice_loss 0.12544 
Epoch [223/300] Validation [8/16] Loss: 0.30831  focal_loss 0.08459  dice_loss 0.22373 
Epoch [223/300] Validation [9/16] Loss: 0.20843  focal_loss 0.07427  dice_loss 0.13415 
Epoch [223/300] Validation [10/16] Loss: 0.28337  focal_loss 0.07950  dice_loss 0.20386 
Epoch [223/300] Validation [11/16] Loss: 0.10537  focal_loss 0.02613  dice_loss 0.07924 
Epoch [223/300] Validation [12/16] Loss: 0.28422  focal_loss 0.06483  dice_loss 0.21939 
Epoch [223/300] Validation [13/16] Loss: 0.31092  focal_loss 0.11386  dice_loss 0.19706 
Epoch [223/300] Validation [14/16] Loss: 0.52070  focal_loss 0.17252  dice_loss 0.34818 
Epoch [223/300] Validation [15/16] Loss: 0.11494  focal_loss 0.03640  dice_loss 0.07854 
Epoch [223/300] Validation [16/16] Loss: 0.06007  focal_loss 0.01774  dice_loss 0.04232 
Epoch [223/300] Validation metric {'Val/mean dice_metric': 0.9351402521133423, 'Val/mean miou_metric': 0.8950685858726501, 'Val/mean f1': 0.9434530735015869, 'Val/mean precision': 0.9440683126449585, 'Val/mean recall': 0.9428385496139526, 'Val/mean hd95_metric': 12.360767364501953}
Cheakpoint...
Epoch [223/300] best acc:tensor([0.9413], device='cuda:0'), Now : mean acc: tensor([0.9351], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9351402521133423, 'Val/mean miou_metric': 0.8950685858726501, 'Val/mean f1': 0.9434530735015869, 'Val/mean precision': 0.9440683126449585, 'Val/mean recall': 0.9428385496139526, 'Val/mean hd95_metric': 12.360767364501953}
Epoch [224/300] Training [1/62] Loss: 0.04095 
Epoch [224/300] Training [2/62] Loss: 0.04942 
Epoch [224/300] Training [3/62] Loss: 0.05296 
Epoch [224/300] Training [4/62] Loss: 0.13026 
Epoch [224/300] Training [5/62] Loss: 0.03927 
Epoch [224/300] Training [6/62] Loss: 0.05177 
Epoch [224/300] Training [7/62] Loss: 0.03421 
Epoch [224/300] Training [8/62] Loss: 0.04068 
Epoch [224/300] Training [9/62] Loss: 0.05403 
Epoch [224/300] Training [10/62] Loss: 0.05008 
Epoch [224/300] Training [11/62] Loss: 0.02904 
Epoch [224/300] Training [12/62] Loss: 0.08142 
Epoch [224/300] Training [13/62] Loss: 0.06787 
Epoch [224/300] Training [14/62] Loss: 0.04643 
Epoch [224/300] Training [15/62] Loss: 0.04697 
Epoch [224/300] Training [16/62] Loss: 0.04395 
Epoch [224/300] Training [17/62] Loss: 0.03383 
Epoch [224/300] Training [18/62] Loss: 0.04077 
Epoch [224/300] Training [19/62] Loss: 0.04244 
Epoch [224/300] Training [20/62] Loss: 0.04569 
Epoch [224/300] Training [21/62] Loss: 0.04423 
Epoch [224/300] Training [22/62] Loss: 0.04481 
Epoch [224/300] Training [23/62] Loss: 0.05827 
Epoch [224/300] Training [24/62] Loss: 0.04831 
Epoch [224/300] Training [25/62] Loss: 0.03917 
Epoch [224/300] Training [26/62] Loss: 0.06545 
Epoch [224/300] Training [27/62] Loss: 0.07166 
Epoch [224/300] Training [28/62] Loss: 0.03383 
Epoch [224/300] Training [29/62] Loss: 0.04591 
Epoch [224/300] Training [30/62] Loss: 0.03197 
Epoch [224/300] Training [31/62] Loss: 0.05161 
Epoch [224/300] Training [32/62] Loss: 0.03808 
Epoch [224/300] Training [33/62] Loss: 0.04417 
Epoch [224/300] Training [34/62] Loss: 0.04419 
Epoch [224/300] Training [35/62] Loss: 0.04749 
Epoch [224/300] Training [36/62] Loss: 0.03660 
Epoch [224/300] Training [37/62] Loss: 0.03326 
Epoch [224/300] Training [38/62] Loss: 0.05448 
Epoch [224/300] Training [39/62] Loss: 0.03615 
Epoch [224/300] Training [40/62] Loss: 0.03700 
Epoch [224/300] Training [41/62] Loss: 0.03969 
Epoch [224/300] Training [42/62] Loss: 0.08277 
Epoch [224/300] Training [43/62] Loss: 0.09019 
Epoch [224/300] Training [44/62] Loss: 0.05947 
Epoch [224/300] Training [45/62] Loss: 0.03433 
Epoch [224/300] Training [46/62] Loss: 0.03826 
Epoch [224/300] Training [47/62] Loss: 0.05123 
Epoch [224/300] Training [48/62] Loss: 0.03944 
Epoch [224/300] Training [49/62] Loss: 0.11572 
Epoch [224/300] Training [50/62] Loss: 0.03265 
Epoch [224/300] Training [51/62] Loss: 0.03447 
Epoch [224/300] Training [52/62] Loss: 0.05655 
Epoch [224/300] Training [53/62] Loss: 0.03952 
Epoch [224/300] Training [54/62] Loss: 0.05223 
Epoch [224/300] Training [55/62] Loss: 0.04713 
Epoch [224/300] Training [56/62] Loss: 0.08013 
Epoch [224/300] Training [57/62] Loss: 0.05698 
Epoch [224/300] Training [58/62] Loss: 0.03729 
Epoch [224/300] Training [59/62] Loss: 0.03942 
Epoch [224/300] Training [60/62] Loss: 0.03449 
Epoch [224/300] Training [61/62] Loss: 0.03993 
Epoch [224/300] Training [62/62] Loss: 0.04349 
Epoch [224/300] Training metric {'Train/mean dice_metric': 0.9653170704841614, 'Train/mean miou_metric': 0.9347932934761047, 'Train/mean f1': 0.9684494733810425, 'Train/mean precision': 0.9638716578483582, 'Train/mean recall': 0.9730712175369263, 'Train/mean hd95_metric': 5.236236095428467}
Epoch [224/300] Validation [1/16] Loss: 0.51742  focal_loss 0.31865  dice_loss 0.19876 
Epoch [224/300] Validation [2/16] Loss: 0.45744  focal_loss 0.20803  dice_loss 0.24941 
Epoch [224/300] Validation [3/16] Loss: 0.71373  focal_loss 0.46317  dice_loss 0.25055 
Epoch [224/300] Validation [4/16] Loss: 0.37794  focal_loss 0.20051  dice_loss 0.17742 
Epoch [224/300] Validation [5/16] Loss: 0.32290  focal_loss 0.10340  dice_loss 0.21950 
Epoch [224/300] Validation [6/16] Loss: 0.22577  focal_loss 0.05992  dice_loss 0.16586 
Epoch [224/300] Validation [7/16] Loss: 0.25566  focal_loss 0.10383  dice_loss 0.15183 
Epoch [224/300] Validation [8/16] Loss: 0.43198  focal_loss 0.15330  dice_loss 0.27867 
Epoch [224/300] Validation [9/16] Loss: 0.19953  focal_loss 0.08949  dice_loss 0.11004 
Epoch [224/300] Validation [10/16] Loss: 0.15155  focal_loss 0.05057  dice_loss 0.10098 
Epoch [224/300] Validation [11/16] Loss: 0.12505  focal_loss 0.03664  dice_loss 0.08841 
Epoch [224/300] Validation [12/16] Loss: 0.34020  focal_loss 0.10208  dice_loss 0.23812 
Epoch [224/300] Validation [13/16] Loss: 0.18963  focal_loss 0.06443  dice_loss 0.12519 
Epoch [224/300] Validation [14/16] Loss: 0.58499  focal_loss 0.20529  dice_loss 0.37970 
Epoch [224/300] Validation [15/16] Loss: 0.11308  focal_loss 0.04178  dice_loss 0.07129 
Epoch [224/300] Validation [16/16] Loss: 0.09208  focal_loss 0.03667  dice_loss 0.05541 
Epoch [224/300] Validation metric {'Val/mean dice_metric': 0.9360160827636719, 'Val/mean miou_metric': 0.8963578343391418, 'Val/mean f1': 0.9435980916023254, 'Val/mean precision': 0.9505407214164734, 'Val/mean recall': 0.9367563128471375, 'Val/mean hd95_metric': 11.33538818359375}
Cheakpoint...
Epoch [224/300] best acc:tensor([0.9413], device='cuda:0'), Now : mean acc: tensor([0.9360], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9360160827636719, 'Val/mean miou_metric': 0.8963578343391418, 'Val/mean f1': 0.9435980916023254, 'Val/mean precision': 0.9505407214164734, 'Val/mean recall': 0.9367563128471375, 'Val/mean hd95_metric': 11.33538818359375}
Epoch [225/300] Training [1/62] Loss: 0.04919 
Epoch [225/300] Training [2/62] Loss: 0.04171 
Epoch [225/300] Training [3/62] Loss: 0.04005 
Epoch [225/300] Training [4/62] Loss: 0.04112 
Epoch [225/300] Training [5/62] Loss: 0.03060 
Epoch [225/300] Training [6/62] Loss: 0.03967 
Epoch [225/300] Training [7/62] Loss: 0.03681 
Epoch [225/300] Training [8/62] Loss: 0.03626 
Epoch [225/300] Training [9/62] Loss: 0.03846 
Epoch [225/300] Training [10/62] Loss: 0.09431 
Epoch [225/300] Training [11/62] Loss: 0.07539 
Epoch [225/300] Training [12/62] Loss: 0.04470 
Epoch [225/300] Training [13/62] Loss: 0.04809 
Epoch [225/300] Training [14/62] Loss: 0.04904 
Epoch [225/300] Training [15/62] Loss: 0.04626 
Epoch [225/300] Training [16/62] Loss: 0.02910 
Epoch [225/300] Training [17/62] Loss: 0.05159 
Epoch [225/300] Training [18/62] Loss: 0.05299 
Epoch [225/300] Training [19/62] Loss: 0.03590 
Epoch [225/300] Training [20/62] Loss: 0.03332 
Epoch [225/300] Training [21/62] Loss: 0.05921 
Epoch [225/300] Training [22/62] Loss: 0.04413 
Epoch [225/300] Training [23/62] Loss: 0.05172 
Epoch [225/300] Training [24/62] Loss: 0.05249 
Epoch [225/300] Training [25/62] Loss: 0.07652 
Epoch [225/300] Training [26/62] Loss: 0.03797 
Epoch [225/300] Training [27/62] Loss: 0.04555 
Epoch [225/300] Training [28/62] Loss: 0.04282 
Epoch [225/300] Training [29/62] Loss: 0.05958 
Epoch [225/300] Training [30/62] Loss: 0.05130 
Epoch [225/300] Training [31/62] Loss: 0.03196 
Epoch [225/300] Training [32/62] Loss: 0.05072 
Epoch [225/300] Training [33/62] Loss: 0.04140 
Epoch [225/300] Training [34/62] Loss: 0.05190 
Epoch [225/300] Training [35/62] Loss: 0.05078 
Epoch [225/300] Training [36/62] Loss: 0.04648 
Epoch [225/300] Training [37/62] Loss: 0.12834 
Epoch [225/300] Training [38/62] Loss: 0.04597 
Epoch [225/300] Training [39/62] Loss: 0.03573 
Epoch [225/300] Training [40/62] Loss: 0.03693 
Epoch [225/300] Training [41/62] Loss: 0.03335 
Epoch [225/300] Training [42/62] Loss: 0.05377 
Epoch [225/300] Training [43/62] Loss: 0.04149 
Epoch [225/300] Training [44/62] Loss: 0.03312 
Epoch [225/300] Training [45/62] Loss: 0.04340 
Epoch [225/300] Training [46/62] Loss: 0.03829 
Epoch [225/300] Training [47/62] Loss: 0.03894 
Epoch [225/300] Training [48/62] Loss: 0.04225 
Epoch [225/300] Training [49/62] Loss: 0.03958 
Epoch [225/300] Training [50/62] Loss: 0.02995 
Epoch [225/300] Training [51/62] Loss: 0.03645 
Epoch [225/300] Training [52/62] Loss: 0.05610 
Epoch [225/300] Training [53/62] Loss: 0.03236 
Epoch [225/300] Training [54/62] Loss: 0.06672 
Epoch [225/300] Training [55/62] Loss: 0.04820 
Epoch [225/300] Training [56/62] Loss: 0.05095 
Epoch [225/300] Training [57/62] Loss: 0.04876 
Epoch [225/300] Training [58/62] Loss: 0.10953 
Epoch [225/300] Training [59/62] Loss: 0.06266 
Epoch [225/300] Training [60/62] Loss: 0.10035 
Epoch [225/300] Training [61/62] Loss: 0.04478 
Epoch [225/300] Training [62/62] Loss: 0.02129 
Epoch [225/300] Training metric {'Train/mean dice_metric': 0.9654592275619507, 'Train/mean miou_metric': 0.9351183772087097, 'Train/mean f1': 0.9688302874565125, 'Train/mean precision': 0.9642665982246399, 'Train/mean recall': 0.9734374284744263, 'Train/mean hd95_metric': 5.272704601287842}
Epoch [225/300] Validation [1/16] Loss: 0.50576  focal_loss 0.34382  dice_loss 0.16195 
Epoch [225/300] Validation [2/16] Loss: 0.43732  focal_loss 0.20004  dice_loss 0.23728 
Epoch [225/300] Validation [3/16] Loss: 0.63588  focal_loss 0.38626  dice_loss 0.24962 
Epoch [225/300] Validation [4/16] Loss: 0.29555  focal_loss 0.13720  dice_loss 0.15835 
Epoch [225/300] Validation [5/16] Loss: 0.28050  focal_loss 0.08594  dice_loss 0.19457 
Epoch [225/300] Validation [6/16] Loss: 0.21172  focal_loss 0.04277  dice_loss 0.16896 
Epoch [225/300] Validation [7/16] Loss: 0.15041  focal_loss 0.05945  dice_loss 0.09096 
Epoch [225/300] Validation [8/16] Loss: 0.35272  focal_loss 0.10307  dice_loss 0.24964 
Epoch [225/300] Validation [9/16] Loss: 0.16905  focal_loss 0.07411  dice_loss 0.09494 
Epoch [225/300] Validation [10/16] Loss: 0.35723  focal_loss 0.14595  dice_loss 0.21128 
Epoch [225/300] Validation [11/16] Loss: 0.11546  focal_loss 0.03655  dice_loss 0.07892 
Epoch [225/300] Validation [12/16] Loss: 0.31540  focal_loss 0.06710  dice_loss 0.24830 
Epoch [225/300] Validation [13/16] Loss: 0.31716  focal_loss 0.12788  dice_loss 0.18928 
Epoch [225/300] Validation [14/16] Loss: 0.34143  focal_loss 0.11462  dice_loss 0.22681 
Epoch [225/300] Validation [15/16] Loss: 0.35068  focal_loss 0.17375  dice_loss 0.17694 
Epoch [225/300] Validation [16/16] Loss: 0.05214  focal_loss 0.01809  dice_loss 0.03404 
Epoch [225/300] Validation metric {'Val/mean dice_metric': 0.9370942711830139, 'Val/mean miou_metric': 0.8985786437988281, 'Val/mean f1': 0.9447299242019653, 'Val/mean precision': 0.9483658671379089, 'Val/mean recall': 0.9411219358444214, 'Val/mean hd95_metric': 11.2302885055542}
Cheakpoint...
Epoch [225/300] best acc:tensor([0.9413], device='cuda:0'), Now : mean acc: tensor([0.9371], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9370942711830139, 'Val/mean miou_metric': 0.8985786437988281, 'Val/mean f1': 0.9447299242019653, 'Val/mean precision': 0.9483658671379089, 'Val/mean recall': 0.9411219358444214, 'Val/mean hd95_metric': 11.2302885055542}
Epoch [226/300] Training [1/62] Loss: 0.05259 
Epoch [226/300] Training [2/62] Loss: 0.05502 
Epoch [226/300] Training [3/62] Loss: 0.04303 
Epoch [226/300] Training [4/62] Loss: 0.04071 
Epoch [226/300] Training [5/62] Loss: 0.07428 
Epoch [226/300] Training [6/62] Loss: 0.03566 
Epoch [226/300] Training [7/62] Loss: 0.04122 
Epoch [226/300] Training [8/62] Loss: 0.03686 
Epoch [226/300] Training [9/62] Loss: 0.02834 
Epoch [226/300] Training [10/62] Loss: 0.03956 
Epoch [226/300] Training [11/62] Loss: 0.03664 
Epoch [226/300] Training [12/62] Loss: 0.03582 
Epoch [226/300] Training [13/62] Loss: 0.05529 
Epoch [226/300] Training [14/62] Loss: 0.05972 
Epoch [226/300] Training [15/62] Loss: 0.04151 
Epoch [226/300] Training [16/62] Loss: 0.04572 
Epoch [226/300] Training [17/62] Loss: 0.06382 
Epoch [226/300] Training [18/62] Loss: 0.04982 
Epoch [226/300] Training [19/62] Loss: 0.06861 
Epoch [226/300] Training [20/62] Loss: 0.03821 
Epoch [226/300] Training [21/62] Loss: 0.05356 
Epoch [226/300] Training [22/62] Loss: 0.04000 
Epoch [226/300] Training [23/62] Loss: 0.03393 
Epoch [226/300] Training [24/62] Loss: 0.05398 
Epoch [226/300] Training [25/62] Loss: 0.06430 
Epoch [226/300] Training [26/62] Loss: 0.05353 
Epoch [226/300] Training [27/62] Loss: 0.04894 
Epoch [226/300] Training [28/62] Loss: 0.06229 
Epoch [226/300] Training [29/62] Loss: 0.04773 
Epoch [226/300] Training [30/62] Loss: 0.04225 
Epoch [226/300] Training [31/62] Loss: 0.03732 
Epoch [226/300] Training [32/62] Loss: 0.05094 
Epoch [226/300] Training [33/62] Loss: 0.07396 
Epoch [226/300] Training [34/62] Loss: 0.03943 
Epoch [226/300] Training [35/62] Loss: 0.05189 
Epoch [226/300] Training [36/62] Loss: 0.05024 
Epoch [226/300] Training [37/62] Loss: 0.03770 
Epoch [226/300] Training [38/62] Loss: 0.07742 
Epoch [226/300] Training [39/62] Loss: 0.05362 
Epoch [226/300] Training [40/62] Loss: 0.03893 
Epoch [226/300] Training [41/62] Loss: 0.03551 
Epoch [226/300] Training [42/62] Loss: 0.03712 
Epoch [226/300] Training [43/62] Loss: 0.05699 
Epoch [226/300] Training [44/62] Loss: 0.03771 
Epoch [226/300] Training [45/62] Loss: 0.05541 
Epoch [226/300] Training [46/62] Loss: 0.04726 
Epoch [226/300] Training [47/62] Loss: 0.04633 
Epoch [226/300] Training [48/62] Loss: 0.03865 
Epoch [226/300] Training [49/62] Loss: 0.06816 
Epoch [226/300] Training [50/62] Loss: 0.03162 
Epoch [226/300] Training [51/62] Loss: 0.05018 
Epoch [226/300] Training [52/62] Loss: 0.03584 
Epoch [226/300] Training [53/62] Loss: 0.03751 
Epoch [226/300] Training [54/62] Loss: 0.04987 
Epoch [226/300] Training [55/62] Loss: 0.04246 
Epoch [226/300] Training [56/62] Loss: 0.03398 
Epoch [226/300] Training [57/62] Loss: 0.04893 
Epoch [226/300] Training [58/62] Loss: 0.03984 
Epoch [226/300] Training [59/62] Loss: 0.04070 
Epoch [226/300] Training [60/62] Loss: 0.04143 
Epoch [226/300] Training [61/62] Loss: 0.07163 
Epoch [226/300] Training [62/62] Loss: 0.02407 
Epoch [226/300] Training metric {'Train/mean dice_metric': 0.966905415058136, 'Train/mean miou_metric': 0.9369916319847107, 'Train/mean f1': 0.9689077138900757, 'Train/mean precision': 0.964504063129425, 'Train/mean recall': 0.9733517169952393, 'Train/mean hd95_metric': 4.991871356964111}
Epoch [226/300] Validation [1/16] Loss: 0.46975  focal_loss 0.27879  dice_loss 0.19095 
Epoch [226/300] Validation [2/16] Loss: 0.34939  focal_loss 0.19418  dice_loss 0.15521 
Epoch [226/300] Validation [3/16] Loss: 0.58320  focal_loss 0.33211  dice_loss 0.25109 
Epoch [226/300] Validation [4/16] Loss: 0.34545  focal_loss 0.16748  dice_loss 0.17797 
Epoch [226/300] Validation [5/16] Loss: 0.37730  focal_loss 0.13938  dice_loss 0.23792 
Epoch [226/300] Validation [6/16] Loss: 0.18827  focal_loss 0.03951  dice_loss 0.14876 
Epoch [226/300] Validation [7/16] Loss: 0.36065  focal_loss 0.18667  dice_loss 0.17398 
Epoch [226/300] Validation [8/16] Loss: 0.41867  focal_loss 0.14721  dice_loss 0.27145 
Epoch [226/300] Validation [9/16] Loss: 0.17260  focal_loss 0.07242  dice_loss 0.10018 
Epoch [226/300] Validation [10/16] Loss: 0.39828  focal_loss 0.15356  dice_loss 0.24473 
Epoch [226/300] Validation [11/16] Loss: 0.09937  focal_loss 0.03382  dice_loss 0.06555 
Epoch [226/300] Validation [12/16] Loss: 0.25857  focal_loss 0.06691  dice_loss 0.19166 
Epoch [226/300] Validation [13/16] Loss: 0.26280  focal_loss 0.09556  dice_loss 0.16724 
Epoch [226/300] Validation [14/16] Loss: 0.47247  focal_loss 0.16568  dice_loss 0.30679 
Epoch [226/300] Validation [15/16] Loss: 0.09600  focal_loss 0.03226  dice_loss 0.06374 
Epoch [226/300] Validation [16/16] Loss: 0.04726  focal_loss 0.01395  dice_loss 0.03332 
Epoch [226/300] Validation metric {'Val/mean dice_metric': 0.9380045533180237, 'Val/mean miou_metric': 0.8988059759140015, 'Val/mean f1': 0.9432323575019836, 'Val/mean precision': 0.9477351307868958, 'Val/mean recall': 0.9387722015380859, 'Val/mean hd95_metric': 10.623044967651367}
Cheakpoint...
Epoch [226/300] best acc:tensor([0.9413], device='cuda:0'), Now : mean acc: tensor([0.9380], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9380045533180237, 'Val/mean miou_metric': 0.8988059759140015, 'Val/mean f1': 0.9432323575019836, 'Val/mean precision': 0.9477351307868958, 'Val/mean recall': 0.9387722015380859, 'Val/mean hd95_metric': 10.623044967651367}
Epoch [227/300] Training [1/62] Loss: 0.05100 
Epoch [227/300] Training [2/62] Loss: 0.04759 
Epoch [227/300] Training [3/62] Loss: 0.07140 
Epoch [227/300] Training [4/62] Loss: 0.04639 
Epoch [227/300] Training [5/62] Loss: 0.04058 
Epoch [227/300] Training [6/62] Loss: 0.11057 
Epoch [227/300] Training [7/62] Loss: 0.05819 
Epoch [227/300] Training [8/62] Loss: 0.04788 
Epoch [227/300] Training [9/62] Loss: 0.03769 
Epoch [227/300] Training [10/62] Loss: 0.06529 
Epoch [227/300] Training [11/62] Loss: 0.03978 
Epoch [227/300] Training [12/62] Loss: 0.06764 
Epoch [227/300] Training [13/62] Loss: 0.04508 
Epoch [227/300] Training [14/62] Loss: 0.03770 
Epoch [227/300] Training [15/62] Loss: 0.03815 
Epoch [227/300] Training [16/62] Loss: 0.04097 
Epoch [227/300] Training [17/62] Loss: 0.04611 
Epoch [227/300] Training [18/62] Loss: 0.03570 
Epoch [227/300] Training [19/62] Loss: 0.04016 
Epoch [227/300] Training [20/62] Loss: 0.06227 
Epoch [227/300] Training [21/62] Loss: 0.04385 
Epoch [227/300] Training [22/62] Loss: 0.05370 
Epoch [227/300] Training [23/62] Loss: 0.03652 
Epoch [227/300] Training [24/62] Loss: 0.03813 
Epoch [227/300] Training [25/62] Loss: 0.03550 
Epoch [227/300] Training [26/62] Loss: 0.05230 
Epoch [227/300] Training [27/62] Loss: 0.04628 
Epoch [227/300] Training [28/62] Loss: 0.03477 
Epoch [227/300] Training [29/62] Loss: 0.04529 
Epoch [227/300] Training [30/62] Loss: 0.07866 
Epoch [227/300] Training [31/62] Loss: 0.03583 
Epoch [227/300] Training [32/62] Loss: 0.03928 
Epoch [227/300] Training [33/62] Loss: 0.05304 
Epoch [227/300] Training [34/62] Loss: 0.05676 
Epoch [227/300] Training [35/62] Loss: 0.10680 
Epoch [227/300] Training [36/62] Loss: 0.04753 
Epoch [227/300] Training [37/62] Loss: 0.07301 
Epoch [227/300] Training [38/62] Loss: 0.04412 
Epoch [227/300] Training [39/62] Loss: 0.03773 
Epoch [227/300] Training [40/62] Loss: 0.03339 
Epoch [227/300] Training [41/62] Loss: 0.05073 
Epoch [227/300] Training [42/62] Loss: 0.07209 
Epoch [227/300] Training [43/62] Loss: 0.04253 
Epoch [227/300] Training [44/62] Loss: 0.04694 
Epoch [227/300] Training [45/62] Loss: 0.04585 
Epoch [227/300] Training [46/62] Loss: 0.03604 
Epoch [227/300] Training [47/62] Loss: 0.04410 
Epoch [227/300] Training [48/62] Loss: 0.03880 
Epoch [227/300] Training [49/62] Loss: 0.04246 
Epoch [227/300] Training [50/62] Loss: 0.04385 
Epoch [227/300] Training [51/62] Loss: 0.09112 
Epoch [227/300] Training [52/62] Loss: 0.06222 
Epoch [227/300] Training [53/62] Loss: 0.03843 
Epoch [227/300] Training [54/62] Loss: 0.04595 
Epoch [227/300] Training [55/62] Loss: 0.05170 
Epoch [227/300] Training [56/62] Loss: 0.04218 
Epoch [227/300] Training [57/62] Loss: 0.06867 
Epoch [227/300] Training [58/62] Loss: 0.03403 
Epoch [227/300] Training [59/62] Loss: 0.03579 
Epoch [227/300] Training [60/62] Loss: 0.05116 
Epoch [227/300] Training [61/62] Loss: 0.02751 
Epoch [227/300] Training [62/62] Loss: 0.03155 
Epoch [227/300] Training metric {'Train/mean dice_metric': 0.965663492679596, 'Train/mean miou_metric': 0.9355424046516418, 'Train/mean f1': 0.9679609537124634, 'Train/mean precision': 0.9634008407592773, 'Train/mean recall': 0.9725642800331116, 'Train/mean hd95_metric': 5.762704372406006}
Epoch [227/300] Validation [1/16] Loss: 0.19529  focal_loss 0.08950  dice_loss 0.10579 
Epoch [227/300] Validation [2/16] Loss: 0.45634  focal_loss 0.21431  dice_loss 0.24203 
Epoch [227/300] Validation [3/16] Loss: 0.57617  focal_loss 0.32196  dice_loss 0.25422 
Epoch [227/300] Validation [4/16] Loss: 0.36963  focal_loss 0.18077  dice_loss 0.18887 
Epoch [227/300] Validation [5/16] Loss: 0.32899  focal_loss 0.08897  dice_loss 0.24002 
Epoch [227/300] Validation [6/16] Loss: 0.19844  focal_loss 0.03379  dice_loss 0.16465 
Epoch [227/300] Validation [7/16] Loss: 0.13683  focal_loss 0.04708  dice_loss 0.08976 
Epoch [227/300] Validation [8/16] Loss: 0.43386  focal_loss 0.15294  dice_loss 0.28092 
Epoch [227/300] Validation [9/16] Loss: 0.14330  focal_loss 0.05991  dice_loss 0.08338 
Epoch [227/300] Validation [10/16] Loss: 0.24910  focal_loss 0.08596  dice_loss 0.16315 
Epoch [227/300] Validation [11/16] Loss: 0.12060  focal_loss 0.03916  dice_loss 0.08144 
Epoch [227/300] Validation [12/16] Loss: 0.33257  focal_loss 0.08086  dice_loss 0.25170 
Epoch [227/300] Validation [13/16] Loss: 0.33719  focal_loss 0.12997  dice_loss 0.20722 
Epoch [227/300] Validation [14/16] Loss: 0.49917  focal_loss 0.17039  dice_loss 0.32878 
Epoch [227/300] Validation [15/16] Loss: 0.09759  focal_loss 0.03172  dice_loss 0.06587 
Epoch [227/300] Validation [16/16] Loss: 0.03976  focal_loss 0.01004  dice_loss 0.02972 
Epoch [227/300] Validation metric {'Val/mean dice_metric': 0.9370111227035522, 'Val/mean miou_metric': 0.8980357646942139, 'Val/mean f1': 0.945053219795227, 'Val/mean precision': 0.9470265507698059, 'Val/mean recall': 0.943088173866272, 'Val/mean hd95_metric': 12.08936595916748}
Cheakpoint...
Epoch [227/300] best acc:tensor([0.9413], device='cuda:0'), Now : mean acc: tensor([0.9370], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9370111227035522, 'Val/mean miou_metric': 0.8980357646942139, 'Val/mean f1': 0.945053219795227, 'Val/mean precision': 0.9470265507698059, 'Val/mean recall': 0.943088173866272, 'Val/mean hd95_metric': 12.08936595916748}
Epoch [228/300] Training [1/62] Loss: 0.04118 
Epoch [228/300] Training [2/62] Loss: 0.05183 
Epoch [228/300] Training [3/62] Loss: 0.04025 
Epoch [228/300] Training [4/62] Loss: 0.03502 
Epoch [228/300] Training [5/62] Loss: 0.03537 
Epoch [228/300] Training [6/62] Loss: 0.04436 
Epoch [228/300] Training [7/62] Loss: 0.07632 
Epoch [228/300] Training [8/62] Loss: 0.04204 
Epoch [228/300] Training [9/62] Loss: 0.08435 
Epoch [228/300] Training [10/62] Loss: 0.06411 
Epoch [228/300] Training [11/62] Loss: 0.05031 
Epoch [228/300] Training [12/62] Loss: 0.03419 
Epoch [228/300] Training [13/62] Loss: 0.05140 
Epoch [228/300] Training [14/62] Loss: 0.04127 
Epoch [228/300] Training [15/62] Loss: 0.02916 
Epoch [228/300] Training [16/62] Loss: 0.03729 
Epoch [228/300] Training [17/62] Loss: 0.05576 
Epoch [228/300] Training [18/62] Loss: 0.05488 
Epoch [228/300] Training [19/62] Loss: 0.04701 
Epoch [228/300] Training [20/62] Loss: 0.04238 
Epoch [228/300] Training [21/62] Loss: 0.04409 
Epoch [228/300] Training [22/62] Loss: 0.03348 
Epoch [228/300] Training [23/62] Loss: 0.03660 
Epoch [228/300] Training [24/62] Loss: 0.03600 
Epoch [228/300] Training [25/62] Loss: 0.04253 
Epoch [228/300] Training [26/62] Loss: 0.03131 
Epoch [228/300] Training [27/62] Loss: 0.04189 
Epoch [228/300] Training [28/62] Loss: 0.05328 
Epoch [228/300] Training [29/62] Loss: 0.05580 
Epoch [228/300] Training [30/62] Loss: 0.03606 
Epoch [228/300] Training [31/62] Loss: 0.03408 
Epoch [228/300] Training [32/62] Loss: 0.03448 
Epoch [228/300] Training [33/62] Loss: 0.04453 
Epoch [228/300] Training [34/62] Loss: 0.05321 
Epoch [228/300] Training [35/62] Loss: 0.04839 
Epoch [228/300] Training [36/62] Loss: 0.04107 
Epoch [228/300] Training [37/62] Loss: 0.03681 
Epoch [228/300] Training [38/62] Loss: 0.04595 
Epoch [228/300] Training [39/62] Loss: 0.03918 
Epoch [228/300] Training [40/62] Loss: 0.03676 
Epoch [228/300] Training [41/62] Loss: 0.03158 
Epoch [228/300] Training [42/62] Loss: 0.05887 
Epoch [228/300] Training [43/62] Loss: 0.03335 
Epoch [228/300] Training [44/62] Loss: 0.04709 
Epoch [228/300] Training [45/62] Loss: 0.05268 
Epoch [228/300] Training [46/62] Loss: 0.03800 
Epoch [228/300] Training [47/62] Loss: 0.04242 
Epoch [228/300] Training [48/62] Loss: 0.07131 
Epoch [228/300] Training [49/62] Loss: 0.04264 
Epoch [228/300] Training [50/62] Loss: 0.03116 
Epoch [228/300] Training [51/62] Loss: 0.08937 
Epoch [228/300] Training [52/62] Loss: 0.03741 
Epoch [228/300] Training [53/62] Loss: 0.07696 
Epoch [228/300] Training [54/62] Loss: 0.06050 
Epoch [228/300] Training [55/62] Loss: 0.04671 
Epoch [228/300] Training [56/62] Loss: 0.04692 
Epoch [228/300] Training [57/62] Loss: 0.04781 
Epoch [228/300] Training [58/62] Loss: 0.03965 
Epoch [228/300] Training [59/62] Loss: 0.03421 
Epoch [228/300] Training [60/62] Loss: 0.03312 
Epoch [228/300] Training [61/62] Loss: 0.04710 
Epoch [228/300] Training [62/62] Loss: 0.02020 
Epoch [228/300] Training metric {'Train/mean dice_metric': 0.968324601650238, 'Train/mean miou_metric': 0.9397784471511841, 'Train/mean f1': 0.9696412682533264, 'Train/mean precision': 0.9651060104370117, 'Train/mean recall': 0.9742193818092346, 'Train/mean hd95_metric': 4.885888576507568}
Epoch [228/300] Validation [1/16] Loss: 0.13116  focal_loss 0.05446  dice_loss 0.07670 
Epoch [228/300] Validation [2/16] Loss: 0.43144  focal_loss 0.18675  dice_loss 0.24469 
Epoch [228/300] Validation [3/16] Loss: 0.64082  focal_loss 0.38930  dice_loss 0.25153 
Epoch [228/300] Validation [4/16] Loss: 0.32695  focal_loss 0.15946  dice_loss 0.16748 
Epoch [228/300] Validation [5/16] Loss: 0.41339  focal_loss 0.14219  dice_loss 0.27120 
Epoch [228/300] Validation [6/16] Loss: 0.18090  focal_loss 0.04535  dice_loss 0.13554 
Epoch [228/300] Validation [7/16] Loss: 0.24985  focal_loss 0.11347  dice_loss 0.13638 
Epoch [228/300] Validation [8/16] Loss: 0.30300  focal_loss 0.09794  dice_loss 0.20506 
Epoch [228/300] Validation [9/16] Loss: 0.15255  focal_loss 0.06968  dice_loss 0.08287 
Epoch [228/300] Validation [10/16] Loss: 0.24247  focal_loss 0.09183  dice_loss 0.15064 
Epoch [228/300] Validation [11/16] Loss: 0.10512  focal_loss 0.03457  dice_loss 0.07055 
Epoch [228/300] Validation [12/16] Loss: 0.31277  focal_loss 0.07543  dice_loss 0.23734 
Epoch [228/300] Validation [13/16] Loss: 0.32214  focal_loss 0.12243  dice_loss 0.19971 
Epoch [228/300] Validation [14/16] Loss: 0.41957  focal_loss 0.12825  dice_loss 0.29132 
Epoch [228/300] Validation [15/16] Loss: 0.09630  focal_loss 0.03105  dice_loss 0.06526 
Epoch [228/300] Validation [16/16] Loss: 0.03974  focal_loss 0.00952  dice_loss 0.03022 
Epoch [228/300] Validation metric {'Val/mean dice_metric': 0.9415996074676514, 'Val/mean miou_metric': 0.9033926129341125, 'Val/mean f1': 0.9471832513809204, 'Val/mean precision': 0.9452376365661621, 'Val/mean recall': 0.9491369128227234, 'Val/mean hd95_metric': 11.361130714416504}
Cheakpoint...
Epoch [228/300] best acc:tensor([0.9416], device='cuda:0'), Now : mean acc: tensor([0.9416], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9415996074676514, 'Val/mean miou_metric': 0.9033926129341125, 'Val/mean f1': 0.9471832513809204, 'Val/mean precision': 0.9452376365661621, 'Val/mean recall': 0.9491369128227234, 'Val/mean hd95_metric': 11.361130714416504}
Epoch [229/300] Training [1/62] Loss: 0.04388 
Epoch [229/300] Training [2/62] Loss: 0.03566 
Epoch [229/300] Training [3/62] Loss: 0.05872 
Epoch [229/300] Training [4/62] Loss: 0.03465 
Epoch [229/300] Training [5/62] Loss: 0.04894 
Epoch [229/300] Training [6/62] Loss: 0.04453 
Epoch [229/300] Training [7/62] Loss: 0.03503 
Epoch [229/300] Training [8/62] Loss: 0.05682 
Epoch [229/300] Training [9/62] Loss: 0.10477 
Epoch [229/300] Training [10/62] Loss: 0.03981 
Epoch [229/300] Training [11/62] Loss: 0.05006 
Epoch [229/300] Training [12/62] Loss: 0.03580 
Epoch [229/300] Training [13/62] Loss: 0.05751 
Epoch [229/300] Training [14/62] Loss: 0.04109 
Epoch [229/300] Training [15/62] Loss: 0.04053 
Epoch [229/300] Training [16/62] Loss: 0.08715 
Epoch [229/300] Training [17/62] Loss: 0.02929 
Epoch [229/300] Training [18/62] Loss: 0.04346 
Epoch [229/300] Training [19/62] Loss: 0.04371 
Epoch [229/300] Training [20/62] Loss: 0.04157 
Epoch [229/300] Training [21/62] Loss: 0.03724 
Epoch [229/300] Training [22/62] Loss: 0.04697 
Epoch [229/300] Training [23/62] Loss: 0.03743 
Epoch [229/300] Training [24/62] Loss: 0.03233 
Epoch [229/300] Training [25/62] Loss: 0.04199 
Epoch [229/300] Training [26/62] Loss: 0.03590 
Epoch [229/300] Training [27/62] Loss: 0.04586 
Epoch [229/300] Training [28/62] Loss: 0.03657 
Epoch [229/300] Training [29/62] Loss: 0.05560 
Epoch [229/300] Training [30/62] Loss: 0.03277 
Epoch [229/300] Training [31/62] Loss: 0.06317 
Epoch [229/300] Training [32/62] Loss: 0.03897 
Epoch [229/300] Training [33/62] Loss: 0.03263 
Epoch [229/300] Training [34/62] Loss: 0.05486 
Epoch [229/300] Training [35/62] Loss: 0.04413 
Epoch [229/300] Training [36/62] Loss: 0.05993 
Epoch [229/300] Training [37/62] Loss: 0.04163 
Epoch [229/300] Training [38/62] Loss: 0.04986 
Epoch [229/300] Training [39/62] Loss: 0.03294 
Epoch [229/300] Training [40/62] Loss: 0.04795 
Epoch [229/300] Training [41/62] Loss: 0.05973 
Epoch [229/300] Training [42/62] Loss: 0.05582 
Epoch [229/300] Training [43/62] Loss: 0.03638 
Epoch [229/300] Training [44/62] Loss: 0.04317 
Epoch [229/300] Training [45/62] Loss: 0.06584 
Epoch [229/300] Training [46/62] Loss: 0.03654 
Epoch [229/300] Training [47/62] Loss: 0.08964 
Epoch [229/300] Training [48/62] Loss: 0.04719 
Epoch [229/300] Training [49/62] Loss: 0.05169 
Epoch [229/300] Training [50/62] Loss: 0.06928 
Epoch [229/300] Training [51/62] Loss: 0.04638 
Epoch [229/300] Training [52/62] Loss: 0.06003 
Epoch [229/300] Training [53/62] Loss: 0.02768 
Epoch [229/300] Training [54/62] Loss: 0.03631 
Epoch [229/300] Training [55/62] Loss: 0.03880 
Epoch [229/300] Training [56/62] Loss: 0.03397 
Epoch [229/300] Training [57/62] Loss: 0.03341 
Epoch [229/300] Training [58/62] Loss: 0.03131 
Epoch [229/300] Training [59/62] Loss: 0.06357 
Epoch [229/300] Training [60/62] Loss: 0.03875 
Epoch [229/300] Training [61/62] Loss: 0.04948 
Epoch [229/300] Training [62/62] Loss: 0.05017 
Epoch [229/300] Training metric {'Train/mean dice_metric': 0.9672509431838989, 'Train/mean miou_metric': 0.937806248664856, 'Train/mean f1': 0.9691693782806396, 'Train/mean precision': 0.964411735534668, 'Train/mean recall': 0.9739741086959839, 'Train/mean hd95_metric': 4.938422679901123}
Epoch [229/300] Validation [1/16] Loss: 0.19360  focal_loss 0.08693  dice_loss 0.10667 
Epoch [229/300] Validation [2/16] Loss: 0.41814  focal_loss 0.17527  dice_loss 0.24288 
Epoch [229/300] Validation [3/16] Loss: 0.70021  focal_loss 0.42681  dice_loss 0.27340 
Epoch [229/300] Validation [4/16] Loss: 0.34534  focal_loss 0.17008  dice_loss 0.17526 
Epoch [229/300] Validation [5/16] Loss: 0.30021  focal_loss 0.07358  dice_loss 0.22663 
Epoch [229/300] Validation [6/16] Loss: 0.19664  focal_loss 0.04711  dice_loss 0.14954 
Epoch [229/300] Validation [7/16] Loss: 0.23446  focal_loss 0.10972  dice_loss 0.12473 
Epoch [229/300] Validation [8/16] Loss: 0.36345  focal_loss 0.10501  dice_loss 0.25844 
Epoch [229/300] Validation [9/16] Loss: 0.14831  focal_loss 0.06697  dice_loss 0.08135 
Epoch [229/300] Validation [10/16] Loss: 0.42345  focal_loss 0.14846  dice_loss 0.27499 
Epoch [229/300] Validation [11/16] Loss: 0.13441  focal_loss 0.04344  dice_loss 0.09096 
Epoch [229/300] Validation [12/16] Loss: 0.34122  focal_loss 0.10378  dice_loss 0.23744 
Epoch [229/300] Validation [13/16] Loss: 0.34947  focal_loss 0.14068  dice_loss 0.20879 
Epoch [229/300] Validation [14/16] Loss: 0.30451  focal_loss 0.09258  dice_loss 0.21193 
Epoch [229/300] Validation [15/16] Loss: 0.10021  focal_loss 0.03496  dice_loss 0.06525 
Epoch [229/300] Validation [16/16] Loss: 0.04229  focal_loss 0.00962  dice_loss 0.03267 
Epoch [229/300] Validation metric {'Val/mean dice_metric': 0.9386851787567139, 'Val/mean miou_metric': 0.9001352190971375, 'Val/mean f1': 0.9448556900024414, 'Val/mean precision': 0.944909393787384, 'Val/mean recall': 0.944801926612854, 'Val/mean hd95_metric': 11.580599784851074}
Cheakpoint...
Epoch [229/300] best acc:tensor([0.9416], device='cuda:0'), Now : mean acc: tensor([0.9387], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9386851787567139, 'Val/mean miou_metric': 0.9001352190971375, 'Val/mean f1': 0.9448556900024414, 'Val/mean precision': 0.944909393787384, 'Val/mean recall': 0.944801926612854, 'Val/mean hd95_metric': 11.580599784851074}
Epoch [230/300] Training [1/62] Loss: 0.05172 
Epoch [230/300] Training [2/62] Loss: 0.03421 
Epoch [230/300] Training [3/62] Loss: 0.04516 
Epoch [230/300] Training [4/62] Loss: 0.07752 
Epoch [230/300] Training [5/62] Loss: 0.06508 
Epoch [230/300] Training [6/62] Loss: 0.04844 
Epoch [230/300] Training [7/62] Loss: 0.07471 
Epoch [230/300] Training [8/62] Loss: 0.04534 
Epoch [230/300] Training [9/62] Loss: 0.02888 
Epoch [230/300] Training [10/62] Loss: 0.05162 
Epoch [230/300] Training [11/62] Loss: 0.04540 
Epoch [230/300] Training [12/62] Loss: 0.04569 
Epoch [230/300] Training [13/62] Loss: 0.04425 
Epoch [230/300] Training [14/62] Loss: 0.03047 
Epoch [230/300] Training [15/62] Loss: 0.03618 
Epoch [230/300] Training [16/62] Loss: 0.04632 
Epoch [230/300] Training [17/62] Loss: 0.03242 
Epoch [230/300] Training [18/62] Loss: 0.03193 
Epoch [230/300] Training [19/62] Loss: 0.04885 
Epoch [230/300] Training [20/62] Loss: 0.04965 
Epoch [230/300] Training [21/62] Loss: 0.03663 
Epoch [230/300] Training [22/62] Loss: 0.06379 
Epoch [230/300] Training [23/62] Loss: 0.04611 
Epoch [230/300] Training [24/62] Loss: 0.04399 
Epoch [230/300] Training [25/62] Loss: 0.09923 
Epoch [230/300] Training [26/62] Loss: 0.03961 
Epoch [230/300] Training [27/62] Loss: 0.04023 
Epoch [230/300] Training [28/62] Loss: 0.03110 
Epoch [230/300] Training [29/62] Loss: 0.03439 
Epoch [230/300] Training [30/62] Loss: 0.03310 
Epoch [230/300] Training [31/62] Loss: 0.04079 
Epoch [230/300] Training [32/62] Loss: 0.03486 
Epoch [230/300] Training [33/62] Loss: 0.07420 
Epoch [230/300] Training [34/62] Loss: 0.04868 
Epoch [230/300] Training [35/62] Loss: 0.03166 
Epoch [230/300] Training [36/62] Loss: 0.03356 
Epoch [230/300] Training [37/62] Loss: 0.04090 
Epoch [230/300] Training [38/62] Loss: 0.03943 
Epoch [230/300] Training [39/62] Loss: 0.20491 
Epoch [230/300] Training [40/62] Loss: 0.04125 
Epoch [230/300] Training [41/62] Loss: 0.03982 
Epoch [230/300] Training [42/62] Loss: 0.07668 
Epoch [230/300] Training [43/62] Loss: 0.02656 
Epoch [230/300] Training [44/62] Loss: 0.03860 
Epoch [230/300] Training [45/62] Loss: 0.04439 
Epoch [230/300] Training [46/62] Loss: 0.03606 
Epoch [230/300] Training [47/62] Loss: 0.03870 
Epoch [230/300] Training [48/62] Loss: 0.05051 
Epoch [230/300] Training [49/62] Loss: 0.03496 
Epoch [230/300] Training [50/62] Loss: 0.03804 
Epoch [230/300] Training [51/62] Loss: 0.02919 
Epoch [230/300] Training [52/62] Loss: 0.03960 
Epoch [230/300] Training [53/62] Loss: 0.06303 
Epoch [230/300] Training [54/62] Loss: 0.03291 
Epoch [230/300] Training [55/62] Loss: 0.05238 
Epoch [230/300] Training [56/62] Loss: 0.04297 
Epoch [230/300] Training [57/62] Loss: 0.04558 
Epoch [230/300] Training [58/62] Loss: 0.03185 
Epoch [230/300] Training [59/62] Loss: 0.03176 
Epoch [230/300] Training [60/62] Loss: 0.04660 
Epoch [230/300] Training [61/62] Loss: 0.04875 
Epoch [230/300] Training [62/62] Loss: 0.02343 
Epoch [230/300] Training metric {'Train/mean dice_metric': 0.9670765995979309, 'Train/mean miou_metric': 0.9386151432991028, 'Train/mean f1': 0.9689896702766418, 'Train/mean precision': 0.9645326137542725, 'Train/mean recall': 0.9734881520271301, 'Train/mean hd95_metric': 5.097886085510254}
Epoch [230/300] Validation [1/16] Loss: 0.16126  focal_loss 0.06810  dice_loss 0.09317 
Epoch [230/300] Validation [2/16] Loss: 0.43038  focal_loss 0.19302  dice_loss 0.23735 
Epoch [230/300] Validation [3/16] Loss: 0.45146  focal_loss 0.20075  dice_loss 0.25071 
Epoch [230/300] Validation [4/16] Loss: 0.34028  focal_loss 0.15808  dice_loss 0.18220 
Epoch [230/300] Validation [5/16] Loss: 0.39619  focal_loss 0.15326  dice_loss 0.24293 
Epoch [230/300] Validation [6/16] Loss: 0.16380  focal_loss 0.04802  dice_loss 0.11578 
Epoch [230/300] Validation [7/16] Loss: 0.19387  focal_loss 0.06858  dice_loss 0.12529 
Epoch [230/300] Validation [8/16] Loss: 0.36741  focal_loss 0.11997  dice_loss 0.24744 
Epoch [230/300] Validation [9/16] Loss: 0.14158  focal_loss 0.06316  dice_loss 0.07841 
Epoch [230/300] Validation [10/16] Loss: 0.21545  focal_loss 0.07328  dice_loss 0.14217 
Epoch [230/300] Validation [11/16] Loss: 0.12355  focal_loss 0.04190  dice_loss 0.08166 
Epoch [230/300] Validation [12/16] Loss: 0.29879  focal_loss 0.06899  dice_loss 0.22980 
Epoch [230/300] Validation [13/16] Loss: 0.28909  focal_loss 0.11214  dice_loss 0.17695 
Epoch [230/300] Validation [14/16] Loss: 0.41283  focal_loss 0.14669  dice_loss 0.26614 
Epoch [230/300] Validation [15/16] Loss: 0.11343  focal_loss 0.03958  dice_loss 0.07385 
Epoch [230/300] Validation [16/16] Loss: 0.10637  focal_loss 0.05540  dice_loss 0.05097 
Epoch [230/300] Validation metric {'Val/mean dice_metric': 0.9408955574035645, 'Val/mean miou_metric': 0.9026991724967957, 'Val/mean f1': 0.9467262625694275, 'Val/mean precision': 0.9474486112594604, 'Val/mean recall': 0.9460052251815796, 'Val/mean hd95_metric': 10.846112251281738}
Cheakpoint...
Epoch [230/300] best acc:tensor([0.9416], device='cuda:0'), Now : mean acc: tensor([0.9409], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9408955574035645, 'Val/mean miou_metric': 0.9026991724967957, 'Val/mean f1': 0.9467262625694275, 'Val/mean precision': 0.9474486112594604, 'Val/mean recall': 0.9460052251815796, 'Val/mean hd95_metric': 10.846112251281738}
Epoch [231/300] Training [1/62] Loss: 0.05706 
Epoch [231/300] Training [2/62] Loss: 0.04306 
Epoch [231/300] Training [3/62] Loss: 0.03982 
Epoch [231/300] Training [4/62] Loss: 0.03492 
Epoch [231/300] Training [5/62] Loss: 0.04585 
Epoch [231/300] Training [6/62] Loss: 0.03124 
Epoch [231/300] Training [7/62] Loss: 0.03613 
Epoch [231/300] Training [8/62] Loss: 0.03976 
Epoch [231/300] Training [9/62] Loss: 0.03301 
Epoch [231/300] Training [10/62] Loss: 0.03742 
Epoch [231/300] Training [11/62] Loss: 0.06218 
Epoch [231/300] Training [12/62] Loss: 0.04529 
Epoch [231/300] Training [13/62] Loss: 0.03624 
Epoch [231/300] Training [14/62] Loss: 0.05748 
Epoch [231/300] Training [15/62] Loss: 0.04711 
Epoch [231/300] Training [16/62] Loss: 0.07712 
Epoch [231/300] Training [17/62] Loss: 0.04310 
Epoch [231/300] Training [18/62] Loss: 0.10527 
Epoch [231/300] Training [19/62] Loss: 0.04948 
Epoch [231/300] Training [20/62] Loss: 0.03808 
Epoch [231/300] Training [21/62] Loss: 0.02744 
Epoch [231/300] Training [22/62] Loss: 0.05010 
Epoch [231/300] Training [23/62] Loss: 0.02931 
Epoch [231/300] Training [24/62] Loss: 0.04785 
Epoch [231/300] Training [25/62] Loss: 0.07197 
Epoch [231/300] Training [26/62] Loss: 0.03575 
Epoch [231/300] Training [27/62] Loss: 0.07853 
Epoch [231/300] Training [28/62] Loss: 0.03609 
Epoch [231/300] Training [29/62] Loss: 0.06761 
Epoch [231/300] Training [30/62] Loss: 0.03296 
Epoch [231/300] Training [31/62] Loss: 0.03068 
Epoch [231/300] Training [32/62] Loss: 0.03587 
Epoch [231/300] Training [33/62] Loss: 0.04361 
Epoch [231/300] Training [34/62] Loss: 0.03977 
Epoch [231/300] Training [35/62] Loss: 0.04039 
Epoch [231/300] Training [36/62] Loss: 0.04086 
Epoch [231/300] Training [37/62] Loss: 0.03283 
Epoch [231/300] Training [38/62] Loss: 0.04384 
Epoch [231/300] Training [39/62] Loss: 0.03592 
Epoch [231/300] Training [40/62] Loss: 0.04138 
Epoch [231/300] Training [41/62] Loss: 0.03746 
Epoch [231/300] Training [42/62] Loss: 0.04067 
Epoch [231/300] Training [43/62] Loss: 0.04944 
Epoch [231/300] Training [44/62] Loss: 0.03980 
Epoch [231/300] Training [45/62] Loss: 0.03242 
Epoch [231/300] Training [46/62] Loss: 0.05281 
Epoch [231/300] Training [47/62] Loss: 0.03624 
Epoch [231/300] Training [48/62] Loss: 0.05104 
Epoch [231/300] Training [49/62] Loss: 0.03580 
Epoch [231/300] Training [50/62] Loss: 0.05466 
Epoch [231/300] Training [51/62] Loss: 0.07689 
Epoch [231/300] Training [52/62] Loss: 0.04825 
Epoch [231/300] Training [53/62] Loss: 0.03867 
Epoch [231/300] Training [54/62] Loss: 0.04056 
Epoch [231/300] Training [55/62] Loss: 0.08036 
Epoch [231/300] Training [56/62] Loss: 0.04100 
Epoch [231/300] Training [57/62] Loss: 0.03428 
Epoch [231/300] Training [58/62] Loss: 0.03333 
Epoch [231/300] Training [59/62] Loss: 0.03360 
Epoch [231/300] Training [60/62] Loss: 0.03758 
Epoch [231/300] Training [61/62] Loss: 0.03778 
Epoch [231/300] Training [62/62] Loss: 0.03851 
Epoch [231/300] Training metric {'Train/mean dice_metric': 0.9685149788856506, 'Train/mean miou_metric': 0.9404733777046204, 'Train/mean f1': 0.9703726768493652, 'Train/mean precision': 0.9661047458648682, 'Train/mean recall': 0.9746785163879395, 'Train/mean hd95_metric': 4.926054000854492}
Epoch [231/300] Validation [1/16] Loss: 0.22417  focal_loss 0.09583  dice_loss 0.12833 
Epoch [231/300] Validation [2/16] Loss: 0.42184  focal_loss 0.18784  dice_loss 0.23400 
Epoch [231/300] Validation [3/16] Loss: 0.71456  focal_loss 0.43073  dice_loss 0.28383 
Epoch [231/300] Validation [4/16] Loss: 0.31912  focal_loss 0.15537  dice_loss 0.16375 
Epoch [231/300] Validation [5/16] Loss: 0.37390  focal_loss 0.15128  dice_loss 0.22262 
Epoch [231/300] Validation [6/16] Loss: 0.26645  focal_loss 0.05691  dice_loss 0.20953 
Epoch [231/300] Validation [7/16] Loss: 0.26225  focal_loss 0.13231  dice_loss 0.12994 
Epoch [231/300] Validation [8/16] Loss: 0.40463  focal_loss 0.15009  dice_loss 0.25454 
Epoch [231/300] Validation [9/16] Loss: 0.16565  focal_loss 0.06831  dice_loss 0.09734 
Epoch [231/300] Validation [10/16] Loss: 0.19673  focal_loss 0.06162  dice_loss 0.13510 
Epoch [231/300] Validation [11/16] Loss: 0.09610  focal_loss 0.03065  dice_loss 0.06545 
Epoch [231/300] Validation [12/16] Loss: 0.28992  focal_loss 0.06694  dice_loss 0.22298 
Epoch [231/300] Validation [13/16] Loss: 0.30725  focal_loss 0.11467  dice_loss 0.19258 
Epoch [231/300] Validation [14/16] Loss: 0.43856  focal_loss 0.13996  dice_loss 0.29860 
Epoch [231/300] Validation [15/16] Loss: 0.10724  focal_loss 0.03677  dice_loss 0.07047 
Epoch [231/300] Validation [16/16] Loss: 0.04183  focal_loss 0.01123  dice_loss 0.03060 
Epoch [231/300] Validation metric {'Val/mean dice_metric': 0.939889132976532, 'Val/mean miou_metric': 0.9018577337265015, 'Val/mean f1': 0.9472367167472839, 'Val/mean precision': 0.9517556428909302, 'Val/mean recall': 0.9427604675292969, 'Val/mean hd95_metric': 11.15262508392334}
Cheakpoint...
Epoch [231/300] best acc:tensor([0.9416], device='cuda:0'), Now : mean acc: tensor([0.9399], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.939889132976532, 'Val/mean miou_metric': 0.9018577337265015, 'Val/mean f1': 0.9472367167472839, 'Val/mean precision': 0.9517556428909302, 'Val/mean recall': 0.9427604675292969, 'Val/mean hd95_metric': 11.15262508392334}
Epoch [232/300] Training [1/62] Loss: 0.05122 
Epoch [232/300] Training [2/62] Loss: 0.04801 
Epoch [232/300] Training [3/62] Loss: 0.03577 
Epoch [232/300] Training [4/62] Loss: 0.05392 
Epoch [232/300] Training [5/62] Loss: 0.03923 
Epoch [232/300] Training [6/62] Loss: 0.04315 
Epoch [232/300] Training [7/62] Loss: 0.02932 
Epoch [232/300] Training [8/62] Loss: 0.03284 
Epoch [232/300] Training [9/62] Loss: 0.07566 
Epoch [232/300] Training [10/62] Loss: 0.04297 
Epoch [232/300] Training [11/62] Loss: 0.05745 
Epoch [232/300] Training [12/62] Loss: 0.03530 
Epoch [232/300] Training [13/62] Loss: 0.10366 
Epoch [232/300] Training [14/62] Loss: 0.03274 
Epoch [232/300] Training [15/62] Loss: 0.03376 
Epoch [232/300] Training [16/62] Loss: 0.03890 
Epoch [232/300] Training [17/62] Loss: 0.04130 
Epoch [232/300] Training [18/62] Loss: 0.03889 
Epoch [232/300] Training [19/62] Loss: 0.03449 
Epoch [232/300] Training [20/62] Loss: 0.05043 
Epoch [232/300] Training [21/62] Loss: 0.03492 
Epoch [232/300] Training [22/62] Loss: 0.03269 
Epoch [232/300] Training [23/62] Loss: 0.05975 
Epoch [232/300] Training [24/62] Loss: 0.04004 
Epoch [232/300] Training [25/62] Loss: 0.03757 
Epoch [232/300] Training [26/62] Loss: 0.04806 
Epoch [232/300] Training [27/62] Loss: 0.08291 
Epoch [232/300] Training [28/62] Loss: 0.03165 
Epoch [232/300] Training [29/62] Loss: 0.03708 
Epoch [232/300] Training [30/62] Loss: 0.03401 
Epoch [232/300] Training [31/62] Loss: 0.03083 
Epoch [232/300] Training [32/62] Loss: 0.04330 
Epoch [232/300] Training [33/62] Loss: 0.08957 
Epoch [232/300] Training [34/62] Loss: 0.03173 
Epoch [232/300] Training [35/62] Loss: 0.03826 
Epoch [232/300] Training [36/62] Loss: 0.03486 
Epoch [232/300] Training [37/62] Loss: 0.03332 
Epoch [232/300] Training [38/62] Loss: 0.03961 
Epoch [232/300] Training [39/62] Loss: 0.04603 
Epoch [232/300] Training [40/62] Loss: 0.04807 
Epoch [232/300] Training [41/62] Loss: 0.03625 
Epoch [232/300] Training [42/62] Loss: 0.04298 
Epoch [232/300] Training [43/62] Loss: 0.03831 
Epoch [232/300] Training [44/62] Loss: 0.02866 
Epoch [232/300] Training [45/62] Loss: 0.08552 
Epoch [232/300] Training [46/62] Loss: 0.03990 
Epoch [232/300] Training [47/62] Loss: 0.02958 
Epoch [232/300] Training [48/62] Loss: 0.03298 
Epoch [232/300] Training [49/62] Loss: 0.03883 
Epoch [232/300] Training [50/62] Loss: 0.03775 
Epoch [232/300] Training [51/62] Loss: 0.03167 
Epoch [232/300] Training [52/62] Loss: 0.06438 
Epoch [232/300] Training [53/62] Loss: 0.03814 
Epoch [232/300] Training [54/62] Loss: 0.03401 
Epoch [232/300] Training [55/62] Loss: 0.03866 
Epoch [232/300] Training [56/62] Loss: 0.05997 
Epoch [232/300] Training [57/62] Loss: 0.04294 
Epoch [232/300] Training [58/62] Loss: 0.04057 
Epoch [232/300] Training [59/62] Loss: 0.07402 
Epoch [232/300] Training [60/62] Loss: 0.04103 
Epoch [232/300] Training [61/62] Loss: 0.03886 
Epoch [232/300] Training [62/62] Loss: 0.02520 
Epoch [232/300] Training metric {'Train/mean dice_metric': 0.9693010449409485, 'Train/mean miou_metric': 0.9418781995773315, 'Train/mean f1': 0.9702730774879456, 'Train/mean precision': 0.9655725955963135, 'Train/mean recall': 0.9750194549560547, 'Train/mean hd95_metric': 4.829744338989258}
Epoch [232/300] Validation [1/16] Loss: 0.46572  focal_loss 0.28332  dice_loss 0.18240 
Epoch [232/300] Validation [2/16] Loss: 0.44239  focal_loss 0.20479  dice_loss 0.23760 
Epoch [232/300] Validation [3/16] Loss: 0.24043  focal_loss 0.06789  dice_loss 0.17255 
Epoch [232/300] Validation [4/16] Loss: 0.26331  focal_loss 0.10914  dice_loss 0.15417 
Epoch [232/300] Validation [5/16] Loss: 0.42695  focal_loss 0.17075  dice_loss 0.25620 
Epoch [232/300] Validation [6/16] Loss: 0.20320  focal_loss 0.04450  dice_loss 0.15870 
Epoch [232/300] Validation [7/16] Loss: 0.17495  focal_loss 0.06006  dice_loss 0.11489 
Epoch [232/300] Validation [8/16] Loss: 0.42850  focal_loss 0.14229  dice_loss 0.28621 
Epoch [232/300] Validation [9/16] Loss: 0.18137  focal_loss 0.07752  dice_loss 0.10384 
Epoch [232/300] Validation [10/16] Loss: 0.18290  focal_loss 0.05719  dice_loss 0.12572 
Epoch [232/300] Validation [11/16] Loss: 0.11911  focal_loss 0.03737  dice_loss 0.08174 
Epoch [232/300] Validation [12/16] Loss: 0.22978  focal_loss 0.05978  dice_loss 0.17000 
Epoch [232/300] Validation [13/16] Loss: 0.28645  focal_loss 0.09708  dice_loss 0.18938 
Epoch [232/300] Validation [14/16] Loss: 0.50246  focal_loss 0.19033  dice_loss 0.31214 
Epoch [232/300] Validation [15/16] Loss: 0.11018  focal_loss 0.03733  dice_loss 0.07285 
Epoch [232/300] Validation [16/16] Loss: 0.04422  focal_loss 0.01272  dice_loss 0.03150 
Epoch [232/300] Validation metric {'Val/mean dice_metric': 0.9419432282447815, 'Val/mean miou_metric': 0.9048469662666321, 'Val/mean f1': 0.9480339884757996, 'Val/mean precision': 0.9485093355178833, 'Val/mean recall': 0.947559118270874, 'Val/mean hd95_metric': 11.190547943115234}
Cheakpoint...
Epoch [232/300] best acc:tensor([0.9419], device='cuda:0'), Now : mean acc: tensor([0.9419], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9419432282447815, 'Val/mean miou_metric': 0.9048469662666321, 'Val/mean f1': 0.9480339884757996, 'Val/mean precision': 0.9485093355178833, 'Val/mean recall': 0.947559118270874, 'Val/mean hd95_metric': 11.190547943115234}
Epoch [233/300] Training [1/62] Loss: 0.09058 
Epoch [233/300] Training [2/62] Loss: 0.03916 
Epoch [233/300] Training [3/62] Loss: 0.05222 
Epoch [233/300] Training [4/62] Loss: 0.03216 
Epoch [233/300] Training [5/62] Loss: 0.09553 
Epoch [233/300] Training [6/62] Loss: 0.03886 
Epoch [233/300] Training [7/62] Loss: 0.05562 
Epoch [233/300] Training [8/62] Loss: 0.06395 
Epoch [233/300] Training [9/62] Loss: 0.03715 
Epoch [233/300] Training [10/62] Loss: 0.07584 
Epoch [233/300] Training [11/62] Loss: 0.08074 
Epoch [233/300] Training [12/62] Loss: 0.04808 
Epoch [233/300] Training [13/62] Loss: 0.03776 
Epoch [233/300] Training [14/62] Loss: 0.05837 
Epoch [233/300] Training [15/62] Loss: 0.03141 
Epoch [233/300] Training [16/62] Loss: 0.03149 
Epoch [233/300] Training [17/62] Loss: 0.03816 
Epoch [233/300] Training [18/62] Loss: 0.03468 
Epoch [233/300] Training [19/62] Loss: 0.08177 
Epoch [233/300] Training [20/62] Loss: 0.02636 
Epoch [233/300] Training [21/62] Loss: 0.03815 
Epoch [233/300] Training [22/62] Loss: 0.04234 
Epoch [233/300] Training [23/62] Loss: 0.04035 
Epoch [233/300] Training [24/62] Loss: 0.04283 
Epoch [233/300] Training [25/62] Loss: 0.03870 
Epoch [233/300] Training [26/62] Loss: 0.06317 
Epoch [233/300] Training [27/62] Loss: 0.03336 
Epoch [233/300] Training [28/62] Loss: 0.04842 
Epoch [233/300] Training [29/62] Loss: 0.02828 
Epoch [233/300] Training [30/62] Loss: 0.03672 
Epoch [233/300] Training [31/62] Loss: 0.03482 
Epoch [233/300] Training [32/62] Loss: 0.04632 
Epoch [233/300] Training [33/62] Loss: 0.03434 
Epoch [233/300] Training [34/62] Loss: 0.03806 
Epoch [233/300] Training [35/62] Loss: 0.02568 
Epoch [233/300] Training [36/62] Loss: 0.03171 
Epoch [233/300] Training [37/62] Loss: 0.03009 
Epoch [233/300] Training [38/62] Loss: 0.04927 
Epoch [233/300] Training [39/62] Loss: 0.04587 
Epoch [233/300] Training [40/62] Loss: 0.04965 
Epoch [233/300] Training [41/62] Loss: 0.04348 
Epoch [233/300] Training [42/62] Loss: 0.04942 
Epoch [233/300] Training [43/62] Loss: 0.04659 
Epoch [233/300] Training [44/62] Loss: 0.07744 
Epoch [233/300] Training [45/62] Loss: 0.02838 
Epoch [233/300] Training [46/62] Loss: 0.03596 
Epoch [233/300] Training [47/62] Loss: 0.06259 
Epoch [233/300] Training [48/62] Loss: 0.02929 
Epoch [233/300] Training [49/62] Loss: 0.08468 
Epoch [233/300] Training [50/62] Loss: 0.03419 
Epoch [233/300] Training [51/62] Loss: 0.03850 
Epoch [233/300] Training [52/62] Loss: 0.03943 
Epoch [233/300] Training [53/62] Loss: 0.08519 
Epoch [233/300] Training [54/62] Loss: 0.03175 
Epoch [233/300] Training [55/62] Loss: 0.04327 
Epoch [233/300] Training [56/62] Loss: 0.03120 
Epoch [233/300] Training [57/62] Loss: 0.04571 
Epoch [233/300] Training [58/62] Loss: 0.03807 
Epoch [233/300] Training [59/62] Loss: 0.03508 
Epoch [233/300] Training [60/62] Loss: 0.07469 
Epoch [233/300] Training [61/62] Loss: 0.08150 
Epoch [233/300] Training [62/62] Loss: 0.02679 
Epoch [233/300] Training metric {'Train/mean dice_metric': 0.9667957425117493, 'Train/mean miou_metric': 0.9381630420684814, 'Train/mean f1': 0.9694685339927673, 'Train/mean precision': 0.9654181003570557, 'Train/mean recall': 0.9735530018806458, 'Train/mean hd95_metric': 5.373048782348633}
Epoch [233/300] Validation [1/16] Loss: 0.45905  focal_loss 0.25568  dice_loss 0.20336 
Epoch [233/300] Validation [2/16] Loss: 0.34604  focal_loss 0.20044  dice_loss 0.14560 
Epoch [233/300] Validation [3/16] Loss: 0.66757  focal_loss 0.40079  dice_loss 0.26677 
Epoch [233/300] Validation [4/16] Loss: 0.31766  focal_loss 0.16041  dice_loss 0.15725 
Epoch [233/300] Validation [5/16] Loss: 0.34722  focal_loss 0.14308  dice_loss 0.20414 
Epoch [233/300] Validation [6/16] Loss: 0.22706  focal_loss 0.06110  dice_loss 0.16596 
Epoch [233/300] Validation [7/16] Loss: 0.21874  focal_loss 0.11000  dice_loss 0.10874 
Epoch [233/300] Validation [8/16] Loss: 0.38961  focal_loss 0.14802  dice_loss 0.24159 
Epoch [233/300] Validation [9/16] Loss: 0.14949  focal_loss 0.06744  dice_loss 0.08205 
Epoch [233/300] Validation [10/16] Loss: 0.17691  focal_loss 0.06012  dice_loss 0.11678 
Epoch [233/300] Validation [11/16] Loss: 0.09828  focal_loss 0.02962  dice_loss 0.06867 
Epoch [233/300] Validation [12/16] Loss: 0.31420  focal_loss 0.08252  dice_loss 0.23168 
Epoch [233/300] Validation [13/16] Loss: 0.30860  focal_loss 0.11761  dice_loss 0.19098 
Epoch [233/300] Validation [14/16] Loss: 0.54628  focal_loss 0.19983  dice_loss 0.34645 
Epoch [233/300] Validation [15/16] Loss: 0.08112  focal_loss 0.02508  dice_loss 0.05604 
Epoch [233/300] Validation [16/16] Loss: 0.04083  focal_loss 0.01152  dice_loss 0.02931 
Epoch [233/300] Validation metric {'Val/mean dice_metric': 0.9401045441627502, 'Val/mean miou_metric': 0.902365505695343, 'Val/mean f1': 0.9453172087669373, 'Val/mean precision': 0.9498960375785828, 'Val/mean recall': 0.9407824277877808, 'Val/mean hd95_metric': 10.856965065002441}
Cheakpoint...
Epoch [233/300] best acc:tensor([0.9419], device='cuda:0'), Now : mean acc: tensor([0.9401], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9401045441627502, 'Val/mean miou_metric': 0.902365505695343, 'Val/mean f1': 0.9453172087669373, 'Val/mean precision': 0.9498960375785828, 'Val/mean recall': 0.9407824277877808, 'Val/mean hd95_metric': 10.856965065002441}
Epoch [234/300] Training [1/62] Loss: 0.03490 
Epoch [234/300] Training [2/62] Loss: 0.12745 
Epoch [234/300] Training [3/62] Loss: 0.03080 
Epoch [234/300] Training [4/62] Loss: 0.08014 
Epoch [234/300] Training [5/62] Loss: 0.03905 
Epoch [234/300] Training [6/62] Loss: 0.04096 
Epoch [234/300] Training [7/62] Loss: 0.03181 
Epoch [234/300] Training [8/62] Loss: 0.04182 
Epoch [234/300] Training [9/62] Loss: 0.05659 
Epoch [234/300] Training [10/62] Loss: 0.04957 
Epoch [234/300] Training [11/62] Loss: 0.02984 
Epoch [234/300] Training [12/62] Loss: 0.04005 
Epoch [234/300] Training [13/62] Loss: 0.04427 
Epoch [234/300] Training [14/62] Loss: 0.03830 
Epoch [234/300] Training [15/62] Loss: 0.05918 
Epoch [234/300] Training [16/62] Loss: 0.03734 
Epoch [234/300] Training [17/62] Loss: 0.03578 
Epoch [234/300] Training [18/62] Loss: 0.04206 
Epoch [234/300] Training [19/62] Loss: 0.08926 
Epoch [234/300] Training [20/62] Loss: 0.05919 
Epoch [234/300] Training [21/62] Loss: 0.14160 
Epoch [234/300] Training [22/62] Loss: 0.05973 
Epoch [234/300] Training [23/62] Loss: 0.04120 
Epoch [234/300] Training [24/62] Loss: 0.03713 
Epoch [234/300] Training [25/62] Loss: 0.05319 
Epoch [234/300] Training [26/62] Loss: 0.06317 
Epoch [234/300] Training [27/62] Loss: 0.02967 
Epoch [234/300] Training [28/62] Loss: 0.04498 
Epoch [234/300] Training [29/62] Loss: 0.03793 
Epoch [234/300] Training [30/62] Loss: 0.03261 
Epoch [234/300] Training [31/62] Loss: 0.04050 
Epoch [234/300] Training [32/62] Loss: 0.04770 
Epoch [234/300] Training [33/62] Loss: 0.04160 
Epoch [234/300] Training [34/62] Loss: 0.04013 
Epoch [234/300] Training [35/62] Loss: 0.03195 
Epoch [234/300] Training [36/62] Loss: 0.05762 
Epoch [234/300] Training [37/62] Loss: 0.03996 
Epoch [234/300] Training [38/62] Loss: 0.02944 
Epoch [234/300] Training [39/62] Loss: 0.03748 
Epoch [234/300] Training [40/62] Loss: 0.06758 
Epoch [234/300] Training [41/62] Loss: 0.09449 
Epoch [234/300] Training [42/62] Loss: 0.03792 
Epoch [234/300] Training [43/62] Loss: 0.04509 
Epoch [234/300] Training [44/62] Loss: 0.03761 
Epoch [234/300] Training [45/62] Loss: 0.03605 
Epoch [234/300] Training [46/62] Loss: 0.07665 
Epoch [234/300] Training [47/62] Loss: 0.05173 
Epoch [234/300] Training [48/62] Loss: 0.04718 
Epoch [234/300] Training [49/62] Loss: 0.03898 
Epoch [234/300] Training [50/62] Loss: 0.04608 
Epoch [234/300] Training [51/62] Loss: 0.04841 
Epoch [234/300] Training [52/62] Loss: 0.11541 
Epoch [234/300] Training [53/62] Loss: 0.03367 
Epoch [234/300] Training [54/62] Loss: 0.03241 
Epoch [234/300] Training [55/62] Loss: 0.04689 
Epoch [234/300] Training [56/62] Loss: 0.03506 
Epoch [234/300] Training [57/62] Loss: 0.03277 
Epoch [234/300] Training [58/62] Loss: 0.03843 
Epoch [234/300] Training [59/62] Loss: 0.02692 
Epoch [234/300] Training [60/62] Loss: 0.03922 
Epoch [234/300] Training [61/62] Loss: 0.04310 
Epoch [234/300] Training [62/62] Loss: 0.01726 
Epoch [234/300] Training metric {'Train/mean dice_metric': 0.9661397337913513, 'Train/mean miou_metric': 0.937702476978302, 'Train/mean f1': 0.9693590998649597, 'Train/mean precision': 0.9652953147888184, 'Train/mean recall': 0.9734570980072021, 'Train/mean hd95_metric': 6.0640459060668945}
Epoch [234/300] Validation [1/16] Loss: 0.17458  focal_loss 0.06586  dice_loss 0.10872 
Epoch [234/300] Validation [2/16] Loss: 0.39487  focal_loss 0.15218  dice_loss 0.24270 
Epoch [234/300] Validation [3/16] Loss: 0.32258  focal_loss 0.11157  dice_loss 0.21101 
Epoch [234/300] Validation [4/16] Loss: 0.35438  focal_loss 0.17318  dice_loss 0.18119 
Epoch [234/300] Validation [5/16] Loss: 0.35262  focal_loss 0.14709  dice_loss 0.20553 
Epoch [234/300] Validation [6/16] Loss: 0.19184  focal_loss 0.05522  dice_loss 0.13662 
Epoch [234/300] Validation [7/16] Loss: 0.18825  focal_loss 0.07587  dice_loss 0.11238 
Epoch [234/300] Validation [8/16] Loss: 0.36472  focal_loss 0.11429  dice_loss 0.25043 
Epoch [234/300] Validation [9/16] Loss: 0.14367  focal_loss 0.06544  dice_loss 0.07823 
Epoch [234/300] Validation [10/16] Loss: 0.37197  focal_loss 0.11261  dice_loss 0.25936 
Epoch [234/300] Validation [11/16] Loss: 0.11536  focal_loss 0.03951  dice_loss 0.07585 
Epoch [234/300] Validation [12/16] Loss: 0.27561  focal_loss 0.07174  dice_loss 0.20388 
Epoch [234/300] Validation [13/16] Loss: 0.31757  focal_loss 0.11403  dice_loss 0.20354 
Epoch [234/300] Validation [14/16] Loss: 0.48247  focal_loss 0.17787  dice_loss 0.30460 
Epoch [234/300] Validation [15/16] Loss: 0.10601  focal_loss 0.04027  dice_loss 0.06574 
Epoch [234/300] Validation [16/16] Loss: 0.04448  focal_loss 0.01361  dice_loss 0.03087 
Epoch [234/300] Validation metric {'Val/mean dice_metric': 0.9390285611152649, 'Val/mean miou_metric': 0.9004904627799988, 'Val/mean f1': 0.9471119046211243, 'Val/mean precision': 0.9465227127075195, 'Val/mean recall': 0.9477017521858215, 'Val/mean hd95_metric': 11.956802368164062}
Cheakpoint...
Epoch [234/300] best acc:tensor([0.9419], device='cuda:0'), Now : mean acc: tensor([0.9390], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9390285611152649, 'Val/mean miou_metric': 0.9004904627799988, 'Val/mean f1': 0.9471119046211243, 'Val/mean precision': 0.9465227127075195, 'Val/mean recall': 0.9477017521858215, 'Val/mean hd95_metric': 11.956802368164062}
Epoch [235/300] Training [1/62] Loss: 0.05009 
Epoch [235/300] Training [2/62] Loss: 0.06020 
Epoch [235/300] Training [3/62] Loss: 0.02860 
Epoch [235/300] Training [4/62] Loss: 0.03370 
Epoch [235/300] Training [5/62] Loss: 0.03251 
Epoch [235/300] Training [6/62] Loss: 0.03988 
Epoch [235/300] Training [7/62] Loss: 0.03772 
Epoch [235/300] Training [8/62] Loss: 0.06432 
Epoch [235/300] Training [9/62] Loss: 0.07308 
Epoch [235/300] Training [10/62] Loss: 0.04353 
Epoch [235/300] Training [11/62] Loss: 0.04346 
Epoch [235/300] Training [12/62] Loss: 0.03932 
Epoch [235/300] Training [13/62] Loss: 0.03519 
Epoch [235/300] Training [14/62] Loss: 0.04501 
Epoch [235/300] Training [15/62] Loss: 0.03199 
Epoch [235/300] Training [16/62] Loss: 0.09732 
Epoch [235/300] Training [17/62] Loss: 0.03751 
Epoch [235/300] Training [18/62] Loss: 0.03234 
Epoch [235/300] Training [19/62] Loss: 0.05007 
Epoch [235/300] Training [20/62] Loss: 0.04827 
Epoch [235/300] Training [21/62] Loss: 0.06789 
Epoch [235/300] Training [22/62] Loss: 0.04601 
Epoch [235/300] Training [23/62] Loss: 0.03470 
Epoch [235/300] Training [24/62] Loss: 0.03754 
Epoch [235/300] Training [25/62] Loss: 0.03652 
Epoch [235/300] Training [26/62] Loss: 0.02608 
Epoch [235/300] Training [27/62] Loss: 0.05896 
Epoch [235/300] Training [28/62] Loss: 0.04126 
Epoch [235/300] Training [29/62] Loss: 0.04117 
Epoch [235/300] Training [30/62] Loss: 0.05187 
Epoch [235/300] Training [31/62] Loss: 0.06374 
Epoch [235/300] Training [32/62] Loss: 0.03995 
Epoch [235/300] Training [33/62] Loss: 0.05012 
Epoch [235/300] Training [34/62] Loss: 0.04869 
Epoch [235/300] Training [35/62] Loss: 0.03536 
Epoch [235/300] Training [36/62] Loss: 0.04657 
Epoch [235/300] Training [37/62] Loss: 0.04550 
Epoch [235/300] Training [38/62] Loss: 0.04865 
Epoch [235/300] Training [39/62] Loss: 0.04074 
Epoch [235/300] Training [40/62] Loss: 0.03387 
Epoch [235/300] Training [41/62] Loss: 0.10090 
Epoch [235/300] Training [42/62] Loss: 0.05987 
Epoch [235/300] Training [43/62] Loss: 0.03181 
Epoch [235/300] Training [44/62] Loss: 0.02856 
Epoch [235/300] Training [45/62] Loss: 0.03393 
Epoch [235/300] Training [46/62] Loss: 0.03963 
Epoch [235/300] Training [47/62] Loss: 0.03020 
Epoch [235/300] Training [48/62] Loss: 0.03859 
Epoch [235/300] Training [49/62] Loss: 0.03920 
Epoch [235/300] Training [50/62] Loss: 0.03141 
Epoch [235/300] Training [51/62] Loss: 0.06217 
Epoch [235/300] Training [52/62] Loss: 0.03815 
Epoch [235/300] Training [53/62] Loss: 0.03834 
Epoch [235/300] Training [54/62] Loss: 0.03236 
Epoch [235/300] Training [55/62] Loss: 0.04078 
Epoch [235/300] Training [56/62] Loss: 0.03010 
Epoch [235/300] Training [57/62] Loss: 0.03827 
Epoch [235/300] Training [58/62] Loss: 0.03584 
Epoch [235/300] Training [59/62] Loss: 0.07939 
Epoch [235/300] Training [60/62] Loss: 0.06080 
Epoch [235/300] Training [61/62] Loss: 0.04373 
Epoch [235/300] Training [62/62] Loss: 0.02361 
Epoch [235/300] Training metric {'Train/mean dice_metric': 0.9690423011779785, 'Train/mean miou_metric': 0.941181480884552, 'Train/mean f1': 0.969980001449585, 'Train/mean precision': 0.9661805629730225, 'Train/mean recall': 0.9738094806671143, 'Train/mean hd95_metric': 5.454685688018799}
Epoch [235/300] Validation [1/16] Loss: 0.19862  focal_loss 0.08705  dice_loss 0.11157 
Epoch [235/300] Validation [2/16] Loss: 0.45296  focal_loss 0.21445  dice_loss 0.23851 
Epoch [235/300] Validation [3/16] Loss: 0.66156  focal_loss 0.38570  dice_loss 0.27587 
Epoch [235/300] Validation [4/16] Loss: 0.27050  focal_loss 0.12623  dice_loss 0.14427 
Epoch [235/300] Validation [5/16] Loss: 0.36935  focal_loss 0.15069  dice_loss 0.21865 
Epoch [235/300] Validation [6/16] Loss: 0.22149  focal_loss 0.06412  dice_loss 0.15737 
Epoch [235/300] Validation [7/16] Loss: 0.17913  focal_loss 0.06609  dice_loss 0.11305 
Epoch [235/300] Validation [8/16] Loss: 0.35760  focal_loss 0.12356  dice_loss 0.23404 
Epoch [235/300] Validation [9/16] Loss: 0.14128  focal_loss 0.05556  dice_loss 0.08572 
Epoch [235/300] Validation [10/16] Loss: 0.22925  focal_loss 0.07189  dice_loss 0.15736 
Epoch [235/300] Validation [11/16] Loss: 0.10431  focal_loss 0.03568  dice_loss 0.06863 
Epoch [235/300] Validation [12/16] Loss: 0.27130  focal_loss 0.06331  dice_loss 0.20799 
Epoch [235/300] Validation [13/16] Loss: 0.15845  focal_loss 0.04923  dice_loss 0.10923 
Epoch [235/300] Validation [14/16] Loss: 0.38619  focal_loss 0.14344  dice_loss 0.24274 
Epoch [235/300] Validation [15/16] Loss: 0.10016  focal_loss 0.03113  dice_loss 0.06903 
Epoch [235/300] Validation [16/16] Loss: 0.06915  focal_loss 0.02312  dice_loss 0.04603 
Epoch [235/300] Validation metric {'Val/mean dice_metric': 0.9441874623298645, 'Val/mean miou_metric': 0.9067855477333069, 'Val/mean f1': 0.9486809968948364, 'Val/mean precision': 0.9503987431526184, 'Val/mean recall': 0.9469695091247559, 'Val/mean hd95_metric': 11.024035453796387}
Cheakpoint...
Epoch [235/300] best acc:tensor([0.9442], device='cuda:0'), Now : mean acc: tensor([0.9442], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9441874623298645, 'Val/mean miou_metric': 0.9067855477333069, 'Val/mean f1': 0.9486809968948364, 'Val/mean precision': 0.9503987431526184, 'Val/mean recall': 0.9469695091247559, 'Val/mean hd95_metric': 11.024035453796387}
Epoch [236/300] Training [1/62] Loss: 0.03032 
Epoch [236/300] Training [2/62] Loss: 0.03668 
Epoch [236/300] Training [3/62] Loss: 0.02890 
Epoch [236/300] Training [4/62] Loss: 0.03118 
Epoch [236/300] Training [5/62] Loss: 0.04581 
Epoch [236/300] Training [6/62] Loss: 0.03531 
Epoch [236/300] Training [7/62] Loss: 0.02904 
Epoch [236/300] Training [8/62] Loss: 0.05174 
Epoch [236/300] Training [9/62] Loss: 0.03511 
Epoch [236/300] Training [10/62] Loss: 0.03565 
Epoch [236/300] Training [11/62] Loss: 0.06382 
Epoch [236/300] Training [12/62] Loss: 0.07176 
Epoch [236/300] Training [13/62] Loss: 0.03615 
Epoch [236/300] Training [14/62] Loss: 0.03981 
Epoch [236/300] Training [15/62] Loss: 0.03518 
Epoch [236/300] Training [16/62] Loss: 0.05832 
Epoch [236/300] Training [17/62] Loss: 0.03303 
Epoch [236/300] Training [18/62] Loss: 0.05622 
Epoch [236/300] Training [19/62] Loss: 0.03335 
Epoch [236/300] Training [20/62] Loss: 0.03393 
Epoch [236/300] Training [21/62] Loss: 0.05879 
Epoch [236/300] Training [22/62] Loss: 0.02951 
Epoch [236/300] Training [23/62] Loss: 0.03164 
Epoch [236/300] Training [24/62] Loss: 0.04035 
Epoch [236/300] Training [25/62] Loss: 0.05398 
Epoch [236/300] Training [26/62] Loss: 0.03667 
Epoch [236/300] Training [27/62] Loss: 0.04611 
Epoch [236/300] Training [28/62] Loss: 0.03076 
Epoch [236/300] Training [29/62] Loss: 0.04612 
Epoch [236/300] Training [30/62] Loss: 0.02573 
Epoch [236/300] Training [31/62] Loss: 0.03445 
Epoch [236/300] Training [32/62] Loss: 0.03173 
Epoch [236/300] Training [33/62] Loss: 0.03570 
Epoch [236/300] Training [34/62] Loss: 0.03323 
Epoch [236/300] Training [35/62] Loss: 0.03538 
Epoch [236/300] Training [36/62] Loss: 0.03596 
Epoch [236/300] Training [37/62] Loss: 0.05374 
Epoch [236/300] Training [38/62] Loss: 0.03898 
Epoch [236/300] Training [39/62] Loss: 0.04427 
Epoch [236/300] Training [40/62] Loss: 0.08992 
Epoch [236/300] Training [41/62] Loss: 0.07034 
Epoch [236/300] Training [42/62] Loss: 0.05786 
Epoch [236/300] Training [43/62] Loss: 0.02966 
Epoch [236/300] Training [44/62] Loss: 0.04144 
Epoch [236/300] Training [45/62] Loss: 0.04747 
Epoch [236/300] Training [46/62] Loss: 0.03919 
Epoch [236/300] Training [47/62] Loss: 0.05542 
Epoch [236/300] Training [48/62] Loss: 0.03729 
Epoch [236/300] Training [49/62] Loss: 0.03876 
Epoch [236/300] Training [50/62] Loss: 0.05247 
Epoch [236/300] Training [51/62] Loss: 0.06284 
Epoch [236/300] Training [52/62] Loss: 0.04149 
Epoch [236/300] Training [53/62] Loss: 0.04236 
Epoch [236/300] Training [54/62] Loss: 0.06968 
Epoch [236/300] Training [55/62] Loss: 0.02819 
Epoch [236/300] Training [56/62] Loss: 0.05566 
Epoch [236/300] Training [57/62] Loss: 0.03938 
Epoch [236/300] Training [58/62] Loss: 0.03967 
Epoch [236/300] Training [59/62] Loss: 0.04110 
Epoch [236/300] Training [60/62] Loss: 0.03139 
Epoch [236/300] Training [61/62] Loss: 0.03140 
Epoch [236/300] Training [62/62] Loss: 0.04179 
Epoch [236/300] Training metric {'Train/mean dice_metric': 0.9705743789672852, 'Train/mean miou_metric': 0.9439927935600281, 'Train/mean f1': 0.9713940024375916, 'Train/mean precision': 0.9670482873916626, 'Train/mean recall': 0.9757790565490723, 'Train/mean hd95_metric': 4.673680305480957}
Epoch [236/300] Validation [1/16] Loss: 0.17258  focal_loss 0.07677  dice_loss 0.09581 
Epoch [236/300] Validation [2/16] Loss: 0.40760  focal_loss 0.19398  dice_loss 0.21361 
Epoch [236/300] Validation [3/16] Loss: 0.55493  focal_loss 0.28430  dice_loss 0.27063 
Epoch [236/300] Validation [4/16] Loss: 0.19000  focal_loss 0.06859  dice_loss 0.12141 
Epoch [236/300] Validation [5/16] Loss: 0.32711  focal_loss 0.11869  dice_loss 0.20842 
Epoch [236/300] Validation [6/16] Loss: 0.24578  focal_loss 0.05368  dice_loss 0.19210 
Epoch [236/300] Validation [7/16] Loss: 0.28303  focal_loss 0.14404  dice_loss 0.13899 
Epoch [236/300] Validation [8/16] Loss: 0.24398  focal_loss 0.08566  dice_loss 0.15833 
Epoch [236/300] Validation [9/16] Loss: 0.25595  focal_loss 0.10513  dice_loss 0.15082 
Epoch [236/300] Validation [10/16] Loss: 0.17972  focal_loss 0.05277  dice_loss 0.12695 
Epoch [236/300] Validation [11/16] Loss: 0.10557  focal_loss 0.03115  dice_loss 0.07442 
Epoch [236/300] Validation [12/16] Loss: 0.28822  focal_loss 0.06553  dice_loss 0.22269 
Epoch [236/300] Validation [13/16] Loss: 0.20053  focal_loss 0.06527  dice_loss 0.13526 
Epoch [236/300] Validation [14/16] Loss: 0.45501  focal_loss 0.14959  dice_loss 0.30541 
Epoch [236/300] Validation [15/16] Loss: 0.08611  focal_loss 0.02591  dice_loss 0.06020 
Epoch [236/300] Validation [16/16] Loss: 0.05309  focal_loss 0.01395  dice_loss 0.03914 
Epoch [236/300] Validation metric {'Val/mean dice_metric': 0.9449424743652344, 'Val/mean miou_metric': 0.9075155854225159, 'Val/mean f1': 0.9486926198005676, 'Val/mean precision': 0.9473551511764526, 'Val/mean recall': 0.9500338435173035, 'Val/mean hd95_metric': 10.335158348083496}
Cheakpoint...
Epoch [236/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9449], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9449424743652344, 'Val/mean miou_metric': 0.9075155854225159, 'Val/mean f1': 0.9486926198005676, 'Val/mean precision': 0.9473551511764526, 'Val/mean recall': 0.9500338435173035, 'Val/mean hd95_metric': 10.335158348083496}
Epoch [237/300] Training [1/62] Loss: 0.03392 
Epoch [237/300] Training [2/62] Loss: 0.05119 
Epoch [237/300] Training [3/62] Loss: 0.04640 
Epoch [237/300] Training [4/62] Loss: 0.04053 
Epoch [237/300] Training [5/62] Loss: 0.03948 
Epoch [237/300] Training [6/62] Loss: 0.04744 
Epoch [237/300] Training [7/62] Loss: 0.04727 
Epoch [237/300] Training [8/62] Loss: 0.03205 
Epoch [237/300] Training [9/62] Loss: 0.05255 
Epoch [237/300] Training [10/62] Loss: 0.03671 
Epoch [237/300] Training [11/62] Loss: 0.03277 
Epoch [237/300] Training [12/62] Loss: 0.06146 
Epoch [237/300] Training [13/62] Loss: 0.04152 
Epoch [237/300] Training [14/62] Loss: 0.04103 
Epoch [237/300] Training [15/62] Loss: 0.03577 
Epoch [237/300] Training [16/62] Loss: 0.03510 
Epoch [237/300] Training [17/62] Loss: 0.03634 
Epoch [237/300] Training [18/62] Loss: 0.03717 
Epoch [237/300] Training [19/62] Loss: 0.03867 
Epoch [237/300] Training [20/62] Loss: 0.06848 
Epoch [237/300] Training [21/62] Loss: 0.04063 
Epoch [237/300] Training [22/62] Loss: 0.03840 
Epoch [237/300] Training [23/62] Loss: 0.03817 
Epoch [237/300] Training [24/62] Loss: 0.05429 
Epoch [237/300] Training [25/62] Loss: 0.05988 
Epoch [237/300] Training [26/62] Loss: 0.02776 
Epoch [237/300] Training [27/62] Loss: 0.04414 
Epoch [237/300] Training [28/62] Loss: 0.02413 
Epoch [237/300] Training [29/62] Loss: 0.03638 
Epoch [237/300] Training [30/62] Loss: 0.05711 
Epoch [237/300] Training [31/62] Loss: 0.25230 
Epoch [237/300] Training [32/62] Loss: 0.03990 
Epoch [237/300] Training [33/62] Loss: 0.04027 
Epoch [237/300] Training [34/62] Loss: 0.03987 
Epoch [237/300] Training [35/62] Loss: 0.03292 
Epoch [237/300] Training [36/62] Loss: 0.05774 
Epoch [237/300] Training [37/62] Loss: 0.07753 
Epoch [237/300] Training [38/62] Loss: 0.05113 
Epoch [237/300] Training [39/62] Loss: 0.04341 
Epoch [237/300] Training [40/62] Loss: 0.03563 
Epoch [237/300] Training [41/62] Loss: 0.03636 
Epoch [237/300] Training [42/62] Loss: 0.03709 
Epoch [237/300] Training [43/62] Loss: 0.03970 
Epoch [237/300] Training [44/62] Loss: 0.04104 
Epoch [237/300] Training [45/62] Loss: 0.04223 
Epoch [237/300] Training [46/62] Loss: 0.03091 
Epoch [237/300] Training [47/62] Loss: 0.04968 
Epoch [237/300] Training [48/62] Loss: 0.04108 
Epoch [237/300] Training [49/62] Loss: 0.03454 
Epoch [237/300] Training [50/62] Loss: 0.03136 
Epoch [237/300] Training [51/62] Loss: 0.02606 
Epoch [237/300] Training [52/62] Loss: 0.02944 
Epoch [237/300] Training [53/62] Loss: 0.02958 
Epoch [237/300] Training [54/62] Loss: 0.14209 
Epoch [237/300] Training [55/62] Loss: 0.03988 
Epoch [237/300] Training [56/62] Loss: 0.04095 
Epoch [237/300] Training [57/62] Loss: 0.02579 
Epoch [237/300] Training [58/62] Loss: 0.13511 
Epoch [237/300] Training [59/62] Loss: 0.06660 
Epoch [237/300] Training [60/62] Loss: 0.07202 
Epoch [237/300] Training [61/62] Loss: 0.02886 
Epoch [237/300] Training [62/62] Loss: 0.05417 
Epoch [237/300] Training metric {'Train/mean dice_metric': 0.9662192463874817, 'Train/mean miou_metric': 0.9388954639434814, 'Train/mean f1': 0.9700292944908142, 'Train/mean precision': 0.9662570953369141, 'Train/mean recall': 0.9738311767578125, 'Train/mean hd95_metric': 5.5153985023498535}
Epoch [237/300] Validation [1/16] Loss: 0.46304  focal_loss 0.31133  dice_loss 0.15171 
Epoch [237/300] Validation [2/16] Loss: 0.40839  focal_loss 0.17843  dice_loss 0.22996 
Epoch [237/300] Validation [3/16] Loss: 0.28396  focal_loss 0.09801  dice_loss 0.18595 
Epoch [237/300] Validation [4/16] Loss: 0.24201  focal_loss 0.11801  dice_loss 0.12400 
Epoch [237/300] Validation [5/16] Loss: 0.33423  focal_loss 0.11560  dice_loss 0.21863 
Epoch [237/300] Validation [6/16] Loss: 0.18586  focal_loss 0.03910  dice_loss 0.14676 
Epoch [237/300] Validation [7/16] Loss: 0.26116  focal_loss 0.12563  dice_loss 0.13554 
Epoch [237/300] Validation [8/16] Loss: 0.30002  focal_loss 0.11191  dice_loss 0.18810 
Epoch [237/300] Validation [9/16] Loss: 0.15328  focal_loss 0.06744  dice_loss 0.08584 
Epoch [237/300] Validation [10/16] Loss: 0.37751  focal_loss 0.14616  dice_loss 0.23136 
Epoch [237/300] Validation [11/16] Loss: 0.15573  focal_loss 0.05156  dice_loss 0.10417 
Epoch [237/300] Validation [12/16] Loss: 0.36764  focal_loss 0.12016  dice_loss 0.24748 
Epoch [237/300] Validation [13/16] Loss: 0.34089  focal_loss 0.13986  dice_loss 0.20103 
Epoch [237/300] Validation [14/16] Loss: 0.41667  focal_loss 0.12813  dice_loss 0.28854 
Epoch [237/300] Validation [15/16] Loss: 0.09894  focal_loss 0.03328  dice_loss 0.06566 
Epoch [237/300] Validation [16/16] Loss: 0.04318  focal_loss 0.01243  dice_loss 0.03075 
Epoch [237/300] Validation metric {'Val/mean dice_metric': 0.9395437836647034, 'Val/mean miou_metric': 0.9022889137268066, 'Val/mean f1': 0.9453640580177307, 'Val/mean precision': 0.9428067803382874, 'Val/mean recall': 0.947935163974762, 'Val/mean hd95_metric': 12.053977012634277}
Cheakpoint...
Epoch [237/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9395], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9395437836647034, 'Val/mean miou_metric': 0.9022889137268066, 'Val/mean f1': 0.9453640580177307, 'Val/mean precision': 0.9428067803382874, 'Val/mean recall': 0.947935163974762, 'Val/mean hd95_metric': 12.053977012634277}
Epoch [238/300] Training [1/62] Loss: 0.03880 
Epoch [238/300] Training [2/62] Loss: 0.04308 
Epoch [238/300] Training [3/62] Loss: 0.05675 
Epoch [238/300] Training [4/62] Loss: 0.05356 
Epoch [238/300] Training [5/62] Loss: 0.07270 
Epoch [238/300] Training [6/62] Loss: 0.03235 
Epoch [238/300] Training [7/62] Loss: 0.04436 
Epoch [238/300] Training [8/62] Loss: 0.04739 
Epoch [238/300] Training [9/62] Loss: 0.07283 
Epoch [238/300] Training [10/62] Loss: 0.05463 
Epoch [238/300] Training [11/62] Loss: 0.07857 
Epoch [238/300] Training [12/62] Loss: 0.03685 
Epoch [238/300] Training [13/62] Loss: 0.07186 
Epoch [238/300] Training [14/62] Loss: 0.05481 
Epoch [238/300] Training [15/62] Loss: 0.03680 
Epoch [238/300] Training [16/62] Loss: 0.03356 
Epoch [238/300] Training [17/62] Loss: 0.04527 
Epoch [238/300] Training [18/62] Loss: 0.05173 
Epoch [238/300] Training [19/62] Loss: 0.05076 
Epoch [238/300] Training [20/62] Loss: 0.03966 
Epoch [238/300] Training [21/62] Loss: 0.03784 
Epoch [238/300] Training [22/62] Loss: 0.04336 
Epoch [238/300] Training [23/62] Loss: 0.05172 
Epoch [238/300] Training [24/62] Loss: 0.03368 
Epoch [238/300] Training [25/62] Loss: 0.03080 
Epoch [238/300] Training [26/62] Loss: 0.04615 
Epoch [238/300] Training [27/62] Loss: 0.05094 
Epoch [238/300] Training [28/62] Loss: 0.03085 
Epoch [238/300] Training [29/62] Loss: 0.02854 
Epoch [238/300] Training [30/62] Loss: 0.03477 
Epoch [238/300] Training [31/62] Loss: 0.03867 
Epoch [238/300] Training [32/62] Loss: 0.03199 
Epoch [238/300] Training [33/62] Loss: 0.05016 
Epoch [238/300] Training [34/62] Loss: 0.06347 
Epoch [238/300] Training [35/62] Loss: 0.06570 
Epoch [238/300] Training [36/62] Loss: 0.03038 
Epoch [238/300] Training [37/62] Loss: 0.05185 
Epoch [238/300] Training [38/62] Loss: 0.03534 
Epoch [238/300] Training [39/62] Loss: 0.02910 
Epoch [238/300] Training [40/62] Loss: 0.03910 
Epoch [238/300] Training [41/62] Loss: 0.04065 
Epoch [238/300] Training [42/62] Loss: 0.03046 
Epoch [238/300] Training [43/62] Loss: 0.03688 
Epoch [238/300] Training [44/62] Loss: 0.04983 
Epoch [238/300] Training [45/62] Loss: 0.03197 
Epoch [238/300] Training [46/62] Loss: 0.03511 
Epoch [238/300] Training [47/62] Loss: 0.03645 
Epoch [238/300] Training [48/62] Loss: 0.03250 
Epoch [238/300] Training [49/62] Loss: 0.03852 
Epoch [238/300] Training [50/62] Loss: 0.02840 
Epoch [238/300] Training [51/62] Loss: 0.03148 
Epoch [238/300] Training [52/62] Loss: 0.03640 
Epoch [238/300] Training [53/62] Loss: 0.03357 
Epoch [238/300] Training [54/62] Loss: 0.03565 
Epoch [238/300] Training [55/62] Loss: 0.05586 
Epoch [238/300] Training [56/62] Loss: 0.04326 
Epoch [238/300] Training [57/62] Loss: 0.03587 
Epoch [238/300] Training [58/62] Loss: 0.02899 
Epoch [238/300] Training [59/62] Loss: 0.09675 
Epoch [238/300] Training [60/62] Loss: 0.03333 
Epoch [238/300] Training [61/62] Loss: 0.03563 
Epoch [238/300] Training [62/62] Loss: 0.03173 
Epoch [238/300] Training metric {'Train/mean dice_metric': 0.9697173237800598, 'Train/mean miou_metric': 0.9425638914108276, 'Train/mean f1': 0.9711816906929016, 'Train/mean precision': 0.9671217203140259, 'Train/mean recall': 0.9752760529518127, 'Train/mean hd95_metric': 4.64829683303833}
Epoch [238/300] Validation [1/16] Loss: 0.53815  focal_loss 0.35146  dice_loss 0.18668 
Epoch [238/300] Validation [2/16] Loss: 0.43673  focal_loss 0.19682  dice_loss 0.23991 
Epoch [238/300] Validation [3/16] Loss: 0.56913  focal_loss 0.32021  dice_loss 0.24892 
Epoch [238/300] Validation [4/16] Loss: 0.28592  focal_loss 0.14235  dice_loss 0.14357 
Epoch [238/300] Validation [5/16] Loss: 0.38169  focal_loss 0.14823  dice_loss 0.23346 
Epoch [238/300] Validation [6/16] Loss: 0.21199  focal_loss 0.06209  dice_loss 0.14991 
Epoch [238/300] Validation [7/16] Loss: 0.21779  focal_loss 0.09717  dice_loss 0.12062 
Epoch [238/300] Validation [8/16] Loss: 0.47164  focal_loss 0.19214  dice_loss 0.27950 
Epoch [238/300] Validation [9/16] Loss: 0.14744  focal_loss 0.07154  dice_loss 0.07590 
Epoch [238/300] Validation [10/16] Loss: 0.23045  focal_loss 0.07532  dice_loss 0.15513 
Epoch [238/300] Validation [11/16] Loss: 0.09831  focal_loss 0.03392  dice_loss 0.06439 
Epoch [238/300] Validation [12/16] Loss: 0.34647  focal_loss 0.10600  dice_loss 0.24047 
Epoch [238/300] Validation [13/16] Loss: 0.20596  focal_loss 0.07260  dice_loss 0.13336 
Epoch [238/300] Validation [14/16] Loss: 0.44593  focal_loss 0.17081  dice_loss 0.27512 
Epoch [238/300] Validation [15/16] Loss: 0.10765  focal_loss 0.04041  dice_loss 0.06725 
Epoch [238/300] Validation [16/16] Loss: 0.05689  focal_loss 0.02294  dice_loss 0.03395 
Epoch [238/300] Validation metric {'Val/mean dice_metric': 0.9421879649162292, 'Val/mean miou_metric': 0.9054659008979797, 'Val/mean f1': 0.9479116201400757, 'Val/mean precision': 0.9513576030731201, 'Val/mean recall': 0.9444904923439026, 'Val/mean hd95_metric': 11.077558517456055}
Cheakpoint...
Epoch [238/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9422], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9421879649162292, 'Val/mean miou_metric': 0.9054659008979797, 'Val/mean f1': 0.9479116201400757, 'Val/mean precision': 0.9513576030731201, 'Val/mean recall': 0.9444904923439026, 'Val/mean hd95_metric': 11.077558517456055}
Epoch [239/300] Training [1/62] Loss: 0.03444 
Epoch [239/300] Training [2/62] Loss: 0.02996 
Epoch [239/300] Training [3/62] Loss: 0.02783 
Epoch [239/300] Training [4/62] Loss: 0.02805 
Epoch [239/300] Training [5/62] Loss: 0.03840 
Epoch [239/300] Training [6/62] Loss: 0.07766 
Epoch [239/300] Training [7/62] Loss: 0.03872 
Epoch [239/300] Training [8/62] Loss: 0.02823 
Epoch [239/300] Training [9/62] Loss: 0.04233 
Epoch [239/300] Training [10/62] Loss: 0.07472 
Epoch [239/300] Training [11/62] Loss: 0.03373 
Epoch [239/300] Training [12/62] Loss: 0.07088 
Epoch [239/300] Training [13/62] Loss: 0.04248 
Epoch [239/300] Training [14/62] Loss: 0.03439 
Epoch [239/300] Training [15/62] Loss: 0.04566 
Epoch [239/300] Training [16/62] Loss: 0.03554 
Epoch [239/300] Training [17/62] Loss: 0.03339 
Epoch [239/300] Training [18/62] Loss: 0.03959 
Epoch [239/300] Training [19/62] Loss: 0.04771 
Epoch [239/300] Training [20/62] Loss: 0.06514 
Epoch [239/300] Training [21/62] Loss: 0.03742 
Epoch [239/300] Training [22/62] Loss: 0.03313 
Epoch [239/300] Training [23/62] Loss: 0.04849 
Epoch [239/300] Training [24/62] Loss: 0.03879 
Epoch [239/300] Training [25/62] Loss: 0.03402 
Epoch [239/300] Training [26/62] Loss: 0.03133 
Epoch [239/300] Training [27/62] Loss: 0.05217 
Epoch [239/300] Training [28/62] Loss: 0.04004 
Epoch [239/300] Training [29/62] Loss: 0.03165 
Epoch [239/300] Training [30/62] Loss: 0.03896 
Epoch [239/300] Training [31/62] Loss: 0.04281 
Epoch [239/300] Training [32/62] Loss: 0.03931 
Epoch [239/300] Training [33/62] Loss: 0.04215 
Epoch [239/300] Training [34/62] Loss: 0.04582 
Epoch [239/300] Training [35/62] Loss: 0.02970 
Epoch [239/300] Training [36/62] Loss: 0.07268 
Epoch [239/300] Training [37/62] Loss: 0.02595 
Epoch [239/300] Training [38/62] Loss: 0.06718 
Epoch [239/300] Training [39/62] Loss: 0.03041 
Epoch [239/300] Training [40/62] Loss: 0.04092 
Epoch [239/300] Training [41/62] Loss: 0.05053 
Epoch [239/300] Training [42/62] Loss: 0.05410 
Epoch [239/300] Training [43/62] Loss: 0.04601 
Epoch [239/300] Training [44/62] Loss: 0.03354 
Epoch [239/300] Training [45/62] Loss: 0.03237 
Epoch [239/300] Training [46/62] Loss: 0.03971 
Epoch [239/300] Training [47/62] Loss: 0.05253 
Epoch [239/300] Training [48/62] Loss: 0.04036 
Epoch [239/300] Training [49/62] Loss: 0.07116 
Epoch [239/300] Training [50/62] Loss: 0.04575 
Epoch [239/300] Training [51/62] Loss: 0.03610 
Epoch [239/300] Training [52/62] Loss: 0.03773 
Epoch [239/300] Training [53/62] Loss: 0.03697 
Epoch [239/300] Training [54/62] Loss: 0.03646 
Epoch [239/300] Training [55/62] Loss: 0.05057 
Epoch [239/300] Training [56/62] Loss: 0.04391 
Epoch [239/300] Training [57/62] Loss: 0.04666 
Epoch [239/300] Training [58/62] Loss: 0.07077 
Epoch [239/300] Training [59/62] Loss: 0.03365 
Epoch [239/300] Training [60/62] Loss: 0.03672 
Epoch [239/300] Training [61/62] Loss: 0.04339 
Epoch [239/300] Training [62/62] Loss: 0.02079 
Epoch [239/300] Training metric {'Train/mean dice_metric': 0.97040855884552, 'Train/mean miou_metric': 0.9435917735099792, 'Train/mean f1': 0.9711037278175354, 'Train/mean precision': 0.9660971760749817, 'Train/mean recall': 0.9761624336242676, 'Train/mean hd95_metric': 4.8569793701171875}
Epoch [239/300] Validation [1/16] Loss: 0.45964  focal_loss 0.23137  dice_loss 0.22827 
Epoch [239/300] Validation [2/16] Loss: 0.39907  focal_loss 0.15968  dice_loss 0.23939 
Epoch [239/300] Validation [3/16] Loss: 0.74511  focal_loss 0.47337  dice_loss 0.27174 
Epoch [239/300] Validation [4/16] Loss: 0.43457  focal_loss 0.21645  dice_loss 0.21812 
Epoch [239/300] Validation [5/16] Loss: 0.30147  focal_loss 0.11058  dice_loss 0.19088 
Epoch [239/300] Validation [6/16] Loss: 0.20524  focal_loss 0.04470  dice_loss 0.16054 
Epoch [239/300] Validation [7/16] Loss: 0.18027  focal_loss 0.06715  dice_loss 0.11312 
Epoch [239/300] Validation [8/16] Loss: 0.25247  focal_loss 0.06622  dice_loss 0.18625 
Epoch [239/300] Validation [9/16] Loss: 0.18081  focal_loss 0.08657  dice_loss 0.09425 
Epoch [239/300] Validation [10/16] Loss: 0.30898  focal_loss 0.09008  dice_loss 0.21890 
Epoch [239/300] Validation [11/16] Loss: 0.10832  focal_loss 0.03886  dice_loss 0.06946 
Epoch [239/300] Validation [12/16] Loss: 0.32160  focal_loss 0.09049  dice_loss 0.23110 
Epoch [239/300] Validation [13/16] Loss: 0.31905  focal_loss 0.13552  dice_loss 0.18353 
Epoch [239/300] Validation [14/16] Loss: 0.53413  focal_loss 0.19578  dice_loss 0.33835 
Epoch [239/300] Validation [15/16] Loss: 0.17764  focal_loss 0.07369  dice_loss 0.10395 
Epoch [239/300] Validation [16/16] Loss: 0.05960  focal_loss 0.01654  dice_loss 0.04306 
Epoch [239/300] Validation metric {'Val/mean dice_metric': 0.9394611120223999, 'Val/mean miou_metric': 0.902306079864502, 'Val/mean f1': 0.9462927579879761, 'Val/mean precision': 0.9522743821144104, 'Val/mean recall': 0.9403857588768005, 'Val/mean hd95_metric': 10.888524055480957}
Cheakpoint...
Epoch [239/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9395], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9394611120223999, 'Val/mean miou_metric': 0.902306079864502, 'Val/mean f1': 0.9462927579879761, 'Val/mean precision': 0.9522743821144104, 'Val/mean recall': 0.9403857588768005, 'Val/mean hd95_metric': 10.888524055480957}
Epoch [240/300] Training [1/62] Loss: 0.03457 
Epoch [240/300] Training [2/62] Loss: 0.02458 
Epoch [240/300] Training [3/62] Loss: 0.03071 
Epoch [240/300] Training [4/62] Loss: 0.04084 
Epoch [240/300] Training [5/62] Loss: 0.05309 
Epoch [240/300] Training [6/62] Loss: 0.07157 
Epoch [240/300] Training [7/62] Loss: 0.03569 
Epoch [240/300] Training [8/62] Loss: 0.02863 
Epoch [240/300] Training [9/62] Loss: 0.04132 
Epoch [240/300] Training [10/62] Loss: 0.04290 
Epoch [240/300] Training [11/62] Loss: 0.02999 
Epoch [240/300] Training [12/62] Loss: 0.04096 
Epoch [240/300] Training [13/62] Loss: 0.03218 
Epoch [240/300] Training [14/62] Loss: 0.03233 
Epoch [240/300] Training [15/62] Loss: 0.02992 
Epoch [240/300] Training [16/62] Loss: 0.04617 
Epoch [240/300] Training [17/62] Loss: 0.04777 
Epoch [240/300] Training [18/62] Loss: 0.03862 
Epoch [240/300] Training [19/62] Loss: 0.04192 
Epoch [240/300] Training [20/62] Loss: 0.13735 
Epoch [240/300] Training [21/62] Loss: 0.03720 
Epoch [240/300] Training [22/62] Loss: 0.05288 
Epoch [240/300] Training [23/62] Loss: 0.05122 
Epoch [240/300] Training [24/62] Loss: 0.03818 
Epoch [240/300] Training [25/62] Loss: 0.03323 
Epoch [240/300] Training [26/62] Loss: 0.04033 
Epoch [240/300] Training [27/62] Loss: 0.05178 
Epoch [240/300] Training [28/62] Loss: 0.03151 
Epoch [240/300] Training [29/62] Loss: 0.04475 
Epoch [240/300] Training [30/62] Loss: 0.03824 
Epoch [240/300] Training [31/62] Loss: 0.03419 
Epoch [240/300] Training [32/62] Loss: 0.04647 
Epoch [240/300] Training [33/62] Loss: 0.04573 
Epoch [240/300] Training [34/62] Loss: 0.07161 
Epoch [240/300] Training [35/62] Loss: 0.11353 
Epoch [240/300] Training [36/62] Loss: 0.04058 
Epoch [240/300] Training [37/62] Loss: 0.03222 
Epoch [240/300] Training [38/62] Loss: 0.06574 
Epoch [240/300] Training [39/62] Loss: 0.04656 
Epoch [240/300] Training [40/62] Loss: 0.03177 
Epoch [240/300] Training [41/62] Loss: 0.04431 
Epoch [240/300] Training [42/62] Loss: 0.06539 
Epoch [240/300] Training [43/62] Loss: 0.04272 
Epoch [240/300] Training [44/62] Loss: 0.04242 
Epoch [240/300] Training [45/62] Loss: 0.04068 
Epoch [240/300] Training [46/62] Loss: 0.03081 
Epoch [240/300] Training [47/62] Loss: 0.02829 
Epoch [240/300] Training [48/62] Loss: 0.04220 
Epoch [240/300] Training [49/62] Loss: 0.04202 
Epoch [240/300] Training [50/62] Loss: 0.03739 
Epoch [240/300] Training [51/62] Loss: 0.05699 
Epoch [240/300] Training [52/62] Loss: 0.03547 
Epoch [240/300] Training [53/62] Loss: 0.06132 
Epoch [240/300] Training [54/62] Loss: 0.02970 
Epoch [240/300] Training [55/62] Loss: 0.03485 
Epoch [240/300] Training [56/62] Loss: 0.03785 
Epoch [240/300] Training [57/62] Loss: 0.06335 
Epoch [240/300] Training [58/62] Loss: 0.03454 
Epoch [240/300] Training [59/62] Loss: 0.04818 
Epoch [240/300] Training [60/62] Loss: 0.03675 
Epoch [240/300] Training [61/62] Loss: 0.02968 
Epoch [240/300] Training [62/62] Loss: 0.03463 
Epoch [240/300] Training metric {'Train/mean dice_metric': 0.9691125750541687, 'Train/mean miou_metric': 0.9422523379325867, 'Train/mean f1': 0.9708506464958191, 'Train/mean precision': 0.9663527011871338, 'Train/mean recall': 0.9753907918930054, 'Train/mean hd95_metric': 4.96826171875}
Epoch [240/300] Validation [1/16] Loss: 0.58538  focal_loss 0.36014  dice_loss 0.22524 
Epoch [240/300] Validation [2/16] Loss: 0.42347  focal_loss 0.19209  dice_loss 0.23138 
Epoch [240/300] Validation [3/16] Loss: 0.36356  focal_loss 0.15660  dice_loss 0.20695 
Epoch [240/300] Validation [4/16] Loss: 0.30825  focal_loss 0.15561  dice_loss 0.15264 
Epoch [240/300] Validation [5/16] Loss: 0.35012  focal_loss 0.12588  dice_loss 0.22424 
Epoch [240/300] Validation [6/16] Loss: 0.21703  focal_loss 0.05210  dice_loss 0.16493 
Epoch [240/300] Validation [7/16] Loss: 0.26382  focal_loss 0.13589  dice_loss 0.12792 
Epoch [240/300] Validation [8/16] Loss: 0.33713  focal_loss 0.09879  dice_loss 0.23834 
Epoch [240/300] Validation [9/16] Loss: 0.14265  focal_loss 0.06429  dice_loss 0.07835 
Epoch [240/300] Validation [10/16] Loss: 0.17292  focal_loss 0.05670  dice_loss 0.11622 
Epoch [240/300] Validation [11/16] Loss: 0.15268  focal_loss 0.04553  dice_loss 0.10716 
Epoch [240/300] Validation [12/16] Loss: 0.23140  focal_loss 0.05566  dice_loss 0.17575 
Epoch [240/300] Validation [13/16] Loss: 0.34619  focal_loss 0.14981  dice_loss 0.19638 
Epoch [240/300] Validation [14/16] Loss: 0.41489  focal_loss 0.14010  dice_loss 0.27478 
Epoch [240/300] Validation [15/16] Loss: 0.10859  focal_loss 0.04026  dice_loss 0.06833 
Epoch [240/300] Validation [16/16] Loss: 0.03859  focal_loss 0.01109  dice_loss 0.02750 
Epoch [240/300] Validation metric {'Val/mean dice_metric': 0.9420222640037537, 'Val/mean miou_metric': 0.9053405523300171, 'Val/mean f1': 0.9478644728660583, 'Val/mean precision': 0.9513370394706726, 'Val/mean recall': 0.9444171190261841, 'Val/mean hd95_metric': 10.87833023071289}
Cheakpoint...
Epoch [240/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9420], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9420222640037537, 'Val/mean miou_metric': 0.9053405523300171, 'Val/mean f1': 0.9478644728660583, 'Val/mean precision': 0.9513370394706726, 'Val/mean recall': 0.9444171190261841, 'Val/mean hd95_metric': 10.87833023071289}
Epoch [241/300] Training [1/62] Loss: 0.04296 
Epoch [241/300] Training [2/62] Loss: 0.03650 
Epoch [241/300] Training [3/62] Loss: 0.03338 
Epoch [241/300] Training [4/62] Loss: 0.03734 
Epoch [241/300] Training [5/62] Loss: 0.03556 
Epoch [241/300] Training [6/62] Loss: 0.03352 
Epoch [241/300] Training [7/62] Loss: 0.02949 
Epoch [241/300] Training [8/62] Loss: 0.03458 
Epoch [241/300] Training [9/62] Loss: 0.03355 
Epoch [241/300] Training [10/62] Loss: 0.04936 
Epoch [241/300] Training [11/62] Loss: 0.03759 
Epoch [241/300] Training [12/62] Loss: 0.02858 
Epoch [241/300] Training [13/62] Loss: 0.03104 
Epoch [241/300] Training [14/62] Loss: 0.05078 
Epoch [241/300] Training [15/62] Loss: 0.03790 
Epoch [241/300] Training [16/62] Loss: 0.04823 
Epoch [241/300] Training [17/62] Loss: 0.06214 
Epoch [241/300] Training [18/62] Loss: 0.02981 
Epoch [241/300] Training [19/62] Loss: 0.04678 
Epoch [241/300] Training [20/62] Loss: 0.05019 
Epoch [241/300] Training [21/62] Loss: 0.03402 
Epoch [241/300] Training [22/62] Loss: 0.03423 
Epoch [241/300] Training [23/62] Loss: 0.03440 
Epoch [241/300] Training [24/62] Loss: 0.06166 
Epoch [241/300] Training [25/62] Loss: 0.03879 
Epoch [241/300] Training [26/62] Loss: 0.03823 
Epoch [241/300] Training [27/62] Loss: 0.03760 
Epoch [241/300] Training [28/62] Loss: 0.07725 
Epoch [241/300] Training [29/62] Loss: 0.03596 
Epoch [241/300] Training [30/62] Loss: 0.06184 
Epoch [241/300] Training [31/62] Loss: 0.03109 
Epoch [241/300] Training [32/62] Loss: 0.03252 
Epoch [241/300] Training [33/62] Loss: 0.07988 
Epoch [241/300] Training [34/62] Loss: 0.02904 
Epoch [241/300] Training [35/62] Loss: 0.04068 
Epoch [241/300] Training [36/62] Loss: 0.03687 
Epoch [241/300] Training [37/62] Loss: 0.03827 
Epoch [241/300] Training [38/62] Loss: 0.04463 
Epoch [241/300] Training [39/62] Loss: 0.04009 
Epoch [241/300] Training [40/62] Loss: 0.05837 
Epoch [241/300] Training [41/62] Loss: 0.05204 
Epoch [241/300] Training [42/62] Loss: 0.03102 
Epoch [241/300] Training [43/62] Loss: 0.04875 
Epoch [241/300] Training [44/62] Loss: 0.05817 
Epoch [241/300] Training [45/62] Loss: 0.03361 
Epoch [241/300] Training [46/62] Loss: 0.02839 
Epoch [241/300] Training [47/62] Loss: 0.03428 
Epoch [241/300] Training [48/62] Loss: 0.02957 
Epoch [241/300] Training [49/62] Loss: 0.03269 
Epoch [241/300] Training [50/62] Loss: 0.03746 
Epoch [241/300] Training [51/62] Loss: 0.03466 
Epoch [241/300] Training [52/62] Loss: 0.03248 
Epoch [241/300] Training [53/62] Loss: 0.02766 
Epoch [241/300] Training [54/62] Loss: 0.04810 
Epoch [241/300] Training [55/62] Loss: 0.05749 
Epoch [241/300] Training [56/62] Loss: 0.03140 
Epoch [241/300] Training [57/62] Loss: 0.03347 
Epoch [241/300] Training [58/62] Loss: 0.02845 
Epoch [241/300] Training [59/62] Loss: 0.05607 
Epoch [241/300] Training [60/62] Loss: 0.03625 
Epoch [241/300] Training [61/62] Loss: 0.03946 
Epoch [241/300] Training [62/62] Loss: 0.17238 
Epoch [241/300] Training metric {'Train/mean dice_metric': 0.9717585444450378, 'Train/mean miou_metric': 0.9457970261573792, 'Train/mean f1': 0.9718759655952454, 'Train/mean precision': 0.9679460525512695, 'Train/mean recall': 0.9758378863334656, 'Train/mean hd95_metric': 4.407846450805664}
Epoch [241/300] Validation [1/16] Loss: 0.20457  focal_loss 0.08880  dice_loss 0.11577 
Epoch [241/300] Validation [2/16] Loss: 0.31659  focal_loss 0.16597  dice_loss 0.15062 
Epoch [241/300] Validation [3/16] Loss: 0.66455  focal_loss 0.40833  dice_loss 0.25621 
Epoch [241/300] Validation [4/16] Loss: 0.34117  focal_loss 0.17767  dice_loss 0.16350 
Epoch [241/300] Validation [5/16] Loss: 0.31865  focal_loss 0.11125  dice_loss 0.20740 
Epoch [241/300] Validation [6/16] Loss: 0.25976  focal_loss 0.09113  dice_loss 0.16864 
Epoch [241/300] Validation [7/16] Loss: 0.36053  focal_loss 0.19437  dice_loss 0.16617 
Epoch [241/300] Validation [8/16] Loss: 0.36447  focal_loss 0.12498  dice_loss 0.23949 
Epoch [241/300] Validation [9/16] Loss: 0.23114  focal_loss 0.09728  dice_loss 0.13385 
Epoch [241/300] Validation [10/16] Loss: 0.19243  focal_loss 0.06782  dice_loss 0.12460 
Epoch [241/300] Validation [11/16] Loss: 0.13596  focal_loss 0.04805  dice_loss 0.08791 
Epoch [241/300] Validation [12/16] Loss: 0.25826  focal_loss 0.05537  dice_loss 0.20289 
Epoch [241/300] Validation [13/16] Loss: 0.34417  focal_loss 0.14326  dice_loss 0.20091 
Epoch [241/300] Validation [14/16] Loss: 0.45696  focal_loss 0.15976  dice_loss 0.29720 
Epoch [241/300] Validation [15/16] Loss: 0.11708  focal_loss 0.04157  dice_loss 0.07551 
Epoch [241/300] Validation [16/16] Loss: 0.05400  focal_loss 0.02011  dice_loss 0.03389 
Epoch [241/300] Validation metric {'Val/mean dice_metric': 0.9440758228302002, 'Val/mean miou_metric': 0.9076265096664429, 'Val/mean f1': 0.9470147490501404, 'Val/mean precision': 0.9460474848747253, 'Val/mean recall': 0.947983980178833, 'Val/mean hd95_metric': 11.228193283081055}
Cheakpoint...
Epoch [241/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9441], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9440758228302002, 'Val/mean miou_metric': 0.9076265096664429, 'Val/mean f1': 0.9470147490501404, 'Val/mean precision': 0.9460474848747253, 'Val/mean recall': 0.947983980178833, 'Val/mean hd95_metric': 11.228193283081055}
Epoch [242/300] Training [1/62] Loss: 0.03980 
Epoch [242/300] Training [2/62] Loss: 0.03605 
Epoch [242/300] Training [3/62] Loss: 0.03093 
Epoch [242/300] Training [4/62] Loss: 0.02667 
Epoch [242/300] Training [5/62] Loss: 0.03156 
Epoch [242/300] Training [6/62] Loss: 0.04939 
Epoch [242/300] Training [7/62] Loss: 0.05636 
Epoch [242/300] Training [8/62] Loss: 0.04120 
Epoch [242/300] Training [9/62] Loss: 0.03356 
Epoch [242/300] Training [10/62] Loss: 0.04009 
Epoch [242/300] Training [11/62] Loss: 0.10294 
Epoch [242/300] Training [12/62] Loss: 0.03539 
Epoch [242/300] Training [13/62] Loss: 0.03258 
Epoch [242/300] Training [14/62] Loss: 0.05373 
Epoch [242/300] Training [15/62] Loss: 0.06828 
Epoch [242/300] Training [16/62] Loss: 0.02995 
Epoch [242/300] Training [17/62] Loss: 0.04010 
Epoch [242/300] Training [18/62] Loss: 0.02627 
Epoch [242/300] Training [19/62] Loss: 0.04841 
Epoch [242/300] Training [20/62] Loss: 0.07176 
Epoch [242/300] Training [21/62] Loss: 0.02912 
Epoch [242/300] Training [22/62] Loss: 0.03204 
Epoch [242/300] Training [23/62] Loss: 0.03129 
Epoch [242/300] Training [24/62] Loss: 0.03387 
Epoch [242/300] Training [25/62] Loss: 0.03566 
Epoch [242/300] Training [26/62] Loss: 0.03716 
Epoch [242/300] Training [27/62] Loss: 0.03170 
Epoch [242/300] Training [28/62] Loss: 0.03375 
Epoch [242/300] Training [29/62] Loss: 0.03611 
Epoch [242/300] Training [30/62] Loss: 0.02691 
Epoch [242/300] Training [31/62] Loss: 0.03069 
Epoch [242/300] Training [32/62] Loss: 0.03854 
Epoch [242/300] Training [33/62] Loss: 0.03214 
Epoch [242/300] Training [34/62] Loss: 0.03133 
Epoch [242/300] Training [35/62] Loss: 0.02363 
Epoch [242/300] Training [36/62] Loss: 0.03307 
Epoch [242/300] Training [37/62] Loss: 0.03472 
Epoch [242/300] Training [38/62] Loss: 0.03848 
Epoch [242/300] Training [39/62] Loss: 0.03758 
Epoch [242/300] Training [40/62] Loss: 0.05180 
Epoch [242/300] Training [41/62] Loss: 0.04010 
Epoch [242/300] Training [42/62] Loss: 0.03879 
Epoch [242/300] Training [43/62] Loss: 0.03854 
Epoch [242/300] Training [44/62] Loss: 0.03449 
Epoch [242/300] Training [45/62] Loss: 0.05239 
Epoch [242/300] Training [46/62] Loss: 0.04384 
Epoch [242/300] Training [47/62] Loss: 0.05838 
Epoch [242/300] Training [48/62] Loss: 0.03921 
Epoch [242/300] Training [49/62] Loss: 0.03935 
Epoch [242/300] Training [50/62] Loss: 0.02563 
Epoch [242/300] Training [51/62] Loss: 0.03645 
Epoch [242/300] Training [52/62] Loss: 0.02842 
Epoch [242/300] Training [53/62] Loss: 0.04815 
Epoch [242/300] Training [54/62] Loss: 0.03830 
Epoch [242/300] Training [55/62] Loss: 0.04419 
Epoch [242/300] Training [56/62] Loss: 0.04798 
Epoch [242/300] Training [57/62] Loss: 0.03106 
Epoch [242/300] Training [58/62] Loss: 0.02760 
Epoch [242/300] Training [59/62] Loss: 0.02765 
Epoch [242/300] Training [60/62] Loss: 0.05151 
Epoch [242/300] Training [61/62] Loss: 0.07984 
Epoch [242/300] Training [62/62] Loss: 0.20899 
Epoch [242/300] Training metric {'Train/mean dice_metric': 0.972047746181488, 'Train/mean miou_metric': 0.9464771151542664, 'Train/mean f1': 0.9724094867706299, 'Train/mean precision': 0.9672169089317322, 'Train/mean recall': 0.9776581525802612, 'Train/mean hd95_metric': 4.194995880126953}
Epoch [242/300] Validation [1/16] Loss: 0.22331  focal_loss 0.11311  dice_loss 0.11020 
Epoch [242/300] Validation [2/16] Loss: 0.46695  focal_loss 0.22845  dice_loss 0.23850 
Epoch [242/300] Validation [3/16] Loss: 0.77079  focal_loss 0.46875  dice_loss 0.30204 
Epoch [242/300] Validation [4/16] Loss: 0.40165  focal_loss 0.19909  dice_loss 0.20255 
Epoch [242/300] Validation [5/16] Loss: 0.31885  focal_loss 0.11597  dice_loss 0.20288 
Epoch [242/300] Validation [6/16] Loss: 0.19103  focal_loss 0.06022  dice_loss 0.13082 
Epoch [242/300] Validation [7/16] Loss: 0.34786  focal_loss 0.18075  dice_loss 0.16711 
Epoch [242/300] Validation [8/16] Loss: 0.40312  focal_loss 0.14720  dice_loss 0.25592 
Epoch [242/300] Validation [9/16] Loss: 0.17987  focal_loss 0.08542  dice_loss 0.09445 
Epoch [242/300] Validation [10/16] Loss: 0.32884  focal_loss 0.11436  dice_loss 0.21447 
Epoch [242/300] Validation [11/16] Loss: 0.10067  focal_loss 0.03328  dice_loss 0.06739 
Epoch [242/300] Validation [12/16] Loss: 0.29393  focal_loss 0.07430  dice_loss 0.21963 
Epoch [242/300] Validation [13/16] Loss: 0.33686  focal_loss 0.13711  dice_loss 0.19975 
Epoch [242/300] Validation [14/16] Loss: 0.42079  focal_loss 0.14740  dice_loss 0.27339 
Epoch [242/300] Validation [15/16] Loss: 0.10197  focal_loss 0.03827  dice_loss 0.06370 
Epoch [242/300] Validation [16/16] Loss: 0.04308  focal_loss 0.01419  dice_loss 0.02889 
Epoch [242/300] Validation metric {'Val/mean dice_metric': 0.942109227180481, 'Val/mean miou_metric': 0.9062241911888123, 'Val/mean f1': 0.9470832347869873, 'Val/mean precision': 0.9478340744972229, 'Val/mean recall': 0.9463337063789368, 'Val/mean hd95_metric': 10.390302658081055}
Cheakpoint...
Epoch [242/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9421], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.942109227180481, 'Val/mean miou_metric': 0.9062241911888123, 'Val/mean f1': 0.9470832347869873, 'Val/mean precision': 0.9478340744972229, 'Val/mean recall': 0.9463337063789368, 'Val/mean hd95_metric': 10.390302658081055}
Epoch [243/300] Training [1/62] Loss: 0.07769 
Epoch [243/300] Training [2/62] Loss: 0.04101 
Epoch [243/300] Training [3/62] Loss: 0.03216 
Epoch [243/300] Training [4/62] Loss: 0.03682 
Epoch [243/300] Training [5/62] Loss: 0.04394 
Epoch [243/300] Training [6/62] Loss: 0.02677 
Epoch [243/300] Training [7/62] Loss: 0.02912 
Epoch [243/300] Training [8/62] Loss: 0.02844 
Epoch [243/300] Training [9/62] Loss: 0.04182 
Epoch [243/300] Training [10/62] Loss: 0.03313 
Epoch [243/300] Training [11/62] Loss: 0.06192 
Epoch [243/300] Training [12/62] Loss: 0.06978 
Epoch [243/300] Training [13/62] Loss: 0.02545 
Epoch [243/300] Training [14/62] Loss: 0.02517 
Epoch [243/300] Training [15/62] Loss: 0.06142 
Epoch [243/300] Training [16/62] Loss: 0.03196 
Epoch [243/300] Training [17/62] Loss: 0.02922 
Epoch [243/300] Training [18/62] Loss: 0.02712 
Epoch [243/300] Training [19/62] Loss: 0.06394 
Epoch [243/300] Training [20/62] Loss: 0.03466 
Epoch [243/300] Training [21/62] Loss: 0.04010 
Epoch [243/300] Training [22/62] Loss: 0.02838 
Epoch [243/300] Training [23/62] Loss: 0.03576 
Epoch [243/300] Training [24/62] Loss: 0.03531 
Epoch [243/300] Training [25/62] Loss: 0.03493 
Epoch [243/300] Training [26/62] Loss: 0.03419 
Epoch [243/300] Training [27/62] Loss: 0.04649 
Epoch [243/300] Training [28/62] Loss: 0.03633 
Epoch [243/300] Training [29/62] Loss: 0.03650 
Epoch [243/300] Training [30/62] Loss: 0.03643 
Epoch [243/300] Training [31/62] Loss: 0.03165 
Epoch [243/300] Training [32/62] Loss: 0.03642 
Epoch [243/300] Training [33/62] Loss: 0.05215 
Epoch [243/300] Training [34/62] Loss: 0.06973 
Epoch [243/300] Training [35/62] Loss: 0.02747 
Epoch [243/300] Training [36/62] Loss: 0.09173 
Epoch [243/300] Training [37/62] Loss: 0.05031 
Epoch [243/300] Training [38/62] Loss: 0.03479 
Epoch [243/300] Training [39/62] Loss: 0.10140 
Epoch [243/300] Training [40/62] Loss: 0.02914 
Epoch [243/300] Training [41/62] Loss: 0.03752 
Epoch [243/300] Training [42/62] Loss: 0.03428 
Epoch [243/300] Training [43/62] Loss: 0.05039 
Epoch [243/300] Training [44/62] Loss: 0.04089 
Epoch [243/300] Training [45/62] Loss: 0.04430 
Epoch [243/300] Training [46/62] Loss: 0.03363 
Epoch [243/300] Training [47/62] Loss: 0.03852 
Epoch [243/300] Training [48/62] Loss: 0.04647 
Epoch [243/300] Training [49/62] Loss: 0.06798 
Epoch [243/300] Training [50/62] Loss: 0.04998 
Epoch [243/300] Training [51/62] Loss: 0.04255 
Epoch [243/300] Training [52/62] Loss: 0.05469 
Epoch [243/300] Training [53/62] Loss: 0.04805 
Epoch [243/300] Training [54/62] Loss: 0.03094 
Epoch [243/300] Training [55/62] Loss: 0.04364 
Epoch [243/300] Training [56/62] Loss: 0.03287 
Epoch [243/300] Training [57/62] Loss: 0.02999 
Epoch [243/300] Training [58/62] Loss: 0.03939 
Epoch [243/300] Training [59/62] Loss: 0.03512 
Epoch [243/300] Training [60/62] Loss: 0.02950 
Epoch [243/300] Training [61/62] Loss: 0.03032 
Epoch [243/300] Training [62/62] Loss: 0.02309 
Epoch [243/300] Training metric {'Train/mean dice_metric': 0.9708700180053711, 'Train/mean miou_metric': 0.9448100328445435, 'Train/mean f1': 0.9719336032867432, 'Train/mean precision': 0.9676681756973267, 'Train/mean recall': 0.9762368202209473, 'Train/mean hd95_metric': 4.75933313369751}
Epoch [243/300] Validation [1/16] Loss: 0.44510  focal_loss 0.29255  dice_loss 0.15255 
Epoch [243/300] Validation [2/16] Loss: 0.42523  focal_loss 0.19032  dice_loss 0.23491 
Epoch [243/300] Validation [3/16] Loss: 0.70813  focal_loss 0.42599  dice_loss 0.28214 
Epoch [243/300] Validation [4/16] Loss: 0.32353  focal_loss 0.16151  dice_loss 0.16202 
Epoch [243/300] Validation [5/16] Loss: 0.31329  focal_loss 0.12574  dice_loss 0.18754 
Epoch [243/300] Validation [6/16] Loss: 0.21459  focal_loss 0.05786  dice_loss 0.15673 
Epoch [243/300] Validation [7/16] Loss: 0.18018  focal_loss 0.07468  dice_loss 0.10549 
Epoch [243/300] Validation [8/16] Loss: 0.29506  focal_loss 0.09101  dice_loss 0.20405 
Epoch [243/300] Validation [9/16] Loss: 0.15262  focal_loss 0.06982  dice_loss 0.08280 
Epoch [243/300] Validation [10/16] Loss: 0.46562  focal_loss 0.20609  dice_loss 0.25953 
Epoch [243/300] Validation [11/16] Loss: 0.12726  focal_loss 0.04325  dice_loss 0.08401 
Epoch [243/300] Validation [12/16] Loss: 0.29994  focal_loss 0.07306  dice_loss 0.22688 
Epoch [243/300] Validation [13/16] Loss: 0.33899  focal_loss 0.14371  dice_loss 0.19528 
Epoch [243/300] Validation [14/16] Loss: 0.53589  focal_loss 0.18427  dice_loss 0.35162 
Epoch [243/300] Validation [15/16] Loss: 0.09287  focal_loss 0.03361  dice_loss 0.05926 
Epoch [243/300] Validation [16/16] Loss: 0.03491  focal_loss 0.00981  dice_loss 0.02510 
Epoch [243/300] Validation metric {'Val/mean dice_metric': 0.9414559006690979, 'Val/mean miou_metric': 0.9060298204421997, 'Val/mean f1': 0.9467720985412598, 'Val/mean precision': 0.9470473527908325, 'Val/mean recall': 0.9464970231056213, 'Val/mean hd95_metric': 10.80788803100586}
Cheakpoint...
Epoch [243/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9415], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9414559006690979, 'Val/mean miou_metric': 0.9060298204421997, 'Val/mean f1': 0.9467720985412598, 'Val/mean precision': 0.9470473527908325, 'Val/mean recall': 0.9464970231056213, 'Val/mean hd95_metric': 10.80788803100586}
Epoch [244/300] Training [1/62] Loss: 0.03569 
Epoch [244/300] Training [2/62] Loss: 0.03181 
Epoch [244/300] Training [3/62] Loss: 0.03820 
Epoch [244/300] Training [4/62] Loss: 0.03946 
Epoch [244/300] Training [5/62] Loss: 0.03373 
Epoch [244/300] Training [6/62] Loss: 0.03604 
Epoch [244/300] Training [7/62] Loss: 0.04051 
Epoch [244/300] Training [8/62] Loss: 0.03486 
Epoch [244/300] Training [9/62] Loss: 0.04465 
Epoch [244/300] Training [10/62] Loss: 0.04744 
Epoch [244/300] Training [11/62] Loss: 0.04882 
Epoch [244/300] Training [12/62] Loss: 0.03273 
Epoch [244/300] Training [13/62] Loss: 0.03246 
Epoch [244/300] Training [14/62] Loss: 0.04295 
Epoch [244/300] Training [15/62] Loss: 0.06223 
Epoch [244/300] Training [16/62] Loss: 0.03024 
Epoch [244/300] Training [17/62] Loss: 0.03997 
Epoch [244/300] Training [18/62] Loss: 0.03493 
Epoch [244/300] Training [19/62] Loss: 0.03084 
Epoch [244/300] Training [20/62] Loss: 0.03249 
Epoch [244/300] Training [21/62] Loss: 0.03096 
Epoch [244/300] Training [22/62] Loss: 0.03507 
Epoch [244/300] Training [23/62] Loss: 0.04396 
Epoch [244/300] Training [24/62] Loss: 0.04125 
Epoch [244/300] Training [25/62] Loss: 0.03449 
Epoch [244/300] Training [26/62] Loss: 0.04180 
Epoch [244/300] Training [27/62] Loss: 0.03880 
Epoch [244/300] Training [28/62] Loss: 0.09503 
Epoch [244/300] Training [29/62] Loss: 0.04568 
Epoch [244/300] Training [30/62] Loss: 0.03454 
Epoch [244/300] Training [31/62] Loss: 0.02733 
Epoch [244/300] Training [32/62] Loss: 0.05246 
Epoch [244/300] Training [33/62] Loss: 0.02808 
Epoch [244/300] Training [34/62] Loss: 0.04040 
Epoch [244/300] Training [35/62] Loss: 0.02677 
Epoch [244/300] Training [36/62] Loss: 0.04396 
Epoch [244/300] Training [37/62] Loss: 0.03235 
Epoch [244/300] Training [38/62] Loss: 0.03050 
Epoch [244/300] Training [39/62] Loss: 0.02425 
Epoch [244/300] Training [40/62] Loss: 0.03843 
Epoch [244/300] Training [41/62] Loss: 0.02630 
Epoch [244/300] Training [42/62] Loss: 0.03370 
Epoch [244/300] Training [43/62] Loss: 0.03430 
Epoch [244/300] Training [44/62] Loss: 0.04113 
Epoch [244/300] Training [45/62] Loss: 0.03374 
Epoch [244/300] Training [46/62] Loss: 0.02698 
Epoch [244/300] Training [47/62] Loss: 0.02906 
Epoch [244/300] Training [48/62] Loss: 0.03613 
Epoch [244/300] Training [49/62] Loss: 0.02813 
Epoch [244/300] Training [50/62] Loss: 0.02624 
Epoch [244/300] Training [51/62] Loss: 0.03772 
Epoch [244/300] Training [52/62] Loss: 0.03093 
Epoch [244/300] Training [53/62] Loss: 0.13662 
Epoch [244/300] Training [54/62] Loss: 0.03306 
Epoch [244/300] Training [55/62] Loss: 0.03243 
Epoch [244/300] Training [56/62] Loss: 0.03662 
Epoch [244/300] Training [57/62] Loss: 0.02683 
Epoch [244/300] Training [58/62] Loss: 0.06329 
Epoch [244/300] Training [59/62] Loss: 0.03314 
Epoch [244/300] Training [60/62] Loss: 0.06518 
Epoch [244/300] Training [61/62] Loss: 0.03620 
Epoch [244/300] Training [62/62] Loss: 0.04333 
Epoch [244/300] Training metric {'Train/mean dice_metric': 0.9726546406745911, 'Train/mean miou_metric': 0.9480173587799072, 'Train/mean f1': 0.973400890827179, 'Train/mean precision': 0.9690666198730469, 'Train/mean recall': 0.9777740836143494, 'Train/mean hd95_metric': 4.512322902679443}
Epoch [244/300] Validation [1/16] Loss: 0.24528  focal_loss 0.11406  dice_loss 0.13121 
Epoch [244/300] Validation [2/16] Loss: 0.37895  focal_loss 0.15551  dice_loss 0.22344 
Epoch [244/300] Validation [3/16] Loss: 0.69222  focal_loss 0.41449  dice_loss 0.27773 
Epoch [244/300] Validation [4/16] Loss: 0.33546  focal_loss 0.17419  dice_loss 0.16127 
Epoch [244/300] Validation [5/16] Loss: 0.33165  focal_loss 0.12875  dice_loss 0.20290 
Epoch [244/300] Validation [6/16] Loss: 0.24969  focal_loss 0.05825  dice_loss 0.19145 
Epoch [244/300] Validation [7/16] Loss: 0.36396  focal_loss 0.19569  dice_loss 0.16827 
Epoch [244/300] Validation [8/16] Loss: 0.33290  focal_loss 0.11275  dice_loss 0.22016 
Epoch [244/300] Validation [9/16] Loss: 0.23023  focal_loss 0.09569  dice_loss 0.13454 
Epoch [244/300] Validation [10/16] Loss: 0.19287  focal_loss 0.07132  dice_loss 0.12155 
Epoch [244/300] Validation [11/16] Loss: 0.10809  focal_loss 0.03796  dice_loss 0.07013 
Epoch [244/300] Validation [12/16] Loss: 0.35007  focal_loss 0.10418  dice_loss 0.24589 
Epoch [244/300] Validation [13/16] Loss: 0.31773  focal_loss 0.12380  dice_loss 0.19393 
Epoch [244/300] Validation [14/16] Loss: 0.60050  focal_loss 0.21983  dice_loss 0.38067 
Epoch [244/300] Validation [15/16] Loss: 0.13130  focal_loss 0.05002  dice_loss 0.08129 
Epoch [244/300] Validation [16/16] Loss: 0.04224  focal_loss 0.01326  dice_loss 0.02898 
Epoch [244/300] Validation metric {'Val/mean dice_metric': 0.9419093132019043, 'Val/mean miou_metric': 0.906967282295227, 'Val/mean f1': 0.9480984210968018, 'Val/mean precision': 0.9478816390037537, 'Val/mean recall': 0.9483152627944946, 'Val/mean hd95_metric': 11.29358959197998}
Cheakpoint...
Epoch [244/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9419], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9419093132019043, 'Val/mean miou_metric': 0.906967282295227, 'Val/mean f1': 0.9480984210968018, 'Val/mean precision': 0.9478816390037537, 'Val/mean recall': 0.9483152627944946, 'Val/mean hd95_metric': 11.29358959197998}
Epoch [245/300] Training [1/62] Loss: 0.04748 
Epoch [245/300] Training [2/62] Loss: 0.03014 
Epoch [245/300] Training [3/62] Loss: 0.03538 
Epoch [245/300] Training [4/62] Loss: 0.07993 
Epoch [245/300] Training [5/62] Loss: 0.03622 
Epoch [245/300] Training [6/62] Loss: 0.02959 
Epoch [245/300] Training [7/62] Loss: 0.04127 
Epoch [245/300] Training [8/62] Loss: 0.04147 
Epoch [245/300] Training [9/62] Loss: 0.05714 
Epoch [245/300] Training [10/62] Loss: 0.03731 
Epoch [245/300] Training [11/62] Loss: 0.03665 
Epoch [245/300] Training [12/62] Loss: 0.03980 
Epoch [245/300] Training [13/62] Loss: 0.03738 
Epoch [245/300] Training [14/62] Loss: 0.02879 
Epoch [245/300] Training [15/62] Loss: 0.03422 
Epoch [245/300] Training [16/62] Loss: 0.04255 
Epoch [245/300] Training [17/62] Loss: 0.03194 
Epoch [245/300] Training [18/62] Loss: 0.06287 
Epoch [245/300] Training [19/62] Loss: 0.10392 
Epoch [245/300] Training [20/62] Loss: 0.06364 
Epoch [245/300] Training [21/62] Loss: 0.03495 
Epoch [245/300] Training [22/62] Loss: 0.04108 
Epoch [245/300] Training [23/62] Loss: 0.08038 
Epoch [245/300] Training [24/62] Loss: 0.05337 
Epoch [245/300] Training [25/62] Loss: 0.03208 
Epoch [245/300] Training [26/62] Loss: 0.05210 
Epoch [245/300] Training [27/62] Loss: 0.04104 
Epoch [245/300] Training [28/62] Loss: 0.05303 
Epoch [245/300] Training [29/62] Loss: 0.02853 
Epoch [245/300] Training [30/62] Loss: 0.19071 
Epoch [245/300] Training [31/62] Loss: 0.02726 
Epoch [245/300] Training [32/62] Loss: 0.04805 
Epoch [245/300] Training [33/62] Loss: 0.02433 
Epoch [245/300] Training [34/62] Loss: 0.04739 
Epoch [245/300] Training [35/62] Loss: 0.03585 
Epoch [245/300] Training [36/62] Loss: 0.04576 
Epoch [245/300] Training [37/62] Loss: 0.04949 
Epoch [245/300] Training [38/62] Loss: 0.03369 
Epoch [245/300] Training [39/62] Loss: 0.04498 
Epoch [245/300] Training [40/62] Loss: 0.04237 
Epoch [245/300] Training [41/62] Loss: 0.02826 
Epoch [245/300] Training [42/62] Loss: 0.02936 
Epoch [245/300] Training [43/62] Loss: 0.05588 
Epoch [245/300] Training [44/62] Loss: 0.03392 
Epoch [245/300] Training [45/62] Loss: 0.03344 
Epoch [245/300] Training [46/62] Loss: 0.02957 
Epoch [245/300] Training [47/62] Loss: 0.04291 
Epoch [245/300] Training [48/62] Loss: 0.03495 
Epoch [245/300] Training [49/62] Loss: 0.03349 
Epoch [245/300] Training [50/62] Loss: 0.03048 
Epoch [245/300] Training [51/62] Loss: 0.03005 
Epoch [245/300] Training [52/62] Loss: 0.03828 
Epoch [245/300] Training [53/62] Loss: 0.05572 
Epoch [245/300] Training [54/62] Loss: 0.05094 
Epoch [245/300] Training [55/62] Loss: 0.03530 
Epoch [245/300] Training [56/62] Loss: 0.05769 
Epoch [245/300] Training [57/62] Loss: 0.02896 
Epoch [245/300] Training [58/62] Loss: 0.04413 
Epoch [245/300] Training [59/62] Loss: 0.02778 
Epoch [245/300] Training [60/62] Loss: 0.03435 
Epoch [245/300] Training [61/62] Loss: 0.02783 
Epoch [245/300] Training [62/62] Loss: 0.03002 
Epoch [245/300] Training metric {'Train/mean dice_metric': 0.9693347811698914, 'Train/mean miou_metric': 0.9432973861694336, 'Train/mean f1': 0.9711586236953735, 'Train/mean precision': 0.9669429063796997, 'Train/mean recall': 0.9754112362861633, 'Train/mean hd95_metric': 4.838255882263184}
Epoch [245/300] Validation [1/16] Loss: 0.17358  focal_loss 0.07772  dice_loss 0.09586 
Epoch [245/300] Validation [2/16] Loss: 0.37420  focal_loss 0.14363  dice_loss 0.23057 
Epoch [245/300] Validation [3/16] Loss: 0.40710  focal_loss 0.18838  dice_loss 0.21873 
Epoch [245/300] Validation [4/16] Loss: 0.36259  focal_loss 0.19238  dice_loss 0.17021 
Epoch [245/300] Validation [5/16] Loss: 0.34057  focal_loss 0.13364  dice_loss 0.20693 
Epoch [245/300] Validation [6/16] Loss: 0.29503  focal_loss 0.09797  dice_loss 0.19706 
Epoch [245/300] Validation [7/16] Loss: 0.30576  focal_loss 0.15038  dice_loss 0.15538 
Epoch [245/300] Validation [8/16] Loss: 0.38266  focal_loss 0.11966  dice_loss 0.26301 
Epoch [245/300] Validation [9/16] Loss: 0.19310  focal_loss 0.09833  dice_loss 0.09477 
Epoch [245/300] Validation [10/16] Loss: 0.21308  focal_loss 0.08353  dice_loss 0.12954 
Epoch [245/300] Validation [11/16] Loss: 0.13829  focal_loss 0.04754  dice_loss 0.09076 
Epoch [245/300] Validation [12/16] Loss: 0.33132  focal_loss 0.10054  dice_loss 0.23078 
Epoch [245/300] Validation [13/16] Loss: 0.29932  focal_loss 0.11076  dice_loss 0.18856 
Epoch [245/300] Validation [14/16] Loss: 0.46173  focal_loss 0.15676  dice_loss 0.30497 
Epoch [245/300] Validation [15/16] Loss: 0.09163  focal_loss 0.03256  dice_loss 0.05907 
Epoch [245/300] Validation [16/16] Loss: 0.03911  focal_loss 0.01155  dice_loss 0.02756 
Epoch [245/300] Validation metric {'Val/mean dice_metric': 0.9415121674537659, 'Val/mean miou_metric': 0.9048938751220703, 'Val/mean f1': 0.9482496380805969, 'Val/mean precision': 0.948115348815918, 'Val/mean recall': 0.9483839869499207, 'Val/mean hd95_metric': 11.599864959716797}
Cheakpoint...
Epoch [245/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9415], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9415121674537659, 'Val/mean miou_metric': 0.9048938751220703, 'Val/mean f1': 0.9482496380805969, 'Val/mean precision': 0.948115348815918, 'Val/mean recall': 0.9483839869499207, 'Val/mean hd95_metric': 11.599864959716797}
Epoch [246/300] Training [1/62] Loss: 0.05523 
Epoch [246/300] Training [2/62] Loss: 0.02899 
Epoch [246/300] Training [3/62] Loss: 0.03788 
Epoch [246/300] Training [4/62] Loss: 0.03645 
Epoch [246/300] Training [5/62] Loss: 0.03565 
Epoch [246/300] Training [6/62] Loss: 0.03546 
Epoch [246/300] Training [7/62] Loss: 0.03042 
Epoch [246/300] Training [8/62] Loss: 0.03073 
Epoch [246/300] Training [9/62] Loss: 0.03797 
Epoch [246/300] Training [10/62] Loss: 0.03397 
Epoch [246/300] Training [11/62] Loss: 0.04781 
Epoch [246/300] Training [12/62] Loss: 0.06879 
Epoch [246/300] Training [13/62] Loss: 0.03836 
Epoch [246/300] Training [14/62] Loss: 0.03602 
Epoch [246/300] Training [15/62] Loss: 0.03125 
Epoch [246/300] Training [16/62] Loss: 0.04367 
Epoch [246/300] Training [17/62] Loss: 0.03707 
Epoch [246/300] Training [18/62] Loss: 0.03980 
Epoch [246/300] Training [19/62] Loss: 0.03734 
Epoch [246/300] Training [20/62] Loss: 0.06500 
Epoch [246/300] Training [21/62] Loss: 0.05358 
Epoch [246/300] Training [22/62] Loss: 0.04963 
Epoch [246/300] Training [23/62] Loss: 0.03828 
Epoch [246/300] Training [24/62] Loss: 0.02828 
Epoch [246/300] Training [25/62] Loss: 0.04669 
Epoch [246/300] Training [26/62] Loss: 0.06219 
Epoch [246/300] Training [27/62] Loss: 0.02616 
Epoch [246/300] Training [28/62] Loss: 0.03010 
Epoch [246/300] Training [29/62] Loss: 0.03580 
Epoch [246/300] Training [30/62] Loss: 0.03593 
Epoch [246/300] Training [31/62] Loss: 0.03186 
Epoch [246/300] Training [32/62] Loss: 0.03289 
Epoch [246/300] Training [33/62] Loss: 0.02976 
Epoch [246/300] Training [34/62] Loss: 0.02560 
Epoch [246/300] Training [35/62] Loss: 0.03353 
Epoch [246/300] Training [36/62] Loss: 0.03698 
Epoch [246/300] Training [37/62] Loss: 0.04223 
Epoch [246/300] Training [38/62] Loss: 0.03252 
Epoch [246/300] Training [39/62] Loss: 0.03446 
Epoch [246/300] Training [40/62] Loss: 0.03904 
Epoch [246/300] Training [41/62] Loss: 0.02928 
Epoch [246/300] Training [42/62] Loss: 0.02869 
Epoch [246/300] Training [43/62] Loss: 0.03967 
Epoch [246/300] Training [44/62] Loss: 0.03384 
Epoch [246/300] Training [45/62] Loss: 0.07617 
Epoch [246/300] Training [46/62] Loss: 0.03737 
Epoch [246/300] Training [47/62] Loss: 0.03174 
Epoch [246/300] Training [48/62] Loss: 0.04657 
Epoch [246/300] Training [49/62] Loss: 0.03138 
Epoch [246/300] Training [50/62] Loss: 0.05188 
Epoch [246/300] Training [51/62] Loss: 0.03145 
Epoch [246/300] Training [52/62] Loss: 0.03135 
Epoch [246/300] Training [53/62] Loss: 0.03163 
Epoch [246/300] Training [54/62] Loss: 0.03306 
Epoch [246/300] Training [55/62] Loss: 0.03348 
Epoch [246/300] Training [56/62] Loss: 0.04561 
Epoch [246/300] Training [57/62] Loss: 0.02804 
Epoch [246/300] Training [58/62] Loss: 0.08351 
Epoch [246/300] Training [59/62] Loss: 0.02895 
Epoch [246/300] Training [60/62] Loss: 0.02634 
Epoch [246/300] Training [61/62] Loss: 0.03211 
Epoch [246/300] Training [62/62] Loss: 0.02843 
Epoch [246/300] Training metric {'Train/mean dice_metric': 0.973331093788147, 'Train/mean miou_metric': 0.9487852454185486, 'Train/mean f1': 0.9734939932823181, 'Train/mean precision': 0.9689770936965942, 'Train/mean recall': 0.978053092956543, 'Train/mean hd95_metric': 4.093313694000244}
Epoch [246/300] Validation [1/16] Loss: 0.18748  focal_loss 0.08276  dice_loss 0.10471 
Epoch [246/300] Validation [2/16] Loss: 0.43941  focal_loss 0.20866  dice_loss 0.23074 
Epoch [246/300] Validation [3/16] Loss: 0.54930  focal_loss 0.27961  dice_loss 0.26969 
Epoch [246/300] Validation [4/16] Loss: 0.25857  focal_loss 0.12216  dice_loss 0.13641 
Epoch [246/300] Validation [5/16] Loss: 0.38241  focal_loss 0.15684  dice_loss 0.22557 
Epoch [246/300] Validation [6/16] Loss: 0.15334  focal_loss 0.04077  dice_loss 0.11258 
Epoch [246/300] Validation [7/16] Loss: 0.30324  focal_loss 0.16344  dice_loss 0.13981 
Epoch [246/300] Validation [8/16] Loss: 0.39025  focal_loss 0.10874  dice_loss 0.28151 
Epoch [246/300] Validation [9/16] Loss: 0.14017  focal_loss 0.05627  dice_loss 0.08389 
Epoch [246/300] Validation [10/16] Loss: 0.22144  focal_loss 0.07789  dice_loss 0.14355 
Epoch [246/300] Validation [11/16] Loss: 0.10103  focal_loss 0.03331  dice_loss 0.06772 
Epoch [246/300] Validation [12/16] Loss: 0.33532  focal_loss 0.08192  dice_loss 0.25341 
Epoch [246/300] Validation [13/16] Loss: 0.31419  focal_loss 0.13164  dice_loss 0.18255 
Epoch [246/300] Validation [14/16] Loss: 0.54670  focal_loss 0.20141  dice_loss 0.34529 
Epoch [246/300] Validation [15/16] Loss: 0.09430  focal_loss 0.02924  dice_loss 0.06506 
Epoch [246/300] Validation [16/16] Loss: 0.05416  focal_loss 0.02135  dice_loss 0.03281 
Epoch [246/300] Validation metric {'Val/mean dice_metric': 0.9449113607406616, 'Val/mean miou_metric': 0.9103768467903137, 'Val/mean f1': 0.9503302574157715, 'Val/mean precision': 0.9522534012794495, 'Val/mean recall': 0.9484149217605591, 'Val/mean hd95_metric': 10.367476463317871}
Cheakpoint...
Epoch [246/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9449], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9449113607406616, 'Val/mean miou_metric': 0.9103768467903137, 'Val/mean f1': 0.9503302574157715, 'Val/mean precision': 0.9522534012794495, 'Val/mean recall': 0.9484149217605591, 'Val/mean hd95_metric': 10.367476463317871}
Epoch [247/300] Training [1/62] Loss: 0.04016 
Epoch [247/300] Training [2/62] Loss: 0.02928 
Epoch [247/300] Training [3/62] Loss: 0.03572 
Epoch [247/300] Training [4/62] Loss: 0.03677 
Epoch [247/300] Training [5/62] Loss: 0.02852 
Epoch [247/300] Training [6/62] Loss: 0.02452 
Epoch [247/300] Training [7/62] Loss: 0.02538 
Epoch [247/300] Training [8/62] Loss: 0.02486 
Epoch [247/300] Training [9/62] Loss: 0.03459 
Epoch [247/300] Training [10/62] Loss: 0.05815 
Epoch [247/300] Training [11/62] Loss: 0.05124 
Epoch [247/300] Training [12/62] Loss: 0.03055 
Epoch [247/300] Training [13/62] Loss: 0.02775 
Epoch [247/300] Training [14/62] Loss: 0.02774 
Epoch [247/300] Training [15/62] Loss: 0.08174 
Epoch [247/300] Training [16/62] Loss: 0.02929 
Epoch [247/300] Training [17/62] Loss: 0.11291 
Epoch [247/300] Training [18/62] Loss: 0.06583 
Epoch [247/300] Training [19/62] Loss: 0.03133 
Epoch [247/300] Training [20/62] Loss: 0.03905 
Epoch [247/300] Training [21/62] Loss: 0.03785 
Epoch [247/300] Training [22/62] Loss: 0.03916 
Epoch [247/300] Training [23/62] Loss: 0.04938 
Epoch [247/300] Training [24/62] Loss: 0.03220 
Epoch [247/300] Training [25/62] Loss: 0.05479 
Epoch [247/300] Training [26/62] Loss: 0.02418 
Epoch [247/300] Training [27/62] Loss: 0.02989 
Epoch [247/300] Training [28/62] Loss: 0.04384 
Epoch [247/300] Training [29/62] Loss: 0.02941 
Epoch [247/300] Training [30/62] Loss: 0.02848 
Epoch [247/300] Training [31/62] Loss: 0.03824 
Epoch [247/300] Training [32/62] Loss: 0.06348 
Epoch [247/300] Training [33/62] Loss: 0.03536 
Epoch [247/300] Training [34/62] Loss: 0.03861 
Epoch [247/300] Training [35/62] Loss: 0.02385 
Epoch [247/300] Training [36/62] Loss: 0.05427 
Epoch [247/300] Training [37/62] Loss: 0.04395 
Epoch [247/300] Training [38/62] Loss: 0.03092 
Epoch [247/300] Training [39/62] Loss: 0.03496 
Epoch [247/300] Training [40/62] Loss: 0.04184 
Epoch [247/300] Training [41/62] Loss: 0.03694 
Epoch [247/300] Training [42/62] Loss: 0.03610 
Epoch [247/300] Training [43/62] Loss: 0.06574 
Epoch [247/300] Training [44/62] Loss: 0.03517 
Epoch [247/300] Training [45/62] Loss: 0.04344 
Epoch [247/300] Training [46/62] Loss: 0.03554 
Epoch [247/300] Training [47/62] Loss: 0.03864 
Epoch [247/300] Training [48/62] Loss: 0.02747 
Epoch [247/300] Training [49/62] Loss: 0.05073 
Epoch [247/300] Training [50/62] Loss: 0.05056 
Epoch [247/300] Training [51/62] Loss: 0.03824 
Epoch [247/300] Training [52/62] Loss: 0.02512 
Epoch [247/300] Training [53/62] Loss: 0.03548 
Epoch [247/300] Training [54/62] Loss: 0.02862 
Epoch [247/300] Training [55/62] Loss: 0.04296 
Epoch [247/300] Training [56/62] Loss: 0.03284 
Epoch [247/300] Training [57/62] Loss: 0.03185 
Epoch [247/300] Training [58/62] Loss: 0.03313 
Epoch [247/300] Training [59/62] Loss: 0.02720 
Epoch [247/300] Training [60/62] Loss: 0.03629 
Epoch [247/300] Training [61/62] Loss: 0.03774 
Epoch [247/300] Training [62/62] Loss: 0.06308 
Epoch [247/300] Training metric {'Train/mean dice_metric': 0.9730240106582642, 'Train/mean miou_metric': 0.9484434723854065, 'Train/mean f1': 0.9731671810150146, 'Train/mean precision': 0.9688353538513184, 'Train/mean recall': 0.9775378704071045, 'Train/mean hd95_metric': 4.116979122161865}
Epoch [247/300] Validation [1/16] Loss: 0.48645  focal_loss 0.30467  dice_loss 0.18179 
Epoch [247/300] Validation [2/16] Loss: 0.49185  focal_loss 0.23158  dice_loss 0.26027 
Epoch [247/300] Validation [3/16] Loss: 0.38562  focal_loss 0.15909  dice_loss 0.22653 
Epoch [247/300] Validation [4/16] Loss: 0.32478  focal_loss 0.16785  dice_loss 0.15693 
Epoch [247/300] Validation [5/16] Loss: 0.40123  focal_loss 0.15373  dice_loss 0.24750 
Epoch [247/300] Validation [6/16] Loss: 0.22490  focal_loss 0.06068  dice_loss 0.16421 
Epoch [247/300] Validation [7/16] Loss: 0.30671  focal_loss 0.15512  dice_loss 0.15159 
Epoch [247/300] Validation [8/16] Loss: 0.39818  focal_loss 0.13216  dice_loss 0.26602 
Epoch [247/300] Validation [9/16] Loss: 0.16395  focal_loss 0.06753  dice_loss 0.09642 
Epoch [247/300] Validation [10/16] Loss: 0.22915  focal_loss 0.07309  dice_loss 0.15607 
Epoch [247/300] Validation [11/16] Loss: 0.12694  focal_loss 0.03965  dice_loss 0.08729 
Epoch [247/300] Validation [12/16] Loss: 0.28155  focal_loss 0.05998  dice_loss 0.22157 
Epoch [247/300] Validation [13/16] Loss: 0.32818  focal_loss 0.13824  dice_loss 0.18994 
Epoch [247/300] Validation [14/16] Loss: 0.43737  focal_loss 0.16225  dice_loss 0.27512 
Epoch [247/300] Validation [15/16] Loss: 0.10008  focal_loss 0.03762  dice_loss 0.06246 
Epoch [247/300] Validation [16/16] Loss: 0.08222  focal_loss 0.03276  dice_loss 0.04946 
Epoch [247/300] Validation metric {'Val/mean dice_metric': 0.9430773258209229, 'Val/mean miou_metric': 0.9079826474189758, 'Val/mean f1': 0.9470083117485046, 'Val/mean precision': 0.9475427269935608, 'Val/mean recall': 0.946474552154541, 'Val/mean hd95_metric': 11.138806343078613}
Cheakpoint...
Epoch [247/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9431], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9430773258209229, 'Val/mean miou_metric': 0.9079826474189758, 'Val/mean f1': 0.9470083117485046, 'Val/mean precision': 0.9475427269935608, 'Val/mean recall': 0.946474552154541, 'Val/mean hd95_metric': 11.138806343078613}
Epoch [248/300] Training [1/62] Loss: 0.04263 
Epoch [248/300] Training [2/62] Loss: 0.03844 
Epoch [248/300] Training [3/62] Loss: 0.03915 
Epoch [248/300] Training [4/62] Loss: 0.03325 
Epoch [248/300] Training [5/62] Loss: 0.03059 
Epoch [248/300] Training [6/62] Loss: 0.02674 
Epoch [248/300] Training [7/62] Loss: 0.04209 
Epoch [248/300] Training [8/62] Loss: 0.03145 
Epoch [248/300] Training [9/62] Loss: 0.03053 
Epoch [248/300] Training [10/62] Loss: 0.04844 
Epoch [248/300] Training [11/62] Loss: 0.08010 
Epoch [248/300] Training [12/62] Loss: 0.03229 
Epoch [248/300] Training [13/62] Loss: 0.02972 
Epoch [248/300] Training [14/62] Loss: 0.02486 
Epoch [248/300] Training [15/62] Loss: 0.04163 
Epoch [248/300] Training [16/62] Loss: 0.03044 
Epoch [248/300] Training [17/62] Loss: 0.03663 
Epoch [248/300] Training [18/62] Loss: 0.06531 
Epoch [248/300] Training [19/62] Loss: 0.02853 
Epoch [248/300] Training [20/62] Loss: 0.04452 
Epoch [248/300] Training [21/62] Loss: 0.03243 
Epoch [248/300] Training [22/62] Loss: 0.03785 
Epoch [248/300] Training [23/62] Loss: 0.03298 
Epoch [248/300] Training [24/62] Loss: 0.03576 
Epoch [248/300] Training [25/62] Loss: 0.03215 
Epoch [248/300] Training [26/62] Loss: 0.03891 
Epoch [248/300] Training [27/62] Loss: 0.04829 
Epoch [248/300] Training [28/62] Loss: 0.04626 
Epoch [248/300] Training [29/62] Loss: 0.02373 
Epoch [248/300] Training [30/62] Loss: 0.02574 
Epoch [248/300] Training [31/62] Loss: 0.03089 
Epoch [248/300] Training [32/62] Loss: 0.03685 
Epoch [248/300] Training [33/62] Loss: 0.04199 
Epoch [248/300] Training [34/62] Loss: 0.03626 
Epoch [248/300] Training [35/62] Loss: 0.03263 
Epoch [248/300] Training [36/62] Loss: 0.04226 
Epoch [248/300] Training [37/62] Loss: 0.05405 
Epoch [248/300] Training [38/62] Loss: 0.03266 
Epoch [248/300] Training [39/62] Loss: 0.04084 
Epoch [248/300] Training [40/62] Loss: 0.04536 
Epoch [248/300] Training [41/62] Loss: 0.10822 
Epoch [248/300] Training [42/62] Loss: 0.03111 
Epoch [248/300] Training [43/62] Loss: 0.03537 
Epoch [248/300] Training [44/62] Loss: 0.05359 
Epoch [248/300] Training [45/62] Loss: 0.03538 
Epoch [248/300] Training [46/62] Loss: 0.03654 
Epoch [248/300] Training [47/62] Loss: 0.03844 
Epoch [248/300] Training [48/62] Loss: 0.03726 
Epoch [248/300] Training [49/62] Loss: 0.03599 
Epoch [248/300] Training [50/62] Loss: 0.03983 
Epoch [248/300] Training [51/62] Loss: 0.03159 
Epoch [248/300] Training [52/62] Loss: 0.02678 
Epoch [248/300] Training [53/62] Loss: 0.03418 
Epoch [248/300] Training [54/62] Loss: 0.05683 
Epoch [248/300] Training [55/62] Loss: 0.03639 
Epoch [248/300] Training [56/62] Loss: 0.03991 
Epoch [248/300] Training [57/62] Loss: 0.03993 
Epoch [248/300] Training [58/62] Loss: 0.03683 
Epoch [248/300] Training [59/62] Loss: 0.03976 
Epoch [248/300] Training [60/62] Loss: 0.09010 
Epoch [248/300] Training [61/62] Loss: 0.04824 
Epoch [248/300] Training [62/62] Loss: 0.03236 
Epoch [248/300] Training metric {'Train/mean dice_metric': 0.972294807434082, 'Train/mean miou_metric': 0.94733065366745, 'Train/mean f1': 0.973097562789917, 'Train/mean precision': 0.9686431288719177, 'Train/mean recall': 0.977593183517456, 'Train/mean hd95_metric': 4.661444187164307}
Epoch [248/300] Validation [1/16] Loss: 0.20087  focal_loss 0.08553  dice_loss 0.11534 
Epoch [248/300] Validation [2/16] Loss: 0.33697  focal_loss 0.20113  dice_loss 0.13585 
Epoch [248/300] Validation [3/16] Loss: 0.65862  focal_loss 0.37748  dice_loss 0.28114 
Epoch [248/300] Validation [4/16] Loss: 0.34580  focal_loss 0.17068  dice_loss 0.17512 
Epoch [248/300] Validation [5/16] Loss: 0.27724  focal_loss 0.07555  dice_loss 0.20169 
Epoch [248/300] Validation [6/16] Loss: 0.21265  focal_loss 0.05717  dice_loss 0.15548 
Epoch [248/300] Validation [7/16] Loss: 0.16134  focal_loss 0.06158  dice_loss 0.09976 
Epoch [248/300] Validation [8/16] Loss: 0.28732  focal_loss 0.08306  dice_loss 0.20426 
Epoch [248/300] Validation [9/16] Loss: 0.25076  focal_loss 0.11174  dice_loss 0.13902 
Epoch [248/300] Validation [10/16] Loss: 0.35481  focal_loss 0.13668  dice_loss 0.21812 
Epoch [248/300] Validation [11/16] Loss: 0.10189  focal_loss 0.03413  dice_loss 0.06776 
Epoch [248/300] Validation [12/16] Loss: 0.29729  focal_loss 0.08651  dice_loss 0.21078 
Epoch [248/300] Validation [13/16] Loss: 0.34400  focal_loss 0.14828  dice_loss 0.19573 
Epoch [248/300] Validation [14/16] Loss: 0.55996  focal_loss 0.22488  dice_loss 0.33508 
Epoch [248/300] Validation [15/16] Loss: 0.10596  focal_loss 0.03704  dice_loss 0.06892 
Epoch [248/300] Validation [16/16] Loss: 0.05276  focal_loss 0.02031  dice_loss 0.03245 
Epoch [248/300] Validation metric {'Val/mean dice_metric': 0.944434642791748, 'Val/mean miou_metric': 0.9088891744613647, 'Val/mean f1': 0.9478775858879089, 'Val/mean precision': 0.9465567469596863, 'Val/mean recall': 0.9492020606994629, 'Val/mean hd95_metric': 11.279930114746094}
Cheakpoint...
Epoch [248/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9444], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.944434642791748, 'Val/mean miou_metric': 0.9088891744613647, 'Val/mean f1': 0.9478775858879089, 'Val/mean precision': 0.9465567469596863, 'Val/mean recall': 0.9492020606994629, 'Val/mean hd95_metric': 11.279930114746094}
Epoch [249/300] Training [1/62] Loss: 0.07486 
Epoch [249/300] Training [2/62] Loss: 0.02485 
Epoch [249/300] Training [3/62] Loss: 0.02517 
Epoch [249/300] Training [4/62] Loss: 0.02723 
Epoch [249/300] Training [5/62] Loss: 0.04102 
Epoch [249/300] Training [6/62] Loss: 0.03353 
Epoch [249/300] Training [7/62] Loss: 0.03484 
Epoch [249/300] Training [8/62] Loss: 0.06524 
Epoch [249/300] Training [9/62] Loss: 0.03682 
Epoch [249/300] Training [10/62] Loss: 0.02642 
Epoch [249/300] Training [11/62] Loss: 0.03016 
Epoch [249/300] Training [12/62] Loss: 0.05608 
Epoch [249/300] Training [13/62] Loss: 0.03111 
Epoch [249/300] Training [14/62] Loss: 0.03061 
Epoch [249/300] Training [15/62] Loss: 0.03526 
Epoch [249/300] Training [16/62] Loss: 0.03121 
Epoch [249/300] Training [17/62] Loss: 0.03683 
Epoch [249/300] Training [18/62] Loss: 0.04289 
Epoch [249/300] Training [19/62] Loss: 0.03093 
Epoch [249/300] Training [20/62] Loss: 0.02775 
Epoch [249/300] Training [21/62] Loss: 0.02942 
Epoch [249/300] Training [22/62] Loss: 0.04052 
Epoch [249/300] Training [23/62] Loss: 0.03129 
Epoch [249/300] Training [24/62] Loss: 0.02760 
Epoch [249/300] Training [25/62] Loss: 0.02683 
Epoch [249/300] Training [26/62] Loss: 0.06623 
Epoch [249/300] Training [27/62] Loss: 0.03475 
Epoch [249/300] Training [28/62] Loss: 0.04405 
Epoch [249/300] Training [29/62] Loss: 0.03568 
Epoch [249/300] Training [30/62] Loss: 0.04611 
Epoch [249/300] Training [31/62] Loss: 0.03887 
Epoch [249/300] Training [32/62] Loss: 0.10113 
Epoch [249/300] Training [33/62] Loss: 0.03539 
Epoch [249/300] Training [34/62] Loss: 0.04937 
Epoch [249/300] Training [35/62] Loss: 0.03563 
Epoch [249/300] Training [36/62] Loss: 0.03776 
Epoch [249/300] Training [37/62] Loss: 0.03017 
Epoch [249/300] Training [38/62] Loss: 0.04760 
Epoch [249/300] Training [39/62] Loss: 0.02994 
Epoch [249/300] Training [40/62] Loss: 0.05036 
Epoch [249/300] Training [41/62] Loss: 0.02739 
Epoch [249/300] Training [42/62] Loss: 0.02804 
Epoch [249/300] Training [43/62] Loss: 0.02465 
Epoch [249/300] Training [44/62] Loss: 0.03959 
Epoch [249/300] Training [45/62] Loss: 0.03687 
Epoch [249/300] Training [46/62] Loss: 0.03045 
Epoch [249/300] Training [47/62] Loss: 0.03011 
Epoch [249/300] Training [48/62] Loss: 0.03789 
Epoch [249/300] Training [49/62] Loss: 0.04063 
Epoch [249/300] Training [50/62] Loss: 0.02991 
Epoch [249/300] Training [51/62] Loss: 0.07501 
Epoch [249/300] Training [52/62] Loss: 0.03379 
Epoch [249/300] Training [53/62] Loss: 0.03022 
Epoch [249/300] Training [54/62] Loss: 0.03440 
Epoch [249/300] Training [55/62] Loss: 0.04121 
Epoch [249/300] Training [56/62] Loss: 0.03977 
Epoch [249/300] Training [57/62] Loss: 0.03154 
Epoch [249/300] Training [58/62] Loss: 0.03641 
Epoch [249/300] Training [59/62] Loss: 0.05289 
Epoch [249/300] Training [60/62] Loss: 0.04402 
Epoch [249/300] Training [61/62] Loss: 0.03577 
Epoch [249/300] Training [62/62] Loss: 0.04322 
Epoch [249/300] Training metric {'Train/mean dice_metric': 0.9735031127929688, 'Train/mean miou_metric': 0.9493604898452759, 'Train/mean f1': 0.9735470414161682, 'Train/mean precision': 0.968673050403595, 'Train/mean recall': 0.9784703850746155, 'Train/mean hd95_metric': 4.227433204650879}
Epoch [249/300] Validation [1/16] Loss: 0.66716  focal_loss 0.42200  dice_loss 0.24516 
Epoch [249/300] Validation [2/16] Loss: 0.35449  focal_loss 0.20901  dice_loss 0.14548 
Epoch [249/300] Validation [3/16] Loss: 0.70737  focal_loss 0.42814  dice_loss 0.27922 
Epoch [249/300] Validation [4/16] Loss: 0.31181  focal_loss 0.15970  dice_loss 0.15211 
Epoch [249/300] Validation [5/16] Loss: 0.33776  focal_loss 0.12099  dice_loss 0.21677 
Epoch [249/300] Validation [6/16] Loss: 0.20885  focal_loss 0.05506  dice_loss 0.15378 
Epoch [249/300] Validation [7/16] Loss: 0.19427  focal_loss 0.07871  dice_loss 0.11556 
Epoch [249/300] Validation [8/16] Loss: 0.33326  focal_loss 0.10279  dice_loss 0.23047 
Epoch [249/300] Validation [9/16] Loss: 0.15535  focal_loss 0.07055  dice_loss 0.08481 
Epoch [249/300] Validation [10/16] Loss: 0.22013  focal_loss 0.08098  dice_loss 0.13915 
Epoch [249/300] Validation [11/16] Loss: 0.12532  focal_loss 0.03781  dice_loss 0.08751 
Epoch [249/300] Validation [12/16] Loss: 0.32467  focal_loss 0.10261  dice_loss 0.22206 
Epoch [249/300] Validation [13/16] Loss: 0.32986  focal_loss 0.13498  dice_loss 0.19487 
Epoch [249/300] Validation [14/16] Loss: 0.52104  focal_loss 0.19755  dice_loss 0.32349 
Epoch [249/300] Validation [15/16] Loss: 0.26216  focal_loss 0.11212  dice_loss 0.15003 
Epoch [249/300] Validation [16/16] Loss: 0.05104  focal_loss 0.01984  dice_loss 0.03120 
Epoch [249/300] Validation metric {'Val/mean dice_metric': 0.943413257598877, 'Val/mean miou_metric': 0.908385157585144, 'Val/mean f1': 0.947236955165863, 'Val/mean precision': 0.9508521556854248, 'Val/mean recall': 0.943649172782898, 'Val/mean hd95_metric': 10.880082130432129}
Cheakpoint...
Epoch [249/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9434], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.943413257598877, 'Val/mean miou_metric': 0.908385157585144, 'Val/mean f1': 0.947236955165863, 'Val/mean precision': 0.9508521556854248, 'Val/mean recall': 0.943649172782898, 'Val/mean hd95_metric': 10.880082130432129}
Epoch [250/300] Training [1/62] Loss: 0.03762 
Epoch [250/300] Training [2/62] Loss: 0.02996 
Epoch [250/300] Training [3/62] Loss: 0.03161 
Epoch [250/300] Training [4/62] Loss: 0.03011 
Epoch [250/300] Training [5/62] Loss: 0.06882 
Epoch [250/300] Training [6/62] Loss: 0.02636 
Epoch [250/300] Training [7/62] Loss: 0.06071 
Epoch [250/300] Training [8/62] Loss: 0.03919 
Epoch [250/300] Training [9/62] Loss: 0.06603 
Epoch [250/300] Training [10/62] Loss: 0.02970 
Epoch [250/300] Training [11/62] Loss: 0.04530 
Epoch [250/300] Training [12/62] Loss: 0.02875 
Epoch [250/300] Training [13/62] Loss: 0.03635 
Epoch [250/300] Training [14/62] Loss: 0.07620 
Epoch [250/300] Training [15/62] Loss: 0.06702 
Epoch [250/300] Training [16/62] Loss: 0.03416 
Epoch [250/300] Training [17/62] Loss: 0.03620 
Epoch [250/300] Training [18/62] Loss: 0.03866 
Epoch [250/300] Training [19/62] Loss: 0.02642 
Epoch [250/300] Training [20/62] Loss: 0.04133 
Epoch [250/300] Training [21/62] Loss: 0.03220 
Epoch [250/300] Training [22/62] Loss: 0.02883 
Epoch [250/300] Training [23/62] Loss: 0.03990 
Epoch [250/300] Training [24/62] Loss: 0.03429 
Epoch [250/300] Training [25/62] Loss: 0.02746 
Epoch [250/300] Training [26/62] Loss: 0.05898 
Epoch [250/300] Training [27/62] Loss: 0.02833 
Epoch [250/300] Training [28/62] Loss: 0.03193 
Epoch [250/300] Training [29/62] Loss: 0.03351 
Epoch [250/300] Training [30/62] Loss: 0.04391 
Epoch [250/300] Training [31/62] Loss: 0.02992 
Epoch [250/300] Training [32/62] Loss: 0.02757 
Epoch [250/300] Training [33/62] Loss: 0.02983 
Epoch [250/300] Training [34/62] Loss: 0.08743 
Epoch [250/300] Training [35/62] Loss: 0.04859 
Epoch [250/300] Training [36/62] Loss: 0.03760 
Epoch [250/300] Training [37/62] Loss: 0.03561 
Epoch [250/300] Training [38/62] Loss: 0.02539 
Epoch [250/300] Training [39/62] Loss: 0.03189 
Epoch [250/300] Training [40/62] Loss: 0.03776 
Epoch [250/300] Training [41/62] Loss: 0.03271 
Epoch [250/300] Training [42/62] Loss: 0.03190 
Epoch [250/300] Training [43/62] Loss: 0.03858 
Epoch [250/300] Training [44/62] Loss: 0.03759 
Epoch [250/300] Training [45/62] Loss: 0.07269 
Epoch [250/300] Training [46/62] Loss: 0.04816 
Epoch [250/300] Training [47/62] Loss: 0.05081 
Epoch [250/300] Training [48/62] Loss: 0.03126 
Epoch [250/300] Training [49/62] Loss: 0.02859 
Epoch [250/300] Training [50/62] Loss: 0.04060 
Epoch [250/300] Training [51/62] Loss: 0.02750 
Epoch [250/300] Training [52/62] Loss: 0.03139 
Epoch [250/300] Training [53/62] Loss: 0.04661 
Epoch [250/300] Training [54/62] Loss: 0.03595 
Epoch [250/300] Training [55/62] Loss: 0.04808 
Epoch [250/300] Training [56/62] Loss: 0.03502 
Epoch [250/300] Training [57/62] Loss: 0.03667 
Epoch [250/300] Training [58/62] Loss: 0.04184 
Epoch [250/300] Training [59/62] Loss: 0.03947 
Epoch [250/300] Training [60/62] Loss: 0.02971 
Epoch [250/300] Training [61/62] Loss: 0.04392 
Epoch [250/300] Training [62/62] Loss: 0.01859 
Epoch [250/300] Training metric {'Train/mean dice_metric': 0.9722763299942017, 'Train/mean miou_metric': 0.9476199746131897, 'Train/mean f1': 0.973316490650177, 'Train/mean precision': 0.9689589142799377, 'Train/mean recall': 0.9777134656906128, 'Train/mean hd95_metric': 4.324863433837891}
Epoch [250/300] Validation [1/16] Loss: 0.51379  focal_loss 0.33409  dice_loss 0.17970 
Epoch [250/300] Validation [2/16] Loss: 0.41748  focal_loss 0.17625  dice_loss 0.24123 
Epoch [250/300] Validation [3/16] Loss: 0.70898  focal_loss 0.42566  dice_loss 0.28332 
Epoch [250/300] Validation [4/16] Loss: 0.25979  focal_loss 0.12269  dice_loss 0.13709 
Epoch [250/300] Validation [5/16] Loss: 0.37512  focal_loss 0.15045  dice_loss 0.22468 
Epoch [250/300] Validation [6/16] Loss: 0.20947  focal_loss 0.05592  dice_loss 0.15354 
Epoch [250/300] Validation [7/16] Loss: 0.32969  focal_loss 0.17892  dice_loss 0.15078 
Epoch [250/300] Validation [8/16] Loss: 0.29792  focal_loss 0.08729  dice_loss 0.21063 
Epoch [250/300] Validation [9/16] Loss: 0.14509  focal_loss 0.06698  dice_loss 0.07811 
Epoch [250/300] Validation [10/16] Loss: 0.21716  focal_loss 0.08450  dice_loss 0.13266 
Epoch [250/300] Validation [11/16] Loss: 0.11180  focal_loss 0.03634  dice_loss 0.07547 
Epoch [250/300] Validation [12/16] Loss: 0.30350  focal_loss 0.10002  dice_loss 0.20349 
Epoch [250/300] Validation [13/16] Loss: 0.17167  focal_loss 0.05480  dice_loss 0.11687 
Epoch [250/300] Validation [14/16] Loss: 0.49577  focal_loss 0.19812  dice_loss 0.29765 
Epoch [250/300] Validation [15/16] Loss: 0.13069  focal_loss 0.05192  dice_loss 0.07877 
Epoch [250/300] Validation [16/16] Loss: 0.05548  focal_loss 0.02165  dice_loss 0.03382 
Epoch [250/300] Validation metric {'Val/mean dice_metric': 0.944539487361908, 'Val/mean miou_metric': 0.9102362394332886, 'Val/mean f1': 0.9496846199035645, 'Val/mean precision': 0.9517547488212585, 'Val/mean recall': 0.9476233720779419, 'Val/mean hd95_metric': 10.116252899169922}
Cheakpoint...
Epoch [250/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9445], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.944539487361908, 'Val/mean miou_metric': 0.9102362394332886, 'Val/mean f1': 0.9496846199035645, 'Val/mean precision': 0.9517547488212585, 'Val/mean recall': 0.9476233720779419, 'Val/mean hd95_metric': 10.116252899169922}
Epoch [251/300] Training [1/62] Loss: 0.04239 
Epoch [251/300] Training [2/62] Loss: 0.02965 
Epoch [251/300] Training [3/62] Loss: 0.02667 
Epoch [251/300] Training [4/62] Loss: 0.03352 
Epoch [251/300] Training [5/62] Loss: 0.03582 
Epoch [251/300] Training [6/62] Loss: 0.03914 
Epoch [251/300] Training [7/62] Loss: 0.06000 
Epoch [251/300] Training [8/62] Loss: 0.03078 
Epoch [251/300] Training [9/62] Loss: 0.02745 
Epoch [251/300] Training [10/62] Loss: 0.03116 
Epoch [251/300] Training [11/62] Loss: 0.06832 
Epoch [251/300] Training [12/62] Loss: 0.03821 
Epoch [251/300] Training [13/62] Loss: 0.03095 
Epoch [251/300] Training [14/62] Loss: 0.03114 
Epoch [251/300] Training [15/62] Loss: 0.04928 
Epoch [251/300] Training [16/62] Loss: 0.02837 
Epoch [251/300] Training [17/62] Loss: 0.04825 
Epoch [251/300] Training [18/62] Loss: 0.02430 
Epoch [251/300] Training [19/62] Loss: 0.04553 
Epoch [251/300] Training [20/62] Loss: 0.04102 
Epoch [251/300] Training [21/62] Loss: 0.03126 
Epoch [251/300] Training [22/62] Loss: 0.02589 
Epoch [251/300] Training [23/62] Loss: 0.03674 
Epoch [251/300] Training [24/62] Loss: 0.03026 
Epoch [251/300] Training [25/62] Loss: 0.03614 
Epoch [251/300] Training [26/62] Loss: 0.03578 
Epoch [251/300] Training [27/62] Loss: 0.03641 
Epoch [251/300] Training [28/62] Loss: 0.03074 
Epoch [251/300] Training [29/62] Loss: 0.02934 
Epoch [251/300] Training [30/62] Loss: 0.03860 
Epoch [251/300] Training [31/62] Loss: 0.02729 
Epoch [251/300] Training [32/62] Loss: 0.03306 
Epoch [251/300] Training [33/62] Loss: 0.03314 
Epoch [251/300] Training [34/62] Loss: 0.02560 
Epoch [251/300] Training [35/62] Loss: 0.03991 
Epoch [251/300] Training [36/62] Loss: 0.03229 
Epoch [251/300] Training [37/62] Loss: 0.05843 
Epoch [251/300] Training [38/62] Loss: 0.02692 
Epoch [251/300] Training [39/62] Loss: 0.04323 
Epoch [251/300] Training [40/62] Loss: 0.04731 
Epoch [251/300] Training [41/62] Loss: 0.04729 
Epoch [251/300] Training [42/62] Loss: 0.02928 
Epoch [251/300] Training [43/62] Loss: 0.09104 
Epoch [251/300] Training [44/62] Loss: 0.04363 
Epoch [251/300] Training [45/62] Loss: 0.03957 
Epoch [251/300] Training [46/62] Loss: 0.07223 
Epoch [251/300] Training [47/62] Loss: 0.02682 
Epoch [251/300] Training [48/62] Loss: 0.03628 
Epoch [251/300] Training [49/62] Loss: 0.03720 
Epoch [251/300] Training [50/62] Loss: 0.02963 
Epoch [251/300] Training [51/62] Loss: 0.02842 
Epoch [251/300] Training [52/62] Loss: 0.03630 
Epoch [251/300] Training [53/62] Loss: 0.03182 
Epoch [251/300] Training [54/62] Loss: 0.02790 
Epoch [251/300] Training [55/62] Loss: 0.02869 
Epoch [251/300] Training [56/62] Loss: 0.06569 
Epoch [251/300] Training [57/62] Loss: 0.05021 
Epoch [251/300] Training [58/62] Loss: 0.04045 
Epoch [251/300] Training [59/62] Loss: 0.03672 
Epoch [251/300] Training [60/62] Loss: 0.03402 
Epoch [251/300] Training [61/62] Loss: 0.03029 
Epoch [251/300] Training [62/62] Loss: 0.02092 
Epoch [251/300] Training metric {'Train/mean dice_metric': 0.9739274978637695, 'Train/mean miou_metric': 0.9500362873077393, 'Train/mean f1': 0.9739012718200684, 'Train/mean precision': 0.9696875810623169, 'Train/mean recall': 0.9781516790390015, 'Train/mean hd95_metric': 4.25244140625}
Epoch [251/300] Validation [1/16] Loss: 0.20053  focal_loss 0.09483  dice_loss 0.10570 
Epoch [251/300] Validation [2/16] Loss: 0.48669  focal_loss 0.23597  dice_loss 0.25072 
Epoch [251/300] Validation [3/16] Loss: 0.75020  focal_loss 0.45265  dice_loss 0.29755 
Epoch [251/300] Validation [4/16] Loss: 0.33179  focal_loss 0.18000  dice_loss 0.15179 
Epoch [251/300] Validation [5/16] Loss: 0.36667  focal_loss 0.15328  dice_loss 0.21338 
Epoch [251/300] Validation [6/16] Loss: 0.23458  focal_loss 0.07764  dice_loss 0.15694 
Epoch [251/300] Validation [7/16] Loss: 0.33714  focal_loss 0.18874  dice_loss 0.14840 
Epoch [251/300] Validation [8/16] Loss: 0.29442  focal_loss 0.08761  dice_loss 0.20681 
Epoch [251/300] Validation [9/16] Loss: 0.18431  focal_loss 0.08543  dice_loss 0.09889 
Epoch [251/300] Validation [10/16] Loss: 0.41331  focal_loss 0.16712  dice_loss 0.24619 
Epoch [251/300] Validation [11/16] Loss: 0.15275  focal_loss 0.04471  dice_loss 0.10804 
Epoch [251/300] Validation [12/16] Loss: 0.26985  focal_loss 0.06076  dice_loss 0.20909 
Epoch [251/300] Validation [13/16] Loss: 0.34921  focal_loss 0.14953  dice_loss 0.19968 
Epoch [251/300] Validation [14/16] Loss: 0.46178  focal_loss 0.17737  dice_loss 0.28441 
Epoch [251/300] Validation [15/16] Loss: 0.11938  focal_loss 0.04756  dice_loss 0.07182 
Epoch [251/300] Validation [16/16] Loss: 0.05700  focal_loss 0.02270  dice_loss 0.03430 
Epoch [251/300] Validation metric {'Val/mean dice_metric': 0.943644106388092, 'Val/mean miou_metric': 0.9093700647354126, 'Val/mean f1': 0.9480849504470825, 'Val/mean precision': 0.9469534754753113, 'Val/mean recall': 0.9492191672325134, 'Val/mean hd95_metric': 11.050597190856934}
Cheakpoint...
Epoch [251/300] best acc:tensor([0.9449], device='cuda:0'), Now : mean acc: tensor([0.9436], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.943644106388092, 'Val/mean miou_metric': 0.9093700647354126, 'Val/mean f1': 0.9480849504470825, 'Val/mean precision': 0.9469534754753113, 'Val/mean recall': 0.9492191672325134, 'Val/mean hd95_metric': 11.050597190856934}
Epoch [252/300] Training [1/62] Loss: 0.03804 
Epoch [252/300] Training [2/62] Loss: 0.03583 
Epoch [252/300] Training [3/62] Loss: 0.02990 
Epoch [252/300] Training [4/62] Loss: 0.03963 
Epoch [252/300] Training [5/62] Loss: 0.04685 
Epoch [252/300] Training [6/62] Loss: 0.04319 
Epoch [252/300] Training [7/62] Loss: 0.05897 
Epoch [252/300] Training [8/62] Loss: 0.03713 
Epoch [252/300] Training [9/62] Loss: 0.03212 
Epoch [252/300] Training [10/62] Loss: 0.03264 
Epoch [252/300] Training [11/62] Loss: 0.03078 
Epoch [252/300] Training [12/62] Loss: 0.03733 
Epoch [252/300] Training [13/62] Loss: 0.04467 
Epoch [252/300] Training [14/62] Loss: 0.03245 
Epoch [252/300] Training [15/62] Loss: 0.03651 
Epoch [252/300] Training [16/62] Loss: 0.03834 
Epoch [252/300] Training [17/62] Loss: 0.02444 
Epoch [252/300] Training [18/62] Loss: 0.02965 
Epoch [252/300] Training [19/62] Loss: 0.02896 
Epoch [252/300] Training [20/62] Loss: 0.02600 
Epoch [252/300] Training [21/62] Loss: 0.02355 
Epoch [252/300] Training [22/62] Loss: 0.04296 
Epoch [252/300] Training [23/62] Loss: 0.03529 
Epoch [252/300] Training [24/62] Loss: 0.03849 
Epoch [252/300] Training [25/62] Loss: 0.03919 
Epoch [252/300] Training [26/62] Loss: 0.02549 
Epoch [252/300] Training [27/62] Loss: 0.03407 
Epoch [252/300] Training [28/62] Loss: 0.03043 
Epoch [252/300] Training [29/62] Loss: 0.03221 
Epoch [252/300] Training [30/62] Loss: 0.03814 
Epoch [252/300] Training [31/62] Loss: 0.04392 
Epoch [252/300] Training [32/62] Loss: 0.01959 
Epoch [252/300] Training [33/62] Loss: 0.02851 
Epoch [252/300] Training [34/62] Loss: 0.04084 
Epoch [252/300] Training [35/62] Loss: 0.04426 
Epoch [252/300] Training [36/62] Loss: 0.03914 
Epoch [252/300] Training [37/62] Loss: 0.03357 
Epoch [252/300] Training [38/62] Loss: 0.03777 
Epoch [252/300] Training [39/62] Loss: 0.02702 
Epoch [252/300] Training [40/62] Loss: 0.04724 
Epoch [252/300] Training [41/62] Loss: 0.02382 
Epoch [252/300] Training [42/62] Loss: 0.03671 
Epoch [252/300] Training [43/62] Loss: 0.02823 
Epoch [252/300] Training [44/62] Loss: 0.03309 
Epoch [252/300] Training [45/62] Loss: 0.02245 
Epoch [252/300] Training [46/62] Loss: 0.05718 
Epoch [252/300] Training [47/62] Loss: 0.03190 
Epoch [252/300] Training [48/62] Loss: 0.07072 
Epoch [252/300] Training [49/62] Loss: 0.04568 
Epoch [252/300] Training [50/62] Loss: 0.03271 
Epoch [252/300] Training [51/62] Loss: 0.03011 
Epoch [252/300] Training [52/62] Loss: 0.09487 
Epoch [252/300] Training [53/62] Loss: 0.03670 
Epoch [252/300] Training [54/62] Loss: 0.03157 
Epoch [252/300] Training [55/62] Loss: 0.02781 
Epoch [252/300] Training [56/62] Loss: 0.05651 
Epoch [252/300] Training [57/62] Loss: 0.02376 
Epoch [252/300] Training [58/62] Loss: 0.03163 
Epoch [252/300] Training [59/62] Loss: 0.03482 
Epoch [252/300] Training [60/62] Loss: 0.03278 
Epoch [252/300] Training [61/62] Loss: 0.03118 
Epoch [252/300] Training [62/62] Loss: 0.02252 
Epoch [252/300] Training metric {'Train/mean dice_metric': 0.9749764204025269, 'Train/mean miou_metric': 0.9521708488464355, 'Train/mean f1': 0.9743890762329102, 'Train/mean precision': 0.9706472754478455, 'Train/mean recall': 0.9781597256660461, 'Train/mean hd95_metric': 3.682237148284912}
Epoch [252/300] Validation [1/16] Loss: 0.53148  focal_loss 0.35612  dice_loss 0.17536 
Epoch [252/300] Validation [2/16] Loss: 0.44044  focal_loss 0.20903  dice_loss 0.23141 
Epoch [252/300] Validation [3/16] Loss: 0.72775  focal_loss 0.44340  dice_loss 0.28435 
Epoch [252/300] Validation [4/16] Loss: 0.23723  focal_loss 0.11628  dice_loss 0.12096 
Epoch [252/300] Validation [5/16] Loss: 0.37778  focal_loss 0.15945  dice_loss 0.21833 
Epoch [252/300] Validation [6/16] Loss: 0.23983  focal_loss 0.06985  dice_loss 0.16998 
Epoch [252/300] Validation [7/16] Loss: 0.25357  focal_loss 0.13356  dice_loss 0.12000 
Epoch [252/300] Validation [8/16] Loss: 0.25115  focal_loss 0.06911  dice_loss 0.18203 
Epoch [252/300] Validation [9/16] Loss: 0.19558  focal_loss 0.09942  dice_loss 0.09616 
Epoch [252/300] Validation [10/16] Loss: 0.25842  focal_loss 0.10970  dice_loss 0.14871 
Epoch [252/300] Validation [11/16] Loss: 0.15099  focal_loss 0.04567  dice_loss 0.10531 
Epoch [252/300] Validation [12/16] Loss: 0.33025  focal_loss 0.09913  dice_loss 0.23112 
Epoch [252/300] Validation [13/16] Loss: 0.15575  focal_loss 0.05083  dice_loss 0.10493 
Epoch [252/300] Validation [14/16] Loss: 0.43084  focal_loss 0.15748  dice_loss 0.27336 
Epoch [252/300] Validation [15/16] Loss: 0.11294  focal_loss 0.04394  dice_loss 0.06900 
Epoch [252/300] Validation [16/16] Loss: 0.04212  focal_loss 0.01309  dice_loss 0.02903 
Epoch [252/300] Validation metric {'Val/mean dice_metric': 0.9475279450416565, 'Val/mean miou_metric': 0.9134952425956726, 'Val/mean f1': 0.9499358534812927, 'Val/mean precision': 0.9498946666717529, 'Val/mean recall': 0.9499770402908325, 'Val/mean hd95_metric': 10.319214820861816}
Cheakpoint...
Epoch [252/300] best acc:tensor([0.9475], device='cuda:0'), Now : mean acc: tensor([0.9475], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9475279450416565, 'Val/mean miou_metric': 0.9134952425956726, 'Val/mean f1': 0.9499358534812927, 'Val/mean precision': 0.9498946666717529, 'Val/mean recall': 0.9499770402908325, 'Val/mean hd95_metric': 10.319214820861816}
Epoch [253/300] Training [1/62] Loss: 0.03056 
Epoch [253/300] Training [2/62] Loss: 0.03064 
Epoch [253/300] Training [3/62] Loss: 0.03265 
Epoch [253/300] Training [4/62] Loss: 0.04586 
Epoch [253/300] Training [5/62] Loss: 0.03356 
Epoch [253/300] Training [6/62] Loss: 0.04910 
Epoch [253/300] Training [7/62] Loss: 0.03493 
Epoch [253/300] Training [8/62] Loss: 0.03069 
Epoch [253/300] Training [9/62] Loss: 0.03017 
Epoch [253/300] Training [10/62] Loss: 0.03578 
Epoch [253/300] Training [11/62] Loss: 0.02835 
Epoch [253/300] Training [12/62] Loss: 0.03283 
Epoch [253/300] Training [13/62] Loss: 0.03024 
Epoch [253/300] Training [14/62] Loss: 0.03508 
Epoch [253/300] Training [15/62] Loss: 0.04128 
Epoch [253/300] Training [16/62] Loss: 0.05414 
Epoch [253/300] Training [17/62] Loss: 0.03840 
Epoch [253/300] Training [18/62] Loss: 0.04486 
Epoch [253/300] Training [19/62] Loss: 0.02588 
Epoch [253/300] Training [20/62] Loss: 0.03146 
Epoch [253/300] Training [21/62] Loss: 0.02743 
Epoch [253/300] Training [22/62] Loss: 0.02601 
Epoch [253/300] Training [23/62] Loss: 0.03244 
Epoch [253/300] Training [24/62] Loss: 0.03491 
Epoch [253/300] Training [25/62] Loss: 0.04065 
Epoch [253/300] Training [26/62] Loss: 0.03065 
Epoch [253/300] Training [27/62] Loss: 0.03986 
Epoch [253/300] Training [28/62] Loss: 0.04362 
Epoch [253/300] Training [29/62] Loss: 0.02822 
Epoch [253/300] Training [30/62] Loss: 0.02845 
Epoch [253/300] Training [31/62] Loss: 0.03284 
Epoch [253/300] Training [32/62] Loss: 0.03633 
Epoch [253/300] Training [33/62] Loss: 0.02780 
Epoch [253/300] Training [34/62] Loss: 0.03938 
Epoch [253/300] Training [35/62] Loss: 0.04965 
Epoch [253/300] Training [36/62] Loss: 0.02701 
Epoch [253/300] Training [37/62] Loss: 0.03812 
Epoch [253/300] Training [38/62] Loss: 0.02929 
Epoch [253/300] Training [39/62] Loss: 0.05745 
Epoch [253/300] Training [40/62] Loss: 0.02868 
Epoch [253/300] Training [41/62] Loss: 0.02954 
Epoch [253/300] Training [42/62] Loss: 0.03243 
Epoch [253/300] Training [43/62] Loss: 0.04240 
Epoch [253/300] Training [44/62] Loss: 0.06446 
Epoch [253/300] Training [45/62] Loss: 0.03601 
Epoch [253/300] Training [46/62] Loss: 0.03593 
Epoch [253/300] Training [47/62] Loss: 0.02467 
Epoch [253/300] Training [48/62] Loss: 0.07303 
Epoch [253/300] Training [49/62] Loss: 0.04297 
Epoch [253/300] Training [50/62] Loss: 0.03069 
Epoch [253/300] Training [51/62] Loss: 0.02403 
Epoch [253/300] Training [52/62] Loss: 0.04180 
Epoch [253/300] Training [53/62] Loss: 0.04340 
Epoch [253/300] Training [54/62] Loss: 0.03685 
Epoch [253/300] Training [55/62] Loss: 0.04143 
Epoch [253/300] Training [56/62] Loss: 0.03163 
Epoch [253/300] Training [57/62] Loss: 0.07174 
Epoch [253/300] Training [58/62] Loss: 0.02798 
Epoch [253/300] Training [59/62] Loss: 0.03227 
Epoch [253/300] Training [60/62] Loss: 0.03461 
Epoch [253/300] Training [61/62] Loss: 0.02425 
Epoch [253/300] Training [62/62] Loss: 0.02334 
Epoch [253/300] Training metric {'Train/mean dice_metric': 0.9747986197471619, 'Train/mean miou_metric': 0.9515584707260132, 'Train/mean f1': 0.9743834733963013, 'Train/mean precision': 0.9694281816482544, 'Train/mean recall': 0.9793896675109863, 'Train/mean hd95_metric': 4.635250568389893}
Epoch [253/300] Validation [1/16] Loss: 0.22358  focal_loss 0.11488  dice_loss 0.10870 
Epoch [253/300] Validation [2/16] Loss: 0.35430  focal_loss 0.21783  dice_loss 0.13648 
Epoch [253/300] Validation [3/16] Loss: 0.70063  focal_loss 0.42566  dice_loss 0.27497 
Epoch [253/300] Validation [4/16] Loss: 0.33867  focal_loss 0.17902  dice_loss 0.15966 
Epoch [253/300] Validation [5/16] Loss: 0.38512  focal_loss 0.15945  dice_loss 0.22567 
Epoch [253/300] Validation [6/16] Loss: 0.20269  focal_loss 0.04847  dice_loss 0.15422 
Epoch [253/300] Validation [7/16] Loss: 0.33810  focal_loss 0.18913  dice_loss 0.14898 
Epoch [253/300] Validation [8/16] Loss: 0.41123  focal_loss 0.14918  dice_loss 0.26205 
Epoch [253/300] Validation [9/16] Loss: 0.15520  focal_loss 0.07425  dice_loss 0.08095 
Epoch [253/300] Validation [10/16] Loss: 0.31939  focal_loss 0.12488  dice_loss 0.19451 
Epoch [253/300] Validation [11/16] Loss: 0.13522  focal_loss 0.04850  dice_loss 0.08673 
Epoch [253/300] Validation [12/16] Loss: 0.29508  focal_loss 0.08576  dice_loss 0.20933 
Epoch [253/300] Validation [13/16] Loss: 0.16638  focal_loss 0.06190  dice_loss 0.10448 
Epoch [253/300] Validation [14/16] Loss: 0.47178  focal_loss 0.19578  dice_loss 0.27599 
Epoch [253/300] Validation [15/16] Loss: 0.10088  focal_loss 0.03941  dice_loss 0.06147 
Epoch [253/300] Validation [16/16] Loss: 0.04013  focal_loss 0.01261  dice_loss 0.02752 
Epoch [253/300] Validation metric {'Val/mean dice_metric': 0.9478466510772705, 'Val/mean miou_metric': 0.914305567741394, 'Val/mean f1': 0.9499015808105469, 'Val/mean precision': 0.9495383501052856, 'Val/mean recall': 0.950265109539032, 'Val/mean hd95_metric': 9.88181209564209}
Cheakpoint...
Epoch [253/300] best acc:tensor([0.9478], device='cuda:0'), Now : mean acc: tensor([0.9478], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9478466510772705, 'Val/mean miou_metric': 0.914305567741394, 'Val/mean f1': 0.9499015808105469, 'Val/mean precision': 0.9495383501052856, 'Val/mean recall': 0.950265109539032, 'Val/mean hd95_metric': 9.88181209564209}
Epoch [254/300] Training [1/62] Loss: 0.03276 
Epoch [254/300] Training [2/62] Loss: 0.03729 
Epoch [254/300] Training [3/62] Loss: 0.03195 
Epoch [254/300] Training [4/62] Loss: 0.05870 
Epoch [254/300] Training [5/62] Loss: 0.03938 
Epoch [254/300] Training [6/62] Loss: 0.03350 
Epoch [254/300] Training [7/62] Loss: 0.03470 
Epoch [254/300] Training [8/62] Loss: 0.03301 
Epoch [254/300] Training [9/62] Loss: 0.03185 
Epoch [254/300] Training [10/62] Loss: 0.04207 
Epoch [254/300] Training [11/62] Loss: 0.02871 
Epoch [254/300] Training [12/62] Loss: 0.02931 
Epoch [254/300] Training [13/62] Loss: 0.03510 
Epoch [254/300] Training [14/62] Loss: 0.07519 
Epoch [254/300] Training [15/62] Loss: 0.03038 
Epoch [254/300] Training [16/62] Loss: 0.04352 
Epoch [254/300] Training [17/62] Loss: 0.03639 
Epoch [254/300] Training [18/62] Loss: 0.10185 
Epoch [254/300] Training [19/62] Loss: 0.02720 
Epoch [254/300] Training [20/62] Loss: 0.02567 
Epoch [254/300] Training [21/62] Loss: 0.03166 
Epoch [254/300] Training [22/62] Loss: 0.03808 
Epoch [254/300] Training [23/62] Loss: 0.03197 
Epoch [254/300] Training [24/62] Loss: 0.03048 
Epoch [254/300] Training [25/62] Loss: 0.02331 
Epoch [254/300] Training [26/62] Loss: 0.02515 
Epoch [254/300] Training [27/62] Loss: 0.03375 
Epoch [254/300] Training [28/62] Loss: 0.02712 
Epoch [254/300] Training [29/62] Loss: 0.04425 
Epoch [254/300] Training [30/62] Loss: 0.03775 
Epoch [254/300] Training [31/62] Loss: 0.03052 
Epoch [254/300] Training [32/62] Loss: 0.03597 
Epoch [254/300] Training [33/62] Loss: 0.03220 
Epoch [254/300] Training [34/62] Loss: 0.04029 
Epoch [254/300] Training [35/62] Loss: 0.04066 
Epoch [254/300] Training [36/62] Loss: 0.02518 
Epoch [254/300] Training [37/62] Loss: 0.02564 
Epoch [254/300] Training [38/62] Loss: 0.06654 
Epoch [254/300] Training [39/62] Loss: 0.03027 
Epoch [254/300] Training [40/62] Loss: 0.03044 
Epoch [254/300] Training [41/62] Loss: 0.04026 
Epoch [254/300] Training [42/62] Loss: 0.03437 
Epoch [254/300] Training [43/62] Loss: 0.05488 
Epoch [254/300] Training [44/62] Loss: 0.05000 
Epoch [254/300] Training [45/62] Loss: 0.03410 
Epoch [254/300] Training [46/62] Loss: 0.03637 
Epoch [254/300] Training [47/62] Loss: 0.03309 
Epoch [254/300] Training [48/62] Loss: 0.04978 
Epoch [254/300] Training [49/62] Loss: 0.02684 
Epoch [254/300] Training [50/62] Loss: 0.02765 
Epoch [254/300] Training [51/62] Loss: 0.05424 
Epoch [254/300] Training [52/62] Loss: 0.04611 
Epoch [254/300] Training [53/62] Loss: 0.02973 
Epoch [254/300] Training [54/62] Loss: 0.04096 
Epoch [254/300] Training [55/62] Loss: 0.02668 
Epoch [254/300] Training [56/62] Loss: 0.03188 
Epoch [254/300] Training [57/62] Loss: 0.05700 
Epoch [254/300] Training [58/62] Loss: 0.03339 
Epoch [254/300] Training [59/62] Loss: 0.03623 
Epoch [254/300] Training [60/62] Loss: 0.02520 
Epoch [254/300] Training [61/62] Loss: 0.02585 
Epoch [254/300] Training [62/62] Loss: 0.02106 
Epoch [254/300] Training metric {'Train/mean dice_metric': 0.9743926525115967, 'Train/mean miou_metric': 0.9508112668991089, 'Train/mean f1': 0.9739673733711243, 'Train/mean precision': 0.9700709581375122, 'Train/mean recall': 0.977895200252533, 'Train/mean hd95_metric': 3.830265760421753}
Epoch [254/300] Validation [1/16] Loss: 0.25402  focal_loss 0.12609  dice_loss 0.12793 
Epoch [254/300] Validation [2/16] Loss: 0.38314  focal_loss 0.22010  dice_loss 0.16304 
Epoch [254/300] Validation [3/16] Loss: 0.74848  focal_loss 0.45898  dice_loss 0.28949 
Epoch [254/300] Validation [4/16] Loss: 0.31968  focal_loss 0.16428  dice_loss 0.15540 
Epoch [254/300] Validation [5/16] Loss: 0.37841  focal_loss 0.15671  dice_loss 0.22170 
Epoch [254/300] Validation [6/16] Loss: 0.19684  focal_loss 0.04478  dice_loss 0.15206 
Epoch [254/300] Validation [7/16] Loss: 0.15077  focal_loss 0.06038  dice_loss 0.09038 
Epoch [254/300] Validation [8/16] Loss: 0.33970  focal_loss 0.10603  dice_loss 0.23367 
Epoch [254/300] Validation [9/16] Loss: 0.15955  focal_loss 0.07582  dice_loss 0.08373 
Epoch [254/300] Validation [10/16] Loss: 0.26633  focal_loss 0.11457  dice_loss 0.15176 
Epoch [254/300] Validation [11/16] Loss: 0.10750  focal_loss 0.03764  dice_loss 0.06986 
Epoch [254/300] Validation [12/16] Loss: 0.29815  focal_loss 0.07374  dice_loss 0.22442 
Epoch [254/300] Validation [13/16] Loss: 0.36746  focal_loss 0.15312  dice_loss 0.21434 
Epoch [254/300] Validation [14/16] Loss: 0.47241  focal_loss 0.17920  dice_loss 0.29321 
Epoch [254/300] Validation [15/16] Loss: 0.13247  focal_loss 0.05343  dice_loss 0.07904 
Epoch [254/300] Validation [16/16] Loss: 0.04062  focal_loss 0.01173  dice_loss 0.02889 
Epoch [254/300] Validation metric {'Val/mean dice_metric': 0.9468724727630615, 'Val/mean miou_metric': 0.9128376841545105, 'Val/mean f1': 0.9507169723510742, 'Val/mean precision': 0.9508728384971619, 'Val/mean recall': 0.9505611062049866, 'Val/mean hd95_metric': 9.800044059753418}
Cheakpoint...
Epoch [254/300] best acc:tensor([0.9478], device='cuda:0'), Now : mean acc: tensor([0.9469], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9468724727630615, 'Val/mean miou_metric': 0.9128376841545105, 'Val/mean f1': 0.9507169723510742, 'Val/mean precision': 0.9508728384971619, 'Val/mean recall': 0.9505611062049866, 'Val/mean hd95_metric': 9.800044059753418}
Epoch [255/300] Training [1/62] Loss: 0.02981 
Epoch [255/300] Training [2/62] Loss: 0.04914 
Epoch [255/300] Training [3/62] Loss: 0.03198 
Epoch [255/300] Training [4/62] Loss: 0.02593 
Epoch [255/300] Training [5/62] Loss: 0.02804 
Epoch [255/300] Training [6/62] Loss: 0.03595 
Epoch [255/300] Training [7/62] Loss: 0.02765 
Epoch [255/300] Training [8/62] Loss: 0.02590 
Epoch [255/300] Training [9/62] Loss: 0.03497 
Epoch [255/300] Training [10/62] Loss: 0.03242 
Epoch [255/300] Training [11/62] Loss: 0.03881 
Epoch [255/300] Training [12/62] Loss: 0.03181 
Epoch [255/300] Training [13/62] Loss: 0.02215 
Epoch [255/300] Training [14/62] Loss: 0.02507 
Epoch [255/300] Training [15/62] Loss: 0.03295 
Epoch [255/300] Training [16/62] Loss: 0.05015 
Epoch [255/300] Training [17/62] Loss: 0.03807 
Epoch [255/300] Training [18/62] Loss: 0.02663 
Epoch [255/300] Training [19/62] Loss: 0.04178 
Epoch [255/300] Training [20/62] Loss: 0.02827 
Epoch [255/300] Training [21/62] Loss: 0.04698 
Epoch [255/300] Training [22/62] Loss: 0.03160 
Epoch [255/300] Training [23/62] Loss: 0.03089 
Epoch [255/300] Training [24/62] Loss: 0.03211 
Epoch [255/300] Training [25/62] Loss: 0.03690 
Epoch [255/300] Training [26/62] Loss: 0.02546 
Epoch [255/300] Training [27/62] Loss: 0.02897 
Epoch [255/300] Training [28/62] Loss: 0.03804 
Epoch [255/300] Training [29/62] Loss: 0.03566 
Epoch [255/300] Training [30/62] Loss: 0.03761 
Epoch [255/300] Training [31/62] Loss: 0.02874 
Epoch [255/300] Training [32/62] Loss: 0.06503 
Epoch [255/300] Training [33/62] Loss: 0.03709 
Epoch [255/300] Training [34/62] Loss: 0.03257 
Epoch [255/300] Training [35/62] Loss: 0.03533 
Epoch [255/300] Training [36/62] Loss: 0.02813 
Epoch [255/300] Training [37/62] Loss: 0.07160 
Epoch [255/300] Training [38/62] Loss: 0.03175 
Epoch [255/300] Training [39/62] Loss: 0.03881 
Epoch [255/300] Training [40/62] Loss: 0.02541 
Epoch [255/300] Training [41/62] Loss: 0.03236 
Epoch [255/300] Training [42/62] Loss: 0.06066 
Epoch [255/300] Training [43/62] Loss: 0.03053 
Epoch [255/300] Training [44/62] Loss: 0.05163 
Epoch [255/300] Training [45/62] Loss: 0.03589 
Epoch [255/300] Training [46/62] Loss: 0.03996 
Epoch [255/300] Training [47/62] Loss: 0.03191 
Epoch [255/300] Training [48/62] Loss: 0.03064 
Epoch [255/300] Training [49/62] Loss: 0.02632 
Epoch [255/300] Training [50/62] Loss: 0.02874 
Epoch [255/300] Training [51/62] Loss: 0.04446 
Epoch [255/300] Training [52/62] Loss: 0.08632 
Epoch [255/300] Training [53/62] Loss: 0.03725 
Epoch [255/300] Training [54/62] Loss: 0.03360 
Epoch [255/300] Training [55/62] Loss: 0.02834 
Epoch [255/300] Training [56/62] Loss: 0.02840 
Epoch [255/300] Training [57/62] Loss: 0.05116 
Epoch [255/300] Training [58/62] Loss: 0.03850 
Epoch [255/300] Training [59/62] Loss: 0.03263 
Epoch [255/300] Training [60/62] Loss: 0.02526 
Epoch [255/300] Training [61/62] Loss: 0.04292 
Epoch [255/300] Training [62/62] Loss: 0.03453 
Epoch [255/300] Training metric {'Train/mean dice_metric': 0.9752251505851746, 'Train/mean miou_metric': 0.9523592591285706, 'Train/mean f1': 0.9745716452598572, 'Train/mean precision': 0.9699192643165588, 'Train/mean recall': 0.9792688488960266, 'Train/mean hd95_metric': 4.028162479400635}
Epoch [255/300] Validation [1/16] Loss: 0.21480  focal_loss 0.10423  dice_loss 0.11057 
Epoch [255/300] Validation [2/16] Loss: 0.47876  focal_loss 0.22992  dice_loss 0.24884 
Epoch [255/300] Validation [3/16] Loss: 0.70699  focal_loss 0.41956  dice_loss 0.28743 
Epoch [255/300] Validation [4/16] Loss: 0.36418  focal_loss 0.18419  dice_loss 0.17999 
Epoch [255/300] Validation [5/16] Loss: 0.38032  focal_loss 0.16076  dice_loss 0.21956 
Epoch [255/300] Validation [6/16] Loss: 0.23007  focal_loss 0.07237  dice_loss 0.15769 
Epoch [255/300] Validation [7/16] Loss: 0.35725  focal_loss 0.19392  dice_loss 0.16333 
Epoch [255/300] Validation [8/16] Loss: 0.39812  focal_loss 0.12965  dice_loss 0.26847 
Epoch [255/300] Validation [9/16] Loss: 0.20520  focal_loss 0.09968  dice_loss 0.10552 
Epoch [255/300] Validation [10/16] Loss: 0.22171  focal_loss 0.08876  dice_loss 0.13295 
Epoch [255/300] Validation [11/16] Loss: 0.09575  focal_loss 0.03482  dice_loss 0.06093 
Epoch [255/300] Validation [12/16] Loss: 0.29500  focal_loss 0.07089  dice_loss 0.22412 
Epoch [255/300] Validation [13/16] Loss: 0.35253  focal_loss 0.14832  dice_loss 0.20421 
Epoch [255/300] Validation [14/16] Loss: 0.48657  focal_loss 0.17739  dice_loss 0.30918 
Epoch [255/300] Validation [15/16] Loss: 0.10872  focal_loss 0.04232  dice_loss 0.06640 
Epoch [255/300] Validation [16/16] Loss: 0.06878  focal_loss 0.02570  dice_loss 0.04308 
Epoch [255/300] Validation metric {'Val/mean dice_metric': 0.9447060227394104, 'Val/mean miou_metric': 0.9108732342720032, 'Val/mean f1': 0.9485952258110046, 'Val/mean precision': 0.9489052295684814, 'Val/mean recall': 0.9482852816581726, 'Val/mean hd95_metric': 10.188684463500977}
Cheakpoint...
Epoch [255/300] best acc:tensor([0.9478], device='cuda:0'), Now : mean acc: tensor([0.9447], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9447060227394104, 'Val/mean miou_metric': 0.9108732342720032, 'Val/mean f1': 0.9485952258110046, 'Val/mean precision': 0.9489052295684814, 'Val/mean recall': 0.9482852816581726, 'Val/mean hd95_metric': 10.188684463500977}
Epoch [256/300] Training [1/62] Loss: 0.03030 
Epoch [256/300] Training [2/62] Loss: 0.02838 
Epoch [256/300] Training [3/62] Loss: 0.02962 
Epoch [256/300] Training [4/62] Loss: 0.02310 
Epoch [256/300] Training [5/62] Loss: 0.06215 
Epoch [256/300] Training [6/62] Loss: 0.02933 
Epoch [256/300] Training [7/62] Loss: 0.02813 
Epoch [256/300] Training [8/62] Loss: 0.04062 
Epoch [256/300] Training [9/62] Loss: 0.03939 
Epoch [256/300] Training [10/62] Loss: 0.05127 
Epoch [256/300] Training [11/62] Loss: 0.03155 
Epoch [256/300] Training [12/62] Loss: 0.03629 
Epoch [256/300] Training [13/62] Loss: 0.03088 
Epoch [256/300] Training [14/62] Loss: 0.02448 
Epoch [256/300] Training [15/62] Loss: 0.04041 
Epoch [256/300] Training [16/62] Loss: 0.03235 
Epoch [256/300] Training [17/62] Loss: 0.02771 
Epoch [256/300] Training [18/62] Loss: 0.04207 
Epoch [256/300] Training [19/62] Loss: 0.04191 
Epoch [256/300] Training [20/62] Loss: 0.02568 
Epoch [256/300] Training [21/62] Loss: 0.02969 
Epoch [256/300] Training [22/62] Loss: 0.02577 
Epoch [256/300] Training [23/62] Loss: 0.03029 
Epoch [256/300] Training [24/62] Loss: 0.04255 
Epoch [256/300] Training [25/62] Loss: 0.03093 
Epoch [256/300] Training [26/62] Loss: 0.02631 
Epoch [256/300] Training [27/62] Loss: 0.03121 
Epoch [256/300] Training [28/62] Loss: 0.05656 
Epoch [256/300] Training [29/62] Loss: 0.02938 
Epoch [256/300] Training [30/62] Loss: 0.02837 
Epoch [256/300] Training [31/62] Loss: 0.04348 
Epoch [256/300] Training [32/62] Loss: 0.04006 
Epoch [256/300] Training [33/62] Loss: 0.03136 
Epoch [256/300] Training [34/62] Loss: 0.04458 
Epoch [256/300] Training [35/62] Loss: 0.04966 
Epoch [256/300] Training [36/62] Loss: 0.03030 
Epoch [256/300] Training [37/62] Loss: 0.03293 
Epoch [256/300] Training [38/62] Loss: 0.03223 
Epoch [256/300] Training [39/62] Loss: 0.04481 
Epoch [256/300] Training [40/62] Loss: 0.03928 
Epoch [256/300] Training [41/62] Loss: 0.02121 
Epoch [256/300] Training [42/62] Loss: 0.02414 
Epoch [256/300] Training [43/62] Loss: 0.06428 
Epoch [256/300] Training [44/62] Loss: 0.02634 
Epoch [256/300] Training [45/62] Loss: 0.03560 
Epoch [256/300] Training [46/62] Loss: 0.03285 
Epoch [256/300] Training [47/62] Loss: 0.03505 
Epoch [256/300] Training [48/62] Loss: 0.09968 
Epoch [256/300] Training [49/62] Loss: 0.04038 
Epoch [256/300] Training [50/62] Loss: 0.03839 
Epoch [256/300] Training [51/62] Loss: 0.04122 
Epoch [256/300] Training [52/62] Loss: 0.03675 
Epoch [256/300] Training [53/62] Loss: 0.02826 
Epoch [256/300] Training [54/62] Loss: 0.04358 
Epoch [256/300] Training [55/62] Loss: 0.03050 
Epoch [256/300] Training [56/62] Loss: 0.02696 
Epoch [256/300] Training [57/62] Loss: 0.05595 
Epoch [256/300] Training [58/62] Loss: 0.03360 
Epoch [256/300] Training [59/62] Loss: 0.04626 
Epoch [256/300] Training [60/62] Loss: 0.02867 
Epoch [256/300] Training [61/62] Loss: 0.03524 
Epoch [256/300] Training [62/62] Loss: 0.03204 
Epoch [256/300] Training metric {'Train/mean dice_metric': 0.9748073220252991, 'Train/mean miou_metric': 0.9518334269523621, 'Train/mean f1': 0.9743122458457947, 'Train/mean precision': 0.9699118733406067, 'Train/mean recall': 0.9787527322769165, 'Train/mean hd95_metric': 3.3547518253326416}
Epoch [256/300] Validation [1/16] Loss: 0.49384  focal_loss 0.33180  dice_loss 0.16203 
Epoch [256/300] Validation [2/16] Loss: 0.39490  focal_loss 0.16334  dice_loss 0.23156 
Epoch [256/300] Validation [3/16] Loss: 0.62399  focal_loss 0.36208  dice_loss 0.26190 
Epoch [256/300] Validation [4/16] Loss: 0.32752  focal_loss 0.16475  dice_loss 0.16277 
Epoch [256/300] Validation [5/16] Loss: 0.37321  focal_loss 0.15627  dice_loss 0.21694 
Epoch [256/300] Validation [6/16] Loss: 0.18195  focal_loss 0.05258  dice_loss 0.12937 
Epoch [256/300] Validation [7/16] Loss: 0.20803  focal_loss 0.08796  dice_loss 0.12007 
Epoch [256/300] Validation [8/16] Loss: 0.34135  focal_loss 0.09770  dice_loss 0.24365 
Epoch [256/300] Validation [9/16] Loss: 0.21658  focal_loss 0.10745  dice_loss 0.10914 
Epoch [256/300] Validation [10/16] Loss: 0.19901  focal_loss 0.07470  dice_loss 0.12431 
Epoch [256/300] Validation [11/16] Loss: 0.14440  focal_loss 0.04579  dice_loss 0.09861 
Epoch [256/300] Validation [12/16] Loss: 0.31150  focal_loss 0.07178  dice_loss 0.23971 
Epoch [256/300] Validation [13/16] Loss: 0.33960  focal_loss 0.13746  dice_loss 0.20213 
Epoch [256/300] Validation [14/16] Loss: 0.42234  focal_loss 0.16809  dice_loss 0.25425 
Epoch [256/300] Validation [15/16] Loss: 0.10671  focal_loss 0.04029  dice_loss 0.06642 
Epoch [256/300] Validation [16/16] Loss: 0.05043  focal_loss 0.01840  dice_loss 0.03202 
Epoch [256/300] Validation metric {'Val/mean dice_metric': 0.9460822939872742, 'Val/mean miou_metric': 0.9120150208473206, 'Val/mean f1': 0.948878824710846, 'Val/mean precision': 0.9492627382278442, 'Val/mean recall': 0.9484951496124268, 'Val/mean hd95_metric': 10.355653762817383}
Cheakpoint...
Epoch [256/300] best acc:tensor([0.9478], device='cuda:0'), Now : mean acc: tensor([0.9461], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9460822939872742, 'Val/mean miou_metric': 0.9120150208473206, 'Val/mean f1': 0.948878824710846, 'Val/mean precision': 0.9492627382278442, 'Val/mean recall': 0.9484951496124268, 'Val/mean hd95_metric': 10.355653762817383}
Epoch [257/300] Training [1/62] Loss: 0.03393 
Epoch [257/300] Training [2/62] Loss: 0.03581 
Epoch [257/300] Training [3/62] Loss: 0.02585 
Epoch [257/300] Training [4/62] Loss: 0.04506 
Epoch [257/300] Training [5/62] Loss: 0.04381 
Epoch [257/300] Training [6/62] Loss: 0.03266 
Epoch [257/300] Training [7/62] Loss: 0.03867 
Epoch [257/300] Training [8/62] Loss: 0.02915 
Epoch [257/300] Training [9/62] Loss: 0.02656 
Epoch [257/300] Training [10/62] Loss: 0.06644 
Epoch [257/300] Training [11/62] Loss: 0.02811 
Epoch [257/300] Training [12/62] Loss: 0.03559 
Epoch [257/300] Training [13/62] Loss: 0.04275 
Epoch [257/300] Training [14/62] Loss: 0.04077 
Epoch [257/300] Training [15/62] Loss: 0.02794 
Epoch [257/300] Training [16/62] Loss: 0.04038 
Epoch [257/300] Training [17/62] Loss: 0.03230 
Epoch [257/300] Training [18/62] Loss: 0.02909 
Epoch [257/300] Training [19/62] Loss: 0.03179 
Epoch [257/300] Training [20/62] Loss: 0.02951 
Epoch [257/300] Training [21/62] Loss: 0.02294 
Epoch [257/300] Training [22/62] Loss: 0.07717 
Epoch [257/300] Training [23/62] Loss: 0.06905 
Epoch [257/300] Training [24/62] Loss: 0.04451 
Epoch [257/300] Training [25/62] Loss: 0.03460 
Epoch [257/300] Training [26/62] Loss: 0.02814 
Epoch [257/300] Training [27/62] Loss: 0.02564 
Epoch [257/300] Training [28/62] Loss: 0.02514 
Epoch [257/300] Training [29/62] Loss: 0.03829 
Epoch [257/300] Training [30/62] Loss: 0.03452 
Epoch [257/300] Training [31/62] Loss: 0.02648 
Epoch [257/300] Training [32/62] Loss: 0.03507 
Epoch [257/300] Training [33/62] Loss: 0.03870 
Epoch [257/300] Training [34/62] Loss: 0.02715 
Epoch [257/300] Training [35/62] Loss: 0.02986 
Epoch [257/300] Training [36/62] Loss: 0.02401 
Epoch [257/300] Training [37/62] Loss: 0.03919 
Epoch [257/300] Training [38/62] Loss: 0.03409 
Epoch [257/300] Training [39/62] Loss: 0.04228 
Epoch [257/300] Training [40/62] Loss: 0.04156 
Epoch [257/300] Training [41/62] Loss: 0.03334 
Epoch [257/300] Training [42/62] Loss: 0.02800 
Epoch [257/300] Training [43/62] Loss: 0.03264 
Epoch [257/300] Training [44/62] Loss: 0.02388 
Epoch [257/300] Training [45/62] Loss: 0.03250 
Epoch [257/300] Training [46/62] Loss: 0.02589 
Epoch [257/300] Training [47/62] Loss: 0.03254 
Epoch [257/300] Training [48/62] Loss: 0.02881 
Epoch [257/300] Training [49/62] Loss: 0.02879 
Epoch [257/300] Training [50/62] Loss: 0.03145 
Epoch [257/300] Training [51/62] Loss: 0.03224 
Epoch [257/300] Training [52/62] Loss: 0.03675 
Epoch [257/300] Training [53/62] Loss: 0.02704 
Epoch [257/300] Training [54/62] Loss: 0.04004 
Epoch [257/300] Training [55/62] Loss: 0.04568 
Epoch [257/300] Training [56/62] Loss: 0.04527 
Epoch [257/300] Training [57/62] Loss: 0.03294 
Epoch [257/300] Training [58/62] Loss: 0.04680 
Epoch [257/300] Training [59/62] Loss: 0.02659 
Epoch [257/300] Training [60/62] Loss: 0.03051 
Epoch [257/300] Training [61/62] Loss: 0.02524 
Epoch [257/300] Training [62/62] Loss: 0.03743 
Epoch [257/300] Training metric {'Train/mean dice_metric': 0.9760971665382385, 'Train/mean miou_metric': 0.9538529515266418, 'Train/mean f1': 0.9750338196754456, 'Train/mean precision': 0.970844030380249, 'Train/mean recall': 0.9792597889900208, 'Train/mean hd95_metric': 3.4711480140686035}
Epoch [257/300] Validation [1/16] Loss: 0.19101  focal_loss 0.09236  dice_loss 0.09864 
Epoch [257/300] Validation [2/16] Loss: 0.47773  focal_loss 0.23122  dice_loss 0.24651 
Epoch [257/300] Validation [3/16] Loss: 0.61544  focal_loss 0.37473  dice_loss 0.24072 
Epoch [257/300] Validation [4/16] Loss: 0.32121  focal_loss 0.16786  dice_loss 0.15335 
Epoch [257/300] Validation [5/16] Loss: 0.25897  focal_loss 0.07217  dice_loss 0.18680 
Epoch [257/300] Validation [6/16] Loss: 0.20852  focal_loss 0.05421  dice_loss 0.15431 
Epoch [257/300] Validation [7/16] Loss: 0.37863  focal_loss 0.21350  dice_loss 0.16512 
Epoch [257/300] Validation [8/16] Loss: 0.26816  focal_loss 0.08747  dice_loss 0.18069 
Epoch [257/300] Validation [9/16] Loss: 0.20620  focal_loss 0.10793  dice_loss 0.09826 
Epoch [257/300] Validation [10/16] Loss: 0.32738  focal_loss 0.13193  dice_loss 0.19545 
Epoch [257/300] Validation [11/16] Loss: 0.11026  focal_loss 0.03881  dice_loss 0.07145 
Epoch [257/300] Validation [12/16] Loss: 0.29149  focal_loss 0.07371  dice_loss 0.21778 
Epoch [257/300] Validation [13/16] Loss: 0.34633  focal_loss 0.13505  dice_loss 0.21128 
Epoch [257/300] Validation [14/16] Loss: 0.37394  focal_loss 0.13353  dice_loss 0.24041 
Epoch [257/300] Validation [15/16] Loss: 0.28123  focal_loss 0.12285  dice_loss 0.15838 
Epoch [257/300] Validation [16/16] Loss: 0.04401  focal_loss 0.01381  dice_loss 0.03020 
Epoch [257/300] Validation metric {'Val/mean dice_metric': 0.9470931887626648, 'Val/mean miou_metric': 0.9137495160102844, 'Val/mean f1': 0.9494563341140747, 'Val/mean precision': 0.9488571286201477, 'Val/mean recall': 0.950056254863739, 'Val/mean hd95_metric': 10.005101203918457}
Cheakpoint...
Epoch [257/300] best acc:tensor([0.9478], device='cuda:0'), Now : mean acc: tensor([0.9471], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9470931887626648, 'Val/mean miou_metric': 0.9137495160102844, 'Val/mean f1': 0.9494563341140747, 'Val/mean precision': 0.9488571286201477, 'Val/mean recall': 0.950056254863739, 'Val/mean hd95_metric': 10.005101203918457}
Epoch [258/300] Training [1/62] Loss: 0.02766 
Epoch [258/300] Training [2/62] Loss: 0.03907 
Epoch [258/300] Training [3/62] Loss: 0.05597 
Epoch [258/300] Training [4/62] Loss: 0.03952 
Epoch [258/300] Training [5/62] Loss: 0.02622 
Epoch [258/300] Training [6/62] Loss: 0.03961 
Epoch [258/300] Training [7/62] Loss: 0.02604 
Epoch [258/300] Training [8/62] Loss: 0.03360 
Epoch [258/300] Training [9/62] Loss: 0.02746 
Epoch [258/300] Training [10/62] Loss: 0.04336 
Epoch [258/300] Training [11/62] Loss: 0.02983 
Epoch [258/300] Training [12/62] Loss: 0.04005 
Epoch [258/300] Training [13/62] Loss: 0.02704 
Epoch [258/300] Training [14/62] Loss: 0.02944 
Epoch [258/300] Training [15/62] Loss: 0.03628 
Epoch [258/300] Training [16/62] Loss: 0.02945 
Epoch [258/300] Training [17/62] Loss: 0.03769 
Epoch [258/300] Training [18/62] Loss: 0.04215 
Epoch [258/300] Training [19/62] Loss: 0.08148 
Epoch [258/300] Training [20/62] Loss: 0.04332 
Epoch [258/300] Training [21/62] Loss: 0.02758 
Epoch [258/300] Training [22/62] Loss: 0.04513 
Epoch [258/300] Training [23/62] Loss: 0.02556 
Epoch [258/300] Training [24/62] Loss: 0.03550 
Epoch [258/300] Training [25/62] Loss: 0.03028 
Epoch [258/300] Training [26/62] Loss: 0.02514 
Epoch [258/300] Training [27/62] Loss: 0.02566 
Epoch [258/300] Training [28/62] Loss: 0.02620 
Epoch [258/300] Training [29/62] Loss: 0.03482 
Epoch [258/300] Training [30/62] Loss: 0.02702 
Epoch [258/300] Training [31/62] Loss: 0.03458 
Epoch [258/300] Training [32/62] Loss: 0.02912 
Epoch [258/300] Training [33/62] Loss: 0.02588 
Epoch [258/300] Training [34/62] Loss: 0.02692 
Epoch [258/300] Training [35/62] Loss: 0.04495 
Epoch [258/300] Training [36/62] Loss: 0.02939 
Epoch [258/300] Training [37/62] Loss: 0.02685 
Epoch [258/300] Training [38/62] Loss: 0.03754 
Epoch [258/300] Training [39/62] Loss: 0.02386 
Epoch [258/300] Training [40/62] Loss: 0.05042 
Epoch [258/300] Training [41/62] Loss: 0.03485 
Epoch [258/300] Training [42/62] Loss: 0.05346 
Epoch [258/300] Training [43/62] Loss: 0.08619 
Epoch [258/300] Training [44/62] Loss: 0.03837 
Epoch [258/300] Training [45/62] Loss: 0.04441 
Epoch [258/300] Training [46/62] Loss: 0.06041 
Epoch [258/300] Training [47/62] Loss: 0.04329 
Epoch [258/300] Training [48/62] Loss: 0.03285 
Epoch [258/300] Training [49/62] Loss: 0.03638 
Epoch [258/300] Training [50/62] Loss: 0.04456 
Epoch [258/300] Training [51/62] Loss: 0.05007 
Epoch [258/300] Training [52/62] Loss: 0.03580 
Epoch [258/300] Training [53/62] Loss: 0.02462 
Epoch [258/300] Training [54/62] Loss: 0.02884 
Epoch [258/300] Training [55/62] Loss: 0.02922 
Epoch [258/300] Training [56/62] Loss: 0.03774 
Epoch [258/300] Training [57/62] Loss: 0.03571 
Epoch [258/300] Training [58/62] Loss: 0.02526 
Epoch [258/300] Training [59/62] Loss: 0.03334 
Epoch [258/300] Training [60/62] Loss: 0.04050 
Epoch [258/300] Training [61/62] Loss: 0.02847 
Epoch [258/300] Training [62/62] Loss: 0.01619 
Epoch [258/300] Training metric {'Train/mean dice_metric': 0.9749497771263123, 'Train/mean miou_metric': 0.951982319355011, 'Train/mean f1': 0.9740874171257019, 'Train/mean precision': 0.9692620635032654, 'Train/mean recall': 0.978961169719696, 'Train/mean hd95_metric': 3.941840648651123}
Epoch [258/300] Validation [1/16] Loss: 0.54233  focal_loss 0.34518  dice_loss 0.19715 
Epoch [258/300] Validation [2/16] Loss: 0.49717  focal_loss 0.24781  dice_loss 0.24935 
Epoch [258/300] Validation [3/16] Loss: 0.67172  focal_loss 0.40214  dice_loss 0.26958 
Epoch [258/300] Validation [4/16] Loss: 0.30869  focal_loss 0.15941  dice_loss 0.14928 
Epoch [258/300] Validation [5/16] Loss: 0.33304  focal_loss 0.13405  dice_loss 0.19899 
Epoch [258/300] Validation [6/16] Loss: 0.21744  focal_loss 0.05821  dice_loss 0.15923 
Epoch [258/300] Validation [7/16] Loss: 0.30166  focal_loss 0.15696  dice_loss 0.14470 
Epoch [258/300] Validation [8/16] Loss: 0.32070  focal_loss 0.09597  dice_loss 0.22473 
Epoch [258/300] Validation [9/16] Loss: 0.15944  focal_loss 0.07592  dice_loss 0.08352 
Epoch [258/300] Validation [10/16] Loss: 0.26603  focal_loss 0.09169  dice_loss 0.17434 
Epoch [258/300] Validation [11/16] Loss: 0.12487  focal_loss 0.03728  dice_loss 0.08759 
Epoch [258/300] Validation [12/16] Loss: 0.35427  focal_loss 0.08557  dice_loss 0.26870 
Epoch [258/300] Validation [13/16] Loss: 0.34138  focal_loss 0.14684  dice_loss 0.19455 
Epoch [258/300] Validation [14/16] Loss: 0.46178  focal_loss 0.16526  dice_loss 0.29652 
Epoch [258/300] Validation [15/16] Loss: 0.13874  focal_loss 0.05378  dice_loss 0.08496 
Epoch [258/300] Validation [16/16] Loss: 0.04075  focal_loss 0.01210  dice_loss 0.02865 
Epoch [258/300] Validation metric {'Val/mean dice_metric': 0.9441388845443726, 'Val/mean miou_metric': 0.910020112991333, 'Val/mean f1': 0.947933554649353, 'Val/mean precision': 0.9498876333236694, 'Val/mean recall': 0.9459874629974365, 'Val/mean hd95_metric': 10.35958194732666}
Cheakpoint...
Epoch [258/300] best acc:tensor([0.9478], device='cuda:0'), Now : mean acc: tensor([0.9441], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9441388845443726, 'Val/mean miou_metric': 0.910020112991333, 'Val/mean f1': 0.947933554649353, 'Val/mean precision': 0.9498876333236694, 'Val/mean recall': 0.9459874629974365, 'Val/mean hd95_metric': 10.35958194732666}
Epoch [259/300] Training [1/62] Loss: 0.03257 
Epoch [259/300] Training [2/62] Loss: 0.04335 
Epoch [259/300] Training [3/62] Loss: 0.02996 
Epoch [259/300] Training [4/62] Loss: 0.09033 
Epoch [259/300] Training [5/62] Loss: 0.02422 
Epoch [259/300] Training [6/62] Loss: 0.03651 
Epoch [259/300] Training [7/62] Loss: 0.02933 
Epoch [259/300] Training [8/62] Loss: 0.03552 
Epoch [259/300] Training [9/62] Loss: 0.03965 
Epoch [259/300] Training [10/62] Loss: 0.02309 
Epoch [259/300] Training [11/62] Loss: 0.03806 
Epoch [259/300] Training [12/62] Loss: 0.02556 
Epoch [259/300] Training [13/62] Loss: 0.03304 
Epoch [259/300] Training [14/62] Loss: 0.06693 
Epoch [259/300] Training [15/62] Loss: 0.03864 
Epoch [259/300] Training [16/62] Loss: 0.03794 
Epoch [259/300] Training [17/62] Loss: 0.03465 
Epoch [259/300] Training [18/62] Loss: 0.02884 
Epoch [259/300] Training [19/62] Loss: 0.02949 
Epoch [259/300] Training [20/62] Loss: 0.03819 
Epoch [259/300] Training [21/62] Loss: 0.03482 
Epoch [259/300] Training [22/62] Loss: 0.02909 
Epoch [259/300] Training [23/62] Loss: 0.04000 
Epoch [259/300] Training [24/62] Loss: 0.04820 
Epoch [259/300] Training [25/62] Loss: 0.02838 
Epoch [259/300] Training [26/62] Loss: 0.03305 
Epoch [259/300] Training [27/62] Loss: 0.03249 
Epoch [259/300] Training [28/62] Loss: 0.04013 
Epoch [259/300] Training [29/62] Loss: 0.03756 
Epoch [259/300] Training [30/62] Loss: 0.04377 
Epoch [259/300] Training [31/62] Loss: 0.03895 
Epoch [259/300] Training [32/62] Loss: 0.02349 
Epoch [259/300] Training [33/62] Loss: 0.02825 
Epoch [259/300] Training [34/62] Loss: 0.02710 
Epoch [259/300] Training [35/62] Loss: 0.04021 
Epoch [259/300] Training [36/62] Loss: 0.03502 
Epoch [259/300] Training [37/62] Loss: 0.03228 
Epoch [259/300] Training [38/62] Loss: 0.03261 
Epoch [259/300] Training [39/62] Loss: 0.04176 
Epoch [259/300] Training [40/62] Loss: 0.03369 
Epoch [259/300] Training [41/62] Loss: 0.03617 
Epoch [259/300] Training [42/62] Loss: 0.03166 
Epoch [259/300] Training [43/62] Loss: 0.03782 
Epoch [259/300] Training [44/62] Loss: 0.03232 
Epoch [259/300] Training [45/62] Loss: 0.02630 
Epoch [259/300] Training [46/62] Loss: 0.02849 
Epoch [259/300] Training [47/62] Loss: 0.03624 
Epoch [259/300] Training [48/62] Loss: 0.03580 
Epoch [259/300] Training [49/62] Loss: 0.03906 
Epoch [259/300] Training [50/62] Loss: 0.02624 
Epoch [259/300] Training [51/62] Loss: 0.03026 
Epoch [259/300] Training [52/62] Loss: 0.02822 
Epoch [259/300] Training [53/62] Loss: 0.03559 
Epoch [259/300] Training [54/62] Loss: 0.06610 
Epoch [259/300] Training [55/62] Loss: 0.02218 
Epoch [259/300] Training [56/62] Loss: 0.04537 
Epoch [259/300] Training [57/62] Loss: 0.03492 
Epoch [259/300] Training [58/62] Loss: 0.03038 
Epoch [259/300] Training [59/62] Loss: 0.03674 
Epoch [259/300] Training [60/62] Loss: 0.03526 
Epoch [259/300] Training [61/62] Loss: 0.03638 
Epoch [259/300] Training [62/62] Loss: 0.04983 
Epoch [259/300] Training metric {'Train/mean dice_metric': 0.9755651950836182, 'Train/mean miou_metric': 0.9529777765274048, 'Train/mean f1': 0.9748251438140869, 'Train/mean precision': 0.9703052639961243, 'Train/mean recall': 0.9793875217437744, 'Train/mean hd95_metric': 3.5079293251037598}
Epoch [259/300] Validation [1/16] Loss: 0.19951  focal_loss 0.09737  dice_loss 0.10214 
Epoch [259/300] Validation [2/16] Loss: 0.37364  focal_loss 0.21644  dice_loss 0.15720 
Epoch [259/300] Validation [3/16] Loss: 0.73556  focal_loss 0.44859  dice_loss 0.28697 
Epoch [259/300] Validation [4/16] Loss: 0.34291  focal_loss 0.17132  dice_loss 0.17159 
Epoch [259/300] Validation [5/16] Loss: 0.37718  focal_loss 0.15609  dice_loss 0.22109 
Epoch [259/300] Validation [6/16] Loss: 0.19708  focal_loss 0.04168  dice_loss 0.15540 
Epoch [259/300] Validation [7/16] Loss: 0.14073  focal_loss 0.05476  dice_loss 0.08597 
Epoch [259/300] Validation [8/16] Loss: 0.32744  focal_loss 0.11584  dice_loss 0.21160 
Epoch [259/300] Validation [9/16] Loss: 0.18225  focal_loss 0.08577  dice_loss 0.09648 
Epoch [259/300] Validation [10/16] Loss: 0.22521  focal_loss 0.09555  dice_loss 0.12966 
Epoch [259/300] Validation [11/16] Loss: 0.13708  focal_loss 0.05014  dice_loss 0.08695 
Epoch [259/300] Validation [12/16] Loss: 0.31535  focal_loss 0.08058  dice_loss 0.23477 
Epoch [259/300] Validation [13/16] Loss: 0.37290  focal_loss 0.16346  dice_loss 0.20944 
Epoch [259/300] Validation [14/16] Loss: 0.53476  focal_loss 0.20358  dice_loss 0.33118 
Epoch [259/300] Validation [15/16] Loss: 0.11686  focal_loss 0.04747  dice_loss 0.06938 
Epoch [259/300] Validation [16/16] Loss: 0.05746  focal_loss 0.01922  dice_loss 0.03824 
Epoch [259/300] Validation metric {'Val/mean dice_metric': 0.9474839568138123, 'Val/mean miou_metric': 0.9142764210700989, 'Val/mean f1': 0.9511096477508545, 'Val/mean precision': 0.9495306015014648, 'Val/mean recall': 0.9526938796043396, 'Val/mean hd95_metric': 9.605222702026367}
Cheakpoint...
Epoch [259/300] best acc:tensor([0.9478], device='cuda:0'), Now : mean acc: tensor([0.9475], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9474839568138123, 'Val/mean miou_metric': 0.9142764210700989, 'Val/mean f1': 0.9511096477508545, 'Val/mean precision': 0.9495306015014648, 'Val/mean recall': 0.9526938796043396, 'Val/mean hd95_metric': 9.605222702026367}
Epoch [260/300] Training [1/62] Loss: 0.03684 
Epoch [260/300] Training [2/62] Loss: 0.02939 
Epoch [260/300] Training [3/62] Loss: 0.03267 
Epoch [260/300] Training [4/62] Loss: 0.03257 
Epoch [260/300] Training [5/62] Loss: 0.02605 
Epoch [260/300] Training [6/62] Loss: 0.02641 
Epoch [260/300] Training [7/62] Loss: 0.03026 
Epoch [260/300] Training [8/62] Loss: 0.02332 
Epoch [260/300] Training [9/62] Loss: 0.02990 
Epoch [260/300] Training [10/62] Loss: 0.03467 
Epoch [260/300] Training [11/62] Loss: 0.03522 
Epoch [260/300] Training [12/62] Loss: 0.03207 
Epoch [260/300] Training [13/62] Loss: 0.04842 
Epoch [260/300] Training [14/62] Loss: 0.03006 
Epoch [260/300] Training [15/62] Loss: 0.03305 
Epoch [260/300] Training [16/62] Loss: 0.04175 
Epoch [260/300] Training [17/62] Loss: 0.03243 
Epoch [260/300] Training [18/62] Loss: 0.03253 
Epoch [260/300] Training [19/62] Loss: 0.03726 
Epoch [260/300] Training [20/62] Loss: 0.02715 
Epoch [260/300] Training [21/62] Loss: 0.03558 
Epoch [260/300] Training [22/62] Loss: 0.02721 
Epoch [260/300] Training [23/62] Loss: 0.03175 
Epoch [260/300] Training [24/62] Loss: 0.03718 
Epoch [260/300] Training [25/62] Loss: 0.03115 
Epoch [260/300] Training [26/62] Loss: 0.02677 
Epoch [260/300] Training [27/62] Loss: 0.02679 
Epoch [260/300] Training [28/62] Loss: 0.03626 
Epoch [260/300] Training [29/62] Loss: 0.02654 
Epoch [260/300] Training [30/62] Loss: 0.03600 
Epoch [260/300] Training [31/62] Loss: 0.04592 
Epoch [260/300] Training [32/62] Loss: 0.03516 
Epoch [260/300] Training [33/62] Loss: 0.02301 
Epoch [260/300] Training [34/62] Loss: 0.02917 
Epoch [260/300] Training [35/62] Loss: 0.03928 
Epoch [260/300] Training [36/62] Loss: 0.02802 
Epoch [260/300] Training [37/62] Loss: 0.02360 
Epoch [260/300] Training [38/62] Loss: 0.03660 
Epoch [260/300] Training [39/62] Loss: 0.03463 
Epoch [260/300] Training [40/62] Loss: 0.03345 
Epoch [260/300] Training [41/62] Loss: 0.02561 
Epoch [260/300] Training [42/62] Loss: 0.02543 
Epoch [260/300] Training [43/62] Loss: 0.03146 
Epoch [260/300] Training [44/62] Loss: 0.03101 
Epoch [260/300] Training [45/62] Loss: 0.02215 
Epoch [260/300] Training [46/62] Loss: 0.03106 
Epoch [260/300] Training [47/62] Loss: 0.02733 
Epoch [260/300] Training [48/62] Loss: 0.03638 
Epoch [260/300] Training [49/62] Loss: 0.04564 
Epoch [260/300] Training [50/62] Loss: 0.02448 
Epoch [260/300] Training [51/62] Loss: 0.03273 
Epoch [260/300] Training [52/62] Loss: 0.03579 
Epoch [260/300] Training [53/62] Loss: 0.02588 
Epoch [260/300] Training [54/62] Loss: 0.02408 
Epoch [260/300] Training [55/62] Loss: 0.03304 
Epoch [260/300] Training [56/62] Loss: 0.06378 
Epoch [260/300] Training [57/62] Loss: 0.03037 
Epoch [260/300] Training [58/62] Loss: 0.02962 
Epoch [260/300] Training [59/62] Loss: 0.03166 
Epoch [260/300] Training [60/62] Loss: 0.02960 
Epoch [260/300] Training [61/62] Loss: 0.05177 
Epoch [260/300] Training [62/62] Loss: 0.02889 
Epoch [260/300] Training metric {'Train/mean dice_metric': 0.9779191017150879, 'Train/mean miou_metric': 0.9570261836051941, 'Train/mean f1': 0.9760224223136902, 'Train/mean precision': 0.9717894196510315, 'Train/mean recall': 0.980292558670044, 'Train/mean hd95_metric': 3.0757761001586914}
Epoch [260/300] Validation [1/16] Loss: 0.26464  focal_loss 0.12895  dice_loss 0.13569 
Epoch [260/300] Validation [2/16] Loss: 0.47010  focal_loss 0.23085  dice_loss 0.23924 
Epoch [260/300] Validation [3/16] Loss: 0.37796  focal_loss 0.18023  dice_loss 0.19773 
Epoch [260/300] Validation [4/16] Loss: 0.26890  focal_loss 0.12778  dice_loss 0.14112 
Epoch [260/300] Validation [5/16] Loss: 0.38310  focal_loss 0.13969  dice_loss 0.24340 
Epoch [260/300] Validation [6/16] Loss: 0.26186  focal_loss 0.07931  dice_loss 0.18255 
Epoch [260/300] Validation [7/16] Loss: 0.26936  focal_loss 0.13802  dice_loss 0.13134 
Epoch [260/300] Validation [8/16] Loss: 0.48110  focal_loss 0.19882  dice_loss 0.28228 
Epoch [260/300] Validation [9/16] Loss: 0.24773  focal_loss 0.11452  dice_loss 0.13321 
Epoch [260/300] Validation [10/16] Loss: 0.31427  focal_loss 0.12499  dice_loss 0.18928 
Epoch [260/300] Validation [11/16] Loss: 0.14133  focal_loss 0.05357  dice_loss 0.08776 
Epoch [260/300] Validation [12/16] Loss: 0.32220  focal_loss 0.09944  dice_loss 0.22276 
Epoch [260/300] Validation [13/16] Loss: 0.16862  focal_loss 0.06308  dice_loss 0.10553 
Epoch [260/300] Validation [14/16] Loss: 0.44573  focal_loss 0.17095  dice_loss 0.27477 
Epoch [260/300] Validation [15/16] Loss: 0.14200  focal_loss 0.06502  dice_loss 0.07698 
Epoch [260/300] Validation [16/16] Loss: 0.04431  focal_loss 0.01562  dice_loss 0.02869 
Epoch [260/300] Validation metric {'Val/mean dice_metric': 0.9483183026313782, 'Val/mean miou_metric': 0.9154528379440308, 'Val/mean f1': 0.9504854083061218, 'Val/mean precision': 0.9475942254066467, 'Val/mean recall': 0.9533944129943848, 'Val/mean hd95_metric': 10.406228065490723}
Cheakpoint...
Epoch [260/300] best acc:tensor([0.9483], device='cuda:0'), Now : mean acc: tensor([0.9483], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9483183026313782, 'Val/mean miou_metric': 0.9154528379440308, 'Val/mean f1': 0.9504854083061218, 'Val/mean precision': 0.9475942254066467, 'Val/mean recall': 0.9533944129943848, 'Val/mean hd95_metric': 10.406228065490723}
Epoch [261/300] Training [1/62] Loss: 0.03047 
Epoch [261/300] Training [2/62] Loss: 0.04338 
Epoch [261/300] Training [3/62] Loss: 0.04127 
Epoch [261/300] Training [4/62] Loss: 0.03466 
Epoch [261/300] Training [5/62] Loss: 0.05325 
Epoch [261/300] Training [6/62] Loss: 0.04443 
Epoch [261/300] Training [7/62] Loss: 0.02881 
Epoch [261/300] Training [8/62] Loss: 0.03404 
Epoch [261/300] Training [9/62] Loss: 0.03372 
Epoch [261/300] Training [10/62] Loss: 0.06037 
Epoch [261/300] Training [11/62] Loss: 0.03545 
Epoch [261/300] Training [12/62] Loss: 0.02633 
Epoch [261/300] Training [13/62] Loss: 0.03704 
Epoch [261/300] Training [14/62] Loss: 0.03851 
Epoch [261/300] Training [15/62] Loss: 0.02694 
Epoch [261/300] Training [16/62] Loss: 0.06457 
Epoch [261/300] Training [17/62] Loss: 0.03455 
Epoch [261/300] Training [18/62] Loss: 0.02829 
Epoch [261/300] Training [19/62] Loss: 0.03689 
Epoch [261/300] Training [20/62] Loss: 0.03239 
Epoch [261/300] Training [21/62] Loss: 0.03333 
Epoch [261/300] Training [22/62] Loss: 0.02579 
Epoch [261/300] Training [23/62] Loss: 0.03586 
Epoch [261/300] Training [24/62] Loss: 0.02589 
Epoch [261/300] Training [25/62] Loss: 0.02661 
Epoch [261/300] Training [26/62] Loss: 0.03123 
Epoch [261/300] Training [27/62] Loss: 0.02976 
Epoch [261/300] Training [28/62] Loss: 0.02482 
Epoch [261/300] Training [29/62] Loss: 0.02947 
Epoch [261/300] Training [30/62] Loss: 0.03570 
Epoch [261/300] Training [31/62] Loss: 0.02832 
Epoch [261/300] Training [32/62] Loss: 0.03512 
Epoch [261/300] Training [33/62] Loss: 0.02847 
Epoch [261/300] Training [34/62] Loss: 0.02558 
Epoch [261/300] Training [35/62] Loss: 0.02631 
Epoch [261/300] Training [36/62] Loss: 0.03088 
Epoch [261/300] Training [37/62] Loss: 0.03165 
Epoch [261/300] Training [38/62] Loss: 0.04216 
Epoch [261/300] Training [39/62] Loss: 0.02326 
Epoch [261/300] Training [40/62] Loss: 0.02899 
Epoch [261/300] Training [41/62] Loss: 0.03985 
Epoch [261/300] Training [42/62] Loss: 0.02802 
Epoch [261/300] Training [43/62] Loss: 0.03489 
Epoch [261/300] Training [44/62] Loss: 0.02369 
Epoch [261/300] Training [45/62] Loss: 0.02637 
Epoch [261/300] Training [46/62] Loss: 0.02697 
Epoch [261/300] Training [47/62] Loss: 0.03027 
Epoch [261/300] Training [48/62] Loss: 0.02911 
Epoch [261/300] Training [49/62] Loss: 0.03445 
Epoch [261/300] Training [50/62] Loss: 0.02957 
Epoch [261/300] Training [51/62] Loss: 0.02596 
Epoch [261/300] Training [52/62] Loss: 0.03029 
Epoch [261/300] Training [53/62] Loss: 0.02474 
Epoch [261/300] Training [54/62] Loss: 0.04220 
Epoch [261/300] Training [55/62] Loss: 0.03112 
Epoch [261/300] Training [56/62] Loss: 0.03499 
Epoch [261/300] Training [57/62] Loss: 0.04009 
Epoch [261/300] Training [58/62] Loss: 0.03225 
Epoch [261/300] Training [59/62] Loss: 0.03517 
Epoch [261/300] Training [60/62] Loss: 0.03259 
Epoch [261/300] Training [61/62] Loss: 0.03267 
Epoch [261/300] Training [62/62] Loss: 0.02921 
Epoch [261/300] Training metric {'Train/mean dice_metric': 0.9774007797241211, 'Train/mean miou_metric': 0.9561656713485718, 'Train/mean f1': 0.9757383465766907, 'Train/mean precision': 0.9711738228797913, 'Train/mean recall': 0.9803459048271179, 'Train/mean hd95_metric': 3.3338167667388916}
Epoch [261/300] Validation [1/16] Loss: 0.20639  focal_loss 0.10108  dice_loss 0.10532 
Epoch [261/300] Validation [2/16] Loss: 0.50415  focal_loss 0.25647  dice_loss 0.24768 
Epoch [261/300] Validation [3/16] Loss: 0.62762  focal_loss 0.38536  dice_loss 0.24226 
Epoch [261/300] Validation [4/16] Loss: 0.36710  focal_loss 0.19646  dice_loss 0.17064 
Epoch [261/300] Validation [5/16] Loss: 0.38729  focal_loss 0.16296  dice_loss 0.22433 
Epoch [261/300] Validation [6/16] Loss: 0.23590  focal_loss 0.06427  dice_loss 0.17164 
Epoch [261/300] Validation [7/16] Loss: 0.27953  focal_loss 0.15866  dice_loss 0.12087 
Epoch [261/300] Validation [8/16] Loss: 0.30177  focal_loss 0.08960  dice_loss 0.21217 
Epoch [261/300] Validation [9/16] Loss: 0.18273  focal_loss 0.09067  dice_loss 0.09205 
Epoch [261/300] Validation [10/16] Loss: 0.28209  focal_loss 0.10537  dice_loss 0.17673 
Epoch [261/300] Validation [11/16] Loss: 0.11143  focal_loss 0.04208  dice_loss 0.06935 
Epoch [261/300] Validation [12/16] Loss: 0.33798  focal_loss 0.10453  dice_loss 0.23345 
Epoch [261/300] Validation [13/16] Loss: 0.19595  focal_loss 0.07042  dice_loss 0.12553 
Epoch [261/300] Validation [14/16] Loss: 0.51935  focal_loss 0.21212  dice_loss 0.30723 
Epoch [261/300] Validation [15/16] Loss: 0.15244  focal_loss 0.06975  dice_loss 0.08269 
Epoch [261/300] Validation [16/16] Loss: 0.04170  focal_loss 0.01383  dice_loss 0.02787 
Epoch [261/300] Validation metric {'Val/mean dice_metric': 0.9484458565711975, 'Val/mean miou_metric': 0.9160776734352112, 'Val/mean f1': 0.9516274333000183, 'Val/mean precision': 0.9514237642288208, 'Val/mean recall': 0.9518311619758606, 'Val/mean hd95_metric': 9.697796821594238}
Cheakpoint...
Epoch [261/300] best acc:tensor([0.9484], device='cuda:0'), Now : mean acc: tensor([0.9484], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9484458565711975, 'Val/mean miou_metric': 0.9160776734352112, 'Val/mean f1': 0.9516274333000183, 'Val/mean precision': 0.9514237642288208, 'Val/mean recall': 0.9518311619758606, 'Val/mean hd95_metric': 9.697796821594238}
Epoch [262/300] Training [1/62] Loss: 0.02298 
Epoch [262/300] Training [2/62] Loss: 0.03996 
Epoch [262/300] Training [3/62] Loss: 0.02410 
Epoch [262/300] Training [4/62] Loss: 0.02537 
Epoch [262/300] Training [5/62] Loss: 0.03687 
Epoch [262/300] Training [6/62] Loss: 0.03262 
Epoch [262/300] Training [7/62] Loss: 0.02643 
Epoch [262/300] Training [8/62] Loss: 0.03944 
Epoch [262/300] Training [9/62] Loss: 0.02353 
Epoch [262/300] Training [10/62] Loss: 0.03275 
Epoch [262/300] Training [11/62] Loss: 0.03711 
Epoch [262/300] Training [12/62] Loss: 0.02532 
Epoch [262/300] Training [13/62] Loss: 0.08043 
Epoch [262/300] Training [14/62] Loss: 0.02751 
Epoch [262/300] Training [15/62] Loss: 0.04567 
Epoch [262/300] Training [16/62] Loss: 0.03991 
Epoch [262/300] Training [17/62] Loss: 0.03075 
Epoch [262/300] Training [18/62] Loss: 0.03264 
Epoch [262/300] Training [19/62] Loss: 0.03959 
Epoch [262/300] Training [20/62] Loss: 0.04176 
Epoch [262/300] Training [21/62] Loss: 0.02810 
Epoch [262/300] Training [22/62] Loss: 0.02422 
Epoch [262/300] Training [23/62] Loss: 0.02787 
Epoch [262/300] Training [24/62] Loss: 0.02581 
Epoch [262/300] Training [25/62] Loss: 0.03233 
Epoch [262/300] Training [26/62] Loss: 0.04336 
Epoch [262/300] Training [27/62] Loss: 0.03326 
Epoch [262/300] Training [28/62] Loss: 0.03275 
Epoch [262/300] Training [29/62] Loss: 0.07473 
Epoch [262/300] Training [30/62] Loss: 0.02722 
Epoch [262/300] Training [31/62] Loss: 0.02456 
Epoch [262/300] Training [32/62] Loss: 0.02964 
Epoch [262/300] Training [33/62] Loss: 0.02372 
Epoch [262/300] Training [34/62] Loss: 0.03515 
Epoch [262/300] Training [35/62] Loss: 0.02872 
Epoch [262/300] Training [36/62] Loss: 0.02579 
Epoch [262/300] Training [37/62] Loss: 0.04782 
Epoch [262/300] Training [38/62] Loss: 0.03914 
Epoch [262/300] Training [39/62] Loss: 0.02620 
Epoch [262/300] Training [40/62] Loss: 0.03248 
Epoch [262/300] Training [41/62] Loss: 0.02877 
Epoch [262/300] Training [42/62] Loss: 0.02913 
Epoch [262/300] Training [43/62] Loss: 0.03999 
Epoch [262/300] Training [44/62] Loss: 0.03660 
Epoch [262/300] Training [45/62] Loss: 0.02256 
Epoch [262/300] Training [46/62] Loss: 0.04033 
Epoch [262/300] Training [47/62] Loss: 0.03510 
Epoch [262/300] Training [48/62] Loss: 0.02591 
Epoch [262/300] Training [49/62] Loss: 0.03039 
Epoch [262/300] Training [50/62] Loss: 0.03510 
Epoch [262/300] Training [51/62] Loss: 0.05090 
Epoch [262/300] Training [52/62] Loss: 0.02805 
Epoch [262/300] Training [53/62] Loss: 0.03468 
Epoch [262/300] Training [54/62] Loss: 0.02247 
Epoch [262/300] Training [55/62] Loss: 0.03491 
Epoch [262/300] Training [56/62] Loss: 0.04740 
Epoch [262/300] Training [57/62] Loss: 0.03130 
Epoch [262/300] Training [58/62] Loss: 0.02749 
Epoch [262/300] Training [59/62] Loss: 0.02999 
Epoch [262/300] Training [60/62] Loss: 0.02215 
Epoch [262/300] Training [61/62] Loss: 0.03150 
Epoch [262/300] Training [62/62] Loss: 0.08286 
Epoch [262/300] Training metric {'Train/mean dice_metric': 0.9769442677497864, 'Train/mean miou_metric': 0.9556663036346436, 'Train/mean f1': 0.9761367440223694, 'Train/mean precision': 0.9717649817466736, 'Train/mean recall': 0.9805479049682617, 'Train/mean hd95_metric': 3.2843992710113525}
Epoch [262/300] Validation [1/16] Loss: 0.46130  focal_loss 0.31548  dice_loss 0.14583 
Epoch [262/300] Validation [2/16] Loss: 0.31002  focal_loss 0.15271  dice_loss 0.15732 
Epoch [262/300] Validation [3/16] Loss: 0.40422  focal_loss 0.16522  dice_loss 0.23900 
Epoch [262/300] Validation [4/16] Loss: 0.30971  focal_loss 0.15529  dice_loss 0.15442 
Epoch [262/300] Validation [5/16] Loss: 0.34125  focal_loss 0.12895  dice_loss 0.21230 
Epoch [262/300] Validation [6/16] Loss: 0.21117  focal_loss 0.05636  dice_loss 0.15481 
Epoch [262/300] Validation [7/16] Loss: 0.18089  focal_loss 0.07969  dice_loss 0.10120 
Epoch [262/300] Validation [8/16] Loss: 0.39407  focal_loss 0.14053  dice_loss 0.25354 
Epoch [262/300] Validation [9/16] Loss: 0.18245  focal_loss 0.09285  dice_loss 0.08960 
Epoch [262/300] Validation [10/16] Loss: 0.24739  focal_loss 0.10902  dice_loss 0.13836 
Epoch [262/300] Validation [11/16] Loss: 0.14884  focal_loss 0.05387  dice_loss 0.09497 
Epoch [262/300] Validation [12/16] Loss: 0.30159  focal_loss 0.07082  dice_loss 0.23077 
Epoch [262/300] Validation [13/16] Loss: 0.34060  focal_loss 0.13392  dice_loss 0.20668 
Epoch [262/300] Validation [14/16] Loss: 0.50603  focal_loss 0.20571  dice_loss 0.30032 
Epoch [262/300] Validation [15/16] Loss: 0.12574  focal_loss 0.05315  dice_loss 0.07260 
Epoch [262/300] Validation [16/16] Loss: 0.04905  focal_loss 0.01685  dice_loss 0.03220 
Epoch [262/300] Validation metric {'Val/mean dice_metric': 0.9487242698669434, 'Val/mean miou_metric': 0.9157004952430725, 'Val/mean f1': 0.9524129629135132, 'Val/mean precision': 0.9519572257995605, 'Val/mean recall': 0.952869176864624, 'Val/mean hd95_metric': 9.700525283813477}
Cheakpoint...
Epoch [262/300] best acc:tensor([0.9487], device='cuda:0'), Now : mean acc: tensor([0.9487], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9487242698669434, 'Val/mean miou_metric': 0.9157004952430725, 'Val/mean f1': 0.9524129629135132, 'Val/mean precision': 0.9519572257995605, 'Val/mean recall': 0.952869176864624, 'Val/mean hd95_metric': 9.700525283813477}
Epoch [263/300] Training [1/62] Loss: 0.03020 
Epoch [263/300] Training [2/62] Loss: 0.02783 
Epoch [263/300] Training [3/62] Loss: 0.04810 
Epoch [263/300] Training [4/62] Loss: 0.02809 
Epoch [263/300] Training [5/62] Loss: 0.03155 
Epoch [263/300] Training [6/62] Loss: 0.03142 
Epoch [263/300] Training [7/62] Loss: 0.04350 
Epoch [263/300] Training [8/62] Loss: 0.02369 
Epoch [263/300] Training [9/62] Loss: 0.03470 
Epoch [263/300] Training [10/62] Loss: 0.03954 
Epoch [263/300] Training [11/62] Loss: 0.03974 
Epoch [263/300] Training [12/62] Loss: 0.03321 
Epoch [263/300] Training [13/62] Loss: 0.05717 
Epoch [263/300] Training [14/62] Loss: 0.03694 
Epoch [263/300] Training [15/62] Loss: 0.02453 
Epoch [263/300] Training [16/62] Loss: 0.03737 
Epoch [263/300] Training [17/62] Loss: 0.03207 
Epoch [263/300] Training [18/62] Loss: 0.05609 
Epoch [263/300] Training [19/62] Loss: 0.02887 
Epoch [263/300] Training [20/62] Loss: 0.02416 
Epoch [263/300] Training [21/62] Loss: 0.02518 
Epoch [263/300] Training [22/62] Loss: 0.05034 
Epoch [263/300] Training [23/62] Loss: 0.06605 
Epoch [263/300] Training [24/62] Loss: 0.02220 
Epoch [263/300] Training [25/62] Loss: 0.03115 
Epoch [263/300] Training [26/62] Loss: 0.02384 
Epoch [263/300] Training [27/62] Loss: 0.02998 
Epoch [263/300] Training [28/62] Loss: 0.03411 
Epoch [263/300] Training [29/62] Loss: 0.04669 
Epoch [263/300] Training [30/62] Loss: 0.03449 
Epoch [263/300] Training [31/62] Loss: 0.03267 
Epoch [263/300] Training [32/62] Loss: 0.03301 
Epoch [263/300] Training [33/62] Loss: 0.02871 
Epoch [263/300] Training [34/62] Loss: 0.02843 
Epoch [263/300] Training [35/62] Loss: 0.04328 
Epoch [263/300] Training [36/62] Loss: 0.03203 
Epoch [263/300] Training [37/62] Loss: 0.02892 
Epoch [263/300] Training [38/62] Loss: 0.06275 
Epoch [263/300] Training [39/62] Loss: 0.02450 
Epoch [263/300] Training [40/62] Loss: 0.03424 
Epoch [263/300] Training [41/62] Loss: 0.04086 
Epoch [263/300] Training [42/62] Loss: 0.03413 
Epoch [263/300] Training [43/62] Loss: 0.03853 
Epoch [263/300] Training [44/62] Loss: 0.14208 
Epoch [263/300] Training [45/62] Loss: 0.03802 
Epoch [263/300] Training [46/62] Loss: 0.03539 
Epoch [263/300] Training [47/62] Loss: 0.03940 
Epoch [263/300] Training [48/62] Loss: 0.05356 
Epoch [263/300] Training [49/62] Loss: 0.07335 
Epoch [263/300] Training [50/62] Loss: 0.02702 
Epoch [263/300] Training [51/62] Loss: 0.02986 
Epoch [263/300] Training [52/62] Loss: 0.02580 
Epoch [263/300] Training [53/62] Loss: 0.02431 
Epoch [263/300] Training [54/62] Loss: 0.02750 
Epoch [263/300] Training [55/62] Loss: 0.02396 
Epoch [263/300] Training [56/62] Loss: 0.02872 
Epoch [263/300] Training [57/62] Loss: 0.03338 
Epoch [263/300] Training [58/62] Loss: 0.08450 
Epoch [263/300] Training [59/62] Loss: 0.03024 
Epoch [263/300] Training [60/62] Loss: 0.02481 
Epoch [263/300] Training [61/62] Loss: 0.04456 
Epoch [263/300] Training [62/62] Loss: 0.01810 
Epoch [263/300] Training metric {'Train/mean dice_metric': 0.973516047000885, 'Train/mean miou_metric': 0.9506624937057495, 'Train/mean f1': 0.9745914936065674, 'Train/mean precision': 0.9695232510566711, 'Train/mean recall': 0.9797129034996033, 'Train/mean hd95_metric': 4.461400032043457}
Epoch [263/300] Validation [1/16] Loss: 0.17873  focal_loss 0.08599  dice_loss 0.09274 
Epoch [263/300] Validation [2/16] Loss: 0.47102  focal_loss 0.23497  dice_loss 0.23605 
Epoch [263/300] Validation [3/16] Loss: 0.57471  focal_loss 0.32180  dice_loss 0.25291 
Epoch [263/300] Validation [4/16] Loss: 0.27907  focal_loss 0.14083  dice_loss 0.13825 
Epoch [263/300] Validation [5/16] Loss: 0.29361  focal_loss 0.11598  dice_loss 0.17763 
Epoch [263/300] Validation [6/16] Loss: 0.21456  focal_loss 0.05966  dice_loss 0.15491 
Epoch [263/300] Validation [7/16] Loss: 0.28781  focal_loss 0.13996  dice_loss 0.14785 
Epoch [263/300] Validation [8/16] Loss: 0.43758  focal_loss 0.16604  dice_loss 0.27154 
Epoch [263/300] Validation [9/16] Loss: 0.18362  focal_loss 0.08987  dice_loss 0.09376 
Epoch [263/300] Validation [10/16] Loss: 0.52209  focal_loss 0.21698  dice_loss 0.30511 
Epoch [263/300] Validation [11/16] Loss: 0.13484  focal_loss 0.04881  dice_loss 0.08603 
Epoch [263/300] Validation [12/16] Loss: 0.31030  focal_loss 0.08770  dice_loss 0.22260 
Epoch [263/300] Validation [13/16] Loss: 0.29143  focal_loss 0.11803  dice_loss 0.17340 
Epoch [263/300] Validation [14/16] Loss: 0.46019  focal_loss 0.16882  dice_loss 0.29138 
Epoch [263/300] Validation [15/16] Loss: 0.11304  focal_loss 0.04652  dice_loss 0.06652 
Epoch [263/300] Validation [16/16] Loss: 0.04201  focal_loss 0.01300  dice_loss 0.02901 
Epoch [263/300] Validation metric {'Val/mean dice_metric': 0.9438889622688293, 'Val/mean miou_metric': 0.9105064272880554, 'Val/mean f1': 0.9493083357810974, 'Val/mean precision': 0.9462529420852661, 'Val/mean recall': 0.9523836374282837, 'Val/mean hd95_metric': 11.239066123962402}
Cheakpoint...
Epoch [263/300] best acc:tensor([0.9487], device='cuda:0'), Now : mean acc: tensor([0.9439], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9438889622688293, 'Val/mean miou_metric': 0.9105064272880554, 'Val/mean f1': 0.9493083357810974, 'Val/mean precision': 0.9462529420852661, 'Val/mean recall': 0.9523836374282837, 'Val/mean hd95_metric': 11.239066123962402}
Epoch [264/300] Training [1/62] Loss: 0.02617 
Epoch [264/300] Training [2/62] Loss: 0.02442 
Epoch [264/300] Training [3/62] Loss: 0.04856 
Epoch [264/300] Training [4/62] Loss: 0.04403 
Epoch [264/300] Training [5/62] Loss: 0.03162 
Epoch [264/300] Training [6/62] Loss: 0.03268 
Epoch [264/300] Training [7/62] Loss: 0.04607 
Epoch [264/300] Training [8/62] Loss: 0.04157 
Epoch [264/300] Training [9/62] Loss: 0.02777 
Epoch [264/300] Training [10/62] Loss: 0.03029 
Epoch [264/300] Training [11/62] Loss: 0.03679 
Epoch [264/300] Training [12/62] Loss: 0.03734 
Epoch [264/300] Training [13/62] Loss: 0.03747 
Epoch [264/300] Training [14/62] Loss: 0.03406 
Epoch [264/300] Training [15/62] Loss: 0.02926 
Epoch [264/300] Training [16/62] Loss: 0.02268 
Epoch [264/300] Training [17/62] Loss: 0.03497 
Epoch [264/300] Training [18/62] Loss: 0.02808 
Epoch [264/300] Training [19/62] Loss: 0.02431 
Epoch [264/300] Training [20/62] Loss: 0.03000 
Epoch [264/300] Training [21/62] Loss: 0.03762 
Epoch [264/300] Training [22/62] Loss: 0.03944 
Epoch [264/300] Training [23/62] Loss: 0.02197 
Epoch [264/300] Training [24/62] Loss: 0.02417 
Epoch [264/300] Training [25/62] Loss: 0.03807 
Epoch [264/300] Training [26/62] Loss: 0.02707 
Epoch [264/300] Training [27/62] Loss: 0.02990 
Epoch [264/300] Training [28/62] Loss: 0.02954 
Epoch [264/300] Training [29/62] Loss: 0.06544 
Epoch [264/300] Training [30/62] Loss: 0.02936 
Epoch [264/300] Training [31/62] Loss: 0.07602 
Epoch [264/300] Training [32/62] Loss: 0.02567 
Epoch [264/300] Training [33/62] Loss: 0.02560 
Epoch [264/300] Training [34/62] Loss: 0.03185 
Epoch [264/300] Training [35/62] Loss: 0.02774 
Epoch [264/300] Training [36/62] Loss: 0.02424 
Epoch [264/300] Training [37/62] Loss: 0.02945 
Epoch [264/300] Training [38/62] Loss: 0.02647 
Epoch [264/300] Training [39/62] Loss: 0.03081 
Epoch [264/300] Training [40/62] Loss: 0.03620 
Epoch [264/300] Training [41/62] Loss: 0.02312 
Epoch [264/300] Training [42/62] Loss: 0.03192 
Epoch [264/300] Training [43/62] Loss: 0.03251 
Epoch [264/300] Training [44/62] Loss: 0.03695 
Epoch [264/300] Training [45/62] Loss: 0.03695 
Epoch [264/300] Training [46/62] Loss: 0.04073 
Epoch [264/300] Training [47/62] Loss: 0.03645 
Epoch [264/300] Training [48/62] Loss: 0.05653 
Epoch [264/300] Training [49/62] Loss: 0.03194 
Epoch [264/300] Training [50/62] Loss: 0.03469 
Epoch [264/300] Training [51/62] Loss: 0.04207 
Epoch [264/300] Training [52/62] Loss: 0.03773 
Epoch [264/300] Training [53/62] Loss: 0.03425 
Epoch [264/300] Training [54/62] Loss: 0.06072 
Epoch [264/300] Training [55/62] Loss: 0.02685 
Epoch [264/300] Training [56/62] Loss: 0.02919 
Epoch [264/300] Training [57/62] Loss: 0.02444 
Epoch [264/300] Training [58/62] Loss: 0.06289 
Epoch [264/300] Training [59/62] Loss: 0.02613 
Epoch [264/300] Training [60/62] Loss: 0.02649 
Epoch [264/300] Training [61/62] Loss: 0.08941 
Epoch [264/300] Training [62/62] Loss: 0.01922 
Epoch [264/300] Training metric {'Train/mean dice_metric': 0.9759839773178101, 'Train/mean miou_metric': 0.9540205597877502, 'Train/mean f1': 0.9745970964431763, 'Train/mean precision': 0.969530463218689, 'Train/mean recall': 0.9797168970108032, 'Train/mean hd95_metric': 3.306532621383667}
Epoch [264/300] Validation [1/16] Loss: 0.45869  focal_loss 0.28183  dice_loss 0.17687 
Epoch [264/300] Validation [2/16] Loss: 0.41411  focal_loss 0.17552  dice_loss 0.23860 
Epoch [264/300] Validation [3/16] Loss: 0.64412  focal_loss 0.37777  dice_loss 0.26636 
Epoch [264/300] Validation [4/16] Loss: 0.34116  focal_loss 0.18238  dice_loss 0.15879 
Epoch [264/300] Validation [5/16] Loss: 0.34613  focal_loss 0.14036  dice_loss 0.20577 
Epoch [264/300] Validation [6/16] Loss: 0.22141  focal_loss 0.06356  dice_loss 0.15785 
Epoch [264/300] Validation [7/16] Loss: 0.29042  focal_loss 0.16087  dice_loss 0.12955 
Epoch [264/300] Validation [8/16] Loss: 0.39095  focal_loss 0.13114  dice_loss 0.25981 
Epoch [264/300] Validation [9/16] Loss: 0.24134  focal_loss 0.10825  dice_loss 0.13309 
Epoch [264/300] Validation [10/16] Loss: 0.23004  focal_loss 0.09927  dice_loss 0.13077 
Epoch [264/300] Validation [11/16] Loss: 0.09227  focal_loss 0.03319  dice_loss 0.05909 
Epoch [264/300] Validation [12/16] Loss: 0.36388  focal_loss 0.10499  dice_loss 0.25889 
Epoch [264/300] Validation [13/16] Loss: 0.34785  focal_loss 0.14955  dice_loss 0.19831 
Epoch [264/300] Validation [14/16] Loss: 0.49106  focal_loss 0.18371  dice_loss 0.30735 
Epoch [264/300] Validation [15/16] Loss: 0.10815  focal_loss 0.04358  dice_loss 0.06458 
Epoch [264/300] Validation [16/16] Loss: 0.03969  focal_loss 0.01238  dice_loss 0.02731 
Epoch [264/300] Validation metric {'Val/mean dice_metric': 0.945302426815033, 'Val/mean miou_metric': 0.912911593914032, 'Val/mean f1': 0.9485023617744446, 'Val/mean precision': 0.9489226341247559, 'Val/mean recall': 0.9480825066566467, 'Val/mean hd95_metric': 9.963556289672852}
Cheakpoint...
Epoch [264/300] best acc:tensor([0.9487], device='cuda:0'), Now : mean acc: tensor([0.9453], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.945302426815033, 'Val/mean miou_metric': 0.912911593914032, 'Val/mean f1': 0.9485023617744446, 'Val/mean precision': 0.9489226341247559, 'Val/mean recall': 0.9480825066566467, 'Val/mean hd95_metric': 9.963556289672852}
Epoch [265/300] Training [1/62] Loss: 0.03103 
Epoch [265/300] Training [2/62] Loss: 0.02721 
Epoch [265/300] Training [3/62] Loss: 0.07490 
Epoch [265/300] Training [4/62] Loss: 0.04135 
Epoch [265/300] Training [5/62] Loss: 0.02621 
Epoch [265/300] Training [6/62] Loss: 0.03266 
Epoch [265/300] Training [7/62] Loss: 0.04238 
Epoch [265/300] Training [8/62] Loss: 0.02724 
Epoch [265/300] Training [9/62] Loss: 0.08393 
Epoch [265/300] Training [10/62] Loss: 0.07052 
Epoch [265/300] Training [11/62] Loss: 0.02845 
Epoch [265/300] Training [12/62] Loss: 0.06606 
Epoch [265/300] Training [13/62] Loss: 0.02207 
Epoch [265/300] Training [14/62] Loss: 0.02406 
Epoch [265/300] Training [15/62] Loss: 0.02465 
Epoch [265/300] Training [16/62] Loss: 0.02902 
Epoch [265/300] Training [17/62] Loss: 0.02438 
Epoch [265/300] Training [18/62] Loss: 0.03862 
Epoch [265/300] Training [19/62] Loss: 0.03247 
Epoch [265/300] Training [20/62] Loss: 0.02380 
Epoch [265/300] Training [21/62] Loss: 0.02991 
Epoch [265/300] Training [22/62] Loss: 0.02733 
Epoch [265/300] Training [23/62] Loss: 0.03994 
Epoch [265/300] Training [24/62] Loss: 0.02823 
Epoch [265/300] Training [25/62] Loss: 0.02827 
Epoch [265/300] Training [26/62] Loss: 0.02289 
Epoch [265/300] Training [27/62] Loss: 0.02206 
Epoch [265/300] Training [28/62] Loss: 0.03160 
Epoch [265/300] Training [29/62] Loss: 0.04230 
Epoch [265/300] Training [30/62] Loss: 0.02707 
Epoch [265/300] Training [31/62] Loss: 0.03361 
Epoch [265/300] Training [32/62] Loss: 0.02844 
Epoch [265/300] Training [33/62] Loss: 0.03290 
Epoch [265/300] Training [34/62] Loss: 0.03051 
Epoch [265/300] Training [35/62] Loss: 0.03232 
Epoch [265/300] Training [36/62] Loss: 0.02995 
Epoch [265/300] Training [37/62] Loss: 0.04640 
Epoch [265/300] Training [38/62] Loss: 0.02229 
Epoch [265/300] Training [39/62] Loss: 0.02318 
Epoch [265/300] Training [40/62] Loss: 0.02982 
Epoch [265/300] Training [41/62] Loss: 0.07345 
Epoch [265/300] Training [42/62] Loss: 0.02819 
Epoch [265/300] Training [43/62] Loss: 0.02677 
Epoch [265/300] Training [44/62] Loss: 0.03294 
Epoch [265/300] Training [45/62] Loss: 0.03148 
Epoch [265/300] Training [46/62] Loss: 0.03032 
Epoch [265/300] Training [47/62] Loss: 0.03630 
Epoch [265/300] Training [48/62] Loss: 0.02724 
Epoch [265/300] Training [49/62] Loss: 0.03417 
Epoch [265/300] Training [50/62] Loss: 0.03261 
Epoch [265/300] Training [51/62] Loss: 0.05811 
Epoch [265/300] Training [52/62] Loss: 0.02983 
Epoch [265/300] Training [53/62] Loss: 0.02873 
Epoch [265/300] Training [54/62] Loss: 0.05125 
Epoch [265/300] Training [55/62] Loss: 0.02946 
Epoch [265/300] Training [56/62] Loss: 0.02924 
Epoch [265/300] Training [57/62] Loss: 0.03451 
Epoch [265/300] Training [58/62] Loss: 0.04324 
Epoch [265/300] Training [59/62] Loss: 0.04394 
Epoch [265/300] Training [60/62] Loss: 0.03921 
Epoch [265/300] Training [61/62] Loss: 0.03760 
Epoch [265/300] Training [62/62] Loss: 0.03901 
Epoch [265/300] Training metric {'Train/mean dice_metric': 0.9761458039283752, 'Train/mean miou_metric': 0.954491138458252, 'Train/mean f1': 0.9751848578453064, 'Train/mean precision': 0.970719575881958, 'Train/mean recall': 0.9796913266181946, 'Train/mean hd95_metric': 3.6135623455047607}
Epoch [265/300] Validation [1/16] Loss: 0.47932  focal_loss 0.33203  dice_loss 0.14729 
Epoch [265/300] Validation [2/16] Loss: 0.42806  focal_loss 0.18807  dice_loss 0.23999 
Epoch [265/300] Validation [3/16] Loss: 0.71354  focal_loss 0.41739  dice_loss 0.29615 
Epoch [265/300] Validation [4/16] Loss: 0.32444  focal_loss 0.16837  dice_loss 0.15607 
Epoch [265/300] Validation [5/16] Loss: 0.34692  focal_loss 0.14042  dice_loss 0.20650 
Epoch [265/300] Validation [6/16] Loss: 0.20115  focal_loss 0.06395  dice_loss 0.13720 
Epoch [265/300] Validation [7/16] Loss: 0.27728  focal_loss 0.15133  dice_loss 0.12595 
Epoch [265/300] Validation [8/16] Loss: 0.40462  focal_loss 0.14620  dice_loss 0.25842 
Epoch [265/300] Validation [9/16] Loss: 0.20079  focal_loss 0.09512  dice_loss 0.10567 
Epoch [265/300] Validation [10/16] Loss: 0.24989  focal_loss 0.11149  dice_loss 0.13840 
Epoch [265/300] Validation [11/16] Loss: 0.09468  focal_loss 0.03449  dice_loss 0.06019 
Epoch [265/300] Validation [12/16] Loss: 0.35614  focal_loss 0.10480  dice_loss 0.25134 
Epoch [265/300] Validation [13/16] Loss: 0.34084  focal_loss 0.15430  dice_loss 0.18654 
Epoch [265/300] Validation [14/16] Loss: 0.47888  focal_loss 0.16267  dice_loss 0.31621 
Epoch [265/300] Validation [15/16] Loss: 0.10096  focal_loss 0.04123  dice_loss 0.05972 
Epoch [265/300] Validation [16/16] Loss: 0.04260  focal_loss 0.01387  dice_loss 0.02874 
Epoch [265/300] Validation metric {'Val/mean dice_metric': 0.9461697936058044, 'Val/mean miou_metric': 0.9136268496513367, 'Val/mean f1': 0.9496524333953857, 'Val/mean precision': 0.9502652287483215, 'Val/mean recall': 0.9490403532981873, 'Val/mean hd95_metric': 9.415534973144531}
Cheakpoint...
Epoch [265/300] best acc:tensor([0.9487], device='cuda:0'), Now : mean acc: tensor([0.9462], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9461697936058044, 'Val/mean miou_metric': 0.9136268496513367, 'Val/mean f1': 0.9496524333953857, 'Val/mean precision': 0.9502652287483215, 'Val/mean recall': 0.9490403532981873, 'Val/mean hd95_metric': 9.415534973144531}
Epoch [266/300] Training [1/62] Loss: 0.04188 
Epoch [266/300] Training [2/62] Loss: 0.03667 
Epoch [266/300] Training [3/62] Loss: 0.02872 
Epoch [266/300] Training [4/62] Loss: 0.07626 
Epoch [266/300] Training [5/62] Loss: 0.03027 
Epoch [266/300] Training [6/62] Loss: 0.05253 
Epoch [266/300] Training [7/62] Loss: 0.02715 
Epoch [266/300] Training [8/62] Loss: 0.02268 
Epoch [266/300] Training [9/62] Loss: 0.02290 
Epoch [266/300] Training [10/62] Loss: 0.02902 
Epoch [266/300] Training [11/62] Loss: 0.03565 
Epoch [266/300] Training [12/62] Loss: 0.02162 
Epoch [266/300] Training [13/62] Loss: 0.03488 
Epoch [266/300] Training [14/62] Loss: 0.02736 
Epoch [266/300] Training [15/62] Loss: 0.04571 
Epoch [266/300] Training [16/62] Loss: 0.04252 
Epoch [266/300] Training [17/62] Loss: 0.02696 
Epoch [266/300] Training [18/62] Loss: 0.02208 
Epoch [266/300] Training [19/62] Loss: 0.03247 
Epoch [266/300] Training [20/62] Loss: 0.03136 
Epoch [266/300] Training [21/62] Loss: 0.02861 
Epoch [266/300] Training [22/62] Loss: 0.02988 
Epoch [266/300] Training [23/62] Loss: 0.03499 
Epoch [266/300] Training [24/62] Loss: 0.02401 
Epoch [266/300] Training [25/62] Loss: 0.02652 
Epoch [266/300] Training [26/62] Loss: 0.03128 
Epoch [266/300] Training [27/62] Loss: 0.03341 
Epoch [266/300] Training [28/62] Loss: 0.02939 
Epoch [266/300] Training [29/62] Loss: 0.02407 
Epoch [266/300] Training [30/62] Loss: 0.03714 
Epoch [266/300] Training [31/62] Loss: 0.03141 
Epoch [266/300] Training [32/62] Loss: 0.02843 
Epoch [266/300] Training [33/62] Loss: 0.02836 
Epoch [266/300] Training [34/62] Loss: 0.03435 
Epoch [266/300] Training [35/62] Loss: 0.06472 
Epoch [266/300] Training [36/62] Loss: 0.02745 
Epoch [266/300] Training [37/62] Loss: 0.02521 
Epoch [266/300] Training [38/62] Loss: 0.03747 
Epoch [266/300] Training [39/62] Loss: 0.02203 
Epoch [266/300] Training [40/62] Loss: 0.03452 
Epoch [266/300] Training [41/62] Loss: 0.03511 
Epoch [266/300] Training [42/62] Loss: 0.02821 
Epoch [266/300] Training [43/62] Loss: 0.03221 
Epoch [266/300] Training [44/62] Loss: 0.03501 
Epoch [266/300] Training [45/62] Loss: 0.02114 
Epoch [266/300] Training [46/62] Loss: 0.02213 
Epoch [266/300] Training [47/62] Loss: 0.03153 
Epoch [266/300] Training [48/62] Loss: 0.02645 
Epoch [266/300] Training [49/62] Loss: 0.03053 
Epoch [266/300] Training [50/62] Loss: 0.02527 
Epoch [266/300] Training [51/62] Loss: 0.03954 
Epoch [266/300] Training [52/62] Loss: 0.03010 
Epoch [266/300] Training [53/62] Loss: 0.02979 
Epoch [266/300] Training [54/62] Loss: 0.02924 
Epoch [266/300] Training [55/62] Loss: 0.02883 
Epoch [266/300] Training [56/62] Loss: 0.03026 
Epoch [266/300] Training [57/62] Loss: 0.02546 
Epoch [266/300] Training [58/62] Loss: 0.02998 
Epoch [266/300] Training [59/62] Loss: 0.05916 
Epoch [266/300] Training [60/62] Loss: 0.03662 
Epoch [266/300] Training [61/62] Loss: 0.02333 
Epoch [266/300] Training [62/62] Loss: 0.02016 
Epoch [266/300] Training metric {'Train/mean dice_metric': 0.9782186150550842, 'Train/mean miou_metric': 0.9578902125358582, 'Train/mean f1': 0.9763339161872864, 'Train/mean precision': 0.9720377326011658, 'Train/mean recall': 0.9806681871414185, 'Train/mean hd95_metric': 3.3496804237365723}
Epoch [266/300] Validation [1/16] Loss: 0.18585  focal_loss 0.09151  dice_loss 0.09434 
Epoch [266/300] Validation [2/16] Loss: 0.53475  focal_loss 0.28266  dice_loss 0.25209 
Epoch [266/300] Validation [3/16] Loss: 0.64738  focal_loss 0.37811  dice_loss 0.26927 
Epoch [266/300] Validation [4/16] Loss: 0.30148  focal_loss 0.15539  dice_loss 0.14609 
Epoch [266/300] Validation [5/16] Loss: 0.38557  focal_loss 0.12925  dice_loss 0.25632 
Epoch [266/300] Validation [6/16] Loss: 0.21425  focal_loss 0.05810  dice_loss 0.15616 
Epoch [266/300] Validation [7/16] Loss: 0.38012  focal_loss 0.21600  dice_loss 0.16412 
Epoch [266/300] Validation [8/16] Loss: 0.42944  focal_loss 0.16686  dice_loss 0.26258 
Epoch [266/300] Validation [9/16] Loss: 0.16780  focal_loss 0.07960  dice_loss 0.08820 
Epoch [266/300] Validation [10/16] Loss: 0.20183  focal_loss 0.07266  dice_loss 0.12918 
Epoch [266/300] Validation [11/16] Loss: 0.13606  focal_loss 0.04661  dice_loss 0.08946 
Epoch [266/300] Validation [12/16] Loss: 0.31668  focal_loss 0.08279  dice_loss 0.23389 
Epoch [266/300] Validation [13/16] Loss: 0.36418  focal_loss 0.15876  dice_loss 0.20542 
Epoch [266/300] Validation [14/16] Loss: 0.47122  focal_loss 0.17970  dice_loss 0.29152 
Epoch [266/300] Validation [15/16] Loss: 0.10353  focal_loss 0.03716  dice_loss 0.06637 
Epoch [266/300] Validation [16/16] Loss: 0.05365  focal_loss 0.02048  dice_loss 0.03316 
Epoch [266/300] Validation metric {'Val/mean dice_metric': 0.9476589560508728, 'Val/mean miou_metric': 0.915969967842102, 'Val/mean f1': 0.9503520727157593, 'Val/mean precision': 0.9490111470222473, 'Val/mean recall': 0.9516968727111816, 'Val/mean hd95_metric': 10.200153350830078}
Cheakpoint...
Epoch [266/300] best acc:tensor([0.9487], device='cuda:0'), Now : mean acc: tensor([0.9477], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9476589560508728, 'Val/mean miou_metric': 0.915969967842102, 'Val/mean f1': 0.9503520727157593, 'Val/mean precision': 0.9490111470222473, 'Val/mean recall': 0.9516968727111816, 'Val/mean hd95_metric': 10.200153350830078}
Epoch [267/300] Training [1/62] Loss: 0.03270 
Epoch [267/300] Training [2/62] Loss: 0.02415 
Epoch [267/300] Training [3/62] Loss: 0.02388 
Epoch [267/300] Training [4/62] Loss: 0.03221 
Epoch [267/300] Training [5/62] Loss: 0.03023 
Epoch [267/300] Training [6/62] Loss: 0.03247 
Epoch [267/300] Training [7/62] Loss: 0.03495 
Epoch [267/300] Training [8/62] Loss: 0.03407 
Epoch [267/300] Training [9/62] Loss: 0.03257 
Epoch [267/300] Training [10/62] Loss: 0.04657 
Epoch [267/300] Training [11/62] Loss: 0.02605 
Epoch [267/300] Training [12/62] Loss: 0.02896 
Epoch [267/300] Training [13/62] Loss: 0.03163 
Epoch [267/300] Training [14/62] Loss: 0.02801 
Epoch [267/300] Training [15/62] Loss: 0.02804 
Epoch [267/300] Training [16/62] Loss: 0.02577 
Epoch [267/300] Training [17/62] Loss: 0.02574 
Epoch [267/300] Training [18/62] Loss: 0.02901 
Epoch [267/300] Training [19/62] Loss: 0.02120 
Epoch [267/300] Training [20/62] Loss: 0.03047 
Epoch [267/300] Training [21/62] Loss: 0.04109 
Epoch [267/300] Training [22/62] Loss: 0.02927 
Epoch [267/300] Training [23/62] Loss: 0.02905 
Epoch [267/300] Training [24/62] Loss: 0.03560 
Epoch [267/300] Training [25/62] Loss: 0.03250 
Epoch [267/300] Training [26/62] Loss: 0.02803 
Epoch [267/300] Training [27/62] Loss: 0.05916 
Epoch [267/300] Training [28/62] Loss: 0.02567 
Epoch [267/300] Training [29/62] Loss: 0.02948 
Epoch [267/300] Training [30/62] Loss: 0.03457 
Epoch [267/300] Training [31/62] Loss: 0.02892 
Epoch [267/300] Training [32/62] Loss: 0.03002 
Epoch [267/300] Training [33/62] Loss: 0.02893 
Epoch [267/300] Training [34/62] Loss: 0.02456 
Epoch [267/300] Training [35/62] Loss: 0.03424 
Epoch [267/300] Training [36/62] Loss: 0.02593 
Epoch [267/300] Training [37/62] Loss: 0.04811 
Epoch [267/300] Training [38/62] Loss: 0.04768 
Epoch [267/300] Training [39/62] Loss: 0.04558 
Epoch [267/300] Training [40/62] Loss: 0.03589 
Epoch [267/300] Training [41/62] Loss: 0.02953 
Epoch [267/300] Training [42/62] Loss: 0.03233 
Epoch [267/300] Training [43/62] Loss: 0.02852 
Epoch [267/300] Training [44/62] Loss: 0.02694 
Epoch [267/300] Training [45/62] Loss: 0.03735 
Epoch [267/300] Training [46/62] Loss: 0.08283 
Epoch [267/300] Training [47/62] Loss: 0.02479 
Epoch [267/300] Training [48/62] Loss: 0.04643 
Epoch [267/300] Training [49/62] Loss: 0.02869 
Epoch [267/300] Training [50/62] Loss: 0.03908 
Epoch [267/300] Training [51/62] Loss: 0.02539 
Epoch [267/300] Training [52/62] Loss: 0.02662 
Epoch [267/300] Training [53/62] Loss: 0.02418 
Epoch [267/300] Training [54/62] Loss: 0.02296 
Epoch [267/300] Training [55/62] Loss: 0.02822 
Epoch [267/300] Training [56/62] Loss: 0.03104 
Epoch [267/300] Training [57/62] Loss: 0.03815 
Epoch [267/300] Training [58/62] Loss: 0.03177 
Epoch [267/300] Training [59/62] Loss: 0.02163 
Epoch [267/300] Training [60/62] Loss: 0.03277 
Epoch [267/300] Training [61/62] Loss: 0.02689 
Epoch [267/300] Training [62/62] Loss: 0.03336 
Epoch [267/300] Training metric {'Train/mean dice_metric': 0.9781985878944397, 'Train/mean miou_metric': 0.9577248692512512, 'Train/mean f1': 0.9765644669532776, 'Train/mean precision': 0.9722484350204468, 'Train/mean recall': 0.9809190034866333, 'Train/mean hd95_metric': 2.8077516555786133}
Epoch [267/300] Validation [1/16] Loss: 0.54973  focal_loss 0.34544  dice_loss 0.20429 
Epoch [267/300] Validation [2/16] Loss: 0.41904  focal_loss 0.23968  dice_loss 0.17936 
Epoch [267/300] Validation [3/16] Loss: 0.66281  focal_loss 0.38580  dice_loss 0.27701 
Epoch [267/300] Validation [4/16] Loss: 0.32178  focal_loss 0.17175  dice_loss 0.15003 
Epoch [267/300] Validation [5/16] Loss: 0.37924  focal_loss 0.17725  dice_loss 0.20199 
Epoch [267/300] Validation [6/16] Loss: 0.24060  focal_loss 0.08167  dice_loss 0.15893 
Epoch [267/300] Validation [7/16] Loss: 0.28539  focal_loss 0.16310  dice_loss 0.12229 
Epoch [267/300] Validation [8/16] Loss: 0.26814  focal_loss 0.06759  dice_loss 0.20054 
Epoch [267/300] Validation [9/16] Loss: 0.21291  focal_loss 0.11537  dice_loss 0.09754 
Epoch [267/300] Validation [10/16] Loss: 0.20176  focal_loss 0.07163  dice_loss 0.13013 
Epoch [267/300] Validation [11/16] Loss: 0.11689  focal_loss 0.04211  dice_loss 0.07478 
Epoch [267/300] Validation [12/16] Loss: 0.32985  focal_loss 0.08532  dice_loss 0.24453 
Epoch [267/300] Validation [13/16] Loss: 0.34567  focal_loss 0.13696  dice_loss 0.20871 
Epoch [267/300] Validation [14/16] Loss: 0.55883  focal_loss 0.20440  dice_loss 0.35442 
Epoch [267/300] Validation [15/16] Loss: 0.12403  focal_loss 0.05163  dice_loss 0.07240 
Epoch [267/300] Validation [16/16] Loss: 0.04045  focal_loss 0.01344  dice_loss 0.02701 
Epoch [267/300] Validation metric {'Val/mean dice_metric': 0.9480728507041931, 'Val/mean miou_metric': 0.9165590405464172, 'Val/mean f1': 0.9502488374710083, 'Val/mean precision': 0.9527888894081116, 'Val/mean recall': 0.9477221965789795, 'Val/mean hd95_metric': 9.194830894470215}
Cheakpoint...
Epoch [267/300] best acc:tensor([0.9487], device='cuda:0'), Now : mean acc: tensor([0.9481], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9480728507041931, 'Val/mean miou_metric': 0.9165590405464172, 'Val/mean f1': 0.9502488374710083, 'Val/mean precision': 0.9527888894081116, 'Val/mean recall': 0.9477221965789795, 'Val/mean hd95_metric': 9.194830894470215}
Epoch [268/300] Training [1/62] Loss: 0.03406 
Epoch [268/300] Training [2/62] Loss: 0.02911 
Epoch [268/300] Training [3/62] Loss: 0.03128 
Epoch [268/300] Training [4/62] Loss: 0.02455 
Epoch [268/300] Training [5/62] Loss: 0.05293 
Epoch [268/300] Training [6/62] Loss: 0.03718 
Epoch [268/300] Training [7/62] Loss: 0.03167 
Epoch [268/300] Training [8/62] Loss: 0.02911 
Epoch [268/300] Training [9/62] Loss: 0.03259 
Epoch [268/300] Training [10/62] Loss: 0.02586 
Epoch [268/300] Training [11/62] Loss: 0.03191 
Epoch [268/300] Training [12/62] Loss: 0.02602 
Epoch [268/300] Training [13/62] Loss: 0.02692 
Epoch [268/300] Training [14/62] Loss: 0.06949 
Epoch [268/300] Training [15/62] Loss: 0.02774 
Epoch [268/300] Training [16/62] Loss: 0.03650 
Epoch [268/300] Training [17/62] Loss: 0.04083 
Epoch [268/300] Training [18/62] Loss: 0.03189 
Epoch [268/300] Training [19/62] Loss: 0.02690 
Epoch [268/300] Training [20/62] Loss: 0.02549 
Epoch [268/300] Training [21/62] Loss: 0.03416 
Epoch [268/300] Training [22/62] Loss: 0.02525 
Epoch [268/300] Training [23/62] Loss: 0.04267 
Epoch [268/300] Training [24/62] Loss: 0.02648 
Epoch [268/300] Training [25/62] Loss: 0.03248 
Epoch [268/300] Training [26/62] Loss: 0.03759 
Epoch [268/300] Training [27/62] Loss: 0.02985 
Epoch [268/300] Training [28/62] Loss: 0.03410 
Epoch [268/300] Training [29/62] Loss: 0.03568 
Epoch [268/300] Training [30/62] Loss: 0.02841 
Epoch [268/300] Training [31/62] Loss: 0.02987 
Epoch [268/300] Training [32/62] Loss: 0.02758 
Epoch [268/300] Training [33/62] Loss: 0.02834 
Epoch [268/300] Training [34/62] Loss: 0.02410 
Epoch [268/300] Training [35/62] Loss: 0.06208 
Epoch [268/300] Training [36/62] Loss: 0.02169 
Epoch [268/300] Training [37/62] Loss: 0.05912 
Epoch [268/300] Training [38/62] Loss: 0.02626 
Epoch [268/300] Training [39/62] Loss: 0.03563 
Epoch [268/300] Training [40/62] Loss: 0.03857 
Epoch [268/300] Training [41/62] Loss: 0.02701 
Epoch [268/300] Training [42/62] Loss: 0.02660 
Epoch [268/300] Training [43/62] Loss: 0.03513 
Epoch [268/300] Training [44/62] Loss: 0.02167 
Epoch [268/300] Training [45/62] Loss: 0.03576 
Epoch [268/300] Training [46/62] Loss: 0.04374 
Epoch [268/300] Training [47/62] Loss: 0.03321 
Epoch [268/300] Training [48/62] Loss: 0.04522 
Epoch [268/300] Training [49/62] Loss: 0.02671 
Epoch [268/300] Training [50/62] Loss: 0.02601 
Epoch [268/300] Training [51/62] Loss: 0.02639 
Epoch [268/300] Training [52/62] Loss: 0.02818 
Epoch [268/300] Training [53/62] Loss: 0.03452 
Epoch [268/300] Training [54/62] Loss: 0.03333 
Epoch [268/300] Training [55/62] Loss: 0.04981 
Epoch [268/300] Training [56/62] Loss: 0.02448 
Epoch [268/300] Training [57/62] Loss: 0.04238 
Epoch [268/300] Training [58/62] Loss: 0.03661 
Epoch [268/300] Training [59/62] Loss: 0.03759 
Epoch [268/300] Training [60/62] Loss: 0.03425 
Epoch [268/300] Training [61/62] Loss: 0.02957 
Epoch [268/300] Training [62/62] Loss: 0.02782 
Epoch [268/300] Training metric {'Train/mean dice_metric': 0.9772367477416992, 'Train/mean miou_metric': 0.9560748934745789, 'Train/mean f1': 0.9759176969528198, 'Train/mean precision': 0.9719046950340271, 'Train/mean recall': 0.9799641370773315, 'Train/mean hd95_metric': 3.806105375289917}
Epoch [268/300] Validation [1/16] Loss: 0.24815  focal_loss 0.12124  dice_loss 0.12691 
Epoch [268/300] Validation [2/16] Loss: 0.52494  focal_loss 0.27765  dice_loss 0.24729 
Epoch [268/300] Validation [3/16] Loss: 0.64889  focal_loss 0.38047  dice_loss 0.26842 
Epoch [268/300] Validation [4/16] Loss: 0.30246  focal_loss 0.15935  dice_loss 0.14311 
Epoch [268/300] Validation [5/16] Loss: 0.35433  focal_loss 0.14862  dice_loss 0.20571 
Epoch [268/300] Validation [6/16] Loss: 0.23201  focal_loss 0.06775  dice_loss 0.16426 
Epoch [268/300] Validation [7/16] Loss: 0.29423  focal_loss 0.16878  dice_loss 0.12545 
Epoch [268/300] Validation [8/16] Loss: 0.40277  focal_loss 0.15985  dice_loss 0.24291 
Epoch [268/300] Validation [9/16] Loss: 0.16287  focal_loss 0.07579  dice_loss 0.08708 
Epoch [268/300] Validation [10/16] Loss: 0.44564  focal_loss 0.18943  dice_loss 0.25621 
Epoch [268/300] Validation [11/16] Loss: 0.11817  focal_loss 0.03605  dice_loss 0.08212 
Epoch [268/300] Validation [12/16] Loss: 0.33679  focal_loss 0.09435  dice_loss 0.24244 
Epoch [268/300] Validation [13/16] Loss: 0.34854  focal_loss 0.15036  dice_loss 0.19819 
Epoch [268/300] Validation [14/16] Loss: 0.48123  focal_loss 0.18607  dice_loss 0.29516 
Epoch [268/300] Validation [15/16] Loss: 0.11200  focal_loss 0.04584  dice_loss 0.06617 
Epoch [268/300] Validation [16/16] Loss: 0.04133  focal_loss 0.01395  dice_loss 0.02738 
Epoch [268/300] Validation metric {'Val/mean dice_metric': 0.9462134838104248, 'Val/mean miou_metric': 0.9138711094856262, 'Val/mean f1': 0.9500143527984619, 'Val/mean precision': 0.9498212933540344, 'Val/mean recall': 0.9502074718475342, 'Val/mean hd95_metric': 10.774396896362305}
Cheakpoint...
Epoch [268/300] best acc:tensor([0.9487], device='cuda:0'), Now : mean acc: tensor([0.9462], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9462134838104248, 'Val/mean miou_metric': 0.9138711094856262, 'Val/mean f1': 0.9500143527984619, 'Val/mean precision': 0.9498212933540344, 'Val/mean recall': 0.9502074718475342, 'Val/mean hd95_metric': 10.774396896362305}
Epoch [269/300] Training [1/62] Loss: 0.05212 
Epoch [269/300] Training [2/62] Loss: 0.02106 
Epoch [269/300] Training [3/62] Loss: 0.03140 
Epoch [269/300] Training [4/62] Loss: 0.02736 
Epoch [269/300] Training [5/62] Loss: 0.04335 
Epoch [269/300] Training [6/62] Loss: 0.02626 
Epoch [269/300] Training [7/62] Loss: 0.03456 
Epoch [269/300] Training [8/62] Loss: 0.01970 
Epoch [269/300] Training [9/62] Loss: 0.02877 
Epoch [269/300] Training [10/62] Loss: 0.02882 
Epoch [269/300] Training [11/62] Loss: 0.03163 
Epoch [269/300] Training [12/62] Loss: 0.02778 
Epoch [269/300] Training [13/62] Loss: 0.02652 
Epoch [269/300] Training [14/62] Loss: 0.02384 
Epoch [269/300] Training [15/62] Loss: 0.02985 
Epoch [269/300] Training [16/62] Loss: 0.09557 
Epoch [269/300] Training [17/62] Loss: 0.04229 
Epoch [269/300] Training [18/62] Loss: 0.03004 
Epoch [269/300] Training [19/62] Loss: 0.02948 
Epoch [269/300] Training [20/62] Loss: 0.02903 
Epoch [269/300] Training [21/62] Loss: 0.02667 
Epoch [269/300] Training [22/62] Loss: 0.03494 
Epoch [269/300] Training [23/62] Loss: 0.03242 
Epoch [269/300] Training [24/62] Loss: 0.02847 
Epoch [269/300] Training [25/62] Loss: 0.03682 
Epoch [269/300] Training [26/62] Loss: 0.02380 
Epoch [269/300] Training [27/62] Loss: 0.03166 
Epoch [269/300] Training [28/62] Loss: 0.02650 
Epoch [269/300] Training [29/62] Loss: 0.02593 
Epoch [269/300] Training [30/62] Loss: 0.02992 
Epoch [269/300] Training [31/62] Loss: 0.02923 
Epoch [269/300] Training [32/62] Loss: 0.03489 
Epoch [269/300] Training [33/62] Loss: 0.02351 
Epoch [269/300] Training [34/62] Loss: 0.02884 
Epoch [269/300] Training [35/62] Loss: 0.03243 
Epoch [269/300] Training [36/62] Loss: 0.02612 
Epoch [269/300] Training [37/62] Loss: 0.05889 
Epoch [269/300] Training [38/62] Loss: 0.03203 
Epoch [269/300] Training [39/62] Loss: 0.02374 
Epoch [269/300] Training [40/62] Loss: 0.03163 
Epoch [269/300] Training [41/62] Loss: 0.02362 
Epoch [269/300] Training [42/62] Loss: 0.03976 
Epoch [269/300] Training [43/62] Loss: 0.04173 
Epoch [269/300] Training [44/62] Loss: 0.03834 
Epoch [269/300] Training [45/62] Loss: 0.03859 
Epoch [269/300] Training [46/62] Loss: 0.02457 
Epoch [269/300] Training [47/62] Loss: 0.02939 
Epoch [269/300] Training [48/62] Loss: 0.02643 
Epoch [269/300] Training [49/62] Loss: 0.03423 
Epoch [269/300] Training [50/62] Loss: 0.02734 
Epoch [269/300] Training [51/62] Loss: 0.02416 
Epoch [269/300] Training [52/62] Loss: 0.03403 
Epoch [269/300] Training [53/62] Loss: 0.03511 
Epoch [269/300] Training [54/62] Loss: 0.02917 
Epoch [269/300] Training [55/62] Loss: 0.02041 
Epoch [269/300] Training [56/62] Loss: 0.03348 
Epoch [269/300] Training [57/62] Loss: 0.02948 
Epoch [269/300] Training [58/62] Loss: 0.03292 
Epoch [269/300] Training [59/62] Loss: 0.02662 
Epoch [269/300] Training [60/62] Loss: 0.02216 
Epoch [269/300] Training [61/62] Loss: 0.02919 
Epoch [269/300] Training [62/62] Loss: 0.02885 
Epoch [269/300] Training metric {'Train/mean dice_metric': 0.9786048531532288, 'Train/mean miou_metric': 0.9585657119750977, 'Train/mean f1': 0.9769231081008911, 'Train/mean precision': 0.9725566506385803, 'Train/mean recall': 0.9813287854194641, 'Train/mean hd95_metric': 3.3131046295166016}
Epoch [269/300] Validation [1/16] Loss: 0.49156  focal_loss 0.31408  dice_loss 0.17748 
Epoch [269/300] Validation [2/16] Loss: 0.49324  focal_loss 0.25265  dice_loss 0.24059 
Epoch [269/300] Validation [3/16] Loss: 0.35177  focal_loss 0.13758  dice_loss 0.21419 
Epoch [269/300] Validation [4/16] Loss: 0.30648  focal_loss 0.16351  dice_loss 0.14296 
Epoch [269/300] Validation [5/16] Loss: 0.37216  focal_loss 0.14208  dice_loss 0.23007 
Epoch [269/300] Validation [6/16] Loss: 0.22299  focal_loss 0.06489  dice_loss 0.15810 
Epoch [269/300] Validation [7/16] Loss: 0.25232  focal_loss 0.14326  dice_loss 0.10906 
Epoch [269/300] Validation [8/16] Loss: 0.37475  focal_loss 0.12835  dice_loss 0.24640 
Epoch [269/300] Validation [9/16] Loss: 0.20500  focal_loss 0.10684  dice_loss 0.09815 
Epoch [269/300] Validation [10/16] Loss: 0.57676  focal_loss 0.25730  dice_loss 0.31946 
Epoch [269/300] Validation [11/16] Loss: 0.08673  focal_loss 0.02697  dice_loss 0.05976 
Epoch [269/300] Validation [12/16] Loss: 0.37357  focal_loss 0.11543  dice_loss 0.25814 
Epoch [269/300] Validation [13/16] Loss: 0.19096  focal_loss 0.07531  dice_loss 0.11565 
Epoch [269/300] Validation [14/16] Loss: 0.50053  focal_loss 0.19332  dice_loss 0.30721 
Epoch [269/300] Validation [15/16] Loss: 0.14195  focal_loss 0.06432  dice_loss 0.07763 
Epoch [269/300] Validation [16/16] Loss: 0.04538  focal_loss 0.01538  dice_loss 0.03000 
Epoch [269/300] Validation metric {'Val/mean dice_metric': 0.9472973346710205, 'Val/mean miou_metric': 0.916392982006073, 'Val/mean f1': 0.9509164690971375, 'Val/mean precision': 0.9510357975959778, 'Val/mean recall': 0.9507970809936523, 'Val/mean hd95_metric': 9.559029579162598}
Cheakpoint...
Epoch [269/300] best acc:tensor([0.9487], device='cuda:0'), Now : mean acc: tensor([0.9473], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9472973346710205, 'Val/mean miou_metric': 0.916392982006073, 'Val/mean f1': 0.9509164690971375, 'Val/mean precision': 0.9510357975959778, 'Val/mean recall': 0.9507970809936523, 'Val/mean hd95_metric': 9.559029579162598}
Epoch [270/300] Training [1/62] Loss: 0.04291 
Epoch [270/300] Training [2/62] Loss: 0.04988 
Epoch [270/300] Training [3/62] Loss: 0.03473 
Epoch [270/300] Training [4/62] Loss: 0.03939 
Epoch [270/300] Training [5/62] Loss: 0.02633 
Epoch [270/300] Training [6/62] Loss: 0.02887 
Epoch [270/300] Training [7/62] Loss: 0.03223 
Epoch [270/300] Training [8/62] Loss: 0.02974 
Epoch [270/300] Training [9/62] Loss: 0.02941 
Epoch [270/300] Training [10/62] Loss: 0.02637 
Epoch [270/300] Training [11/62] Loss: 0.02687 
Epoch [270/300] Training [12/62] Loss: 0.02048 
Epoch [270/300] Training [13/62] Loss: 0.02079 
Epoch [270/300] Training [14/62] Loss: 0.03269 
Epoch [270/300] Training [15/62] Loss: 0.02437 
Epoch [270/300] Training [16/62] Loss: 0.03101 
Epoch [270/300] Training [17/62] Loss: 0.03591 
Epoch [270/300] Training [18/62] Loss: 0.04000 
Epoch [270/300] Training [19/62] Loss: 0.02961 
Epoch [270/300] Training [20/62] Loss: 0.03268 
Epoch [270/300] Training [21/62] Loss: 0.03113 
Epoch [270/300] Training [22/62] Loss: 0.03005 
Epoch [270/300] Training [23/62] Loss: 0.05374 
Epoch [270/300] Training [24/62] Loss: 0.04274 
Epoch [270/300] Training [25/62] Loss: 0.02532 
Epoch [270/300] Training [26/62] Loss: 0.09406 
Epoch [270/300] Training [27/62] Loss: 0.02263 
Epoch [270/300] Training [28/62] Loss: 0.03392 
Epoch [270/300] Training [29/62] Loss: 0.03738 
Epoch [270/300] Training [30/62] Loss: 0.03171 
Epoch [270/300] Training [31/62] Loss: 0.02535 
Epoch [270/300] Training [32/62] Loss: 0.02137 
Epoch [270/300] Training [33/62] Loss: 0.02204 
Epoch [270/300] Training [34/62] Loss: 0.02914 
Epoch [270/300] Training [35/62] Loss: 0.02652 
Epoch [270/300] Training [36/62] Loss: 0.03074 
Epoch [270/300] Training [37/62] Loss: 0.02029 
Epoch [270/300] Training [38/62] Loss: 0.02411 
Epoch [270/300] Training [39/62] Loss: 0.03435 
Epoch [270/300] Training [40/62] Loss: 0.04106 
Epoch [270/300] Training [41/62] Loss: 0.02823 
Epoch [270/300] Training [42/62] Loss: 0.02710 
Epoch [270/300] Training [43/62] Loss: 0.02904 
Epoch [270/300] Training [44/62] Loss: 0.03182 
Epoch [270/300] Training [45/62] Loss: 0.02711 
Epoch [270/300] Training [46/62] Loss: 0.02521 
Epoch [270/300] Training [47/62] Loss: 0.03926 
Epoch [270/300] Training [48/62] Loss: 0.02416 
Epoch [270/300] Training [49/62] Loss: 0.03489 
Epoch [270/300] Training [50/62] Loss: 0.02301 
Epoch [270/300] Training [51/62] Loss: 0.02879 
Epoch [270/300] Training [52/62] Loss: 0.03323 
Epoch [270/300] Training [53/62] Loss: 0.03224 
Epoch [270/300] Training [54/62] Loss: 0.02547 
Epoch [270/300] Training [55/62] Loss: 0.02238 
Epoch [270/300] Training [56/62] Loss: 0.03182 
Epoch [270/300] Training [57/62] Loss: 0.02719 
Epoch [270/300] Training [58/62] Loss: 0.04060 
Epoch [270/300] Training [59/62] Loss: 0.03146 
Epoch [270/300] Training [60/62] Loss: 0.02594 
Epoch [270/300] Training [61/62] Loss: 0.02015 
Epoch [270/300] Training [62/62] Loss: 0.02414 
Epoch [270/300] Training metric {'Train/mean dice_metric': 0.9788379073143005, 'Train/mean miou_metric': 0.9591542482376099, 'Train/mean f1': 0.9765635132789612, 'Train/mean precision': 0.9716953039169312, 'Train/mean recall': 0.9814806580543518, 'Train/mean hd95_metric': 3.08302903175354}
Epoch [270/300] Validation [1/16] Loss: 0.52379  focal_loss 0.35425  dice_loss 0.16953 
Epoch [270/300] Validation [2/16] Loss: 0.53737  focal_loss 0.28136  dice_loss 0.25601 
Epoch [270/300] Validation [3/16] Loss: 0.32626  focal_loss 0.12851  dice_loss 0.19775 
Epoch [270/300] Validation [4/16] Loss: 0.29186  focal_loss 0.15428  dice_loss 0.13758 
Epoch [270/300] Validation [5/16] Loss: 0.37243  focal_loss 0.13228  dice_loss 0.24015 
Epoch [270/300] Validation [6/16] Loss: 0.23741  focal_loss 0.06734  dice_loss 0.17007 
Epoch [270/300] Validation [7/16] Loss: 0.27284  focal_loss 0.15577  dice_loss 0.11707 
Epoch [270/300] Validation [8/16] Loss: 0.41869  focal_loss 0.16263  dice_loss 0.25606 
Epoch [270/300] Validation [9/16] Loss: 0.21255  focal_loss 0.11314  dice_loss 0.09942 
Epoch [270/300] Validation [10/16] Loss: 0.29161  focal_loss 0.10274  dice_loss 0.18887 
Epoch [270/300] Validation [11/16] Loss: 0.11245  focal_loss 0.04788  dice_loss 0.06457 
Epoch [270/300] Validation [12/16] Loss: 0.32387  focal_loss 0.08827  dice_loss 0.23560 
Epoch [270/300] Validation [13/16] Loss: 0.36604  focal_loss 0.16034  dice_loss 0.20570 
Epoch [270/300] Validation [14/16] Loss: 0.61328  focal_loss 0.23253  dice_loss 0.38076 
Epoch [270/300] Validation [15/16] Loss: 0.13013  focal_loss 0.05418  dice_loss 0.07595 
Epoch [270/300] Validation [16/16] Loss: 0.04424  focal_loss 0.01577  dice_loss 0.02847 
Epoch [270/300] Validation metric {'Val/mean dice_metric': 0.946927547454834, 'Val/mean miou_metric': 0.9156789183616638, 'Val/mean f1': 0.9503244161605835, 'Val/mean precision': 0.9507158398628235, 'Val/mean recall': 0.9499335289001465, 'Val/mean hd95_metric': 10.368734359741211}
Cheakpoint...
Epoch [270/300] best acc:tensor([0.9487], device='cuda:0'), Now : mean acc: tensor([0.9469], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.946927547454834, 'Val/mean miou_metric': 0.9156789183616638, 'Val/mean f1': 0.9503244161605835, 'Val/mean precision': 0.9507158398628235, 'Val/mean recall': 0.9499335289001465, 'Val/mean hd95_metric': 10.368734359741211}
Epoch [271/300] Training [1/62] Loss: 0.03914 
Epoch [271/300] Training [2/62] Loss: 0.03011 
Epoch [271/300] Training [3/62] Loss: 0.03116 
Epoch [271/300] Training [4/62] Loss: 0.02890 
Epoch [271/300] Training [5/62] Loss: 0.09335 
Epoch [271/300] Training [6/62] Loss: 0.03773 
Epoch [271/300] Training [7/62] Loss: 0.02496 
Epoch [271/300] Training [8/62] Loss: 0.03072 
Epoch [271/300] Training [9/62] Loss: 0.03707 
Epoch [271/300] Training [10/62] Loss: 0.04403 
Epoch [271/300] Training [11/62] Loss: 0.01859 
Epoch [271/300] Training [12/62] Loss: 0.02170 
Epoch [271/300] Training [13/62] Loss: 0.02577 
Epoch [271/300] Training [14/62] Loss: 0.05701 
Epoch [271/300] Training [15/62] Loss: 0.02951 
Epoch [271/300] Training [16/62] Loss: 0.02523 
Epoch [271/300] Training [17/62] Loss: 0.04104 
Epoch [271/300] Training [18/62] Loss: 0.05939 
Epoch [271/300] Training [19/62] Loss: 0.03311 
Epoch [271/300] Training [20/62] Loss: 0.02694 
Epoch [271/300] Training [21/62] Loss: 0.04718 
Epoch [271/300] Training [22/62] Loss: 0.03377 
Epoch [271/300] Training [23/62] Loss: 0.02469 
Epoch [271/300] Training [24/62] Loss: 0.02540 
Epoch [271/300] Training [25/62] Loss: 0.02230 
Epoch [271/300] Training [26/62] Loss: 0.02894 
Epoch [271/300] Training [27/62] Loss: 0.03355 
Epoch [271/300] Training [28/62] Loss: 0.02653 
Epoch [271/300] Training [29/62] Loss: 0.03783 
Epoch [271/300] Training [30/62] Loss: 0.04712 
Epoch [271/300] Training [31/62] Loss: 0.03236 
Epoch [271/300] Training [32/62] Loss: 0.02994 
Epoch [271/300] Training [33/62] Loss: 0.02812 
Epoch [271/300] Training [34/62] Loss: 0.03784 
Epoch [271/300] Training [35/62] Loss: 0.02367 
Epoch [271/300] Training [36/62] Loss: 0.03086 
Epoch [271/300] Training [37/62] Loss: 0.02086 
Epoch [271/300] Training [38/62] Loss: 0.02921 
Epoch [271/300] Training [39/62] Loss: 0.02080 
Epoch [271/300] Training [40/62] Loss: 0.02862 
Epoch [271/300] Training [41/62] Loss: 0.02773 
Epoch [271/300] Training [42/62] Loss: 0.02238 
Epoch [271/300] Training [43/62] Loss: 0.03491 
Epoch [271/300] Training [44/62] Loss: 0.02945 
Epoch [271/300] Training [45/62] Loss: 0.02938 
Epoch [271/300] Training [46/62] Loss: 0.02836 
Epoch [271/300] Training [47/62] Loss: 0.03564 
Epoch [271/300] Training [48/62] Loss: 0.02602 
Epoch [271/300] Training [49/62] Loss: 0.02798 
Epoch [271/300] Training [50/62] Loss: 0.02782 
Epoch [271/300] Training [51/62] Loss: 0.02665 
Epoch [271/300] Training [52/62] Loss: 0.03771 
Epoch [271/300] Training [53/62] Loss: 0.02810 
Epoch [271/300] Training [54/62] Loss: 0.03242 
Epoch [271/300] Training [55/62] Loss: 0.02380 
Epoch [271/300] Training [56/62] Loss: 0.03846 
Epoch [271/300] Training [57/62] Loss: 0.02221 
Epoch [271/300] Training [58/62] Loss: 0.02970 
Epoch [271/300] Training [59/62] Loss: 0.02759 
Epoch [271/300] Training [60/62] Loss: 0.02999 
Epoch [271/300] Training [61/62] Loss: 0.03280 
Epoch [271/300] Training [62/62] Loss: 0.02574 
Epoch [271/300] Training metric {'Train/mean dice_metric': 0.9782715439796448, 'Train/mean miou_metric': 0.9582120180130005, 'Train/mean f1': 0.9765285849571228, 'Train/mean precision': 0.9720431566238403, 'Train/mean recall': 0.9810555577278137, 'Train/mean hd95_metric': 2.9623708724975586}
Epoch [271/300] Validation [1/16] Loss: 0.21384  focal_loss 0.10759  dice_loss 0.10625 
Epoch [271/300] Validation [2/16] Loss: 0.49576  focal_loss 0.25156  dice_loss 0.24420 
Epoch [271/300] Validation [3/16] Loss: 0.66230  focal_loss 0.39067  dice_loss 0.27163 
Epoch [271/300] Validation [4/16] Loss: 0.25669  focal_loss 0.12585  dice_loss 0.13083 
Epoch [271/300] Validation [5/16] Loss: 0.29008  focal_loss 0.12312  dice_loss 0.16696 
Epoch [271/300] Validation [6/16] Loss: 0.22479  focal_loss 0.05796  dice_loss 0.16682 
Epoch [271/300] Validation [7/16] Loss: 0.33536  focal_loss 0.18307  dice_loss 0.15229 
Epoch [271/300] Validation [8/16] Loss: 0.42464  focal_loss 0.17358  dice_loss 0.25106 
Epoch [271/300] Validation [9/16] Loss: 0.21204  focal_loss 0.11151  dice_loss 0.10053 
Epoch [271/300] Validation [10/16] Loss: 0.24992  focal_loss 0.11409  dice_loss 0.13582 
Epoch [271/300] Validation [11/16] Loss: 0.10791  focal_loss 0.03843  dice_loss 0.06948 
Epoch [271/300] Validation [12/16] Loss: 0.32631  focal_loss 0.08514  dice_loss 0.24117 
Epoch [271/300] Validation [13/16] Loss: 0.24620  focal_loss 0.09548  dice_loss 0.15072 
Epoch [271/300] Validation [14/16] Loss: 0.47977  focal_loss 0.19400  dice_loss 0.28576 
Epoch [271/300] Validation [15/16] Loss: 0.10900  focal_loss 0.04602  dice_loss 0.06298 
Epoch [271/300] Validation [16/16] Loss: 0.05186  focal_loss 0.02004  dice_loss 0.03182 
Epoch [271/300] Validation metric {'Val/mean dice_metric': 0.9498067498207092, 'Val/mean miou_metric': 0.9183930158615112, 'Val/mean f1': 0.9523741006851196, 'Val/mean precision': 0.951421320438385, 'Val/mean recall': 0.9533288478851318, 'Val/mean hd95_metric': 9.872516632080078}
Cheakpoint...
Epoch [271/300] best acc:tensor([0.9498], device='cuda:0'), Now : mean acc: tensor([0.9498], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9498067498207092, 'Val/mean miou_metric': 0.9183930158615112, 'Val/mean f1': 0.9523741006851196, 'Val/mean precision': 0.951421320438385, 'Val/mean recall': 0.9533288478851318, 'Val/mean hd95_metric': 9.872516632080078}
Epoch [272/300] Training [1/62] Loss: 0.02721 
Epoch [272/300] Training [2/62] Loss: 0.03425 
Epoch [272/300] Training [3/62] Loss: 0.02890 
Epoch [272/300] Training [4/62] Loss: 0.01874 
Epoch [272/300] Training [5/62] Loss: 0.03091 
Epoch [272/300] Training [6/62] Loss: 0.03103 
Epoch [272/300] Training [7/62] Loss: 0.03278 
Epoch [272/300] Training [8/62] Loss: 0.02112 
Epoch [272/300] Training [9/62] Loss: 0.03382 
Epoch [272/300] Training [10/62] Loss: 0.02708 
Epoch [272/300] Training [11/62] Loss: 0.02537 
Epoch [272/300] Training [12/62] Loss: 0.02256 
Epoch [272/300] Training [13/62] Loss: 0.03475 
Epoch [272/300] Training [14/62] Loss: 0.03648 
Epoch [272/300] Training [15/62] Loss: 0.02463 
Epoch [272/300] Training [16/62] Loss: 0.04253 
Epoch [272/300] Training [17/62] Loss: 0.03608 
Epoch [272/300] Training [18/62] Loss: 0.02877 
Epoch [272/300] Training [19/62] Loss: 0.04247 
Epoch [272/300] Training [20/62] Loss: 0.02460 
Epoch [272/300] Training [21/62] Loss: 0.02828 
Epoch [272/300] Training [22/62] Loss: 0.02055 
Epoch [272/300] Training [23/62] Loss: 0.02260 
Epoch [272/300] Training [24/62] Loss: 0.02779 
Epoch [272/300] Training [25/62] Loss: 0.02478 
Epoch [272/300] Training [26/62] Loss: 0.02952 
Epoch [272/300] Training [27/62] Loss: 0.02268 
Epoch [272/300] Training [28/62] Loss: 0.03452 
Epoch [272/300] Training [29/62] Loss: 0.03195 
Epoch [272/300] Training [30/62] Loss: 0.02619 
Epoch [272/300] Training [31/62] Loss: 0.04166 
Epoch [272/300] Training [32/62] Loss: 0.03749 
Epoch [272/300] Training [33/62] Loss: 0.03697 
Epoch [272/300] Training [34/62] Loss: 0.02461 
Epoch [272/300] Training [35/62] Loss: 0.03523 
Epoch [272/300] Training [36/62] Loss: 0.01819 
Epoch [272/300] Training [37/62] Loss: 0.05043 
Epoch [272/300] Training [38/62] Loss: 0.02824 
Epoch [272/300] Training [39/62] Loss: 0.03143 
Epoch [272/300] Training [40/62] Loss: 0.02694 
Epoch [272/300] Training [41/62] Loss: 0.03414 
Epoch [272/300] Training [42/62] Loss: 0.05989 
Epoch [272/300] Training [43/62] Loss: 0.08422 
Epoch [272/300] Training [44/62] Loss: 0.03874 
Epoch [272/300] Training [45/62] Loss: 0.02096 
Epoch [272/300] Training [46/62] Loss: 0.04035 
Epoch [272/300] Training [47/62] Loss: 0.04042 
Epoch [272/300] Training [48/62] Loss: 0.02139 
Epoch [272/300] Training [49/62] Loss: 0.02834 
Epoch [272/300] Training [50/62] Loss: 0.03132 
Epoch [272/300] Training [51/62] Loss: 0.02616 
Epoch [272/300] Training [52/62] Loss: 0.04174 
Epoch [272/300] Training [53/62] Loss: 0.04459 
Epoch [272/300] Training [54/62] Loss: 0.03426 
Epoch [272/300] Training [55/62] Loss: 0.02620 
Epoch [272/300] Training [56/62] Loss: 0.08056 
Epoch [272/300] Training [57/62] Loss: 0.03424 
Epoch [272/300] Training [58/62] Loss: 0.03625 
Epoch [272/300] Training [59/62] Loss: 0.02960 
Epoch [272/300] Training [60/62] Loss: 0.02873 
Epoch [272/300] Training [61/62] Loss: 0.02880 
Epoch [272/300] Training [62/62] Loss: 0.03282 
Epoch [272/300] Training metric {'Train/mean dice_metric': 0.9778490662574768, 'Train/mean miou_metric': 0.9573970437049866, 'Train/mean f1': 0.9762300848960876, 'Train/mean precision': 0.9717028737068176, 'Train/mean recall': 0.9807996153831482, 'Train/mean hd95_metric': 2.9981601238250732}
Epoch [272/300] Validation [1/16] Loss: 0.18952  focal_loss 0.09517  dice_loss 0.09434 
Epoch [272/300] Validation [2/16] Loss: 0.49065  focal_loss 0.24598  dice_loss 0.24467 
Epoch [272/300] Validation [3/16] Loss: 0.34046  focal_loss 0.12919  dice_loss 0.21127 
Epoch [272/300] Validation [4/16] Loss: 0.30774  focal_loss 0.16109  dice_loss 0.14664 
Epoch [272/300] Validation [5/16] Loss: 0.34612  focal_loss 0.14340  dice_loss 0.20272 
Epoch [272/300] Validation [6/16] Loss: 0.21354  focal_loss 0.04722  dice_loss 0.16632 
Epoch [272/300] Validation [7/16] Loss: 0.27939  focal_loss 0.15514  dice_loss 0.12425 
Epoch [272/300] Validation [8/16] Loss: 0.39984  focal_loss 0.15591  dice_loss 0.24393 
Epoch [272/300] Validation [9/16] Loss: 0.16948  focal_loss 0.08155  dice_loss 0.08792 
Epoch [272/300] Validation [10/16] Loss: 0.28258  focal_loss 0.13033  dice_loss 0.15226 
Epoch [272/300] Validation [11/16] Loss: 0.12282  focal_loss 0.04920  dice_loss 0.07362 
Epoch [272/300] Validation [12/16] Loss: 0.33677  focal_loss 0.09530  dice_loss 0.24148 
Epoch [272/300] Validation [13/16] Loss: 0.36677  focal_loss 0.16154  dice_loss 0.20523 
Epoch [272/300] Validation [14/16] Loss: 0.41816  focal_loss 0.16645  dice_loss 0.25171 
Epoch [272/300] Validation [15/16] Loss: 0.11090  focal_loss 0.04111  dice_loss 0.06980 
Epoch [272/300] Validation [16/16] Loss: 0.05324  focal_loss 0.01963  dice_loss 0.03361 
Epoch [272/300] Validation metric {'Val/mean dice_metric': 0.9496956467628479, 'Val/mean miou_metric': 0.9178542494773865, 'Val/mean f1': 0.9527724981307983, 'Val/mean precision': 0.9506277441978455, 'Val/mean recall': 0.9549269676208496, 'Val/mean hd95_metric': 9.082619667053223}
Cheakpoint...
Epoch [272/300] best acc:tensor([0.9498], device='cuda:0'), Now : mean acc: tensor([0.9497], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9496956467628479, 'Val/mean miou_metric': 0.9178542494773865, 'Val/mean f1': 0.9527724981307983, 'Val/mean precision': 0.9506277441978455, 'Val/mean recall': 0.9549269676208496, 'Val/mean hd95_metric': 9.082619667053223}
Epoch [273/300] Training [1/62] Loss: 0.02355 
Epoch [273/300] Training [2/62] Loss: 0.04275 
Epoch [273/300] Training [3/62] Loss: 0.04034 
Epoch [273/300] Training [4/62] Loss: 0.03615 
Epoch [273/300] Training [5/62] Loss: 0.03512 
Epoch [273/300] Training [6/62] Loss: 0.02383 
Epoch [273/300] Training [7/62] Loss: 0.03429 
Epoch [273/300] Training [8/62] Loss: 0.03280 
Epoch [273/300] Training [9/62] Loss: 0.03394 
Epoch [273/300] Training [10/62] Loss: 0.03091 
Epoch [273/300] Training [11/62] Loss: 0.02614 
Epoch [273/300] Training [12/62] Loss: 0.03092 
Epoch [273/300] Training [13/62] Loss: 0.03238 
Epoch [273/300] Training [14/62] Loss: 0.02787 
Epoch [273/300] Training [15/62] Loss: 0.02886 
Epoch [273/300] Training [16/62] Loss: 0.02827 
Epoch [273/300] Training [17/62] Loss: 0.02520 
Epoch [273/300] Training [18/62] Loss: 0.04324 
Epoch [273/300] Training [19/62] Loss: 0.02283 
Epoch [273/300] Training [20/62] Loss: 0.03914 
Epoch [273/300] Training [21/62] Loss: 0.02553 
Epoch [273/300] Training [22/62] Loss: 0.02837 
Epoch [273/300] Training [23/62] Loss: 0.03561 
Epoch [273/300] Training [24/62] Loss: 0.03071 
Epoch [273/300] Training [25/62] Loss: 0.02612 
Epoch [273/300] Training [26/62] Loss: 0.02427 
Epoch [273/300] Training [27/62] Loss: 0.04060 
Epoch [273/300] Training [28/62] Loss: 0.03896 
Epoch [273/300] Training [29/62] Loss: 0.02692 
Epoch [273/300] Training [30/62] Loss: 0.03005 
Epoch [273/300] Training [31/62] Loss: 0.03565 
Epoch [273/300] Training [32/62] Loss: 0.02405 
Epoch [273/300] Training [33/62] Loss: 0.03308 
Epoch [273/300] Training [34/62] Loss: 0.02535 
Epoch [273/300] Training [35/62] Loss: 0.03099 
Epoch [273/300] Training [36/62] Loss: 0.02609 
Epoch [273/300] Training [37/62] Loss: 0.02534 
Epoch [273/300] Training [38/62] Loss: 0.03639 
Epoch [273/300] Training [39/62] Loss: 0.03247 
Epoch [273/300] Training [40/62] Loss: 0.03239 
Epoch [273/300] Training [41/62] Loss: 0.02884 
Epoch [273/300] Training [42/62] Loss: 0.02867 
Epoch [273/300] Training [43/62] Loss: 0.03700 
Epoch [273/300] Training [44/62] Loss: 0.03339 
Epoch [273/300] Training [45/62] Loss: 0.02405 
Epoch [273/300] Training [46/62] Loss: 0.03780 
Epoch [273/300] Training [47/62] Loss: 0.02917 
Epoch [273/300] Training [48/62] Loss: 0.02985 
Epoch [273/300] Training [49/62] Loss: 0.02375 
Epoch [273/300] Training [50/62] Loss: 0.02480 
Epoch [273/300] Training [51/62] Loss: 0.02790 
Epoch [273/300] Training [52/62] Loss: 0.02835 
Epoch [273/300] Training [53/62] Loss: 0.02124 
Epoch [273/300] Training [54/62] Loss: 0.03125 
Epoch [273/300] Training [55/62] Loss: 0.02203 
Epoch [273/300] Training [56/62] Loss: 0.02522 
Epoch [273/300] Training [57/62] Loss: 0.02711 
Epoch [273/300] Training [58/62] Loss: 0.02983 
Epoch [273/300] Training [59/62] Loss: 0.02404 
Epoch [273/300] Training [60/62] Loss: 0.03484 
Epoch [273/300] Training [61/62] Loss: 0.06038 
Epoch [273/300] Training [62/62] Loss: 0.03073 
Epoch [273/300] Training metric {'Train/mean dice_metric': 0.9792995452880859, 'Train/mean miou_metric': 0.9595401883125305, 'Train/mean f1': 0.9771742820739746, 'Train/mean precision': 0.9727632999420166, 'Train/mean recall': 0.9816254377365112, 'Train/mean hd95_metric': 2.7619400024414062}
Epoch [273/300] Validation [1/16] Loss: 0.21121  focal_loss 0.10732  dice_loss 0.10390 
Epoch [273/300] Validation [2/16] Loss: 0.52363  focal_loss 0.27484  dice_loss 0.24879 
Epoch [273/300] Validation [3/16] Loss: 0.68106  focal_loss 0.40631  dice_loss 0.27475 
Epoch [273/300] Validation [4/16] Loss: 0.30472  focal_loss 0.16324  dice_loss 0.14148 
Epoch [273/300] Validation [5/16] Loss: 0.36151  focal_loss 0.15184  dice_loss 0.20967 
Epoch [273/300] Validation [6/16] Loss: 0.29048  focal_loss 0.10289  dice_loss 0.18759 
Epoch [273/300] Validation [7/16] Loss: 0.29539  focal_loss 0.16822  dice_loss 0.12716 
Epoch [273/300] Validation [8/16] Loss: 0.30521  focal_loss 0.09278  dice_loss 0.21242 
Epoch [273/300] Validation [9/16] Loss: 0.21302  focal_loss 0.11164  dice_loss 0.10138 
Epoch [273/300] Validation [10/16] Loss: 0.25506  focal_loss 0.11567  dice_loss 0.13939 
Epoch [273/300] Validation [11/16] Loss: 0.14604  focal_loss 0.05989  dice_loss 0.08615 
Epoch [273/300] Validation [12/16] Loss: 0.34918  focal_loss 0.11360  dice_loss 0.23558 
Epoch [273/300] Validation [13/16] Loss: 0.34679  focal_loss 0.14864  dice_loss 0.19815 
Epoch [273/300] Validation [14/16] Loss: 0.37526  focal_loss 0.14010  dice_loss 0.23516 
Epoch [273/300] Validation [15/16] Loss: 0.11351  focal_loss 0.04595  dice_loss 0.06755 
Epoch [273/300] Validation [16/16] Loss: 0.04241  focal_loss 0.01427  dice_loss 0.02814 
Epoch [273/300] Validation metric {'Val/mean dice_metric': 0.9503047466278076, 'Val/mean miou_metric': 0.9186102151870728, 'Val/mean f1': 0.9514010548591614, 'Val/mean precision': 0.9502536058425903, 'Val/mean recall': 0.9525511860847473, 'Val/mean hd95_metric': 9.956785202026367}
Cheakpoint...
Epoch [273/300] best acc:tensor([0.9503], device='cuda:0'), Now : mean acc: tensor([0.9503], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9503047466278076, 'Val/mean miou_metric': 0.9186102151870728, 'Val/mean f1': 0.9514010548591614, 'Val/mean precision': 0.9502536058425903, 'Val/mean recall': 0.9525511860847473, 'Val/mean hd95_metric': 9.956785202026367}
Epoch [274/300] Training [1/62] Loss: 0.02477 
Epoch [274/300] Training [2/62] Loss: 0.03690 
Epoch [274/300] Training [3/62] Loss: 0.03429 
Epoch [274/300] Training [4/62] Loss: 0.02658 
Epoch [274/300] Training [5/62] Loss: 0.02372 
Epoch [274/300] Training [6/62] Loss: 0.03516 
Epoch [274/300] Training [7/62] Loss: 0.02396 
Epoch [274/300] Training [8/62] Loss: 0.02248 
Epoch [274/300] Training [9/62] Loss: 0.02101 
Epoch [274/300] Training [10/62] Loss: 0.02960 
Epoch [274/300] Training [11/62] Loss: 0.02890 
Epoch [274/300] Training [12/62] Loss: 0.05967 
Epoch [274/300] Training [13/62] Loss: 0.02737 
Epoch [274/300] Training [14/62] Loss: 0.03340 
Epoch [274/300] Training [15/62] Loss: 0.03080 
Epoch [274/300] Training [16/62] Loss: 0.02662 
Epoch [274/300] Training [17/62] Loss: 0.03077 
Epoch [274/300] Training [18/62] Loss: 0.02982 
Epoch [274/300] Training [19/62] Loss: 0.03332 
Epoch [274/300] Training [20/62] Loss: 0.04357 
Epoch [274/300] Training [21/62] Loss: 0.01841 
Epoch [274/300] Training [22/62] Loss: 0.04963 
Epoch [274/300] Training [23/62] Loss: 0.02336 
Epoch [274/300] Training [24/62] Loss: 0.02790 
Epoch [274/300] Training [25/62] Loss: 0.02549 
Epoch [274/300] Training [26/62] Loss: 0.06693 
Epoch [274/300] Training [27/62] Loss: 0.03193 
Epoch [274/300] Training [28/62] Loss: 0.03170 
Epoch [274/300] Training [29/62] Loss: 0.03128 
Epoch [274/300] Training [30/62] Loss: 0.04494 
Epoch [274/300] Training [31/62] Loss: 0.03077 
Epoch [274/300] Training [32/62] Loss: 0.03205 
Epoch [274/300] Training [33/62] Loss: 0.02388 
Epoch [274/300] Training [34/62] Loss: 0.03155 
Epoch [274/300] Training [35/62] Loss: 0.03119 
Epoch [274/300] Training [36/62] Loss: 0.02980 
Epoch [274/300] Training [37/62] Loss: 0.02759 
Epoch [274/300] Training [38/62] Loss: 0.02578 
Epoch [274/300] Training [39/62] Loss: 0.07505 
Epoch [274/300] Training [40/62] Loss: 0.02845 
Epoch [274/300] Training [41/62] Loss: 0.02486 
Epoch [274/300] Training [42/62] Loss: 0.02810 
Epoch [274/300] Training [43/62] Loss: 0.02860 
Epoch [274/300] Training [44/62] Loss: 0.02106 
Epoch [274/300] Training [45/62] Loss: 0.02460 
Epoch [274/300] Training [46/62] Loss: 0.02130 
Epoch [274/300] Training [47/62] Loss: 0.03065 
Epoch [274/300] Training [48/62] Loss: 0.02672 
Epoch [274/300] Training [49/62] Loss: 0.06629 
Epoch [274/300] Training [50/62] Loss: 0.04295 
Epoch [274/300] Training [51/62] Loss: 0.02972 
Epoch [274/300] Training [52/62] Loss: 0.03573 
Epoch [274/300] Training [53/62] Loss: 0.04260 
Epoch [274/300] Training [54/62] Loss: 0.07386 
Epoch [274/300] Training [55/62] Loss: 0.02818 
Epoch [274/300] Training [56/62] Loss: 0.03365 
Epoch [274/300] Training [57/62] Loss: 0.02290 
Epoch [274/300] Training [58/62] Loss: 0.02636 
Epoch [274/300] Training [59/62] Loss: 0.04449 
Epoch [274/300] Training [60/62] Loss: 0.03269 
Epoch [274/300] Training [61/62] Loss: 0.02624 
Epoch [274/300] Training [62/62] Loss: 0.04750 
Epoch [274/300] Training metric {'Train/mean dice_metric': 0.9776255488395691, 'Train/mean miou_metric': 0.9569582939147949, 'Train/mean f1': 0.976521909236908, 'Train/mean precision': 0.9718018770217896, 'Train/mean recall': 0.9812880754470825, 'Train/mean hd95_metric': 3.739637851715088}
Epoch [274/300] Validation [1/16] Loss: 0.20940  focal_loss 0.10359  dice_loss 0.10582 
Epoch [274/300] Validation [2/16] Loss: 0.48495  focal_loss 0.24755  dice_loss 0.23740 
Epoch [274/300] Validation [3/16] Loss: 0.66405  focal_loss 0.38653  dice_loss 0.27752 
Epoch [274/300] Validation [4/16] Loss: 0.30195  focal_loss 0.14064  dice_loss 0.16131 
Epoch [274/300] Validation [5/16] Loss: 0.39024  focal_loss 0.15920  dice_loss 0.23104 
Epoch [274/300] Validation [6/16] Loss: 0.26321  focal_loss 0.06454  dice_loss 0.19867 
Epoch [274/300] Validation [7/16] Loss: 0.28623  focal_loss 0.16220  dice_loss 0.12404 
Epoch [274/300] Validation [8/16] Loss: 0.31499  focal_loss 0.10305  dice_loss 0.21194 
Epoch [274/300] Validation [9/16] Loss: 0.16900  focal_loss 0.08401  dice_loss 0.08499 
Epoch [274/300] Validation [10/16] Loss: 0.51045  focal_loss 0.20570  dice_loss 0.30475 
Epoch [274/300] Validation [11/16] Loss: 0.16960  focal_loss 0.06442  dice_loss 0.10518 
Epoch [274/300] Validation [12/16] Loss: 0.39474  focal_loss 0.13510  dice_loss 0.25964 
Epoch [274/300] Validation [13/16] Loss: 0.36621  focal_loss 0.15931  dice_loss 0.20689 
Epoch [274/300] Validation [14/16] Loss: 0.44618  focal_loss 0.16530  dice_loss 0.28089 
Epoch [274/300] Validation [15/16] Loss: 0.14129  focal_loss 0.06530  dice_loss 0.07599 
Epoch [274/300] Validation [16/16] Loss: 0.05365  focal_loss 0.02123  dice_loss 0.03243 
Epoch [274/300] Validation metric {'Val/mean dice_metric': 0.945050835609436, 'Val/mean miou_metric': 0.9129964709281921, 'Val/mean f1': 0.9507471323013306, 'Val/mean precision': 0.9500977993011475, 'Val/mean recall': 0.9513971209526062, 'Val/mean hd95_metric': 11.806066513061523}
Cheakpoint...
Epoch [274/300] best acc:tensor([0.9503], device='cuda:0'), Now : mean acc: tensor([0.9451], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.945050835609436, 'Val/mean miou_metric': 0.9129964709281921, 'Val/mean f1': 0.9507471323013306, 'Val/mean precision': 0.9500977993011475, 'Val/mean recall': 0.9513971209526062, 'Val/mean hd95_metric': 11.806066513061523}
Epoch [275/300] Training [1/62] Loss: 0.03471 
Epoch [275/300] Training [2/62] Loss: 0.02644 
Epoch [275/300] Training [3/62] Loss: 0.02730 
Epoch [275/300] Training [4/62] Loss: 0.02860 
Epoch [275/300] Training [5/62] Loss: 0.04718 
Epoch [275/300] Training [6/62] Loss: 0.02492 
Epoch [275/300] Training [7/62] Loss: 0.02325 
Epoch [275/300] Training [8/62] Loss: 0.02964 
Epoch [275/300] Training [9/62] Loss: 0.02190 
Epoch [275/300] Training [10/62] Loss: 0.02725 
Epoch [275/300] Training [11/62] Loss: 0.02850 
Epoch [275/300] Training [12/62] Loss: 0.02977 
Epoch [275/300] Training [13/62] Loss: 0.03513 
Epoch [275/300] Training [14/62] Loss: 0.03289 
Epoch [275/300] Training [15/62] Loss: 0.03966 
Epoch [275/300] Training [16/62] Loss: 0.02653 
Epoch [275/300] Training [17/62] Loss: 0.02844 
Epoch [275/300] Training [18/62] Loss: 0.07108 
Epoch [275/300] Training [19/62] Loss: 0.03519 
Epoch [275/300] Training [20/62] Loss: 0.05668 
Epoch [275/300] Training [21/62] Loss: 0.02263 
Epoch [275/300] Training [22/62] Loss: 0.03298 
Epoch [275/300] Training [23/62] Loss: 0.03402 
Epoch [275/300] Training [24/62] Loss: 0.06696 
Epoch [275/300] Training [25/62] Loss: 0.02637 
Epoch [275/300] Training [26/62] Loss: 0.02266 
Epoch [275/300] Training [27/62] Loss: 0.04513 
Epoch [275/300] Training [28/62] Loss: 0.03971 
Epoch [275/300] Training [29/62] Loss: 0.01812 
Epoch [275/300] Training [30/62] Loss: 0.02555 
Epoch [275/300] Training [31/62] Loss: 0.02914 
Epoch [275/300] Training [32/62] Loss: 0.02688 
Epoch [275/300] Training [33/62] Loss: 0.03272 
Epoch [275/300] Training [34/62] Loss: 0.02698 
Epoch [275/300] Training [35/62] Loss: 0.03133 
Epoch [275/300] Training [36/62] Loss: 0.02484 
Epoch [275/300] Training [37/62] Loss: 0.02726 
Epoch [275/300] Training [38/62] Loss: 0.02663 
Epoch [275/300] Training [39/62] Loss: 0.03033 
Epoch [275/300] Training [40/62] Loss: 0.03423 
Epoch [275/300] Training [41/62] Loss: 0.05616 
Epoch [275/300] Training [42/62] Loss: 0.05245 
Epoch [275/300] Training [43/62] Loss: 0.02634 
Epoch [275/300] Training [44/62] Loss: 0.04106 
Epoch [275/300] Training [45/62] Loss: 0.03808 
Epoch [275/300] Training [46/62] Loss: 0.03168 
Epoch [275/300] Training [47/62] Loss: 0.02275 
Epoch [275/300] Training [48/62] Loss: 0.02111 
Epoch [275/300] Training [49/62] Loss: 0.04218 
Epoch [275/300] Training [50/62] Loss: 0.02676 
Epoch [275/300] Training [51/62] Loss: 0.03258 
Epoch [275/300] Training [52/62] Loss: 0.02221 
Epoch [275/300] Training [53/62] Loss: 0.03372 
Epoch [275/300] Training [54/62] Loss: 0.02930 
Epoch [275/300] Training [55/62] Loss: 0.02395 
Epoch [275/300] Training [56/62] Loss: 0.02307 
Epoch [275/300] Training [57/62] Loss: 0.02941 
Epoch [275/300] Training [58/62] Loss: 0.02689 
Epoch [275/300] Training [59/62] Loss: 0.05329 
Epoch [275/300] Training [60/62] Loss: 0.04494 
Epoch [275/300] Training [61/62] Loss: 0.02723 
Epoch [275/300] Training [62/62] Loss: 0.03406 
Epoch [275/300] Training metric {'Train/mean dice_metric': 0.9779556393623352, 'Train/mean miou_metric': 0.9573614597320557, 'Train/mean f1': 0.9762405157089233, 'Train/mean precision': 0.9717907309532166, 'Train/mean recall': 0.9807311296463013, 'Train/mean hd95_metric': 3.0434296131134033}
Epoch [275/300] Validation [1/16] Loss: 0.21341  focal_loss 0.10874  dice_loss 0.10467 
Epoch [275/300] Validation [2/16] Loss: 0.49432  focal_loss 0.25029  dice_loss 0.24403 
Epoch [275/300] Validation [3/16] Loss: 0.37927  focal_loss 0.15500  dice_loss 0.22427 
Epoch [275/300] Validation [4/16] Loss: 0.25862  focal_loss 0.12330  dice_loss 0.13532 
Epoch [275/300] Validation [5/16] Loss: 0.39786  focal_loss 0.16556  dice_loss 0.23231 
Epoch [275/300] Validation [6/16] Loss: 0.31647  focal_loss 0.09146  dice_loss 0.22501 
Epoch [275/300] Validation [7/16] Loss: 0.21604  focal_loss 0.10258  dice_loss 0.11346 
Epoch [275/300] Validation [8/16] Loss: 0.34774  focal_loss 0.12150  dice_loss 0.22624 
Epoch [275/300] Validation [9/16] Loss: 0.24261  focal_loss 0.12084  dice_loss 0.12177 
Epoch [275/300] Validation [10/16] Loss: 0.51268  focal_loss 0.20382  dice_loss 0.30886 
Epoch [275/300] Validation [11/16] Loss: 0.11525  focal_loss 0.03839  dice_loss 0.07686 
Epoch [275/300] Validation [12/16] Loss: 0.35298  focal_loss 0.09469  dice_loss 0.25829 
Epoch [275/300] Validation [13/16] Loss: 0.36549  focal_loss 0.16762  dice_loss 0.19787 
Epoch [275/300] Validation [14/16] Loss: 0.41236  focal_loss 0.16617  dice_loss 0.24619 
Epoch [275/300] Validation [15/16] Loss: 0.11820  focal_loss 0.05103  dice_loss 0.06717 
Epoch [275/300] Validation [16/16] Loss: 0.07265  focal_loss 0.02843  dice_loss 0.04422 
Epoch [275/300] Validation metric {'Val/mean dice_metric': 0.9463373422622681, 'Val/mean miou_metric': 0.9138303399085999, 'Val/mean f1': 0.9509016275405884, 'Val/mean precision': 0.9509853720664978, 'Val/mean recall': 0.9508180022239685, 'Val/mean hd95_metric': 10.624338150024414}
Cheakpoint...
Epoch [275/300] best acc:tensor([0.9503], device='cuda:0'), Now : mean acc: tensor([0.9463], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9463373422622681, 'Val/mean miou_metric': 0.9138303399085999, 'Val/mean f1': 0.9509016275405884, 'Val/mean precision': 0.9509853720664978, 'Val/mean recall': 0.9508180022239685, 'Val/mean hd95_metric': 10.624338150024414}
Epoch [276/300] Training [1/62] Loss: 0.02201 
Epoch [276/300] Training [2/62] Loss: 0.03012 
Epoch [276/300] Training [3/62] Loss: 0.02577 
Epoch [276/300] Training [4/62] Loss: 0.02578 
Epoch [276/300] Training [5/62] Loss: 0.04690 
Epoch [276/300] Training [6/62] Loss: 0.02856 
Epoch [276/300] Training [7/62] Loss: 0.02272 
Epoch [276/300] Training [8/62] Loss: 0.02477 
Epoch [276/300] Training [9/62] Loss: 0.03346 
Epoch [276/300] Training [10/62] Loss: 0.03153 
Epoch [276/300] Training [11/62] Loss: 0.02375 
Epoch [276/300] Training [12/62] Loss: 0.03466 
Epoch [276/300] Training [13/62] Loss: 0.03079 
Epoch [276/300] Training [14/62] Loss: 0.04293 
Epoch [276/300] Training [15/62] Loss: 0.02975 
Epoch [276/300] Training [16/62] Loss: 0.03420 
Epoch [276/300] Training [17/62] Loss: 0.03705 
Epoch [276/300] Training [18/62] Loss: 0.03028 
Epoch [276/300] Training [19/62] Loss: 0.02452 
Epoch [276/300] Training [20/62] Loss: 0.03124 
Epoch [276/300] Training [21/62] Loss: 0.03011 
Epoch [276/300] Training [22/62] Loss: 0.03521 
Epoch [276/300] Training [23/62] Loss: 0.03597 
Epoch [276/300] Training [24/62] Loss: 0.02416 
Epoch [276/300] Training [25/62] Loss: 0.03261 
Epoch [276/300] Training [26/62] Loss: 0.02968 
Epoch [276/300] Training [27/62] Loss: 0.04348 
Epoch [276/300] Training [28/62] Loss: 0.02958 
Epoch [276/300] Training [29/62] Loss: 0.02280 
Epoch [276/300] Training [30/62] Loss: 0.05906 
Epoch [276/300] Training [31/62] Loss: 0.02536 
Epoch [276/300] Training [32/62] Loss: 0.02189 
Epoch [276/300] Training [33/62] Loss: 0.03316 
Epoch [276/300] Training [34/62] Loss: 0.03040 
Epoch [276/300] Training [35/62] Loss: 0.02413 
Epoch [276/300] Training [36/62] Loss: 0.02964 
Epoch [276/300] Training [37/62] Loss: 0.03253 
Epoch [276/300] Training [38/62] Loss: 0.02674 
Epoch [276/300] Training [39/62] Loss: 0.03618 
Epoch [276/300] Training [40/62] Loss: 0.03489 
Epoch [276/300] Training [41/62] Loss: 0.02731 
Epoch [276/300] Training [42/62] Loss: 0.02825 
Epoch [276/300] Training [43/62] Loss: 0.05296 
Epoch [276/300] Training [44/62] Loss: 0.04712 
Epoch [276/300] Training [45/62] Loss: 0.02433 
Epoch [276/300] Training [46/62] Loss: 0.02377 
Epoch [276/300] Training [47/62] Loss: 0.04755 
Epoch [276/300] Training [48/62] Loss: 0.02587 
Epoch [276/300] Training [49/62] Loss: 0.02213 
Epoch [276/300] Training [50/62] Loss: 0.02344 
Epoch [276/300] Training [51/62] Loss: 0.06899 
Epoch [276/300] Training [52/62] Loss: 0.02625 
Epoch [276/300] Training [53/62] Loss: 0.04367 
Epoch [276/300] Training [54/62] Loss: 0.02843 
Epoch [276/300] Training [55/62] Loss: 0.03179 
Epoch [276/300] Training [56/62] Loss: 0.02439 
Epoch [276/300] Training [57/62] Loss: 0.03563 
Epoch [276/300] Training [58/62] Loss: 0.03678 
Epoch [276/300] Training [59/62] Loss: 0.02749 
Epoch [276/300] Training [60/62] Loss: 0.02871 
Epoch [276/300] Training [61/62] Loss: 0.03600 
Epoch [276/300] Training [62/62] Loss: 0.01808 
Epoch [276/300] Training metric {'Train/mean dice_metric': 0.9785789251327515, 'Train/mean miou_metric': 0.9583345055580139, 'Train/mean f1': 0.9761186242103577, 'Train/mean precision': 0.9713426828384399, 'Train/mean recall': 0.980941653251648, 'Train/mean hd95_metric': 2.8599603176116943}
Epoch [276/300] Validation [1/16] Loss: 0.50122  focal_loss 0.32653  dice_loss 0.17469 
Epoch [276/300] Validation [2/16] Loss: 0.44382  focal_loss 0.20577  dice_loss 0.23805 
Epoch [276/300] Validation [3/16] Loss: 0.68464  focal_loss 0.39948  dice_loss 0.28516 
Epoch [276/300] Validation [4/16] Loss: 0.31634  focal_loss 0.16609  dice_loss 0.15024 
Epoch [276/300] Validation [5/16] Loss: 0.35975  focal_loss 0.15157  dice_loss 0.20818 
Epoch [276/300] Validation [6/16] Loss: 0.26503  focal_loss 0.07398  dice_loss 0.19105 
Epoch [276/300] Validation [7/16] Loss: 0.26347  focal_loss 0.15114  dice_loss 0.11232 
Epoch [276/300] Validation [8/16] Loss: 0.35449  focal_loss 0.12819  dice_loss 0.22630 
Epoch [276/300] Validation [9/16] Loss: 0.21178  focal_loss 0.11559  dice_loss 0.09619 
Epoch [276/300] Validation [10/16] Loss: 0.41871  focal_loss 0.17717  dice_loss 0.24154 
Epoch [276/300] Validation [11/16] Loss: 0.11755  focal_loss 0.04761  dice_loss 0.06994 
Epoch [276/300] Validation [12/16] Loss: 0.32066  focal_loss 0.08454  dice_loss 0.23611 
Epoch [276/300] Validation [13/16] Loss: 0.32114  focal_loss 0.13699  dice_loss 0.18415 
Epoch [276/300] Validation [14/16] Loss: 0.40986  focal_loss 0.14815  dice_loss 0.26171 
Epoch [276/300] Validation [15/16] Loss: 0.11003  focal_loss 0.04679  dice_loss 0.06324 
Epoch [276/300] Validation [16/16] Loss: 0.04662  focal_loss 0.01509  dice_loss 0.03153 
Epoch [276/300] Validation metric {'Val/mean dice_metric': 0.9473244547843933, 'Val/mean miou_metric': 0.9167217016220093, 'Val/mean f1': 0.9506962299346924, 'Val/mean precision': 0.9522324204444885, 'Val/mean recall': 0.949164867401123, 'Val/mean hd95_metric': 10.26898193359375}
Cheakpoint...
Epoch [276/300] best acc:tensor([0.9503], device='cuda:0'), Now : mean acc: tensor([0.9473], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9473244547843933, 'Val/mean miou_metric': 0.9167217016220093, 'Val/mean f1': 0.9506962299346924, 'Val/mean precision': 0.9522324204444885, 'Val/mean recall': 0.949164867401123, 'Val/mean hd95_metric': 10.26898193359375}
Epoch [277/300] Training [1/62] Loss: 0.09816 
Epoch [277/300] Training [2/62] Loss: 0.02546 
Epoch [277/300] Training [3/62] Loss: 0.02425 
Epoch [277/300] Training [4/62] Loss: 0.01989 
Epoch [277/300] Training [5/62] Loss: 0.06461 
Epoch [277/300] Training [6/62] Loss: 0.02174 
Epoch [277/300] Training [7/62] Loss: 0.02744 
Epoch [277/300] Training [8/62] Loss: 0.02469 
Epoch [277/300] Training [9/62] Loss: 0.03096 
Epoch [277/300] Training [10/62] Loss: 0.02249 
Epoch [277/300] Training [11/62] Loss: 0.04169 
Epoch [277/300] Training [12/62] Loss: 0.03166 
Epoch [277/300] Training [13/62] Loss: 0.02341 
Epoch [277/300] Training [14/62] Loss: 0.02252 
Epoch [277/300] Training [15/62] Loss: 0.02598 
Epoch [277/300] Training [16/62] Loss: 0.04553 
Epoch [277/300] Training [17/62] Loss: 0.03634 
Epoch [277/300] Training [18/62] Loss: 0.09035 
Epoch [277/300] Training [19/62] Loss: 0.02374 
Epoch [277/300] Training [20/62] Loss: 0.03311 
Epoch [277/300] Training [21/62] Loss: 0.02468 
Epoch [277/300] Training [22/62] Loss: 0.02803 
Epoch [277/300] Training [23/62] Loss: 0.05749 
Epoch [277/300] Training [24/62] Loss: 0.03936 
Epoch [277/300] Training [25/62] Loss: 0.02262 
Epoch [277/300] Training [26/62] Loss: 0.02592 
Epoch [277/300] Training [27/62] Loss: 0.02357 
Epoch [277/300] Training [28/62] Loss: 0.02802 
Epoch [277/300] Training [29/62] Loss: 0.03400 
Epoch [277/300] Training [30/62] Loss: 0.02515 
Epoch [277/300] Training [31/62] Loss: 0.03209 
Epoch [277/300] Training [32/62] Loss: 0.02062 
Epoch [277/300] Training [33/62] Loss: 0.04400 
Epoch [277/300] Training [34/62] Loss: 0.02524 
Epoch [277/300] Training [35/62] Loss: 0.02371 
Epoch [277/300] Training [36/62] Loss: 0.03916 
Epoch [277/300] Training [37/62] Loss: 0.03625 
Epoch [277/300] Training [38/62] Loss: 0.03365 
Epoch [277/300] Training [39/62] Loss: 0.03028 
Epoch [277/300] Training [40/62] Loss: 0.02635 
Epoch [277/300] Training [41/62] Loss: 0.03448 
Epoch [277/300] Training [42/62] Loss: 0.03399 
Epoch [277/300] Training [43/62] Loss: 0.04323 
Epoch [277/300] Training [44/62] Loss: 0.05098 
Epoch [277/300] Training [45/62] Loss: 0.02164 
Epoch [277/300] Training [46/62] Loss: 0.04837 
Epoch [277/300] Training [47/62] Loss: 0.03572 
Epoch [277/300] Training [48/62] Loss: 0.02870 
Epoch [277/300] Training [49/62] Loss: 0.02137 
Epoch [277/300] Training [50/62] Loss: 0.06475 
Epoch [277/300] Training [51/62] Loss: 0.03057 
Epoch [277/300] Training [52/62] Loss: 0.03272 
Epoch [277/300] Training [53/62] Loss: 0.02762 
Epoch [277/300] Training [54/62] Loss: 0.02342 
Epoch [277/300] Training [55/62] Loss: 0.02267 
Epoch [277/300] Training [56/62] Loss: 0.03151 
Epoch [277/300] Training [57/62] Loss: 0.04728 
Epoch [277/300] Training [58/62] Loss: 0.03505 
Epoch [277/300] Training [59/62] Loss: 0.03564 
Epoch [277/300] Training [60/62] Loss: 0.03084 
Epoch [277/300] Training [61/62] Loss: 0.02068 
Epoch [277/300] Training [62/62] Loss: 0.02611 
Epoch [277/300] Training metric {'Train/mean dice_metric': 0.9767137765884399, 'Train/mean miou_metric': 0.9560651779174805, 'Train/mean f1': 0.9766806364059448, 'Train/mean precision': 0.9719579815864563, 'Train/mean recall': 0.9814494252204895, 'Train/mean hd95_metric': 3.470262050628662}
Epoch [277/300] Validation [1/16] Loss: 0.19980  focal_loss 0.10143  dice_loss 0.09836 
Epoch [277/300] Validation [2/16] Loss: 0.41466  focal_loss 0.24186  dice_loss 0.17280 
Epoch [277/300] Validation [3/16] Loss: 0.70010  focal_loss 0.42334  dice_loss 0.27676 
Epoch [277/300] Validation [4/16] Loss: 0.29766  focal_loss 0.14276  dice_loss 0.15490 
Epoch [277/300] Validation [5/16] Loss: 0.37924  focal_loss 0.14195  dice_loss 0.23729 
Epoch [277/300] Validation [6/16] Loss: 0.25361  focal_loss 0.06445  dice_loss 0.18916 
Epoch [277/300] Validation [7/16] Loss: 0.37041  focal_loss 0.21867  dice_loss 0.15174 
Epoch [277/300] Validation [8/16] Loss: 0.27722  focal_loss 0.09055  dice_loss 0.18667 
Epoch [277/300] Validation [9/16] Loss: 0.16169  focal_loss 0.08199  dice_loss 0.07969 
Epoch [277/300] Validation [10/16] Loss: 0.49800  focal_loss 0.20268  dice_loss 0.29532 
Epoch [277/300] Validation [11/16] Loss: 0.10462  focal_loss 0.03714  dice_loss 0.06748 
Epoch [277/300] Validation [12/16] Loss: 0.37471  focal_loss 0.10840  dice_loss 0.26631 
Epoch [277/300] Validation [13/16] Loss: 0.37411  focal_loss 0.16189  dice_loss 0.21222 
Epoch [277/300] Validation [14/16] Loss: 0.44506  focal_loss 0.16493  dice_loss 0.28014 
Epoch [277/300] Validation [15/16] Loss: 0.28216  focal_loss 0.12812  dice_loss 0.15404 
Epoch [277/300] Validation [16/16] Loss: 0.05296  focal_loss 0.02046  dice_loss 0.03250 
Epoch [277/300] Validation metric {'Val/mean dice_metric': 0.9449594616889954, 'Val/mean miou_metric': 0.9124388098716736, 'Val/mean f1': 0.9487165808677673, 'Val/mean precision': 0.9474523067474365, 'Val/mean recall': 0.9499841928482056, 'Val/mean hd95_metric': 11.22149658203125}
Cheakpoint...
Epoch [277/300] best acc:tensor([0.9503], device='cuda:0'), Now : mean acc: tensor([0.9450], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9449594616889954, 'Val/mean miou_metric': 0.9124388098716736, 'Val/mean f1': 0.9487165808677673, 'Val/mean precision': 0.9474523067474365, 'Val/mean recall': 0.9499841928482056, 'Val/mean hd95_metric': 11.22149658203125}
Epoch [278/300] Training [1/62] Loss: 0.03394 
Epoch [278/300] Training [2/62] Loss: 0.02036 
Epoch [278/300] Training [3/62] Loss: 0.02902 
Epoch [278/300] Training [4/62] Loss: 0.04749 
Epoch [278/300] Training [5/62] Loss: 0.02377 
Epoch [278/300] Training [6/62] Loss: 0.02739 
Epoch [278/300] Training [7/62] Loss: 0.02315 
Epoch [278/300] Training [8/62] Loss: 0.03272 
Epoch [278/300] Training [9/62] Loss: 0.02313 
Epoch [278/300] Training [10/62] Loss: 0.02240 
Epoch [278/300] Training [11/62] Loss: 0.02933 
Epoch [278/300] Training [12/62] Loss: 0.02367 
Epoch [278/300] Training [13/62] Loss: 0.02512 
Epoch [278/300] Training [14/62] Loss: 0.02735 
Epoch [278/300] Training [15/62] Loss: 0.02305 
Epoch [278/300] Training [16/62] Loss: 0.03524 
Epoch [278/300] Training [17/62] Loss: 0.03795 
Epoch [278/300] Training [18/62] Loss: 0.02849 
Epoch [278/300] Training [19/62] Loss: 0.02877 
Epoch [278/300] Training [20/62] Loss: 0.03109 
Epoch [278/300] Training [21/62] Loss: 0.03913 
Epoch [278/300] Training [22/62] Loss: 0.02809 
Epoch [278/300] Training [23/62] Loss: 0.03021 
Epoch [278/300] Training [24/62] Loss: 0.02129 
Epoch [278/300] Training [25/62] Loss: 0.02678 
Epoch [278/300] Training [26/62] Loss: 0.07431 
Epoch [278/300] Training [27/62] Loss: 0.03820 
Epoch [278/300] Training [28/62] Loss: 0.02895 
Epoch [278/300] Training [29/62] Loss: 0.02440 
Epoch [278/300] Training [30/62] Loss: 0.03131 
Epoch [278/300] Training [31/62] Loss: 0.03383 
Epoch [278/300] Training [32/62] Loss: 0.02373 
Epoch [278/300] Training [33/62] Loss: 0.05375 
Epoch [278/300] Training [34/62] Loss: 0.02729 
Epoch [278/300] Training [35/62] Loss: 0.02793 
Epoch [278/300] Training [36/62] Loss: 0.01926 
Epoch [278/300] Training [37/62] Loss: 0.03629 
Epoch [278/300] Training [38/62] Loss: 0.02513 
Epoch [278/300] Training [39/62] Loss: 0.02482 
Epoch [278/300] Training [40/62] Loss: 0.03262 
Epoch [278/300] Training [41/62] Loss: 0.02824 
Epoch [278/300] Training [42/62] Loss: 0.04291 
Epoch [278/300] Training [43/62] Loss: 0.02712 
Epoch [278/300] Training [44/62] Loss: 0.02930 
Epoch [278/300] Training [45/62] Loss: 0.02364 
Epoch [278/300] Training [46/62] Loss: 0.02614 
Epoch [278/300] Training [47/62] Loss: 0.02570 
Epoch [278/300] Training [48/62] Loss: 0.02823 
Epoch [278/300] Training [49/62] Loss: 0.02860 
Epoch [278/300] Training [50/62] Loss: 0.03013 
Epoch [278/300] Training [51/62] Loss: 0.03015 
Epoch [278/300] Training [52/62] Loss: 0.02623 
Epoch [278/300] Training [53/62] Loss: 0.03511 
Epoch [278/300] Training [54/62] Loss: 0.04077 
Epoch [278/300] Training [55/62] Loss: 0.03038 
Epoch [278/300] Training [56/62] Loss: 0.02407 
Epoch [278/300] Training [57/62] Loss: 0.04081 
Epoch [278/300] Training [58/62] Loss: 0.03733 
Epoch [278/300] Training [59/62] Loss: 0.02518 
Epoch [278/300] Training [60/62] Loss: 0.04163 
Epoch [278/300] Training [61/62] Loss: 0.03343 
Epoch [278/300] Training [62/62] Loss: 0.02041 
Epoch [278/300] Training metric {'Train/mean dice_metric': 0.9794301390647888, 'Train/mean miou_metric': 0.9599139094352722, 'Train/mean f1': 0.9772047400474548, 'Train/mean precision': 0.9728944897651672, 'Train/mean recall': 0.9815534353256226, 'Train/mean hd95_metric': 3.0953826904296875}
Epoch [278/300] Validation [1/16] Loss: 0.24272  focal_loss 0.12072  dice_loss 0.12200 
Epoch [278/300] Validation [2/16] Loss: 0.42926  focal_loss 0.26126  dice_loss 0.16799 
Epoch [278/300] Validation [3/16] Loss: 0.36417  focal_loss 0.15344  dice_loss 0.21073 
Epoch [278/300] Validation [4/16] Loss: 0.26082  focal_loss 0.12837  dice_loss 0.13245 
Epoch [278/300] Validation [5/16] Loss: 0.29237  focal_loss 0.09877  dice_loss 0.19360 
Epoch [278/300] Validation [6/16] Loss: 0.27385  focal_loss 0.07772  dice_loss 0.19613 
Epoch [278/300] Validation [7/16] Loss: 0.29905  focal_loss 0.17062  dice_loss 0.12843 
Epoch [278/300] Validation [8/16] Loss: 0.39599  focal_loss 0.14272  dice_loss 0.25327 
Epoch [278/300] Validation [9/16] Loss: 0.16653  focal_loss 0.08671  dice_loss 0.07981 
Epoch [278/300] Validation [10/16] Loss: 0.20886  focal_loss 0.07958  dice_loss 0.12928 
Epoch [278/300] Validation [11/16] Loss: 0.09829  focal_loss 0.03566  dice_loss 0.06262 
Epoch [278/300] Validation [12/16] Loss: 0.31709  focal_loss 0.07966  dice_loss 0.23743 
Epoch [278/300] Validation [13/16] Loss: 0.18900  focal_loss 0.07676  dice_loss 0.11224 
Epoch [278/300] Validation [14/16] Loss: 0.50950  focal_loss 0.22886  dice_loss 0.28064 
Epoch [278/300] Validation [15/16] Loss: 0.12328  focal_loss 0.05585  dice_loss 0.06743 
Epoch [278/300] Validation [16/16] Loss: 0.04275  focal_loss 0.01454  dice_loss 0.02821 
Epoch [278/300] Validation metric {'Val/mean dice_metric': 0.9528906345367432, 'Val/mean miou_metric': 0.9216292500495911, 'Val/mean f1': 0.9552038908004761, 'Val/mean precision': 0.9547762274742126, 'Val/mean recall': 0.9556320309638977, 'Val/mean hd95_metric': 9.687213897705078}
Cheakpoint...
Epoch [278/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9529], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9528906345367432, 'Val/mean miou_metric': 0.9216292500495911, 'Val/mean f1': 0.9552038908004761, 'Val/mean precision': 0.9547762274742126, 'Val/mean recall': 0.9556320309638977, 'Val/mean hd95_metric': 9.687213897705078}
Epoch [279/300] Training [1/62] Loss: 0.02433 
Epoch [279/300] Training [2/62] Loss: 0.04615 
Epoch [279/300] Training [3/62] Loss: 0.02683 
Epoch [279/300] Training [4/62] Loss: 0.05692 
Epoch [279/300] Training [5/62] Loss: 0.02291 
Epoch [279/300] Training [6/62] Loss: 0.02172 
Epoch [279/300] Training [7/62] Loss: 0.02995 
Epoch [279/300] Training [8/62] Loss: 0.02361 
Epoch [279/300] Training [9/62] Loss: 0.01980 
Epoch [279/300] Training [10/62] Loss: 0.02280 
Epoch [279/300] Training [11/62] Loss: 0.04647 
Epoch [279/300] Training [12/62] Loss: 0.01918 
Epoch [279/300] Training [13/62] Loss: 0.11327 
Epoch [279/300] Training [14/62] Loss: 0.02776 
Epoch [279/300] Training [15/62] Loss: 0.03178 
Epoch [279/300] Training [16/62] Loss: 0.02542 
Epoch [279/300] Training [17/62] Loss: 0.02121 
Epoch [279/300] Training [18/62] Loss: 0.03603 
Epoch [279/300] Training [19/62] Loss: 0.02137 
Epoch [279/300] Training [20/62] Loss: 0.06990 
Epoch [279/300] Training [21/62] Loss: 0.02802 
Epoch [279/300] Training [22/62] Loss: 0.04034 
Epoch [279/300] Training [23/62] Loss: 0.03130 
Epoch [279/300] Training [24/62] Loss: 0.02902 
Epoch [279/300] Training [25/62] Loss: 0.02990 
Epoch [279/300] Training [26/62] Loss: 0.02448 
Epoch [279/300] Training [27/62] Loss: 0.04468 
Epoch [279/300] Training [28/62] Loss: 0.02121 
Epoch [279/300] Training [29/62] Loss: 0.03533 
Epoch [279/300] Training [30/62] Loss: 0.04598 
Epoch [279/300] Training [31/62] Loss: 0.02459 
Epoch [279/300] Training [32/62] Loss: 0.03448 
Epoch [279/300] Training [33/62] Loss: 0.02961 
Epoch [279/300] Training [34/62] Loss: 0.02998 
Epoch [279/300] Training [35/62] Loss: 0.02400 
Epoch [279/300] Training [36/62] Loss: 0.02896 
Epoch [279/300] Training [37/62] Loss: 0.02141 
Epoch [279/300] Training [38/62] Loss: 0.03570 
Epoch [279/300] Training [39/62] Loss: 0.03399 
Epoch [279/300] Training [40/62] Loss: 0.04579 
Epoch [279/300] Training [41/62] Loss: 0.02551 
Epoch [279/300] Training [42/62] Loss: 0.03103 
Epoch [279/300] Training [43/62] Loss: 0.02451 
Epoch [279/300] Training [44/62] Loss: 0.02863 
Epoch [279/300] Training [45/62] Loss: 0.03060 
Epoch [279/300] Training [46/62] Loss: 0.04226 
Epoch [279/300] Training [47/62] Loss: 0.02499 
Epoch [279/300] Training [48/62] Loss: 0.02076 
Epoch [279/300] Training [49/62] Loss: 0.02679 
Epoch [279/300] Training [50/62] Loss: 0.02490 
Epoch [279/300] Training [51/62] Loss: 0.02512 
Epoch [279/300] Training [52/62] Loss: 0.03103 
Epoch [279/300] Training [53/62] Loss: 0.02389 
Epoch [279/300] Training [54/62] Loss: 0.03014 
Epoch [279/300] Training [55/62] Loss: 0.02329 
Epoch [279/300] Training [56/62] Loss: 0.02429 
Epoch [279/300] Training [57/62] Loss: 0.02544 
Epoch [279/300] Training [58/62] Loss: 0.03383 
Epoch [279/300] Training [59/62] Loss: 0.02712 
Epoch [279/300] Training [60/62] Loss: 0.02299 
Epoch [279/300] Training [61/62] Loss: 0.02923 
Epoch [279/300] Training [62/62] Loss: 0.01289 
Epoch [279/300] Training metric {'Train/mean dice_metric': 0.9792171716690063, 'Train/mean miou_metric': 0.95991051197052, 'Train/mean f1': 0.9767690896987915, 'Train/mean precision': 0.9717298150062561, 'Train/mean recall': 0.9818609356880188, 'Train/mean hd95_metric': 3.211045026779175}
Epoch [279/300] Validation [1/16] Loss: 0.21242  focal_loss 0.10813  dice_loss 0.10429 
Epoch [279/300] Validation [2/16] Loss: 0.42635  focal_loss 0.19362  dice_loss 0.23273 
Epoch [279/300] Validation [3/16] Loss: 0.75793  focal_loss 0.46214  dice_loss 0.29579 
Epoch [279/300] Validation [4/16] Loss: 0.42346  focal_loss 0.21654  dice_loss 0.20692 
Epoch [279/300] Validation [5/16] Loss: 0.34591  focal_loss 0.13259  dice_loss 0.21332 
Epoch [279/300] Validation [6/16] Loss: 0.27161  focal_loss 0.07698  dice_loss 0.19463 
Epoch [279/300] Validation [7/16] Loss: 0.40860  focal_loss 0.24316  dice_loss 0.16544 
Epoch [279/300] Validation [8/16] Loss: 0.38133  focal_loss 0.13913  dice_loss 0.24220 
Epoch [279/300] Validation [9/16] Loss: 0.21629  focal_loss 0.11733  dice_loss 0.09896 
Epoch [279/300] Validation [10/16] Loss: 0.27510  focal_loss 0.12564  dice_loss 0.14946 
Epoch [279/300] Validation [11/16] Loss: 0.10464  focal_loss 0.03779  dice_loss 0.06685 
Epoch [279/300] Validation [12/16] Loss: 0.27073  focal_loss 0.07207  dice_loss 0.19866 
Epoch [279/300] Validation [13/16] Loss: 0.39115  focal_loss 0.18005  dice_loss 0.21110 
Epoch [279/300] Validation [14/16] Loss: 0.48750  focal_loss 0.20249  dice_loss 0.28501 
Epoch [279/300] Validation [15/16] Loss: 0.12011  focal_loss 0.04927  dice_loss 0.07084 
Epoch [279/300] Validation [16/16] Loss: 0.05384  focal_loss 0.02033  dice_loss 0.03351 
Epoch [279/300] Validation metric {'Val/mean dice_metric': 0.9479228258132935, 'Val/mean miou_metric': 0.9169976711273193, 'Val/mean f1': 0.9502007961273193, 'Val/mean precision': 0.9489012956619263, 'Val/mean recall': 0.9515039324760437, 'Val/mean hd95_metric': 10.33640193939209}
Cheakpoint...
Epoch [279/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9479], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9479228258132935, 'Val/mean miou_metric': 0.9169976711273193, 'Val/mean f1': 0.9502007961273193, 'Val/mean precision': 0.9489012956619263, 'Val/mean recall': 0.9515039324760437, 'Val/mean hd95_metric': 10.33640193939209}
Epoch [280/300] Training [1/62] Loss: 0.03711 
Epoch [280/300] Training [2/62] Loss: 0.03959 
Epoch [280/300] Training [3/62] Loss: 0.03631 
Epoch [280/300] Training [4/62] Loss: 0.03452 
Epoch [280/300] Training [5/62] Loss: 0.02316 
Epoch [280/300] Training [6/62] Loss: 0.02547 
Epoch [280/300] Training [7/62] Loss: 0.02922 
Epoch [280/300] Training [8/62] Loss: 0.02333 
Epoch [280/300] Training [9/62] Loss: 0.02856 
Epoch [280/300] Training [10/62] Loss: 0.03140 
Epoch [280/300] Training [11/62] Loss: 0.03668 
Epoch [280/300] Training [12/62] Loss: 0.03251 
Epoch [280/300] Training [13/62] Loss: 0.02811 
Epoch [280/300] Training [14/62] Loss: 0.02572 
Epoch [280/300] Training [15/62] Loss: 0.04798 
Epoch [280/300] Training [16/62] Loss: 0.02504 
Epoch [280/300] Training [17/62] Loss: 0.03358 
Epoch [280/300] Training [18/62] Loss: 0.02937 
Epoch [280/300] Training [19/62] Loss: 0.02522 
Epoch [280/300] Training [20/62] Loss: 0.03369 
Epoch [280/300] Training [21/62] Loss: 0.02434 
Epoch [280/300] Training [22/62] Loss: 0.03037 
Epoch [280/300] Training [23/62] Loss: 0.02499 
Epoch [280/300] Training [24/62] Loss: 0.02078 
Epoch [280/300] Training [25/62] Loss: 0.02545 
Epoch [280/300] Training [26/62] Loss: 0.03297 
Epoch [280/300] Training [27/62] Loss: 0.01916 
Epoch [280/300] Training [28/62] Loss: 0.02201 
Epoch [280/300] Training [29/62] Loss: 0.04928 
Epoch [280/300] Training [30/62] Loss: 0.02749 
Epoch [280/300] Training [31/62] Loss: 0.02094 
Epoch [280/300] Training [32/62] Loss: 0.03903 
Epoch [280/300] Training [33/62] Loss: 0.02623 
Epoch [280/300] Training [34/62] Loss: 0.02644 
Epoch [280/300] Training [35/62] Loss: 0.03373 
Epoch [280/300] Training [36/62] Loss: 0.02729 
Epoch [280/300] Training [37/62] Loss: 0.02138 
Epoch [280/300] Training [38/62] Loss: 0.02543 
Epoch [280/300] Training [39/62] Loss: 0.04189 
Epoch [280/300] Training [40/62] Loss: 0.02794 
Epoch [280/300] Training [41/62] Loss: 0.03297 
Epoch [280/300] Training [42/62] Loss: 0.03485 
Epoch [280/300] Training [43/62] Loss: 0.02909 
Epoch [280/300] Training [44/62] Loss: 0.03570 
Epoch [280/300] Training [45/62] Loss: 0.02765 
Epoch [280/300] Training [46/62] Loss: 0.02348 
Epoch [280/300] Training [47/62] Loss: 0.03174 
Epoch [280/300] Training [48/62] Loss: 0.02446 
Epoch [280/300] Training [49/62] Loss: 0.02563 
Epoch [280/300] Training [50/62] Loss: 0.03680 
Epoch [280/300] Training [51/62] Loss: 0.05722 
Epoch [280/300] Training [52/62] Loss: 0.02132 
Epoch [280/300] Training [53/62] Loss: 0.02927 
Epoch [280/300] Training [54/62] Loss: 0.03440 
Epoch [280/300] Training [55/62] Loss: 0.03328 
Epoch [280/300] Training [56/62] Loss: 0.04388 
Epoch [280/300] Training [57/62] Loss: 0.05982 
Epoch [280/300] Training [58/62] Loss: 0.02150 
Epoch [280/300] Training [59/62] Loss: 0.02562 
Epoch [280/300] Training [60/62] Loss: 0.02498 
Epoch [280/300] Training [61/62] Loss: 0.03263 
Epoch [280/300] Training [62/62] Loss: 0.03161 
Epoch [280/300] Training metric {'Train/mean dice_metric': 0.9793021082878113, 'Train/mean miou_metric': 0.9597619771957397, 'Train/mean f1': 0.9775238037109375, 'Train/mean precision': 0.9730347394943237, 'Train/mean recall': 0.9820544123649597, 'Train/mean hd95_metric': 3.300546646118164}
Epoch [280/300] Validation [1/16] Loss: 0.51226  focal_loss 0.33377  dice_loss 0.17849 
Epoch [280/300] Validation [2/16] Loss: 0.49738  focal_loss 0.26212  dice_loss 0.23526 
Epoch [280/300] Validation [3/16] Loss: 0.70720  focal_loss 0.42753  dice_loss 0.27967 
Epoch [280/300] Validation [4/16] Loss: 0.36160  focal_loss 0.18266  dice_loss 0.17893 
Epoch [280/300] Validation [5/16] Loss: 0.39390  focal_loss 0.18695  dice_loss 0.20696 
Epoch [280/300] Validation [6/16] Loss: 0.24589  focal_loss 0.07154  dice_loss 0.17435 
Epoch [280/300] Validation [7/16] Loss: 0.42552  focal_loss 0.25258  dice_loss 0.17294 
Epoch [280/300] Validation [8/16] Loss: 0.40244  focal_loss 0.14726  dice_loss 0.25519 
Epoch [280/300] Validation [9/16] Loss: 0.24485  focal_loss 0.11290  dice_loss 0.13195 
Epoch [280/300] Validation [10/16] Loss: 0.43322  focal_loss 0.18890  dice_loss 0.24432 
Epoch [280/300] Validation [11/16] Loss: 0.12154  focal_loss 0.04953  dice_loss 0.07201 
Epoch [280/300] Validation [12/16] Loss: 0.31014  focal_loss 0.07922  dice_loss 0.23092 
Epoch [280/300] Validation [13/16] Loss: 0.37703  focal_loss 0.17583  dice_loss 0.20120 
Epoch [280/300] Validation [14/16] Loss: 0.46628  focal_loss 0.18522  dice_loss 0.28107 
Epoch [280/300] Validation [15/16] Loss: 0.12874  focal_loss 0.05770  dice_loss 0.07103 
Epoch [280/300] Validation [16/16] Loss: 0.04581  focal_loss 0.01597  dice_loss 0.02984 
Epoch [280/300] Validation metric {'Val/mean dice_metric': 0.9456188678741455, 'Val/mean miou_metric': 0.9149171710014343, 'Val/mean f1': 0.9494080543518066, 'Val/mean precision': 0.9504632949829102, 'Val/mean recall': 0.9483553171157837, 'Val/mean hd95_metric': 10.71607780456543}
Cheakpoint...
Epoch [280/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9456], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9456188678741455, 'Val/mean miou_metric': 0.9149171710014343, 'Val/mean f1': 0.9494080543518066, 'Val/mean precision': 0.9504632949829102, 'Val/mean recall': 0.9483553171157837, 'Val/mean hd95_metric': 10.71607780456543}
Epoch [281/300] Training [1/62] Loss: 0.02812 
Epoch [281/300] Training [2/62] Loss: 0.03356 
Epoch [281/300] Training [3/62] Loss: 0.04188 
Epoch [281/300] Training [4/62] Loss: 0.02606 
Epoch [281/300] Training [5/62] Loss: 0.03489 
Epoch [281/300] Training [6/62] Loss: 0.05141 
Epoch [281/300] Training [7/62] Loss: 0.02703 
Epoch [281/300] Training [8/62] Loss: 0.02005 
Epoch [281/300] Training [9/62] Loss: 0.03436 
Epoch [281/300] Training [10/62] Loss: 0.02348 
Epoch [281/300] Training [11/62] Loss: 0.02724 
Epoch [281/300] Training [12/62] Loss: 0.04718 
Epoch [281/300] Training [13/62] Loss: 0.04289 
Epoch [281/300] Training [14/62] Loss: 0.02479 
Epoch [281/300] Training [15/62] Loss: 0.02199 
Epoch [281/300] Training [16/62] Loss: 0.02429 
Epoch [281/300] Training [17/62] Loss: 0.02770 
Epoch [281/300] Training [18/62] Loss: 0.02131 
Epoch [281/300] Training [19/62] Loss: 0.02259 
Epoch [281/300] Training [20/62] Loss: 0.01817 
Epoch [281/300] Training [21/62] Loss: 0.02138 
Epoch [281/300] Training [22/62] Loss: 0.02821 
Epoch [281/300] Training [23/62] Loss: 0.02181 
Epoch [281/300] Training [24/62] Loss: 0.02610 
Epoch [281/300] Training [25/62] Loss: 0.02323 
Epoch [281/300] Training [26/62] Loss: 0.04588 
Epoch [281/300] Training [27/62] Loss: 0.03175 
Epoch [281/300] Training [28/62] Loss: 0.02502 
Epoch [281/300] Training [29/62] Loss: 0.03340 
Epoch [281/300] Training [30/62] Loss: 0.02501 
Epoch [281/300] Training [31/62] Loss: 0.05118 
Epoch [281/300] Training [32/62] Loss: 0.02408 
Epoch [281/300] Training [33/62] Loss: 0.02872 
Epoch [281/300] Training [34/62] Loss: 0.02876 
Epoch [281/300] Training [35/62] Loss: 0.02749 
Epoch [281/300] Training [36/62] Loss: 0.02652 
Epoch [281/300] Training [37/62] Loss: 0.02570 
Epoch [281/300] Training [38/62] Loss: 0.02633 
Epoch [281/300] Training [39/62] Loss: 0.04346 
Epoch [281/300] Training [40/62] Loss: 0.02985 
Epoch [281/300] Training [41/62] Loss: 0.03240 
Epoch [281/300] Training [42/62] Loss: 0.02275 
Epoch [281/300] Training [43/62] Loss: 0.03019 
Epoch [281/300] Training [44/62] Loss: 0.06875 
Epoch [281/300] Training [45/62] Loss: 0.02758 
Epoch [281/300] Training [46/62] Loss: 0.02272 
Epoch [281/300] Training [47/62] Loss: 0.02282 
Epoch [281/300] Training [48/62] Loss: 0.01688 
Epoch [281/300] Training [49/62] Loss: 0.03475 
Epoch [281/300] Training [50/62] Loss: 0.02003 
Epoch [281/300] Training [51/62] Loss: 0.02563 
Epoch [281/300] Training [52/62] Loss: 0.01982 
Epoch [281/300] Training [53/62] Loss: 0.02484 
Epoch [281/300] Training [54/62] Loss: 0.02967 
Epoch [281/300] Training [55/62] Loss: 0.02785 
Epoch [281/300] Training [56/62] Loss: 0.03133 
Epoch [281/300] Training [57/62] Loss: 0.03732 
Epoch [281/300] Training [58/62] Loss: 0.02656 
Epoch [281/300] Training [59/62] Loss: 0.02288 
Epoch [281/300] Training [60/62] Loss: 0.03045 
Epoch [281/300] Training [61/62] Loss: 0.02507 
Epoch [281/300] Training [62/62] Loss: 0.01785 
Epoch [281/300] Training metric {'Train/mean dice_metric': 0.9805527329444885, 'Train/mean miou_metric': 0.9620240926742554, 'Train/mean f1': 0.9779855608940125, 'Train/mean precision': 0.97347491979599, 'Train/mean recall': 0.9825382232666016, 'Train/mean hd95_metric': 2.7061879634857178}
Epoch [281/300] Validation [1/16] Loss: 0.26378  focal_loss 0.12900  dice_loss 0.13478 
Epoch [281/300] Validation [2/16] Loss: 0.48907  focal_loss 0.24991  dice_loss 0.23916 
Epoch [281/300] Validation [3/16] Loss: 0.66881  focal_loss 0.41749  dice_loss 0.25131 
Epoch [281/300] Validation [4/16] Loss: 0.28368  focal_loss 0.13689  dice_loss 0.14680 
Epoch [281/300] Validation [5/16] Loss: 0.35131  focal_loss 0.13244  dice_loss 0.21887 
Epoch [281/300] Validation [6/16] Loss: 0.22979  focal_loss 0.06541  dice_loss 0.16439 
Epoch [281/300] Validation [7/16] Loss: 0.34088  focal_loss 0.17991  dice_loss 0.16097 
Epoch [281/300] Validation [8/16] Loss: 0.34143  focal_loss 0.12708  dice_loss 0.21434 
Epoch [281/300] Validation [9/16] Loss: 0.17347  focal_loss 0.08537  dice_loss 0.08810 
Epoch [281/300] Validation [10/16] Loss: 0.24611  focal_loss 0.11214  dice_loss 0.13398 
Epoch [281/300] Validation [11/16] Loss: 0.13019  focal_loss 0.05250  dice_loss 0.07769 
Epoch [281/300] Validation [12/16] Loss: 0.33395  focal_loss 0.11981  dice_loss 0.21414 
Epoch [281/300] Validation [13/16] Loss: 0.36672  focal_loss 0.16922  dice_loss 0.19750 
Epoch [281/300] Validation [14/16] Loss: 0.56086  focal_loss 0.24360  dice_loss 0.31725 
Epoch [281/300] Validation [15/16] Loss: 0.12256  focal_loss 0.05356  dice_loss 0.06900 
Epoch [281/300] Validation [16/16] Loss: 0.07277  focal_loss 0.02780  dice_loss 0.04497 
Epoch [281/300] Validation metric {'Val/mean dice_metric': 0.9502938389778137, 'Val/mean miou_metric': 0.9203417301177979, 'Val/mean f1': 0.9523465633392334, 'Val/mean precision': 0.9513266086578369, 'Val/mean recall': 0.9533688426017761, 'Val/mean hd95_metric': 9.423467636108398}
Cheakpoint...
Epoch [281/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9503], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9502938389778137, 'Val/mean miou_metric': 0.9203417301177979, 'Val/mean f1': 0.9523465633392334, 'Val/mean precision': 0.9513266086578369, 'Val/mean recall': 0.9533688426017761, 'Val/mean hd95_metric': 9.423467636108398}
Epoch [282/300] Training [1/62] Loss: 0.05046 
Epoch [282/300] Training [2/62] Loss: 0.03057 
Epoch [282/300] Training [3/62] Loss: 0.03504 
Epoch [282/300] Training [4/62] Loss: 0.03337 
Epoch [282/300] Training [5/62] Loss: 0.03987 
Epoch [282/300] Training [6/62] Loss: 0.02836 
Epoch [282/300] Training [7/62] Loss: 0.02873 
Epoch [282/300] Training [8/62] Loss: 0.03208 
Epoch [282/300] Training [9/62] Loss: 0.02888 
Epoch [282/300] Training [10/62] Loss: 0.02797 
Epoch [282/300] Training [11/62] Loss: 0.03653 
Epoch [282/300] Training [12/62] Loss: 0.02285 
Epoch [282/300] Training [13/62] Loss: 0.04703 
Epoch [282/300] Training [14/62] Loss: 0.02734 
Epoch [282/300] Training [15/62] Loss: 0.02776 
Epoch [282/300] Training [16/62] Loss: 0.01935 
Epoch [282/300] Training [17/62] Loss: 0.02321 
Epoch [282/300] Training [18/62] Loss: 0.02311 
Epoch [282/300] Training [19/62] Loss: 0.03366 
Epoch [282/300] Training [20/62] Loss: 0.02474 
Epoch [282/300] Training [21/62] Loss: 0.02379 
Epoch [282/300] Training [22/62] Loss: 0.05121 
Epoch [282/300] Training [23/62] Loss: 0.02422 
Epoch [282/300] Training [24/62] Loss: 0.02722 
Epoch [282/300] Training [25/62] Loss: 0.03170 
Epoch [282/300] Training [26/62] Loss: 0.02669 
Epoch [282/300] Training [27/62] Loss: 0.02689 
Epoch [282/300] Training [28/62] Loss: 0.02716 
Epoch [282/300] Training [29/62] Loss: 0.02902 
Epoch [282/300] Training [30/62] Loss: 0.02975 
Epoch [282/300] Training [31/62] Loss: 0.03975 
Epoch [282/300] Training [32/62] Loss: 0.03160 
Epoch [282/300] Training [33/62] Loss: 0.03450 
Epoch [282/300] Training [34/62] Loss: 0.02931 
Epoch [282/300] Training [35/62] Loss: 0.03864 
Epoch [282/300] Training [36/62] Loss: 0.02636 
Epoch [282/300] Training [37/62] Loss: 0.03664 
Epoch [282/300] Training [38/62] Loss: 0.02825 
Epoch [282/300] Training [39/62] Loss: 0.02042 
Epoch [282/300] Training [40/62] Loss: 0.02675 
Epoch [282/300] Training [41/62] Loss: 0.04034 
Epoch [282/300] Training [42/62] Loss: 0.03683 
Epoch [282/300] Training [43/62] Loss: 0.02464 
Epoch [282/300] Training [44/62] Loss: 0.04051 
Epoch [282/300] Training [45/62] Loss: 0.03117 
Epoch [282/300] Training [46/62] Loss: 0.04031 
Epoch [282/300] Training [47/62] Loss: 0.03121 
Epoch [282/300] Training [48/62] Loss: 0.02611 
Epoch [282/300] Training [49/62] Loss: 0.02260 
Epoch [282/300] Training [50/62] Loss: 0.02282 
Epoch [282/300] Training [51/62] Loss: 0.03143 
Epoch [282/300] Training [52/62] Loss: 0.02239 
Epoch [282/300] Training [53/62] Loss: 0.03028 
Epoch [282/300] Training [54/62] Loss: 0.03408 
Epoch [282/300] Training [55/62] Loss: 0.02997 
Epoch [282/300] Training [56/62] Loss: 0.02869 
Epoch [282/300] Training [57/62] Loss: 0.02538 
Epoch [282/300] Training [58/62] Loss: 0.03103 
Epoch [282/300] Training [59/62] Loss: 0.02952 
Epoch [282/300] Training [60/62] Loss: 0.02401 
Epoch [282/300] Training [61/62] Loss: 0.03489 
Epoch [282/300] Training [62/62] Loss: 0.03304 
Epoch [282/300] Training metric {'Train/mean dice_metric': 0.9795582294464111, 'Train/mean miou_metric': 0.9601145386695862, 'Train/mean f1': 0.977155864238739, 'Train/mean precision': 0.972663938999176, 'Train/mean recall': 0.9816896319389343, 'Train/mean hd95_metric': 2.7431297302246094}
Epoch [282/300] Validation [1/16] Loss: 0.54923  focal_loss 0.38082  dice_loss 0.16841 
Epoch [282/300] Validation [2/16] Loss: 0.42571  focal_loss 0.19532  dice_loss 0.23040 
Epoch [282/300] Validation [3/16] Loss: 0.69820  focal_loss 0.42592  dice_loss 0.27228 
Epoch [282/300] Validation [4/16] Loss: 0.34083  focal_loss 0.18166  dice_loss 0.15917 
Epoch [282/300] Validation [5/16] Loss: 0.35776  focal_loss 0.14863  dice_loss 0.20913 
Epoch [282/300] Validation [6/16] Loss: 0.23558  focal_loss 0.07310  dice_loss 0.16247 
Epoch [282/300] Validation [7/16] Loss: 0.38043  focal_loss 0.22721  dice_loss 0.15322 
Epoch [282/300] Validation [8/16] Loss: 0.42782  focal_loss 0.17211  dice_loss 0.25571 
Epoch [282/300] Validation [9/16] Loss: 0.17398  focal_loss 0.08862  dice_loss 0.08536 
Epoch [282/300] Validation [10/16] Loss: 0.41046  focal_loss 0.16613  dice_loss 0.24432 
Epoch [282/300] Validation [11/16] Loss: 0.15152  focal_loss 0.06442  dice_loss 0.08709 
Epoch [282/300] Validation [12/16] Loss: 0.36231  focal_loss 0.11627  dice_loss 0.24604 
Epoch [282/300] Validation [13/16] Loss: 0.21302  focal_loss 0.07594  dice_loss 0.13708 
Epoch [282/300] Validation [14/16] Loss: 0.46727  focal_loss 0.19538  dice_loss 0.27189 
Epoch [282/300] Validation [15/16] Loss: 0.11344  focal_loss 0.04871  dice_loss 0.06473 
Epoch [282/300] Validation [16/16] Loss: 0.04690  focal_loss 0.01649  dice_loss 0.03041 
Epoch [282/300] Validation metric {'Val/mean dice_metric': 0.9480608701705933, 'Val/mean miou_metric': 0.9173093438148499, 'Val/mean f1': 0.9505654573440552, 'Val/mean precision': 0.9511052966117859, 'Val/mean recall': 0.9500262141227722, 'Val/mean hd95_metric': 10.653111457824707}
Cheakpoint...
Epoch [282/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9481], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9480608701705933, 'Val/mean miou_metric': 0.9173093438148499, 'Val/mean f1': 0.9505654573440552, 'Val/mean precision': 0.9511052966117859, 'Val/mean recall': 0.9500262141227722, 'Val/mean hd95_metric': 10.653111457824707}
Epoch [283/300] Training [1/62] Loss: 0.02740 
Epoch [283/300] Training [2/62] Loss: 0.02075 
Epoch [283/300] Training [3/62] Loss: 0.02430 
Epoch [283/300] Training [4/62] Loss: 0.03347 
Epoch [283/300] Training [5/62] Loss: 0.02400 
Epoch [283/300] Training [6/62] Loss: 0.02711 
Epoch [283/300] Training [7/62] Loss: 0.02751 
Epoch [283/300] Training [8/62] Loss: 0.02730 
Epoch [283/300] Training [9/62] Loss: 0.02774 
Epoch [283/300] Training [10/62] Loss: 0.02893 
Epoch [283/300] Training [11/62] Loss: 0.02781 
Epoch [283/300] Training [12/62] Loss: 0.03277 
Epoch [283/300] Training [13/62] Loss: 0.02618 
Epoch [283/300] Training [14/62] Loss: 0.02476 
Epoch [283/300] Training [15/62] Loss: 0.03200 
Epoch [283/300] Training [16/62] Loss: 0.03626 
Epoch [283/300] Training [17/62] Loss: 0.02311 
Epoch [283/300] Training [18/62] Loss: 0.02742 
Epoch [283/300] Training [19/62] Loss: 0.02440 
Epoch [283/300] Training [20/62] Loss: 0.02691 
Epoch [283/300] Training [21/62] Loss: 0.04250 
Epoch [283/300] Training [22/62] Loss: 0.02527 
Epoch [283/300] Training [23/62] Loss: 0.02836 
Epoch [283/300] Training [24/62] Loss: 0.03599 
Epoch [283/300] Training [25/62] Loss: 0.05414 
Epoch [283/300] Training [26/62] Loss: 0.02868 
Epoch [283/300] Training [27/62] Loss: 0.02455 
Epoch [283/300] Training [28/62] Loss: 0.02483 
Epoch [283/300] Training [29/62] Loss: 0.02541 
Epoch [283/300] Training [30/62] Loss: 0.02641 
Epoch [283/300] Training [31/62] Loss: 0.02352 
Epoch [283/300] Training [32/62] Loss: 0.02747 
Epoch [283/300] Training [33/62] Loss: 0.02580 
Epoch [283/300] Training [34/62] Loss: 0.04295 
Epoch [283/300] Training [35/62] Loss: 0.02264 
Epoch [283/300] Training [36/62] Loss: 0.01784 
Epoch [283/300] Training [37/62] Loss: 0.02523 
Epoch [283/300] Training [38/62] Loss: 0.03622 
Epoch [283/300] Training [39/62] Loss: 0.02157 
Epoch [283/300] Training [40/62] Loss: 0.03192 
Epoch [283/300] Training [41/62] Loss: 0.02011 
Epoch [283/300] Training [42/62] Loss: 0.03380 
Epoch [283/300] Training [43/62] Loss: 0.02029 
Epoch [283/300] Training [44/62] Loss: 0.03430 
Epoch [283/300] Training [45/62] Loss: 0.02405 
Epoch [283/300] Training [46/62] Loss: 0.02464 
Epoch [283/300] Training [47/62] Loss: 0.03035 
Epoch [283/300] Training [48/62] Loss: 0.03102 
Epoch [283/300] Training [49/62] Loss: 0.06572 
Epoch [283/300] Training [50/62] Loss: 0.02233 
Epoch [283/300] Training [51/62] Loss: 0.02732 
Epoch [283/300] Training [52/62] Loss: 0.03471 
Epoch [283/300] Training [53/62] Loss: 0.03067 
Epoch [283/300] Training [54/62] Loss: 0.02661 
Epoch [283/300] Training [55/62] Loss: 0.03070 
Epoch [283/300] Training [56/62] Loss: 0.01978 
Epoch [283/300] Training [57/62] Loss: 0.03250 
Epoch [283/300] Training [58/62] Loss: 0.03291 
Epoch [283/300] Training [59/62] Loss: 0.02742 
Epoch [283/300] Training [60/62] Loss: 0.02154 
Epoch [283/300] Training [61/62] Loss: 0.04485 
Epoch [283/300] Training [62/62] Loss: 0.01881 
Epoch [283/300] Training metric {'Train/mean dice_metric': 0.9805601239204407, 'Train/mean miou_metric': 0.9620930552482605, 'Train/mean f1': 0.9776055216789246, 'Train/mean precision': 0.9731900691986084, 'Train/mean recall': 0.9820613265037537, 'Train/mean hd95_metric': 2.9822115898132324}
Epoch [283/300] Validation [1/16] Loss: 0.52077  focal_loss 0.34238  dice_loss 0.17840 
Epoch [283/300] Validation [2/16] Loss: 0.50290  focal_loss 0.25769  dice_loss 0.24521 
Epoch [283/300] Validation [3/16] Loss: 0.38482  focal_loss 0.16907  dice_loss 0.21575 
Epoch [283/300] Validation [4/16] Loss: 0.26846  focal_loss 0.12995  dice_loss 0.13851 
Epoch [283/300] Validation [5/16] Loss: 0.28853  focal_loss 0.08716  dice_loss 0.20137 
Epoch [283/300] Validation [6/16] Loss: 0.34285  focal_loss 0.11712  dice_loss 0.22573 
Epoch [283/300] Validation [7/16] Loss: 0.34879  focal_loss 0.18479  dice_loss 0.16401 
Epoch [283/300] Validation [8/16] Loss: 0.40100  focal_loss 0.16795  dice_loss 0.23305 
Epoch [283/300] Validation [9/16] Loss: 0.21171  focal_loss 0.11187  dice_loss 0.09984 
Epoch [283/300] Validation [10/16] Loss: 0.31137  focal_loss 0.11840  dice_loss 0.19297 
Epoch [283/300] Validation [11/16] Loss: 0.11125  focal_loss 0.04714  dice_loss 0.06411 
Epoch [283/300] Validation [12/16] Loss: 0.36916  focal_loss 0.12285  dice_loss 0.24631 
Epoch [283/300] Validation [13/16] Loss: 0.39012  focal_loss 0.17890  dice_loss 0.21123 
Epoch [283/300] Validation [14/16] Loss: 0.54732  focal_loss 0.21250  dice_loss 0.33483 
Epoch [283/300] Validation [15/16] Loss: 0.24511  focal_loss 0.10394  dice_loss 0.14117 
Epoch [283/300] Validation [16/16] Loss: 0.05437  focal_loss 0.02099  dice_loss 0.03338 
Epoch [283/300] Validation metric {'Val/mean dice_metric': 0.9470081329345703, 'Val/mean miou_metric': 0.9166624546051025, 'Val/mean f1': 0.9489473700523376, 'Val/mean precision': 0.9481464624404907, 'Val/mean recall': 0.9497496485710144, 'Val/mean hd95_metric': 11.070796012878418}
Cheakpoint...
Epoch [283/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9470], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9470081329345703, 'Val/mean miou_metric': 0.9166624546051025, 'Val/mean f1': 0.9489473700523376, 'Val/mean precision': 0.9481464624404907, 'Val/mean recall': 0.9497496485710144, 'Val/mean hd95_metric': 11.070796012878418}
Epoch [284/300] Training [1/62] Loss: 0.03033 
Epoch [284/300] Training [2/62] Loss: 0.02698 
Epoch [284/300] Training [3/62] Loss: 0.02284 
Epoch [284/300] Training [4/62] Loss: 0.02782 
Epoch [284/300] Training [5/62] Loss: 0.03498 
Epoch [284/300] Training [6/62] Loss: 0.02541 
Epoch [284/300] Training [7/62] Loss: 0.02701 
Epoch [284/300] Training [8/62] Loss: 0.03295 
Epoch [284/300] Training [9/62] Loss: 0.04087 
Epoch [284/300] Training [10/62] Loss: 0.02048 
Epoch [284/300] Training [11/62] Loss: 0.02259 
Epoch [284/300] Training [12/62] Loss: 0.02344 
Epoch [284/300] Training [13/62] Loss: 0.02302 
Epoch [284/300] Training [14/62] Loss: 0.02899 
Epoch [284/300] Training [15/62] Loss: 0.02797 
Epoch [284/300] Training [16/62] Loss: 0.02514 
Epoch [284/300] Training [17/62] Loss: 0.04684 
Epoch [284/300] Training [18/62] Loss: 0.03321 
Epoch [284/300] Training [19/62] Loss: 0.02393 
Epoch [284/300] Training [20/62] Loss: 0.04839 
Epoch [284/300] Training [21/62] Loss: 0.03100 
Epoch [284/300] Training [22/62] Loss: 0.02942 
Epoch [284/300] Training [23/62] Loss: 0.03846 
Epoch [284/300] Training [24/62] Loss: 0.02907 
Epoch [284/300] Training [25/62] Loss: 0.03763 
Epoch [284/300] Training [26/62] Loss: 0.03175 
Epoch [284/300] Training [27/62] Loss: 0.02129 
Epoch [284/300] Training [28/62] Loss: 0.02791 
Epoch [284/300] Training [29/62] Loss: 0.02649 
Epoch [284/300] Training [30/62] Loss: 0.02442 
Epoch [284/300] Training [31/62] Loss: 0.02922 
Epoch [284/300] Training [32/62] Loss: 0.02057 
Epoch [284/300] Training [33/62] Loss: 0.02384 
Epoch [284/300] Training [34/62] Loss: 0.02235 
Epoch [284/300] Training [35/62] Loss: 0.02761 
Epoch [284/300] Training [36/62] Loss: 0.02750 
Epoch [284/300] Training [37/62] Loss: 0.03248 
Epoch [284/300] Training [38/62] Loss: 0.02583 
Epoch [284/300] Training [39/62] Loss: 0.02450 
Epoch [284/300] Training [40/62] Loss: 0.02992 
Epoch [284/300] Training [41/62] Loss: 0.02633 
Epoch [284/300] Training [42/62] Loss: 0.02034 
Epoch [284/300] Training [43/62] Loss: 0.03042 
Epoch [284/300] Training [44/62] Loss: 0.02662 
Epoch [284/300] Training [45/62] Loss: 0.03424 
Epoch [284/300] Training [46/62] Loss: 0.02661 
Epoch [284/300] Training [47/62] Loss: 0.03572 
Epoch [284/300] Training [48/62] Loss: 0.03481 
Epoch [284/300] Training [49/62] Loss: 0.02891 
Epoch [284/300] Training [50/62] Loss: 0.02948 
Epoch [284/300] Training [51/62] Loss: 0.02566 
Epoch [284/300] Training [52/62] Loss: 0.02834 
Epoch [284/300] Training [53/62] Loss: 0.03060 
Epoch [284/300] Training [54/62] Loss: 0.02359 
Epoch [284/300] Training [55/62] Loss: 0.02292 
Epoch [284/300] Training [56/62] Loss: 0.03392 
Epoch [284/300] Training [57/62] Loss: 0.03415 
Epoch [284/300] Training [58/62] Loss: 0.02338 
Epoch [284/300] Training [59/62] Loss: 0.02187 
Epoch [284/300] Training [60/62] Loss: 0.03210 
Epoch [284/300] Training [61/62] Loss: 0.03569 
Epoch [284/300] Training [62/62] Loss: 0.02109 
Epoch [284/300] Training metric {'Train/mean dice_metric': 0.9807020425796509, 'Train/mean miou_metric': 0.9621505737304688, 'Train/mean f1': 0.978029191493988, 'Train/mean precision': 0.9735763072967529, 'Train/mean recall': 0.9825230240821838, 'Train/mean hd95_metric': 2.6659417152404785}
Epoch [284/300] Validation [1/16] Loss: 0.23732  focal_loss 0.11507  dice_loss 0.12226 
Epoch [284/300] Validation [2/16] Loss: 0.52808  focal_loss 0.28261  dice_loss 0.24547 
Epoch [284/300] Validation [3/16] Loss: 0.69276  focal_loss 0.42393  dice_loss 0.26883 
Epoch [284/300] Validation [4/16] Loss: 0.31057  focal_loss 0.16903  dice_loss 0.14154 
Epoch [284/300] Validation [5/16] Loss: 0.35567  focal_loss 0.14158  dice_loss 0.21409 
Epoch [284/300] Validation [6/16] Loss: 0.26804  focal_loss 0.07581  dice_loss 0.19223 
Epoch [284/300] Validation [7/16] Loss: 0.33900  focal_loss 0.18356  dice_loss 0.15544 
Epoch [284/300] Validation [8/16] Loss: 0.37337  focal_loss 0.13394  dice_loss 0.23944 
Epoch [284/300] Validation [9/16] Loss: 0.21238  focal_loss 0.10881  dice_loss 0.10357 
Epoch [284/300] Validation [10/16] Loss: 0.21145  focal_loss 0.08257  dice_loss 0.12888 
Epoch [284/300] Validation [11/16] Loss: 0.12109  focal_loss 0.04830  dice_loss 0.07278 
Epoch [284/300] Validation [12/16] Loss: 0.40673  focal_loss 0.12606  dice_loss 0.28067 
Epoch [284/300] Validation [13/16] Loss: 0.34921  focal_loss 0.14423  dice_loss 0.20498 
Epoch [284/300] Validation [14/16] Loss: 0.49152  focal_loss 0.20004  dice_loss 0.29148 
Epoch [284/300] Validation [15/16] Loss: 0.25748  focal_loss 0.11349  dice_loss 0.14399 
Epoch [284/300] Validation [16/16] Loss: 0.04210  focal_loss 0.01433  dice_loss 0.02777 
Epoch [284/300] Validation metric {'Val/mean dice_metric': 0.9482725262641907, 'Val/mean miou_metric': 0.9179093241691589, 'Val/mean f1': 0.9500681757926941, 'Val/mean precision': 0.9489222764968872, 'Val/mean recall': 0.9512168765068054, 'Val/mean hd95_metric': 10.087838172912598}
Cheakpoint...
Epoch [284/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9483], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9482725262641907, 'Val/mean miou_metric': 0.9179093241691589, 'Val/mean f1': 0.9500681757926941, 'Val/mean precision': 0.9489222764968872, 'Val/mean recall': 0.9512168765068054, 'Val/mean hd95_metric': 10.087838172912598}
Epoch [285/300] Training [1/62] Loss: 0.03244 
Epoch [285/300] Training [2/62] Loss: 0.04366 
Epoch [285/300] Training [3/62] Loss: 0.03492 
Epoch [285/300] Training [4/62] Loss: 0.03100 
Epoch [285/300] Training [5/62] Loss: 0.03093 
Epoch [285/300] Training [6/62] Loss: 0.07010 
Epoch [285/300] Training [7/62] Loss: 0.02439 
Epoch [285/300] Training [8/62] Loss: 0.02247 
Epoch [285/300] Training [9/62] Loss: 0.02731 
Epoch [285/300] Training [10/62] Loss: 0.01997 
Epoch [285/300] Training [11/62] Loss: 0.02366 
Epoch [285/300] Training [12/62] Loss: 0.03187 
Epoch [285/300] Training [13/62] Loss: 0.03171 
Epoch [285/300] Training [14/62] Loss: 0.03040 
Epoch [285/300] Training [15/62] Loss: 0.02636 
Epoch [285/300] Training [16/62] Loss: 0.03278 
Epoch [285/300] Training [17/62] Loss: 0.02866 
Epoch [285/300] Training [18/62] Loss: 0.03830 
Epoch [285/300] Training [19/62] Loss: 0.02532 
Epoch [285/300] Training [20/62] Loss: 0.03412 
Epoch [285/300] Training [21/62] Loss: 0.06072 
Epoch [285/300] Training [22/62] Loss: 0.02535 
Epoch [285/300] Training [23/62] Loss: 0.02719 
Epoch [285/300] Training [24/62] Loss: 0.02326 
Epoch [285/300] Training [25/62] Loss: 0.02451 
Epoch [285/300] Training [26/62] Loss: 0.02412 
Epoch [285/300] Training [27/62] Loss: 0.02400 
Epoch [285/300] Training [28/62] Loss: 0.02407 
Epoch [285/300] Training [29/62] Loss: 0.03614 
Epoch [285/300] Training [30/62] Loss: 0.02389 
Epoch [285/300] Training [31/62] Loss: 0.03270 
Epoch [285/300] Training [32/62] Loss: 0.02584 
Epoch [285/300] Training [33/62] Loss: 0.05405 
Epoch [285/300] Training [34/62] Loss: 0.02646 
Epoch [285/300] Training [35/62] Loss: 0.02825 
Epoch [285/300] Training [36/62] Loss: 0.02478 
Epoch [285/300] Training [37/62] Loss: 0.06024 
Epoch [285/300] Training [38/62] Loss: 0.02512 
Epoch [285/300] Training [39/62] Loss: 0.02364 
Epoch [285/300] Training [40/62] Loss: 0.02413 
Epoch [285/300] Training [41/62] Loss: 0.02827 
Epoch [285/300] Training [42/62] Loss: 0.02191 
Epoch [285/300] Training [43/62] Loss: 0.02581 
Epoch [285/300] Training [44/62] Loss: 0.02816 
Epoch [285/300] Training [45/62] Loss: 0.03038 
Epoch [285/300] Training [46/62] Loss: 0.03545 
Epoch [285/300] Training [47/62] Loss: 0.04192 
Epoch [285/300] Training [48/62] Loss: 0.03899 
Epoch [285/300] Training [49/62] Loss: 0.02473 
Epoch [285/300] Training [50/62] Loss: 0.02123 
Epoch [285/300] Training [51/62] Loss: 0.02751 
Epoch [285/300] Training [52/62] Loss: 0.02788 
Epoch [285/300] Training [53/62] Loss: 0.02570 
Epoch [285/300] Training [54/62] Loss: 0.02515 
Epoch [285/300] Training [55/62] Loss: 0.02774 
Epoch [285/300] Training [56/62] Loss: 0.02080 
Epoch [285/300] Training [57/62] Loss: 0.02004 
Epoch [285/300] Training [58/62] Loss: 0.03058 
Epoch [285/300] Training [59/62] Loss: 0.02530 
Epoch [285/300] Training [60/62] Loss: 0.02781 
Epoch [285/300] Training [61/62] Loss: 0.03430 
Epoch [285/300] Training [62/62] Loss: 0.02851 
Epoch [285/300] Training metric {'Train/mean dice_metric': 0.9796596765518188, 'Train/mean miou_metric': 0.9605013728141785, 'Train/mean f1': 0.977702796459198, 'Train/mean precision': 0.9735276699066162, 'Train/mean recall': 0.9819139838218689, 'Train/mean hd95_metric': 2.7910029888153076}
Epoch [285/300] Validation [1/16] Loss: 0.22623  focal_loss 0.11796  dice_loss 0.10827 
Epoch [285/300] Validation [2/16] Loss: 0.47236  focal_loss 0.23040  dice_loss 0.24196 
Epoch [285/300] Validation [3/16] Loss: 0.67504  focal_loss 0.42158  dice_loss 0.25346 
Epoch [285/300] Validation [4/16] Loss: 0.35318  focal_loss 0.19345  dice_loss 0.15972 
Epoch [285/300] Validation [5/16] Loss: 0.37690  focal_loss 0.14477  dice_loss 0.23214 
Epoch [285/300] Validation [6/16] Loss: 0.25473  focal_loss 0.06622  dice_loss 0.18851 
Epoch [285/300] Validation [7/16] Loss: 0.19546  focal_loss 0.09182  dice_loss 0.10364 
Epoch [285/300] Validation [8/16] Loss: 0.38163  focal_loss 0.14454  dice_loss 0.23709 
Epoch [285/300] Validation [9/16] Loss: 0.17162  focal_loss 0.09074  dice_loss 0.08088 
Epoch [285/300] Validation [10/16] Loss: 0.40437  focal_loss 0.16643  dice_loss 0.23794 
Epoch [285/300] Validation [11/16] Loss: 0.11584  focal_loss 0.04780  dice_loss 0.06803 
Epoch [285/300] Validation [12/16] Loss: 0.32840  focal_loss 0.08626  dice_loss 0.24214 
Epoch [285/300] Validation [13/16] Loss: 0.39175  focal_loss 0.18238  dice_loss 0.20938 
Epoch [285/300] Validation [14/16] Loss: 0.38598  focal_loss 0.14980  dice_loss 0.23619 
Epoch [285/300] Validation [15/16] Loss: 0.11733  focal_loss 0.04673  dice_loss 0.07060 
Epoch [285/300] Validation [16/16] Loss: 0.05778  focal_loss 0.02386  dice_loss 0.03392 
Epoch [285/300] Validation metric {'Val/mean dice_metric': 0.9491154551506042, 'Val/mean miou_metric': 0.9186912178993225, 'Val/mean f1': 0.9520482420921326, 'Val/mean precision': 0.9498780965805054, 'Val/mean recall': 0.9542284607887268, 'Val/mean hd95_metric': 9.896191596984863}
Cheakpoint...
Epoch [285/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9491], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9491154551506042, 'Val/mean miou_metric': 0.9186912178993225, 'Val/mean f1': 0.9520482420921326, 'Val/mean precision': 0.9498780965805054, 'Val/mean recall': 0.9542284607887268, 'Val/mean hd95_metric': 9.896191596984863}
Epoch [286/300] Training [1/62] Loss: 0.02284 
Epoch [286/300] Training [2/62] Loss: 0.03306 
Epoch [286/300] Training [3/62] Loss: 0.02454 
Epoch [286/300] Training [4/62] Loss: 0.04014 
Epoch [286/300] Training [5/62] Loss: 0.02885 
Epoch [286/300] Training [6/62] Loss: 0.02479 
Epoch [286/300] Training [7/62] Loss: 0.02419 
Epoch [286/300] Training [8/62] Loss: 0.02674 
Epoch [286/300] Training [9/62] Loss: 0.02732 
Epoch [286/300] Training [10/62] Loss: 0.02932 
Epoch [286/300] Training [11/62] Loss: 0.02273 
Epoch [286/300] Training [12/62] Loss: 0.02709 
Epoch [286/300] Training [13/62] Loss: 0.02859 
Epoch [286/300] Training [14/62] Loss: 0.02135 
Epoch [286/300] Training [15/62] Loss: 0.02310 
Epoch [286/300] Training [16/62] Loss: 0.01887 
Epoch [286/300] Training [17/62] Loss: 0.02001 
Epoch [286/300] Training [18/62] Loss: 0.03098 
Epoch [286/300] Training [19/62] Loss: 0.01745 
Epoch [286/300] Training [20/62] Loss: 0.02502 
Epoch [286/300] Training [21/62] Loss: 0.02249 
Epoch [286/300] Training [22/62] Loss: 0.01982 
Epoch [286/300] Training [23/62] Loss: 0.03638 
Epoch [286/300] Training [24/62] Loss: 0.04602 
Epoch [286/300] Training [25/62] Loss: 0.02885 
Epoch [286/300] Training [26/62] Loss: 0.04562 
Epoch [286/300] Training [27/62] Loss: 0.03362 
Epoch [286/300] Training [28/62] Loss: 0.05554 
Epoch [286/300] Training [29/62] Loss: 0.02883 
Epoch [286/300] Training [30/62] Loss: 0.03195 
Epoch [286/300] Training [31/62] Loss: 0.04247 
Epoch [286/300] Training [32/62] Loss: 0.04962 
Epoch [286/300] Training [33/62] Loss: 0.03067 
Epoch [286/300] Training [34/62] Loss: 0.02146 
Epoch [286/300] Training [35/62] Loss: 0.03041 
Epoch [286/300] Training [36/62] Loss: 0.02810 
Epoch [286/300] Training [37/62] Loss: 0.02139 
Epoch [286/300] Training [38/62] Loss: 0.02524 
Epoch [286/300] Training [39/62] Loss: 0.03969 
Epoch [286/300] Training [40/62] Loss: 0.03152 
Epoch [286/300] Training [41/62] Loss: 0.04267 
Epoch [286/300] Training [42/62] Loss: 0.02071 
Epoch [286/300] Training [43/62] Loss: 0.02773 
Epoch [286/300] Training [44/62] Loss: 0.02358 
Epoch [286/300] Training [45/62] Loss: 0.02911 
Epoch [286/300] Training [46/62] Loss: 0.02682 
Epoch [286/300] Training [47/62] Loss: 0.03770 
Epoch [286/300] Training [48/62] Loss: 0.06284 
Epoch [286/300] Training [49/62] Loss: 0.03405 
Epoch [286/300] Training [50/62] Loss: 0.02411 
Epoch [286/300] Training [51/62] Loss: 0.02063 
Epoch [286/300] Training [52/62] Loss: 0.04001 
Epoch [286/300] Training [53/62] Loss: 0.02713 
Epoch [286/300] Training [54/62] Loss: 0.03009 
Epoch [286/300] Training [55/62] Loss: 0.02409 
Epoch [286/300] Training [56/62] Loss: 0.02917 
Epoch [286/300] Training [57/62] Loss: 0.02422 
Epoch [286/300] Training [58/62] Loss: 0.04271 
Epoch [286/300] Training [59/62] Loss: 0.02628 
Epoch [286/300] Training [60/62] Loss: 0.04278 
Epoch [286/300] Training [61/62] Loss: 0.02867 
Epoch [286/300] Training [62/62] Loss: 0.03119 
Epoch [286/300] Training metric {'Train/mean dice_metric': 0.97999507188797, 'Train/mean miou_metric': 0.9610633254051208, 'Train/mean f1': 0.9767501354217529, 'Train/mean precision': 0.9718615412712097, 'Train/mean recall': 0.9816881418228149, 'Train/mean hd95_metric': 2.865145206451416}
Epoch [286/300] Validation [1/16] Loss: 0.51026  focal_loss 0.33648  dice_loss 0.17378 
Epoch [286/300] Validation [2/16] Loss: 0.44308  focal_loss 0.20474  dice_loss 0.23834 
Epoch [286/300] Validation [3/16] Loss: 0.36887  focal_loss 0.15014  dice_loss 0.21872 
Epoch [286/300] Validation [4/16] Loss: 0.32493  focal_loss 0.17202  dice_loss 0.15291 
Epoch [286/300] Validation [5/16] Loss: 0.31882  focal_loss 0.13308  dice_loss 0.18573 
Epoch [286/300] Validation [6/16] Loss: 0.24357  focal_loss 0.06667  dice_loss 0.17690 
Epoch [286/300] Validation [7/16] Loss: 0.16504  focal_loss 0.07352  dice_loss 0.09152 
Epoch [286/300] Validation [8/16] Loss: 0.42537  focal_loss 0.16920  dice_loss 0.25617 
Epoch [286/300] Validation [9/16] Loss: 0.17528  focal_loss 0.09105  dice_loss 0.08423 
Epoch [286/300] Validation [10/16] Loss: 0.26646  focal_loss 0.09368  dice_loss 0.17278 
Epoch [286/300] Validation [11/16] Loss: 0.15498  focal_loss 0.05916  dice_loss 0.09582 
Epoch [286/300] Validation [12/16] Loss: 0.33953  focal_loss 0.09609  dice_loss 0.24344 
Epoch [286/300] Validation [13/16] Loss: 0.18232  focal_loss 0.07280  dice_loss 0.10952 
Epoch [286/300] Validation [14/16] Loss: 0.50059  focal_loss 0.19321  dice_loss 0.30738 
Epoch [286/300] Validation [15/16] Loss: 0.11696  focal_loss 0.04923  dice_loss 0.06773 
Epoch [286/300] Validation [16/16] Loss: 0.04672  focal_loss 0.01651  dice_loss 0.03022 
Epoch [286/300] Validation metric {'Val/mean dice_metric': 0.9507309794425964, 'Val/mean miou_metric': 0.9201645255088806, 'Val/mean f1': 0.9529191851615906, 'Val/mean precision': 0.9516905546188354, 'Val/mean recall': 0.9541507959365845, 'Val/mean hd95_metric': 9.913174629211426}
Cheakpoint...
Epoch [286/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9507], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9507309794425964, 'Val/mean miou_metric': 0.9201645255088806, 'Val/mean f1': 0.9529191851615906, 'Val/mean precision': 0.9516905546188354, 'Val/mean recall': 0.9541507959365845, 'Val/mean hd95_metric': 9.913174629211426}
Epoch [287/300] Training [1/62] Loss: 0.03145 
Epoch [287/300] Training [2/62] Loss: 0.03004 
Epoch [287/300] Training [3/62] Loss: 0.02380 
Epoch [287/300] Training [4/62] Loss: 0.02856 
Epoch [287/300] Training [5/62] Loss: 0.02127 
Epoch [287/300] Training [6/62] Loss: 0.02439 
Epoch [287/300] Training [7/62] Loss: 0.04758 
Epoch [287/300] Training [8/62] Loss: 0.02506 
Epoch [287/300] Training [9/62] Loss: 0.03140 
Epoch [287/300] Training [10/62] Loss: 0.03211 
Epoch [287/300] Training [11/62] Loss: 0.05132 
Epoch [287/300] Training [12/62] Loss: 0.03263 
Epoch [287/300] Training [13/62] Loss: 0.03815 
Epoch [287/300] Training [14/62] Loss: 0.02923 
Epoch [287/300] Training [15/62] Loss: 0.03004 
Epoch [287/300] Training [16/62] Loss: 0.02764 
Epoch [287/300] Training [17/62] Loss: 0.03656 
Epoch [287/300] Training [18/62] Loss: 0.03467 
Epoch [287/300] Training [19/62] Loss: 0.03443 
Epoch [287/300] Training [20/62] Loss: 0.01954 
Epoch [287/300] Training [21/62] Loss: 0.01918 
Epoch [287/300] Training [22/62] Loss: 0.02636 
Epoch [287/300] Training [23/62] Loss: 0.02760 
Epoch [287/300] Training [24/62] Loss: 0.02099 
Epoch [287/300] Training [25/62] Loss: 0.02276 
Epoch [287/300] Training [26/62] Loss: 0.02533 
Epoch [287/300] Training [27/62] Loss: 0.02793 
Epoch [287/300] Training [28/62] Loss: 0.02069 
Epoch [287/300] Training [29/62] Loss: 0.04568 
Epoch [287/300] Training [30/62] Loss: 0.03006 
Epoch [287/300] Training [31/62] Loss: 0.03091 
Epoch [287/300] Training [32/62] Loss: 0.03723 
Epoch [287/300] Training [33/62] Loss: 0.03255 
Epoch [287/300] Training [34/62] Loss: 0.02434 
Epoch [287/300] Training [35/62] Loss: 0.02247 
Epoch [287/300] Training [36/62] Loss: 0.02301 
Epoch [287/300] Training [37/62] Loss: 0.02032 
Epoch [287/300] Training [38/62] Loss: 0.02865 
Epoch [287/300] Training [39/62] Loss: 0.02365 
Epoch [287/300] Training [40/62] Loss: 0.02586 
Epoch [287/300] Training [41/62] Loss: 0.02535 
Epoch [287/300] Training [42/62] Loss: 0.07911 
Epoch [287/300] Training [43/62] Loss: 0.02296 
Epoch [287/300] Training [44/62] Loss: 0.03065 
Epoch [287/300] Training [45/62] Loss: 0.02775 
Epoch [287/300] Training [46/62] Loss: 0.02455 
Epoch [287/300] Training [47/62] Loss: 0.02537 
Epoch [287/300] Training [48/62] Loss: 0.05178 
Epoch [287/300] Training [49/62] Loss: 0.03726 
Epoch [287/300] Training [50/62] Loss: 0.03125 
Epoch [287/300] Training [51/62] Loss: 0.02498 
Epoch [287/300] Training [52/62] Loss: 0.06172 
Epoch [287/300] Training [53/62] Loss: 0.02628 
Epoch [287/300] Training [54/62] Loss: 0.02592 
Epoch [287/300] Training [55/62] Loss: 0.02695 
Epoch [287/300] Training [56/62] Loss: 0.02533 
Epoch [287/300] Training [57/62] Loss: 0.02377 
Epoch [287/300] Training [58/62] Loss: 0.02012 
Epoch [287/300] Training [59/62] Loss: 0.03549 
Epoch [287/300] Training [60/62] Loss: 0.03087 
Epoch [287/300] Training [61/62] Loss: 0.03359 
Epoch [287/300] Training [62/62] Loss: 0.01963 
Epoch [287/300] Training metric {'Train/mean dice_metric': 0.9797583222389221, 'Train/mean miou_metric': 0.9608128070831299, 'Train/mean f1': 0.9775547385215759, 'Train/mean precision': 0.9729320406913757, 'Train/mean recall': 0.9822216629981995, 'Train/mean hd95_metric': 2.704094648361206}
Epoch [287/300] Validation [1/16] Loss: 0.22337  focal_loss 0.11635  dice_loss 0.10703 
Epoch [287/300] Validation [2/16] Loss: 0.53888  focal_loss 0.29628  dice_loss 0.24260 
Epoch [287/300] Validation [3/16] Loss: 0.38872  focal_loss 0.17218  dice_loss 0.21654 
Epoch [287/300] Validation [4/16] Loss: 0.31448  focal_loss 0.17166  dice_loss 0.14283 
Epoch [287/300] Validation [5/16] Loss: 0.33437  focal_loss 0.09974  dice_loss 0.23463 
Epoch [287/300] Validation [6/16] Loss: 0.22625  focal_loss 0.06048  dice_loss 0.16577 
Epoch [287/300] Validation [7/16] Loss: 0.21000  focal_loss 0.10020  dice_loss 0.10981 
Epoch [287/300] Validation [8/16] Loss: 0.45020  focal_loss 0.17909  dice_loss 0.27111 
Epoch [287/300] Validation [9/16] Loss: 0.18112  focal_loss 0.09396  dice_loss 0.08716 
Epoch [287/300] Validation [10/16] Loss: 0.21851  focal_loss 0.08517  dice_loss 0.13334 
Epoch [287/300] Validation [11/16] Loss: 0.12682  focal_loss 0.05047  dice_loss 0.07635 
Epoch [287/300] Validation [12/16] Loss: 0.34760  focal_loss 0.09243  dice_loss 0.25517 
Epoch [287/300] Validation [13/16] Loss: 0.36557  focal_loss 0.17426  dice_loss 0.19131 
Epoch [287/300] Validation [14/16] Loss: 0.48334  focal_loss 0.20072  dice_loss 0.28262 
Epoch [287/300] Validation [15/16] Loss: 0.12960  focal_loss 0.05855  dice_loss 0.07105 
Epoch [287/300] Validation [16/16] Loss: 0.06018  focal_loss 0.02529  dice_loss 0.03489 
Epoch [287/300] Validation metric {'Val/mean dice_metric': 0.9504263997077942, 'Val/mean miou_metric': 0.9198111891746521, 'Val/mean f1': 0.9528806209564209, 'Val/mean precision': 0.9517652988433838, 'Val/mean recall': 0.9539987444877625, 'Val/mean hd95_metric': 10.047320365905762}
Cheakpoint...
Epoch [287/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9504], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9504263997077942, 'Val/mean miou_metric': 0.9198111891746521, 'Val/mean f1': 0.9528806209564209, 'Val/mean precision': 0.9517652988433838, 'Val/mean recall': 0.9539987444877625, 'Val/mean hd95_metric': 10.047320365905762}
Epoch [288/300] Training [1/62] Loss: 0.03133 
Epoch [288/300] Training [2/62] Loss: 0.02992 
Epoch [288/300] Training [3/62] Loss: 0.04055 
Epoch [288/300] Training [4/62] Loss: 0.05424 
Epoch [288/300] Training [5/62] Loss: 0.02446 
Epoch [288/300] Training [6/62] Loss: 0.03237 
Epoch [288/300] Training [7/62] Loss: 0.02844 
Epoch [288/300] Training [8/62] Loss: 0.04733 
Epoch [288/300] Training [9/62] Loss: 0.03195 
Epoch [288/300] Training [10/62] Loss: 0.02352 
Epoch [288/300] Training [11/62] Loss: 0.02921 
Epoch [288/300] Training [12/62] Loss: 0.02572 
Epoch [288/300] Training [13/62] Loss: 0.02127 
Epoch [288/300] Training [14/62] Loss: 0.02915 
Epoch [288/300] Training [15/62] Loss: 0.02843 
Epoch [288/300] Training [16/62] Loss: 0.02396 
Epoch [288/300] Training [17/62] Loss: 0.02418 
Epoch [288/300] Training [18/62] Loss: 0.03440 
Epoch [288/300] Training [19/62] Loss: 0.03272 
Epoch [288/300] Training [20/62] Loss: 0.02591 
Epoch [288/300] Training [21/62] Loss: 0.02301 
Epoch [288/300] Training [22/62] Loss: 0.02571 
Epoch [288/300] Training [23/62] Loss: 0.03118 
Epoch [288/300] Training [24/62] Loss: 0.02175 
Epoch [288/300] Training [25/62] Loss: 0.02797 
Epoch [288/300] Training [26/62] Loss: 0.03215 
Epoch [288/300] Training [27/62] Loss: 0.02939 
Epoch [288/300] Training [28/62] Loss: 0.02079 
Epoch [288/300] Training [29/62] Loss: 0.02478 
Epoch [288/300] Training [30/62] Loss: 0.02610 
Epoch [288/300] Training [31/62] Loss: 0.03806 
Epoch [288/300] Training [32/62] Loss: 0.05492 
Epoch [288/300] Training [33/62] Loss: 0.03122 
Epoch [288/300] Training [34/62] Loss: 0.02044 
Epoch [288/300] Training [35/62] Loss: 0.02399 
Epoch [288/300] Training [36/62] Loss: 0.02917 
Epoch [288/300] Training [37/62] Loss: 0.02469 
Epoch [288/300] Training [38/62] Loss: 0.02899 
Epoch [288/300] Training [39/62] Loss: 0.03016 
Epoch [288/300] Training [40/62] Loss: 0.03044 
Epoch [288/300] Training [41/62] Loss: 0.03230 
Epoch [288/300] Training [42/62] Loss: 0.08087 
Epoch [288/300] Training [43/62] Loss: 0.03961 
Epoch [288/300] Training [44/62] Loss: 0.03229 
Epoch [288/300] Training [45/62] Loss: 0.02465 
Epoch [288/300] Training [46/62] Loss: 0.03381 
Epoch [288/300] Training [47/62] Loss: 0.02348 
Epoch [288/300] Training [48/62] Loss: 0.02910 
Epoch [288/300] Training [49/62] Loss: 0.03045 
Epoch [288/300] Training [50/62] Loss: 0.02538 
Epoch [288/300] Training [51/62] Loss: 0.02578 
Epoch [288/300] Training [52/62] Loss: 0.02137 
Epoch [288/300] Training [53/62] Loss: 0.02789 
Epoch [288/300] Training [54/62] Loss: 0.03074 
Epoch [288/300] Training [55/62] Loss: 0.02958 
Epoch [288/300] Training [56/62] Loss: 0.03398 
Epoch [288/300] Training [57/62] Loss: 0.03209 
Epoch [288/300] Training [58/62] Loss: 0.02944 
Epoch [288/300] Training [59/62] Loss: 0.02979 
Epoch [288/300] Training [60/62] Loss: 0.05682 
Epoch [288/300] Training [61/62] Loss: 0.04540 
Epoch [288/300] Training [62/62] Loss: 0.05646 
Epoch [288/300] Training metric {'Train/mean dice_metric': 0.9792601466178894, 'Train/mean miou_metric': 0.9597931504249573, 'Train/mean f1': 0.9770223498344421, 'Train/mean precision': 0.9727807641029358, 'Train/mean recall': 0.9813011884689331, 'Train/mean hd95_metric': 3.2468440532684326}
Epoch [288/300] Validation [1/16] Loss: 0.56860  focal_loss 0.38864  dice_loss 0.17996 
Epoch [288/300] Validation [2/16] Loss: 0.46789  focal_loss 0.24668  dice_loss 0.22121 
Epoch [288/300] Validation [3/16] Loss: 0.38425  focal_loss 0.16751  dice_loss 0.21674 
Epoch [288/300] Validation [4/16] Loss: 0.38104  focal_loss 0.20455  dice_loss 0.17649 
Epoch [288/300] Validation [5/16] Loss: 0.37737  focal_loss 0.14491  dice_loss 0.23246 
Epoch [288/300] Validation [6/16] Loss: 0.28201  focal_loss 0.09100  dice_loss 0.19101 
Epoch [288/300] Validation [7/16] Loss: 0.27994  focal_loss 0.14594  dice_loss 0.13401 
Epoch [288/300] Validation [8/16] Loss: 0.47808  focal_loss 0.19746  dice_loss 0.28062 
Epoch [288/300] Validation [9/16] Loss: 0.16991  focal_loss 0.08907  dice_loss 0.08083 
Epoch [288/300] Validation [10/16] Loss: 0.44772  focal_loss 0.19740  dice_loss 0.25032 
Epoch [288/300] Validation [11/16] Loss: 0.13574  focal_loss 0.05474  dice_loss 0.08100 
Epoch [288/300] Validation [12/16] Loss: 0.32330  focal_loss 0.08232  dice_loss 0.24098 
Epoch [288/300] Validation [13/16] Loss: 0.40526  focal_loss 0.18618  dice_loss 0.21908 
Epoch [288/300] Validation [14/16] Loss: 0.59050  focal_loss 0.23145  dice_loss 0.35905 
Epoch [288/300] Validation [15/16] Loss: 0.12917  focal_loss 0.05608  dice_loss 0.07308 
Epoch [288/300] Validation [16/16] Loss: 0.07559  focal_loss 0.03130  dice_loss 0.04429 
Epoch [288/300] Validation metric {'Val/mean dice_metric': 0.9454704523086548, 'Val/mean miou_metric': 0.9141709804534912, 'Val/mean f1': 0.949607253074646, 'Val/mean precision': 0.9485481381416321, 'Val/mean recall': 0.9506689310073853, 'Val/mean hd95_metric': 11.784112930297852}
Cheakpoint...
Epoch [288/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9455], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9454704523086548, 'Val/mean miou_metric': 0.9141709804534912, 'Val/mean f1': 0.949607253074646, 'Val/mean precision': 0.9485481381416321, 'Val/mean recall': 0.9506689310073853, 'Val/mean hd95_metric': 11.784112930297852}
Epoch [289/300] Training [1/62] Loss: 0.03889 
Epoch [289/300] Training [2/62] Loss: 0.03204 
Epoch [289/300] Training [3/62] Loss: 0.02771 
Epoch [289/300] Training [4/62] Loss: 0.02930 
Epoch [289/300] Training [5/62] Loss: 0.03029 
Epoch [289/300] Training [6/62] Loss: 0.02665 
Epoch [289/300] Training [7/62] Loss: 0.02999 
Epoch [289/300] Training [8/62] Loss: 0.02758 
Epoch [289/300] Training [9/62] Loss: 0.02545 
Epoch [289/300] Training [10/62] Loss: 0.02486 
Epoch [289/300] Training [11/62] Loss: 0.03095 
Epoch [289/300] Training [12/62] Loss: 0.06742 
Epoch [289/300] Training [13/62] Loss: 0.02756 
Epoch [289/300] Training [14/62] Loss: 0.03229 
Epoch [289/300] Training [15/62] Loss: 0.02874 
Epoch [289/300] Training [16/62] Loss: 0.03371 
Epoch [289/300] Training [17/62] Loss: 0.02907 
Epoch [289/300] Training [18/62] Loss: 0.02289 
Epoch [289/300] Training [19/62] Loss: 0.04058 
Epoch [289/300] Training [20/62] Loss: 0.03461 
Epoch [289/300] Training [21/62] Loss: 0.03620 
Epoch [289/300] Training [22/62] Loss: 0.02226 
Epoch [289/300] Training [23/62] Loss: 0.02467 
Epoch [289/300] Training [24/62] Loss: 0.02978 
Epoch [289/300] Training [25/62] Loss: 0.03820 
Epoch [289/300] Training [26/62] Loss: 0.06656 
Epoch [289/300] Training [27/62] Loss: 0.03539 
Epoch [289/300] Training [28/62] Loss: 0.02745 
Epoch [289/300] Training [29/62] Loss: 0.02729 
Epoch [289/300] Training [30/62] Loss: 0.03956 
Epoch [289/300] Training [31/62] Loss: 0.02275 
Epoch [289/300] Training [32/62] Loss: 0.02255 
Epoch [289/300] Training [33/62] Loss: 0.02348 
Epoch [289/300] Training [34/62] Loss: 0.02778 
Epoch [289/300] Training [35/62] Loss: 0.03940 
Epoch [289/300] Training [36/62] Loss: 0.03035 
Epoch [289/300] Training [37/62] Loss: 0.03505 
Epoch [289/300] Training [38/62] Loss: 0.02884 
Epoch [289/300] Training [39/62] Loss: 0.02070 
Epoch [289/300] Training [40/62] Loss: 0.04121 
Epoch [289/300] Training [41/62] Loss: 0.05310 
Epoch [289/300] Training [42/62] Loss: 0.03146 
Epoch [289/300] Training [43/62] Loss: 0.03091 
Epoch [289/300] Training [44/62] Loss: 0.02404 
Epoch [289/300] Training [45/62] Loss: 0.02538 
Epoch [289/300] Training [46/62] Loss: 0.03557 
Epoch [289/300] Training [47/62] Loss: 0.02590 
Epoch [289/300] Training [48/62] Loss: 0.02269 
Epoch [289/300] Training [49/62] Loss: 0.03046 
Epoch [289/300] Training [50/62] Loss: 0.02639 
Epoch [289/300] Training [51/62] Loss: 0.02424 
Epoch [289/300] Training [52/62] Loss: 0.02204 
Epoch [289/300] Training [53/62] Loss: 0.03240 
Epoch [289/300] Training [54/62] Loss: 0.04339 
Epoch [289/300] Training [55/62] Loss: 0.02320 
Epoch [289/300] Training [56/62] Loss: 0.02811 
Epoch [289/300] Training [57/62] Loss: 0.03740 
Epoch [289/300] Training [58/62] Loss: 0.02577 
Epoch [289/300] Training [59/62] Loss: 0.02312 
Epoch [289/300] Training [60/62] Loss: 0.02453 
Epoch [289/300] Training [61/62] Loss: 0.02022 
Epoch [289/300] Training [62/62] Loss: 0.01825 
Epoch [289/300] Training metric {'Train/mean dice_metric': 0.9793874621391296, 'Train/mean miou_metric': 0.9600083827972412, 'Train/mean f1': 0.9769087433815002, 'Train/mean precision': 0.9724020957946777, 'Train/mean recall': 0.9814574718475342, 'Train/mean hd95_metric': 3.0626399517059326}
Epoch [289/300] Validation [1/16] Loss: 0.25223  focal_loss 0.12444  dice_loss 0.12779 
Epoch [289/300] Validation [2/16] Loss: 0.56163  focal_loss 0.30562  dice_loss 0.25601 
Epoch [289/300] Validation [3/16] Loss: 0.38292  focal_loss 0.16852  dice_loss 0.21440 
Epoch [289/300] Validation [4/16] Loss: 0.27174  focal_loss 0.13490  dice_loss 0.13684 
Epoch [289/300] Validation [5/16] Loss: 0.34523  focal_loss 0.13578  dice_loss 0.20945 
Epoch [289/300] Validation [6/16] Loss: 0.28372  focal_loss 0.08155  dice_loss 0.20217 
Epoch [289/300] Validation [7/16] Loss: 0.29833  focal_loss 0.17287  dice_loss 0.12546 
Epoch [289/300] Validation [8/16] Loss: 0.40698  focal_loss 0.14627  dice_loss 0.26070 
Epoch [289/300] Validation [9/16] Loss: 0.21499  focal_loss 0.11454  dice_loss 0.10046 
Epoch [289/300] Validation [10/16] Loss: 0.21860  focal_loss 0.08498  dice_loss 0.13362 
Epoch [289/300] Validation [11/16] Loss: 0.11785  focal_loss 0.05090  dice_loss 0.06694 
Epoch [289/300] Validation [12/16] Loss: 0.31867  focal_loss 0.08153  dice_loss 0.23714 
Epoch [289/300] Validation [13/16] Loss: 0.34704  focal_loss 0.16004  dice_loss 0.18701 
Epoch [289/300] Validation [14/16] Loss: 0.42920  focal_loss 0.17836  dice_loss 0.25084 
Epoch [289/300] Validation [15/16] Loss: 0.27542  focal_loss 0.12390  dice_loss 0.15152 
Epoch [289/300] Validation [16/16] Loss: 0.04345  focal_loss 0.01501  dice_loss 0.02844 
Epoch [289/300] Validation metric {'Val/mean dice_metric': 0.9490753412246704, 'Val/mean miou_metric': 0.9178247451782227, 'Val/mean f1': 0.951678991317749, 'Val/mean precision': 0.9520142674446106, 'Val/mean recall': 0.9513439536094666, 'Val/mean hd95_metric': 10.555789947509766}
Cheakpoint...
Epoch [289/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9491], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9490753412246704, 'Val/mean miou_metric': 0.9178247451782227, 'Val/mean f1': 0.951678991317749, 'Val/mean precision': 0.9520142674446106, 'Val/mean recall': 0.9513439536094666, 'Val/mean hd95_metric': 10.555789947509766}
Epoch [290/300] Training [1/62] Loss: 0.03221 
Epoch [290/300] Training [2/62] Loss: 0.02930 
Epoch [290/300] Training [3/62] Loss: 0.02523 
Epoch [290/300] Training [4/62] Loss: 0.03051 
Epoch [290/300] Training [5/62] Loss: 0.03234 
Epoch [290/300] Training [6/62] Loss: 0.04221 
Epoch [290/300] Training [7/62] Loss: 0.02730 
Epoch [290/300] Training [8/62] Loss: 0.02353 
Epoch [290/300] Training [9/62] Loss: 0.02362 
Epoch [290/300] Training [10/62] Loss: 0.02847 
Epoch [290/300] Training [11/62] Loss: 0.03541 
Epoch [290/300] Training [12/62] Loss: 0.02251 
Epoch [290/300] Training [13/62] Loss: 0.02537 
Epoch [290/300] Training [14/62] Loss: 0.02508 
Epoch [290/300] Training [15/62] Loss: 0.02587 
Epoch [290/300] Training [16/62] Loss: 0.06964 
Epoch [290/300] Training [17/62] Loss: 0.03725 
Epoch [290/300] Training [18/62] Loss: 0.02598 
Epoch [290/300] Training [19/62] Loss: 0.14160 
Epoch [290/300] Training [20/62] Loss: 0.01919 
Epoch [290/300] Training [21/62] Loss: 0.02831 
Epoch [290/300] Training [22/62] Loss: 0.02687 
Epoch [290/300] Training [23/62] Loss: 0.02233 
Epoch [290/300] Training [24/62] Loss: 0.02776 
Epoch [290/300] Training [25/62] Loss: 0.02251 
Epoch [290/300] Training [26/62] Loss: 0.02957 
Epoch [290/300] Training [27/62] Loss: 0.02085 
Epoch [290/300] Training [28/62] Loss: 0.02506 
Epoch [290/300] Training [29/62] Loss: 0.02193 
Epoch [290/300] Training [30/62] Loss: 0.02326 
Epoch [290/300] Training [31/62] Loss: 0.03275 
Epoch [290/300] Training [32/62] Loss: 0.03272 
Epoch [290/300] Training [33/62] Loss: 0.02547 
Epoch [290/300] Training [34/62] Loss: 0.02942 
Epoch [290/300] Training [35/62] Loss: 0.02186 
Epoch [290/300] Training [36/62] Loss: 0.02024 
Epoch [290/300] Training [37/62] Loss: 0.03573 
Epoch [290/300] Training [38/62] Loss: 0.03369 
Epoch [290/300] Training [39/62] Loss: 0.02638 
Epoch [290/300] Training [40/62] Loss: 0.02936 
Epoch [290/300] Training [41/62] Loss: 0.02836 
Epoch [290/300] Training [42/62] Loss: 0.02487 
Epoch [290/300] Training [43/62] Loss: 0.02769 
Epoch [290/300] Training [44/62] Loss: 0.02485 
Epoch [290/300] Training [45/62] Loss: 0.03810 
Epoch [290/300] Training [46/62] Loss: 0.03327 
Epoch [290/300] Training [47/62] Loss: 0.02202 
Epoch [290/300] Training [48/62] Loss: 0.02357 
Epoch [290/300] Training [49/62] Loss: 0.02610 
Epoch [290/300] Training [50/62] Loss: 0.02878 
Epoch [290/300] Training [51/62] Loss: 0.02892 
Epoch [290/300] Training [52/62] Loss: 0.03749 
Epoch [290/300] Training [53/62] Loss: 0.02264 
Epoch [290/300] Training [54/62] Loss: 0.03386 
Epoch [290/300] Training [55/62] Loss: 0.02632 
Epoch [290/300] Training [56/62] Loss: 0.07686 
Epoch [290/300] Training [57/62] Loss: 0.02582 
Epoch [290/300] Training [58/62] Loss: 0.02615 
Epoch [290/300] Training [59/62] Loss: 0.02929 
Epoch [290/300] Training [60/62] Loss: 0.03136 
Epoch [290/300] Training [61/62] Loss: 0.03321 
Epoch [290/300] Training [62/62] Loss: 0.04833 
Epoch [290/300] Training metric {'Train/mean dice_metric': 0.9787707924842834, 'Train/mean miou_metric': 0.9602441787719727, 'Train/mean f1': 0.9774423241615295, 'Train/mean precision': 0.9728843569755554, 'Train/mean recall': 0.9820432066917419, 'Train/mean hd95_metric': 2.7964515686035156}
Epoch [290/300] Validation [1/16] Loss: 0.21668  focal_loss 0.11259  dice_loss 0.10409 
Epoch [290/300] Validation [2/16] Loss: 0.50288  focal_loss 0.25832  dice_loss 0.24456 
Epoch [290/300] Validation [3/16] Loss: 0.72265  focal_loss 0.44521  dice_loss 0.27744 
Epoch [290/300] Validation [4/16] Loss: 0.31936  focal_loss 0.17666  dice_loss 0.14270 
Epoch [290/300] Validation [5/16] Loss: 0.37544  focal_loss 0.14431  dice_loss 0.23113 
Epoch [290/300] Validation [6/16] Loss: 0.23449  focal_loss 0.07190  dice_loss 0.16259 
Epoch [290/300] Validation [7/16] Loss: 0.24906  focal_loss 0.12220  dice_loss 0.12686 
Epoch [290/300] Validation [8/16] Loss: 0.38309  focal_loss 0.13512  dice_loss 0.24797 
Epoch [290/300] Validation [9/16] Loss: 0.22458  focal_loss 0.12051  dice_loss 0.10407 
Epoch [290/300] Validation [10/16] Loss: 0.25135  focal_loss 0.10751  dice_loss 0.14384 
Epoch [290/300] Validation [11/16] Loss: 0.11814  focal_loss 0.04685  dice_loss 0.07129 
Epoch [290/300] Validation [12/16] Loss: 0.33373  focal_loss 0.08521  dice_loss 0.24852 
Epoch [290/300] Validation [13/16] Loss: 0.37849  focal_loss 0.17166  dice_loss 0.20683 
Epoch [290/300] Validation [14/16] Loss: 0.49838  focal_loss 0.20347  dice_loss 0.29491 
Epoch [290/300] Validation [15/16] Loss: 0.12546  focal_loss 0.05630  dice_loss 0.06916 
Epoch [290/300] Validation [16/16] Loss: 0.04451  focal_loss 0.01504  dice_loss 0.02947 
Epoch [290/300] Validation metric {'Val/mean dice_metric': 0.9485964179039001, 'Val/mean miou_metric': 0.9182674288749695, 'Val/mean f1': 0.9518185257911682, 'Val/mean precision': 0.9508971571922302, 'Val/mean recall': 0.9527416825294495, 'Val/mean hd95_metric': 10.07297134399414}
Cheakpoint...
Epoch [290/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9486], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9485964179039001, 'Val/mean miou_metric': 0.9182674288749695, 'Val/mean f1': 0.9518185257911682, 'Val/mean precision': 0.9508971571922302, 'Val/mean recall': 0.9527416825294495, 'Val/mean hd95_metric': 10.07297134399414}
Epoch [291/300] Training [1/62] Loss: 0.02256 
Epoch [291/300] Training [2/62] Loss: 0.03130 
Epoch [291/300] Training [3/62] Loss: 0.02161 
Epoch [291/300] Training [4/62] Loss: 0.03972 
Epoch [291/300] Training [5/62] Loss: 0.01826 
Epoch [291/300] Training [6/62] Loss: 0.02390 
Epoch [291/300] Training [7/62] Loss: 0.04317 
Epoch [291/300] Training [8/62] Loss: 0.03061 
Epoch [291/300] Training [9/62] Loss: 0.02413 
Epoch [291/300] Training [10/62] Loss: 0.02237 
Epoch [291/300] Training [11/62] Loss: 0.03174 
Epoch [291/300] Training [12/62] Loss: 0.05734 
Epoch [291/300] Training [13/62] Loss: 0.04143 
Epoch [291/300] Training [14/62] Loss: 0.02612 
Epoch [291/300] Training [15/62] Loss: 0.02700 
Epoch [291/300] Training [16/62] Loss: 0.02607 
Epoch [291/300] Training [17/62] Loss: 0.02959 
Epoch [291/300] Training [18/62] Loss: 0.01962 
Epoch [291/300] Training [19/62] Loss: 0.04957 
Epoch [291/300] Training [20/62] Loss: 0.02207 
Epoch [291/300] Training [21/62] Loss: 0.02423 
Epoch [291/300] Training [22/62] Loss: 0.02030 
Epoch [291/300] Training [23/62] Loss: 0.03395 
Epoch [291/300] Training [24/62] Loss: 0.02227 
Epoch [291/300] Training [25/62] Loss: 0.01901 
Epoch [291/300] Training [26/62] Loss: 0.02788 
Epoch [291/300] Training [27/62] Loss: 0.05993 
Epoch [291/300] Training [28/62] Loss: 0.02961 
Epoch [291/300] Training [29/62] Loss: 0.04147 
Epoch [291/300] Training [30/62] Loss: 0.02693 
Epoch [291/300] Training [31/62] Loss: 0.02811 
Epoch [291/300] Training [32/62] Loss: 0.03257 
Epoch [291/300] Training [33/62] Loss: 0.08608 
Epoch [291/300] Training [34/62] Loss: 0.03323 
Epoch [291/300] Training [35/62] Loss: 0.02422 
Epoch [291/300] Training [36/62] Loss: 0.02788 
Epoch [291/300] Training [37/62] Loss: 0.02505 
Epoch [291/300] Training [38/62] Loss: 0.03539 
Epoch [291/300] Training [39/62] Loss: 0.03195 
Epoch [291/300] Training [40/62] Loss: 0.03758 
Epoch [291/300] Training [41/62] Loss: 0.02138 
Epoch [291/300] Training [42/62] Loss: 0.03923 
Epoch [291/300] Training [43/62] Loss: 0.03682 
Epoch [291/300] Training [44/62] Loss: 0.04174 
Epoch [291/300] Training [45/62] Loss: 0.03457 
Epoch [291/300] Training [46/62] Loss: 0.04578 
Epoch [291/300] Training [47/62] Loss: 0.04365 
Epoch [291/300] Training [48/62] Loss: 0.03514 
Epoch [291/300] Training [49/62] Loss: 0.04004 
Epoch [291/300] Training [50/62] Loss: 0.03525 
Epoch [291/300] Training [51/62] Loss: 0.03426 
Epoch [291/300] Training [52/62] Loss: 0.02784 
Epoch [291/300] Training [53/62] Loss: 0.03038 
Epoch [291/300] Training [54/62] Loss: 0.03169 
Epoch [291/300] Training [55/62] Loss: 0.03451 
Epoch [291/300] Training [56/62] Loss: 0.02273 
Epoch [291/300] Training [57/62] Loss: 0.02898 
Epoch [291/300] Training [58/62] Loss: 0.01883 
Epoch [291/300] Training [59/62] Loss: 0.03686 
Epoch [291/300] Training [60/62] Loss: 0.02509 
Epoch [291/300] Training [61/62] Loss: 0.03272 
Epoch [291/300] Training [62/62] Loss: 0.02346 
Epoch [291/300] Training metric {'Train/mean dice_metric': 0.9780154228210449, 'Train/mean miou_metric': 0.9578011631965637, 'Train/mean f1': 0.977355420589447, 'Train/mean precision': 0.9726578593254089, 'Train/mean recall': 0.9820985794067383, 'Train/mean hd95_metric': 3.197845697402954}
Epoch [291/300] Validation [1/16] Loss: 0.25206  focal_loss 0.12557  dice_loss 0.12649 
Epoch [291/300] Validation [2/16] Loss: 0.49217  focal_loss 0.25411  dice_loss 0.23806 
Epoch [291/300] Validation [3/16] Loss: 0.38789  focal_loss 0.16866  dice_loss 0.21923 
Epoch [291/300] Validation [4/16] Loss: 0.34851  focal_loss 0.18633  dice_loss 0.16217 
Epoch [291/300] Validation [5/16] Loss: 0.33351  focal_loss 0.14284  dice_loss 0.19067 
Epoch [291/300] Validation [6/16] Loss: 0.22856  focal_loss 0.06508  dice_loss 0.16348 
Epoch [291/300] Validation [7/16] Loss: 0.30963  focal_loss 0.18094  dice_loss 0.12869 
Epoch [291/300] Validation [8/16] Loss: 0.33838  focal_loss 0.10080  dice_loss 0.23758 
Epoch [291/300] Validation [9/16] Loss: 0.17599  focal_loss 0.09035  dice_loss 0.08564 
Epoch [291/300] Validation [10/16] Loss: 0.22198  focal_loss 0.08690  dice_loss 0.13508 
Epoch [291/300] Validation [11/16] Loss: 0.11893  focal_loss 0.04759  dice_loss 0.07134 
Epoch [291/300] Validation [12/16] Loss: 0.36289  focal_loss 0.11699  dice_loss 0.24589 
Epoch [291/300] Validation [13/16] Loss: 0.39934  focal_loss 0.18700  dice_loss 0.21233 
Epoch [291/300] Validation [14/16] Loss: 0.43615  focal_loss 0.17339  dice_loss 0.26276 
Epoch [291/300] Validation [15/16] Loss: 0.11862  focal_loss 0.04976  dice_loss 0.06885 
Epoch [291/300] Validation [16/16] Loss: 0.11860  focal_loss 0.06400  dice_loss 0.05460 
Epoch [291/300] Validation metric {'Val/mean dice_metric': 0.949227511882782, 'Val/mean miou_metric': 0.9171448945999146, 'Val/mean f1': 0.9531908631324768, 'Val/mean precision': 0.9533863663673401, 'Val/mean recall': 0.9529953598976135, 'Val/mean hd95_metric': 10.579963684082031}
Cheakpoint...
Epoch [291/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9492], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.949227511882782, 'Val/mean miou_metric': 0.9171448945999146, 'Val/mean f1': 0.9531908631324768, 'Val/mean precision': 0.9533863663673401, 'Val/mean recall': 0.9529953598976135, 'Val/mean hd95_metric': 10.579963684082031}
Epoch [292/300] Training [1/62] Loss: 0.02520 
Epoch [292/300] Training [2/62] Loss: 0.03893 
Epoch [292/300] Training [3/62] Loss: 0.03782 
Epoch [292/300] Training [4/62] Loss: 0.03120 
Epoch [292/300] Training [5/62] Loss: 0.01975 
Epoch [292/300] Training [6/62] Loss: 0.02363 
Epoch [292/300] Training [7/62] Loss: 0.02574 
Epoch [292/300] Training [8/62] Loss: 0.02653 
Epoch [292/300] Training [9/62] Loss: 0.03082 
Epoch [292/300] Training [10/62] Loss: 0.02727 
Epoch [292/300] Training [11/62] Loss: 0.02679 
Epoch [292/300] Training [12/62] Loss: 0.03616 
Epoch [292/300] Training [13/62] Loss: 0.02126 
Epoch [292/300] Training [14/62] Loss: 0.02333 
Epoch [292/300] Training [15/62] Loss: 0.02984 
Epoch [292/300] Training [16/62] Loss: 0.02068 
Epoch [292/300] Training [17/62] Loss: 0.03478 
Epoch [292/300] Training [18/62] Loss: 0.02472 
Epoch [292/300] Training [19/62] Loss: 0.02099 
Epoch [292/300] Training [20/62] Loss: 0.02837 
Epoch [292/300] Training [21/62] Loss: 0.05700 
Epoch [292/300] Training [22/62] Loss: 0.02870 
Epoch [292/300] Training [23/62] Loss: 0.03348 
Epoch [292/300] Training [24/62] Loss: 0.02970 
Epoch [292/300] Training [25/62] Loss: 0.02895 
Epoch [292/300] Training [26/62] Loss: 0.02638 
Epoch [292/300] Training [27/62] Loss: 0.02353 
Epoch [292/300] Training [28/62] Loss: 0.02887 
Epoch [292/300] Training [29/62] Loss: 0.02370 
Epoch [292/300] Training [30/62] Loss: 0.02407 
Epoch [292/300] Training [31/62] Loss: 0.02616 
Epoch [292/300] Training [32/62] Loss: 0.02728 
Epoch [292/300] Training [33/62] Loss: 0.02929 
Epoch [292/300] Training [34/62] Loss: 0.04142 
Epoch [292/300] Training [35/62] Loss: 0.03174 
Epoch [292/300] Training [36/62] Loss: 0.03164 
Epoch [292/300] Training [37/62] Loss: 0.02531 
Epoch [292/300] Training [38/62] Loss: 0.02698 
Epoch [292/300] Training [39/62] Loss: 0.02734 
Epoch [292/300] Training [40/62] Loss: 0.02068 
Epoch [292/300] Training [41/62] Loss: 0.03381 
Epoch [292/300] Training [42/62] Loss: 0.03161 
Epoch [292/300] Training [43/62] Loss: 0.03513 
Epoch [292/300] Training [44/62] Loss: 0.02479 
Epoch [292/300] Training [45/62] Loss: 0.02177 
Epoch [292/300] Training [46/62] Loss: 0.02809 
Epoch [292/300] Training [47/62] Loss: 0.02889 
Epoch [292/300] Training [48/62] Loss: 0.02508 
Epoch [292/300] Training [49/62] Loss: 0.03042 
Epoch [292/300] Training [50/62] Loss: 0.03004 
Epoch [292/300] Training [51/62] Loss: 0.03377 
Epoch [292/300] Training [52/62] Loss: 0.02951 
Epoch [292/300] Training [53/62] Loss: 0.02386 
Epoch [292/300] Training [54/62] Loss: 0.02306 
Epoch [292/300] Training [55/62] Loss: 0.02282 
Epoch [292/300] Training [56/62] Loss: 0.03356 
Epoch [292/300] Training [57/62] Loss: 0.03724 
Epoch [292/300] Training [58/62] Loss: 0.02596 
Epoch [292/300] Training [59/62] Loss: 0.03320 
Epoch [292/300] Training [60/62] Loss: 0.05417 
Epoch [292/300] Training [61/62] Loss: 0.02338 
Epoch [292/300] Training [62/62] Loss: 0.03391 
Epoch [292/300] Training metric {'Train/mean dice_metric': 0.9806568622589111, 'Train/mean miou_metric': 0.9622640609741211, 'Train/mean f1': 0.9780681133270264, 'Train/mean precision': 0.9735766649246216, 'Train/mean recall': 0.98260098695755, 'Train/mean hd95_metric': 2.972410202026367}
Epoch [292/300] Validation [1/16] Loss: 0.55239  focal_loss 0.37050  dice_loss 0.18189 
Epoch [292/300] Validation [2/16] Loss: 0.51323  focal_loss 0.27024  dice_loss 0.24299 
Epoch [292/300] Validation [3/16] Loss: 0.46509  focal_loss 0.21478  dice_loss 0.25032 
Epoch [292/300] Validation [4/16] Loss: 0.31374  focal_loss 0.16997  dice_loss 0.14377 
Epoch [292/300] Validation [5/16] Loss: 0.35170  focal_loss 0.13954  dice_loss 0.21216 
Epoch [292/300] Validation [6/16] Loss: 0.22294  focal_loss 0.06877  dice_loss 0.15418 
Epoch [292/300] Validation [7/16] Loss: 0.31546  focal_loss 0.18385  dice_loss 0.13161 
Epoch [292/300] Validation [8/16] Loss: 0.46774  focal_loss 0.19301  dice_loss 0.27473 
Epoch [292/300] Validation [9/16] Loss: 0.22884  focal_loss 0.12008  dice_loss 0.10875 
Epoch [292/300] Validation [10/16] Loss: 0.25709  focal_loss 0.11677  dice_loss 0.14032 
Epoch [292/300] Validation [11/16] Loss: 0.13163  focal_loss 0.05105  dice_loss 0.08058 
Epoch [292/300] Validation [12/16] Loss: 0.37221  focal_loss 0.10656  dice_loss 0.26565 
Epoch [292/300] Validation [13/16] Loss: 0.37181  focal_loss 0.17107  dice_loss 0.20073 
Epoch [292/300] Validation [14/16] Loss: 0.50550  focal_loss 0.20847  dice_loss 0.29704 
Epoch [292/300] Validation [15/16] Loss: 0.11366  focal_loss 0.04732  dice_loss 0.06634 
Epoch [292/300] Validation [16/16] Loss: 0.04323  focal_loss 0.01485  dice_loss 0.02838 
Epoch [292/300] Validation metric {'Val/mean dice_metric': 0.9489149451255798, 'Val/mean miou_metric': 0.9186170697212219, 'Val/mean f1': 0.9512763619422913, 'Val/mean precision': 0.9520047903060913, 'Val/mean recall': 0.9505491852760315, 'Val/mean hd95_metric': 10.32264232635498}
Cheakpoint...
Epoch [292/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9489], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9489149451255798, 'Val/mean miou_metric': 0.9186170697212219, 'Val/mean f1': 0.9512763619422913, 'Val/mean precision': 0.9520047903060913, 'Val/mean recall': 0.9505491852760315, 'Val/mean hd95_metric': 10.32264232635498}
Epoch [293/300] Training [1/62] Loss: 0.02275 
Epoch [293/300] Training [2/62] Loss: 0.01878 
Epoch [293/300] Training [3/62] Loss: 0.05656 
Epoch [293/300] Training [4/62] Loss: 0.02223 
Epoch [293/300] Training [5/62] Loss: 0.04964 
Epoch [293/300] Training [6/62] Loss: 0.02664 
Epoch [293/300] Training [7/62] Loss: 0.02889 
Epoch [293/300] Training [8/62] Loss: 0.02627 
Epoch [293/300] Training [9/62] Loss: 0.02742 
Epoch [293/300] Training [10/62] Loss: 0.02745 
Epoch [293/300] Training [11/62] Loss: 0.02624 
Epoch [293/300] Training [12/62] Loss: 0.02763 
Epoch [293/300] Training [13/62] Loss: 0.02798 
Epoch [293/300] Training [14/62] Loss: 0.02887 
Epoch [293/300] Training [15/62] Loss: 0.02627 
Epoch [293/300] Training [16/62] Loss: 0.02760 
Epoch [293/300] Training [17/62] Loss: 0.02753 
Epoch [293/300] Training [18/62] Loss: 0.02958 
Epoch [293/300] Training [19/62] Loss: 0.03096 
Epoch [293/300] Training [20/62] Loss: 0.02632 
Epoch [293/300] Training [21/62] Loss: 0.02095 
Epoch [293/300] Training [22/62] Loss: 0.02935 
Epoch [293/300] Training [23/62] Loss: 0.03468 
Epoch [293/300] Training [24/62] Loss: 0.02378 
Epoch [293/300] Training [25/62] Loss: 0.02208 
Epoch [293/300] Training [26/62] Loss: 0.03111 
Epoch [293/300] Training [27/62] Loss: 0.01825 
Epoch [293/300] Training [28/62] Loss: 0.02696 
Epoch [293/300] Training [29/62] Loss: 0.02770 
Epoch [293/300] Training [30/62] Loss: 0.02667 
Epoch [293/300] Training [31/62] Loss: 0.01953 
Epoch [293/300] Training [32/62] Loss: 0.02103 
Epoch [293/300] Training [33/62] Loss: 0.01953 
Epoch [293/300] Training [34/62] Loss: 0.02202 
Epoch [293/300] Training [35/62] Loss: 0.03333 
Epoch [293/300] Training [36/62] Loss: 0.02459 
Epoch [293/300] Training [37/62] Loss: 0.05919 
Epoch [293/300] Training [38/62] Loss: 0.04160 
Epoch [293/300] Training [39/62] Loss: 0.02539 
Epoch [293/300] Training [40/62] Loss: 0.05091 
Epoch [293/300] Training [41/62] Loss: 0.02664 
Epoch [293/300] Training [42/62] Loss: 0.05157 
Epoch [293/300] Training [43/62] Loss: 0.02307 
Epoch [293/300] Training [44/62] Loss: 0.02432 
Epoch [293/300] Training [45/62] Loss: 0.02470 
Epoch [293/300] Training [46/62] Loss: 0.02580 
Epoch [293/300] Training [47/62] Loss: 0.02477 
Epoch [293/300] Training [48/62] Loss: 0.02944 
Epoch [293/300] Training [49/62] Loss: 0.04112 
Epoch [293/300] Training [50/62] Loss: 0.02438 
Epoch [293/300] Training [51/62] Loss: 0.03321 
Epoch [293/300] Training [52/62] Loss: 0.02191 
Epoch [293/300] Training [53/62] Loss: 0.02440 
Epoch [293/300] Training [54/62] Loss: 0.02749 
Epoch [293/300] Training [55/62] Loss: 0.02719 
Epoch [293/300] Training [56/62] Loss: 0.03294 
Epoch [293/300] Training [57/62] Loss: 0.02458 
Epoch [293/300] Training [58/62] Loss: 0.02806 
Epoch [293/300] Training [59/62] Loss: 0.03041 
Epoch [293/300] Training [60/62] Loss: 0.03184 
Epoch [293/300] Training [61/62] Loss: 0.03422 
Epoch [293/300] Training [62/62] Loss: 0.04371 
Epoch [293/300] Training metric {'Train/mean dice_metric': 0.9805830717086792, 'Train/mean miou_metric': 0.9622891545295715, 'Train/mean f1': 0.9783855676651001, 'Train/mean precision': 0.9741261601448059, 'Train/mean recall': 0.9826824069023132, 'Train/mean hd95_metric': 2.6598358154296875}
Epoch [293/300] Validation [1/16] Loss: 0.31263  focal_loss 0.16406  dice_loss 0.14857 
Epoch [293/300] Validation [2/16] Loss: 0.52226  focal_loss 0.27392  dice_loss 0.24833 
Epoch [293/300] Validation [3/16] Loss: 0.68883  focal_loss 0.43221  dice_loss 0.25662 
Epoch [293/300] Validation [4/16] Loss: 0.31864  focal_loss 0.17415  dice_loss 0.14449 
Epoch [293/300] Validation [5/16] Loss: 0.42832  focal_loss 0.19650  dice_loss 0.23182 
Epoch [293/300] Validation [6/16] Loss: 0.28829  focal_loss 0.08463  dice_loss 0.20366 
Epoch [293/300] Validation [7/16] Loss: 0.31429  focal_loss 0.18337  dice_loss 0.13092 
Epoch [293/300] Validation [8/16] Loss: 0.38404  focal_loss 0.14326  dice_loss 0.24078 
Epoch [293/300] Validation [9/16] Loss: 0.22859  focal_loss 0.12515  dice_loss 0.10344 
Epoch [293/300] Validation [10/16] Loss: 0.56633  focal_loss 0.24757  dice_loss 0.31876 
Epoch [293/300] Validation [11/16] Loss: 0.15463  focal_loss 0.06085  dice_loss 0.09378 
Epoch [293/300] Validation [12/16] Loss: 0.33786  focal_loss 0.09470  dice_loss 0.24315 
Epoch [293/300] Validation [13/16] Loss: 0.25375  focal_loss 0.10218  dice_loss 0.15156 
Epoch [293/300] Validation [14/16] Loss: 0.49478  focal_loss 0.18876  dice_loss 0.30602 
Epoch [293/300] Validation [15/16] Loss: 0.15556  focal_loss 0.07550  dice_loss 0.08006 
Epoch [293/300] Validation [16/16] Loss: 0.04456  focal_loss 0.01509  dice_loss 0.02947 
Epoch [293/300] Validation metric {'Val/mean dice_metric': 0.9468505382537842, 'Val/mean miou_metric': 0.9160661101341248, 'Val/mean f1': 0.9509192705154419, 'Val/mean precision': 0.9509243369102478, 'Val/mean recall': 0.9509141445159912, 'Val/mean hd95_metric': 10.160862922668457}
Cheakpoint...
Epoch [293/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9469], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9468505382537842, 'Val/mean miou_metric': 0.9160661101341248, 'Val/mean f1': 0.9509192705154419, 'Val/mean precision': 0.9509243369102478, 'Val/mean recall': 0.9509141445159912, 'Val/mean hd95_metric': 10.160862922668457}
Epoch [294/300] Training [1/62] Loss: 0.05646 
Epoch [294/300] Training [2/62] Loss: 0.02444 
Epoch [294/300] Training [3/62] Loss: 0.09439 
Epoch [294/300] Training [4/62] Loss: 0.03452 
Epoch [294/300] Training [5/62] Loss: 0.02967 
Epoch [294/300] Training [6/62] Loss: 0.03254 
Epoch [294/300] Training [7/62] Loss: 0.03266 
Epoch [294/300] Training [8/62] Loss: 0.03219 
Epoch [294/300] Training [9/62] Loss: 0.02266 
Epoch [294/300] Training [10/62] Loss: 0.02441 
Epoch [294/300] Training [11/62] Loss: 0.02586 
Epoch [294/300] Training [12/62] Loss: 0.03127 
Epoch [294/300] Training [13/62] Loss: 0.03171 
Epoch [294/300] Training [14/62] Loss: 0.02935 
Epoch [294/300] Training [15/62] Loss: 0.03785 
Epoch [294/300] Training [16/62] Loss: 0.05585 
Epoch [294/300] Training [17/62] Loss: 0.02793 
Epoch [294/300] Training [18/62] Loss: 0.02141 
Epoch [294/300] Training [19/62] Loss: 0.03154 
Epoch [294/300] Training [20/62] Loss: 0.04302 
Epoch [294/300] Training [21/62] Loss: 0.04438 
Epoch [294/300] Training [22/62] Loss: 0.02205 
Epoch [294/300] Training [23/62] Loss: 0.03037 
Epoch [294/300] Training [24/62] Loss: 0.01851 
Epoch [294/300] Training [25/62] Loss: 0.03434 
Epoch [294/300] Training [26/62] Loss: 0.02844 
Epoch [294/300] Training [27/62] Loss: 0.03362 
Epoch [294/300] Training [28/62] Loss: 0.02469 
Epoch [294/300] Training [29/62] Loss: 0.02882 
Epoch [294/300] Training [30/62] Loss: 0.02478 
Epoch [294/300] Training [31/62] Loss: 0.02432 
Epoch [294/300] Training [32/62] Loss: 0.01968 
Epoch [294/300] Training [33/62] Loss: 0.02372 
Epoch [294/300] Training [34/62] Loss: 0.03083 
Epoch [294/300] Training [35/62] Loss: 0.03204 
Epoch [294/300] Training [36/62] Loss: 0.04032 
Epoch [294/300] Training [37/62] Loss: 0.02369 
Epoch [294/300] Training [38/62] Loss: 0.02083 
Epoch [294/300] Training [39/62] Loss: 0.02988 
Epoch [294/300] Training [40/62] Loss: 0.02747 
Epoch [294/300] Training [41/62] Loss: 0.03089 
Epoch [294/300] Training [42/62] Loss: 0.02870 
Epoch [294/300] Training [43/62] Loss: 0.02410 
Epoch [294/300] Training [44/62] Loss: 0.03003 
Epoch [294/300] Training [45/62] Loss: 0.02160 
Epoch [294/300] Training [46/62] Loss: 0.02618 
Epoch [294/300] Training [47/62] Loss: 0.02733 
Epoch [294/300] Training [48/62] Loss: 0.02111 
Epoch [294/300] Training [49/62] Loss: 0.02300 
Epoch [294/300] Training [50/62] Loss: 0.03300 
Epoch [294/300] Training [51/62] Loss: 0.03493 
Epoch [294/300] Training [52/62] Loss: 0.03386 
Epoch [294/300] Training [53/62] Loss: 0.03265 
Epoch [294/300] Training [54/62] Loss: 0.03311 
Epoch [294/300] Training [55/62] Loss: 0.03199 
Epoch [294/300] Training [56/62] Loss: 0.03776 
Epoch [294/300] Training [57/62] Loss: 0.02652 
Epoch [294/300] Training [58/62] Loss: 0.02387 
Epoch [294/300] Training [59/62] Loss: 0.02076 
Epoch [294/300] Training [60/62] Loss: 0.03602 
Epoch [294/300] Training [61/62] Loss: 0.02122 
Epoch [294/300] Training [62/62] Loss: 0.01671 
Epoch [294/300] Training metric {'Train/mean dice_metric': 0.9793969988822937, 'Train/mean miou_metric': 0.9604752659797668, 'Train/mean f1': 0.9775931239128113, 'Train/mean precision': 0.9733037948608398, 'Train/mean recall': 0.9819203019142151, 'Train/mean hd95_metric': 3.1204097270965576}
Epoch [294/300] Validation [1/16] Loss: 0.22134  focal_loss 0.11610  dice_loss 0.10524 
Epoch [294/300] Validation [2/16] Loss: 0.46716  focal_loss 0.24803  dice_loss 0.21912 
Epoch [294/300] Validation [3/16] Loss: 0.68555  focal_loss 0.42872  dice_loss 0.25682 
Epoch [294/300] Validation [4/16] Loss: 0.27538  focal_loss 0.12929  dice_loss 0.14610 
Epoch [294/300] Validation [5/16] Loss: 0.36664  focal_loss 0.15575  dice_loss 0.21090 
Epoch [294/300] Validation [6/16] Loss: 0.28673  focal_loss 0.08172  dice_loss 0.20502 
Epoch [294/300] Validation [7/16] Loss: 0.17785  focal_loss 0.07893  dice_loss 0.09892 
Epoch [294/300] Validation [8/16] Loss: 0.32742  focal_loss 0.10307  dice_loss 0.22435 
Epoch [294/300] Validation [9/16] Loss: 0.24891  focal_loss 0.11313  dice_loss 0.13577 
Epoch [294/300] Validation [10/16] Loss: 0.25575  focal_loss 0.11541  dice_loss 0.14034 
Epoch [294/300] Validation [11/16] Loss: 0.11043  focal_loss 0.04786  dice_loss 0.06257 
Epoch [294/300] Validation [12/16] Loss: 0.34460  focal_loss 0.09723  dice_loss 0.24737 
Epoch [294/300] Validation [13/16] Loss: 0.36293  focal_loss 0.16640  dice_loss 0.19652 
Epoch [294/300] Validation [14/16] Loss: 0.54232  focal_loss 0.22191  dice_loss 0.32041 
Epoch [294/300] Validation [15/16] Loss: 0.14579  focal_loss 0.06470  dice_loss 0.08109 
Epoch [294/300] Validation [16/16] Loss: 0.04361  focal_loss 0.01511  dice_loss 0.02849 
Epoch [294/300] Validation metric {'Val/mean dice_metric': 0.9492781162261963, 'Val/mean miou_metric': 0.9180942177772522, 'Val/mean f1': 0.9524040818214417, 'Val/mean precision': 0.950442910194397, 'Val/mean recall': 0.9543731212615967, 'Val/mean hd95_metric': 10.530754089355469}
Cheakpoint...
Epoch [294/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9493], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9492781162261963, 'Val/mean miou_metric': 0.9180942177772522, 'Val/mean f1': 0.9524040818214417, 'Val/mean precision': 0.950442910194397, 'Val/mean recall': 0.9543731212615967, 'Val/mean hd95_metric': 10.530754089355469}
Epoch [295/300] Training [1/62] Loss: 0.04062 
Epoch [295/300] Training [2/62] Loss: 0.02923 
Epoch [295/300] Training [3/62] Loss: 0.02802 
Epoch [295/300] Training [4/62] Loss: 0.02564 
Epoch [295/300] Training [5/62] Loss: 0.02902 
Epoch [295/300] Training [6/62] Loss: 0.04554 
Epoch [295/300] Training [7/62] Loss: 0.03010 
Epoch [295/300] Training [8/62] Loss: 0.03850 
Epoch [295/300] Training [9/62] Loss: 0.02728 
Epoch [295/300] Training [10/62] Loss: 0.03273 
Epoch [295/300] Training [11/62] Loss: 0.13891 
Epoch [295/300] Training [12/62] Loss: 0.03113 
Epoch [295/300] Training [13/62] Loss: 0.02124 
Epoch [295/300] Training [14/62] Loss: 0.03046 
Epoch [295/300] Training [15/62] Loss: 0.02111 
Epoch [295/300] Training [16/62] Loss: 0.03415 
Epoch [295/300] Training [17/62] Loss: 0.03187 
Epoch [295/300] Training [18/62] Loss: 0.03010 
Epoch [295/300] Training [19/62] Loss: 0.03120 
Epoch [295/300] Training [20/62] Loss: 0.02809 
Epoch [295/300] Training [21/62] Loss: 0.03432 
Epoch [295/300] Training [22/62] Loss: 0.02243 
Epoch [295/300] Training [23/62] Loss: 0.03063 
Epoch [295/300] Training [24/62] Loss: 0.03058 
Epoch [295/300] Training [25/62] Loss: 0.02320 
Epoch [295/300] Training [26/62] Loss: 0.02293 
Epoch [295/300] Training [27/62] Loss: 0.02185 
Epoch [295/300] Training [28/62] Loss: 0.02200 
Epoch [295/300] Training [29/62] Loss: 0.02306 
Epoch [295/300] Training [30/62] Loss: 0.02455 
Epoch [295/300] Training [31/62] Loss: 0.02502 
Epoch [295/300] Training [32/62] Loss: 0.02646 
Epoch [295/300] Training [33/62] Loss: 0.03367 
Epoch [295/300] Training [34/62] Loss: 0.04151 
Epoch [295/300] Training [35/62] Loss: 0.03972 
Epoch [295/300] Training [36/62] Loss: 0.02402 
Epoch [295/300] Training [37/62] Loss: 0.02563 
Epoch [295/300] Training [38/62] Loss: 0.02185 
Epoch [295/300] Training [39/62] Loss: 0.04162 
Epoch [295/300] Training [40/62] Loss: 0.02539 
Epoch [295/300] Training [41/62] Loss: 0.02821 
Epoch [295/300] Training [42/62] Loss: 0.04149 
Epoch [295/300] Training [43/62] Loss: 0.02434 
Epoch [295/300] Training [44/62] Loss: 0.03677 
Epoch [295/300] Training [45/62] Loss: 0.03193 
Epoch [295/300] Training [46/62] Loss: 0.03461 
Epoch [295/300] Training [47/62] Loss: 0.02717 
Epoch [295/300] Training [48/62] Loss: 0.03063 
Epoch [295/300] Training [49/62] Loss: 0.03021 
Epoch [295/300] Training [50/62] Loss: 0.03235 
Epoch [295/300] Training [51/62] Loss: 0.05189 
Epoch [295/300] Training [52/62] Loss: 0.02725 
Epoch [295/300] Training [53/62] Loss: 0.02909 
Epoch [295/300] Training [54/62] Loss: 0.02999 
Epoch [295/300] Training [55/62] Loss: 0.03230 
Epoch [295/300] Training [56/62] Loss: 0.02661 
Epoch [295/300] Training [57/62] Loss: 0.02785 
Epoch [295/300] Training [58/62] Loss: 0.05338 
Epoch [295/300] Training [59/62] Loss: 0.02294 
Epoch [295/300] Training [60/62] Loss: 0.02628 
Epoch [295/300] Training [61/62] Loss: 0.03003 
Epoch [295/300] Training [62/62] Loss: 0.01560 
Epoch [295/300] Training metric {'Train/mean dice_metric': 0.9783544540405273, 'Train/mean miou_metric': 0.9590858221054077, 'Train/mean f1': 0.9770802855491638, 'Train/mean precision': 0.9725282788276672, 'Train/mean recall': 0.9816750288009644, 'Train/mean hd95_metric': 2.8698036670684814}
Epoch [295/300] Validation [1/16] Loss: 0.22025  focal_loss 0.11533  dice_loss 0.10492 
Epoch [295/300] Validation [2/16] Loss: 0.49362  focal_loss 0.25630  dice_loss 0.23732 
Epoch [295/300] Validation [3/16] Loss: 0.71764  focal_loss 0.43552  dice_loss 0.28212 
Epoch [295/300] Validation [4/16] Loss: 0.31710  focal_loss 0.17632  dice_loss 0.14079 
Epoch [295/300] Validation [5/16] Loss: 0.31588  focal_loss 0.12902  dice_loss 0.18686 
Epoch [295/300] Validation [6/16] Loss: 0.27334  focal_loss 0.07217  dice_loss 0.20117 
Epoch [295/300] Validation [7/16] Loss: 0.16626  focal_loss 0.07140  dice_loss 0.09486 
Epoch [295/300] Validation [8/16] Loss: 0.33607  focal_loss 0.12342  dice_loss 0.21265 
Epoch [295/300] Validation [9/16] Loss: 0.19241  focal_loss 0.09903  dice_loss 0.09338 
Epoch [295/300] Validation [10/16] Loss: 0.22319  focal_loss 0.08607  dice_loss 0.13713 
Epoch [295/300] Validation [11/16] Loss: 0.11257  focal_loss 0.04585  dice_loss 0.06672 
Epoch [295/300] Validation [12/16] Loss: 0.34159  focal_loss 0.09191  dice_loss 0.24968 
Epoch [295/300] Validation [13/16] Loss: 0.40049  focal_loss 0.18692  dice_loss 0.21358 
Epoch [295/300] Validation [14/16] Loss: 0.48035  focal_loss 0.19053  dice_loss 0.28982 
Epoch [295/300] Validation [15/16] Loss: 0.27532  focal_loss 0.11954  dice_loss 0.15577 
Epoch [295/300] Validation [16/16] Loss: 0.04442  focal_loss 0.01497  dice_loss 0.02946 
Epoch [295/300] Validation metric {'Val/mean dice_metric': 0.9482542276382446, 'Val/mean miou_metric': 0.9170619249343872, 'Val/mean f1': 0.9516445994377136, 'Val/mean precision': 0.9505840539932251, 'Val/mean recall': 0.9527075290679932, 'Val/mean hd95_metric': 10.432316780090332}
Cheakpoint...
Epoch [295/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9483], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9482542276382446, 'Val/mean miou_metric': 0.9170619249343872, 'Val/mean f1': 0.9516445994377136, 'Val/mean precision': 0.9505840539932251, 'Val/mean recall': 0.9527075290679932, 'Val/mean hd95_metric': 10.432316780090332}
Epoch [296/300] Training [1/62] Loss: 0.02622 
Epoch [296/300] Training [2/62] Loss: 0.03362 
Epoch [296/300] Training [3/62] Loss: 0.02124 
Epoch [296/300] Training [4/62] Loss: 0.02432 
Epoch [296/300] Training [5/62] Loss: 0.01810 
Epoch [296/300] Training [6/62] Loss: 0.02847 
Epoch [296/300] Training [7/62] Loss: 0.02335 
Epoch [296/300] Training [8/62] Loss: 0.03899 
Epoch [296/300] Training [9/62] Loss: 0.02699 
Epoch [296/300] Training [10/62] Loss: 0.04192 
Epoch [296/300] Training [11/62] Loss: 0.02065 
Epoch [296/300] Training [12/62] Loss: 0.03520 
Epoch [296/300] Training [13/62] Loss: 0.04071 
Epoch [296/300] Training [14/62] Loss: 0.03895 
Epoch [296/300] Training [15/62] Loss: 0.02634 
Epoch [296/300] Training [16/62] Loss: 0.02207 
Epoch [296/300] Training [17/62] Loss: 0.03109 
Epoch [296/300] Training [18/62] Loss: 0.02209 
Epoch [296/300] Training [19/62] Loss: 0.02016 
Epoch [296/300] Training [20/62] Loss: 0.02222 
Epoch [296/300] Training [21/62] Loss: 0.02998 
Epoch [296/300] Training [22/62] Loss: 0.03425 
Epoch [296/300] Training [23/62] Loss: 0.01926 
Epoch [296/300] Training [24/62] Loss: 0.02209 
Epoch [296/300] Training [25/62] Loss: 0.02430 
Epoch [296/300] Training [26/62] Loss: 0.03020 
Epoch [296/300] Training [27/62] Loss: 0.03614 
Epoch [296/300] Training [28/62] Loss: 0.02654 
Epoch [296/300] Training [29/62] Loss: 0.02576 
Epoch [296/300] Training [30/62] Loss: 0.04939 
Epoch [296/300] Training [31/62] Loss: 0.03068 
Epoch [296/300] Training [32/62] Loss: 0.02266 
Epoch [296/300] Training [33/62] Loss: 0.02008 
Epoch [296/300] Training [34/62] Loss: 0.02207 
Epoch [296/300] Training [35/62] Loss: 0.02292 
Epoch [296/300] Training [36/62] Loss: 0.04005 
Epoch [296/300] Training [37/62] Loss: 0.03220 
Epoch [296/300] Training [38/62] Loss: 0.02716 
Epoch [296/300] Training [39/62] Loss: 0.02543 
Epoch [296/300] Training [40/62] Loss: 0.04147 
Epoch [296/300] Training [41/62] Loss: 0.02665 
Epoch [296/300] Training [42/62] Loss: 0.02771 
Epoch [296/300] Training [43/62] Loss: 0.03318 
Epoch [296/300] Training [44/62] Loss: 0.03379 
Epoch [296/300] Training [45/62] Loss: 0.02449 
Epoch [296/300] Training [46/62] Loss: 0.02814 
Epoch [296/300] Training [47/62] Loss: 0.03057 
Epoch [296/300] Training [48/62] Loss: 0.12827 
Epoch [296/300] Training [49/62] Loss: 0.02986 
Epoch [296/300] Training [50/62] Loss: 0.02140 
Epoch [296/300] Training [51/62] Loss: 0.02802 
Epoch [296/300] Training [52/62] Loss: 0.02440 
Epoch [296/300] Training [53/62] Loss: 0.02782 
Epoch [296/300] Training [54/62] Loss: 0.02456 
Epoch [296/300] Training [55/62] Loss: 0.03017 
Epoch [296/300] Training [56/62] Loss: 0.02398 
Epoch [296/300] Training [57/62] Loss: 0.03895 
Epoch [296/300] Training [58/62] Loss: 0.02607 
Epoch [296/300] Training [59/62] Loss: 0.02610 
Epoch [296/300] Training [60/62] Loss: 0.04022 
Epoch [296/300] Training [61/62] Loss: 0.03934 
Epoch [296/300] Training [62/62] Loss: 0.01783 
Epoch [296/300] Training metric {'Train/mean dice_metric': 0.9795617461204529, 'Train/mean miou_metric': 0.9611745476722717, 'Train/mean f1': 0.9776408076286316, 'Train/mean precision': 0.9725368022918701, 'Train/mean recall': 0.9827985763549805, 'Train/mean hd95_metric': 2.8309168815612793}
Epoch [296/300] Validation [1/16] Loss: 0.21716  focal_loss 0.11218  dice_loss 0.10498 
Epoch [296/300] Validation [2/16] Loss: 0.43264  focal_loss 0.19902  dice_loss 0.23362 
Epoch [296/300] Validation [3/16] Loss: 0.72022  focal_loss 0.43819  dice_loss 0.28203 
Epoch [296/300] Validation [4/16] Loss: 0.31951  focal_loss 0.17292  dice_loss 0.14659 
Epoch [296/300] Validation [5/16] Loss: 0.29121  focal_loss 0.09558  dice_loss 0.19563 
Epoch [296/300] Validation [6/16] Loss: 0.19290  focal_loss 0.06217  dice_loss 0.13073 
Epoch [296/300] Validation [7/16] Loss: 0.15991  focal_loss 0.07200  dice_loss 0.08791 
Epoch [296/300] Validation [8/16] Loss: 0.33952  focal_loss 0.13228  dice_loss 0.20723 
Epoch [296/300] Validation [9/16] Loss: 0.18191  focal_loss 0.09041  dice_loss 0.09150 
Epoch [296/300] Validation [10/16] Loss: 0.39498  focal_loss 0.17764  dice_loss 0.21734 
Epoch [296/300] Validation [11/16] Loss: 0.11086  focal_loss 0.04661  dice_loss 0.06425 
Epoch [296/300] Validation [12/16] Loss: 0.37265  focal_loss 0.10685  dice_loss 0.26579 
Epoch [296/300] Validation [13/16] Loss: 0.20394  focal_loss 0.07993  dice_loss 0.12402 
Epoch [296/300] Validation [14/16] Loss: 0.48787  focal_loss 0.20271  dice_loss 0.28516 
Epoch [296/300] Validation [15/16] Loss: 0.27373  focal_loss 0.12321  dice_loss 0.15052 
Epoch [296/300] Validation [16/16] Loss: 0.04343  focal_loss 0.01499  dice_loss 0.02844 
Epoch [296/300] Validation metric {'Val/mean dice_metric': 0.9501820206642151, 'Val/mean miou_metric': 0.9197683930397034, 'Val/mean f1': 0.9525774717330933, 'Val/mean precision': 0.9504593014717102, 'Val/mean recall': 0.9547049403190613, 'Val/mean hd95_metric': 9.672382354736328}
Cheakpoint...
Epoch [296/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9502], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9501820206642151, 'Val/mean miou_metric': 0.9197683930397034, 'Val/mean f1': 0.9525774717330933, 'Val/mean precision': 0.9504593014717102, 'Val/mean recall': 0.9547049403190613, 'Val/mean hd95_metric': 9.672382354736328}
Epoch [297/300] Training [1/62] Loss: 0.02821 
Epoch [297/300] Training [2/62] Loss: 0.02723 
Epoch [297/300] Training [3/62] Loss: 0.02362 
Epoch [297/300] Training [4/62] Loss: 0.02557 
Epoch [297/300] Training [5/62] Loss: 0.03869 
Epoch [297/300] Training [6/62] Loss: 0.03470 
Epoch [297/300] Training [7/62] Loss: 0.02011 
Epoch [297/300] Training [8/62] Loss: 0.02577 
Epoch [297/300] Training [9/62] Loss: 0.02838 
Epoch [297/300] Training [10/62] Loss: 0.02856 
Epoch [297/300] Training [11/62] Loss: 0.02241 
Epoch [297/300] Training [12/62] Loss: 0.03678 
Epoch [297/300] Training [13/62] Loss: 0.02092 
Epoch [297/300] Training [14/62] Loss: 0.03553 
Epoch [297/300] Training [15/62] Loss: 0.02158 
Epoch [297/300] Training [16/62] Loss: 0.04135 
Epoch [297/300] Training [17/62] Loss: 0.03318 
Epoch [297/300] Training [18/62] Loss: 0.02452 
Epoch [297/300] Training [19/62] Loss: 0.02474 
Epoch [297/300] Training [20/62] Loss: 0.02425 
Epoch [297/300] Training [21/62] Loss: 0.02499 
Epoch [297/300] Training [22/62] Loss: 0.02429 
Epoch [297/300] Training [23/62] Loss: 0.03471 
Epoch [297/300] Training [24/62] Loss: 0.03205 
Epoch [297/300] Training [25/62] Loss: 0.03407 
Epoch [297/300] Training [26/62] Loss: 0.02057 
Epoch [297/300] Training [27/62] Loss: 0.03303 
Epoch [297/300] Training [28/62] Loss: 0.02981 
Epoch [297/300] Training [29/62] Loss: 0.03167 
Epoch [297/300] Training [30/62] Loss: 0.02414 
Epoch [297/300] Training [31/62] Loss: 0.03169 
Epoch [297/300] Training [32/62] Loss: 0.02654 
Epoch [297/300] Training [33/62] Loss: 0.02185 
Epoch [297/300] Training [34/62] Loss: 0.02391 
Epoch [297/300] Training [35/62] Loss: 0.03189 
Epoch [297/300] Training [36/62] Loss: 0.03562 
Epoch [297/300] Training [37/62] Loss: 0.03843 
Epoch [297/300] Training [38/62] Loss: 0.02802 
Epoch [297/300] Training [39/62] Loss: 0.02255 
Epoch [297/300] Training [40/62] Loss: 0.03556 
Epoch [297/300] Training [41/62] Loss: 0.03681 
Epoch [297/300] Training [42/62] Loss: 0.03682 
Epoch [297/300] Training [43/62] Loss: 0.02966 
Epoch [297/300] Training [44/62] Loss: 0.02125 
Epoch [297/300] Training [45/62] Loss: 0.03150 
Epoch [297/300] Training [46/62] Loss: 0.02528 
Epoch [297/300] Training [47/62] Loss: 0.03164 
Epoch [297/300] Training [48/62] Loss: 0.02403 
Epoch [297/300] Training [49/62] Loss: 0.05618 
Epoch [297/300] Training [50/62] Loss: 0.03274 
Epoch [297/300] Training [51/62] Loss: 0.02782 
Epoch [297/300] Training [52/62] Loss: 0.03224 
Epoch [297/300] Training [53/62] Loss: 0.02330 
Epoch [297/300] Training [54/62] Loss: 0.08964 
Epoch [297/300] Training [55/62] Loss: 0.05716 
Epoch [297/300] Training [56/62] Loss: 0.02492 
Epoch [297/300] Training [57/62] Loss: 0.02114 
Epoch [297/300] Training [58/62] Loss: 0.02928 
Epoch [297/300] Training [59/62] Loss: 0.02650 
Epoch [297/300] Training [60/62] Loss: 0.03176 
Epoch [297/300] Training [61/62] Loss: 0.02338 
Epoch [297/300] Training [62/62] Loss: 0.01621 
Epoch [297/300] Training metric {'Train/mean dice_metric': 0.9798413515090942, 'Train/mean miou_metric': 0.9608649611473083, 'Train/mean f1': 0.9764329195022583, 'Train/mean precision': 0.9731199145317078, 'Train/mean recall': 0.9797686338424683, 'Train/mean hd95_metric': 3.1694109439849854}
Epoch [297/300] Validation [1/16] Loss: 0.26587  focal_loss 0.13325  dice_loss 0.13262 
Epoch [297/300] Validation [2/16] Loss: 0.43140  focal_loss 0.24767  dice_loss 0.18373 
Epoch [297/300] Validation [3/16] Loss: 0.71557  focal_loss 0.43316  dice_loss 0.28241 
Epoch [297/300] Validation [4/16] Loss: 0.31822  focal_loss 0.17437  dice_loss 0.14385 
Epoch [297/300] Validation [5/16] Loss: 0.35990  focal_loss 0.15298  dice_loss 0.20693 
Epoch [297/300] Validation [6/16] Loss: 0.25063  focal_loss 0.08018  dice_loss 0.17045 
Epoch [297/300] Validation [7/16] Loss: 0.27827  focal_loss 0.16014  dice_loss 0.11813 
Epoch [297/300] Validation [8/16] Loss: 0.40772  focal_loss 0.14679  dice_loss 0.26093 
Epoch [297/300] Validation [9/16] Loss: 0.17014  focal_loss 0.08926  dice_loss 0.08088 
Epoch [297/300] Validation [10/16] Loss: 0.21917  focal_loss 0.08476  dice_loss 0.13441 
Epoch [297/300] Validation [11/16] Loss: 0.12025  focal_loss 0.05113  dice_loss 0.06912 
Epoch [297/300] Validation [12/16] Loss: 0.37880  focal_loss 0.10928  dice_loss 0.26951 
Epoch [297/300] Validation [13/16] Loss: 0.40189  focal_loss 0.17927  dice_loss 0.22262 
Epoch [297/300] Validation [14/16] Loss: 0.46343  focal_loss 0.17917  dice_loss 0.28426 
Epoch [297/300] Validation [15/16] Loss: 0.13104  focal_loss 0.05917  dice_loss 0.07188 
Epoch [297/300] Validation [16/16] Loss: 0.05702  focal_loss 0.02315  dice_loss 0.03387 
Epoch [297/300] Validation metric {'Val/mean dice_metric': 0.9499274492263794, 'Val/mean miou_metric': 0.9187695980072021, 'Val/mean f1': 0.9516744017601013, 'Val/mean precision': 0.9531895518302917, 'Val/mean recall': 0.9501640200614929, 'Val/mean hd95_metric': 10.570466995239258}
Cheakpoint...
Epoch [297/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9499], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9499274492263794, 'Val/mean miou_metric': 0.9187695980072021, 'Val/mean f1': 0.9516744017601013, 'Val/mean precision': 0.9531895518302917, 'Val/mean recall': 0.9501640200614929, 'Val/mean hd95_metric': 10.570466995239258}
Epoch [298/300] Training [1/62] Loss: 0.02069 
Epoch [298/300] Training [2/62] Loss: 0.02747 
Epoch [298/300] Training [3/62] Loss: 0.03247 
Epoch [298/300] Training [4/62] Loss: 0.02628 
Epoch [298/300] Training [5/62] Loss: 0.02818 
Epoch [298/300] Training [6/62] Loss: 0.02833 
Epoch [298/300] Training [7/62] Loss: 0.03000 
Epoch [298/300] Training [8/62] Loss: 0.02097 
Epoch [298/300] Training [9/62] Loss: 0.02235 
Epoch [298/300] Training [10/62] Loss: 0.02912 
Epoch [298/300] Training [11/62] Loss: 0.09801 
Epoch [298/300] Training [12/62] Loss: 0.02491 
Epoch [298/300] Training [13/62] Loss: 0.02506 
Epoch [298/300] Training [14/62] Loss: 0.02225 
Epoch [298/300] Training [15/62] Loss: 0.03445 
Epoch [298/300] Training [16/62] Loss: 0.02444 
Epoch [298/300] Training [17/62] Loss: 0.03395 
Epoch [298/300] Training [18/62] Loss: 0.02234 
Epoch [298/300] Training [19/62] Loss: 0.03890 
Epoch [298/300] Training [20/62] Loss: 0.02845 
Epoch [298/300] Training [21/62] Loss: 0.02529 
Epoch [298/300] Training [22/62] Loss: 0.02412 
Epoch [298/300] Training [23/62] Loss: 0.02242 
Epoch [298/300] Training [24/62] Loss: 0.02507 
Epoch [298/300] Training [25/62] Loss: 0.02171 
Epoch [298/300] Training [26/62] Loss: 0.03021 
Epoch [298/300] Training [27/62] Loss: 0.03478 
Epoch [298/300] Training [28/62] Loss: 0.02567 
Epoch [298/300] Training [29/62] Loss: 0.02773 
Epoch [298/300] Training [30/62] Loss: 0.02832 
Epoch [298/300] Training [31/62] Loss: 0.02820 
Epoch [298/300] Training [32/62] Loss: 0.02321 
Epoch [298/300] Training [33/62] Loss: 0.02423 
Epoch [298/300] Training [34/62] Loss: 0.02862 
Epoch [298/300] Training [35/62] Loss: 0.03656 
Epoch [298/300] Training [36/62] Loss: 0.02958 
Epoch [298/300] Training [37/62] Loss: 0.06050 
Epoch [298/300] Training [38/62] Loss: 0.02323 
Epoch [298/300] Training [39/62] Loss: 0.03162 
Epoch [298/300] Training [40/62] Loss: 0.02218 
Epoch [298/300] Training [41/62] Loss: 0.02940 
Epoch [298/300] Training [42/62] Loss: 0.02785 
Epoch [298/300] Training [43/62] Loss: 0.03424 
Epoch [298/300] Training [44/62] Loss: 0.03568 
Epoch [298/300] Training [45/62] Loss: 0.02175 
Epoch [298/300] Training [46/62] Loss: 0.02325 
Epoch [298/300] Training [47/62] Loss: 0.02958 
Epoch [298/300] Training [48/62] Loss: 0.03223 
Epoch [298/300] Training [49/62] Loss: 0.02900 
Epoch [298/300] Training [50/62] Loss: 0.03081 
Epoch [298/300] Training [51/62] Loss: 0.06832 
Epoch [298/300] Training [52/62] Loss: 0.03056 
Epoch [298/300] Training [53/62] Loss: 0.02389 
Epoch [298/300] Training [54/62] Loss: 0.02246 
Epoch [298/300] Training [55/62] Loss: 0.02412 
Epoch [298/300] Training [56/62] Loss: 0.02753 
Epoch [298/300] Training [57/62] Loss: 0.03529 
Epoch [298/300] Training [58/62] Loss: 0.02321 
Epoch [298/300] Training [59/62] Loss: 0.04507 
Epoch [298/300] Training [60/62] Loss: 0.02720 
Epoch [298/300] Training [61/62] Loss: 0.02519 
Epoch [298/300] Training [62/62] Loss: 0.02367 
Epoch [298/300] Training metric {'Train/mean dice_metric': 0.9799003005027771, 'Train/mean miou_metric': 0.961238443851471, 'Train/mean f1': 0.9770248532295227, 'Train/mean precision': 0.973232626914978, 'Train/mean recall': 0.9808468222618103, 'Train/mean hd95_metric': 3.3082611560821533}
Epoch [298/300] Validation [1/16] Loss: 0.55228  focal_loss 0.38218  dice_loss 0.17010 
Epoch [298/300] Validation [2/16] Loss: 0.44886  focal_loss 0.21097  dice_loss 0.23789 
Epoch [298/300] Validation [3/16] Loss: 0.34156  focal_loss 0.14431  dice_loss 0.19725 
Epoch [298/300] Validation [4/16] Loss: 0.37571  focal_loss 0.20524  dice_loss 0.17047 
Epoch [298/300] Validation [5/16] Loss: 0.35856  focal_loss 0.15202  dice_loss 0.20654 
Epoch [298/300] Validation [6/16] Loss: 0.26947  focal_loss 0.07531  dice_loss 0.19416 
Epoch [298/300] Validation [7/16] Loss: 0.16363  focal_loss 0.07227  dice_loss 0.09136 
Epoch [298/300] Validation [8/16] Loss: 0.37513  focal_loss 0.13606  dice_loss 0.23907 
Epoch [298/300] Validation [9/16] Loss: 0.20975  focal_loss 0.11209  dice_loss 0.09765 
Epoch [298/300] Validation [10/16] Loss: 0.37611  focal_loss 0.16682  dice_loss 0.20929 
Epoch [298/300] Validation [11/16] Loss: 0.11821  focal_loss 0.04967  dice_loss 0.06854 
Epoch [298/300] Validation [12/16] Loss: 0.36436  focal_loss 0.11919  dice_loss 0.24516 
Epoch [298/300] Validation [13/16] Loss: 0.19823  focal_loss 0.07387  dice_loss 0.12436 
Epoch [298/300] Validation [14/16] Loss: 0.47194  focal_loss 0.18865  dice_loss 0.28329 
Epoch [298/300] Validation [15/16] Loss: 0.27188  focal_loss 0.12203  dice_loss 0.14984 
Epoch [298/300] Validation [16/16] Loss: 0.04738  focal_loss 0.01678  dice_loss 0.03060 
Epoch [298/300] Validation metric {'Val/mean dice_metric': 0.949108362197876, 'Val/mean miou_metric': 0.9186283946037292, 'Val/mean f1': 0.951123833656311, 'Val/mean precision': 0.9515987634658813, 'Val/mean recall': 0.9506494998931885, 'Val/mean hd95_metric': 10.606596946716309}
Cheakpoint...
Epoch [298/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9491], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.949108362197876, 'Val/mean miou_metric': 0.9186283946037292, 'Val/mean f1': 0.951123833656311, 'Val/mean precision': 0.9515987634658813, 'Val/mean recall': 0.9506494998931885, 'Val/mean hd95_metric': 10.606596946716309}
Epoch [299/300] Training [1/62] Loss: 0.02335 
Epoch [299/300] Training [2/62] Loss: 0.02178 
Epoch [299/300] Training [3/62] Loss: 0.04325 
Epoch [299/300] Training [4/62] Loss: 0.02179 
Epoch [299/300] Training [5/62] Loss: 0.03625 
Epoch [299/300] Training [6/62] Loss: 0.04163 
Epoch [299/300] Training [7/62] Loss: 0.06202 
Epoch [299/300] Training [8/62] Loss: 0.03122 
Epoch [299/300] Training [9/62] Loss: 0.02212 
Epoch [299/300] Training [10/62] Loss: 0.05291 
Epoch [299/300] Training [11/62] Loss: 0.02651 
Epoch [299/300] Training [12/62] Loss: 0.02783 
Epoch [299/300] Training [13/62] Loss: 0.02309 
Epoch [299/300] Training [14/62] Loss: 0.04566 
Epoch [299/300] Training [15/62] Loss: 0.02704 
Epoch [299/300] Training [16/62] Loss: 0.03019 
Epoch [299/300] Training [17/62] Loss: 0.02609 
Epoch [299/300] Training [18/62] Loss: 0.02273 
Epoch [299/300] Training [19/62] Loss: 0.02777 
Epoch [299/300] Training [20/62] Loss: 0.01985 
Epoch [299/300] Training [21/62] Loss: 0.02618 
Epoch [299/300] Training [22/62] Loss: 0.01829 
Epoch [299/300] Training [23/62] Loss: 0.03398 
Epoch [299/300] Training [24/62] Loss: 0.02811 
Epoch [299/300] Training [25/62] Loss: 0.03130 
Epoch [299/300] Training [26/62] Loss: 0.06070 
Epoch [299/300] Training [27/62] Loss: 0.03089 
Epoch [299/300] Training [28/62] Loss: 0.02545 
Epoch [299/300] Training [29/62] Loss: 0.02413 
Epoch [299/300] Training [30/62] Loss: 0.02290 
Epoch [299/300] Training [31/62] Loss: 0.03414 
Epoch [299/300] Training [32/62] Loss: 0.02443 
Epoch [299/300] Training [33/62] Loss: 0.03248 
Epoch [299/300] Training [34/62] Loss: 0.02312 
Epoch [299/300] Training [35/62] Loss: 0.02853 
Epoch [299/300] Training [36/62] Loss: 0.03982 
Epoch [299/300] Training [37/62] Loss: 0.02713 
Epoch [299/300] Training [38/62] Loss: 0.02279 
Epoch [299/300] Training [39/62] Loss: 0.02803 
Epoch [299/300] Training [40/62] Loss: 0.02080 
Epoch [299/300] Training [41/62] Loss: 0.02175 
Epoch [299/300] Training [42/62] Loss: 0.02227 
Epoch [299/300] Training [43/62] Loss: 0.02701 
Epoch [299/300] Training [44/62] Loss: 0.03167 
Epoch [299/300] Training [45/62] Loss: 0.03342 
Epoch [299/300] Training [46/62] Loss: 0.02429 
Epoch [299/300] Training [47/62] Loss: 0.02845 
Epoch [299/300] Training [48/62] Loss: 0.03660 
Epoch [299/300] Training [49/62] Loss: 0.03328 
Epoch [299/300] Training [50/62] Loss: 0.02678 
Epoch [299/300] Training [51/62] Loss: 0.02423 
Epoch [299/300] Training [52/62] Loss: 0.02131 
Epoch [299/300] Training [53/62] Loss: 0.03741 
Epoch [299/300] Training [54/62] Loss: 0.04366 
Epoch [299/300] Training [55/62] Loss: 0.05405 
Epoch [299/300] Training [56/62] Loss: 0.02155 
Epoch [299/300] Training [57/62] Loss: 0.03136 
Epoch [299/300] Training [58/62] Loss: 0.02627 
Epoch [299/300] Training [59/62] Loss: 0.03118 
Epoch [299/300] Training [60/62] Loss: 0.03124 
Epoch [299/300] Training [61/62] Loss: 0.02527 
Epoch [299/300] Training [62/62] Loss: 0.02074 
Epoch [299/300] Training metric {'Train/mean dice_metric': 0.9798188805580139, 'Train/mean miou_metric': 0.9608214497566223, 'Train/mean f1': 0.9774355292320251, 'Train/mean precision': 0.9725418090820312, 'Train/mean recall': 0.9823786020278931, 'Train/mean hd95_metric': 3.2333924770355225}
Epoch [299/300] Validation [1/16] Loss: 0.24429  focal_loss 0.12242  dice_loss 0.12186 
Epoch [299/300] Validation [2/16] Loss: 0.51353  focal_loss 0.26663  dice_loss 0.24690 
Epoch [299/300] Validation [3/16] Loss: 0.71112  focal_loss 0.43333  dice_loss 0.27778 
Epoch [299/300] Validation [4/16] Loss: 0.33034  focal_loss 0.18076  dice_loss 0.14958 
Epoch [299/300] Validation [5/16] Loss: 0.35939  focal_loss 0.15233  dice_loss 0.20706 
Epoch [299/300] Validation [6/16] Loss: 0.22958  focal_loss 0.07011  dice_loss 0.15947 
Epoch [299/300] Validation [7/16] Loss: 0.41774  focal_loss 0.24968  dice_loss 0.16807 
Epoch [299/300] Validation [8/16] Loss: 0.29891  focal_loss 0.08993  dice_loss 0.20898 
Epoch [299/300] Validation [9/16] Loss: 0.25652  focal_loss 0.13095  dice_loss 0.12557 
Epoch [299/300] Validation [10/16] Loss: 0.37047  focal_loss 0.14236  dice_loss 0.22811 
Epoch [299/300] Validation [11/16] Loss: 0.15300  focal_loss 0.06455  dice_loss 0.08845 
Epoch [299/300] Validation [12/16] Loss: 0.37012  focal_loss 0.12482  dice_loss 0.24531 
Epoch [299/300] Validation [13/16] Loss: 0.36367  focal_loss 0.15889  dice_loss 0.20478 
Epoch [299/300] Validation [14/16] Loss: 0.45705  focal_loss 0.18019  dice_loss 0.27686 
Epoch [299/300] Validation [15/16] Loss: 0.16289  focal_loss 0.07754  dice_loss 0.08535 
Epoch [299/300] Validation [16/16] Loss: 0.04494  focal_loss 0.01525  dice_loss 0.02968 
Epoch [299/300] Validation metric {'Val/mean dice_metric': 0.9476898908615112, 'Val/mean miou_metric': 0.9164225459098816, 'Val/mean f1': 0.9498301148414612, 'Val/mean precision': 0.9495466947555542, 'Val/mean recall': 0.9501135945320129, 'Val/mean hd95_metric': 11.164729118347168}
Cheakpoint...
Epoch [299/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9477], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9476898908615112, 'Val/mean miou_metric': 0.9164225459098816, 'Val/mean f1': 0.9498301148414612, 'Val/mean precision': 0.9495466947555542, 'Val/mean recall': 0.9501135945320129, 'Val/mean hd95_metric': 11.164729118347168}
Epoch [300/300] Training [1/62] Loss: 0.02928 
Epoch [300/300] Training [2/62] Loss: 0.03468 
Epoch [300/300] Training [3/62] Loss: 0.02905 
Epoch [300/300] Training [4/62] Loss: 0.02649 
Epoch [300/300] Training [5/62] Loss: 0.03046 
Epoch [300/300] Training [6/62] Loss: 0.03450 
Epoch [300/300] Training [7/62] Loss: 0.02755 
Epoch [300/300] Training [8/62] Loss: 0.03079 
Epoch [300/300] Training [9/62] Loss: 0.02671 
Epoch [300/300] Training [10/62] Loss: 0.01928 
Epoch [300/300] Training [11/62] Loss: 0.03473 
Epoch [300/300] Training [12/62] Loss: 0.04191 
Epoch [300/300] Training [13/62] Loss: 0.03121 
Epoch [300/300] Training [14/62] Loss: 0.02159 
Epoch [300/300] Training [15/62] Loss: 0.02255 
Epoch [300/300] Training [16/62] Loss: 0.02703 
Epoch [300/300] Training [17/62] Loss: 0.02485 
Epoch [300/300] Training [18/62] Loss: 0.02329 
Epoch [300/300] Training [19/62] Loss: 0.02415 
Epoch [300/300] Training [20/62] Loss: 0.02135 
Epoch [300/300] Training [21/62] Loss: 0.04159 
Epoch [300/300] Training [22/62] Loss: 0.02732 
Epoch [300/300] Training [23/62] Loss: 0.02989 
Epoch [300/300] Training [24/62] Loss: 0.02296 
Epoch [300/300] Training [25/62] Loss: 0.02704 
Epoch [300/300] Training [26/62] Loss: 0.02856 
Epoch [300/300] Training [27/62] Loss: 0.02538 
Epoch [300/300] Training [28/62] Loss: 0.03205 
Epoch [300/300] Training [29/62] Loss: 0.02077 
Epoch [300/300] Training [30/62] Loss: 0.02935 
Epoch [300/300] Training [31/62] Loss: 0.02833 
Epoch [300/300] Training [32/62] Loss: 0.02724 
Epoch [300/300] Training [33/62] Loss: 0.03207 
Epoch [300/300] Training [34/62] Loss: 0.02048 
Epoch [300/300] Training [35/62] Loss: 0.03535 
Epoch [300/300] Training [36/62] Loss: 0.03274 
Epoch [300/300] Training [37/62] Loss: 0.02578 
Epoch [300/300] Training [38/62] Loss: 0.05641 
Epoch [300/300] Training [39/62] Loss: 0.02557 
Epoch [300/300] Training [40/62] Loss: 0.04003 
Epoch [300/300] Training [41/62] Loss: 0.02686 
Epoch [300/300] Training [42/62] Loss: 0.02409 
Epoch [300/300] Training [43/62] Loss: 0.02414 
Epoch [300/300] Training [44/62] Loss: 0.02398 
Epoch [300/300] Training [45/62] Loss: 0.02400 
Epoch [300/300] Training [46/62] Loss: 0.02690 
Epoch [300/300] Training [47/62] Loss: 0.02425 
Epoch [300/300] Training [48/62] Loss: 0.04432 
Epoch [300/300] Training [49/62] Loss: 0.02997 
Epoch [300/300] Training [50/62] Loss: 0.03965 
Epoch [300/300] Training [51/62] Loss: 0.02347 
Epoch [300/300] Training [52/62] Loss: 0.03754 
Epoch [300/300] Training [53/62] Loss: 0.02050 
Epoch [300/300] Training [54/62] Loss: 0.03032 
Epoch [300/300] Training [55/62] Loss: 0.02370 
Epoch [300/300] Training [56/62] Loss: 0.03625 
Epoch [300/300] Training [57/62] Loss: 0.02891 
Epoch [300/300] Training [58/62] Loss: 0.02857 
Epoch [300/300] Training [59/62] Loss: 0.02583 
Epoch [300/300] Training [60/62] Loss: 0.02305 
Epoch [300/300] Training [61/62] Loss: 0.03448 
Epoch [300/300] Training [62/62] Loss: 0.01830 
Epoch [300/300] Training metric {'Train/mean dice_metric': 0.9806668758392334, 'Train/mean miou_metric': 0.9621762037277222, 'Train/mean f1': 0.977617084980011, 'Train/mean precision': 0.972789466381073, 'Train/mean recall': 0.9824928641319275, 'Train/mean hd95_metric': 2.6055819988250732}
Epoch [300/300] Validation [1/16] Loss: 0.54863  focal_loss 0.34535  dice_loss 0.20328 
Epoch [300/300] Validation [2/16] Loss: 0.49742  focal_loss 0.25803  dice_loss 0.23938 
Epoch [300/300] Validation [3/16] Loss: 0.67952  focal_loss 0.42362  dice_loss 0.25590 
Epoch [300/300] Validation [4/16] Loss: 0.31795  focal_loss 0.17417  dice_loss 0.14378 
Epoch [300/300] Validation [5/16] Loss: 0.36220  focal_loss 0.12698  dice_loss 0.23522 
Epoch [300/300] Validation [6/16] Loss: 0.24433  focal_loss 0.06901  dice_loss 0.17531 
Epoch [300/300] Validation [7/16] Loss: 0.34159  focal_loss 0.19735  dice_loss 0.14425 
Epoch [300/300] Validation [8/16] Loss: 0.40854  focal_loss 0.14712  dice_loss 0.26142 
Epoch [300/300] Validation [9/16] Loss: 0.28268  focal_loss 0.13768  dice_loss 0.14500 
Epoch [300/300] Validation [10/16] Loss: 0.26982  focal_loss 0.12278  dice_loss 0.14705 
Epoch [300/300] Validation [11/16] Loss: 0.12349  focal_loss 0.04860  dice_loss 0.07489 
Epoch [300/300] Validation [12/16] Loss: 0.32565  focal_loss 0.08578  dice_loss 0.23987 
Epoch [300/300] Validation [13/16] Loss: 0.39286  focal_loss 0.18317  dice_loss 0.20969 
Epoch [300/300] Validation [14/16] Loss: 0.54671  focal_loss 0.21561  dice_loss 0.33110 
Epoch [300/300] Validation [15/16] Loss: 0.12370  focal_loss 0.05408  dice_loss 0.06962 
Epoch [300/300] Validation [16/16] Loss: 0.04340  focal_loss 0.01496  dice_loss 0.02844 
Epoch [300/300] Validation metric {'Val/mean dice_metric': 0.9472953677177429, 'Val/mean miou_metric': 0.9171573519706726, 'Val/mean f1': 0.9500738978385925, 'Val/mean precision': 0.9510849118232727, 'Val/mean recall': 0.949065089225769, 'Val/mean hd95_metric': 10.285833358764648}
Cheakpoint...
Epoch [300/300] best acc:tensor([0.9529], device='cuda:0'), Now : mean acc: tensor([0.9473], device='cuda:0'), mean class: {'Val/mean dice_metric': 0.9472953677177429, 'Val/mean miou_metric': 0.9171573519706726, 'Val/mean f1': 0.9500738978385925, 'Val/mean precision': 0.9510849118232727, 'Val/mean recall': 0.949065089225769, 'Val/mean hd95_metric': 10.285833358764648}
最高acc: tensor([0.9529], device='cuda:0')
最高class : {'Val/mean dice_metric': 0.9528906345367432, 'Val/mean miou_metric': 0.9216292500495911, 'Val/mean f1': 0.9552038908004761, 'Val/mean precision': 0.9547762274742126, 'Val/mean recall': 0.9556320309638977, 'Val/mean hd95_metric': 9.687213897705078}
最优保存轮数: 277
